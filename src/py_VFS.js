__BRYTHON__.use_VFS = true;
__BRYTHON__.VFS={"heapq": [".py", "\"\"\"Heap queue algorithm (a.k.a. priority queue).\n\nHeaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for\nall k, counting elements from 0.  For the sake of comparison,\nnon-existing elements are considered to be infinite.  The interesting\nproperty of a heap is that a[0] is always its smallest element.\n\nUsage:\n\nheap = []            # creates an empty heap\nheappush(heap, item) # pushes a new item on the heap\nitem = heappop(heap) # pops the smallest item from the heap\nitem = heap[0]       # smallest item on the heap without popping it\nheapify(x)           # transforms list into a heap, in-place, in linear time\nitem = heapreplace(heap, item) # pops and returns smallest item, and adds\n                               # new item; the heap size is unchanged\n\nOur API differs from textbook heap algorithms as follows:\n\n- We use 0-based indexing.  This makes the relationship between the\n  index for a node and the indexes for its children slightly less\n  obvious, but is more suitable since Python uses 0-based indexing.\n\n- Our heappop() method returns the smallest item, not the largest.\n\nThese two make it possible to view the heap as a regular Python list\nwithout surprises: heap[0] is the smallest item, and heap.sort()\nmaintains the heap invariant!\n\"\"\"\n\n# Original code by Kevin O'Connor, augmented by Tim Peters and Raymond Hettinger\n\n__about__ = \"\"\"Heap queues\n\n[explanation by Fran\u00e7ois Pinard]\n\nHeaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for\nall k, counting elements from 0.  For the sake of comparison,\nnon-existing elements are considered to be infinite.  The interesting\nproperty of a heap is that a[0] is always its smallest element.\n\nThe strange invariant above is meant to be an efficient memory\nrepresentation for a tournament.  The numbers below are `k', not a[k]:\n\n                                   0\n\n                  1                                 2\n\n          3               4                5               6\n\n      7       8       9       10      11      12      13      14\n\n    15 16   17 18   19 20   21 22   23 24   25 26   27 28   29 30\n\n\nIn the tree above, each cell `k' is topping `2*k+1' and `2*k+2'.  In\nan usual binary tournament we see in sports, each cell is the winner\nover the two cells it tops, and we can trace the winner down the tree\nto see all opponents s/he had.  However, in many computer applications\nof such tournaments, we do not need to trace the history of a winner.\nTo be more memory efficient, when a winner is promoted, we try to\nreplace it by something else at a lower level, and the rule becomes\nthat a cell and the two cells it tops contain three different items,\nbut the top cell \"wins\" over the two topped cells.\n\nIf this heap invariant is protected at all time, index 0 is clearly\nthe overall winner.  The simplest algorithmic way to remove it and\nfind the \"next\" winner is to move some loser (let's say cell 30 in the\ndiagram above) into the 0 position, and then percolate this new 0 down\nthe tree, exchanging values, until the invariant is re-established.\nThis is clearly logarithmic on the total number of items in the tree.\nBy iterating over all items, you get an O(n ln n) sort.\n\nA nice feature of this sort is that you can efficiently insert new\nitems while the sort is going on, provided that the inserted items are\nnot \"better\" than the last 0'th element you extracted.  This is\nespecially useful in simulation contexts, where the tree holds all\nincoming events, and the \"win\" condition means the smallest scheduled\ntime.  When an event schedule other events for execution, they are\nscheduled into the future, so they can easily go into the heap.  So, a\nheap is a good structure for implementing schedulers (this is what I\nused for my MIDI sequencer :-).\n\nVarious structures for implementing schedulers have been extensively\nstudied, and heaps are good for this, as they are reasonably speedy,\nthe speed is almost constant, and the worst case is not much different\nthan the average case.  However, there are other representations which\nare more efficient overall, yet the worst cases might be terrible.\n\nHeaps are also very useful in big disk sorts.  You most probably all\nknow that a big sort implies producing \"runs\" (which are pre-sorted\nsequences, which size is usually related to the amount of CPU memory),\nfollowed by a merging passes for these runs, which merging is often\nvery cleverly organised[1].  It is very important that the initial\nsort produces the longest runs possible.  Tournaments are a good way\nto that.  If, using all the memory available to hold a tournament, you\nreplace and percolate items that happen to fit the current run, you'll\nproduce runs which are twice the size of the memory for random input,\nand much better for input fuzzily ordered.\n\nMoreover, if you output the 0'th item on disk and get an input which\nmay not fit in the current tournament (because the value \"wins\" over\nthe last output value), it cannot fit in the heap, so the size of the\nheap decreases.  The freed memory could be cleverly reused immediately\nfor progressively building a second heap, which grows at exactly the\nsame rate the first heap is melting.  When the first heap completely\nvanishes, you switch heaps and start a new run.  Clever and quite\neffective!\n\nIn a word, heaps are useful memory structures to know.  I use them in\na few applications, and I think it is good to keep a `heap' module\naround. :-)\n\n--------------------\n[1] The disk balancing algorithms which are current, nowadays, are\nmore annoying than clever, and this is a consequence of the seeking\ncapabilities of the disks.  On devices which cannot seek, like big\ntape drives, the story was quite different, and one had to be very\nclever to ensure (far in advance) that each tape movement will be the\nmost effective possible (that is, will best participate at\n\"progressing\" the merge).  Some tapes were even able to read\nbackwards, and this was also used to avoid the rewinding time.\nBelieve me, real good tape sorts were quite spectacular to watch!\nFrom all times, sorting has always been a Great Art! :-)\n\"\"\"\n\n__all__ = ['heappush', 'heappop', 'heapify', 'heapreplace', 'merge',\n           'nlargest', 'nsmallest', 'heappushpop']\n\nfrom itertools import islice, count, tee, chain\n\ndef heappush(heap, item):\n    \"\"\"Push item onto heap, maintaining the heap invariant.\"\"\"\n    heap.append(item)\n    _siftdown(heap, 0, len(heap)-1)\n\ndef heappop(heap):\n    \"\"\"Pop the smallest item off the heap, maintaining the heap invariant.\"\"\"\n    lastelt = heap.pop()    # raises appropriate IndexError if heap is empty\n    if heap:\n        returnitem = heap[0]\n        heap[0] = lastelt\n        _siftup(heap, 0)\n    else:\n        returnitem = lastelt\n    return returnitem\n\ndef heapreplace(heap, item):\n    \"\"\"Pop and return the current smallest value, and add the new item.\n\n    This is more efficient than heappop() followed by heappush(), and can be\n    more appropriate when using a fixed-size heap.  Note that the value\n    returned may be larger than item!  That constrains reasonable uses of\n    this routine unless written as part of a conditional replacement:\n\n        if item > heap[0]:\n            item = heapreplace(heap, item)\n    \"\"\"\n    returnitem = heap[0]    # raises appropriate IndexError if heap is empty\n    heap[0] = item\n    _siftup(heap, 0)\n    return returnitem\n\ndef heappushpop(heap, item):\n    \"\"\"Fast version of a heappush followed by a heappop.\"\"\"\n    if heap and heap[0] < item:\n        item, heap[0] = heap[0], item\n        _siftup(heap, 0)\n    return item\n\ndef heapify(x):\n    \"\"\"Transform list into a heap, in-place, in O(len(x)) time.\"\"\"\n    n = len(x)\n    # Transform bottom-up.  The largest index there's any point to looking at\n    # is the largest with a child index in-range, so must have 2*i + 1 < n,\n    # or i < (n-1)/2.  If n is even = 2*j, this is (2*j-1)/2 = j-1/2 so\n    # j-1 is the largest, which is n//2 - 1.  If n is odd = 2*j+1, this is\n    # (2*j+1-1)/2 = j so j-1 is the largest, and that's again n//2-1.\n    for i in reversed(range(n//2)):\n        _siftup(x, i)\n\ndef _heappushpop_max(heap, item):\n    \"\"\"Maxheap version of a heappush followed by a heappop.\"\"\"\n    if heap and item < heap[0]:\n        item, heap[0] = heap[0], item\n        _siftup_max(heap, 0)\n    return item\n\ndef _heapify_max(x):\n    \"\"\"Transform list into a maxheap, in-place, in O(len(x)) time.\"\"\"\n    n = len(x)\n    for i in reversed(range(n//2)):\n        _siftup_max(x, i)\n\ndef nlargest(n, iterable):\n    \"\"\"Find the n largest elements in a dataset.\n\n    Equivalent to:  sorted(iterable, reverse=True)[:n]\n    \"\"\"\n    if n < 0:\n        return []\n    it = iter(iterable)\n    result = list(islice(it, n))\n    if not result:\n        return result\n    heapify(result)\n    _heappushpop = heappushpop\n    for elem in it:\n        _heappushpop(result, elem)\n    result.sort(reverse=True)\n    return result\n\ndef nsmallest(n, iterable):\n    \"\"\"Find the n smallest elements in a dataset.\n\n    Equivalent to:  sorted(iterable)[:n]\n    \"\"\"\n    if n < 0:\n        return []\n    it = iter(iterable)\n    result = list(islice(it, n))\n    if not result:\n        return result\n    _heapify_max(result)\n    _heappushpop = _heappushpop_max\n    for elem in it:\n        _heappushpop(result, elem)\n    result.sort()\n    return result\n\n# 'heap' is a heap at all indices >= startpos, except possibly for pos.  pos\n# is the index of a leaf with a possibly out-of-order value.  Restore the\n# heap invariant.\ndef _siftdown(heap, startpos, pos):\n    newitem = heap[pos]\n    # Follow the path to the root, moving parents down until finding a place\n    # newitem fits.\n    while pos > startpos:\n        parentpos = (pos - 1) >> 1\n        parent = heap[parentpos]\n        if newitem < parent:\n            heap[pos] = parent\n            pos = parentpos\n            continue\n        break\n    heap[pos] = newitem\n\n# The child indices of heap index pos are already heaps, and we want to make\n# a heap at index pos too.  We do this by bubbling the smaller child of\n# pos up (and so on with that child's children, etc) until hitting a leaf,\n# then using _siftdown to move the oddball originally at index pos into place.\n#\n# We *could* break out of the loop as soon as we find a pos where newitem <=\n# both its children, but turns out that's not a good idea, and despite that\n# many books write the algorithm that way.  During a heap pop, the last array\n# element is sifted in, and that tends to be large, so that comparing it\n# against values starting from the root usually doesn't pay (= usually doesn't\n# get us out of the loop early).  See Knuth, Volume 3, where this is\n# explained and quantified in an exercise.\n#\n# Cutting the # of comparisons is important, since these routines have no\n# way to extract \"the priority\" from an array element, so that intelligence\n# is likely to be hiding in custom comparison methods, or in array elements\n# storing (priority, record) tuples.  Comparisons are thus potentially\n# expensive.\n#\n# On random arrays of length 1000, making this change cut the number of\n# comparisons made by heapify() a little, and those made by exhaustive\n# heappop() a lot, in accord with theory.  Here are typical results from 3\n# runs (3 just to demonstrate how small the variance is):\n#\n# Compares needed by heapify     Compares needed by 1000 heappops\n# --------------------------     --------------------------------\n# 1837 cut to 1663               14996 cut to 8680\n# 1855 cut to 1659               14966 cut to 8678\n# 1847 cut to 1660               15024 cut to 8703\n#\n# Building the heap by using heappush() 1000 times instead required\n# 2198, 2148, and 2219 compares:  heapify() is more efficient, when\n# you can use it.\n#\n# The total compares needed by list.sort() on the same lists were 8627,\n# 8627, and 8632 (this should be compared to the sum of heapify() and\n# heappop() compares):  list.sort() is (unsurprisingly!) more efficient\n# for sorting.\n\ndef _siftup(heap, pos):\n    endpos = len(heap)\n    startpos = pos\n    newitem = heap[pos]\n    # Bubble up the smaller child until hitting a leaf.\n    childpos = 2*pos + 1    # leftmost child position\n    while childpos < endpos:\n        # Set childpos to index of smaller child.\n        rightpos = childpos + 1\n        if rightpos < endpos and not heap[childpos] < heap[rightpos]:\n            childpos = rightpos\n        # Move the smaller child up.\n        heap[pos] = heap[childpos]\n        pos = childpos\n        childpos = 2*pos + 1\n    # The leaf at pos is empty now.  Put newitem there, and bubble it up\n    # to its final resting place (by sifting its parents down).\n    heap[pos] = newitem\n    _siftdown(heap, startpos, pos)\n\ndef _siftdown_max(heap, startpos, pos):\n    'Maxheap variant of _siftdown'\n    newitem = heap[pos]\n    # Follow the path to the root, moving parents down until finding a place\n    # newitem fits.\n    while pos > startpos:\n        parentpos = (pos - 1) >> 1\n        parent = heap[parentpos]\n        if parent < newitem:\n            heap[pos] = parent\n            pos = parentpos\n            continue\n        break\n    heap[pos] = newitem\n\ndef _siftup_max(heap, pos):\n    'Maxheap variant of _siftup'\n    endpos = len(heap)\n    startpos = pos\n    newitem = heap[pos]\n    # Bubble up the larger child until hitting a leaf.\n    childpos = 2*pos + 1    # leftmost child position\n    while childpos < endpos:\n        # Set childpos to index of larger child.\n        rightpos = childpos + 1\n        if rightpos < endpos and not heap[rightpos] < heap[childpos]:\n            childpos = rightpos\n        # Move the larger child up.\n        heap[pos] = heap[childpos]\n        pos = childpos\n        childpos = 2*pos + 1\n    # The leaf at pos is empty now.  Put newitem there, and bubble it up\n    # to its final resting place (by sifting its parents down).\n    heap[pos] = newitem\n    _siftdown_max(heap, startpos, pos)\n\n# If available, use C implementation\ntry:\n    from _heapq import *\nexcept ImportError:\n    pass\n\ndef merge(*iterables):\n    '''Merge multiple sorted inputs into a single sorted output.\n\n    Similar to sorted(itertools.chain(*iterables)) but returns a generator,\n    does not pull the data into memory all at once, and assumes that each of\n    the input streams is already sorted (smallest to largest).\n\n    >>> list(merge([1,3,5,7], [0,2,4,8], [5,10,15,20], [], [25]))\n    [0, 1, 2, 3, 4, 5, 5, 7, 8, 10, 15, 20, 25]\n\n    '''\n    _heappop, _heapreplace, _StopIteration = heappop, heapreplace, StopIteration\n    _len = len\n\n    h = []\n    h_append = h.append\n    for itnum, it in enumerate(map(iter, iterables)):\n        try:\n            next = it.__next__\n            h_append([next(), itnum, next])\n        except _StopIteration:\n            pass\n    heapify(h)\n\n    while _len(h) > 1:\n        try:\n            while True:\n                v, itnum, next = s = h[0]\n                yield v\n                s[0] = next()               # raises StopIteration when exhausted\n                _heapreplace(h, s)          # restore heap condition\n        except _StopIteration:\n            _heappop(h)                     # remove empty iterator\n    if h:\n        # fast case when only a single iterator remains\n        v, itnum, next = h[0]\n        yield v\n        yield from next.__self__\n\n# Extend the implementations of nsmallest and nlargest to use a key= argument\n_nsmallest = nsmallest\ndef nsmallest(n, iterable, key=None):\n    \"\"\"Find the n smallest elements in a dataset.\n\n    Equivalent to:  sorted(iterable, key=key)[:n]\n    \"\"\"\n    # Short-cut for n==1 is to use min() when len(iterable)>0\n    if n == 1:\n        it = iter(iterable)\n        head = list(islice(it, 1))\n        if not head:\n            return []\n        if key is None:\n            return [min(chain(head, it))]\n        return [min(chain(head, it), key=key)]\n\n    # When n>=size, it's faster to use sorted()\n    try:\n        size = len(iterable)\n    except (TypeError, AttributeError):\n        pass\n    else:\n        if n >= size:\n            return sorted(iterable, key=key)[:n]\n\n    # When key is none, use simpler decoration\n    if key is None:\n        it = zip(iterable, count())                         # decorate\n        result = _nsmallest(n, it)\n        return [r[0] for r in result]                       # undecorate\n\n    # General case, slowest method\n    in1, in2 = tee(iterable)\n    it = zip(map(key, in1), count(), in2)                   # decorate\n    result = _nsmallest(n, it)\n    return [r[2] for r in result]                           # undecorate\n\n_nlargest = nlargest\ndef nlargest(n, iterable, key=None):\n    \"\"\"Find the n largest elements in a dataset.\n\n    Equivalent to:  sorted(iterable, key=key, reverse=True)[:n]\n    \"\"\"\n\n    # Short-cut for n==1 is to use max() when len(iterable)>0\n    if n == 1:\n        it = iter(iterable)\n        head = list(islice(it, 1))\n        if not head:\n            return []\n        if key is None:\n            return [max(chain(head, it))]\n        return [max(chain(head, it), key=key)]\n\n    # When n>=size, it's faster to use sorted()\n    try:\n        size = len(iterable)\n    except (TypeError, AttributeError):\n        pass\n    else:\n        if n >= size:\n            return sorted(iterable, key=key, reverse=True)[:n]\n\n    # When key is none, use simpler decoration\n    if key is None:\n        it = zip(iterable, count(0,-1))                     # decorate\n        result = _nlargest(n, it)\n        return [r[0] for r in result]                       # undecorate\n\n    # General case, slowest method\n    in1, in2 = tee(iterable)\n    it = zip(map(key, in1), count(0,-1), in2)               # decorate\n    result = _nlargest(n, it)\n    return [r[2] for r in result]                           # undecorate\n\nif __name__ == \"__main__\":\n    # Simple sanity test\n    heap = []\n    data = [1, 3, 5, 7, 9, 2, 4, 6, 8, 0]\n    for item in data:\n        heappush(heap, item)\n    sort = []\n    while heap:\n        sort.append(heappop(heap))\n    print(sort)\n\n    import doctest\n    doctest.testmod()\n"], "crypto_js.rollups.sha384": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(a,c){var d={},j=d.lib={},f=function(){},m=j.Base={extend:function(a){f.prototype=this;var b=new f;a&&b.mixIn(a);b.hasOwnProperty(\"init\")||(b.init=function(){b.$super.init.apply(this,arguments)});b.init.prototype=b;b.$super=this;return b},create:function(){var a=this.extend();a.init.apply(a,arguments);return a},init:function(){},mixIn:function(a){for(var b in a)a.hasOwnProperty(b)&&(this[b]=a[b]);a.hasOwnProperty(\"toString\")&&(this.toString=a.toString)},clone:function(){return this.init.prototype.extend(this)}},\nB=j.WordArray=m.extend({init:function(a,b){a=this.words=a||[];this.sigBytes=b!=c?b:4*a.length},toString:function(a){return(a||y).stringify(this)},concat:function(a){var b=this.words,g=a.words,e=this.sigBytes;a=a.sigBytes;this.clamp();if(e%4)for(var k=0;k<a;k++)b[e+k>>>2]|=(g[k>>>2]>>>24-8*(k%4)&255)<<24-8*((e+k)%4);else if(65535<g.length)for(k=0;k<a;k+=4)b[e+k>>>2]=g[k>>>2];else b.push.apply(b,g);this.sigBytes+=a;return this},clamp:function(){var n=this.words,b=this.sigBytes;n[b>>>2]&=4294967295<<\n32-8*(b%4);n.length=a.ceil(b/4)},clone:function(){var a=m.clone.call(this);a.words=this.words.slice(0);return a},random:function(n){for(var b=[],g=0;g<n;g+=4)b.push(4294967296*a.random()|0);return new B.init(b,n)}}),v=d.enc={},y=v.Hex={stringify:function(a){var b=a.words;a=a.sigBytes;for(var g=[],e=0;e<a;e++){var k=b[e>>>2]>>>24-8*(e%4)&255;g.push((k>>>4).toString(16));g.push((k&15).toString(16))}return g.join(\"\")},parse:function(a){for(var b=a.length,g=[],e=0;e<b;e+=2)g[e>>>3]|=parseInt(a.substr(e,\n2),16)<<24-4*(e%8);return new B.init(g,b/2)}},F=v.Latin1={stringify:function(a){var b=a.words;a=a.sigBytes;for(var g=[],e=0;e<a;e++)g.push(String.fromCharCode(b[e>>>2]>>>24-8*(e%4)&255));return g.join(\"\")},parse:function(a){for(var b=a.length,g=[],e=0;e<b;e++)g[e>>>2]|=(a.charCodeAt(e)&255)<<24-8*(e%4);return new B.init(g,b)}},ha=v.Utf8={stringify:function(a){try{return decodeURIComponent(escape(F.stringify(a)))}catch(b){throw Error(\"Malformed UTF-8 data\");}},parse:function(a){return F.parse(unescape(encodeURIComponent(a)))}},\nZ=j.BufferedBlockAlgorithm=m.extend({reset:function(){this._data=new B.init;this._nDataBytes=0},_append:function(a){\"string\"==typeof a&&(a=ha.parse(a));this._data.concat(a);this._nDataBytes+=a.sigBytes},_process:function(n){var b=this._data,g=b.words,e=b.sigBytes,k=this.blockSize,m=e/(4*k),m=n?a.ceil(m):a.max((m|0)-this._minBufferSize,0);n=m*k;e=a.min(4*n,e);if(n){for(var c=0;c<n;c+=k)this._doProcessBlock(g,c);c=g.splice(0,n);b.sigBytes-=e}return new B.init(c,e)},clone:function(){var a=m.clone.call(this);\na._data=this._data.clone();return a},_minBufferSize:0});j.Hasher=Z.extend({cfg:m.extend(),init:function(a){this.cfg=this.cfg.extend(a);this.reset()},reset:function(){Z.reset.call(this);this._doReset()},update:function(a){this._append(a);this._process();return this},finalize:function(a){a&&this._append(a);return this._doFinalize()},blockSize:16,_createHelper:function(a){return function(b,g){return(new a.init(g)).finalize(b)}},_createHmacHelper:function(a){return function(b,g){return(new ia.HMAC.init(a,\ng)).finalize(b)}}});var ia=d.algo={};return d}(Math);\n(function(a){var c=CryptoJS,d=c.lib,j=d.Base,f=d.WordArray,c=c.x64={};c.Word=j.extend({init:function(a,c){this.high=a;this.low=c}});c.WordArray=j.extend({init:function(c,d){c=this.words=c||[];this.sigBytes=d!=a?d:8*c.length},toX32:function(){for(var a=this.words,c=a.length,d=[],j=0;j<c;j++){var F=a[j];d.push(F.high);d.push(F.low)}return f.create(d,this.sigBytes)},clone:function(){for(var a=j.clone.call(this),c=a.words=this.words.slice(0),d=c.length,f=0;f<d;f++)c[f]=c[f].clone();return a}})})();\n(function(){function a(){return f.create.apply(f,arguments)}for(var c=CryptoJS,d=c.lib.Hasher,j=c.x64,f=j.Word,m=j.WordArray,j=c.algo,B=[a(1116352408,3609767458),a(1899447441,602891725),a(3049323471,3964484399),a(3921009573,2173295548),a(961987163,4081628472),a(1508970993,3053834265),a(2453635748,2937671579),a(2870763221,3664609560),a(3624381080,2734883394),a(310598401,1164996542),a(607225278,1323610764),a(1426881987,3590304994),a(1925078388,4068182383),a(2162078206,991336113),a(2614888103,633803317),\na(3248222580,3479774868),a(3835390401,2666613458),a(4022224774,944711139),a(264347078,2341262773),a(604807628,2007800933),a(770255983,1495990901),a(1249150122,1856431235),a(1555081692,3175218132),a(1996064986,2198950837),a(2554220882,3999719339),a(2821834349,766784016),a(2952996808,2566594879),a(3210313671,3203337956),a(3336571891,1034457026),a(3584528711,2466948901),a(113926993,3758326383),a(338241895,168717936),a(666307205,1188179964),a(773529912,1546045734),a(1294757372,1522805485),a(1396182291,\n2643833823),a(1695183700,2343527390),a(1986661051,1014477480),a(2177026350,1206759142),a(2456956037,344077627),a(2730485921,1290863460),a(2820302411,3158454273),a(3259730800,3505952657),a(3345764771,106217008),a(3516065817,3606008344),a(3600352804,1432725776),a(4094571909,1467031594),a(275423344,851169720),a(430227734,3100823752),a(506948616,1363258195),a(659060556,3750685593),a(883997877,3785050280),a(958139571,3318307427),a(1322822218,3812723403),a(1537002063,2003034995),a(1747873779,3602036899),\na(1955562222,1575990012),a(2024104815,1125592928),a(2227730452,2716904306),a(2361852424,442776044),a(2428436474,593698344),a(2756734187,3733110249),a(3204031479,2999351573),a(3329325298,3815920427),a(3391569614,3928383900),a(3515267271,566280711),a(3940187606,3454069534),a(4118630271,4000239992),a(116418474,1914138554),a(174292421,2731055270),a(289380356,3203993006),a(460393269,320620315),a(685471733,587496836),a(852142971,1086792851),a(1017036298,365543100),a(1126000580,2618297676),a(1288033470,\n3409855158),a(1501505948,4234509866),a(1607167915,987167468),a(1816402316,1246189591)],v=[],y=0;80>y;y++)v[y]=a();j=j.SHA512=d.extend({_doReset:function(){this._hash=new m.init([new f.init(1779033703,4089235720),new f.init(3144134277,2227873595),new f.init(1013904242,4271175723),new f.init(2773480762,1595750129),new f.init(1359893119,2917565137),new f.init(2600822924,725511199),new f.init(528734635,4215389547),new f.init(1541459225,327033209)])},_doProcessBlock:function(a,c){for(var d=this._hash.words,\nf=d[0],j=d[1],b=d[2],g=d[3],e=d[4],k=d[5],m=d[6],d=d[7],y=f.high,M=f.low,$=j.high,N=j.low,aa=b.high,O=b.low,ba=g.high,P=g.low,ca=e.high,Q=e.low,da=k.high,R=k.low,ea=m.high,S=m.low,fa=d.high,T=d.low,s=y,p=M,G=$,D=N,H=aa,E=O,W=ba,I=P,t=ca,q=Q,U=da,J=R,V=ea,K=S,X=fa,L=T,u=0;80>u;u++){var z=v[u];if(16>u)var r=z.high=a[c+2*u]|0,h=z.low=a[c+2*u+1]|0;else{var r=v[u-15],h=r.high,w=r.low,r=(h>>>1|w<<31)^(h>>>8|w<<24)^h>>>7,w=(w>>>1|h<<31)^(w>>>8|h<<24)^(w>>>7|h<<25),C=v[u-2],h=C.high,l=C.low,C=(h>>>19|l<<\n13)^(h<<3|l>>>29)^h>>>6,l=(l>>>19|h<<13)^(l<<3|h>>>29)^(l>>>6|h<<26),h=v[u-7],Y=h.high,A=v[u-16],x=A.high,A=A.low,h=w+h.low,r=r+Y+(h>>>0<w>>>0?1:0),h=h+l,r=r+C+(h>>>0<l>>>0?1:0),h=h+A,r=r+x+(h>>>0<A>>>0?1:0);z.high=r;z.low=h}var Y=t&U^~t&V,A=q&J^~q&K,z=s&G^s&H^G&H,ja=p&D^p&E^D&E,w=(s>>>28|p<<4)^(s<<30|p>>>2)^(s<<25|p>>>7),C=(p>>>28|s<<4)^(p<<30|s>>>2)^(p<<25|s>>>7),l=B[u],ka=l.high,ga=l.low,l=L+((q>>>14|t<<18)^(q>>>18|t<<14)^(q<<23|t>>>9)),x=X+((t>>>14|q<<18)^(t>>>18|q<<14)^(t<<23|q>>>9))+(l>>>0<\nL>>>0?1:0),l=l+A,x=x+Y+(l>>>0<A>>>0?1:0),l=l+ga,x=x+ka+(l>>>0<ga>>>0?1:0),l=l+h,x=x+r+(l>>>0<h>>>0?1:0),h=C+ja,z=w+z+(h>>>0<C>>>0?1:0),X=V,L=K,V=U,K=J,U=t,J=q,q=I+l|0,t=W+x+(q>>>0<I>>>0?1:0)|0,W=H,I=E,H=G,E=D,G=s,D=p,p=l+h|0,s=x+z+(p>>>0<l>>>0?1:0)|0}M=f.low=M+p;f.high=y+s+(M>>>0<p>>>0?1:0);N=j.low=N+D;j.high=$+G+(N>>>0<D>>>0?1:0);O=b.low=O+E;b.high=aa+H+(O>>>0<E>>>0?1:0);P=g.low=P+I;g.high=ba+W+(P>>>0<I>>>0?1:0);Q=e.low=Q+q;e.high=ca+t+(Q>>>0<q>>>0?1:0);R=k.low=R+J;k.high=da+U+(R>>>0<J>>>0?1:0);\nS=m.low=S+K;m.high=ea+V+(S>>>0<K>>>0?1:0);T=d.low=T+L;d.high=fa+X+(T>>>0<L>>>0?1:0)},_doFinalize:function(){var a=this._data,c=a.words,d=8*this._nDataBytes,f=8*a.sigBytes;c[f>>>5]|=128<<24-f%32;c[(f+128>>>10<<5)+30]=Math.floor(d/4294967296);c[(f+128>>>10<<5)+31]=d;a.sigBytes=4*c.length;this._process();return this._hash.toX32()},clone:function(){var a=d.clone.call(this);a._hash=this._hash.clone();return a},blockSize:32});c.SHA512=d._createHelper(j);c.HmacSHA512=d._createHmacHelper(j)})();\n(function(){var a=CryptoJS,c=a.x64,d=c.Word,j=c.WordArray,c=a.algo,f=c.SHA512,c=c.SHA384=f.extend({_doReset:function(){this._hash=new j.init([new d.init(3418070365,3238371032),new d.init(1654270250,914150663),new d.init(2438529370,812702999),new d.init(355462360,4144912697),new d.init(1731405415,4290775857),new d.init(2394180231,1750603025),new d.init(3675008525,1694076839),new d.init(1203062813,3204075428)])},_doFinalize:function(){var a=f._doFinalize.call(this);a.sigBytes-=16;return a}});a.SHA384=\nf._createHelper(c);a.HmacSHA384=f._createHmacHelper(c)})();\n"], "functools": [".py", "\"\"\"functools.py - Tools for working with functions and callable objects\n\"\"\"\n# Python module wrapper for _functools C module\n# to allow utilities written in Python to be added\n# to the functools module.\n# Written by Nick Coghlan <ncoghlan at gmail.com>\n# and Raymond Hettinger <python at rcn.com>\n#   Copyright (C) 2006-2010 Python Software Foundation.\n# See C source code for _functools credits/copyright\n\n__all__ = ['update_wrapper', 'wraps', 'WRAPPER_ASSIGNMENTS', 'WRAPPER_UPDATES',\n           'total_ordering', 'cmp_to_key', 'lru_cache', 'reduce', 'partial']\n\nfrom _functools import partial, reduce\nfrom collections import namedtuple\ntry:\n    from _thread import RLock\nexcept:\n    class RLock:\n        'Dummy reentrant lock for builds without threads'\n        def __enter__(self): pass\n        def __exit__(self, exctype, excinst, exctb): pass\n\n\n################################################################################\n### update_wrapper() and wraps() decorator\n################################################################################\n\n# update_wrapper() and wraps() are tools to help write\n# wrapper functions that can handle naive introspection\n\nWRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__',\n                       '__annotations__')\nWRAPPER_UPDATES = ('__dict__',)\ndef update_wrapper(wrapper,\n                   wrapped,\n                   assigned = WRAPPER_ASSIGNMENTS,\n                   updated = WRAPPER_UPDATES):\n    \"\"\"Update a wrapper function to look like the wrapped function\n\n       wrapper is the function to be updated\n       wrapped is the original function\n       assigned is a tuple naming the attributes assigned directly\n       from the wrapped function to the wrapper function (defaults to\n       functools.WRAPPER_ASSIGNMENTS)\n       updated is a tuple naming the attributes of the wrapper that\n       are updated with the corresponding attribute from the wrapped\n       function (defaults to functools.WRAPPER_UPDATES)\n    \"\"\"\n    wrapper.__wrapped__ = wrapped\n    for attr in assigned:\n        try:\n            value = getattr(wrapped, attr)\n        except AttributeError:\n            pass\n        else:\n            setattr(wrapper, attr, value)\n    for attr in updated:\n        getattr(wrapper, attr).update(getattr(wrapped, attr, {}))\n    # Return the wrapper so this can be used as a decorator via partial()\n    return wrapper\n\ndef wraps(wrapped,\n          assigned = WRAPPER_ASSIGNMENTS,\n          updated = WRAPPER_UPDATES):\n    \"\"\"Decorator factory to apply update_wrapper() to a wrapper function\n\n       Returns a decorator that invokes update_wrapper() with the decorated\n       function as the wrapper argument and the arguments to wraps() as the\n       remaining arguments. Default arguments are as for update_wrapper().\n       This is a convenience function to simplify applying partial() to\n       update_wrapper().\n    \"\"\"\n    return partial(update_wrapper, wrapped=wrapped,\n                   assigned=assigned, updated=updated)\n\n\n################################################################################\n### total_ordering class decorator\n################################################################################\n\ndef total_ordering(cls):\n    \"\"\"Class decorator that fills in missing ordering methods\"\"\"\n    convert = {\n        '__lt__': [('__gt__', lambda self, other: not (self < other or self == other)),\n                   ('__le__', lambda self, other: self < other or self == other),\n                   ('__ge__', lambda self, other: not self < other)],\n        '__le__': [('__ge__', lambda self, other: not self <= other or self == other),\n                   ('__lt__', lambda self, other: self <= other and not self == other),\n                   ('__gt__', lambda self, other: not self <= other)],\n        '__gt__': [('__lt__', lambda self, other: not (self > other or self == other)),\n                   ('__ge__', lambda self, other: self > other or self == other),\n                   ('__le__', lambda self, other: not self > other)],\n        '__ge__': [('__le__', lambda self, other: (not self >= other) or self == other),\n                   ('__gt__', lambda self, other: self >= other and not self == other),\n                   ('__lt__', lambda self, other: not self >= other)]\n    }\n    # Find user-defined comparisons (not those inherited from object).\n    roots = [op for op in convert if getattr(cls, op, None) is not getattr(object, op, None)]\n    if not roots:\n        raise ValueError('must define at least one ordering operation: < > <= >=')\n    root = max(roots)       # prefer __lt__ to __le__ to __gt__ to __ge__\n    for opname, opfunc in convert[root]:\n        if opname not in roots:\n            opfunc.__name__ = opname\n            opfunc.__doc__ = getattr(int, opname).__doc__\n            setattr(cls, opname, opfunc)\n    return cls\n\n\n################################################################################\n### cmp_to_key() function converter\n################################################################################\n\ndef cmp_to_key(mycmp):\n    \"\"\"Convert a cmp= function into a key= function\"\"\"\n    class K(object):\n        __slots__ = ['obj']\n        def __init__(self, obj):\n            self.obj = obj\n        def __lt__(self, other):\n            return mycmp(self.obj, other.obj) < 0\n        def __gt__(self, other):\n            return mycmp(self.obj, other.obj) > 0\n        def __eq__(self, other):\n            return mycmp(self.obj, other.obj) == 0\n        def __le__(self, other):\n            return mycmp(self.obj, other.obj) <= 0\n        def __ge__(self, other):\n            return mycmp(self.obj, other.obj) >= 0\n        def __ne__(self, other):\n            return mycmp(self.obj, other.obj) != 0\n        __hash__ = None\n    return K\n\ntry:\n    from _functools import cmp_to_key\nexcept ImportError:\n    pass\n\n\n################################################################################\n### LRU Cache function decorator\n################################################################################\n\n_CacheInfo = namedtuple(\"CacheInfo\", [\"hits\", \"misses\", \"maxsize\", \"currsize\"])\n\nclass _HashedSeq(list):\n    \"\"\" This class guarantees that hash() will be called no more than once\n        per element.  This is important because the lru_cache() will hash\n        the key multiple times on a cache miss.\n\n    \"\"\"\n\n    __slots__ = 'hashvalue'\n\n    def __init__(self, tup, hash=hash):\n        self[:] = tup\n        self.hashvalue = hash(tup)\n\n    def __hash__(self):\n        return self.hashvalue\n\ndef _make_key(args, kwds, typed,\n             kwd_mark = (object(),),\n             fasttypes = {int, str, frozenset, type(None)},\n             sorted=sorted, tuple=tuple, type=type, len=len):\n    \"\"\"Make a cache key from optionally typed positional and keyword arguments\n\n    The key is constructed in a way that is flat as possible rather than\n    as a nested structure that would take more memory.\n\n    If there is only a single argument and its data type is known to cache\n    its hash value, then that argument is returned without a wrapper.  This\n    saves space and improves lookup speed.\n\n    \"\"\"\n    key = args\n    if kwds:\n        sorted_items = sorted(kwds.items())\n        key += kwd_mark\n        for item in sorted_items:\n            key += item\n    if typed:\n        key += tuple(type(v) for v in args)\n        if kwds:\n            key += tuple(type(v) for k, v in sorted_items)\n    elif len(key) == 1 and type(key[0]) in fasttypes:\n        return key[0]\n    return _HashedSeq(key)\n\ndef lru_cache(maxsize=128, typed=False):\n    \"\"\"Least-recently-used cache decorator.\n\n    If *maxsize* is set to None, the LRU features are disabled and the cache\n    can grow without bound.\n\n    If *typed* is True, arguments of different types will be cached separately.\n    For example, f(3.0) and f(3) will be treated as distinct calls with\n    distinct results.\n\n    Arguments to the cached function must be hashable.\n\n    View the cache statistics named tuple (hits, misses, maxsize, currsize)\n    with f.cache_info().  Clear the cache and statistics with f.cache_clear().\n    Access the underlying function with f.__wrapped__.\n\n    See:  http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used\n\n    \"\"\"\n\n    # Users should only access the lru_cache through its public API:\n    #       cache_info, cache_clear, and f.__wrapped__\n    # The internals of the lru_cache are encapsulated for thread safety and\n    # to allow the implementation to change (including a possible C version).\n\n    # Constants shared by all lru cache instances:\n    sentinel = object()          # unique object used to signal cache misses\n    make_key = _make_key         # build a key from the function arguments\n    PREV, NEXT, KEY, RESULT = 0, 1, 2, 3   # names for the link fields\n\n    def decorating_function(user_function):\n\n        cache = {}\n        hits = misses = 0\n        full = False\n        cache_get = cache.get    # bound method to lookup a key or return None\n        lock = RLock()           # because linkedlist updates aren't threadsafe\n        root = []                # root of the circular doubly linked list\n        root[:] = [root, root, None, None]     # initialize by pointing to self\n\n        if maxsize == 0:\n\n            def wrapper(*args, **kwds):\n                # No caching -- just a statistics update after a successful call\n                nonlocal misses\n                result = user_function(*args, **kwds)\n                misses += 1\n                return result\n\n        elif maxsize is None:\n\n            def wrapper(*args, **kwds):\n                # Simple caching without ordering or size limit\n                nonlocal hits, misses\n                key = make_key(args, kwds, typed)\n                result = cache_get(key, sentinel)\n                if result is not sentinel:\n                    hits += 1\n                    return result\n                result = user_function(*args, **kwds)\n                cache[key] = result\n                misses += 1\n                return result\n\n        else:\n\n            def wrapper(*args, **kwds):\n                # Size limited caching that tracks accesses by recency\n                nonlocal root, hits, misses, full\n                key = make_key(args, kwds, typed)\n                with lock:\n                    link = cache_get(key)\n                    if link is not None:\n                        # Move the link to the front of the circular queue\n                        link_prev, link_next, _key, result = link\n                        link_prev[NEXT] = link_next\n                        link_next[PREV] = link_prev\n                        last = root[PREV]\n                        last[NEXT] = root[PREV] = link\n                        link[PREV] = last\n                        link[NEXT] = root\n                        hits += 1\n                        return result\n                result = user_function(*args, **kwds)\n                with lock:\n                    if key in cache:\n                        # Getting here means that this same key was added to the\n                        # cache while the lock was released.  Since the link\n                        # update is already done, we need only return the\n                        # computed result and update the count of misses.\n                        pass\n                    elif full:\n                        # Use the old root to store the new key and result.\n                        oldroot = root\n                        oldroot[KEY] = key\n                        oldroot[RESULT] = result\n                        # Empty the oldest link and make it the new root.\n                        # Keep a reference to the old key and old result to\n                        # prevent their ref counts from going to zero during the\n                        # update. That will prevent potentially arbitrary object\n                        # clean-up code (i.e. __del__) from running while we're\n                        # still adjusting the links.\n                        root = oldroot[NEXT]\n                        oldkey = root[KEY]\n                        oldresult = root[RESULT]\n                        root[KEY] = root[RESULT] = None\n                        # Now update the cache dictionary.\n                        del cache[oldkey]\n                        # Save the potentially reentrant cache[key] assignment\n                        # for last, after the root and links have been put in\n                        # a consistent state.\n                        cache[key] = oldroot\n                    else:\n                        # Put result in a new link at the front of the queue.\n                        last = root[PREV]\n                        link = [last, root, key, result]\n                        last[NEXT] = root[PREV] = cache[key] = link\n                        full = (len(cache) >= maxsize)\n                    misses += 1\n                return result\n\n        def cache_info():\n            \"\"\"Report cache statistics\"\"\"\n            with lock:\n                return _CacheInfo(hits, misses, maxsize, len(cache))\n\n        def cache_clear():\n            \"\"\"Clear the cache and cache statistics\"\"\"\n            nonlocal hits, misses, full\n            with lock:\n                cache.clear()\n                root[:] = [root, root, None, None]\n                hits = misses = 0\n                full = False\n\n        wrapper.cache_info = cache_info\n        wrapper.cache_clear = cache_clear\n        return update_wrapper(wrapper, user_function)\n\n    return decorating_function\n"], "random": [".py", "\"\"\"Random variable generators.\n\n    integers\n    --------\n           uniform within range\n\n    sequences\n    ---------\n           pick random element\n           pick random sample\n           generate random permutation\n\n    distributions on the real line:\n    ------------------------------\n           uniform\n           triangular\n           normal (Gaussian)\n           lognormal\n           negative exponential\n           gamma\n           beta\n           pareto\n           Weibull\n\n    distributions on the circle (angles 0 to 2pi)\n    ---------------------------------------------\n           circular uniform\n           von Mises\n\nGeneral notes on the underlying Mersenne Twister core generator:\n\n* The period is 2**19937-1.\n* It is one of the most extensively tested generators in existence.\n* The random() method is implemented in C, executes in a single Python step,\n  and is, therefore, threadsafe.\n\n\"\"\"\n\nfrom warnings import warn as _warn\nfrom types import MethodType as _MethodType, BuiltinMethodType as _BuiltinMethodType\nfrom math import log as _log, exp as _exp, pi as _pi, e as _e, ceil as _ceil\nfrom math import sqrt as _sqrt, acos as _acos, cos as _cos, sin as _sin\nfrom os import urandom as _urandom\nfrom collections.abc import Set as _Set, Sequence as _Sequence\nfrom hashlib import sha512 as _sha512\n\n__all__ = [\"Random\",\"seed\",\"random\",\"uniform\",\"randint\",\"choice\",\"sample\",\n           \"randrange\",\"shuffle\",\"normalvariate\",\"lognormvariate\",\n           \"expovariate\",\"vonmisesvariate\",\"gammavariate\",\"triangular\",\n           \"gauss\",\"betavariate\",\"paretovariate\",\"weibullvariate\",\n           \"getstate\",\"setstate\", \"getrandbits\",\n           \"SystemRandom\"]\n\nNV_MAGICCONST = 4 * _exp(-0.5)/_sqrt(2.0)\nTWOPI = 2.0*_pi\nLOG4 = _log(4.0)\nSG_MAGICCONST = 1.0 + _log(4.5)\nBPF = 53        # Number of bits in a float\nRECIP_BPF = 2**-BPF\n\n\n# Translated by Guido van Rossum from C source provided by\n# Adrian Baddeley.  Adapted by Raymond Hettinger for use with\n# the Mersenne Twister  and os.urandom() core generators.\n\nimport _random\n\nclass Random(_random.Random):\n    \"\"\"Random number generator base class used by bound module functions.\n\n    Used to instantiate instances of Random to get generators that don't\n    share state.\n\n    Class Random can also be subclassed if you want to use a different basic\n    generator of your own devising: in that case, override the following\n    methods:  random(), seed(), getstate(), and setstate().\n    Optionally, implement a getrandbits() method so that randrange()\n    can cover arbitrarily large ranges.\n\n    \"\"\"\n\n    VERSION = 3     # used by getstate/setstate\n\n    def __init__(self, x=None):\n        \"\"\"Initialize an instance.\n\n        Optional argument x controls seeding, as for Random.seed().\n        \"\"\"\n\n        self.seed(x)\n        self.gauss_next = None\n\n    def seed(self, a=None, version=2):\n        \"\"\"Initialize internal state from hashable object.\n\n        None or no argument seeds from current time or from an operating\n        system specific randomness source if available.\n\n        For version 2 (the default), all of the bits are used if *a* is a str,\n        bytes, or bytearray.  For version 1, the hash() of *a* is used instead.\n\n        If *a* is an int, all bits are used.\n\n        \"\"\"\n\n        if a is None:\n            try:\n                a = int.from_bytes(_urandom(32), 'big')\n            except NotImplementedError:\n                import time\n                a = int(time.time() * 256) # use fractional seconds\n\n        if version == 2:\n            if isinstance(a, (str, bytes, bytearray)):\n                if isinstance(a, str):\n                    a = a.encode()\n                a += _sha512(a).digest()\n                a = int.from_bytes(a, 'big')\n\n        super().seed(a)\n        self.gauss_next = None\n\n    def getstate(self):\n        \"\"\"Return internal state; can be passed to setstate() later.\"\"\"\n        return self.VERSION, super().getstate(), self.gauss_next\n\n    def setstate(self, state):\n        \"\"\"Restore internal state from object returned by getstate().\"\"\"\n        version = state[0]\n        if version == 3:\n            version, internalstate, self.gauss_next = state\n            super().setstate(internalstate)\n        elif version == 2:\n            version, internalstate, self.gauss_next = state\n            # In version 2, the state was saved as signed ints, which causes\n            #   inconsistencies between 32/64-bit systems. The state is\n            #   really unsigned 32-bit ints, so we convert negative ints from\n            #   version 2 to positive longs for version 3.\n            try:\n                internalstate = tuple(x % (2**32) for x in internalstate)\n            except ValueError as e:\n                raise TypeError from e\n            super().setstate(internalstate)\n        else:\n            raise ValueError(\"state with version %s passed to \"\n                             \"Random.setstate() of version %s\" %\n                             (version, self.VERSION))\n\n## ---- Methods below this point do not need to be overridden when\n## ---- subclassing for the purpose of using a different core generator.\n\n## -------------------- pickle support  -------------------\n\n    def __getstate__(self): # for pickle\n        return self.getstate()\n\n    def __setstate__(self, state):  # for pickle\n        self.setstate(state)\n\n    def __reduce__(self):\n        return self.__class__, (), self.getstate()\n\n## -------------------- integer methods  -------------------\n\n    def randrange(self, start, stop=None, step=1, _int=int):\n        \"\"\"Choose a random item from range(start, stop[, step]).\n\n        This fixes the problem with randint() which includes the\n        endpoint; in Python this is usually not what you want.\n\n        \"\"\"\n\n        # This code is a bit messy to make it fast for the\n        # common case while still doing adequate error checking.\n        istart = _int(start)\n        if istart != start:\n            raise ValueError(\"non-integer arg 1 for randrange()\")\n        if stop is None:\n            if istart > 0:\n                return self._randbelow(istart)\n            raise ValueError(\"empty range for randrange()\")\n\n        # stop argument supplied.\n        istop = _int(stop)\n        if istop != stop:\n            raise ValueError(\"non-integer stop for randrange()\")\n        width = istop - istart\n        if step == 1 and width > 0:\n            return istart + self._randbelow(width)\n        if step == 1:\n            raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n\n        # Non-unit step argument supplied.\n        istep = _int(step)\n        if istep != step:\n            raise ValueError(\"non-integer step for randrange()\")\n        if istep > 0:\n            n = (width + istep - 1) // istep\n        elif istep < 0:\n            n = (width + istep + 1) // istep\n        else:\n            raise ValueError(\"zero step for randrange()\")\n\n        if n <= 0:\n            raise ValueError(\"empty range for randrange()\")\n\n        return istart + istep*self._randbelow(n)\n\n    def randint(self, a, b):\n        \"\"\"Return random integer in range [a, b], including both end points.\n        \"\"\"\n\n        return self.randrange(a, b+1)\n\n    def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n                   Method=_MethodType, BuiltinMethod=_BuiltinMethodType):\n        \"Return a random int in the range [0,n).  Raises ValueError if n==0.\"\n\n        getrandbits = self.getrandbits\n        # Only call self.getrandbits if the original random() builtin method\n        # has not been overridden or if a new getrandbits() was supplied.\n        if type(self.random) is BuiltinMethod or type(getrandbits) is Method:\n            k = n.bit_length()  # don't use (n-1) here because n can be 1\n            r = getrandbits(k)          # 0 <= r < 2**k\n            while r >= n:\n                r = getrandbits(k)\n            return r\n        # There's an overriden random() method but no new getrandbits() method,\n        # so we can only use random() from here.\n        random = self.random\n        if n >= maxsize:\n            _warn(\"Underlying random() generator does not supply \\n\"\n                \"enough bits to choose from a population range this large.\\n\"\n                \"To remove the range limitation, add a getrandbits() method.\")\n            return int(random() * n)\n        rem = maxsize % n\n        limit = (maxsize - rem) / maxsize   # int(limit * maxsize) % n == 0\n        r = random()\n        while r >= limit:\n            r = random()\n        return int(r*maxsize) % n\n\n## -------------------- sequence methods  -------------------\n\n    def choice(self, seq):\n        \"\"\"Choose a random element from a non-empty sequence.\"\"\"\n        try:\n            i = self._randbelow(len(seq))\n        except ValueError:\n            raise IndexError('Cannot choose from an empty sequence')\n        return seq[i]\n\n    def shuffle(self, x, random=None):\n        \"\"\"x, random=random.random -> shuffle list x in place; return None.\n\n        Optional arg random is a 0-argument function returning a random\n        float in [0.0, 1.0); by default, the standard random.random.\n\n        \"\"\"\n\n        if random is None:\n            randbelow = self._randbelow\n            for i in reversed(range(1, len(x))):\n                # pick an element in x[:i+1] with which to exchange x[i]\n                j = randbelow(i+1)\n                x[i], x[j] = x[j], x[i]\n        else:\n            _int = int\n            for i in reversed(range(1, len(x))):\n                # pick an element in x[:i+1] with which to exchange x[i]\n                j = _int(random() * (i+1))\n                x[i], x[j] = x[j], x[i]\n\n    def sample(self, population, k):\n        \"\"\"Chooses k unique random elements from a population sequence or set.\n\n        Returns a new list containing elements from the population while\n        leaving the original population unchanged.  The resulting list is\n        in selection order so that all sub-slices will also be valid random\n        samples.  This allows raffle winners (the sample) to be partitioned\n        into grand prize and second place winners (the subslices).\n\n        Members of the population need not be hashable or unique.  If the\n        population contains repeats, then each occurrence is a possible\n        selection in the sample.\n\n        To choose a sample in a range of integers, use range as an argument.\n        This is especially fast and space efficient for sampling from a\n        large population:   sample(range(10000000), 60)\n        \"\"\"\n\n        # Sampling without replacement entails tracking either potential\n        # selections (the pool) in a list or previous selections in a set.\n\n        # When the number of selections is small compared to the\n        # population, then tracking selections is efficient, requiring\n        # only a small set and an occasional reselection.  For\n        # a larger number of selections, the pool tracking method is\n        # preferred since the list takes less space than the\n        # set and it doesn't suffer from frequent reselections.\n\n        if isinstance(population, _Set):\n            population = tuple(population)\n        if not isinstance(population, _Sequence):\n            raise TypeError(\"Population must be a sequence or set.  For dicts, use list(d).\")\n        randbelow = self._randbelow\n        n = len(population)\n        if not 0 <= k <= n:\n            raise ValueError(\"Sample larger than population\")\n        result = [None] * k\n        setsize = 21        # size of a small set minus size of an empty list\n        if k > 5:\n            setsize += 4 ** _ceil(_log(k * 3, 4)) # table size for big sets\n        if n <= setsize:\n            # An n-length list is smaller than a k-length set\n            pool = list(population)\n            for i in range(k):         # invariant:  non-selected at [0,n-i)\n                j = randbelow(n-i)\n                result[i] = pool[j]\n                pool[j] = pool[n-i-1]   # move non-selected item into vacancy\n        else:\n            selected = set()\n            selected_add = selected.add\n            for i in range(k):\n                j = randbelow(n)\n                while j in selected:\n                    j = randbelow(n)\n                selected_add(j)\n                result[i] = population[j]\n        return result\n\n## -------------------- real-valued distributions  -------------------\n\n## -------------------- uniform distribution -------------------\n\n    def uniform(self, a, b):\n        \"Get a random number in the range [a, b) or [a, b] depending on rounding.\"\n        return a + (b-a) * self.random()\n\n## -------------------- triangular --------------------\n\n    def triangular(self, low=0.0, high=1.0, mode=None):\n        \"\"\"Triangular distribution.\n\n        Continuous distribution bounded by given lower and upper limits,\n        and having a given mode value in-between.\n\n        http://en.wikipedia.org/wiki/Triangular_distribution\n\n        \"\"\"\n        u = self.random()\n        c = 0.5 if mode is None else (mode - low) / (high - low)\n        if u > c:\n            u = 1.0 - u\n            c = 1.0 - c\n            low, high = high, low\n        return low + (high - low) * (u * c) ** 0.5\n\n## -------------------- normal distribution --------------------\n\n    def normalvariate(self, mu, sigma):\n        \"\"\"Normal distribution.\n\n        mu is the mean, and sigma is the standard deviation.\n\n        \"\"\"\n        # mu = mean, sigma = standard deviation\n\n        # Uses Kinderman and Monahan method. Reference: Kinderman,\n        # A.J. and Monahan, J.F., \"Computer generation of random\n        # variables using the ratio of uniform deviates\", ACM Trans\n        # Math Software, 3, (1977), pp257-260.\n\n        random = self.random\n        while 1:\n            u1 = random()\n            u2 = 1.0 - random()\n            z = NV_MAGICCONST*(u1-0.5)/u2\n            zz = z*z/4.0\n            if zz <= -_log(u2):\n                break\n        return mu + z*sigma\n\n## -------------------- lognormal distribution --------------------\n\n    def lognormvariate(self, mu, sigma):\n        \"\"\"Log normal distribution.\n\n        If you take the natural logarithm of this distribution, you'll get a\n        normal distribution with mean mu and standard deviation sigma.\n        mu can have any value, and sigma must be greater than zero.\n\n        \"\"\"\n        return _exp(self.normalvariate(mu, sigma))\n\n## -------------------- exponential distribution --------------------\n\n    def expovariate(self, lambd):\n        \"\"\"Exponential distribution.\n\n        lambd is 1.0 divided by the desired mean.  It should be\n        nonzero.  (The parameter would be called \"lambda\", but that is\n        a reserved word in Python.)  Returned values range from 0 to\n        positive infinity if lambd is positive, and from negative\n        infinity to 0 if lambd is negative.\n\n        \"\"\"\n        # lambd: rate lambd = 1/mean\n        # ('lambda' is a Python reserved word)\n\n        # we use 1-random() instead of random() to preclude the\n        # possibility of taking the log of zero.\n        return -_log(1.0 - self.random())/lambd\n\n## -------------------- von Mises distribution --------------------\n\n    def vonmisesvariate(self, mu, kappa):\n        \"\"\"Circular data distribution.\n\n        mu is the mean angle, expressed in radians between 0 and 2*pi, and\n        kappa is the concentration parameter, which must be greater than or\n        equal to zero.  If kappa is equal to zero, this distribution reduces\n        to a uniform random angle over the range 0 to 2*pi.\n\n        \"\"\"\n        # mu:    mean angle (in radians between 0 and 2*pi)\n        # kappa: concentration parameter kappa (>= 0)\n        # if kappa = 0 generate uniform random angle\n\n        # Based upon an algorithm published in: Fisher, N.I.,\n        # \"Statistical Analysis of Circular Data\", Cambridge\n        # University Press, 1993.\n\n        # Thanks to Magnus Kessler for a correction to the\n        # implementation of step 4.\n\n        random = self.random\n        if kappa <= 1e-6:\n            return TWOPI * random()\n\n        s = 0.5 / kappa\n        r = s + _sqrt(1.0 + s * s)\n\n        while 1:\n            u1 = random()\n            z = _cos(_pi * u1)\n\n            d = z / (r + z)\n            u2 = random()\n            if u2 < 1.0 - d * d or u2 <= (1.0 - d) * _exp(d):\n                break\n\n        q = 1.0 / r\n        f = (q + z) / (1.0 + q * z)\n        u3 = random()\n        if u3 > 0.5:\n            theta = (mu + _acos(f)) % TWOPI\n        else:\n            theta = (mu - _acos(f)) % TWOPI\n\n        return theta\n\n## -------------------- gamma distribution --------------------\n\n    def gammavariate(self, alpha, beta):\n        \"\"\"Gamma distribution.  Not the gamma function!\n\n        Conditions on the parameters are alpha > 0 and beta > 0.\n\n        The probability distribution function is:\n\n                    x ** (alpha - 1) * math.exp(-x / beta)\n          pdf(x) =  --------------------------------------\n                      math.gamma(alpha) * beta ** alpha\n\n        \"\"\"\n\n        # alpha > 0, beta > 0, mean is alpha*beta, variance is alpha*beta**2\n\n        # Warning: a few older sources define the gamma distribution in terms\n        # of alpha > -1.0\n        if alpha <= 0.0 or beta <= 0.0:\n            raise ValueError('gammavariate: alpha and beta must be > 0.0')\n\n        random = self.random\n        if alpha > 1.0:\n\n            # Uses R.C.H. Cheng, \"The generation of Gamma\n            # variables with non-integral shape parameters\",\n            # Applied Statistics, (1977), 26, No. 1, p71-74\n\n            ainv = _sqrt(2.0 * alpha - 1.0)\n            bbb = alpha - LOG4\n            ccc = alpha + ainv\n\n            while 1:\n                u1 = random()\n                if not 1e-7 < u1 < .9999999:\n                    continue\n                u2 = 1.0 - random()\n                v = _log(u1/(1.0-u1))/ainv\n                x = alpha*_exp(v)\n                z = u1*u1*u2\n                r = bbb+ccc*v-x\n                if r + SG_MAGICCONST - 4.5*z >= 0.0 or r >= _log(z):\n                    return x * beta\n\n        elif alpha == 1.0:\n            # expovariate(1)\n            u = random()\n            while u <= 1e-7:\n                u = random()\n            return -_log(u) * beta\n\n        else:   # alpha is between 0 and 1 (exclusive)\n\n            # Uses ALGORITHM GS of Statistical Computing - Kennedy & Gentle\n\n            while 1:\n                u = random()\n                b = (_e + alpha)/_e\n                p = b*u\n                if p <= 1.0:\n                    x = p ** (1.0/alpha)\n                else:\n                    x = -_log((b-p)/alpha)\n                u1 = random()\n                if p > 1.0:\n                    if u1 <= x ** (alpha - 1.0):\n                        break\n                elif u1 <= _exp(-x):\n                    break\n            return x * beta\n\n## -------------------- Gauss (faster alternative) --------------------\n\n    def gauss(self, mu, sigma):\n        \"\"\"Gaussian distribution.\n\n        mu is the mean, and sigma is the standard deviation.  This is\n        slightly faster than the normalvariate() function.\n\n        Not thread-safe without a lock around calls.\n\n        \"\"\"\n\n        # When x and y are two variables from [0, 1), uniformly\n        # distributed, then\n        #\n        #    cos(2*pi*x)*sqrt(-2*log(1-y))\n        #    sin(2*pi*x)*sqrt(-2*log(1-y))\n        #\n        # are two *independent* variables with normal distribution\n        # (mu = 0, sigma = 1).\n        # (Lambert Meertens)\n        # (corrected version; bug discovered by Mike Miller, fixed by LM)\n\n        # Multithreading note: When two threads call this function\n        # simultaneously, it is possible that they will receive the\n        # same return value.  The window is very small though.  To\n        # avoid this, you have to use a lock around all calls.  (I\n        # didn't want to slow this down in the serial case by using a\n        # lock here.)\n\n        random = self.random\n        z = self.gauss_next\n        self.gauss_next = None\n        if z is None:\n            x2pi = random() * TWOPI\n            g2rad = _sqrt(-2.0 * _log(1.0 - random()))\n            z = _cos(x2pi) * g2rad\n            self.gauss_next = _sin(x2pi) * g2rad\n\n        return mu + z*sigma\n\n## -------------------- beta --------------------\n## See\n## http://mail.python.org/pipermail/python-bugs-list/2001-January/003752.html\n## for Ivan Frohne's insightful analysis of why the original implementation:\n##\n##    def betavariate(self, alpha, beta):\n##        # Discrete Event Simulation in C, pp 87-88.\n##\n##        y = self.expovariate(alpha)\n##        z = self.expovariate(1.0/beta)\n##        return z/(y+z)\n##\n## was dead wrong, and how it probably got that way.\n\n    def betavariate(self, alpha, beta):\n        \"\"\"Beta distribution.\n\n        Conditions on the parameters are alpha > 0 and beta > 0.\n        Returned values range between 0 and 1.\n\n        \"\"\"\n\n        # This version due to Janne Sinkkonen, and matches all the std\n        # texts (e.g., Knuth Vol 2 Ed 3 pg 134 \"the beta distribution\").\n        y = self.gammavariate(alpha, 1.)\n        if y == 0:\n            return 0.0\n        else:\n            return y / (y + self.gammavariate(beta, 1.))\n\n## -------------------- Pareto --------------------\n\n    def paretovariate(self, alpha):\n        \"\"\"Pareto distribution.  alpha is the shape parameter.\"\"\"\n        # Jain, pg. 495\n\n        u = 1.0 - self.random()\n        return 1.0 / u ** (1.0/alpha)\n\n## -------------------- Weibull --------------------\n\n    def weibullvariate(self, alpha, beta):\n        \"\"\"Weibull distribution.\n\n        alpha is the scale parameter and beta is the shape parameter.\n\n        \"\"\"\n        # Jain, pg. 499; bug fix courtesy Bill Arms\n\n        u = 1.0 - self.random()\n        return alpha * (-_log(u)) ** (1.0/beta)\n\n## --------------- Operating System Random Source  ------------------\n\nclass SystemRandom(Random):\n    \"\"\"Alternate random number generator using sources provided\n    by the operating system (such as /dev/urandom on Unix or\n    CryptGenRandom on Windows).\n\n     Not available on all systems (see os.urandom() for details).\n    \"\"\"\n\n    def random(self):\n        \"\"\"Get the next random number in the range [0.0, 1.0).\"\"\"\n        return (int.from_bytes(_urandom(7), 'big') >> 3) * RECIP_BPF\n\n    def getrandbits(self, k):\n        \"\"\"getrandbits(k) -> x.  Generates an int with k random bits.\"\"\"\n        if k <= 0:\n            raise ValueError('number of bits must be greater than zero')\n        if k != int(k):\n            raise TypeError('number of bits should be an integer')\n        numbytes = (k + 7) // 8                       # bits / 8 and rounded up\n        x = int.from_bytes(_urandom(numbytes), 'big')\n        return x >> (numbytes * 8 - k)                # trim excess bits\n\n    def seed(self, *args, **kwds):\n        \"Stub method.  Not used for a system random number generator.\"\n        return None\n\n    def _notimplemented(self, *args, **kwds):\n        \"Method should not be called for a system random number generator.\"\n        raise NotImplementedError('System entropy source does not have state.')\n    getstate = setstate = _notimplemented\n\n## -------------------- test program --------------------\n\ndef _test_generator(n, func, args):\n    import time\n    print(n, 'times', func.__name__)\n    total = 0.0\n    sqsum = 0.0\n    smallest = 1e10\n    largest = -1e10\n    t0 = time.time()\n    for i in range(n):\n        x = func(*args)\n        total += x\n        sqsum = sqsum + x*x\n        smallest = min(x, smallest)\n        largest = max(x, largest)\n    t1 = time.time()\n    print(round(t1-t0, 3), 'sec,', end=' ')\n    avg = total/n\n    stddev = _sqrt(sqsum/n - avg*avg)\n    print('avg %g, stddev %g, min %g, max %g' % \\\n              (avg, stddev, smallest, largest))\n\n\ndef _test(N=2000):\n    _test_generator(N, random, ())\n    _test_generator(N, normalvariate, (0.0, 1.0))\n    _test_generator(N, lognormvariate, (0.0, 1.0))\n    _test_generator(N, vonmisesvariate, (0.0, 1.0))\n    _test_generator(N, gammavariate, (0.01, 1.0))\n    _test_generator(N, gammavariate, (0.1, 1.0))\n    _test_generator(N, gammavariate, (0.1, 2.0))\n    _test_generator(N, gammavariate, (0.5, 1.0))\n    _test_generator(N, gammavariate, (0.9, 1.0))\n    _test_generator(N, gammavariate, (1.0, 1.0))\n    _test_generator(N, gammavariate, (2.0, 1.0))\n    _test_generator(N, gammavariate, (20.0, 1.0))\n    _test_generator(N, gammavariate, (200.0, 1.0))\n    _test_generator(N, gauss, (0.0, 1.0))\n    _test_generator(N, betavariate, (3.0, 3.0))\n    _test_generator(N, triangular, (0.0, 1.0, 1.0/3.0))\n\n# Create one instance, seeded from current time, and export its methods\n# as module-level functions.  The functions share state across all uses\n#(both in the user's code and in the Python libraries), but that's fine\n# for most programs and is easier for the casual user than making them\n# instantiate their own Random() instance.\n\n_inst = Random()\nseed = _inst.seed\nrandom = _inst.random\nuniform = _inst.uniform\ntriangular = _inst.triangular\nrandint = _inst.randint\nchoice = _inst.choice\nrandrange = _inst.randrange\nsample = _inst.sample\nshuffle = _inst.shuffle\nnormalvariate = _inst.normalvariate\nlognormvariate = _inst.lognormvariate\nexpovariate = _inst.expovariate\nvonmisesvariate = _inst.vonmisesvariate\ngammavariate = _inst.gammavariate\ngauss = _inst.gauss\nbetavariate = _inst.betavariate\nparetovariate = _inst.paretovariate\nweibullvariate = _inst.weibullvariate\ngetstate = _inst.getstate\nsetstate = _inst.setstate\ngetrandbits = _inst.getrandbits\n\nif __name__ == '__main__':\n    _test()\n"], "test.test_re": [".py", "# FIXME: brython: implement test.support\n#from test.support import verbose, run_unittest, gc_collect, bigmemtest, _2G, \\\n#        cpython_only\n\nverbose = True\n\n# FIXME: brython: Not used in this module ?\n#import io\nimport re\n\n# FIXME: brython: implement re.Scanner\n#from re import Scanner\nimport sre_constants\nimport sys\nimport string\nimport traceback\n# FIXME: brython: implement _weakref\n#from weakref import proxy\n\n# Misc tests from Tim Peters' re.doc\n\n# WARNING: Don't change details in these tests if you don't know\n# what you're doing. Some of these tests were carefully modeled to\n# cover most of the code.\n\nimport unittest\n\nclass ReTests(unittest.TestCase):\n\n    # FIXME: brython: implement test.support\n#    def test_keep_buffer(self):\n#        # See bug 14212\n#        b = bytearray(b'x')\n#        it = re.finditer(b'a', b)\n#        with self.assertRaises(BufferError):\n#            b.extend(b'x'*400)\n#        list(it)\n#        del it\n#        gc_collect()\n#        b.extend(b'x'*400)\n\n    # FIXME: brython: implement _weakref\n#    def test_weakref(self):\n#        s = 'QabbbcR'\n#        x = re.compile('ab+c')\n#        y = proxy(x)\n#        self.assertEqual(x.findall('QabbbcR'), y.findall('QabbbcR'))\n\n    def test_search_star_plus(self):\n        self.assertEqual(re.search('x*', 'axx').span(0), (0, 0))\n        self.assertEqual(re.search('x*', 'axx').span(), (0, 0))\n        self.assertEqual(re.search('x+', 'axx').span(0), (1, 3))\n        self.assertEqual(re.search('x+', 'axx').span(), (1, 3))\n        self.assertEqual(re.search('x', 'aaa'), None)\n        self.assertEqual(re.match('a*', 'xxx').span(0), (0, 0))\n        self.assertEqual(re.match('a*', 'xxx').span(), (0, 0))\n        self.assertEqual(re.match('x*', 'xxxa').span(0), (0, 3))\n        self.assertEqual(re.match('x*', 'xxxa').span(), (0, 3))\n        self.assertEqual(re.match('a+', 'xxx'), None)\n\n    def bump_num(self, matchobj):\n        int_value = int(matchobj.group(0))\n        return str(int_value + 1)\n\n    def test_basic_re_sub(self):\n        self.assertEqual(re.sub(\"(?i)b+\", \"x\", \"bbbb BBBB\"), 'x x')\n        self.assertEqual(re.sub(r'\\d+', self.bump_num, '08.2 -2 23x99y'),\n                         '9.3 -3 24x100y')\n        self.assertEqual(re.sub(r'\\d+', self.bump_num, '08.2 -2 23x99y', 3),\n                         '9.3 -3 23x99y')\n\n        self.assertEqual(re.sub('.', lambda m: r\"\\n\", 'x'), '\\\\n')\n        self.assertEqual(re.sub('.', r\"\\n\", 'x'), '\\n')\n\n        s = r\"\\1\\1\"\n        self.assertEqual(re.sub('(.)', s, 'x'), 'xx')\n        self.assertEqual(re.sub('(.)', re.escape(s), 'x'), s)\n        self.assertEqual(re.sub('(.)', lambda m: s, 'x'), s)\n\n        self.assertEqual(re.sub('(?P<a>x)', '\\g<a>\\g<a>', 'xx'), 'xxxx')\n        self.assertEqual(re.sub('(?P<a>x)', '\\g<a>\\g<1>', 'xx'), 'xxxx')\n        self.assertEqual(re.sub('(?P<unk>x)', '\\g<unk>\\g<unk>', 'xx'), 'xxxx')\n        self.assertEqual(re.sub('(?P<unk>x)', '\\g<1>\\g<1>', 'xx'), 'xxxx')\n\n        self.assertEqual(re.sub('a',r'\\t\\n\\v\\r\\f\\a\\b\\B\\Z\\a\\A\\w\\W\\s\\S\\d\\D','a'),\n                         '\\t\\n\\v\\r\\f\\a\\b\\\\B\\\\Z\\a\\\\A\\\\w\\\\W\\\\s\\\\S\\\\d\\\\D')\n        self.assertEqual(re.sub('a', '\\t\\n\\v\\r\\f\\a', 'a'), '\\t\\n\\v\\r\\f\\a')\n        self.assertEqual(re.sub('a', '\\t\\n\\v\\r\\f\\a', 'a'),\n                         (chr(9)+chr(10)+chr(11)+chr(13)+chr(12)+chr(7)))\n\n        self.assertEqual(re.sub('^\\s*', 'X', 'test'), 'Xtest')\n\n    def test_bug_449964(self):\n        # fails for group followed by other escape\n        self.assertEqual(re.sub(r'(?P<unk>x)', '\\g<1>\\g<1>\\\\b', 'xx'),\n                         'xx\\bxx\\b')\n\n    def test_bug_449000(self):\n        # Test for sub() on escaped characters\n        self.assertEqual(re.sub(r'\\r\\n', r'\\n', 'abc\\r\\ndef\\r\\n'),\n                         'abc\\ndef\\n')\n        self.assertEqual(re.sub('\\r\\n', r'\\n', 'abc\\r\\ndef\\r\\n'),\n                         'abc\\ndef\\n')\n        self.assertEqual(re.sub(r'\\r\\n', '\\n', 'abc\\r\\ndef\\r\\n'),\n                         'abc\\ndef\\n')\n        self.assertEqual(re.sub('\\r\\n', '\\n', 'abc\\r\\ndef\\r\\n'),\n                         'abc\\ndef\\n')\n\n    def test_bug_1661(self):\n        # Verify that flags do not get silently ignored with compiled patterns\n        pattern = re.compile('.')\n        self.assertRaises(ValueError, re.match, pattern, 'A', re.I)\n        self.assertRaises(ValueError, re.search, pattern, 'A', re.I)\n        self.assertRaises(ValueError, re.findall, pattern, 'A', re.I)\n        self.assertRaises(ValueError, re.compile, pattern, re.I)\n\n    def test_bug_3629(self):\n        # A regex that triggered a bug in the sre-code validator\n        re.compile(\"(?P<quote>)(?(quote))\")\n\n    def test_sub_template_numeric_escape(self):\n        # bug 776311 and friends\n        self.assertEqual(re.sub('x', r'\\0', 'x'), '\\0')\n        self.assertEqual(re.sub('x', r'\\000', 'x'), '\\000')\n        self.assertEqual(re.sub('x', r'\\001', 'x'), '\\001')\n        self.assertEqual(re.sub('x', r'\\008', 'x'), '\\0' + '8')\n        self.assertEqual(re.sub('x', r'\\009', 'x'), '\\0' + '9')\n        self.assertEqual(re.sub('x', r'\\111', 'x'), '\\111')\n        self.assertEqual(re.sub('x', r'\\117', 'x'), '\\117')\n\n        self.assertEqual(re.sub('x', r'\\1111', 'x'), '\\1111')\n        self.assertEqual(re.sub('x', r'\\1111', 'x'), '\\111' + '1')\n\n        self.assertEqual(re.sub('x', r'\\00', 'x'), '\\x00')\n        self.assertEqual(re.sub('x', r'\\07', 'x'), '\\x07')\n        self.assertEqual(re.sub('x', r'\\08', 'x'), '\\0' + '8')\n        self.assertEqual(re.sub('x', r'\\09', 'x'), '\\0' + '9')\n        self.assertEqual(re.sub('x', r'\\0a', 'x'), '\\0' + 'a')\n\n        self.assertEqual(re.sub('x', r'\\400', 'x'), '\\0')\n        self.assertEqual(re.sub('x', r'\\777', 'x'), '\\377')\n\n        self.assertRaises(re.error, re.sub, 'x', r'\\1', 'x')\n        self.assertRaises(re.error, re.sub, 'x', r'\\8', 'x')\n        self.assertRaises(re.error, re.sub, 'x', r'\\9', 'x')\n        self.assertRaises(re.error, re.sub, 'x', r'\\11', 'x')\n        self.assertRaises(re.error, re.sub, 'x', r'\\18', 'x')\n        self.assertRaises(re.error, re.sub, 'x', r'\\1a', 'x')\n        self.assertRaises(re.error, re.sub, 'x', r'\\90', 'x')\n        self.assertRaises(re.error, re.sub, 'x', r'\\99', 'x')\n        self.assertRaises(re.error, re.sub, 'x', r'\\118', 'x') # r'\\11' + '8'\n        self.assertRaises(re.error, re.sub, 'x', r'\\11a', 'x')\n        self.assertRaises(re.error, re.sub, 'x', r'\\181', 'x') # r'\\18' + '1'\n        self.assertRaises(re.error, re.sub, 'x', r'\\800', 'x') # r'\\80' + '0'\n\n        # in python2.3 (etc), these loop endlessly in sre_parser.py\n        self.assertEqual(re.sub('(((((((((((x)))))))))))', r'\\11', 'x'), 'x')\n        self.assertEqual(re.sub('((((((((((y))))))))))(.)', r'\\118', 'xyz'),\n                         'xz8')\n        self.assertEqual(re.sub('((((((((((y))))))))))(.)', r'\\11a', 'xyz'),\n                         'xza')\n\n    def test_qualified_re_sub(self):\n        self.assertEqual(re.sub('a', 'b', 'aaaaa'), 'bbbbb')\n        self.assertEqual(re.sub('a', 'b', 'aaaaa', 1), 'baaaa')\n\n    def test_bug_114660(self):\n        self.assertEqual(re.sub(r'(\\S)\\s+(\\S)', r'\\1 \\2', 'hello  there'),\n                         'hello there')\n\n    def test_bug_462270(self):\n        # Test for empty sub() behaviour, see SF bug #462270\n        self.assertEqual(re.sub('x*', '-', 'abxd'), '-a-b-d-')\n        self.assertEqual(re.sub('x+', '-', 'abxd'), 'ab-d')\n\n    def test_symbolic_groups(self):\n        re.compile('(?P<a>x)(?P=a)(?(a)y)')\n        re.compile('(?P<a1>x)(?P=a1)(?(a1)y)')\n        self.assertRaises(re.error, re.compile, '(?P<a>)(?P<a>)')\n        self.assertRaises(re.error, re.compile, '(?Px)')\n        self.assertRaises(re.error, re.compile, '(?P=)')\n        self.assertRaises(re.error, re.compile, '(?P=1)')\n        self.assertRaises(re.error, re.compile, '(?P=a)')\n        self.assertRaises(re.error, re.compile, '(?P=a1)')\n        self.assertRaises(re.error, re.compile, '(?P=a.)')\n        self.assertRaises(re.error, re.compile, '(?P<)')\n        self.assertRaises(re.error, re.compile, '(?P<>)')\n        self.assertRaises(re.error, re.compile, '(?P<1>)')\n        self.assertRaises(re.error, re.compile, '(?P<a.>)')\n        self.assertRaises(re.error, re.compile, '(?())')\n        self.assertRaises(re.error, re.compile, '(?(a))')\n        self.assertRaises(re.error, re.compile, '(?(1a))')\n        self.assertRaises(re.error, re.compile, '(?(a.))')\n        # New valid/invalid identifiers in Python 3\n        re.compile('(?P<\u00b5>x)(?P=\u00b5)(?(\u00b5)y)')\n        re.compile('(?P<\ud835\udd18\ud835\udd2b\ud835\udd26\ud835\udd20\ud835\udd2c\ud835\udd21\ud835\udd22>x)(?P=\ud835\udd18\ud835\udd2b\ud835\udd26\ud835\udd20\ud835\udd2c\ud835\udd21\ud835\udd22)(?(\ud835\udd18\ud835\udd2b\ud835\udd26\ud835\udd20\ud835\udd2c\ud835\udd21\ud835\udd22)y)')\n        self.assertRaises(re.error, re.compile, '(?P<\u00a9>x)')\n\n    def test_symbolic_refs(self):\n        self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<a', 'xx')\n        self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<', 'xx')\n        self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g', 'xx')\n        self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<a a>', 'xx')\n        self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<>', 'xx')\n        self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<1a1>', 'xx')\n        self.assertRaises(IndexError, re.sub, '(?P<a>x)', '\\g<ab>', 'xx')\n        self.assertRaises(re.error, re.sub, '(?P<a>x)|(?P<b>y)', '\\g<b>', 'xx')\n        self.assertRaises(re.error, re.sub, '(?P<a>x)|(?P<b>y)', '\\\\2', 'xx')\n        self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<-1>', 'xx')\n        # New valid/invalid identifiers in Python 3\n        self.assertEqual(re.sub('(?P<\u00b5>x)', r'\\g<\u00b5>', 'xx'), 'xx')\n        self.assertEqual(re.sub('(?P<\ud835\udd18\ud835\udd2b\ud835\udd26\ud835\udd20\ud835\udd2c\ud835\udd21\ud835\udd22>x)', r'\\g<\ud835\udd18\ud835\udd2b\ud835\udd26\ud835\udd20\ud835\udd2c\ud835\udd21\ud835\udd22>', 'xx'), 'xx')\n        self.assertRaises(re.error, re.sub, '(?P<a>x)', r'\\g<\u00a9>', 'xx')\n\n    def test_re_subn(self):\n        self.assertEqual(re.subn(\"(?i)b+\", \"x\", \"bbbb BBBB\"), ('x x', 2))\n        self.assertEqual(re.subn(\"b+\", \"x\", \"bbbb BBBB\"), ('x BBBB', 1))\n        self.assertEqual(re.subn(\"b+\", \"x\", \"xyz\"), ('xyz', 0))\n        self.assertEqual(re.subn(\"b*\", \"x\", \"xyz\"), ('xxxyxzx', 4))\n        self.assertEqual(re.subn(\"b*\", \"x\", \"xyz\", 2), ('xxxyz', 2))\n\n    def test_re_split(self):\n        self.assertEqual(re.split(\":\", \":a:b::c\"), ['', 'a', 'b', '', 'c'])\n        self.assertEqual(re.split(\":*\", \":a:b::c\"), ['', 'a', 'b', 'c'])\n        self.assertEqual(re.split(\"(:*)\", \":a:b::c\"),\n                         ['', ':', 'a', ':', 'b', '::', 'c'])\n        self.assertEqual(re.split(\"(?::*)\", \":a:b::c\"), ['', 'a', 'b', 'c'])\n        self.assertEqual(re.split(\"(:)*\", \":a:b::c\"),\n                         ['', ':', 'a', ':', 'b', ':', 'c'])\n        self.assertEqual(re.split(\"([b:]+)\", \":a:b::c\"),\n                         ['', ':', 'a', ':b::', 'c'])\n        self.assertEqual(re.split(\"(b)|(:+)\", \":a:b::c\"),\n                         ['', None, ':', 'a', None, ':', '', 'b', None, '',\n                          None, '::', 'c'])\n        self.assertEqual(re.split(\"(?:b)|(?::+)\", \":a:b::c\"),\n                         ['', 'a', '', '', 'c'])\n\n    def test_qualified_re_split(self):\n        self.assertEqual(re.split(\":\", \":a:b::c\", 2), ['', 'a', 'b::c'])\n        self.assertEqual(re.split(':', 'a:b:c:d', 2), ['a', 'b', 'c:d'])\n        self.assertEqual(re.split(\"(:)\", \":a:b::c\", 2),\n                         ['', ':', 'a', ':', 'b::c'])\n        self.assertEqual(re.split(\"(:*)\", \":a:b::c\", 2),\n                         ['', ':', 'a', ':', 'b::c'])\n\n    def test_re_findall(self):\n        self.assertEqual(re.findall(\":+\", \"abc\"), [])\n        self.assertEqual(re.findall(\":+\", \"a:b::c:::d\"), [\":\", \"::\", \":::\"])\n        self.assertEqual(re.findall(\"(:+)\", \"a:b::c:::d\"), [\":\", \"::\", \":::\"])\n        self.assertEqual(re.findall(\"(:)(:*)\", \"a:b::c:::d\"), [(\":\", \"\"),\n                                                               (\":\", \":\"),\n                                                               (\":\", \"::\")])\n\n    def test_bug_117612(self):\n        self.assertEqual(re.findall(r\"(a|(b))\", \"aba\"),\n                         [(\"a\", \"\"),(\"b\", \"b\"),(\"a\", \"\")])\n\n    def test_re_match(self):\n        self.assertEqual(re.match('a', 'a').groups(), ())\n        self.assertEqual(re.match('(a)', 'a').groups(), ('a',))\n        self.assertEqual(re.match(r'(a)', 'a').group(0), 'a')\n        self.assertEqual(re.match(r'(a)', 'a').group(1), 'a')\n        self.assertEqual(re.match(r'(a)', 'a').group(1, 1), ('a', 'a'))\n\n        pat = re.compile('((a)|(b))(c)?')\n        self.assertEqual(pat.match('a').groups(), ('a', 'a', None, None))\n        self.assertEqual(pat.match('b').groups(), ('b', None, 'b', None))\n        self.assertEqual(pat.match('ac').groups(), ('a', 'a', None, 'c'))\n        self.assertEqual(pat.match('bc').groups(), ('b', None, 'b', 'c'))\n        self.assertEqual(pat.match('bc').groups(\"\"), ('b', \"\", 'b', 'c'))\n\n        # A single group\n        m = re.match('(a)', 'a')\n        self.assertEqual(m.group(0), 'a')\n        self.assertEqual(m.group(0), 'a')\n        self.assertEqual(m.group(1), 'a')\n        self.assertEqual(m.group(1, 1), ('a', 'a'))\n\n        pat = re.compile('(?:(?P<a1>a)|(?P<b2>b))(?P<c3>c)?')\n        self.assertEqual(pat.match('a').group(1, 2, 3), ('a', None, None))\n        self.assertEqual(pat.match('b').group('a1', 'b2', 'c3'),\n                         (None, 'b', None))\n        self.assertEqual(pat.match('ac').group(1, 'b2', 3), ('a', None, 'c'))\n\n    def test_re_groupref_exists(self):\n        self.assertEqual(re.match('^(\\()?([^()]+)(?(1)\\))$', '(a)').groups(),\n                         ('(', 'a'))\n        self.assertEqual(re.match('^(\\()?([^()]+)(?(1)\\))$', 'a').groups(),\n                         (None, 'a'))\n        self.assertEqual(re.match('^(\\()?([^()]+)(?(1)\\))$', 'a)'), None)\n        self.assertEqual(re.match('^(\\()?([^()]+)(?(1)\\))$', '(a'), None)\n        self.assertEqual(re.match('^(?:(a)|c)((?(1)b|d))$', 'ab').groups(),\n                         ('a', 'b'))\n        self.assertEqual(re.match('^(?:(a)|c)((?(1)b|d))$', 'cd').groups(),\n                         (None, 'd'))\n        self.assertEqual(re.match('^(?:(a)|c)((?(1)|d))$', 'cd').groups(),\n                         (None, 'd'))\n        self.assertEqual(re.match('^(?:(a)|c)((?(1)|d))$', 'a').groups(),\n                         ('a', ''))\n\n        # Tests for bug #1177831: exercise groups other than the first group\n        p = re.compile('(?P<g1>a)(?P<g2>b)?((?(g2)c|d))')\n        self.assertEqual(p.match('abc').groups(),\n                         ('a', 'b', 'c'))\n        self.assertEqual(p.match('ad').groups(),\n                         ('a', None, 'd'))\n        self.assertEqual(p.match('abd'), None)\n        self.assertEqual(p.match('ac'), None)\n\n\n    def test_re_groupref(self):\n        self.assertEqual(re.match(r'^(\\|)?([^()]+)\\1$', '|a|').groups(),\n                         ('|', 'a'))\n        self.assertEqual(re.match(r'^(\\|)?([^()]+)\\1?$', 'a').groups(),\n                         (None, 'a'))\n        self.assertEqual(re.match(r'^(\\|)?([^()]+)\\1$', 'a|'), None)\n        self.assertEqual(re.match(r'^(\\|)?([^()]+)\\1$', '|a'), None)\n        self.assertEqual(re.match(r'^(?:(a)|c)(\\1)$', 'aa').groups(),\n                         ('a', 'a'))\n        self.assertEqual(re.match(r'^(?:(a)|c)(\\1)?$', 'c').groups(),\n                         (None, None))\n\n    def test_groupdict(self):\n        self.assertEqual(re.match('(?P<first>first) (?P<second>second)',\n                                  'first second').groupdict(),\n                         {'first':'first', 'second':'second'})\n\n    def test_expand(self):\n        self.assertEqual(re.match(\"(?P<first>first) (?P<second>second)\",\n                                  \"first second\")\n                                  .expand(r\"\\2 \\1 \\g<second> \\g<first>\"),\n                         \"second first second first\")\n\n    def test_repeat_minmax(self):\n        self.assertEqual(re.match(\"^(\\w){1}$\", \"abc\"), None)\n        self.assertEqual(re.match(\"^(\\w){1}?$\", \"abc\"), None)\n        self.assertEqual(re.match(\"^(\\w){1,2}$\", \"abc\"), None)\n        self.assertEqual(re.match(\"^(\\w){1,2}?$\", \"abc\"), None)\n\n        self.assertEqual(re.match(\"^(\\w){3}$\", \"abc\").group(1), \"c\")\n        self.assertEqual(re.match(\"^(\\w){1,3}$\", \"abc\").group(1), \"c\")\n        self.assertEqual(re.match(\"^(\\w){1,4}$\", \"abc\").group(1), \"c\")\n        self.assertEqual(re.match(\"^(\\w){3,4}?$\", \"abc\").group(1), \"c\")\n        self.assertEqual(re.match(\"^(\\w){3}?$\", \"abc\").group(1), \"c\")\n        self.assertEqual(re.match(\"^(\\w){1,3}?$\", \"abc\").group(1), \"c\")\n        self.assertEqual(re.match(\"^(\\w){1,4}?$\", \"abc\").group(1), \"c\")\n        self.assertEqual(re.match(\"^(\\w){3,4}?$\", \"abc\").group(1), \"c\")\n\n        self.assertEqual(re.match(\"^x{1}$\", \"xxx\"), None)\n        self.assertEqual(re.match(\"^x{1}?$\", \"xxx\"), None)\n        self.assertEqual(re.match(\"^x{1,2}$\", \"xxx\"), None)\n        self.assertEqual(re.match(\"^x{1,2}?$\", \"xxx\"), None)\n\n        self.assertNotEqual(re.match(\"^x{3}$\", \"xxx\"), None)\n        self.assertNotEqual(re.match(\"^x{1,3}$\", \"xxx\"), None)\n        self.assertNotEqual(re.match(\"^x{1,4}$\", \"xxx\"), None)\n        self.assertNotEqual(re.match(\"^x{3,4}?$\", \"xxx\"), None)\n        self.assertNotEqual(re.match(\"^x{3}?$\", \"xxx\"), None)\n        self.assertNotEqual(re.match(\"^x{1,3}?$\", \"xxx\"), None)\n        self.assertNotEqual(re.match(\"^x{1,4}?$\", \"xxx\"), None)\n        self.assertNotEqual(re.match(\"^x{3,4}?$\", \"xxx\"), None)\n\n        self.assertEqual(re.match(\"^x{}$\", \"xxx\"), None)\n        self.assertNotEqual(re.match(\"^x{}$\", \"x{}\"), None)\n\n    def test_getattr(self):\n        self.assertEqual(re.compile(\"(?i)(a)(b)\").pattern, \"(?i)(a)(b)\")\n        self.assertEqual(re.compile(\"(?i)(a)(b)\").flags, re.I | re.U)\n        self.assertEqual(re.compile(\"(?i)(a)(b)\").groups, 2)\n        self.assertEqual(re.compile(\"(?i)(a)(b)\").groupindex, {})\n        self.assertEqual(re.compile(\"(?i)(?P<first>a)(?P<other>b)\").groupindex,\n                         {'first': 1, 'other': 2})\n\n        self.assertEqual(re.match(\"(a)\", \"a\").pos, 0)\n        self.assertEqual(re.match(\"(a)\", \"a\").endpos, 1)\n        self.assertEqual(re.match(\"(a)\", \"a\").string, \"a\")\n        self.assertEqual(re.match(\"(a)\", \"a\").regs, ((0, 1), (0, 1)))\n        self.assertNotEqual(re.match(\"(a)\", \"a\").re, None)\n\n    def test_special_escapes(self):\n        self.assertEqual(re.search(r\"\\b(b.)\\b\",\n                                   \"abcd abc bcd bx\").group(1), \"bx\")\n        self.assertEqual(re.search(r\"\\B(b.)\\B\",\n                                   \"abc bcd bc abxd\").group(1), \"bx\")\n        self.assertEqual(re.search(r\"\\b(b.)\\b\",\n                                   \"abcd abc bcd bx\", re.LOCALE).group(1), \"bx\")\n        self.assertEqual(re.search(r\"\\B(b.)\\B\",\n                                   \"abc bcd bc abxd\", re.LOCALE).group(1), \"bx\")\n        self.assertEqual(re.search(r\"\\b(b.)\\b\",\n                                   \"abcd abc bcd bx\", re.UNICODE).group(1), \"bx\")\n        self.assertEqual(re.search(r\"\\B(b.)\\B\",\n                                   \"abc bcd bc abxd\", re.UNICODE).group(1), \"bx\")\n        self.assertEqual(re.search(r\"^abc$\", \"\\nabc\\n\", re.M).group(0), \"abc\")\n        self.assertEqual(re.search(r\"^\\Aabc\\Z$\", \"abc\", re.M).group(0), \"abc\")\n        self.assertEqual(re.search(r\"^\\Aabc\\Z$\", \"\\nabc\\n\", re.M), None)\n        self.assertEqual(re.search(r\"\\b(b.)\\b\",\n                                   \"abcd abc bcd bx\").group(1), \"bx\")\n        self.assertEqual(re.search(r\"\\B(b.)\\B\",\n                                   \"abc bcd bc abxd\").group(1), \"bx\")\n        self.assertEqual(re.search(r\"^abc$\", \"\\nabc\\n\", re.M).group(0), \"abc\")\n        self.assertEqual(re.search(r\"^\\Aabc\\Z$\", \"abc\", re.M).group(0), \"abc\")\n        self.assertEqual(re.search(r\"^\\Aabc\\Z$\", \"\\nabc\\n\", re.M), None)\n        self.assertEqual(re.search(r\"\\d\\D\\w\\W\\s\\S\",\n                                   \"1aa! a\").group(0), \"1aa! a\")\n        self.assertEqual(re.search(r\"\\d\\D\\w\\W\\s\\S\",\n                                   \"1aa! a\", re.LOCALE).group(0), \"1aa! a\")\n        self.assertEqual(re.search(r\"\\d\\D\\w\\W\\s\\S\",\n                                   \"1aa! a\", re.UNICODE).group(0), \"1aa! a\")\n\n    def test_string_boundaries(self):\n        # See http://bugs.python.org/issue10713\n        self.assertEqual(re.search(r\"\\b(abc)\\b\", \"abc\").group(1),\n                         \"abc\")\n        # There's a word boundary at the start of a string.\n        self.assertTrue(re.match(r\"\\b\", \"abc\"))\n        # A non-empty string includes a non-boundary zero-length match.\n        self.assertTrue(re.search(r\"\\B\", \"abc\"))\n        # There is no non-boundary match at the start of a string.\n        self.assertFalse(re.match(r\"\\B\", \"abc\"))\n        # However, an empty string contains no word boundaries, and also no\n        # non-boundaries.\n        self.assertEqual(re.search(r\"\\B\", \"\"), None)\n        # This one is questionable and different from the perlre behaviour,\n        # but describes current behavior.\n        self.assertEqual(re.search(r\"\\b\", \"\"), None)\n        # A single word-character string has two boundaries, but no\n        # non-boundary gaps.\n        self.assertEqual(len(re.findall(r\"\\b\", \"a\")), 2)\n        self.assertEqual(len(re.findall(r\"\\B\", \"a\")), 0)\n        # If there are no words, there are no boundaries\n        self.assertEqual(len(re.findall(r\"\\b\", \" \")), 0)\n        self.assertEqual(len(re.findall(r\"\\b\", \"   \")), 0)\n        # Can match around the whitespace.\n        self.assertEqual(len(re.findall(r\"\\B\", \" \")), 2)\n\n    def test_bigcharset(self):\n        self.assertEqual(re.match(\"([\\u2222\\u2223])\",\n                                  \"\\u2222\").group(1), \"\\u2222\")\n        self.assertEqual(re.match(\"([\\u2222\\u2223])\",\n                                  \"\\u2222\", re.UNICODE).group(1), \"\\u2222\")\n\n    def test_big_codesize(self):\n        # Issue #1160\n        r = re.compile('|'.join(('%d'%x for x in range(10000))))\n        self.assertIsNotNone(r.match('1000'))\n        self.assertIsNotNone(r.match('9999'))\n\n    def test_anyall(self):\n        self.assertEqual(re.match(\"a.b\", \"a\\nb\", re.DOTALL).group(0),\n                         \"a\\nb\")\n        self.assertEqual(re.match(\"a.*b\", \"a\\n\\nb\", re.DOTALL).group(0),\n                         \"a\\n\\nb\")\n\n    def test_non_consuming(self):\n        self.assertEqual(re.match(\"(a(?=\\s[^a]))\", \"a b\").group(1), \"a\")\n        self.assertEqual(re.match(\"(a(?=\\s[^a]*))\", \"a b\").group(1), \"a\")\n        self.assertEqual(re.match(\"(a(?=\\s[abc]))\", \"a b\").group(1), \"a\")\n        self.assertEqual(re.match(\"(a(?=\\s[abc]*))\", \"a bc\").group(1), \"a\")\n        self.assertEqual(re.match(r\"(a)(?=\\s\\1)\", \"a a\").group(1), \"a\")\n        self.assertEqual(re.match(r\"(a)(?=\\s\\1*)\", \"a aa\").group(1), \"a\")\n        self.assertEqual(re.match(r\"(a)(?=\\s(abc|a))\", \"a a\").group(1), \"a\")\n\n        self.assertEqual(re.match(r\"(a(?!\\s[^a]))\", \"a a\").group(1), \"a\")\n        self.assertEqual(re.match(r\"(a(?!\\s[abc]))\", \"a d\").group(1), \"a\")\n        self.assertEqual(re.match(r\"(a)(?!\\s\\1)\", \"a b\").group(1), \"a\")\n        self.assertEqual(re.match(r\"(a)(?!\\s(abc|a))\", \"a b\").group(1), \"a\")\n\n    def test_ignore_case(self):\n        self.assertEqual(re.match(\"abc\", \"ABC\", re.I).group(0), \"ABC\")\n        self.assertEqual(re.match(\"abc\", \"ABC\", re.I).group(0), \"ABC\")\n        self.assertEqual(re.match(r\"(a\\s[^a])\", \"a b\", re.I).group(1), \"a b\")\n        self.assertEqual(re.match(r\"(a\\s[^a]*)\", \"a bb\", re.I).group(1), \"a bb\")\n        self.assertEqual(re.match(r\"(a\\s[abc])\", \"a b\", re.I).group(1), \"a b\")\n        self.assertEqual(re.match(r\"(a\\s[abc]*)\", \"a bb\", re.I).group(1), \"a bb\")\n        self.assertEqual(re.match(r\"((a)\\s\\2)\", \"a a\", re.I).group(1), \"a a\")\n        self.assertEqual(re.match(r\"((a)\\s\\2*)\", \"a aa\", re.I).group(1), \"a aa\")\n        self.assertEqual(re.match(r\"((a)\\s(abc|a))\", \"a a\", re.I).group(1), \"a a\")\n        self.assertEqual(re.match(r\"((a)\\s(abc|a)*)\", \"a aa\", re.I).group(1), \"a aa\")\n\n    def test_category(self):\n        self.assertEqual(re.match(r\"(\\s)\", \" \").group(1), \" \")\n\n    def test_getlower(self):\n        import _sre\n        self.assertEqual(_sre.getlower(ord('A'), 0), ord('a'))\n        self.assertEqual(_sre.getlower(ord('A'), re.LOCALE), ord('a'))\n        self.assertEqual(_sre.getlower(ord('A'), re.UNICODE), ord('a'))\n\n        self.assertEqual(re.match(\"abc\", \"ABC\", re.I).group(0), \"ABC\")\n        self.assertEqual(re.match(\"abc\", \"ABC\", re.I).group(0), \"ABC\")\n\n    def test_not_literal(self):\n        self.assertEqual(re.search(\"\\s([^a])\", \" b\").group(1), \"b\")\n        self.assertEqual(re.search(\"\\s([^a]*)\", \" bb\").group(1), \"bb\")\n\n    def test_search_coverage(self):\n        self.assertEqual(re.search(\"\\s(b)\", \" b\").group(1), \"b\")\n        self.assertEqual(re.search(\"a\\s\", \"a \").group(0), \"a \")\n\n    def assertMatch(self, pattern, text, match=None, span=None,\n                    matcher=re.match):\n        if match is None and span is None:\n            # the pattern matches the whole text\n            match = text\n            span = (0, len(text))\n        elif match is None or span is None:\n            raise ValueError('If match is not None, span should be specified '\n                             '(and vice versa).')\n        m = matcher(pattern, text)\n        self.assertTrue(m)\n        self.assertEqual(m.group(), match)\n        self.assertEqual(m.span(), span)\n\n    def test_re_escape(self):\n        alnum_chars = string.ascii_letters + string.digits + '_'\n        p = ''.join(chr(i) for i in range(256))\n        for c in p:\n            if c in alnum_chars:\n                self.assertEqual(re.escape(c), c)\n            elif c == '\\x00':\n                self.assertEqual(re.escape(c), '\\\\000')\n            else:\n                self.assertEqual(re.escape(c), '\\\\' + c)\n            self.assertMatch(re.escape(c), c)\n        self.assertMatch(re.escape(p), p)\n\n    def test_re_escape_byte(self):\n        alnum_chars = (string.ascii_letters + string.digits + '_').encode('ascii')\n        p = bytes(range(256))\n        for i in p:\n            b = bytes([i])\n            if b in alnum_chars:\n                self.assertEqual(re.escape(b), b)\n            elif i == 0:\n                self.assertEqual(re.escape(b), b'\\\\000')\n            else:\n                self.assertEqual(re.escape(b), b'\\\\' + b)\n            self.assertMatch(re.escape(b), b)\n        self.assertMatch(re.escape(p), p)\n\n    def test_re_escape_non_ascii(self):\n        s = 'xxx\\u2620\\u2620\\u2620xxx'\n        s_escaped = re.escape(s)\n        self.assertEqual(s_escaped, 'xxx\\\\\\u2620\\\\\\u2620\\\\\\u2620xxx')\n        self.assertMatch(s_escaped, s)\n        self.assertMatch('.%s+.' % re.escape('\\u2620'), s,\n                         'x\\u2620\\u2620\\u2620x', (2, 7), re.search)\n\n    def test_re_escape_non_ascii_bytes(self):\n        b = 'y\\u2620y\\u2620y'.encode('utf-8')\n        b_escaped = re.escape(b)\n        self.assertEqual(b_escaped, b'y\\\\\\xe2\\\\\\x98\\\\\\xa0y\\\\\\xe2\\\\\\x98\\\\\\xa0y')\n        self.assertMatch(b_escaped, b)\n        res = re.findall(re.escape('\\u2620'.encode('utf-8')), b)\n        self.assertEqual(len(res), 2)\n\n    def pickle_test(self, pickle):\n        oldpat = re.compile('a(?:b|(c|e){1,2}?|d)+?(.)')\n        s = pickle.dumps(oldpat)\n        newpat = pickle.loads(s)\n        self.assertEqual(oldpat, newpat)\n\n    def test_constants(self):\n        self.assertEqual(re.I, re.IGNORECASE)\n        self.assertEqual(re.L, re.LOCALE)\n        self.assertEqual(re.M, re.MULTILINE)\n        self.assertEqual(re.S, re.DOTALL)\n        self.assertEqual(re.X, re.VERBOSE)\n\n    def test_flags(self):\n        for flag in [re.I, re.M, re.X, re.S, re.L]:\n            self.assertNotEqual(re.compile('^pattern$', flag), None)\n\n    def test_sre_character_literals(self):\n        for i in [0, 8, 16, 32, 64, 127, 128, 255, 256, 0xFFFF, 0x10000, 0x10FFFF]:\n            if i < 256:\n                self.assertIsNotNone(re.match(r\"\\%03o\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"\\%03o0\" % i, chr(i)+\"0\"))\n                self.assertIsNotNone(re.match(r\"\\%03o8\" % i, chr(i)+\"8\"))\n                self.assertIsNotNone(re.match(r\"\\x%02x\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"\\x%02x0\" % i, chr(i)+\"0\"))\n                self.assertIsNotNone(re.match(r\"\\x%02xz\" % i, chr(i)+\"z\"))\n            if i < 0x10000:\n                self.assertIsNotNone(re.match(r\"\\u%04x\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"\\u%04x0\" % i, chr(i)+\"0\"))\n                self.assertIsNotNone(re.match(r\"\\u%04xz\" % i, chr(i)+\"z\"))\n            self.assertIsNotNone(re.match(r\"\\U%08x\" % i, chr(i)))\n            self.assertIsNotNone(re.match(r\"\\U%08x0\" % i, chr(i)+\"0\"))\n            self.assertIsNotNone(re.match(r\"\\U%08xz\" % i, chr(i)+\"z\"))\n        self.assertIsNotNone(re.match(r\"\\0\", \"\\000\"))\n        self.assertIsNotNone(re.match(r\"\\08\", \"\\0008\"))\n        self.assertIsNotNone(re.match(r\"\\01\", \"\\001\"))\n        self.assertIsNotNone(re.match(r\"\\018\", \"\\0018\"))\n        self.assertIsNotNone(re.match(r\"\\567\", chr(0o167)))\n        self.assertRaises(re.error, re.match, r\"\\911\", \"\")\n        self.assertRaises(re.error, re.match, r\"\\x1\", \"\")\n        self.assertRaises(re.error, re.match, r\"\\x1z\", \"\")\n        self.assertRaises(re.error, re.match, r\"\\u123\", \"\")\n        self.assertRaises(re.error, re.match, r\"\\u123z\", \"\")\n        self.assertRaises(re.error, re.match, r\"\\U0001234\", \"\")\n        self.assertRaises(re.error, re.match, r\"\\U0001234z\", \"\")\n        self.assertRaises(re.error, re.match, r\"\\U00110000\", \"\")\n\n    def test_sre_character_class_literals(self):\n        for i in [0, 8, 16, 32, 64, 127, 128, 255, 256, 0xFFFF, 0x10000, 0x10FFFF]:\n            if i < 256:\n                self.assertIsNotNone(re.match(r\"[\\%o]\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"[\\%o8]\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"[\\%03o]\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"[\\%03o0]\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"[\\%03o8]\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"[\\x%02x]\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"[\\x%02x0]\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"[\\x%02xz]\" % i, chr(i)))\n            if i < 0x10000:\n                self.assertIsNotNone(re.match(r\"[\\u%04x]\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"[\\u%04x0]\" % i, chr(i)))\n                self.assertIsNotNone(re.match(r\"[\\u%04xz]\" % i, chr(i)))\n            self.assertIsNotNone(re.match(r\"[\\U%08x]\" % i, chr(i)))\n            self.assertIsNotNone(re.match(r\"[\\U%08x0]\" % i, chr(i)+\"0\"))\n            self.assertIsNotNone(re.match(r\"[\\U%08xz]\" % i, chr(i)+\"z\"))\n        self.assertIsNotNone(re.match(r\"[\\U0001d49c-\\U0001d4b5]\", \"\\U0001d49e\"))\n        self.assertRaises(re.error, re.match, r\"[\\911]\", \"\")\n        self.assertRaises(re.error, re.match, r\"[\\x1z]\", \"\")\n        self.assertRaises(re.error, re.match, r\"[\\u123z]\", \"\")\n        self.assertRaises(re.error, re.match, r\"[\\U0001234z]\", \"\")\n        self.assertRaises(re.error, re.match, r\"[\\U00110000]\", \"\")\n\n    def test_sre_byte_literals(self):\n        for i in [0, 8, 16, 32, 64, 127, 128, 255]:\n            self.assertIsNotNone(re.match((r\"\\%03o\" % i).encode(), bytes([i])))\n            self.assertIsNotNone(re.match((r\"\\%03o0\" % i).encode(), bytes([i])+b\"0\"))\n            self.assertIsNotNone(re.match((r\"\\%03o8\" % i).encode(), bytes([i])+b\"8\"))\n            self.assertIsNotNone(re.match((r\"\\x%02x\" % i).encode(), bytes([i])))\n            self.assertIsNotNone(re.match((r\"\\x%02x0\" % i).encode(), bytes([i])+b\"0\"))\n            self.assertIsNotNone(re.match((r\"\\x%02xz\" % i).encode(), bytes([i])+b\"z\"))\n        self.assertIsNotNone(re.match(br\"\\u\", b'u'))\n        self.assertIsNotNone(re.match(br\"\\U\", b'U'))\n        self.assertIsNotNone(re.match(br\"\\0\", b\"\\000\"))\n        self.assertIsNotNone(re.match(br\"\\08\", b\"\\0008\"))\n        self.assertIsNotNone(re.match(br\"\\01\", b\"\\001\"))\n        self.assertIsNotNone(re.match(br\"\\018\", b\"\\0018\"))\n        self.assertIsNotNone(re.match(br\"\\567\", bytes([0o167])))\n        self.assertRaises(re.error, re.match, br\"\\911\", b\"\")\n        self.assertRaises(re.error, re.match, br\"\\x1\", b\"\")\n        self.assertRaises(re.error, re.match, br\"\\x1z\", b\"\")\n\n    def test_sre_byte_class_literals(self):\n        for i in [0, 8, 16, 32, 64, 127, 128, 255]:\n            self.assertIsNotNone(re.match((r\"[\\%o]\" % i).encode(), bytes([i])))\n            self.assertIsNotNone(re.match((r\"[\\%o8]\" % i).encode(), bytes([i])))\n            self.assertIsNotNone(re.match((r\"[\\%03o]\" % i).encode(), bytes([i])))\n            self.assertIsNotNone(re.match((r\"[\\%03o0]\" % i).encode(), bytes([i])))\n            self.assertIsNotNone(re.match((r\"[\\%03o8]\" % i).encode(), bytes([i])))\n            self.assertIsNotNone(re.match((r\"[\\x%02x]\" % i).encode(), bytes([i])))\n            self.assertIsNotNone(re.match((r\"[\\x%02x0]\" % i).encode(), bytes([i])))\n            self.assertIsNotNone(re.match((r\"[\\x%02xz]\" % i).encode(), bytes([i])))\n        self.assertIsNotNone(re.match(br\"[\\u]\", b'u'))\n        self.assertIsNotNone(re.match(br\"[\\U]\", b'U'))\n        self.assertRaises(re.error, re.match, br\"[\\911]\", \"\")\n        self.assertRaises(re.error, re.match, br\"[\\x1z]\", \"\")\n\n    def test_bug_113254(self):\n        self.assertEqual(re.match(r'(a)|(b)', 'b').start(1), -1)\n        self.assertEqual(re.match(r'(a)|(b)', 'b').end(1), -1)\n        self.assertEqual(re.match(r'(a)|(b)', 'b').span(1), (-1, -1))\n\n    def test_bug_527371(self):\n        # bug described in patches 527371/672491\n        self.assertEqual(re.match(r'(a)?a','a').lastindex, None)\n        self.assertEqual(re.match(r'(a)(b)?b','ab').lastindex, 1)\n        self.assertEqual(re.match(r'(?P<a>a)(?P<b>b)?b','ab').lastgroup, 'a')\n        self.assertEqual(re.match(\"(?P<a>a(b))\", \"ab\").lastgroup, 'a')\n        self.assertEqual(re.match(\"((a))\", \"a\").lastindex, 1)\n\n    def test_bug_545855(self):\n        # bug 545855 -- This pattern failed to cause a compile error as it\n        # should, instead provoking a TypeError.\n        self.assertRaises(re.error, re.compile, 'foo[a-')\n\n    def test_bug_418626(self):\n        # bugs 418626 at al. -- Testing Greg Chapman's addition of op code\n        # SRE_OP_MIN_REPEAT_ONE for eliminating recursion on simple uses of\n        # pattern '*?' on a long string.\n        self.assertEqual(re.match('.*?c', 10000*'ab'+'cd').end(0), 20001)\n        self.assertEqual(re.match('.*?cd', 5000*'ab'+'c'+5000*'ab'+'cde').end(0),\n                         20003)\n        self.assertEqual(re.match('.*?cd', 20000*'abc'+'de').end(0), 60001)\n        # non-simple '*?' still used to hit the recursion limit, before the\n        # non-recursive scheme was implemented.\n        self.assertEqual(re.search('(a|b)*?c', 10000*'ab'+'cd').end(0), 20001)\n\n    def test_bug_612074(self):\n        pat=\"[\"+re.escape(\"\\u2039\")+\"]\"\n        self.assertEqual(re.compile(pat) and 1, 1)\n\n    def test_stack_overflow(self):\n        # nasty cases that used to overflow the straightforward recursive\n        # implementation of repeated groups.\n        self.assertEqual(re.match('(x)*', 50000*'x').group(1), 'x')\n        self.assertEqual(re.match('(x)*y', 50000*'x'+'y').group(1), 'x')\n        self.assertEqual(re.match('(x)*?y', 50000*'x'+'y').group(1), 'x')\n\n    def test_unlimited_zero_width_repeat(self):\n        # Issue #9669\n        self.assertIsNone(re.match(r'(?:a?)*y', 'z'))\n        self.assertIsNone(re.match(r'(?:a?)+y', 'z'))\n        self.assertIsNone(re.match(r'(?:a?){2,}y', 'z'))\n        self.assertIsNone(re.match(r'(?:a?)*?y', 'z'))\n        self.assertIsNone(re.match(r'(?:a?)+?y', 'z'))\n        self.assertIsNone(re.match(r'(?:a?){2,}?y', 'z'))\n\n#    def test_scanner(self):\n#        def s_ident(scanner, token): return token\n#        def s_operator(scanner, token): return \"op%s\" % token\n#        def s_float(scanner, token): return float(token)\n#        def s_int(scanner, token): return int(token)\n#\n#        scanner = Scanner([\n#            (r\"[a-zA-Z_]\\w*\", s_ident),\n#            (r\"\\d+\\.\\d*\", s_float),\n#            (r\"\\d+\", s_int),\n#            (r\"=|\\+|-|\\*|/\", s_operator),\n#            (r\"\\s+\", None),\n#            ])\n#\n#        self.assertNotEqual(scanner.scanner.scanner(\"\").pattern, None)\n#\n#        self.assertEqual(scanner.scan(\"sum = 3*foo + 312.50 + bar\"),\n#                         (['sum', 'op=', 3, 'op*', 'foo', 'op+', 312.5,\n#                           'op+', 'bar'], ''))\n\n    def test_bug_448951(self):\n        # bug 448951 (similar to 429357, but with single char match)\n        # (Also test greedy matches.)\n        for op in '','?','*':\n            self.assertEqual(re.match(r'((.%s):)?z'%op, 'z').groups(),\n                             (None, None))\n            self.assertEqual(re.match(r'((.%s):)?z'%op, 'a:z').groups(),\n                             ('a:', 'a'))\n\n    def test_bug_725106(self):\n        # capturing groups in alternatives in repeats\n        self.assertEqual(re.match('^((a)|b)*', 'abc').groups(),\n                         ('b', 'a'))\n        self.assertEqual(re.match('^(([ab])|c)*', 'abc').groups(),\n                         ('c', 'b'))\n        self.assertEqual(re.match('^((d)|[ab])*', 'abc').groups(),\n                         ('b', None))\n        self.assertEqual(re.match('^((a)c|[ab])*', 'abc').groups(),\n                         ('b', None))\n        self.assertEqual(re.match('^((a)|b)*?c', 'abc').groups(),\n                         ('b', 'a'))\n        self.assertEqual(re.match('^(([ab])|c)*?d', 'abcd').groups(),\n                         ('c', 'b'))\n        self.assertEqual(re.match('^((d)|[ab])*?c', 'abc').groups(),\n                         ('b', None))\n        self.assertEqual(re.match('^((a)c|[ab])*?c', 'abc').groups(),\n                         ('b', None))\n\n    def test_bug_725149(self):\n        # mark_stack_base restoring before restoring marks\n        self.assertEqual(re.match('(a)(?:(?=(b)*)c)*', 'abb').groups(),\n                         ('a', None))\n        self.assertEqual(re.match('(a)((?!(b)*))*', 'abb').groups(),\n                         ('a', None, None))\n\n    def test_bug_764548(self):\n        # bug 764548, re.compile() barfs on str/unicode subclasses\n        class my_unicode(str): pass\n        pat = re.compile(my_unicode(\"abc\"))\n        self.assertEqual(pat.match(\"xyz\"), None)\n\n    def test_finditer(self):\n        iter = re.finditer(r\":+\", \"a:b::c:::d\")\n        self.assertEqual([item.group(0) for item in iter],\n                         [\":\", \"::\", \":::\"])\n\n        pat = re.compile(r\":+\")\n        iter = pat.finditer(\"a:b::c:::d\", 1, 10)\n        self.assertEqual([item.group(0) for item in iter],\n                         [\":\", \"::\", \":::\"])\n\n        pat = re.compile(r\":+\")\n        iter = pat.finditer(\"a:b::c:::d\", pos=1, endpos=10)\n        self.assertEqual([item.group(0) for item in iter],\n                         [\":\", \"::\", \":::\"])\n\n        pat = re.compile(r\":+\")\n        iter = pat.finditer(\"a:b::c:::d\", endpos=10, pos=1)\n        self.assertEqual([item.group(0) for item in iter],\n                         [\":\", \"::\", \":::\"])\n\n        pat = re.compile(r\":+\")\n        iter = pat.finditer(\"a:b::c:::d\", pos=3, endpos=8)\n        self.assertEqual([item.group(0) for item in iter],\n                         [\"::\", \"::\"])\n\n    def test_bug_926075(self):\n        self.assertTrue(re.compile('bug_926075') is not\n                     re.compile(b'bug_926075'))\n\n    def test_bug_931848(self):\n        pattern = eval('\"[\\u002E\\u3002\\uFF0E\\uFF61]\"')\n        self.assertEqual(re.compile(pattern).split(\"a.b.c\"),\n                         ['a','b','c'])\n\n    def test_bug_581080(self):\n        iter = re.finditer(r\"\\s\", \"a b\")\n        self.assertEqual(next(iter).span(), (1,2))\n        self.assertRaises(StopIteration, next, iter)\n\n        scanner = re.compile(r\"\\s\").scanner(\"a b\")\n        self.assertEqual(scanner.search().span(), (1, 2))\n        self.assertEqual(scanner.search(), None)\n\n    def test_bug_817234(self):\n        iter = re.finditer(r\".*\", \"asdf\")\n        self.assertEqual(next(iter).span(), (0, 4))\n        self.assertEqual(next(iter).span(), (4, 4))\n        self.assertRaises(StopIteration, next, iter)\n\n    def test_bug_6561(self):\n        # '\\d' should match characters in Unicode category 'Nd'\n        # (Number, Decimal Digit), but not those in 'Nl' (Number,\n        # Letter) or 'No' (Number, Other).\n        decimal_digits = [\n            '\\u0037', # '\\N{DIGIT SEVEN}', category 'Nd'\n            '\\u0e58', # '\\N{THAI DIGIT SIX}', category 'Nd'\n            '\\uff10', # '\\N{FULLWIDTH DIGIT ZERO}', category 'Nd'\n            ]\n        for x in decimal_digits:\n            self.assertEqual(re.match('^\\d$', x).group(0), x)\n\n        not_decimal_digits = [\n            '\\u2165', # '\\N{ROMAN NUMERAL SIX}', category 'Nl'\n            '\\u3039', # '\\N{HANGZHOU NUMERAL TWENTY}', category 'Nl'\n            '\\u2082', # '\\N{SUBSCRIPT TWO}', category 'No'\n            '\\u32b4', # '\\N{CIRCLED NUMBER THIRTY NINE}', category 'No'\n            ]\n        for x in not_decimal_digits:\n            self.assertIsNone(re.match('^\\d$', x))\n\n    def test_empty_array(self):\n        # SF buf 1647541\n        import array\n        for typecode in 'bBuhHiIlLfd':\n            a = array.array(typecode)\n            self.assertEqual(re.compile(b\"bla\").match(a), None)\n            self.assertEqual(re.compile(b\"\").match(a).groups(), ())\n\n    def test_inline_flags(self):\n        # Bug #1700\n        upper_char = chr(0x1ea0) # Latin Capital Letter A with Dot Bellow\n        lower_char = chr(0x1ea1) # Latin Small Letter A with Dot Bellow\n\n        p = re.compile(upper_char, re.I | re.U)\n        q = p.match(lower_char)\n        self.assertNotEqual(q, None)\n\n        p = re.compile(lower_char, re.I | re.U)\n        q = p.match(upper_char)\n        self.assertNotEqual(q, None)\n\n        p = re.compile('(?i)' + upper_char, re.U)\n        q = p.match(lower_char)\n        self.assertNotEqual(q, None)\n\n        p = re.compile('(?i)' + lower_char, re.U)\n        q = p.match(upper_char)\n        self.assertNotEqual(q, None)\n\n        p = re.compile('(?iu)' + upper_char)\n        q = p.match(lower_char)\n        self.assertNotEqual(q, None)\n\n        p = re.compile('(?iu)' + lower_char)\n        q = p.match(upper_char)\n        self.assertNotEqual(q, None)\n\n    def test_dollar_matches_twice(self):\n        \"$ matches the end of string, and just before the terminating \\n\"\n        pattern = re.compile('$')\n        self.assertEqual(pattern.sub('#', 'a\\nb\\n'), 'a\\nb#\\n#')\n        self.assertEqual(pattern.sub('#', 'a\\nb\\nc'), 'a\\nb\\nc#')\n        self.assertEqual(pattern.sub('#', '\\n'), '#\\n#')\n\n        pattern = re.compile('$', re.MULTILINE)\n        self.assertEqual(pattern.sub('#', 'a\\nb\\n' ), 'a#\\nb#\\n#' )\n        self.assertEqual(pattern.sub('#', 'a\\nb\\nc'), 'a#\\nb#\\nc#')\n        self.assertEqual(pattern.sub('#', '\\n'), '#\\n#')\n\n    def test_bytes_str_mixing(self):\n        # Mixing str and bytes is disallowed\n        pat = re.compile('.')\n        bpat = re.compile(b'.')\n        self.assertRaises(TypeError, pat.match, b'b')\n        self.assertRaises(TypeError, bpat.match, 'b')\n        self.assertRaises(TypeError, pat.sub, b'b', 'c')\n        self.assertRaises(TypeError, pat.sub, 'b', b'c')\n        self.assertRaises(TypeError, pat.sub, b'b', b'c')\n        self.assertRaises(TypeError, bpat.sub, b'b', 'c')\n        self.assertRaises(TypeError, bpat.sub, 'b', b'c')\n        self.assertRaises(TypeError, bpat.sub, 'b', 'c')\n\n    def test_ascii_and_unicode_flag(self):\n        # String patterns\n        for flags in (0, re.UNICODE):\n            pat = re.compile('\\xc0', flags | re.IGNORECASE)\n            self.assertNotEqual(pat.match('\\xe0'), None)\n            pat = re.compile('\\w', flags)\n            self.assertNotEqual(pat.match('\\xe0'), None)\n        pat = re.compile('\\xc0', re.ASCII | re.IGNORECASE)\n        self.assertEqual(pat.match('\\xe0'), None)\n        pat = re.compile('(?a)\\xc0', re.IGNORECASE)\n        self.assertEqual(pat.match('\\xe0'), None)\n        pat = re.compile('\\w', re.ASCII)\n        self.assertEqual(pat.match('\\xe0'), None)\n        pat = re.compile('(?a)\\w')\n        self.assertEqual(pat.match('\\xe0'), None)\n        # Bytes patterns\n        for flags in (0, re.ASCII):\n            pat = re.compile(b'\\xc0', re.IGNORECASE)\n            self.assertEqual(pat.match(b'\\xe0'), None)\n            pat = re.compile(b'\\w')\n            self.assertEqual(pat.match(b'\\xe0'), None)\n        # Incompatibilities\n        self.assertRaises(ValueError, re.compile, b'\\w', re.UNICODE)\n        self.assertRaises(ValueError, re.compile, b'(?u)\\w')\n        self.assertRaises(ValueError, re.compile, '\\w', re.UNICODE | re.ASCII)\n        self.assertRaises(ValueError, re.compile, '(?u)\\w', re.ASCII)\n        self.assertRaises(ValueError, re.compile, '(?a)\\w', re.UNICODE)\n        self.assertRaises(ValueError, re.compile, '(?au)\\w')\n\n    def test_bug_6509(self):\n        # Replacement strings of both types must parse properly.\n        # all strings\n        pat = re.compile('a(\\w)')\n        self.assertEqual(pat.sub('b\\\\1', 'ac'), 'bc')\n        pat = re.compile('a(.)')\n        self.assertEqual(pat.sub('b\\\\1', 'a\\u1234'), 'b\\u1234')\n        pat = re.compile('..')\n        self.assertEqual(pat.sub(lambda m: 'str', 'a5'), 'str')\n\n        # all bytes\n        pat = re.compile(b'a(\\w)')\n        self.assertEqual(pat.sub(b'b\\\\1', b'ac'), b'bc')\n        pat = re.compile(b'a(.)')\n        self.assertEqual(pat.sub(b'b\\\\1', b'a\\xCD'), b'b\\xCD')\n        pat = re.compile(b'..')\n        self.assertEqual(pat.sub(lambda m: b'bytes', b'a5'), b'bytes')\n\n    def test_dealloc(self):\n        # issue 3299: check for segfault in debug build\n        import _sre\n        # the overflow limit is different on wide and narrow builds and it\n        # depends on the definition of SRE_CODE (see sre.h).\n        # 2**128 should be big enough to overflow on both. For smaller values\n        # a RuntimeError is raised instead of OverflowError.\n        long_overflow = 2**128\n        self.assertRaises(TypeError, re.finditer, \"a\", {})\n        self.assertRaises(OverflowError, _sre.compile, \"abc\", 0, [long_overflow])\n        self.assertRaises(TypeError, _sre.compile, {}, 0, [])\n\n    def test_search_dot_unicode(self):\n        self.assertIsNotNone(re.search(\"123.*-\", '123abc-'))\n        self.assertIsNotNone(re.search(\"123.*-\", '123\\xe9-'))\n        self.assertIsNotNone(re.search(\"123.*-\", '123\\u20ac-'))\n        self.assertIsNotNone(re.search(\"123.*-\", '123\\U0010ffff-'))\n        self.assertIsNotNone(re.search(\"123.*-\", '123\\xe9\\u20ac\\U0010ffff-'))\n\n    def test_compile(self):\n        # Test return value when given string and pattern as parameter\n        pattern = re.compile('random pattern')\n        self.assertIsInstance(pattern, re._pattern_type)\n        same_pattern = re.compile(pattern)\n        self.assertIsInstance(same_pattern, re._pattern_type)\n        self.assertIs(same_pattern, pattern)\n        # Test behaviour when not given a string or pattern as parameter\n        self.assertRaises(TypeError, re.compile, 0)\n\n    def test_bug_13899(self):\n        # Issue #13899: re pattern r\"[\\A]\" should work like \"A\" but matches\n        # nothing. Ditto B and Z.\n        self.assertEqual(re.findall(r'[\\A\\B\\b\\C\\Z]', 'AB\\bCZ'),\n                         ['A', 'B', '\\b', 'C', 'Z'])\n\n    # FIXME: brython: implement test.support\n#    @bigmemtest(size=_2G, memuse=1)\n#    def test_large_search(self, size):\n#        # Issue #10182: indices were 32-bit-truncated.\n#        s = 'a' * size\n#        m = re.search('$', s)\n#        self.assertIsNotNone(m)\n#        self.assertEqual(m.start(), size)\n#        self.assertEqual(m.end(), size)\n\n    # FIXME: brython: implement test.support\n    # The huge memuse is because of re.sub() using a list and a join()\n    # to create the replacement result.\n#    @bigmemtest(size=_2G, memuse=16 + 2)\n#    def test_large_subn(self, size):\n#        # Issue #10182: indices were 32-bit-truncated.\n#        s = 'a' * size\n#        r, n = re.subn('', '', s)\n#        self.assertEqual(r, s)\n#        self.assertEqual(n, size + 1)\n\n    def test_bug_16688(self):\n        # Issue 16688: Backreferences make case-insensitive regex fail on\n        # non-ASCII strings.\n        self.assertEqual(re.findall(r\"(?i)(a)\\1\", \"aa \\u0100\"), ['a'])\n        self.assertEqual(re.match(r\"(?s).{1,3}\", \"\\u0100\\u0100\").span(), (0, 2))\n\n    def test_repeat_minmax_overflow(self):\n        # Issue #13169\n        string = \"x\" * 100000\n        self.assertEqual(re.match(r\".{65535}\", string).span(), (0, 65535))\n        self.assertEqual(re.match(r\".{,65535}\", string).span(), (0, 65535))\n        self.assertEqual(re.match(r\".{65535,}?\", string).span(), (0, 65535))\n        self.assertEqual(re.match(r\".{65536}\", string).span(), (0, 65536))\n        self.assertEqual(re.match(r\".{,65536}\", string).span(), (0, 65536))\n        self.assertEqual(re.match(r\".{65536,}?\", string).span(), (0, 65536))\n        # 2**128 should be big enough to overflow both SRE_CODE and Py_ssize_t.\n        self.assertRaises(OverflowError, re.compile, r\".{%d}\" % 2**128)\n        self.assertRaises(OverflowError, re.compile, r\".{,%d}\" % 2**128)\n        self.assertRaises(OverflowError, re.compile, r\".{%d,}?\" % 2**128)\n        self.assertRaises(OverflowError, re.compile, r\".{%d,%d}\" % (2**129, 2**128))\n\n    # FIXME: brython: implement test.support\n#    @cpython_only\n#    def test_repeat_minmax_overflow_maxrepeat(self):\n#        try:\n#            from _sre import MAXREPEAT\n#        except ImportError:\n#            self.skipTest('requires _sre.MAXREPEAT constant')\n#        string = \"x\" * 100000\n#        self.assertIsNone(re.match(r\".{%d}\" % (MAXREPEAT - 1), string))\n#        self.assertEqual(re.match(r\".{,%d}\" % (MAXREPEAT - 1), string).span(),\n#                         (0, 100000))\n#        self.assertIsNone(re.match(r\".{%d,}?\" % (MAXREPEAT - 1), string))\n#        self.assertRaises(OverflowError, re.compile, r\".{%d}\" % MAXREPEAT)\n#        self.assertRaises(OverflowError, re.compile, r\".{,%d}\" % MAXREPEAT)\n#        self.assertRaises(OverflowError, re.compile, r\".{%d,}?\" % MAXREPEAT)\n\n    def test_backref_group_name_in_exception(self):\n        # Issue 17341: Poor error message when compiling invalid regex\n        with self.assertRaisesRegex(sre_constants.error, '<foo>'):\n            re.compile('(?P=<foo>)')\n\n    def test_group_name_in_exception(self):\n        # Issue 17341: Poor error message when compiling invalid regex\n        with self.assertRaisesRegex(sre_constants.error, '\\?foo'):\n            re.compile('(?P<?foo>)')\n\n\ndef run_re_tests():\n    from test.re_tests import tests, SUCCEED, FAIL, SYNTAX_ERROR\n    if verbose:\n        print('Running re_tests test suite')\n    else:\n        # To save time, only run the first and last 10 tests\n        #tests = tests[:10] + tests[-10:]\n        pass\n\n    for t in tests:\n        sys.stdout.flush()\n        pattern = s = outcome = repl = expected = None\n        if len(t) == 5:\n            pattern, s, outcome, repl, expected = t\n        elif len(t) == 3:\n            pattern, s, outcome = t\n        else:\n            raise ValueError('Test tuples should have 3 or 5 fields', t)\n\n        try:\n            obj = re.compile(pattern)\n        except re.error:\n            if outcome == SYNTAX_ERROR: pass  # Expected a syntax error\n            else:\n                print('=== Syntax error:', t)\n        except KeyboardInterrupt: raise KeyboardInterrupt\n        except:\n            print('*** Unexpected error ***', t)\n            if verbose:\n                traceback.print_exc(file=sys.stdout)\n        else:\n            try:\n                result = obj.search(s)\n            except re.error as msg:\n                print('=== Unexpected exception', t, repr(msg))\n            if outcome == SYNTAX_ERROR:\n                # This should have been a syntax error; forget it.\n                pass\n            elif outcome == FAIL:\n                if result is None: pass   # No match, as expected\n                else: print('=== Succeeded incorrectly', t)\n            elif outcome == SUCCEED:\n                if result is not None:\n                    # Matched, as expected, so now we compute the\n                    # result string and compare it to our expected result.\n                    start, end = result.span(0)\n                    vardict={'found': result.group(0),\n                             'groups': result.group(),\n                             'flags': result.re.flags}\n                    for i in range(1, 100):\n                        try:\n                            gi = result.group(i)\n                            # Special hack because else the string concat fails:\n                            if gi is None:\n                                gi = \"None\"\n                        except IndexError:\n                            gi = \"Error\"\n                        vardict['g%d' % i] = gi\n                    for i in result.re.groupindex.keys():\n                        try:\n                            gi = result.group(i)\n                            if gi is None:\n                                gi = \"None\"\n                        except IndexError:\n                            gi = \"Error\"\n                        vardict[i] = gi\n                    repl = eval(repl, vardict)\n                    if repl != expected:\n                        print('=== grouping error', t, end=' ')\n                        print(repr(repl) + ' should be ' + repr(expected))\n                else:\n                    print('=== Failed incorrectly', t)\n\n                # Try the match with both pattern and string converted to\n                # bytes, and check that it still succeeds.\n                try:\n                    bpat = bytes(pattern, \"ascii\")\n                    bs = bytes(s, \"ascii\")\n                except UnicodeEncodeError:\n                    # skip non-ascii tests\n                    pass\n                else:\n                    try:\n                        bpat = re.compile(bpat)\n                    except Exception:\n                        print('=== Fails on bytes pattern compile', t)\n                        if verbose:\n                            traceback.print_exc(file=sys.stdout)\n                    else:\n                        bytes_result = bpat.search(bs)\n                        if bytes_result is None:\n                            print('=== Fails on bytes pattern match', t)\n\n                # Try the match with the search area limited to the extent\n                # of the match and see if it still succeeds.  \\B will\n                # break (because it won't match at the end or start of a\n                # string), so we'll ignore patterns that feature it.\n\n                if pattern[:2] != '\\\\B' and pattern[-2:] != '\\\\B' \\\n                               and result is not None:\n                    obj = re.compile(pattern)\n                    result = obj.search(s, result.start(0), result.end(0) + 1)\n                    if result is None:\n                        print('=== Failed on range-limited match', t)\n\n                # Try the match with IGNORECASE enabled, and check that it\n                # still succeeds.\n                obj = re.compile(pattern, re.IGNORECASE)\n                result = obj.search(s)\n                if result is None:\n                    print('=== Fails on case-insensitive match', t)\n\n                # Try the match with LOCALE enabled, and check that it\n                # still succeeds.\n                if '(?u)' not in pattern:\n                    obj = re.compile(pattern, re.LOCALE)\n                    result = obj.search(s)\n                    if result is None:\n                        print('=== Fails on locale-sensitive match', t)\n\n                # Try the match with UNICODE locale enabled, and check\n                # that it still succeeds.\n                obj = re.compile(pattern, re.UNICODE)\n                result = obj.search(s)\n                if result is None:\n                    print('=== Fails on unicode-sensitive match', t)\n\n\ndef test_main():\n    # FIXME: brython: implement test.support\n#    run_unittest(ReTests)\n    run_re_tests()\n\nif __name__ == \"__main__\":\n    test_main()\n"], "datetime": [".py", "\"\"\"Concrete date/time and related types.\n\nSee http://www.iana.org/time-zones/repository/tz-link.html for\ntime zone and DST data sources.\n\"\"\"\n\nimport time as _time\nimport math as _math\n\ndef _cmp(x, y):\n    return 0 if x == y else 1 if x > y else -1\n\nMINYEAR = 1\nMAXYEAR = 9999\n_MAXORDINAL = 3652059 # date.max.toordinal()\n\n# Utility functions, adapted from Python's Demo/classes/Dates.py, which\n# also assumes the current Gregorian calendar indefinitely extended in\n# both directions.  Difference:  Dates.py calls January 1 of year 0 day\n# number 1.  The code here calls January 1 of year 1 day number 1.  This is\n# to match the definition of the \"proleptic Gregorian\" calendar in Dershowitz\n# and Reingold's \"Calendrical Calculations\", where it's the base calendar\n# for all computations.  See the book for algorithms for converting between\n# proleptic Gregorian ordinals and many other calendar systems.\n\n_DAYS_IN_MONTH = [None, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n\n_DAYS_BEFORE_MONTH = [None]\ndbm = 0\nfor dim in _DAYS_IN_MONTH[1:]:\n    _DAYS_BEFORE_MONTH.append(dbm)\n    dbm += dim\ndel dbm, dim\n\ndef _is_leap(year):\n    \"year -> 1 if leap year, else 0.\"\n    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n\ndef _days_before_year(year):\n    \"year -> number of days before January 1st of year.\"\n    y = year - 1\n    return y*365 + y//4 - y//100 + y//400\n\ndef _days_in_month(year, month):\n    \"year, month -> number of days in that month in that year.\"\n    assert 1 <= month <= 12, month\n    if month == 2 and _is_leap(year):\n        return 29\n    return _DAYS_IN_MONTH[month]\n\ndef _days_before_month(year, month):\n    \"year, month -> number of days in year preceding first day of month.\"\n    assert 1 <= month <= 12, 'month must be in 1..12'\n    return _DAYS_BEFORE_MONTH[month] + (month > 2 and _is_leap(year))\n\ndef _ymd2ord(year, month, day):\n    \"year, month, day -> ordinal, considering 01-Jan-0001 as day 1.\"\n    assert 1 <= month <= 12, 'month must be in 1..12'\n    dim = _days_in_month(year, month)\n    assert 1 <= day <= dim, ('day must be in 1..%d' % dim)\n    return (_days_before_year(year) +\n            _days_before_month(year, month) +\n            day)\n\n_DI400Y = _days_before_year(401)    # number of days in 400 years\n_DI100Y = _days_before_year(101)    #    \"    \"   \"   \" 100   \"\n_DI4Y   = _days_before_year(5)      #    \"    \"   \"   \"   4   \"\n\n# A 4-year cycle has an extra leap day over what we'd get from pasting\n# together 4 single years.\nassert _DI4Y == 4 * 365 + 1\n\n# Similarly, a 400-year cycle has an extra leap day over what we'd get from\n# pasting together 4 100-year cycles.\nassert _DI400Y == 4 * _DI100Y + 1\n\n# OTOH, a 100-year cycle has one fewer leap day than we'd get from\n# pasting together 25 4-year cycles.\nassert _DI100Y == 25 * _DI4Y - 1\n\ndef _ord2ymd(n):\n    \"ordinal -> (year, month, day), considering 01-Jan-0001 as day 1.\"\n\n    # n is a 1-based index, starting at 1-Jan-1.  The pattern of leap years\n    # repeats exactly every 400 years.  The basic strategy is to find the\n    # closest 400-year boundary at or before n, then work with the offset\n    # from that boundary to n.  Life is much clearer if we subtract 1 from\n    # n first -- then the values of n at 400-year boundaries are exactly\n    # those divisible by _DI400Y:\n    #\n    #     D  M   Y            n              n-1\n    #     -- --- ----        ----------     ----------------\n    #     31 Dec -400        -_DI400Y       -_DI400Y -1\n    #      1 Jan -399         -_DI400Y +1   -_DI400Y      400-year boundary\n    #     ...\n    #     30 Dec  000        -1             -2\n    #     31 Dec  000         0             -1\n    #      1 Jan  001         1              0            400-year boundary\n    #      2 Jan  001         2              1\n    #      3 Jan  001         3              2\n    #     ...\n    #     31 Dec  400         _DI400Y        _DI400Y -1\n    #      1 Jan  401         _DI400Y +1     _DI400Y      400-year boundary\n    n -= 1\n    n400, n = divmod(n, _DI400Y)\n    year = n400 * 400 + 1   # ..., -399, 1, 401, ...\n\n    # Now n is the (non-negative) offset, in days, from January 1 of year, to\n    # the desired date.  Now compute how many 100-year cycles precede n.\n    # Note that it's possible for n100 to equal 4!  In that case 4 full\n    # 100-year cycles precede the desired day, which implies the desired\n    # day is December 31 at the end of a 400-year cycle.\n    n100, n = divmod(n, _DI100Y)\n\n    # Now compute how many 4-year cycles precede it.\n    n4, n = divmod(n, _DI4Y)\n\n    # And now how many single years.  Again n1 can be 4, and again meaning\n    # that the desired day is December 31 at the end of the 4-year cycle.\n    n1, n = divmod(n, 365)\n\n    year += n100 * 100 + n4 * 4 + n1\n    if n1 == 4 or n100 == 4:\n        assert n == 0\n        return year-1, 12, 31\n\n    # Now the year is correct, and n is the offset from January 1.  We find\n    # the month via an estimate that's either exact or one too large.\n    leapyear = n1 == 3 and (n4 != 24 or n100 == 3)\n    assert leapyear == _is_leap(year)\n    month = (n + 50) >> 5\n    preceding = _DAYS_BEFORE_MONTH[month] + (month > 2 and leapyear)\n    if preceding > n:  # estimate is too large\n        month -= 1\n        preceding -= _DAYS_IN_MONTH[month] + (month == 2 and leapyear)\n    n -= preceding\n    assert 0 <= n < _days_in_month(year, month)\n\n    # Now the year and month are correct, and n is the offset from the\n    # start of that month:  we're done!\n    return year, month, n+1\n\n# Month and day names.  For localized versions, see the calendar module.\n_MONTHNAMES = [None, \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n                     \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n_DAYNAMES = [None, \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n\n\ndef _build_struct_time(y, m, d, hh, mm, ss, dstflag):\n    wday = (_ymd2ord(y, m, d) + 6) % 7\n    dnum = _days_before_month(y, m) + d\n    return _time.struct_time((y, m, d, hh, mm, ss, wday, dnum, dstflag))\n\ndef _format_time(hh, mm, ss, us):\n    # Skip trailing microseconds when us==0.\n    result = \"%02d:%02d:%02d\" % (hh, mm, ss)\n    if us:\n        result += \".%06d\" % us\n    return result\n\n# Correctly substitute for %z and %Z escapes in strftime formats.\ndef _wrap_strftime(object, format, timetuple):\n    # Don't call utcoffset() or tzname() unless actually needed.\n    freplace = None # the string to use for %f\n    zreplace = None # the string to use for %z\n    Zreplace = None # the string to use for %Z\n\n    # Scan format for %z and %Z escapes, replacing as needed.\n    newformat = []\n    push = newformat.append\n    i, n = 0, len(format)\n    while i < n:\n        ch = format[i]\n        i += 1\n        if ch == '%':\n            if i < n:\n                ch = format[i]\n                i += 1\n                if ch == 'f':\n                    if freplace is None:\n                        freplace = '%06d' % getattr(object,\n                                                    'microsecond', 0)\n                    newformat.append(freplace)\n                elif ch == 'z':\n                    if zreplace is None:\n                        zreplace = \"\"\n                        if hasattr(object, \"utcoffset\"):\n                            offset = object.utcoffset()\n                            if offset is not None:\n                                sign = '+'\n                                if offset.days < 0:\n                                    offset = -offset\n                                    sign = '-'\n                                h, m = divmod(offset, timedelta(hours=1))\n                                assert not m % timedelta(minutes=1), \"whole minute\"\n                                m //= timedelta(minutes=1)\n                                zreplace = '%c%02d%02d' % (sign, h, m)\n                    assert '%' not in zreplace\n                    newformat.append(zreplace)\n                elif ch == 'Z':\n                    if Zreplace is None:\n                        Zreplace = \"\"\n                        if hasattr(object, \"tzname\"):\n                            s = object.tzname()\n                            if s is not None:\n                                # strftime is going to have at this: escape %\n                                Zreplace = s.replace('%', '%%')\n                    newformat.append(Zreplace)\n                else:\n                    push('%')\n                    push(ch)\n            else:\n                push('%')\n        else:\n            push(ch)\n    newformat = \"\".join(newformat)\n    return _time.strftime(newformat, timetuple)\n\ndef _call_tzinfo_method(tzinfo, methname, tzinfoarg):\n    if tzinfo is None:\n        return None\n    return getattr(tzinfo, methname)(tzinfoarg)\n\n# Just raise TypeError if the arg isn't None or a string.\ndef _check_tzname(name):\n    if name is not None and not isinstance(name, str):\n        raise TypeError(\"tzinfo.tzname() must return None or string, \"\n                        \"not '%s'\" % type(name))\n\n# name is the offset-producing method, \"utcoffset\" or \"dst\".\n# offset is what it returned.\n# If offset isn't None or timedelta, raises TypeError.\n# If offset is None, returns None.\n# Else offset is checked for being in range, and a whole # of minutes.\n# If it is, its integer value is returned.  Else ValueError is raised.\ndef _check_utc_offset(name, offset):\n    assert name in (\"utcoffset\", \"dst\")\n    if offset is None:\n        return\n    if not isinstance(offset, timedelta):\n        raise TypeError(\"tzinfo.%s() must return None \"\n                        \"or timedelta, not '%s'\" % (name, type(offset)))\n    if offset % timedelta(minutes=1) or offset.microseconds:\n        raise ValueError(\"tzinfo.%s() must return a whole number \"\n                         \"of minutes, got %s\" % (name, offset))\n    if not -timedelta(1) < offset < timedelta(1):\n        raise ValueError(\"%s()=%s, must be must be strictly between\"\n                         \" -timedelta(hours=24) and timedelta(hours=24)\"\n                         % (name, offset))\n\ndef _check_date_fields(year, month, day):\n    if not isinstance(year, int):\n        raise TypeError('int expected')\n    if not MINYEAR <= year <= MAXYEAR:\n        raise ValueError('year must be in %d..%d' % (MINYEAR, MAXYEAR), year)\n    if not 1 <= month <= 12:\n        raise ValueError('month must be in 1..12', month)\n    dim = _days_in_month(year, month)\n    if not 1 <= day <= dim:\n        raise ValueError('day must be in 1..%d' % dim, day)\n\ndef _check_time_fields(hour, minute, second, microsecond):\n    if not isinstance(hour, int):\n        raise TypeError('int expected')\n    if not 0 <= hour <= 23:\n        raise ValueError('hour must be in 0..23', hour)\n    if not 0 <= minute <= 59:\n        raise ValueError('minute must be in 0..59', minute)\n    if not 0 <= second <= 59:\n        raise ValueError('second must be in 0..59', second)\n    if not 0 <= microsecond <= 999999:\n        raise ValueError('microsecond must be in 0..999999', microsecond)\n\ndef _check_tzinfo_arg(tz):\n    if tz is not None and not isinstance(tz, tzinfo):\n        raise TypeError(\"tzinfo argument must be None or of a tzinfo subclass\")\n\ndef _cmperror(x, y):\n    raise TypeError(\"can't compare '%s' to '%s'\" % (\n                    type(x).__name__, type(y).__name__))\n\nclass timedelta:\n    \"\"\"Represent the difference between two datetime objects.\n\n    Supported operators:\n\n    - add, subtract timedelta\n    - unary plus, minus, abs\n    - compare to timedelta\n    - multiply, divide by int\n\n    In addition, datetime supports subtraction of two datetime objects\n    returning a timedelta, and addition or subtraction of a datetime\n    and a timedelta giving a datetime.\n\n    Representation: (days, seconds, microseconds).  Why?  Because I\n    felt like it.\n    \"\"\"\n    __slots__ = '_days', '_seconds', '_microseconds'\n\n    def __new__(cls, days=0, seconds=0, microseconds=0,\n                milliseconds=0, minutes=0, hours=0, weeks=0):\n        # Doing this efficiently and accurately in C is going to be difficult\n        # and error-prone, due to ubiquitous overflow possibilities, and that\n        # C double doesn't have enough bits of precision to represent\n        # microseconds over 10K years faithfully.  The code here tries to make\n        # explicit where go-fast assumptions can be relied on, in order to\n        # guide the C implementation; it's way more convoluted than speed-\n        # ignoring auto-overflow-to-long idiomatic Python could be.\n\n        # XXX Check that all inputs are ints or floats.\n\n        # Final values, all integer.\n        # s and us fit in 32-bit signed ints; d isn't bounded.\n        d = s = us = 0\n\n        # Normalize everything to days, seconds, microseconds.\n        days += weeks*7\n        seconds += minutes*60 + hours*3600\n        microseconds += milliseconds*1000\n\n        # Get rid of all fractions, and normalize s and us.\n        # Take a deep breath <wink>.\n        if isinstance(days, float):\n            dayfrac, days = _math.modf(days)\n            daysecondsfrac, daysecondswhole = _math.modf(dayfrac * (24.*3600.))\n            assert daysecondswhole == int(daysecondswhole)  # can't overflow\n            s = int(daysecondswhole)\n            assert days == int(days)\n            d = int(days)\n        else:\n            daysecondsfrac = 0.0\n            d = days\n        assert isinstance(daysecondsfrac, float)\n        assert abs(daysecondsfrac) <= 1.0\n        assert isinstance(d, int)\n        assert abs(s) <= 24 * 3600\n        # days isn't referenced again before redefinition\n\n        if isinstance(seconds, float):\n            secondsfrac, seconds = _math.modf(seconds)\n            assert seconds == int(seconds)\n            seconds = int(seconds)\n            secondsfrac += daysecondsfrac\n            assert abs(secondsfrac) <= 2.0\n        else:\n            secondsfrac = daysecondsfrac\n        # daysecondsfrac isn't referenced again\n        assert isinstance(secondsfrac, float)\n        assert abs(secondsfrac) <= 2.0\n\n        assert isinstance(seconds, int)\n        days, seconds = divmod(seconds, 24*3600)\n        d += days\n        s += int(seconds)    # can't overflow\n        assert isinstance(s, int)\n        assert abs(s) <= 2 * 24 * 3600\n        # seconds isn't referenced again before redefinition\n\n        usdouble = secondsfrac * 1e6\n        assert abs(usdouble) < 2.1e6    # exact value not critical\n        # secondsfrac isn't referenced again\n\n        if isinstance(microseconds, float):\n            microseconds += usdouble\n            microseconds = round(microseconds, 0)\n            seconds, microseconds = divmod(microseconds, 1e6)\n            assert microseconds == int(microseconds)\n            assert seconds == int(seconds)\n            days, seconds = divmod(seconds, 24.*3600.)\n            assert days == int(days)\n            assert seconds == int(seconds)\n            d += int(days)\n            s += int(seconds)   # can't overflow\n            assert isinstance(s, int)\n            assert abs(s) <= 3 * 24 * 3600\n        else:\n            seconds, microseconds = divmod(microseconds, 1000000)\n            days, seconds = divmod(seconds, 24*3600)\n            d += days\n            s += int(seconds)    # can't overflow\n            assert isinstance(s, int)\n            assert abs(s) <= 3 * 24 * 3600\n            microseconds = float(microseconds)\n            microseconds += usdouble\n            microseconds = round(microseconds, 0)\n        assert abs(s) <= 3 * 24 * 3600\n        assert abs(microseconds) < 3.1e6\n\n        # Just a little bit of carrying possible for microseconds and seconds.\n        assert isinstance(microseconds, float)\n        assert int(microseconds) == microseconds\n        us = int(microseconds)\n        seconds, us = divmod(us, 1000000)\n        s += seconds    # cant't overflow\n        assert isinstance(s, int)\n        days, s = divmod(s, 24*3600)\n        d += days\n\n        assert isinstance(d, int)\n        assert isinstance(s, int) and 0 <= s < 24*3600\n        assert isinstance(us, int) and 0 <= us < 1000000\n\n        self = object.__new__(cls)\n\n        self._days = d\n        self._seconds = s\n        self._microseconds = us\n        if abs(d) > 999999999:\n            raise OverflowError(\"timedelta # of days is too large: %d\" % d)\n\n        return self\n\n    def __repr__(self):\n        if self._microseconds:\n            return \"%s(%d, %d, %d)\" % ('datetime.' + self.__class__.__name__,\n                                       self._days,\n                                       self._seconds,\n                                       self._microseconds)\n        if self._seconds:\n            return \"%s(%d, %d)\" % ('datetime.' + self.__class__.__name__,\n                                   self._days,\n                                   self._seconds)\n        return \"%s(%d)\" % ('datetime.' + self.__class__.__name__, self._days)\n\n    def __str__(self):\n        mm, ss = divmod(self._seconds, 60)\n        hh, mm = divmod(mm, 60)\n        s = \"%d:%02d:%02d\" % (hh, mm, ss)\n        if self._days:\n            def plural(n):\n                return n, abs(n) != 1 and \"s\" or \"\"\n            s = (\"%d day%s, \" % plural(self._days)) + s\n        if self._microseconds:\n            s = s + \".%06d\" % self._microseconds\n        return s\n\n    def total_seconds(self):\n        \"\"\"Total seconds in the duration.\"\"\"\n        return ((self.days * 86400 + self.seconds)*10**6 +\n                self.microseconds) / 10**6\n\n    # Read-only field accessors\n    @property\n    def days(self):\n        \"\"\"days\"\"\"\n        return self._days\n\n    @property\n    def seconds(self):\n        \"\"\"seconds\"\"\"\n        return self._seconds\n\n    @property\n    def microseconds(self):\n        \"\"\"microseconds\"\"\"\n        return self._microseconds\n\n    def __add__(self, other):\n        if isinstance(other, timedelta):\n            # for CPython compatibility, we cannot use\n            # our __class__ here, but need a real timedelta\n            return timedelta(self._days + other._days,\n                             self._seconds + other._seconds,\n                             self._microseconds + other._microseconds)\n        return NotImplemented\n\n    __radd__ = __add__\n\n    def __sub__(self, other):\n        if isinstance(other, timedelta):\n            # for CPython compatibility, we cannot use\n            # our __class__ here, but need a real timedelta\n            return timedelta(self._days - other._days,\n                             self._seconds - other._seconds,\n                             self._microseconds - other._microseconds)\n        return NotImplemented\n\n    def __rsub__(self, other):\n        if isinstance(other, timedelta):\n            return -self + other\n        return NotImplemented\n\n    def __neg__(self):\n        # for CPython compatibility, we cannot use\n        # our __class__ here, but need a real timedelta\n        return timedelta(-self._days,\n                         -self._seconds,\n                         -self._microseconds)\n\n    def __pos__(self):\n        return self\n\n    def __abs__(self):\n        if self._days < 0:\n            return -self\n        else:\n            return self\n\n    def __mul__(self, other):\n        if isinstance(other, int):\n            # for CPython compatibility, we cannot use\n            # our __class__ here, but need a real timedelta\n            return timedelta(self._days * other,\n                             self._seconds * other,\n                             self._microseconds * other)\n        if isinstance(other, float):\n            a, b = other.as_integer_ratio()\n            return self * a / b\n        return NotImplemented\n\n    __rmul__ = __mul__\n\n    def _to_microseconds(self):\n        return ((self._days * (24*3600) + self._seconds) * 1000000 +\n                self._microseconds)\n\n    def __floordiv__(self, other):\n        if not isinstance(other, (int, timedelta)):\n            return NotImplemented\n        usec = self._to_microseconds()\n        if isinstance(other, timedelta):\n            return usec // other._to_microseconds()\n        if isinstance(other, int):\n            return timedelta(0, 0, usec // other)\n\n    def __truediv__(self, other):\n        if not isinstance(other, (int, float, timedelta)):\n            return NotImplemented\n        usec = self._to_microseconds()\n        if isinstance(other, timedelta):\n            return usec / other._to_microseconds()\n        if isinstance(other, int):\n            return timedelta(0, 0, usec / other)\n        if isinstance(other, float):\n            a, b = other.as_integer_ratio()\n            return timedelta(0, 0, b * usec / a)\n\n    def __mod__(self, other):\n        if isinstance(other, timedelta):\n            r = self._to_microseconds() % other._to_microseconds()\n            return timedelta(0, 0, r)\n        return NotImplemented\n\n    def __divmod__(self, other):\n        if isinstance(other, timedelta):\n            q, r = divmod(self._to_microseconds(),\n                          other._to_microseconds())\n            return q, timedelta(0, 0, r)\n        return NotImplemented\n\n    # Comparisons of timedelta objects with other.\n\n    def __eq__(self, other):\n        if isinstance(other, timedelta):\n            return self._cmp(other) == 0\n        else:\n            return False\n\n    def __ne__(self, other):\n        if isinstance(other, timedelta):\n            return self._cmp(other) != 0\n        else:\n            return True\n\n    def __le__(self, other):\n        if isinstance(other, timedelta):\n            return self._cmp(other) <= 0\n        else:\n            _cmperror(self, other)\n\n    def __lt__(self, other):\n        if isinstance(other, timedelta):\n            return self._cmp(other) < 0\n        else:\n            _cmperror(self, other)\n\n    def __ge__(self, other):\n        if isinstance(other, timedelta):\n            return self._cmp(other) >= 0\n        else:\n            _cmperror(self, other)\n\n    def __gt__(self, other):\n        if isinstance(other, timedelta):\n            return self._cmp(other) > 0\n        else:\n            _cmperror(self, other)\n\n    def _cmp(self, other):\n        assert isinstance(other, timedelta)\n        return _cmp(self._getstate(), other._getstate())\n\n    def __hash__(self):\n        return hash(self._getstate())\n\n    def __bool__(self):\n        return (self._days != 0 or\n                self._seconds != 0 or\n                self._microseconds != 0)\n\n    # Pickle support.\n\n    def _getstate(self):\n        return (self._days, self._seconds, self._microseconds)\n\n    def __reduce__(self):\n        return (self.__class__, self._getstate())\n\ntimedelta.min = timedelta(-999999999)\ntimedelta.max = timedelta(days=999999999, hours=23, minutes=59, seconds=59,\n                          microseconds=999999)\ntimedelta.resolution = timedelta(microseconds=1)\n\nclass date:\n    \"\"\"Concrete date type.\n\n    Constructors:\n\n    __new__()\n    fromtimestamp()\n    today()\n    fromordinal()\n\n    Operators:\n\n    __repr__, __str__\n    __cmp__, __hash__\n    __add__, __radd__, __sub__ (add/radd only with timedelta arg)\n\n    Methods:\n\n    timetuple()\n    toordinal()\n    weekday()\n    isoweekday(), isocalendar(), isoformat()\n    ctime()\n    strftime()\n\n    Properties (readonly):\n    year, month, day\n    \"\"\"\n    __slots__ = '_year', '_month', '_day'\n\n    def __new__(cls, year, month=None, day=None):\n        \"\"\"Constructor.\n\n        Arguments:\n\n        year, month, day (required, base 1)\n        \"\"\"\n        if (isinstance(year, bytes) and len(year) == 4 and\n            1 <= year[2] <= 12 and month is None):  # Month is sane\n            # Pickle support\n            self = object.__new__(cls)\n            self.__setstate(year)\n            return self\n        _check_date_fields(year, month, day)\n        self = object.__new__(cls)\n        self._year = year\n        self._month = month\n        self._day = day\n        return self\n\n    # Additional constructors\n\n    @classmethod\n    def fromtimestamp(cls, t):\n        \"Construct a date from a POSIX timestamp (like time.time()).\"\n        y, m, d, hh, mm, ss, weekday, jday, dst = _time.localtime(t)\n        return cls(y, m, d)\n\n    @classmethod\n    def today(cls):\n        \"Construct a date from time.time().\"\n        t = _time.time()\n        return cls.fromtimestamp(t)\n\n    @classmethod\n    def fromordinal(cls, n):\n        \"\"\"Contruct a date from a proleptic Gregorian ordinal.\n\n        January 1 of year 1 is day 1.  Only the year, month and day are\n        non-zero in the result.\n        \"\"\"\n        y, m, d = _ord2ymd(n)\n        return cls(y, m, d)\n\n    # Conversions to string\n\n    def __repr__(self):\n        \"\"\"Convert to formal string, for repr().\n\n        >>> dt = datetime(2010, 1, 1)\n        >>> repr(dt)\n        'datetime.datetime(2010, 1, 1, 0, 0)'\n\n        >>> dt = datetime(2010, 1, 1, tzinfo=timezone.utc)\n        >>> repr(dt)\n        'datetime.datetime(2010, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)'\n        \"\"\"\n        return \"%s(%d, %d, %d)\" % ('datetime.' + self.__class__.__name__,\n                                   self._year,\n                                   self._month,\n                                   self._day)\n    # XXX These shouldn't depend on time.localtime(), because that\n    # clips the usable dates to [1970 .. 2038).  At least ctime() is\n    # easily done without using strftime() -- that's better too because\n    # strftime(\"%c\", ...) is locale specific.\n\n\n    def ctime(self):\n        \"Return ctime() style string.\"\n        weekday = self.toordinal() % 7 or 7\n        return \"%s %s %2d 00:00:00 %04d\" % (\n            _DAYNAMES[weekday],\n            _MONTHNAMES[self._month],\n            self._day, self._year)\n\n    def strftime(self, fmt):\n        \"Format using strftime().\"\n        return _wrap_strftime(self, fmt, self.timetuple())\n\n    def __format__(self, fmt):\n        if len(fmt) != 0:\n            return self.strftime(fmt)\n        return str(self)\n\n    def isoformat(self):\n        \"\"\"Return the date formatted according to ISO.\n\n        This is 'YYYY-MM-DD'.\n\n        References:\n        - http://www.w3.org/TR/NOTE-datetime\n        - http://www.cl.cam.ac.uk/~mgk25/iso-time.html\n        \"\"\"\n        return \"%04d-%02d-%02d\" % (self._year, self._month, self._day)\n\n    __str__ = isoformat\n\n    # Read-only field accessors\n    @property\n    def year(self):\n        \"\"\"year (1-9999)\"\"\"\n        return self._year\n\n    @property\n    def month(self):\n        \"\"\"month (1-12)\"\"\"\n        return self._month\n\n    @property\n    def day(self):\n        \"\"\"day (1-31)\"\"\"\n        return self._day\n\n    # Standard conversions, __cmp__, __hash__ (and helpers)\n\n    def timetuple(self):\n        \"Return local time tuple compatible with time.localtime().\"\n        return _build_struct_time(self._year, self._month, self._day,\n                                  0, 0, 0, -1)\n\n    def toordinal(self):\n        \"\"\"Return proleptic Gregorian ordinal for the year, month and day.\n\n        January 1 of year 1 is day 1.  Only the year, month and day values\n        contribute to the result.\n        \"\"\"\n        return _ymd2ord(self._year, self._month, self._day)\n\n    def replace(self, year=None, month=None, day=None):\n        \"\"\"Return a new date with new values for the specified fields.\"\"\"\n        if year is None:\n            year = self._year\n        if month is None:\n            month = self._month\n        if day is None:\n            day = self._day\n        _check_date_fields(year, month, day)\n        return date(year, month, day)\n\n    # Comparisons of date objects with other.\n\n    def __eq__(self, other):\n        if isinstance(other, date):\n            return self._cmp(other) == 0\n        return NotImplemented\n\n    def __ne__(self, other):\n        if isinstance(other, date):\n            return self._cmp(other) != 0\n        return NotImplemented\n\n    def __le__(self, other):\n        if isinstance(other, date):\n            return self._cmp(other) <= 0\n        return NotImplemented\n\n    def __lt__(self, other):\n        if isinstance(other, date):\n            return self._cmp(other) < 0\n        return NotImplemented\n\n    def __ge__(self, other):\n        if isinstance(other, date):\n            return self._cmp(other) >= 0\n        return NotImplemented\n\n    def __gt__(self, other):\n        if isinstance(other, date):\n            return self._cmp(other) > 0\n        return NotImplemented\n\n    def _cmp(self, other):\n        assert isinstance(other, date)\n        y, m, d = self._year, self._month, self._day\n        y2, m2, d2 = other._year, other._month, other._day\n        return _cmp((y, m, d), (y2, m2, d2))\n\n    def __hash__(self):\n        \"Hash.\"\n        return hash(self._getstate())\n\n    # Computations\n\n    def __add__(self, other):\n        \"Add a date to a timedelta.\"\n        if isinstance(other, timedelta):\n            o = self.toordinal() + other.days\n            if 0 < o <= _MAXORDINAL:\n                return date.fromordinal(o)\n            raise OverflowError(\"result out of range\")\n        return NotImplemented\n\n    __radd__ = __add__\n\n    def __sub__(self, other):\n        \"\"\"Subtract two dates, or a date and a timedelta.\"\"\"\n        if isinstance(other, timedelta):\n            return self + timedelta(-other.days)\n        if isinstance(other, date):\n            days1 = self.toordinal()\n            days2 = other.toordinal()\n            return timedelta(days1 - days2)\n        return NotImplemented\n\n    def weekday(self):\n        \"Return day of the week, where Monday == 0 ... Sunday == 6.\"\n        return (self.toordinal() + 6) % 7\n\n    # Day-of-the-week and week-of-the-year, according to ISO\n\n    def isoweekday(self):\n        \"Return day of the week, where Monday == 1 ... Sunday == 7.\"\n        # 1-Jan-0001 is a Monday\n        return self.toordinal() % 7 or 7\n\n    def isocalendar(self):\n        \"\"\"Return a 3-tuple containing ISO year, week number, and weekday.\n\n        The first ISO week of the year is the (Mon-Sun) week\n        containing the year's first Thursday; everything else derives\n        from that.\n\n        The first week is 1; Monday is 1 ... Sunday is 7.\n\n        ISO calendar algorithm taken from\n        http://www.phys.uu.nl/~vgent/calendar/isocalendar.htm\n        \"\"\"\n        year = self._year\n        week1monday = _isoweek1monday(year)\n        today = _ymd2ord(self._year, self._month, self._day)\n        # Internally, week and day have origin 0\n        week, day = divmod(today - week1monday, 7)\n        if week < 0:\n            year -= 1\n            week1monday = _isoweek1monday(year)\n            week, day = divmod(today - week1monday, 7)\n        elif week >= 52:\n            if today >= _isoweek1monday(year+1):\n                year += 1\n                week = 0\n        return year, week+1, day+1\n\n    # Pickle support.\n\n    def _getstate(self):\n        yhi, ylo = divmod(self._year, 256)\n        return bytes([yhi, ylo, self._month, self._day]),\n\n    def __setstate(self, string):\n        if len(string) != 4 or not (1 <= string[2] <= 12):\n            raise TypeError(\"not enough arguments\")\n        yhi, ylo, self._month, self._day = string\n        self._year = yhi * 256 + ylo\n\n    def __reduce__(self):\n        return (self.__class__, self._getstate())\n\n_date_class = date  # so functions w/ args named \"date\" can get at the class\n\ndate.min = date(1, 1, 1)\ndate.max = date(9999, 12, 31)\ndate.resolution = timedelta(days=1)\n\nclass tzinfo:\n    \"\"\"Abstract base class for time zone info classes.\n\n    Subclasses must override the name(), utcoffset() and dst() methods.\n    \"\"\"\n    __slots__ = ()\n    def tzname(self, dt):\n        \"datetime -> string name of time zone.\"\n        raise NotImplementedError(\"tzinfo subclass must override tzname()\")\n\n    def utcoffset(self, dt):\n        \"datetime -> minutes east of UTC (negative for west of UTC)\"\n        raise NotImplementedError(\"tzinfo subclass must override utcoffset()\")\n\n    def dst(self, dt):\n        \"\"\"datetime -> DST offset in minutes east of UTC.\n\n        Return 0 if DST not in effect.  utcoffset() must include the DST\n        offset.\n        \"\"\"\n        raise NotImplementedError(\"tzinfo subclass must override dst()\")\n\n    def fromutc(self, dt):\n        \"datetime in UTC -> datetime in local time.\"\n\n        if not isinstance(dt, datetime):\n            raise TypeError(\"fromutc() requires a datetime argument\")\n        if dt.tzinfo is not self:\n            raise ValueError(\"dt.tzinfo is not self\")\n\n        dtoff = dt.utcoffset()\n        if dtoff is None:\n            raise ValueError(\"fromutc() requires a non-None utcoffset() \"\n                             \"result\")\n\n        # See the long comment block at the end of this file for an\n        # explanation of this algorithm.\n        dtdst = dt.dst()\n        if dtdst is None:\n            raise ValueError(\"fromutc() requires a non-None dst() result\")\n        delta = dtoff - dtdst\n        if delta:\n            dt += delta\n            dtdst = dt.dst()\n            if dtdst is None:\n                raise ValueError(\"fromutc(): dt.dst gave inconsistent \"\n                                 \"results; cannot convert\")\n        return dt + dtdst\n\n    # Pickle support.\n\n    def __reduce__(self):\n        getinitargs = getattr(self, \"__getinitargs__\", None)\n        if getinitargs:\n            args = getinitargs()\n        else:\n            args = ()\n        getstate = getattr(self, \"__getstate__\", None)\n        if getstate:\n            state = getstate()\n        else:\n            state = getattr(self, \"__dict__\", None) or None\n        if state is None:\n            return (self.__class__, args)\n        else:\n            return (self.__class__, args, state)\n\n_tzinfo_class = tzinfo\n\nclass time:\n    \"\"\"Time with time zone.\n\n    Constructors:\n\n    __new__()\n\n    Operators:\n\n    __repr__, __str__\n    __cmp__, __hash__\n\n    Methods:\n\n    strftime()\n    isoformat()\n    utcoffset()\n    tzname()\n    dst()\n\n    Properties (readonly):\n    hour, minute, second, microsecond, tzinfo\n    \"\"\"\n\n    def __new__(cls, hour=0, minute=0, second=0, microsecond=0, tzinfo=None):\n        \"\"\"Constructor.\n\n        Arguments:\n\n        hour, minute (required)\n        second, microsecond (default to zero)\n        tzinfo (default to None)\n        \"\"\"\n        self = object.__new__(cls)\n        if isinstance(hour, bytes) and len(hour) == 6:\n            # Pickle support\n            self.__setstate(hour, minute or None)\n            return self\n        _check_tzinfo_arg(tzinfo)\n        _check_time_fields(hour, minute, second, microsecond)\n        self._hour = hour\n        self._minute = minute\n        self._second = second\n        self._microsecond = microsecond\n        self._tzinfo = tzinfo\n        return self\n\n    # Read-only field accessors\n    @property\n    def hour(self):\n        \"\"\"hour (0-23)\"\"\"\n        return self._hour\n\n    @property\n    def minute(self):\n        \"\"\"minute (0-59)\"\"\"\n        return self._minute\n\n    @property\n    def second(self):\n        \"\"\"second (0-59)\"\"\"\n        return self._second\n\n    @property\n    def microsecond(self):\n        \"\"\"microsecond (0-999999)\"\"\"\n        return self._microsecond\n\n    @property\n    def tzinfo(self):\n        \"\"\"timezone info object\"\"\"\n        return self._tzinfo\n\n    # Standard conversions, __hash__ (and helpers)\n\n    # Comparisons of time objects with other.\n\n    def __eq__(self, other):\n        if isinstance(other, time):\n            return self._cmp(other, allow_mixed=True) == 0\n        else:\n            return False\n\n    def __ne__(self, other):\n        if isinstance(other, time):\n            return self._cmp(other, allow_mixed=True) != 0\n        else:\n            return True\n\n    def __le__(self, other):\n        if isinstance(other, time):\n            return self._cmp(other) <= 0\n        else:\n            _cmperror(self, other)\n\n    def __lt__(self, other):\n        if isinstance(other, time):\n            return self._cmp(other) < 0\n        else:\n            _cmperror(self, other)\n\n    def __ge__(self, other):\n        if isinstance(other, time):\n            return self._cmp(other) >= 0\n        else:\n            _cmperror(self, other)\n\n    def __gt__(self, other):\n        if isinstance(other, time):\n            return self._cmp(other) > 0\n        else:\n            _cmperror(self, other)\n\n    def _cmp(self, other, allow_mixed=False):\n        assert isinstance(other, time)\n        mytz = self._tzinfo\n        ottz = other._tzinfo\n        myoff = otoff = None\n\n        if mytz is ottz:\n            base_compare = True\n        else:\n            myoff = self.utcoffset()\n            otoff = other.utcoffset()\n            base_compare = myoff == otoff\n\n        if base_compare:\n            return _cmp((self._hour, self._minute, self._second,\n                         self._microsecond),\n                       (other._hour, other._minute, other._second,\n                        other._microsecond))\n        if myoff is None or otoff is None:\n            if allow_mixed:\n                return 2 # arbitrary non-zero value\n            else:\n                raise TypeError(\"cannot compare naive and aware times\")\n        myhhmm = self._hour * 60 + self._minute - myoff//timedelta(minutes=1)\n        othhmm = other._hour * 60 + other._minute - otoff//timedelta(minutes=1)\n        return _cmp((myhhmm, self._second, self._microsecond),\n                    (othhmm, other._second, other._microsecond))\n\n    def __hash__(self):\n        \"\"\"Hash.\"\"\"\n        tzoff = self.utcoffset()\n        if not tzoff: # zero or None\n            return hash(self._getstate()[0])\n        h, m = divmod(timedelta(hours=self.hour, minutes=self.minute) - tzoff,\n                      timedelta(hours=1))\n        assert not m % timedelta(minutes=1), \"whole minute\"\n        m //= timedelta(minutes=1)\n        if 0 <= h < 24:\n            return hash(time(h, m, self.second, self.microsecond))\n        return hash((h, m, self.second, self.microsecond))\n\n    # Conversion to string\n\n    def _tzstr(self, sep=\":\"):\n        \"\"\"Return formatted timezone offset (+xx:xx) or None.\"\"\"\n        off = self.utcoffset()\n        if off is not None:\n            if off.days < 0:\n                sign = \"-\"\n                off = -off\n            else:\n                sign = \"+\"\n            hh, mm = divmod(off, timedelta(hours=1))\n            assert not mm % timedelta(minutes=1), \"whole minute\"\n            mm //= timedelta(minutes=1)\n            assert 0 <= hh < 24\n            off = \"%s%02d%s%02d\" % (sign, hh, sep, mm)\n        return off\n\n    def __repr__(self):\n        \"\"\"Convert to formal string, for repr().\"\"\"\n        if self._microsecond != 0:\n            s = \", %d, %d\" % (self._second, self._microsecond)\n        elif self._second != 0:\n            s = \", %d\" % self._second\n        else:\n            s = \"\"\n        s= \"%s(%d, %d%s)\" % ('datetime.' + self.__class__.__name__,\n                             self._hour, self._minute, s)\n        if self._tzinfo is not None:\n            assert s[-1:] == \")\"\n            s = s[:-1] + \", tzinfo=%r\" % self._tzinfo + \")\"\n        return s\n\n    def isoformat(self):\n        \"\"\"Return the time formatted according to ISO.\n\n        This is 'HH:MM:SS.mmmmmm+zz:zz', or 'HH:MM:SS+zz:zz' if\n        self.microsecond == 0.\n        \"\"\"\n        s = _format_time(self._hour, self._minute, self._second,\n                         self._microsecond)\n        tz = self._tzstr()\n        if tz:\n            s += tz\n        return s\n\n    __str__ = isoformat\n\n    def strftime(self, fmt):\n        \"\"\"Format using strftime().  The date part of the timestamp passed\n        to underlying strftime should not be used.\n        \"\"\"\n        # The year must be >= 1000 else Python's strftime implementation\n        # can raise a bogus exception.\n        timetuple = (1900, 1, 1,\n                     self._hour, self._minute, self._second,\n                     0, 1, -1)\n        return _wrap_strftime(self, fmt, timetuple)\n\n    def __format__(self, fmt):\n        if len(fmt) != 0:\n            return self.strftime(fmt)\n        return str(self)\n\n    # Timezone functions\n\n    def utcoffset(self):\n        \"\"\"Return the timezone offset in minutes east of UTC (negative west of\n        UTC).\"\"\"\n        if self._tzinfo is None:\n            return None\n        offset = self._tzinfo.utcoffset(None)\n        _check_utc_offset(\"utcoffset\", offset)\n        return offset\n\n    def tzname(self):\n        \"\"\"Return the timezone name.\n\n        Note that the name is 100% informational -- there's no requirement that\n        it mean anything in particular. For example, \"GMT\", \"UTC\", \"-500\",\n        \"-5:00\", \"EDT\", \"US/Eastern\", \"America/New York\" are all valid replies.\n        \"\"\"\n        if self._tzinfo is None:\n            return None\n        name = self._tzinfo.tzname(None)\n        _check_tzname(name)\n        return name\n\n    def dst(self):\n        \"\"\"Return 0 if DST is not in effect, or the DST offset (in minutes\n        eastward) if DST is in effect.\n\n        This is purely informational; the DST offset has already been added to\n        the UTC offset returned by utcoffset() if applicable, so there's no\n        need to consult dst() unless you're interested in displaying the DST\n        info.\n        \"\"\"\n        if self._tzinfo is None:\n            return None\n        offset = self._tzinfo.dst(None)\n        _check_utc_offset(\"dst\", offset)\n        return offset\n\n    def replace(self, hour=None, minute=None, second=None, microsecond=None,\n                tzinfo=True):\n        \"\"\"Return a new time with new values for the specified fields.\"\"\"\n        if hour is None:\n            hour = self.hour\n        if minute is None:\n            minute = self.minute\n        if second is None:\n            second = self.second\n        if microsecond is None:\n            microsecond = self.microsecond\n        if tzinfo is True:\n            tzinfo = self.tzinfo\n        _check_time_fields(hour, minute, second, microsecond)\n        _check_tzinfo_arg(tzinfo)\n        return time(hour, minute, second, microsecond, tzinfo)\n\n    def __bool__(self):\n        if self.second or self.microsecond:\n            return True\n        offset = self.utcoffset() or timedelta(0)\n        return timedelta(hours=self.hour, minutes=self.minute) != offset\n\n    # Pickle support.\n\n    def _getstate(self):\n        us2, us3 = divmod(self._microsecond, 256)\n        us1, us2 = divmod(us2, 256)\n        basestate = bytes([self._hour, self._minute, self._second,\n                           us1, us2, us3])\n        if self._tzinfo is None:\n            return (basestate,)\n        else:\n            return (basestate, self._tzinfo)\n\n    def __setstate(self, string, tzinfo):\n        if len(string) != 6 or string[0] >= 24:\n            raise TypeError(\"an integer is required\")\n        (self._hour, self._minute, self._second,\n         us1, us2, us3) = string\n        self._microsecond = (((us1 << 8) | us2) << 8) | us3\n        if tzinfo is None or isinstance(tzinfo, _tzinfo_class):\n            self._tzinfo = tzinfo\n        else:\n            raise TypeError(\"bad tzinfo state arg %r\" % tzinfo)\n\n    def __reduce__(self):\n        return (time, self._getstate())\n\n_time_class = time  # so functions w/ args named \"time\" can get at the class\n\ntime.min = time(0, 0, 0)\ntime.max = time(23, 59, 59, 999999)\ntime.resolution = timedelta(microseconds=1)\n\nclass datetime(date):\n    \"\"\"datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])\n\n    The year, month and day arguments are required. tzinfo may be None, or an\n    instance of a tzinfo subclass. The remaining arguments may be ints.\n    \"\"\"\n\n    __slots__ = date.__slots__ + (\n        '_hour', '_minute', '_second',\n        '_microsecond', '_tzinfo')\n    def __new__(cls, year, month=None, day=None, hour=0, minute=0, second=0,\n                microsecond=0, tzinfo=None):\n        if isinstance(year, bytes) and len(year) == 10:\n            # Pickle support\n            self = date.__new__(cls, year[:4])\n            self.__setstate(year, month)\n            return self\n        _check_tzinfo_arg(tzinfo)\n        _check_time_fields(hour, minute, second, microsecond)\n        self = date.__new__(cls, year, month, day)\n        self._hour = hour\n        self._minute = minute\n        self._second = second\n        self._microsecond = microsecond\n        self._tzinfo = tzinfo\n        return self\n\n    # Read-only field accessors\n    @property\n    def hour(self):\n        \"\"\"hour (0-23)\"\"\"\n        return self._hour\n\n    @property\n    def minute(self):\n        \"\"\"minute (0-59)\"\"\"\n        return self._minute\n\n    @property\n    def second(self):\n        \"\"\"second (0-59)\"\"\"\n        return self._second\n\n    @property\n    def microsecond(self):\n        \"\"\"microsecond (0-999999)\"\"\"\n        return self._microsecond\n\n    @property\n    def tzinfo(self):\n        \"\"\"timezone info object\"\"\"\n        return self._tzinfo\n\n    @classmethod\n    def fromtimestamp(cls, t, tz=None):\n        \"\"\"Construct a datetime from a POSIX timestamp (like time.time()).\n\n        A timezone info object may be passed in as well.\n        \"\"\"\n\n        _check_tzinfo_arg(tz)\n\n        converter = _time.localtime if tz is None else _time.gmtime\n\n        t, frac = divmod(t, 1.0)\n        us = int(frac * 1e6)\n\n        # If timestamp is less than one microsecond smaller than a\n        # full second, us can be rounded up to 1000000.  In this case,\n        # roll over to seconds, otherwise, ValueError is raised\n        # by the constructor.\n        if us == 1000000:\n            t += 1\n            us = 0\n        y, m, d, hh, mm, ss, weekday, jday, dst = converter(t)\n        ss = min(ss, 59)    # clamp out leap seconds if the platform has them\n        result = cls(y, m, d, hh, mm, ss, us, tz)\n        if tz is not None:\n            result = tz.fromutc(result)\n        return result\n\n    @classmethod\n    def utcfromtimestamp(cls, t):\n        \"Construct a UTC datetime from a POSIX timestamp (like time.time()).\"\n        t, frac = divmod(t, 1.0)\n        us = int(frac * 1e6)\n\n        # If timestamp is less than one microsecond smaller than a\n        # full second, us can be rounded up to 1000000.  In this case,\n        # roll over to seconds, otherwise, ValueError is raised\n        # by the constructor.\n        if us == 1000000:\n            t += 1\n            us = 0\n        y, m, d, hh, mm, ss, weekday, jday, dst = _time.gmtime(t)\n        ss = min(ss, 59)    # clamp out leap seconds if the platform has them\n        return cls(y, m, d, hh, mm, ss, us)\n\n    # XXX This is supposed to do better than we *can* do by using time.time(),\n    # XXX if the platform supports a more accurate way.  The C implementation\n    # XXX uses gettimeofday on platforms that have it, but that isn't\n    # XXX available from Python.  So now() may return different results\n    # XXX across the implementations.\n    @classmethod\n    def now(cls, tz=None):\n        \"Construct a datetime from time.time() and optional time zone info.\"\n        t = _time.time()\n        return cls.fromtimestamp(t, tz)\n\n    @classmethod\n    def utcnow(cls):\n        \"Construct a UTC datetime from time.time().\"\n        t = _time.time()\n        return cls.utcfromtimestamp(t)\n\n    @classmethod\n    def combine(cls, date, time):\n        \"Construct a datetime from a given date and a given time.\"\n        if not isinstance(date, _date_class):\n            raise TypeError(\"date argument must be a date instance\")\n        if not isinstance(time, _time_class):\n            raise TypeError(\"time argument must be a time instance\")\n        return cls(date.year, date.month, date.day,\n                   time.hour, time.minute, time.second, time.microsecond,\n                   time.tzinfo)\n\n    def timetuple(self):\n        \"Return local time tuple compatible with time.localtime().\"\n        dst = self.dst()\n        if dst is None:\n            dst = -1\n        elif dst:\n            dst = 1\n        else:\n            dst = 0\n        return _build_struct_time(self.year, self.month, self.day,\n                                  self.hour, self.minute, self.second,\n                                  dst)\n\n    def timestamp(self):\n        \"Return POSIX timestamp as float\"\n        if self._tzinfo is None:\n            return _time.mktime((self.year, self.month, self.day,\n                                 self.hour, self.minute, self.second,\n                                 -1, -1, -1)) + self.microsecond / 1e6\n        else:\n            return (self - _EPOCH).total_seconds()\n\n    def utctimetuple(self):\n        \"Return UTC time tuple compatible with time.gmtime().\"\n        offset = self.utcoffset()\n        if offset:\n            self -= offset\n        y, m, d = self.year, self.month, self.day\n        hh, mm, ss = self.hour, self.minute, self.second\n        return _build_struct_time(y, m, d, hh, mm, ss, 0)\n\n    def date(self):\n        \"Return the date part.\"\n        return date(self._year, self._month, self._day)\n\n    def time(self):\n        \"Return the time part, with tzinfo None.\"\n        return time(self.hour, self.minute, self.second, self.microsecond)\n\n    def timetz(self):\n        \"Return the time part, with same tzinfo.\"\n        return time(self.hour, self.minute, self.second, self.microsecond,\n                    self._tzinfo)\n\n    def replace(self, year=None, month=None, day=None, hour=None,\n                minute=None, second=None, microsecond=None, tzinfo=True):\n        \"\"\"Return a new datetime with new values for the specified fields.\"\"\"\n        if year is None:\n            year = self.year\n        if month is None:\n            month = self.month\n        if day is None:\n            day = self.day\n        if hour is None:\n            hour = self.hour\n        if minute is None:\n            minute = self.minute\n        if second is None:\n            second = self.second\n        if microsecond is None:\n            microsecond = self.microsecond\n        if tzinfo is True:\n            tzinfo = self.tzinfo\n        _check_date_fields(year, month, day)\n        _check_time_fields(hour, minute, second, microsecond)\n        _check_tzinfo_arg(tzinfo)\n        return datetime(year, month, day, hour, minute, second,\n                          microsecond, tzinfo)\n\n    def astimezone(self, tz=None):\n        if tz is None:\n            if self.tzinfo is None:\n                raise ValueError(\"astimezone() requires an aware datetime\")\n            ts = (self - _EPOCH) // timedelta(seconds=1)\n            localtm = _time.localtime(ts)\n            local = datetime(*localtm[:6])\n            try:\n                # Extract TZ data if available\n                gmtoff = localtm.tm_gmtoff\n                zone = localtm.tm_zone\n            except AttributeError:\n                # Compute UTC offset and compare with the value implied\n                # by tm_isdst.  If the values match, use the zone name\n                # implied by tm_isdst.\n                delta = local - datetime(*_time.gmtime(ts)[:6])\n                dst = _time.daylight and localtm.tm_isdst > 0\n                gmtoff = -(_time.altzone if dst else _time.timezone)\n                if delta == timedelta(seconds=gmtoff):\n                    tz = timezone(delta, _time.tzname[dst])\n                else:\n                    tz = timezone(delta)\n            else:\n                tz = timezone(timedelta(seconds=gmtoff), zone)\n\n        elif not isinstance(tz, tzinfo):\n            raise TypeError(\"tz argument must be an instance of tzinfo\")\n\n        mytz = self.tzinfo\n        if mytz is None:\n            raise ValueError(\"astimezone() requires an aware datetime\")\n\n        if tz is mytz:\n            return self\n\n        # Convert self to UTC, and attach the new time zone object.\n        myoffset = self.utcoffset()\n        if myoffset is None:\n            raise ValueError(\"astimezone() requires an aware datetime\")\n        utc = (self - myoffset).replace(tzinfo=tz)\n\n        # Convert from UTC to tz's local time.\n        return tz.fromutc(utc)\n\n    # Ways to produce a string.\n\n    def ctime(self):\n        \"Return ctime() style string.\"\n        weekday = self.toordinal() % 7 or 7\n        return \"%s %s %2d %02d:%02d:%02d %04d\" % (\n            _DAYNAMES[weekday],\n            _MONTHNAMES[self._month],\n            self._day,\n            self._hour, self._minute, self._second,\n            self._year)\n\n    def isoformat(self, sep='T'):\n        \"\"\"Return the time formatted according to ISO.\n\n        This is 'YYYY-MM-DD HH:MM:SS.mmmmmm', or 'YYYY-MM-DD HH:MM:SS' if\n        self.microsecond == 0.\n\n        If self.tzinfo is not None, the UTC offset is also attached, giving\n        'YYYY-MM-DD HH:MM:SS.mmmmmm+HH:MM' or 'YYYY-MM-DD HH:MM:SS+HH:MM'.\n\n        Optional argument sep specifies the separator between date and\n        time, default 'T'.\n        \"\"\"\n        s = (\"%04d-%02d-%02d%c\" % (self._year, self._month, self._day,\n                                  sep) +\n                _format_time(self._hour, self._minute, self._second,\n                             self._microsecond))\n        off = self.utcoffset()\n        if off is not None:\n            if off.days < 0:\n                sign = \"-\"\n                off = -off\n            else:\n                sign = \"+\"\n            hh, mm = divmod(off, timedelta(hours=1))\n            assert not mm % timedelta(minutes=1), \"whole minute\"\n            mm //= timedelta(minutes=1)\n            s += \"%s%02d:%02d\" % (sign, hh, mm)\n        return s\n\n    def __repr__(self):\n        \"\"\"Convert to formal string, for repr().\"\"\"\n        L = [self._year, self._month, self._day, # These are never zero\n             self._hour, self._minute, self._second, self._microsecond]\n        if L[-1] == 0:\n            del L[-1]\n        if L[-1] == 0:\n            del L[-1]\n        s = \", \".join(map(str, L))\n        s = \"%s(%s)\" % ('datetime.' + self.__class__.__name__, s)\n        if self._tzinfo is not None:\n            assert s[-1:] == \")\"\n            s = s[:-1] + \", tzinfo=%r\" % self._tzinfo + \")\"\n        return s\n\n    def __str__(self):\n        \"Convert to string, for str().\"\n        return self.isoformat(sep=' ')\n\n    @classmethod\n    def strptime(cls, date_string, format):\n        'string, format -> new datetime parsed from a string (like time.strptime()).'\n        import _strptime\n        return _strptime._strptime_datetime(cls, date_string, format)\n\n    def utcoffset(self):\n        \"\"\"Return the timezone offset in minutes east of UTC (negative west of\n        UTC).\"\"\"\n        if self._tzinfo is None:\n            return None\n        offset = self._tzinfo.utcoffset(self)\n        _check_utc_offset(\"utcoffset\", offset)\n        return offset\n\n    def tzname(self):\n        \"\"\"Return the timezone name.\n\n        Note that the name is 100% informational -- there's no requirement that\n        it mean anything in particular. For example, \"GMT\", \"UTC\", \"-500\",\n        \"-5:00\", \"EDT\", \"US/Eastern\", \"America/New York\" are all valid replies.\n        \"\"\"\n        name = _call_tzinfo_method(self._tzinfo, \"tzname\", self)\n        _check_tzname(name)\n        return name\n\n    def dst(self):\n        \"\"\"Return 0 if DST is not in effect, or the DST offset (in minutes\n        eastward) if DST is in effect.\n\n        This is purely informational; the DST offset has already been added to\n        the UTC offset returned by utcoffset() if applicable, so there's no\n        need to consult dst() unless you're interested in displaying the DST\n        info.\n        \"\"\"\n        if self._tzinfo is None:\n            return None\n        offset = self._tzinfo.dst(self)\n        _check_utc_offset(\"dst\", offset)\n        return offset\n\n    # Comparisons of datetime objects with other.\n\n    def __eq__(self, other):\n        if isinstance(other, datetime):\n            return self._cmp(other, allow_mixed=True) == 0\n        elif not isinstance(other, date):\n            return NotImplemented\n        else:\n            return False\n\n    def __ne__(self, other):\n        if isinstance(other, datetime):\n            return self._cmp(other, allow_mixed=True) != 0\n        elif not isinstance(other, date):\n            return NotImplemented\n        else:\n            return True\n\n    def __le__(self, other):\n        if isinstance(other, datetime):\n            return self._cmp(other) <= 0\n        elif not isinstance(other, date):\n            return NotImplemented\n        else:\n            _cmperror(self, other)\n\n    def __lt__(self, other):\n        if isinstance(other, datetime):\n            return self._cmp(other) < 0\n        elif not isinstance(other, date):\n            return NotImplemented\n        else:\n            _cmperror(self, other)\n\n    def __ge__(self, other):\n        if isinstance(other, datetime):\n            return self._cmp(other) >= 0\n        elif not isinstance(other, date):\n            return NotImplemented\n        else:\n            _cmperror(self, other)\n\n    def __gt__(self, other):\n        if isinstance(other, datetime):\n            return self._cmp(other) > 0\n        elif not isinstance(other, date):\n            return NotImplemented\n        else:\n            _cmperror(self, other)\n\n    def _cmp(self, other, allow_mixed=False):\n        assert isinstance(other, datetime)\n        mytz = self._tzinfo\n        ottz = other._tzinfo\n        myoff = otoff = None\n\n        if mytz is ottz:\n            base_compare = True\n        else:\n            myoff = self.utcoffset()\n            otoff = other.utcoffset()\n            base_compare = myoff == otoff\n\n        if base_compare:\n            return _cmp((self._year, self._month, self._day,\n                         self._hour, self._minute, self._second,\n                         self._microsecond),\n                       (other._year, other._month, other._day,\n                        other._hour, other._minute, other._second,\n                        other._microsecond))\n        if myoff is None or otoff is None:\n            if allow_mixed:\n                return 2 # arbitrary non-zero value\n            else:\n                raise TypeError(\"cannot compare naive and aware datetimes\")\n        # XXX What follows could be done more efficiently...\n        diff = self - other     # this will take offsets into account\n        if diff.days < 0:\n            return -1\n        return diff and 1 or 0\n\n    def __add__(self, other):\n        \"Add a datetime and a timedelta.\"\n        if not isinstance(other, timedelta):\n            return NotImplemented\n        delta = timedelta(self.toordinal(),\n                          hours=self._hour,\n                          minutes=self._minute,\n                          seconds=self._second,\n                          microseconds=self._microsecond)\n        delta += other\n        hour, rem = divmod(delta.seconds, 3600)\n        minute, second = divmod(rem, 60)\n        if 0 < delta.days <= _MAXORDINAL:\n            return datetime.combine(date.fromordinal(delta.days),\n                                    time(hour, minute, second,\n                                         delta.microseconds,\n                                         tzinfo=self._tzinfo))\n        raise OverflowError(\"result out of range\")\n\n    __radd__ = __add__\n\n    def __sub__(self, other):\n        \"Subtract two datetimes, or a datetime and a timedelta.\"\n        if not isinstance(other, datetime):\n            if isinstance(other, timedelta):\n                return self + -other\n            return NotImplemented\n\n        days1 = self.toordinal()\n        days2 = other.toordinal()\n        secs1 = self._second + self._minute * 60 + self._hour * 3600\n        secs2 = other._second + other._minute * 60 + other._hour * 3600\n        base = timedelta(days1 - days2,\n                         secs1 - secs2,\n                         self._microsecond - other._microsecond)\n        if self._tzinfo is other._tzinfo:\n            return base\n        myoff = self.utcoffset()\n        otoff = other.utcoffset()\n        if myoff == otoff:\n            return base\n        if myoff is None or otoff is None:\n            raise TypeError(\"cannot mix naive and timezone-aware time\")\n        return base + otoff - myoff\n\n    def __hash__(self):\n        tzoff = self.utcoffset()\n        if tzoff is None:\n            return hash(self._getstate()[0])\n        days = _ymd2ord(self.year, self.month, self.day)\n        seconds = self.hour * 3600 + self.minute * 60 + self.second\n        return hash(timedelta(days, seconds, self.microsecond) - tzoff)\n\n    # Pickle support.\n\n    def _getstate(self):\n        yhi, ylo = divmod(self._year, 256)\n        us2, us3 = divmod(self._microsecond, 256)\n        us1, us2 = divmod(us2, 256)\n        basestate = bytes([yhi, ylo, self._month, self._day,\n                           self._hour, self._minute, self._second,\n                           us1, us2, us3])\n        if self._tzinfo is None:\n            return (basestate,)\n        else:\n            return (basestate, self._tzinfo)\n\n    def __setstate(self, string, tzinfo):\n        (yhi, ylo, self._month, self._day, self._hour,\n         self._minute, self._second, us1, us2, us3) = string\n        self._year = yhi * 256 + ylo\n        self._microsecond = (((us1 << 8) | us2) << 8) | us3\n        if tzinfo is None or isinstance(tzinfo, _tzinfo_class):\n            self._tzinfo = tzinfo\n        else:\n            raise TypeError(\"bad tzinfo state arg %r\" % tzinfo)\n\n    def __reduce__(self):\n        return (self.__class__, self._getstate())\n\n\ndatetime.min = datetime(1, 1, 1)\ndatetime.max = datetime(9999, 12, 31, 23, 59, 59, 999999)\ndatetime.resolution = timedelta(microseconds=1)\n\n\ndef _isoweek1monday(year):\n    # Helper to calculate the day number of the Monday starting week 1\n    # XXX This could be done more efficiently\n    THURSDAY = 3\n    firstday = _ymd2ord(year, 1, 1)\n    firstweekday = (firstday + 6) % 7 # See weekday() above\n    week1monday = firstday - firstweekday\n    if firstweekday > THURSDAY:\n        week1monday += 7\n    return week1monday\n\nclass timezone(tzinfo):\n    __slots__ = '_offset', '_name'\n\n    # Sentinel value to disallow None\n    _Omitted = object()\n    def __new__(cls, offset, name=_Omitted):\n        if not isinstance(offset, timedelta):\n            raise TypeError(\"offset must be a timedelta\")\n        if name is cls._Omitted:\n            if not offset:\n                return cls.utc\n            name = None\n        elif not isinstance(name, str):\n            raise TypeError(\"name must be a string\")\n        if not cls._minoffset <= offset <= cls._maxoffset:\n            raise ValueError(\"offset must be a timedelta\"\n                             \" strictly between -timedelta(hours=24) and\"\n                             \" timedelta(hours=24).\")\n        if (offset.microseconds != 0 or\n            offset.seconds % 60 != 0):\n            raise ValueError(\"offset must be a timedelta\"\n                             \" representing a whole number of minutes\")\n        return cls._create(offset, name)\n\n    @classmethod\n    def _create(cls, offset, name=None):\n        self = tzinfo.__new__(cls)\n        self._offset = offset\n        self._name = name\n        return self\n\n    def __getinitargs__(self):\n        \"\"\"pickle support\"\"\"\n        if self._name is None:\n            return (self._offset,)\n        return (self._offset, self._name)\n\n    def __eq__(self, other):\n        if type(other) != timezone:\n            return False\n        return self._offset == other._offset\n\n    def __hash__(self):\n        return hash(self._offset)\n\n    def __repr__(self):\n        \"\"\"Convert to formal string, for repr().\n\n        >>> tz = timezone.utc\n        >>> repr(tz)\n        'datetime.timezone.utc'\n        >>> tz = timezone(timedelta(hours=-5), 'EST')\n        >>> repr(tz)\n        \"datetime.timezone(datetime.timedelta(-1, 68400), 'EST')\"\n        \"\"\"\n        if self is self.utc:\n            return 'datetime.timezone.utc'\n        if self._name is None:\n            return \"%s(%r)\" % ('datetime.' + self.__class__.__name__,\n                               self._offset)\n        return \"%s(%r, %r)\" % ('datetime.' + self.__class__.__name__,\n                               self._offset, self._name)\n\n    def __str__(self):\n        return self.tzname(None)\n\n    def utcoffset(self, dt):\n        if isinstance(dt, datetime) or dt is None:\n            return self._offset\n        raise TypeError(\"utcoffset() argument must be a datetime instance\"\n                        \" or None\")\n\n    def tzname(self, dt):\n        if isinstance(dt, datetime) or dt is None:\n            if self._name is None:\n                return self._name_from_offset(self._offset)\n            return self._name\n        raise TypeError(\"tzname() argument must be a datetime instance\"\n                        \" or None\")\n\n    def dst(self, dt):\n        if isinstance(dt, datetime) or dt is None:\n            return None\n        raise TypeError(\"dst() argument must be a datetime instance\"\n                        \" or None\")\n\n    def fromutc(self, dt):\n        if isinstance(dt, datetime):\n            if dt.tzinfo is not self:\n                raise ValueError(\"fromutc: dt.tzinfo \"\n                                 \"is not self\")\n            return dt + self._offset\n        raise TypeError(\"fromutc() argument must be a datetime instance\"\n                        \" or None\")\n\n    _maxoffset = timedelta(hours=23, minutes=59)\n    _minoffset = -_maxoffset\n\n    @staticmethod\n    def _name_from_offset(delta):\n        if delta < timedelta(0):\n            sign = '-'\n            delta = -delta\n        else:\n            sign = '+'\n        hours, rest = divmod(delta, timedelta(hours=1))\n        minutes = rest // timedelta(minutes=1)\n        return 'UTC{}{:02d}:{:02d}'.format(sign, hours, minutes)\n\ntimezone.utc = timezone._create(timedelta(0))\ntimezone.min = timezone._create(timezone._minoffset)\ntimezone.max = timezone._create(timezone._maxoffset)\n_EPOCH = datetime(1970, 1, 1, tzinfo=timezone.utc)\n\"\"\"\nSome time zone algebra.  For a datetime x, let\n    x.n = x stripped of its timezone -- its naive time.\n    x.o = x.utcoffset(), and assuming that doesn't raise an exception or\n          return None\n    x.d = x.dst(), and assuming that doesn't raise an exception or\n          return None\n    x.s = x's standard offset, x.o - x.d\n\nNow some derived rules, where k is a duration (timedelta).\n\n1. x.o = x.s + x.d\n   This follows from the definition of x.s.\n\n2. If x and y have the same tzinfo member, x.s = y.s.\n   This is actually a requirement, an assumption we need to make about\n   sane tzinfo classes.\n\n3. The naive UTC time corresponding to x is x.n - x.o.\n   This is again a requirement for a sane tzinfo class.\n\n4. (x+k).s = x.s\n   This follows from #2, and that datimetimetz+timedelta preserves tzinfo.\n\n5. (x+k).n = x.n + k\n   Again follows from how arithmetic is defined.\n\nNow we can explain tz.fromutc(x).  Let's assume it's an interesting case\n(meaning that the various tzinfo methods exist, and don't blow up or return\nNone when called).\n\nThe function wants to return a datetime y with timezone tz, equivalent to x.\nx is already in UTC.\n\nBy #3, we want\n\n    y.n - y.o = x.n                             [1]\n\nThe algorithm starts by attaching tz to x.n, and calling that y.  So\nx.n = y.n at the start.  Then it wants to add a duration k to y, so that [1]\nbecomes true; in effect, we want to solve [2] for k:\n\n   (y+k).n - (y+k).o = x.n                      [2]\n\nBy #1, this is the same as\n\n   (y+k).n - ((y+k).s + (y+k).d) = x.n          [3]\n\nBy #5, (y+k).n = y.n + k, which equals x.n + k because x.n=y.n at the start.\nSubstituting that into [3],\n\n   x.n + k - (y+k).s - (y+k).d = x.n; the x.n terms cancel, leaving\n   k - (y+k).s - (y+k).d = 0; rearranging,\n   k = (y+k).s - (y+k).d; by #4, (y+k).s == y.s, so\n   k = y.s - (y+k).d\n\nOn the RHS, (y+k).d can't be computed directly, but y.s can be, and we\napproximate k by ignoring the (y+k).d term at first.  Note that k can't be\nvery large, since all offset-returning methods return a duration of magnitude\nless than 24 hours.  For that reason, if y is firmly in std time, (y+k).d must\nbe 0, so ignoring it has no consequence then.\n\nIn any case, the new value is\n\n    z = y + y.s                                 [4]\n\nIt's helpful to step back at look at [4] from a higher level:  it's simply\nmapping from UTC to tz's standard time.\n\nAt this point, if\n\n    z.n - z.o = x.n                             [5]\n\nwe have an equivalent time, and are almost done.  The insecurity here is\nat the start of daylight time.  Picture US Eastern for concreteness.  The wall\ntime jumps from 1:59 to 3:00, and wall hours of the form 2:MM don't make good\nsense then.  The docs ask that an Eastern tzinfo class consider such a time to\nbe EDT (because it's \"after 2\"), which is a redundant spelling of 1:MM EST\non the day DST starts.  We want to return the 1:MM EST spelling because that's\nthe only spelling that makes sense on the local wall clock.\n\nIn fact, if [5] holds at this point, we do have the standard-time spelling,\nbut that takes a bit of proof.  We first prove a stronger result.  What's the\ndifference between the LHS and RHS of [5]?  Let\n\n    diff = x.n - (z.n - z.o)                    [6]\n\nNow\n    z.n =                       by [4]\n    (y + y.s).n =               by #5\n    y.n + y.s =                 since y.n = x.n\n    x.n + y.s =                 since z and y are have the same tzinfo member,\n                                    y.s = z.s by #2\n    x.n + z.s\n\nPlugging that back into [6] gives\n\n    diff =\n    x.n - ((x.n + z.s) - z.o) =     expanding\n    x.n - x.n - z.s + z.o =         cancelling\n    - z.s + z.o =                   by #2\n    z.d\n\nSo diff = z.d.\n\nIf [5] is true now, diff = 0, so z.d = 0 too, and we have the standard-time\nspelling we wanted in the endcase described above.  We're done.  Contrarily,\nif z.d = 0, then we have a UTC equivalent, and are also done.\n\nIf [5] is not true now, diff = z.d != 0, and z.d is the offset we need to\nadd to z (in effect, z is in tz's standard time, and we need to shift the\nlocal clock into tz's daylight time).\n\nLet\n\n    z' = z + z.d = z + diff                     [7]\n\nand we can again ask whether\n\n    z'.n - z'.o = x.n                           [8]\n\nIf so, we're done.  If not, the tzinfo class is insane, according to the\nassumptions we've made.  This also requires a bit of proof.  As before, let's\ncompute the difference between the LHS and RHS of [8] (and skipping some of\nthe justifications for the kinds of substitutions we've done several times\nalready):\n\n    diff' = x.n - (z'.n - z'.o) =           replacing z'.n via [7]\n            x.n  - (z.n + diff - z'.o) =    replacing diff via [6]\n            x.n - (z.n + x.n - (z.n - z.o) - z'.o) =\n            x.n - z.n - x.n + z.n - z.o + z'.o =    cancel x.n\n            - z.n + z.n - z.o + z'.o =              cancel z.n\n            - z.o + z'.o =                      #1 twice\n            -z.s - z.d + z'.s + z'.d =          z and z' have same tzinfo\n            z'.d - z.d\n\nSo z' is UTC-equivalent to x iff z'.d = z.d at this point.  If they are equal,\nwe've found the UTC-equivalent so are done.  In fact, we stop with [7] and\nreturn z', not bothering to compute z'.d.\n\nHow could z.d and z'd differ?  z' = z + z.d [7], so merely moving z' by\na dst() offset, and starting *from* a time already in DST (we know z.d != 0),\nwould have to change the result dst() returns:  we start in DST, and moving\na little further into it takes us out of DST.\n\nThere isn't a sane case where this can happen.  The closest it gets is at\nthe end of DST, where there's an hour in UTC with no spelling in a hybrid\ntzinfo class.  In US Eastern, that's 5:MM UTC = 0:MM EST = 1:MM EDT.  During\nthat hour, on an Eastern clock 1:MM is taken as being in standard time (6:MM\nUTC) because the docs insist on that, but 0:MM is taken as being in daylight\ntime (4:MM UTC).  There is no local time mapping to 5:MM UTC.  The local\nclock jumps from 1:59 back to 1:00 again, and repeats the 1:MM hour in\nstandard time.  Since that's what the local clock *does*, we want to map both\nUTC hours 5:MM and 6:MM to 1:MM Eastern.  The result is ambiguous\nin local time, but so it goes -- it's the way the local clock works.\n\nWhen x = 5:MM UTC is the input to this algorithm, x.o=0, y.o=-5 and y.d=0,\nso z=0:MM.  z.d=60 (minutes) then, so [5] doesn't hold and we keep going.\nz' = z + z.d = 1:MM then, and z'.d=0, and z'.d - z.d = -60 != 0 so [8]\n(correctly) concludes that z' is not UTC-equivalent to x.\n\nBecause we know z.d said z was in daylight time (else [5] would have held and\nwe would have stopped then), and we know z.d != z'.d (else [8] would have held\nand we have stopped then), and there are only 2 possible values dst() can\nreturn in Eastern, it follows that z'.d must be 0 (which it is in the example,\nbut the reasoning doesn't depend on the example -- it depends on there being\ntwo possible dst() outcomes, one zero and the other non-zero).  Therefore\nz' must be in standard time, and is the spelling we want in this case.\n\nNote again that z' is not UTC-equivalent as far as the hybrid tzinfo class is\nconcerned (because it takes z' as being in standard time rather than the\ndaylight time we intend here), but returning it gives the real-life \"local\nclock repeats an hour\" behavior when mapping the \"unspellable\" UTC hour into\ntz.\n\nWhen the input is 6:MM, z=1:MM and z.d=0, and we stop at once, again with\nthe 1:MM standard time spelling we want.\n\nSo how can this break?  One of the assumptions must be violated.  Two\npossibilities:\n\n1) [2] effectively says that y.s is invariant across all y belong to a given\n   time zone.  This isn't true if, for political reasons or continental drift,\n   a region decides to change its base offset from UTC.\n\n2) There may be versions of \"double daylight\" time where the tail end of\n   the analysis gives up a step too early.  I haven't thought about that\n   enough to say.\n\nIn any case, it's clear that the default fromutc() is strong enough to handle\n\"almost all\" time zones:  so long as the standard offset is invariant, it\ndoesn't matter if daylight time transition points change from year to year, or\nif daylight time is skipped in some years; it doesn't matter how large or\nsmall dst() may get within its bounds; and it doesn't even matter if some\nperverse time zone returns a negative dst()).  So a breaking case must be\npretty bizarre, and a tzinfo subclass can override fromutc() if it is.\n\"\"\"\ntry:\n    from _datetime import *\nexcept ImportError:\n    pass\nelse:\n    # Clean up unused names\n    del (_DAYNAMES, _DAYS_BEFORE_MONTH, _DAYS_IN_MONTH,\n         _DI100Y, _DI400Y, _DI4Y, _MAXORDINAL, _MONTHNAMES,\n         _build_struct_time, _call_tzinfo_method, _check_date_fields,\n         _check_time_fields, _check_tzinfo_arg, _check_tzname,\n         _check_utc_offset, _cmp, _cmperror, _date_class, _days_before_month,\n         _days_before_year, _days_in_month, _format_time, _is_leap,\n         _isoweek1monday, _math, _ord2ymd, _time, _time_class, _tzinfo_class,\n         _wrap_strftime, _ymd2ord)\n    # XXX Since import * above excludes names that start with _,\n    # docstring does not get overwritten. In the future, it may be\n    # appropriate to maintain a single module level docstring and\n    # remove the following line.\n    from _datetime import __doc__\n"], "sysconfig": [".py", "\"\"\"Access to Python's configuration information.\"\"\"\n\n#well emulate this module since it does with settings very close to the\n#OS and metal\n\nvariables={'TANH_PRESERVES_ZERO_SIGN': 0, 'WITH_DOC_STRINGS': 0}\n\ndef get_config_var(var):\n    if var in variables:\n       return variables[var]\n\n    raise NotImplementedError(\"sysconfig.py:get_config_var: variable '%s' does not exist\" % variable)\n"], "gc": [".py", "\"\"\"This module provides access to the garbage collector for reference cycles.\n\nenable() -- Enable automatic garbage collection.\ndisable() -- Disable automatic garbage collection.\nisenabled() -- Returns true if automatic collection is enabled.\ncollect() -- Do a full collection right now.\nget_count() -- Return the current collection counts.\nset_debug() -- Set debugging flags.\nget_debug() -- Get debugging flags.\nset_threshold() -- Set the collection thresholds.\nget_threshold() -- Return the current the collection thresholds.\nget_objects() -- Return a list of all objects tracked by the collector.\nis_tracked() -- Returns true if a given object is tracked.\nget_referrers() -- Return the list of objects that refer to an object.\nget_referents() -- Return the list of objects that an object refers to.\n\"\"\"\n\n\nDEBUG_COLLECTABLE = 2\n\nDEBUG_LEAK = 38\n\nDEBUG_SAVEALL = 32\n\nDEBUG_STATS = 1\n\nDEBUG_UNCOLLECTABLE = 4\n\nclass __loader__:\n    pass\n\ncallbacks = []\n\ndef collect(*args,**kw):\n    \"\"\"collect([generation]) -> n    \n    With no arguments, run a full collection.  The optional argument\n    may be an integer specifying which generation to collect.  A ValueError\n    is raised if the generation number is invalid.\n    \n    The number of unreachable objects is returned.\n    \"\"\"\n    pass\n\ndef disable(*args,**kw):\n    \"\"\"disable() -> None    \n    Disable automatic garbage collection.\n    \"\"\"\n    pass\n\ndef enable(*args,**kw):\n    \"\"\"enable() -> None    \n    Enable automatic garbage collection.\n    \"\"\"\n    pass\n\ngarbage = []\n\ndef get_count(*args,**kw):\n    \"\"\"get_count() -> (count0, count1, count2)    \n    Return the current collection counts\n    \"\"\"\n    pass\n\ndef get_debug(*args,**kw):\n    \"\"\"get_debug() -> flags    \n    Get the garbage collection debugging flags.\n    \"\"\"\n    pass\n\ndef get_objects(*args,**kw):\n    \"\"\"get_objects() -> [...]    \n    Return a list of objects tracked by the collector (excluding the list\n    returned).\n    \"\"\"\n    pass\n\ndef get_referents(*args,**kw):\n    \"\"\"get_referents(*objs) -> list    Return the list of objects that are directly referred to by objs.\"\"\"\n    pass\n\ndef get_referrers(*args,**kw):\n    \"\"\"get_referrers(*objs) -> list    Return the list of objects that directly refer to any of objs.\"\"\"\n    pass\n\ndef get_threshold(*args,**kw):\n    \"\"\"get_threshold() -> (threshold0, threshold1, threshold2)    \n    Return the current collection thresholds\n    \"\"\"\n    pass\n\ndef is_tracked(*args,**kw):\n    \"\"\"is_tracked(obj) -> bool    \n    Returns true if the object is tracked by the garbage collector.\n    Simple atomic objects will return false.\n    \"\"\"\n    pass\n\ndef isenabled(*args,**kw):\n    \"\"\"isenabled() -> status    \n    Returns true if automatic garbage collection is enabled.\n    \"\"\"\n    pass\n\ndef set_debug(*args,**kw):\n    \"\"\"set_debug(flags) -> None    \n    Set the garbage collection debugging flags. Debugging information is\n    written to sys.stderr.\n    \n    flags is an integer and can have the following bits turned on:\n    \n      DEBUG_STATS - Print statistics during collection.\n      DEBUG_COLLECTABLE - Print collectable objects found.\n      DEBUG_UNCOLLECTABLE - Print unreachable but uncollectable objects found.\n      DEBUG_SAVEALL - Save objects to gc.garbage rather than freeing them.\n      DEBUG_LEAK - Debug leaking programs (everything but STATS).\n    \"\"\"\n    pass\n\ndef set_threshold(*args,**kw):\n    \"\"\"set_threshold(threshold0, [threshold1, threshold2]) -> None    \n    Sets the collection thresholds.  Setting threshold0 to zero disables\n    collection.\n    \"\"\"\n    pass\n"], "_svg": [".js", "// creation of an HTML element\nvar $module = (function($B){\n\nvar _b_ = $B.builtins\nvar $TagSumDict = $B.$TagSum.$dict\n\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\nvar $svgNS = \"http://www.w3.org/2000/svg\"\nvar $xlinkNS = \"http://www.w3.org/1999/xlink\"\n\nfunction makeTagDict(tagName){\n    // return the dictionary for the class associated with tagName\n    var dict = {__class__:$B.$type,\n        __name__:tagName\n        }\n\n    dict.__init__ = function(){\n        var $ns=$B.$MakeArgs('pow',arguments,['self'],[],'args','kw')\n        var self = $ns['self']\n        var args = $ns['args']\n        if(args.length==1){\n            var first=args[0]\n            if(isinstance(first,[str,int,float])){\n                self.elt.appendChild(document.createTextNode(str(first)))\n            } else if(first.__class__===$TagSumDict){\n                for(var i=0;i<first.children.length;i++){\n                    self.elt.appendChild(first.children[i].elt)\n                }\n            } else { // argument is another DOMNode instance\n                try{self.elt.appendChild(first.elt)}\n                catch(err){throw ValueError('wrong element '+first)}\n            }\n        }\n\n        // attributes\n        for(var i=0;i<$ns['kw'].$keys.length;i++){\n            // keyword arguments\n            var arg = $ns['kw'].$keys[i]\n            var value = $ns['kw'].$values[i]\n            if(arg.toLowerCase().substr(0,2)===\"on\"){ \n                // Event binding passed as argument \"onclick\", \"onfocus\"...\n                // Better use method bind of DOMNode objects\n                var js = '$B.DOMNode.bind(self,\"'\n                js += arg.toLowerCase().substr(2)\n                eval(js+'\",function(){'+value+'})')\n            }else if(arg.toLowerCase()==\"style\"){\n                $B.DOMNode.set_style(self,value)\n            }else if(arg.toLowerCase().indexOf(\"href\") !== -1){ // xlink:href\n                self.elt.setAttributeNS( \"http://www.w3.org/1999/xlink\",\"href\",value)\n            } else {\n                if(value!==false){\n                    // option.selected=false sets it to true :-)\n                    try{\n                        arg = arg.toLowerCase()\n                        self.elt.setAttributeNS(null,arg,value)\n                        if(arg==\"class\"){ // for IE\n                            self.elt.setAttribute(\"className\",value)\n                        }\n                    }catch(err){\n                        throw ValueError(\"can't set attribute \"+arg)\n                    }\n                }\n            }\n        }\n    }\n\n    dict.__mro__ = [dict,$B.DOMNode,$B.builtins.object.$dict]\n\n    dict.__new__ = function(cls){\n        var res = $B.$DOMNode(document.createElementNS($svgNS,tagName))\n        res.__class__ = cls.$dict\n        return res\n    }\n\n    return dict\n}\n\n\n// the classes used for tag sums, $TagSum and $TagSumClass \n// are defined in py_dom.js\n\nfunction makeFactory(tagName){\n    var factory = function(){\n        var res = $B.$DOMNode(document.createElementNS($svgNS,tagName))\n        res.__class__ = dicts[tagName]\n        // apply __init__\n        var args = [res]\n        for(var i=0;i<arguments.length;i++){args.push(arguments[i])}\n        dicts[tagName].__init__.apply(null,args)\n        return res\n    }\n    factory.__class__=$B.$factory\n    factory.$dict = dicts[tagName]\n    return factory\n}\n\n// SVG\nvar $svg_tags = ['a',\n'altGlyph',\n'altGlyphDef',\n'altGlyphItem',\n'animate',\n'animateColor',\n'animateMotion',\n'animateTransform',\n'circle',\n'clipPath',\n'color_profile', // instead of color-profile\n'cursor',\n'defs',\n'desc',\n'ellipse',\n'feBlend',\n'foreignObject', //patch to enable foreign objects\n'g',\n'image',\n'line',\n'linearGradient',\n'marker',\n'mask',\n'path',\n'pattern',\n'polygon',\n'polyline',\n'radialGradient',\n'rect',\n'set',\n'stop',\n'svg',\n'text',\n'tref',\n'tspan',\n'use']\n\n// create classes\nvar obj = new Object()\nvar dicts = {}\nfor(var i=0;i<$svg_tags.length;i++){\n    var tag = $svg_tags[i]\n    dicts[tag]=makeTagDict(tag)\n    obj[tag] = makeFactory(tag)\n    dicts[tag].$factory = obj[tag]\n}\nreturn obj\n})(__BRYTHON__)\n"], "external_import": [".py", "import os\nfrom browser import doc\nimport urllib.request\n\n## this module is able to download modules that are external to\n## localhost/src\n## so we could download from any URL\n\nclass ModuleFinder:\n    def __init__(self, path_entry):\n        print(\"external_import here..\")\n        #print(path_entry)\n        self._module=None\n        if path_entry.startswith('http://'):\n           self.path_entry=path_entry\n        else:\n            raise ImportError()\n        \n    def __str__(self):\n        return '<%s for \"%s\">' % (self.__class__.__name__, self.path_entry)\n        \n    def find_module(self, fullname, path=None):\n        path = path or self.path_entry\n        #print('looking for \"%s\" in %s ...' % (fullname, path))\n        for _ext in ['js', 'pyj', 'py']:\n            _fp,_url,_headers=urllib.request.urlopen(path + '/' + '%s.%s' % (fullname, _ext))\n            self._module=_fp.read()\n            _fp.close()\n            if self._module is not None:\n               print(\"module found at %s:%s\" % (path, fullname))\n               return ModuleLoader(path, fullname, self._module)\n\n        print('module %s not found' % fullname)\n        raise ImportError()\n        return None\n\nclass ModuleLoader:\n    \"\"\"Load source for modules\"\"\"\n    \n    def __init__(self, filepath, name, module_source):\n        self._filepath=filepath\n        self._name=name\n        self._module_source=module_source\n        \n    def get_source(self):\n        return self._module_source\n\n    def is_package(self):\n        return '.' in self._name\n            \n    def load_module(self):\n        if self._name in sys.modules:\n           #print('reusing existing module from previous import of \"%s\"' % fullname)\n           mod = sys.modules[self._name]\n           return mod\n        \n        _src=self.get_source()\n        if self._filepath.endswith('.js'):\n           mod=JSObject(import_js_module(_src, self._filepath, self._name))\n        elif self._filepath.endswith('.py'):\n           mod=JSObject(import_py_module(_src, self._filepath, self._name))\n        elif self._filepath.endswith('.pyj'):\n           mod=JSObject(import_pyj_module(_src, self._filepath, self._name))\n        else:\n           raise ImportError('Invalid Module: %s' % self._filepath)\n\n        # Set a few properties required by PEP 302\n        mod.__file__ = self._filepath\n        mod.__name__ = self._name\n        mod.__path__ = os.path.abspath(self._filepath)\n        mod.__loader__ = self\n        mod.__package__ = '.'.join(self._name.split('.')[:-1])\n        \n        if self.is_package():\n           print('adding path for package')\n           # Set __path__ for packages\n           # so we can find the sub-modules.\n           mod.__path__ = [ self._filepath ]\n        else:\n            print('imported as regular module')\n        \n        print('creating a new module object for \"%s\"' % self._name)\n        sys.modules.setdefault(self._name, mod)\n        JSObject(__BRYTHON__.imported)[self._name]=mod\n\n        return mod\n"], "_dummy_thread": [".py", "\"\"\"Drop-in replacement for the thread module.\n\nMeant to be used as a brain-dead substitute so that threaded code does\nnot need to be rewritten for when the thread module is not present.\n\nSuggested usage is::\n\n    try:\n        import _thread\n    except ImportError:\n        import _dummy_thread as _thread\n\n\"\"\"\n# Exports only things specified by thread documentation;\n# skipping obsolete synonyms allocate(), start_new(), exit_thread().\n__all__ = ['error', 'start_new_thread', 'exit', 'get_ident', 'allocate_lock',\n           'interrupt_main', 'LockType']\n\n# A dummy value\nTIMEOUT_MAX = 2**31\n\n# NOTE: this module can be imported early in the extension building process,\n# and so top level imports of other modules should be avoided.  Instead, all\n# imports are done when needed on a function-by-function basis.  Since threads\n# are disabled, the import lock should not be an issue anyway (??).\n\nerror = RuntimeError\n\ndef start_new_thread(function, args, kwargs={}):\n    \"\"\"Dummy implementation of _thread.start_new_thread().\n\n    Compatibility is maintained by making sure that ``args`` is a\n    tuple and ``kwargs`` is a dictionary.  If an exception is raised\n    and it is SystemExit (which can be done by _thread.exit()) it is\n    caught and nothing is done; all other exceptions are printed out\n    by using traceback.print_exc().\n\n    If the executed function calls interrupt_main the KeyboardInterrupt will be\n    raised when the function returns.\n\n    \"\"\"\n    if type(args) != type(tuple()):\n        raise TypeError(\"2nd arg must be a tuple\")\n    if type(kwargs) != type(dict()):\n        raise TypeError(\"3rd arg must be a dict\")\n    global _main\n    _main = False\n    try:\n        function(*args, **kwargs)\n    except SystemExit:\n        pass\n    except:\n        import traceback\n        traceback.print_exc()\n    _main = True\n    global _interrupt\n    if _interrupt:\n        _interrupt = False\n        raise KeyboardInterrupt\n\ndef exit():\n    \"\"\"Dummy implementation of _thread.exit().\"\"\"\n    raise SystemExit\n\ndef get_ident():\n    \"\"\"Dummy implementation of _thread.get_ident().\n\n    Since this module should only be used when _threadmodule is not\n    available, it is safe to assume that the current process is the\n    only thread.  Thus a constant can be safely returned.\n    \"\"\"\n    return -1\n\ndef allocate_lock():\n    \"\"\"Dummy implementation of _thread.allocate_lock().\"\"\"\n    return LockType()\n\ndef stack_size(size=None):\n    \"\"\"Dummy implementation of _thread.stack_size().\"\"\"\n    if size is not None:\n        raise error(\"setting thread stack size not supported\")\n    return 0\n\nclass LockType(object):\n    \"\"\"Class implementing dummy implementation of _thread.LockType.\n\n    Compatibility is maintained by maintaining self.locked_status\n    which is a boolean that stores the state of the lock.  Pickling of\n    the lock, though, should not be done since if the _thread module is\n    then used with an unpickled ``lock()`` from here problems could\n    occur from this class not having atomic methods.\n\n    \"\"\"\n\n    def __init__(self):\n        self.locked_status = False\n\n    def acquire(self, waitflag=None, timeout=-1):\n        \"\"\"Dummy implementation of acquire().\n\n        For blocking calls, self.locked_status is automatically set to\n        True and returned appropriately based on value of\n        ``waitflag``.  If it is non-blocking, then the value is\n        actually checked and not set if it is already acquired.  This\n        is all done so that threading.Condition's assert statements\n        aren't triggered and throw a little fit.\n\n        \"\"\"\n        if waitflag is None or waitflag:\n            self.locked_status = True\n            return True\n        else:\n            if not self.locked_status:\n                self.locked_status = True\n                return True\n            else:\n                if timeout > 0:\n                    import time\n                    time.sleep(timeout)\n                return False\n\n    __enter__ = acquire\n\n    def __exit__(self, typ, val, tb):\n        self.release()\n\n    def release(self):\n        \"\"\"Release the dummy lock.\"\"\"\n        # XXX Perhaps shouldn't actually bother to test?  Could lead\n        #     to problems for complex, threaded code.\n        if not self.locked_status:\n            raise error\n        self.locked_status = False\n        return True\n\n    def locked(self):\n        return self.locked_status\n\n# Used to signal that interrupt_main was called in a \"thread\"\n_interrupt = False\n# True when not executing in a \"thread\"\n_main = True\n\ndef interrupt_main():\n    \"\"\"Set _interrupt flag to True to have start_new_thread raise\n    KeyboardInterrupt upon exiting.\"\"\"\n    if _main:\n        raise KeyboardInterrupt\n    else:\n        global _interrupt\n        _interrupt = True\n"], "importlib.util": [".py", "\"\"\"Utility code for constructing importers, etc.\"\"\"\n\nfrom ._bootstrap import module_for_loader\nfrom ._bootstrap import set_loader\nfrom ._bootstrap import set_package\nfrom ._bootstrap import _resolve_name\n\n\ndef resolve_name(name, package):\n    \"\"\"Resolve a relative module name to an absolute one.\"\"\"\n    if not name.startswith('.'):\n        return name\n    elif not package:\n        raise ValueError('{!r} is not a relative name '\n                         '(no leading dot)'.format(name))\n    level = 0\n    for character in name:\n        if character != '.':\n            break\n        level += 1\n    return _resolve_name(name[level:], package, level)\n"], "_markupbase": [".py", "\"\"\"Shared support for scanning document type declarations in HTML and XHTML.\n\nThis module is used as a foundation for the html.parser module.  It has no\ndocumented public API and should not be used directly.\n\n\"\"\"\n\nimport re\n\n_declname_match = re.compile(r'[a-zA-Z][-_.a-zA-Z0-9]*\\s*').match\n_declstringlit_match = re.compile(r'(\\'[^\\']*\\'|\"[^\"]*\")\\s*').match\n_commentclose = re.compile(r'--\\s*>')\n_markedsectionclose = re.compile(r']\\s*]\\s*>')\n\n# An analysis of the MS-Word extensions is available at\n# http://www.planetpublish.com/xmlarena/xap/Thursday/WordtoXML.pdf\n\n_msmarkedsectionclose = re.compile(r']\\s*>')\n\ndel re\n\n\nclass ParserBase:\n    \"\"\"Parser base class which provides some common support methods used\n    by the SGML/HTML and XHTML parsers.\"\"\"\n\n    def __init__(self):\n        if self.__class__ is ParserBase:\n            raise RuntimeError(\n                \"_markupbase.ParserBase must be subclassed\")\n\n    def error(self, message):\n        raise NotImplementedError(\n            \"subclasses of ParserBase must override error()\")\n\n    def reset(self):\n        self.lineno = 1\n        self.offset = 0\n\n    def getpos(self):\n        \"\"\"Return current line number and offset.\"\"\"\n        return self.lineno, self.offset\n\n    # Internal -- update line number and offset.  This should be\n    # called for each piece of data exactly once, in order -- in other\n    # words the concatenation of all the input strings to this\n    # function should be exactly the entire input.\n    def updatepos(self, i, j):\n        if i >= j:\n            return j\n        rawdata = self.rawdata\n        nlines = rawdata.count(\"\\n\", i, j)\n        if nlines:\n            self.lineno = self.lineno + nlines\n            pos = rawdata.rindex(\"\\n\", i, j) # Should not fail\n            self.offset = j-(pos+1)\n        else:\n            self.offset = self.offset + j-i\n        return j\n\n    _decl_otherchars = ''\n\n    # Internal -- parse declaration (for use by subclasses).\n    def parse_declaration(self, i):\n        # This is some sort of declaration; in \"HTML as\n        # deployed,\" this should only be the document type\n        # declaration (\"<!DOCTYPE html...>\").\n        # ISO 8879:1986, however, has more complex\n        # declaration syntax for elements in <!...>, including:\n        # --comment--\n        # [marked section]\n        # name in the following list: ENTITY, DOCTYPE, ELEMENT,\n        # ATTLIST, NOTATION, SHORTREF, USEMAP,\n        # LINKTYPE, LINK, IDLINK, USELINK, SYSTEM\n        rawdata = self.rawdata\n        j = i + 2\n        assert rawdata[i:j] == \"<!\", \"unexpected call to parse_declaration\"\n        if rawdata[j:j+1] == \">\":\n            # the empty comment <!>\n            return j + 1\n        if rawdata[j:j+1] in (\"-\", \"\"):\n            # Start of comment followed by buffer boundary,\n            # or just a buffer boundary.\n            return -1\n        # A simple, practical version could look like: ((name|stringlit) S*) + '>'\n        n = len(rawdata)\n        if rawdata[j:j+2] == '--': #comment\n            # Locate --.*-- as the body of the comment\n            return self.parse_comment(i)\n        elif rawdata[j] == '[': #marked section\n            # Locate [statusWord [...arbitrary SGML...]] as the body of the marked section\n            # Where statusWord is one of TEMP, CDATA, IGNORE, INCLUDE, RCDATA\n            # Note that this is extended by Microsoft Office \"Save as Web\" function\n            # to include [if...] and [endif].\n            return self.parse_marked_section(i)\n        else: #all other declaration elements\n            decltype, j = self._scan_name(j, i)\n        if j < 0:\n            return j\n        if decltype == \"doctype\":\n            self._decl_otherchars = ''\n        while j < n:\n            c = rawdata[j]\n            if c == \">\":\n                # end of declaration syntax\n                data = rawdata[i+2:j]\n                if decltype == \"doctype\":\n                    self.handle_decl(data)\n                else:\n                    # According to the HTML5 specs sections \"8.2.4.44 Bogus\n                    # comment state\" and \"8.2.4.45 Markup declaration open\n                    # state\", a comment token should be emitted.\n                    # Calling unknown_decl provides more flexibility though.\n                    self.unknown_decl(data)\n                return j + 1\n            if c in \"\\\"'\":\n                m = _declstringlit_match(rawdata, j)\n                if not m:\n                    return -1 # incomplete\n                j = m.end()\n            elif c in \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n                name, j = self._scan_name(j, i)\n            elif c in self._decl_otherchars:\n                j = j + 1\n            elif c == \"[\":\n                # this could be handled in a separate doctype parser\n                if decltype == \"doctype\":\n                    j = self._parse_doctype_subset(j + 1, i)\n                elif decltype in {\"attlist\", \"linktype\", \"link\", \"element\"}:\n                    # must tolerate []'d groups in a content model in an element declaration\n                    # also in data attribute specifications of attlist declaration\n                    # also link type declaration subsets in linktype declarations\n                    # also link attribute specification lists in link declarations\n                    self.error(\"unsupported '[' char in %s declaration\" % decltype)\n                else:\n                    self.error(\"unexpected '[' char in declaration\")\n            else:\n                self.error(\n                    \"unexpected %r char in declaration\" % rawdata[j])\n            if j < 0:\n                return j\n        return -1 # incomplete\n\n    # Internal -- parse a marked section\n    # Override this to handle MS-word extension syntax <![if word]>content<![endif]>\n    def parse_marked_section(self, i, report=1):\n        rawdata= self.rawdata\n        assert rawdata[i:i+3] == '<![', \"unexpected call to parse_marked_section()\"\n        sectName, j = self._scan_name( i+3, i )\n        if j < 0:\n            return j\n        if sectName in {\"temp\", \"cdata\", \"ignore\", \"include\", \"rcdata\"}:\n            # look for standard ]]> ending\n            match= _markedsectionclose.search(rawdata, i+3)\n        elif sectName in {\"if\", \"else\", \"endif\"}:\n            # look for MS Office ]> ending\n            match= _msmarkedsectionclose.search(rawdata, i+3)\n        else:\n            self.error('unknown status keyword %r in marked section' % rawdata[i+3:j])\n        if not match:\n            return -1\n        if report:\n            j = match.start(0)\n            self.unknown_decl(rawdata[i+3: j])\n        return match.end(0)\n\n    # Internal -- parse comment, return length or -1 if not terminated\n    def parse_comment(self, i, report=1):\n        rawdata = self.rawdata\n        if rawdata[i:i+4] != '<!--':\n            self.error('unexpected call to parse_comment()')\n        match = _commentclose.search(rawdata, i+4)\n        if not match:\n            return -1\n        if report:\n            j = match.start(0)\n            self.handle_comment(rawdata[i+4: j])\n        return match.end(0)\n\n    # Internal -- scan past the internal subset in a <!DOCTYPE declaration,\n    # returning the index just past any whitespace following the trailing ']'.\n    def _parse_doctype_subset(self, i, declstartpos):\n        rawdata = self.rawdata\n        n = len(rawdata)\n        j = i\n        while j < n:\n            c = rawdata[j]\n            if c == \"<\":\n                s = rawdata[j:j+2]\n                if s == \"<\":\n                    # end of buffer; incomplete\n                    return -1\n                if s != \"<!\":\n                    self.updatepos(declstartpos, j + 1)\n                    self.error(\"unexpected char in internal subset (in %r)\" % s)\n                if (j + 2) == n:\n                    # end of buffer; incomplete\n                    return -1\n                if (j + 4) > n:\n                    # end of buffer; incomplete\n                    return -1\n                if rawdata[j:j+4] == \"<!--\":\n                    j = self.parse_comment(j, report=0)\n                    if j < 0:\n                        return j\n                    continue\n                name, j = self._scan_name(j + 2, declstartpos)\n                if j == -1:\n                    return -1\n                if name not in {\"attlist\", \"element\", \"entity\", \"notation\"}:\n                    self.updatepos(declstartpos, j + 2)\n                    self.error(\n                        \"unknown declaration %r in internal subset\" % name)\n                # handle the individual names\n                meth = getattr(self, \"_parse_doctype_\" + name)\n                j = meth(j, declstartpos)\n                if j < 0:\n                    return j\n            elif c == \"%\":\n                # parameter entity reference\n                if (j + 1) == n:\n                    # end of buffer; incomplete\n                    return -1\n                s, j = self._scan_name(j + 1, declstartpos)\n                if j < 0:\n                    return j\n                if rawdata[j] == \";\":\n                    j = j + 1\n            elif c == \"]\":\n                j = j + 1\n                while j < n and rawdata[j].isspace():\n                    j = j + 1\n                if j < n:\n                    if rawdata[j] == \">\":\n                        return j\n                    self.updatepos(declstartpos, j)\n                    self.error(\"unexpected char after internal subset\")\n                else:\n                    return -1\n            elif c.isspace():\n                j = j + 1\n            else:\n                self.updatepos(declstartpos, j)\n                self.error(\"unexpected char %r in internal subset\" % c)\n        # end of buffer reached\n        return -1\n\n    # Internal -- scan past <!ELEMENT declarations\n    def _parse_doctype_element(self, i, declstartpos):\n        name, j = self._scan_name(i, declstartpos)\n        if j == -1:\n            return -1\n        # style content model; just skip until '>'\n        rawdata = self.rawdata\n        if '>' in rawdata[j:]:\n            return rawdata.find(\">\", j) + 1\n        return -1\n\n    # Internal -- scan past <!ATTLIST declarations\n    def _parse_doctype_attlist(self, i, declstartpos):\n        rawdata = self.rawdata\n        name, j = self._scan_name(i, declstartpos)\n        c = rawdata[j:j+1]\n        if c == \"\":\n            return -1\n        if c == \">\":\n            return j + 1\n        while 1:\n            # scan a series of attribute descriptions; simplified:\n            #   name type [value] [#constraint]\n            name, j = self._scan_name(j, declstartpos)\n            if j < 0:\n                return j\n            c = rawdata[j:j+1]\n            if c == \"\":\n                return -1\n            if c == \"(\":\n                # an enumerated type; look for ')'\n                if \")\" in rawdata[j:]:\n                    j = rawdata.find(\")\", j) + 1\n                else:\n                    return -1\n                while rawdata[j:j+1].isspace():\n                    j = j + 1\n                if not rawdata[j:]:\n                    # end of buffer, incomplete\n                    return -1\n            else:\n                name, j = self._scan_name(j, declstartpos)\n            c = rawdata[j:j+1]\n            if not c:\n                return -1\n            if c in \"'\\\"\":\n                m = _declstringlit_match(rawdata, j)\n                if m:\n                    j = m.end()\n                else:\n                    return -1\n                c = rawdata[j:j+1]\n                if not c:\n                    return -1\n            if c == \"#\":\n                if rawdata[j:] == \"#\":\n                    # end of buffer\n                    return -1\n                name, j = self._scan_name(j + 1, declstartpos)\n                if j < 0:\n                    return j\n                c = rawdata[j:j+1]\n                if not c:\n                    return -1\n            if c == '>':\n                # all done\n                return j + 1\n\n    # Internal -- scan past <!NOTATION declarations\n    def _parse_doctype_notation(self, i, declstartpos):\n        name, j = self._scan_name(i, declstartpos)\n        if j < 0:\n            return j\n        rawdata = self.rawdata\n        while 1:\n            c = rawdata[j:j+1]\n            if not c:\n                # end of buffer; incomplete\n                return -1\n            if c == '>':\n                return j + 1\n            if c in \"'\\\"\":\n                m = _declstringlit_match(rawdata, j)\n                if not m:\n                    return -1\n                j = m.end()\n            else:\n                name, j = self._scan_name(j, declstartpos)\n                if j < 0:\n                    return j\n\n    # Internal -- scan past <!ENTITY declarations\n    def _parse_doctype_entity(self, i, declstartpos):\n        rawdata = self.rawdata\n        if rawdata[i:i+1] == \"%\":\n            j = i + 1\n            while 1:\n                c = rawdata[j:j+1]\n                if not c:\n                    return -1\n                if c.isspace():\n                    j = j + 1\n                else:\n                    break\n        else:\n            j = i\n        name, j = self._scan_name(j, declstartpos)\n        if j < 0:\n            return j\n        while 1:\n            c = self.rawdata[j:j+1]\n            if not c:\n                return -1\n            if c in \"'\\\"\":\n                m = _declstringlit_match(rawdata, j)\n                if m:\n                    j = m.end()\n                else:\n                    return -1    # incomplete\n            elif c == \">\":\n                return j + 1\n            else:\n                name, j = self._scan_name(j, declstartpos)\n                if j < 0:\n                    return j\n\n    # Internal -- scan a name token and the new position and the token, or\n    # return -1 if we've reached the end of the buffer.\n    def _scan_name(self, i, declstartpos):\n        rawdata = self.rawdata\n        n = len(rawdata)\n        if i == n:\n            return None, -1\n        m = _declname_match(rawdata, i)\n        if m:\n            s = m.group()\n            name = s.strip()\n            if (i + len(s)) == n:\n                return None, -1  # end of buffer\n            return name.lower(), m.end()\n        else:\n            self.updatepos(declstartpos, i)\n            self.error(\"expected name token at %r\"\n                       % rawdata[declstartpos:declstartpos+20])\n\n    # To be overridden -- handlers for unknown objects\n    def unknown_decl(self, data):\n        pass\n"], "builtins": [".js", "var $module = (function(){\n    var obj = {__class__:__BRYTHON__.$ModuleDict,__name__:'builtins'}\n    var builtin_names = ['ArithmeticError', 'AssertionError', 'AttributeError', \n    'BaseException', 'BlockingIOError', 'BrokenPipeError', 'BufferError', \n    'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', \n    'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', \n    'DeprecationWarning', 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', \n    'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', \n    'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', \n    'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError',\n    'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError', \n    'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', \n    'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', \n    'ProcessLookupError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', \n    'RuntimeWarning', 'StopIteration', 'SyntaxError', 'SyntaxWarning', \n    'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', \n    'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', \n    'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', \n    'ValueError', 'Warning', 'WindowsError', 'ZeroDivisionError', '_', \n    '__build_class__', '__debug__', '__doc__', '__import__', '__name__', \n    '__package__', 'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'bytearray', \n    'bytes','callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', \n    'credits','delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', \n    'exit', 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', \n    'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', \n    'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', \n    'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', \n    'property', 'quit', 'range', 'repr', 'reversed', 'round', 'set', 'setattr', \n    'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', \n    'vars', 'zip']\n    for(var i=0;i<builtin_names.length;i++){\n        try{eval(\"obj['\"+builtin_names[i]+\"']=__BRYTHON__.builtins.\"+builtin_names[i])}\n        catch(err){if (__BRYTHON__.$debug) {console.log(err)}}\n    }\n    return obj\n})()\n"], "struct": [".py", "__all__ = [\n    # Functions\n    'calcsize', 'pack', 'pack_into', 'unpack', 'unpack_from',\n\n    # Classes\n    'Struct',\n\n    # Exceptions\n    'error'\n    ]\n\nfrom _struct import *\nfrom _struct import _clearcache\nfrom _struct import __doc__\n"], "re": [".py", "#\n# Copyright (c) 2014 Olemis Lang.  All rights reserved.\n#\n# Choose either Javascript (faster) or Python engine based on regex complexity\n# with a noticeable preference for the former.\n#\n\nr\"\"\"Support for regular expressions (RE).\n\nThis module provides regular expression matching operations similar to\nthose found in Perl.  It supports both 8-bit and Unicode strings; both\nthe pattern and the strings being processed can contain null bytes and\ncharacters outside the US ASCII range.\n\nRegular expressions can contain both special and ordinary characters.\nMost ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\nregular expressions; they simply match themselves.  You can\nconcatenate ordinary characters, so last matches the string 'last'.\n\nThe special characters are:\n    \".\"      Matches any character except a newline.\n    \"^\"      Matches the start of the string.\n    \"$\"      Matches the end of the string or just before the newline at\n             the end of the string.\n    \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n             Greedy means that it will match as many repetitions as possible.\n    \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n    \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n    *?,+?,?? Non-greedy versions of the previous three special characters.\n    {m,n}    Matches from m to n repetitions of the preceding RE.\n    {m,n}?   Non-greedy version of the above.\n    \"\\\\\"     Either escapes special characters or signals a special sequence.\n    []       Indicates a set of characters.\n             A \"^\" as the first character indicates a complementing set.\n    \"|\"      A|B, creates an RE that will match either A or B.\n    (...)    Matches the RE inside the parentheses.\n             The contents can be retrieved or matched later in the string.\n    (?aiLmsux) Set the A, I, L, M, S, U, or X flag for the RE (see below).\n    (?:...)  Non-grouping version of regular parentheses.\n    (?P<name>...) The substring matched by the group is accessible by name.\n    (?P=name)     Matches the text matched earlier by the group named name.\n    (?#...)  A comment; ignored.\n    (?=...)  Matches if ... matches next, but doesn't consume the string.\n    (?!...)  Matches if ... doesn't match next.\n    (?<=...) Matches if preceded by ... (must be fixed length).\n    (?<!...) Matches if not preceded by ... (must be fixed length).\n    (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,\n                       the (optional) no pattern otherwise.\n\nThe special sequences consist of \"\\\\\" and a character from the list\nbelow.  If the ordinary character is not on the list, then the\nresulting RE will match the second character.\n    \\number  Matches the contents of the group of the same number.\n    \\A       Matches only at the start of the string.\n    \\Z       Matches only at the end of the string.\n    \\b       Matches the empty string, but only at the start or end of a word.\n    \\B       Matches the empty string, but not at the start or end of a word.\n    \\d       Matches any decimal digit; equivalent to the set [0-9] in\n             bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the whole\n             range of Unicode digits.\n    \\D       Matches any non-digit character; equivalent to [^\\d].\n    \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] in\n             bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the whole\n             range of Unicode whitespace characters.\n    \\S       Matches any non-whitespace character; equivalent to [^\\s].\n    \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]\n             in bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the\n             range of Unicode alphanumeric characters (letters plus digits\n             plus underscore).\n             With LOCALE, it will match the set [0-9_] plus characters defined\n             as letters for the current locale.\n    \\W       Matches the complement of \\w.\n    \\\\       Matches a literal backslash.\n\nThis module exports the following functions:\n    match    Match a regular expression pattern to the beginning of a string.\n    search   Search a string for the presence of a pattern.\n    sub      Substitute occurrences of a pattern found in a string.\n    subn     Same as sub, but also return the number of substitutions made.\n    split    Split a string by the occurrences of a pattern.\n    findall  Find all occurrences of a pattern in a string.\n    finditer Return an iterator yielding a match object for each match.\n    compile  Compile a pattern into a RegexObject.\n    purge    Clear the regular expression cache.\n    escape   Backslash all non-alphanumerics in a string.\n\nSome of the functions in this module takes flags as optional parameters:\n    A  ASCII       For string patterns, make \\w, \\W, \\b, \\B, \\d, \\D\n                   match the corresponding ASCII character categories\n                   (rather than the whole Unicode categories, which is the\n                   default).\n                   For bytes patterns, this flag is the only available\n                   behaviour and needn't be specified.\n    I  IGNORECASE  Perform case-insensitive matching.\n    L  LOCALE      Make \\w, \\W, \\b, \\B, dependent on the current locale.\n    M  MULTILINE   \"^\" matches the beginning of lines (after a newline)\n                   as well as the string.\n                   \"$\" matches the end of lines (before a newline) as well\n                   as the end of the string.\n    S  DOTALL      \".\" matches any character at all, including the newline.\n    X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.\n    U  UNICODE     For compatibility only. Ignored for string patterns (it\n                   is the default), and forbidden for bytes patterns.\n\nThis module also defines an exception 'error'.\n\n\"\"\"\nimport sys\nimport _jsre\n_pymdl = [None]\n\nif not _jsre._is_valid():\n   from pyre import *\n\n# public symbols\n__all__ = [ \"match\", \"search\", \"sub\", \"subn\", \"split\", \"findall\",\n    \"compile\", \"purge\", \"template\", \"escape\", \"A\", \"I\", \"L\", \"M\", \"S\", \"X\",\n    \"U\", \"ASCII\", \"IGNORECASE\", \"LOCALE\", \"MULTILINE\", \"DOTALL\", \"VERBOSE\",\n    \"UNICODE\", \n    # TODO: brython - same exception class in sre_constants and _jsre\n    #\"error\" \n    ]\n\n__version__ = \"2.2.1\"\n\n# flags\nA = ASCII = _jsre.A # assume ascii \"locale\"\nI = IGNORECASE = _jsre.I # ignore case\nL = LOCALE = _jsre.L # assume current 8-bit locale\nU = UNICODE = _jsre.U # assume unicode \"locale\"\nM = MULTILINE = _jsre.M # make anchors look for newline\nS = DOTALL = _jsre.S # make dot match newline\nX = VERBOSE = _jsre.X # ignore whitespace and comments\n\n# sre exception\n# TODO: brython - same exception class in sre_constants and _jsre\n#error = sre_compile.error\n\n# --------------------------------------------------------------------\n# public interface\n\ndef _pyre():\n    mdl = _pymdl[0]\n    if mdl is None:\n       import pyre\n       _pymdl[0] = pyre\n       return pyre\n\n    return mdl\n\n# --------------------------------------------------------------------\n# public interface\n\ndef match(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern at the start of the string, returning\n    a match object, or None if no match was found.\"\"\"\n    \n    if not isinstance(pattern, str):\n       return pattern.match(string, flags)\n\n    if _jsre._is_valid(pattern):\n       return _jsre.match(pattern, string, flags)\n\n    return _pyre().match(pattern, string, flags)\n\ndef search(pattern, string, flags=0):\n    \"\"\"Scan through string looking for a match to the pattern, returning\n    a match object, or None if no match was found.\"\"\"\n\n    if not isinstance(pattern, str):\n       return pattern.search(string, flags)\n\n    if _jsre._is_valid(pattern):\n       return _jsre.search(pattern, string, flags)\n\n    return _pyre().search(pattern, string, flags)\n\n\ndef sub(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in string by the\n    replacement repl.  repl can be either a string or a callable;\n    if a string, backslash escapes in it are processed.  If it is\n    a callable, it's passed the match object and must return\n    a replacement string to be used.\"\"\"\n\n    if not isinstance(pattern, str):\n       return pattern.sub(repl, string, count, flags)\n\n    if _jsre._is_valid(pattern):\n        return _jsre.sub(pattern, repl, string, count, flags)\n    \n    return _pyre().sub(pattern, repl, string, count, flags)\n\ndef subn(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return a 2-tuple containing (new_string, number).\n    new_string is the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in the source\n    string by the replacement repl.  number is the number of\n    substitutions that were made. repl can be either a string or a\n    callable; if a string, backslash escapes in it are processed.\n    If it is a callable, it's passed the match object and must\n    return a replacement string to be used.\"\"\"\n\n    if not isinstance(pattern, str):\n       return pattern.subn(repl, string, count, flags)\n\n    if _jsre._is_valid(pattern):\n        return _jsre.subn(pattern, repl, string, count, flags)\n\n    return _pyre().subn(pattern, repl, string, count, flags)\n\ndef split(pattern, string, maxsplit=0, flags=0):\n    \"\"\"Split the source string by the occurrences of the pattern,\n    returning a list containing the resulting substrings.  If\n    capturing parentheses are used in pattern, then the text of all\n    groups in the pattern are also returned as part of the resulting\n    list.  If maxsplit is nonzero, at most maxsplit splits occur,\n    and the remainder of the string is returned as the final element\n    of the list.\"\"\"\n\n    if not isinstance(pattern, str):\n       return pattern.split(string, maxsplit, flags)\n\n    if _jsre._is_valid(pattern):\n        return _jsre.split(pattern, string, maxsplit, flags)\n\n    return _pyre().split(pattern, string, maxsplit, flags)\n\ndef findall(pattern, string, flags=0):\n    \"\"\"Return a list of all non-overlapping matches in the string.\n\n    If one or more capturing groups are present in the pattern, return\n    a list of groups; this will be a list of tuples if the pattern\n    has more than one group.\n\n    Empty matches are included in the result.\"\"\"\n\n    if not isinstance(pattern, str):\n       return pattern.findall(pattern, string, flags)\n\n    if _jsre._is_valid(pattern):\n        return _jsre.findall(pattern, string, flags)\n    else:\n        return _pyre().findall(pattern, string, flags)\n\ndef finditer(pattern, string, flags=0):\n    \"\"\"Return an iterator over all non-overlapping matches in the\n       string.  For each match, the iterator returns a match object.\n\n       Empty matches are included in the result.\"\"\"\n\n    return _pyre().finditer(pattern, string, flags)\n\ndef compile(pattern, flags=0):\n    \"Compile a regular expression pattern, returning a pattern object.\"\n\n    if _jsre._is_valid(pattern):\n       return _jsre.compile(pattern, flags)\n\n    return _pyre().compile(pattern, flags)\n\ndef purge():\n    \"Clear the regular expression caches\"\n    if _pymdl[0] is not None:\n        return _pymdl[0].purge()\n\ndef template(pattern, flags=0):\n    \"Compile a template pattern, returning a pattern object\"\n    return _pyre().template(pattern, flags)\n\ndef escape(pattern):\n    \"\"\"\n    Escape all the characters in pattern except ASCII letters, numbers and '_'.\n    \"\"\"\n    # FIXME: Do not load _re module\n    return _pyre().escape(pattern)\n"], "tempfile": [".py", "\"\"\"Temporary files.\n\nThis module provides generic, low- and high-level interfaces for\ncreating temporary files and directories.  The interfaces listed\nas \"safe\" just below can be used without fear of race conditions.\nThose listed as \"unsafe\" cannot, and are provided for backward\ncompatibility only.\n\nThis module also provides some data items to the user:\n\n  TMP_MAX  - maximum number of names that will be tried before\n             giving up.\n  tempdir  - If this is set to a string before the first use of\n             any routine from this module, it will be considered as\n             another candidate location to store temporary files.\n\"\"\"\n\n__all__ = [\n    \"NamedTemporaryFile\", \"TemporaryFile\", # high level safe interfaces\n    \"SpooledTemporaryFile\", \"TemporaryDirectory\",\n    \"mkstemp\", \"mkdtemp\",                  # low level safe interfaces\n    \"mktemp\",                              # deprecated unsafe interface\n    \"TMP_MAX\", \"gettempprefix\",            # constants\n    \"tempdir\", \"gettempdir\"\n   ]\n\n\n# Imports.\n\nimport warnings as _warnings\nimport sys as _sys\nimport io as _io\nimport os as _os\nimport errno as _errno\nfrom random import Random as _Random\n\ntry:\n    import fcntl as _fcntl\nexcept ImportError:\n    def _set_cloexec(fd):\n        pass\nelse:\n    def _set_cloexec(fd):\n        try:\n            flags = _fcntl.fcntl(fd, _fcntl.F_GETFD, 0)\n        except OSError:\n            pass\n        else:\n            # flags read successfully, modify\n            flags |= _fcntl.FD_CLOEXEC\n            _fcntl.fcntl(fd, _fcntl.F_SETFD, flags)\n\n\ntry:\n    import _thread\nexcept ImportError:\n    import _dummy_thread as _thread\n_allocate_lock = _thread.allocate_lock\n\n_text_openflags = _os.O_RDWR | _os.O_CREAT | _os.O_EXCL\nif hasattr(_os, 'O_NOINHERIT'):\n    _text_openflags |= _os.O_NOINHERIT\nif hasattr(_os, 'O_NOFOLLOW'):\n    _text_openflags |= _os.O_NOFOLLOW\n\n_bin_openflags = _text_openflags\nif hasattr(_os, 'O_BINARY'):\n    _bin_openflags |= _os.O_BINARY\n\nif hasattr(_os, 'TMP_MAX'):\n    TMP_MAX = _os.TMP_MAX\nelse:\n    TMP_MAX = 10000\n\n# Although it does not have an underscore for historical reasons, this\n# variable is an internal implementation detail (see issue 10354).\ntemplate = \"tmp\"\n\n# Internal routines.\n\n_once_lock = _allocate_lock()\n\nif hasattr(_os, \"lstat\"):\n    _stat = _os.lstat\nelif hasattr(_os, \"stat\"):\n    _stat = _os.stat\nelse:\n    # Fallback.  All we need is something that raises OSError if the\n    # file doesn't exist.\n    def _stat(fn):\n        f = open(fn)\n        f.close()\n\ndef _exists(fn):\n    try:\n        _stat(fn)\n    except OSError:\n        return False\n    else:\n        return True\n\nclass _RandomNameSequence:\n    \"\"\"An instance of _RandomNameSequence generates an endless\n    sequence of unpredictable strings which can safely be incorporated\n    into file names.  Each string is six characters long.  Multiple\n    threads can safely use the same instance at the same time.\n\n    _RandomNameSequence is an iterator.\"\"\"\n\n    characters = \"abcdefghijklmnopqrstuvwxyz0123456789_\"\n\n    @property\n    def rng(self):\n        cur_pid = _os.getpid()\n        if cur_pid != getattr(self, '_rng_pid', None):\n            self._rng = _Random()\n            self._rng_pid = cur_pid\n        return self._rng\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        c = self.characters\n        choose = self.rng.choice\n        letters = [choose(c) for dummy in \"123456\"]\n        return ''.join(letters)\n\ndef _candidate_tempdir_list():\n    \"\"\"Generate a list of candidate temporary directories which\n    _get_default_tempdir will try.\"\"\"\n\n    dirlist = []\n\n    # First, try the environment.\n    for envname in 'TMPDIR', 'TEMP', 'TMP':\n        dirname = _os.getenv(envname)\n        if dirname: dirlist.append(dirname)\n\n    # Failing that, try OS-specific locations.\n    if _os.name == 'nt':\n        dirlist.extend([ r'c:\\temp', r'c:\\tmp', r'\\temp', r'\\tmp' ])\n    else:\n        dirlist.extend([ '/tmp', '/var/tmp', '/usr/tmp' ])\n\n    # As a last resort, the current directory.\n    try:\n        dirlist.append(_os.getcwd())\n    except (AttributeError, OSError):\n        dirlist.append(_os.curdir)\n\n    return dirlist\n\ndef _get_default_tempdir():\n    \"\"\"Calculate the default directory to use for temporary files.\n    This routine should be called exactly once.\n\n    We determine whether or not a candidate temp dir is usable by\n    trying to create and write to a file in that directory.  If this\n    is successful, the test file is deleted.  To prevent denial of\n    service, the name of the test file must be randomized.\"\"\"\n\n    namer = _RandomNameSequence()\n    dirlist = _candidate_tempdir_list()\n\n    for dir in dirlist:\n        if dir != _os.curdir:\n            dir = _os.path.normcase(_os.path.abspath(dir))\n        # Try only a few names per directory.\n        for seq in range(100):\n            name = next(namer)\n            filename = _os.path.join(dir, name)\n            try:\n                fd = _os.open(filename, _bin_openflags, 0o600)\n                try:\n                    try:\n                        with _io.open(fd, 'wb', closefd=False) as fp:\n                            fp.write(b'blat')\n                    finally:\n                        _os.close(fd)\n                finally:\n                    _os.unlink(filename)\n                return dir\n            except FileExistsError:\n                pass\n            except OSError:\n                break   # no point trying more names in this directory\n    raise FileNotFoundError(_errno.ENOENT,\n                            \"No usable temporary directory found in %s\" %\n                            dirlist)\n\n_name_sequence = None\n\ndef _get_candidate_names():\n    \"\"\"Common setup sequence for all user-callable interfaces.\"\"\"\n\n    global _name_sequence\n    if _name_sequence is None:\n        _once_lock.acquire()\n        try:\n            if _name_sequence is None:\n                _name_sequence = _RandomNameSequence()\n        finally:\n            _once_lock.release()\n    return _name_sequence\n\n\ndef _mkstemp_inner(dir, pre, suf, flags):\n    \"\"\"Code common to mkstemp, TemporaryFile, and NamedTemporaryFile.\"\"\"\n\n    names = _get_candidate_names()\n\n    for seq in range(TMP_MAX):\n        name = next(names)\n        file = _os.path.join(dir, pre + name + suf)\n        try:\n            fd = _os.open(file, flags, 0o600)\n            _set_cloexec(fd)\n            return (fd, _os.path.abspath(file))\n        except FileExistsError:\n            continue    # try again\n        except PermissionError:\n            # This exception is thrown when a directory with the chosen name\n            # already exists on windows.\n            if _os.name == 'nt':\n                continue\n            else:\n                raise\n\n    raise FileExistsError(_errno.EEXIST,\n                          \"No usable temporary file name found\")\n\n\n# User visible interfaces.\n\ndef gettempprefix():\n    \"\"\"Accessor for tempdir.template.\"\"\"\n    return template\n\ntempdir = None\n\ndef gettempdir():\n    \"\"\"Accessor for tempfile.tempdir.\"\"\"\n    global tempdir\n    if tempdir is None:\n        _once_lock.acquire()\n        try:\n            if tempdir is None:\n                tempdir = _get_default_tempdir()\n        finally:\n            _once_lock.release()\n    return tempdir\n\ndef mkstemp(suffix=\"\", prefix=template, dir=None, text=False):\n    \"\"\"User-callable function to create and return a unique temporary\n    file.  The return value is a pair (fd, name) where fd is the\n    file descriptor returned by os.open, and name is the filename.\n\n    If 'suffix' is specified, the file name will end with that suffix,\n    otherwise there will be no suffix.\n\n    If 'prefix' is specified, the file name will begin with that prefix,\n    otherwise a default prefix is used.\n\n    If 'dir' is specified, the file will be created in that directory,\n    otherwise a default directory is used.\n\n    If 'text' is specified and true, the file is opened in text\n    mode.  Else (the default) the file is opened in binary mode.  On\n    some operating systems, this makes no difference.\n\n    The file is readable and writable only by the creating user ID.\n    If the operating system uses permission bits to indicate whether a\n    file is executable, the file is executable by no one. The file\n    descriptor is not inherited by children of this process.\n\n    Caller is responsible for deleting the file when done with it.\n    \"\"\"\n\n    if dir is None:\n        dir = gettempdir()\n\n    if text:\n        flags = _text_openflags\n    else:\n        flags = _bin_openflags\n\n    return _mkstemp_inner(dir, prefix, suffix, flags)\n\n\ndef mkdtemp(suffix=\"\", prefix=template, dir=None):\n    \"\"\"User-callable function to create and return a unique temporary\n    directory.  The return value is the pathname of the directory.\n\n    Arguments are as for mkstemp, except that the 'text' argument is\n    not accepted.\n\n    The directory is readable, writable, and searchable only by the\n    creating user.\n\n    Caller is responsible for deleting the directory when done with it.\n    \"\"\"\n\n    if dir is None:\n        dir = gettempdir()\n\n    names = _get_candidate_names()\n\n    for seq in range(TMP_MAX):\n        name = next(names)\n        file = _os.path.join(dir, prefix + name + suffix)\n        try:\n            _os.mkdir(file, 0o700)\n            return file\n        except FileExistsError:\n            continue    # try again\n\n    raise FileExistsError(_errno.EEXIST,\n                          \"No usable temporary directory name found\")\n\ndef mktemp(suffix=\"\", prefix=template, dir=None):\n    \"\"\"User-callable function to return a unique temporary file name.  The\n    file is not created.\n\n    Arguments are as for mkstemp, except that the 'text' argument is\n    not accepted.\n\n    This function is unsafe and should not be used.  The file name\n    refers to a file that did not exist at some point, but by the time\n    you get around to creating it, someone else may have beaten you to\n    the punch.\n    \"\"\"\n\n##    from warnings import warn as _warn\n##    _warn(\"mktemp is a potential security risk to your program\",\n##          RuntimeWarning, stacklevel=2)\n\n    if dir is None:\n        dir = gettempdir()\n\n    names = _get_candidate_names()\n    for seq in range(TMP_MAX):\n        name = next(names)\n        file = _os.path.join(dir, prefix + name + suffix)\n        if not _exists(file):\n            return file\n\n    raise FileExistsError(_errno.EEXIST,\n                          \"No usable temporary filename found\")\n\n\nclass _TemporaryFileWrapper:\n    \"\"\"Temporary file wrapper\n\n    This class provides a wrapper around files opened for\n    temporary use.  In particular, it seeks to automatically\n    remove the file when it is no longer needed.\n    \"\"\"\n\n    def __init__(self, file, name, delete=True):\n        self.file = file\n        self.name = name\n        self.close_called = False\n        self.delete = delete\n\n    def __getattr__(self, name):\n        # Attribute lookups are delegated to the underlying file\n        # and cached for non-numeric results\n        # (i.e. methods are cached, closed and friends are not)\n        file = self.__dict__['file']\n        a = getattr(file, name)\n        if not isinstance(a, int):\n            setattr(self, name, a)\n        return a\n\n    # The underlying __enter__ method returns the wrong object\n    # (self.file) so override it to return the wrapper\n    def __enter__(self):\n        self.file.__enter__()\n        return self\n\n    # iter() doesn't use __getattr__ to find the __iter__ method\n    def __iter__(self):\n        return iter(self.file)\n\n    # NT provides delete-on-close as a primitive, so we don't need\n    # the wrapper to do anything special.  We still use it so that\n    # file.name is useful (i.e. not \"(fdopen)\") with NamedTemporaryFile.\n    if _os.name != 'nt':\n        # Cache the unlinker so we don't get spurious errors at\n        # shutdown when the module-level \"os\" is None'd out.  Note\n        # that this must be referenced as self.unlink, because the\n        # name TemporaryFileWrapper may also get None'd out before\n        # __del__ is called.\n        unlink = _os.unlink\n\n        def close(self):\n            if not self.close_called:\n                self.close_called = True\n                self.file.close()\n                if self.delete:\n                    self.unlink(self.name)\n\n        def __del__(self):\n            self.close()\n\n        # Need to trap __exit__ as well to ensure the file gets\n        # deleted when used in a with statement\n        def __exit__(self, exc, value, tb):\n            result = self.file.__exit__(exc, value, tb)\n            self.close()\n            return result\n    else:\n        def __exit__(self, exc, value, tb):\n            self.file.__exit__(exc, value, tb)\n\n\ndef NamedTemporaryFile(mode='w+b', buffering=-1, encoding=None,\n                       newline=None, suffix=\"\", prefix=template,\n                       dir=None, delete=True):\n    \"\"\"Create and return a temporary file.\n    Arguments:\n    'prefix', 'suffix', 'dir' -- as for mkstemp.\n    'mode' -- the mode argument to io.open (default \"w+b\").\n    'buffering' -- the buffer size argument to io.open (default -1).\n    'encoding' -- the encoding argument to io.open (default None)\n    'newline' -- the newline argument to io.open (default None)\n    'delete' -- whether the file is deleted on close (default True).\n    The file is created as mkstemp() would do it.\n\n    Returns an object with a file-like interface; the name of the file\n    is accessible as file.name.  The file will be automatically deleted\n    when it is closed unless the 'delete' argument is set to False.\n    \"\"\"\n\n    if dir is None:\n        dir = gettempdir()\n\n    flags = _bin_openflags\n\n    # Setting O_TEMPORARY in the flags causes the OS to delete\n    # the file when it is closed.  This is only supported by Windows.\n    if _os.name == 'nt' and delete:\n        flags |= _os.O_TEMPORARY\n\n    (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags)\n    file = _io.open(fd, mode, buffering=buffering,\n                    newline=newline, encoding=encoding)\n\n    return _TemporaryFileWrapper(file, name, delete)\n\nif _os.name != 'posix' or _os.sys.platform == 'cygwin':\n    # On non-POSIX and Cygwin systems, assume that we cannot unlink a file\n    # while it is open.\n    TemporaryFile = NamedTemporaryFile\n\nelse:\n    def TemporaryFile(mode='w+b', buffering=-1, encoding=None,\n                      newline=None, suffix=\"\", prefix=template,\n                      dir=None):\n        \"\"\"Create and return a temporary file.\n        Arguments:\n        'prefix', 'suffix', 'dir' -- as for mkstemp.\n        'mode' -- the mode argument to io.open (default \"w+b\").\n        'buffering' -- the buffer size argument to io.open (default -1).\n        'encoding' -- the encoding argument to io.open (default None)\n        'newline' -- the newline argument to io.open (default None)\n        The file is created as mkstemp() would do it.\n\n        Returns an object with a file-like interface.  The file has no\n        name, and will cease to exist when it is closed.\n        \"\"\"\n\n        if dir is None:\n            dir = gettempdir()\n\n        flags = _bin_openflags\n\n        (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags)\n        try:\n            _os.unlink(name)\n            return _io.open(fd, mode, buffering=buffering,\n                            newline=newline, encoding=encoding)\n        except:\n            _os.close(fd)\n            raise\n\nclass SpooledTemporaryFile:\n    \"\"\"Temporary file wrapper, specialized to switch from BytesIO\n    or StringIO to a real file when it exceeds a certain size or\n    when a fileno is needed.\n    \"\"\"\n    _rolled = False\n\n    def __init__(self, max_size=0, mode='w+b', buffering=-1,\n                 encoding=None, newline=None,\n                 suffix=\"\", prefix=template, dir=None):\n        if 'b' in mode:\n            self._file = _io.BytesIO()\n        else:\n            # Setting newline=\"\\n\" avoids newline translation;\n            # this is important because otherwise on Windows we'd\n            # hget double newline translation upon rollover().\n            self._file = _io.StringIO(newline=\"\\n\")\n        self._max_size = max_size\n        self._rolled = False\n        self._TemporaryFileArgs = {'mode': mode, 'buffering': buffering,\n                                   'suffix': suffix, 'prefix': prefix,\n                                   'encoding': encoding, 'newline': newline,\n                                   'dir': dir}\n\n    def _check(self, file):\n        if self._rolled: return\n        max_size = self._max_size\n        if max_size and file.tell() > max_size:\n            self.rollover()\n\n    def rollover(self):\n        if self._rolled: return\n        file = self._file\n        newfile = self._file = TemporaryFile(**self._TemporaryFileArgs)\n        del self._TemporaryFileArgs\n\n        newfile.write(file.getvalue())\n        newfile.seek(file.tell(), 0)\n\n        self._rolled = True\n\n    # The method caching trick from NamedTemporaryFile\n    # won't work here, because _file may change from a\n    # BytesIO/StringIO instance to a real file. So we list\n    # all the methods directly.\n\n    # Context management protocol\n    def __enter__(self):\n        if self._file.closed:\n            raise ValueError(\"Cannot enter context with closed file\")\n        return self\n\n    def __exit__(self, exc, value, tb):\n        self._file.close()\n\n    # file protocol\n    def __iter__(self):\n        return self._file.__iter__()\n\n    def close(self):\n        self._file.close()\n\n    @property\n    def closed(self):\n        return self._file.closed\n\n    @property\n    def encoding(self):\n        try:\n            return self._file.encoding\n        except AttributeError:\n            if 'b' in self._TemporaryFileArgs['mode']:\n                raise\n            return self._TemporaryFileArgs['encoding']\n\n    def fileno(self):\n        self.rollover()\n        return self._file.fileno()\n\n    def flush(self):\n        self._file.flush()\n\n    def isatty(self):\n        return self._file.isatty()\n\n    @property\n    def mode(self):\n        try:\n            return self._file.mode\n        except AttributeError:\n            return self._TemporaryFileArgs['mode']\n\n    @property\n    def name(self):\n        try:\n            return self._file.name\n        except AttributeError:\n            return None\n\n    @property\n    def newlines(self):\n        try:\n            return self._file.newlines\n        except AttributeError:\n            if 'b' in self._TemporaryFileArgs['mode']:\n                raise\n            return self._TemporaryFileArgs['newline']\n\n    def read(self, *args):\n        return self._file.read(*args)\n\n    def readline(self, *args):\n        return self._file.readline(*args)\n\n    def readlines(self, *args):\n        return self._file.readlines(*args)\n\n    def seek(self, *args):\n        self._file.seek(*args)\n\n    @property\n    def softspace(self):\n        return self._file.softspace\n\n    def tell(self):\n        return self._file.tell()\n\n    def truncate(self, size=None):\n        if size is None:\n            self._file.truncate()\n        else:\n            if size > self._max_size:\n                self.rollover()\n            self._file.truncate(size)\n\n    def write(self, s):\n        file = self._file\n        rv = file.write(s)\n        self._check(file)\n        return rv\n\n    def writelines(self, iterable):\n        file = self._file\n        rv = file.writelines(iterable)\n        self._check(file)\n        return rv\n\n\nclass TemporaryDirectory(object):\n    \"\"\"Create and return a temporary directory.  This has the same\n    behavior as mkdtemp but can be used as a context manager.  For\n    example:\n\n        with TemporaryDirectory() as tmpdir:\n            ...\n\n    Upon exiting the context, the directory and everything contained\n    in it are removed.\n    \"\"\"\n\n    def __init__(self, suffix=\"\", prefix=template, dir=None):\n        self._closed = False\n        self.name = None # Handle mkdtemp raising an exception\n        self.name = mkdtemp(suffix, prefix, dir)\n\n    def __repr__(self):\n        return \"<{} {!r}>\".format(self.__class__.__name__, self.name)\n\n    def __enter__(self):\n        return self.name\n\n    def cleanup(self, _warn=False):\n        if self.name and not self._closed:\n            try:\n                self._rmtree(self.name)\n            except (TypeError, AttributeError) as ex:\n                # Issue #10188: Emit a warning on stderr\n                # if the directory could not be cleaned\n                # up due to missing globals\n                if \"None\" not in str(ex):\n                    raise\n                print(\"ERROR: {!r} while cleaning up {!r}\".format(ex, self,),\n                      file=_sys.stderr)\n                return\n            self._closed = True\n            if _warn:\n                self._warn(\"Implicitly cleaning up {!r}\".format(self),\n                           ResourceWarning)\n\n    def __exit__(self, exc, value, tb):\n        self.cleanup()\n\n    def __del__(self):\n        # Issue a ResourceWarning if implicit cleanup needed\n        self.cleanup(_warn=True)\n\n    # XXX (ncoghlan): The following code attempts to make\n    # this class tolerant of the module nulling out process\n    # that happens during CPython interpreter shutdown\n    # Alas, it doesn't actually manage it. See issue #10188\n    _listdir = staticmethod(_os.listdir)\n    _path_join = staticmethod(_os.path.join)\n    _isdir = staticmethod(_os.path.isdir)\n    _islink = staticmethod(_os.path.islink)\n    _remove = staticmethod(_os.remove)\n    _rmdir = staticmethod(_os.rmdir)\n    _os_error = OSError\n    _warn = _warnings.warn\n\n    def _rmtree(self, path):\n        # Essentially a stripped down version of shutil.rmtree.  We can't\n        # use globals because they may be None'ed out at shutdown.\n        for name in self._listdir(path):\n            fullname = self._path_join(path, name)\n            try:\n                isdir = self._isdir(fullname) and not self._islink(fullname)\n            except self._os_error:\n                isdir = False\n            if isdir:\n                self._rmtree(fullname)\n            else:\n                try:\n                    self._remove(fullname)\n                except self._os_error:\n                    pass\n        try:\n            self._rmdir(path)\n        except self._os_error:\n            pass\n"], "base64": [".py", "#! /usr/bin/env python3\n\n\"\"\"RFC 3548: Base16, Base32, Base64 Data Encodings\"\"\"\n\n# Modified 04-Oct-1995 by Jack Jansen to use binascii module\n# Modified 30-Dec-2003 by Barry Warsaw to add full RFC 3548 support\n# Modified 22-May-2007 by Guido van Rossum to use bytes everywhere\n\nimport re\nimport struct\nimport binascii\n\n\n__all__ = [\n    # Legacy interface exports traditional RFC 1521 Base64 encodings\n    'encode', 'decode', 'encodebytes', 'decodebytes',\n    # Generalized interface for other encodings\n    'b64encode', 'b64decode', 'b32encode', 'b32decode',\n    'b16encode', 'b16decode',\n    # Standard Base64 encoding\n    'standard_b64encode', 'standard_b64decode',\n    # Some common Base64 alternatives.  As referenced by RFC 3458, see thread\n    # starting at:\n    #\n    # http://zgp.org/pipermail/p2p-hackers/2001-September/000316.html\n    'urlsafe_b64encode', 'urlsafe_b64decode',\n    ]\n\n\nbytes_types = (bytes, bytearray)  # Types acceptable as binary data\n\ndef _bytes_from_decode_data(s):\n    if isinstance(s, str):\n        try:\n            return s.encode('ascii')\n        except UnicodeEncodeError:\n            raise ValueError('string argument should contain only ASCII characters')\n    elif isinstance(s, bytes_types):\n        return s\n    else:\n        raise TypeError(\"argument should be bytes or ASCII string, not %s\" % s.__class__.__name__)\n\n\n\n# Base64 encoding/decoding uses binascii\n\ndef b64encode(s, altchars=None):\n    \"\"\"Encode a byte string using Base64.\n\n    s is the byte string to encode.  Optional altchars must be a byte\n    string of length 2 which specifies an alternative alphabet for the\n    '+' and '/' characters.  This allows an application to\n    e.g. generate url or filesystem safe Base64 strings.\n\n    The encoded byte string is returned.\n    \"\"\"\n    if not isinstance(s, bytes_types):\n        raise TypeError(\"expected bytes, not %s\" % s.__class__.__name__)\n    # Strip off the trailing newline\n    encoded = binascii.b2a_base64(s)[:-1]\n    if altchars is not None:\n        if not isinstance(altchars, bytes_types):\n            raise TypeError(\"expected bytes, not %s\"\n                            % altchars.__class__.__name__)\n        assert len(altchars) == 2, repr(altchars)\n        return encoded.translate(bytes.maketrans(b'+/', altchars))\n    return encoded\n\n\ndef b64decode(s, altchars=None, validate=False):\n    \"\"\"Decode a Base64 encoded byte string.\n\n    s is the byte string to decode.  Optional altchars must be a\n    string of length 2 which specifies the alternative alphabet used\n    instead of the '+' and '/' characters.\n\n    The decoded string is returned.  A binascii.Error is raised if s is\n    incorrectly padded.\n\n    If validate is False (the default), non-base64-alphabet characters are\n    discarded prior to the padding check.  If validate is True,\n    non-base64-alphabet characters in the input result in a binascii.Error.\n    \"\"\"\n    s = _bytes_from_decode_data(s)\n    if altchars is not None:\n        altchars = _bytes_from_decode_data(altchars)\n        assert len(altchars) == 2, repr(altchars)\n        s = s.translate(bytes.maketrans(altchars, b'+/'))\n    if validate and not re.match(b'^[A-Za-z0-9+/]*={0,2}$', s):\n        raise binascii.Error('Non-base64 digit found')\n    return binascii.a2b_base64(s)\n\n\ndef standard_b64encode(s):\n    \"\"\"Encode a byte string using the standard Base64 alphabet.\n\n    s is the byte string to encode.  The encoded byte string is returned.\n    \"\"\"\n    return b64encode(s)\n\ndef standard_b64decode(s):\n    \"\"\"Decode a byte string encoded with the standard Base64 alphabet.\n\n    s is the byte string to decode.  The decoded byte string is\n    returned.  binascii.Error is raised if the input is incorrectly\n    padded or if there are non-alphabet characters present in the\n    input.\n    \"\"\"\n    return b64decode(s)\n\n\n_urlsafe_encode_translation = bytes.maketrans(b'+/', b'-_')\n_urlsafe_decode_translation = bytes.maketrans(b'-_', b'+/')\n\ndef urlsafe_b64encode(s):\n    \"\"\"Encode a byte string using a url-safe Base64 alphabet.\n\n    s is the byte string to encode.  The encoded byte string is\n    returned.  The alphabet uses '-' instead of '+' and '_' instead of\n    '/'.\n    \"\"\"\n    return b64encode(s).translate(_urlsafe_encode_translation)\n\ndef urlsafe_b64decode(s):\n    \"\"\"Decode a byte string encoded with the standard Base64 alphabet.\n\n    s is the byte string to decode.  The decoded byte string is\n    returned.  binascii.Error is raised if the input is incorrectly\n    padded or if there are non-alphabet characters present in the\n    input.\n\n    The alphabet uses '-' instead of '+' and '_' instead of '/'.\n    \"\"\"\n    s = _bytes_from_decode_data(s)\n    s = s.translate(_urlsafe_decode_translation)\n    return b64decode(s)\n\n\n\n# Base32 encoding/decoding must be done in Python\n_b32alphabet = {\n    0: b'A',  9: b'J', 18: b'S', 27: b'3',\n    1: b'B', 10: b'K', 19: b'T', 28: b'4',\n    2: b'C', 11: b'L', 20: b'U', 29: b'5',\n    3: b'D', 12: b'M', 21: b'V', 30: b'6',\n    4: b'E', 13: b'N', 22: b'W', 31: b'7',\n    5: b'F', 14: b'O', 23: b'X',\n    6: b'G', 15: b'P', 24: b'Y',\n    7: b'H', 16: b'Q', 25: b'Z',\n    8: b'I', 17: b'R', 26: b'2',\n    }\n\n_b32tab = [v[0] for k, v in sorted(_b32alphabet.items())]\n_b32rev = dict([(v[0], k) for k, v in _b32alphabet.items()])\n\n\ndef b32encode(s):\n    \"\"\"Encode a byte string using Base32.\n\n    s is the byte string to encode.  The encoded byte string is returned.\n    \"\"\"\n    if not isinstance(s, bytes_types):\n        raise TypeError(\"expected bytes, not %s\" % s.__class__.__name__)\n    quanta, leftover = divmod(len(s), 5)\n    # Pad the last quantum with zero bits if necessary\n    if leftover:\n        s = s + bytes(5 - leftover)  # Don't use += !\n        quanta += 1\n    encoded = bytearray()\n    for i in range(quanta):\n        # c1 and c2 are 16 bits wide, c3 is 8 bits wide.  The intent of this\n        # code is to process the 40 bits in units of 5 bits.  So we take the 1\n        # leftover bit of c1 and tack it onto c2.  Then we take the 2 leftover\n        # bits of c2 and tack them onto c3.  The shifts and masks are intended\n        # to give us values of exactly 5 bits in width.\n        c1, c2, c3 = struct.unpack('!HHB', s[i*5:(i+1)*5])\n        c2 += (c1 & 1) << 16 # 17 bits wide\n        c3 += (c2 & 3) << 8  # 10 bits wide\n        encoded += bytes([_b32tab[c1 >> 11],         # bits 1 - 5\n                          _b32tab[(c1 >> 6) & 0x1f], # bits 6 - 10\n                          _b32tab[(c1 >> 1) & 0x1f], # bits 11 - 15\n                          _b32tab[c2 >> 12],         # bits 16 - 20 (1 - 5)\n                          _b32tab[(c2 >> 7) & 0x1f], # bits 21 - 25 (6 - 10)\n                          _b32tab[(c2 >> 2) & 0x1f], # bits 26 - 30 (11 - 15)\n                          _b32tab[c3 >> 5],          # bits 31 - 35 (1 - 5)\n                          _b32tab[c3 & 0x1f],        # bits 36 - 40 (1 - 5)\n                          ])\n    # Adjust for any leftover partial quanta\n    if leftover == 1:\n        encoded[-6:] = b'======'\n    elif leftover == 2:\n        encoded[-4:] = b'===='\n    elif leftover == 3:\n        encoded[-3:] = b'==='\n    elif leftover == 4:\n        encoded[-1:] = b'='\n    return bytes(encoded)\n\n\ndef b32decode(s, casefold=False, map01=None):\n    \"\"\"Decode a Base32 encoded byte string.\n\n    s is the byte string to decode.  Optional casefold is a flag\n    specifying whether a lowercase alphabet is acceptable as input.\n    For security purposes, the default is False.\n\n    RFC 3548 allows for optional mapping of the digit 0 (zero) to the\n    letter O (oh), and for optional mapping of the digit 1 (one) to\n    either the letter I (eye) or letter L (el).  The optional argument\n    map01 when not None, specifies which letter the digit 1 should be\n    mapped to (when map01 is not None, the digit 0 is always mapped to\n    the letter O).  For security purposes the default is None, so that\n    0 and 1 are not allowed in the input.\n\n    The decoded byte string is returned.  binascii.Error is raised if\n    the input is incorrectly padded or if there are non-alphabet\n    characters present in the input.\n    \"\"\"\n    s = _bytes_from_decode_data(s)\n    quanta, leftover = divmod(len(s), 8)\n    if leftover:\n        raise binascii.Error('Incorrect padding')\n    # Handle section 2.4 zero and one mapping.  The flag map01 will be either\n    # False, or the character to map the digit 1 (one) to.  It should be\n    # either L (el) or I (eye).\n    if map01 is not None:\n        map01 = _bytes_from_decode_data(map01)\n        assert len(map01) == 1, repr(map01)\n        s = s.translate(bytes.maketrans(b'01', b'O' + map01))\n    if casefold:\n        s = s.upper()\n    # Strip off pad characters from the right.  We need to count the pad\n    # characters because this will tell us how many null bytes to remove from\n    # the end of the decoded string.\n    padchars = 0\n    mo = re.search(b'(?P<pad>[=]*)$', s)\n    if mo:\n        padchars = len(mo.group('pad'))\n        if padchars > 0:\n            s = s[:-padchars]\n    # Now decode the full quanta\n    parts = []\n    acc = 0\n    shift = 35\n    for c in s:\n        val = _b32rev.get(c)\n        if val is None:\n            raise binascii.Error('Non-base32 digit found')\n        acc += _b32rev[c] << shift\n        shift -= 5\n        if shift < 0:\n            parts.append(binascii.unhexlify(bytes('%010x' % acc, \"ascii\")))\n            acc = 0\n            shift = 35\n    # Process the last, partial quanta\n    last = binascii.unhexlify(bytes('%010x' % acc, \"ascii\"))\n    if padchars == 0:\n        last = b''                      # No characters\n    elif padchars == 1:\n        last = last[:-1]\n    elif padchars == 3:\n        last = last[:-2]\n    elif padchars == 4:\n        last = last[:-3]\n    elif padchars == 6:\n        last = last[:-4]\n    else:\n        raise binascii.Error('Incorrect padding')\n    parts.append(last)\n    return b''.join(parts)\n\n\n\n# RFC 3548, Base 16 Alphabet specifies uppercase, but hexlify() returns\n# lowercase.  The RFC also recommends against accepting input case\n# insensitively.\ndef b16encode(s):\n    \"\"\"Encode a byte string using Base16.\n\n    s is the byte string to encode.  The encoded byte string is returned.\n    \"\"\"\n    if not isinstance(s, bytes_types):\n        raise TypeError(\"expected bytes, not %s\" % s.__class__.__name__)\n    return binascii.hexlify(s).upper()\n\n\ndef b16decode(s, casefold=False):\n    \"\"\"Decode a Base16 encoded byte string.\n\n    s is the byte string to decode.  Optional casefold is a flag\n    specifying whether a lowercase alphabet is acceptable as input.\n    For security purposes, the default is False.\n\n    The decoded byte string is returned.  binascii.Error is raised if\n    s were incorrectly padded or if there are non-alphabet characters\n    present in the string.\n    \"\"\"\n    s = _bytes_from_decode_data(s)\n    if casefold:\n        s = s.upper()\n    if re.search(b'[^0-9A-F]', s):\n        raise binascii.Error('Non-base16 digit found')\n    return binascii.unhexlify(s)\n\n\n\n# Legacy interface.  This code could be cleaned up since I don't believe\n# binascii has any line length limitations.  It just doesn't seem worth it\n# though.  The files should be opened in binary mode.\n\nMAXLINESIZE = 76 # Excluding the CRLF\nMAXBINSIZE = (MAXLINESIZE//4)*3\n\ndef encode(input, output):\n    \"\"\"Encode a file; input and output are binary files.\"\"\"\n    while True:\n        s = input.read(MAXBINSIZE)\n        if not s:\n            break\n        while len(s) < MAXBINSIZE:\n            ns = input.read(MAXBINSIZE-len(s))\n            if not ns:\n                break\n            s += ns\n        line = binascii.b2a_base64(s)\n        output.write(line)\n\n\ndef decode(input, output):\n    \"\"\"Decode a file; input and output are binary files.\"\"\"\n    while True:\n        line = input.readline()\n        if not line:\n            break\n        s = binascii.a2b_base64(line)\n        output.write(s)\n\n\ndef encodebytes(s):\n    \"\"\"Encode a bytestring into a bytestring containing multiple lines\n    of base-64 data.\"\"\"\n    if not isinstance(s, bytes_types):\n        raise TypeError(\"expected bytes, not %s\" % s.__class__.__name__)\n    pieces = []\n    for i in range(0, len(s), MAXBINSIZE):\n        chunk = s[i : i + MAXBINSIZE]\n        pieces.append(binascii.b2a_base64(chunk))\n    return b\"\".join(pieces)\n\ndef encodestring(s):\n    \"\"\"Legacy alias of encodebytes().\"\"\"\n    import warnings\n    warnings.warn(\"encodestring() is a deprecated alias, use encodebytes()\",\n                  DeprecationWarning, 2)\n    return encodebytes(s)\n\n\ndef decodebytes(s):\n    \"\"\"Decode a bytestring of base-64 data into a bytestring.\"\"\"\n    if not isinstance(s, bytes_types):\n        raise TypeError(\"expected bytes, not %s\" % s.__class__.__name__)\n    return binascii.a2b_base64(s)\n\ndef decodestring(s):\n    \"\"\"Legacy alias of decodebytes().\"\"\"\n    import warnings\n    warnings.warn(\"decodestring() is a deprecated alias, use decodebytes()\",\n                  DeprecationWarning, 2)\n    return decodebytes(s)\n\n\n# Usable as a script...\ndef main():\n    \"\"\"Small main program\"\"\"\n    import sys, getopt\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], 'deut')\n    except getopt.error as msg:\n        sys.stdout = sys.stderr\n        print(msg)\n        print(\"\"\"usage: %s [-d|-e|-u|-t] [file|-]\n        -d, -u: decode\n        -e: encode (default)\n        -t: encode and decode string 'Aladdin:open sesame'\"\"\"%sys.argv[0])\n        sys.exit(2)\n    func = encode\n    for o, a in opts:\n        if o == '-e': func = encode\n        if o == '-d': func = decode\n        if o == '-u': func = decode\n        if o == '-t': test(); return\n    if args and args[0] != '-':\n        with open(args[0], 'rb') as f:\n            func(f, sys.stdout.buffer)\n    else:\n        func(sys.stdin.buffer, sys.stdout.buffer)\n\n\ndef test():\n    s0 = b\"Aladdin:open sesame\"\n    print(repr(s0))\n    s1 = encodebytes(s0)\n    print(repr(s1))\n    s2 = decodebytes(s1)\n    print(repr(s2))\n    assert s0 == s2\n\n\nif __name__ == '__main__':\n    main()\n"], "platform": [".py", "#!/usr/bin/env python3\n\n\"\"\" This module tries to retrieve as much platform-identifying data as\n    possible. It makes this information available via function APIs.\n\n    If called from the command line, it prints the platform\n    information concatenated as single string to stdout. The output\n    format is useable as part of a filename.\n\n\"\"\"\n#    This module is maintained by Marc-Andre Lemburg <mal@egenix.com>.\n#    If you find problems, please submit bug reports/patches via the\n#    Python bug tracker (http://bugs.python.org) and assign them to \"lemburg\".\n#\n#    Still needed:\n#    * more support for WinCE\n#    * support for MS-DOS (PythonDX ?)\n#    * support for Amiga and other still unsupported platforms running Python\n#    * support for additional Linux distributions\n#\n#    Many thanks to all those who helped adding platform-specific\n#    checks (in no particular order):\n#\n#      Charles G Waldman, David Arnold, Gordon McMillan, Ben Darnell,\n#      Jeff Bauer, Cliff Crawford, Ivan Van Laningham, Josef\n#      Betancourt, Randall Hopper, Karl Putland, John Farrell, Greg\n#      Andruk, Just van Rossum, Thomas Heller, Mark R. Levinson, Mark\n#      Hammond, Bill Tutt, Hans Nowak, Uwe Zessin (OpenVMS support),\n#      Colin Kong, Trent Mick, Guido van Rossum, Anthony Baxter\n#\n#    History:\n#\n#    <see CVS and SVN checkin messages for history>\n#\n#    1.0.7 - added DEV_NULL\n#    1.0.6 - added linux_distribution()\n#    1.0.5 - fixed Java support to allow running the module on Jython\n#    1.0.4 - added IronPython support\n#    1.0.3 - added normalization of Windows system name\n#    1.0.2 - added more Windows support\n#    1.0.1 - reformatted to make doc.py happy\n#    1.0.0 - reformatted a bit and checked into Python CVS\n#    0.8.0 - added sys.version parser and various new access\n#            APIs (python_version(), python_compiler(), etc.)\n#    0.7.2 - fixed architecture() to use sizeof(pointer) where available\n#    0.7.1 - added support for Caldera OpenLinux\n#    0.7.0 - some fixes for WinCE; untabified the source file\n#    0.6.2 - support for OpenVMS - requires version 1.5.2-V006 or higher and\n#            vms_lib.getsyi() configured\n#    0.6.1 - added code to prevent 'uname -p' on platforms which are\n#            known not to support it\n#    0.6.0 - fixed win32_ver() to hopefully work on Win95,98,NT and Win2k;\n#            did some cleanup of the interfaces - some APIs have changed\n#    0.5.5 - fixed another type in the MacOS code... should have\n#            used more coffee today ;-)\n#    0.5.4 - fixed a few typos in the MacOS code\n#    0.5.3 - added experimental MacOS support; added better popen()\n#            workarounds in _syscmd_ver() -- still not 100% elegant\n#            though\n#    0.5.2 - fixed uname() to return '' instead of 'unknown' in all\n#            return values (the system uname command tends to return\n#            'unknown' instead of just leaving the field emtpy)\n#    0.5.1 - included code for slackware dist; added exception handlers\n#            to cover up situations where platforms don't have os.popen\n#            (e.g. Mac) or fail on socket.gethostname(); fixed libc\n#            detection RE\n#    0.5.0 - changed the API names referring to system commands to *syscmd*;\n#            added java_ver(); made syscmd_ver() a private\n#            API (was system_ver() in previous versions) -- use uname()\n#            instead; extended the win32_ver() to also return processor\n#            type information\n#    0.4.0 - added win32_ver() and modified the platform() output for WinXX\n#    0.3.4 - fixed a bug in _follow_symlinks()\n#    0.3.3 - fixed popen() and \"file\" command invokation bugs\n#    0.3.2 - added architecture() API and support for it in platform()\n#    0.3.1 - fixed syscmd_ver() RE to support Windows NT\n#    0.3.0 - added system alias support\n#    0.2.3 - removed 'wince' again... oh well.\n#    0.2.2 - added 'wince' to syscmd_ver() supported platforms\n#    0.2.1 - added cache logic and changed the platform string format\n#    0.2.0 - changed the API to use functions instead of module globals\n#            since some action take too long to be run on module import\n#    0.1.0 - first release\n#\n#    You can always get the latest version of this module at:\n#\n#             http://www.egenix.com/files/python/platform.py\n#\n#    If that URL should fail, try contacting the author.\n\n__copyright__ = \"\"\"\n    Copyright (c) 1999-2000, Marc-Andre Lemburg; mailto:mal@lemburg.com\n    Copyright (c) 2000-2010, eGenix.com Software GmbH; mailto:info@egenix.com\n\n    Permission to use, copy, modify, and distribute this software and its\n    documentation for any purpose and without fee or royalty is hereby granted,\n    provided that the above copyright notice appear in all copies and that\n    both that copyright notice and this permission notice appear in\n    supporting documentation or portions thereof, including modifications,\n    that you make.\n\n    EGENIX.COM SOFTWARE GMBH DISCLAIMS ALL WARRANTIES WITH REGARD TO\n    THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n    FITNESS, IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL,\n    INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING\n    FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,\n    NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION\n    WITH THE USE OR PERFORMANCE OF THIS SOFTWARE !\n\n\"\"\"\n\n__version__ = '1.0.7'\n\nimport collections\nimport sys, os, re, subprocess\n\n### Globals & Constants\n\n# Determine the platform's /dev/null device\ntry:\n    DEV_NULL = os.devnull\nexcept AttributeError:\n    # os.devnull was added in Python 2.4, so emulate it for earlier\n    # Python versions\n    if sys.platform in ('dos','win32','win16','os2'):\n        # Use the old CP/M NUL as device name\n        DEV_NULL = 'NUL'\n    else:\n        # Standard Unix uses /dev/null\n        DEV_NULL = '/dev/null'\n\n### Platform specific APIs\n\n_libc_search = re.compile(b'(__libc_init)'\n                          b'|'\n                          b'(GLIBC_([0-9.]+))'\n                          b'|'\n                          br'(libc(_\\w+)?\\.so(?:\\.(\\d[0-9.]*))?)', re.ASCII)\n\ndef libc_ver(executable=sys.executable,lib='',version='',\n\n             chunksize=16384):\n\n    \"\"\" Tries to determine the libc version that the file executable\n        (which defaults to the Python interpreter) is linked against.\n\n        Returns a tuple of strings (lib,version) which default to the\n        given parameters in case the lookup fails.\n\n        Note that the function has intimate knowledge of how different\n        libc versions add symbols to the executable and thus is probably\n        only useable for executables compiled using gcc.\n\n        The file is read and scanned in chunks of chunksize bytes.\n\n    \"\"\"\n    if hasattr(os.path, 'realpath'):\n        # Python 2.2 introduced os.path.realpath(); it is used\n        # here to work around problems with Cygwin not being\n        # able to open symlinks for reading\n        executable = os.path.realpath(executable)\n    f = open(executable,'rb')\n    binary = f.read(chunksize)\n    pos = 0\n    while 1:\n        if b'libc' in binary or b'GLIBC' in binary:\n            m = _libc_search.search(binary,pos)\n        else:\n            m = None\n        if not m:\n            binary = f.read(chunksize)\n            if not binary:\n                break\n            pos = 0\n            continue\n        libcinit,glibc,glibcversion,so,threads,soversion = [\n            s.decode('latin1') if s is not None else s\n            for s in m.groups()]\n        if libcinit and not lib:\n            lib = 'libc'\n        elif glibc:\n            if lib != 'glibc':\n                lib = 'glibc'\n                version = glibcversion\n            elif glibcversion > version:\n                version = glibcversion\n        elif so:\n            if lib != 'glibc':\n                lib = 'libc'\n                if soversion and soversion > version:\n                    version = soversion\n                if threads and version[-len(threads):] != threads:\n                    version = version + threads\n        pos = m.end()\n    f.close()\n    return lib,version\n\ndef _dist_try_harder(distname,version,id):\n\n    \"\"\" Tries some special tricks to get the distribution\n        information in case the default method fails.\n\n        Currently supports older SuSE Linux, Caldera OpenLinux and\n        Slackware Linux distributions.\n\n    \"\"\"\n    if os.path.exists('/var/adm/inst-log/info'):\n        # SuSE Linux stores distribution information in that file\n        distname = 'SuSE'\n        for line in open('/var/adm/inst-log/info'):\n            tv = line.split()\n            if len(tv) == 2:\n                tag,value = tv\n            else:\n                continue\n            if tag == 'MIN_DIST_VERSION':\n                version = value.strip()\n            elif tag == 'DIST_IDENT':\n                values = value.split('-')\n                id = values[2]\n        return distname,version,id\n\n    if os.path.exists('/etc/.installed'):\n        # Caldera OpenLinux has some infos in that file (thanks to Colin Kong)\n        for line in open('/etc/.installed'):\n            pkg = line.split('-')\n            if len(pkg) >= 2 and pkg[0] == 'OpenLinux':\n                # XXX does Caldera support non Intel platforms ? If yes,\n                #     where can we find the needed id ?\n                return 'OpenLinux',pkg[1],id\n\n    if os.path.isdir('/usr/lib/setup'):\n        # Check for slackware version tag file (thanks to Greg Andruk)\n        verfiles = os.listdir('/usr/lib/setup')\n        for n in range(len(verfiles)-1, -1, -1):\n            if verfiles[n][:14] != 'slack-version-':\n                del verfiles[n]\n        if verfiles:\n            verfiles.sort()\n            distname = 'slackware'\n            version = verfiles[-1][14:]\n            return distname,version,id\n\n    return distname,version,id\n\n_release_filename = re.compile(r'(\\w+)[-_](release|version)', re.ASCII)\n_lsb_release_version = re.compile(r'(.+)'\n                                   ' release '\n                                   '([\\d.]+)'\n                                   '[^(]*(?:\\((.+)\\))?', re.ASCII)\n_release_version = re.compile(r'([^0-9]+)'\n                               '(?: release )?'\n                               '([\\d.]+)'\n                               '[^(]*(?:\\((.+)\\))?', re.ASCII)\n\n# See also http://www.novell.com/coolsolutions/feature/11251.html\n# and http://linuxmafia.com/faq/Admin/release-files.html\n# and http://data.linux-ntfs.org/rpm/whichrpm\n# and http://www.die.net/doc/linux/man/man1/lsb_release.1.html\n\n_supported_dists = (\n    'SuSE', 'debian', 'fedora', 'redhat', 'centos',\n    'mandrake', 'mandriva', 'rocks', 'slackware', 'yellowdog', 'gentoo',\n    'UnitedLinux', 'turbolinux', 'arch', 'mageia')\n\ndef _parse_release_file(firstline):\n\n    # Default to empty 'version' and 'id' strings.  Both defaults are used\n    # when 'firstline' is empty.  'id' defaults to empty when an id can not\n    # be deduced.\n    version = ''\n    id = ''\n\n    # Parse the first line\n    m = _lsb_release_version.match(firstline)\n    if m is not None:\n        # LSB format: \"distro release x.x (codename)\"\n        return tuple(m.groups())\n\n    # Pre-LSB format: \"distro x.x (codename)\"\n    m = _release_version.match(firstline)\n    if m is not None:\n        return tuple(m.groups())\n\n    # Unknown format... take the first two words\n    l = firstline.strip().split()\n    if l:\n        version = l[0]\n        if len(l) > 1:\n            id = l[1]\n    return '', version, id\n\ndef linux_distribution(distname='', version='', id='',\n\n                       supported_dists=_supported_dists,\n                       full_distribution_name=1):\n\n    \"\"\" Tries to determine the name of the Linux OS distribution name.\n\n        The function first looks for a distribution release file in\n        /etc and then reverts to _dist_try_harder() in case no\n        suitable files are found.\n\n        supported_dists may be given to define the set of Linux\n        distributions to look for. It defaults to a list of currently\n        supported Linux distributions identified by their release file\n        name.\n\n        If full_distribution_name is true (default), the full\n        distribution read from the OS is returned. Otherwise the short\n        name taken from supported_dists is used.\n\n        Returns a tuple (distname,version,id) which default to the\n        args given as parameters.\n\n    \"\"\"\n    try:\n        etc = os.listdir('/etc')\n    except os.error:\n        # Probably not a Unix system\n        return distname,version,id\n    etc.sort()\n    for file in etc:\n        m = _release_filename.match(file)\n        if m is not None:\n            _distname,dummy = m.groups()\n            if _distname in supported_dists:\n                distname = _distname\n                break\n    else:\n        return _dist_try_harder(distname,version,id)\n\n    # Read the first line\n    with open('/etc/'+file, 'r') as f:\n        firstline = f.readline()\n    _distname, _version, _id = _parse_release_file(firstline)\n\n    if _distname and full_distribution_name:\n        distname = _distname\n    if _version:\n        version = _version\n    if _id:\n        id = _id\n    return distname, version, id\n\n# To maintain backwards compatibility:\n\ndef dist(distname='',version='',id='',\n\n         supported_dists=_supported_dists):\n\n    \"\"\" Tries to determine the name of the Linux OS distribution name.\n\n        The function first looks for a distribution release file in\n        /etc and then reverts to _dist_try_harder() in case no\n        suitable files are found.\n\n        Returns a tuple (distname,version,id) which default to the\n        args given as parameters.\n\n    \"\"\"\n    return linux_distribution(distname, version, id,\n                              supported_dists=supported_dists,\n                              full_distribution_name=0)\n\ndef popen(cmd, mode='r', bufsize=-1):\n\n    \"\"\" Portable popen() interface.\n    \"\"\"\n    import warnings\n    warnings.warn('use os.popen instead', DeprecationWarning, stacklevel=2)\n    return os.popen(cmd, mode, bufsize)\n\ndef _norm_version(version, build=''):\n\n    \"\"\" Normalize the version and build strings and return a single\n        version string using the format major.minor.build (or patchlevel).\n    \"\"\"\n    l = version.split('.')\n    if build:\n        l.append(build)\n    try:\n        ints = map(int,l)\n    except ValueError:\n        strings = l\n    else:\n        strings = list(map(str,ints))\n    version = '.'.join(strings[:3])\n    return version\n\n_ver_output = re.compile(r'(?:([\\w ]+) ([\\w.]+) '\n                         '.*'\n                         '\\[.* ([\\d.]+)\\])')\n\n# Examples of VER command output:\n#\n#   Windows 2000:  Microsoft Windows 2000 [Version 5.00.2195]\n#   Windows XP:    Microsoft Windows XP [Version 5.1.2600]\n#   Windows Vista: Microsoft Windows [Version 6.0.6002]\n#\n# Note that the \"Version\" string gets localized on different\n# Windows versions.\n\ndef _syscmd_ver(system='', release='', version='',\n\n               supported_platforms=('win32','win16','dos','os2')):\n\n    \"\"\" Tries to figure out the OS version used and returns\n        a tuple (system,release,version).\n\n        It uses the \"ver\" shell command for this which is known\n        to exists on Windows, DOS and OS/2. XXX Others too ?\n\n        In case this fails, the given parameters are used as\n        defaults.\n\n    \"\"\"\n    if sys.platform not in supported_platforms:\n        return system,release,version\n\n    # Try some common cmd strings\n    for cmd in ('ver','command /c ver','cmd /c ver'):\n        try:\n            pipe = popen(cmd)\n            info = pipe.read()\n            if pipe.close():\n                raise os.error('command failed')\n            # XXX How can I suppress shell errors from being written\n            #     to stderr ?\n        except os.error as why:\n            #print 'Command %s failed: %s' % (cmd,why)\n            continue\n        except IOError as why:\n            #print 'Command %s failed: %s' % (cmd,why)\n            continue\n        else:\n            break\n    else:\n        return system,release,version\n\n    # Parse the output\n    info = info.strip()\n    m = _ver_output.match(info)\n    if m is not None:\n        system,release,version = m.groups()\n        # Strip trailing dots from version and release\n        if release[-1] == '.':\n            release = release[:-1]\n        if version[-1] == '.':\n            version = version[:-1]\n        # Normalize the version and build strings (eliminating additional\n        # zeros)\n        version = _norm_version(version)\n    return system,release,version\n\ndef _win32_getvalue(key,name,default=''):\n\n    \"\"\" Read a value for name from the registry key.\n\n        In case this fails, default is returned.\n\n    \"\"\"\n    try:\n        # Use win32api if available\n        from win32api import RegQueryValueEx\n    except ImportError:\n        # On Python 2.0 and later, emulate using winreg\n        import winreg\n        RegQueryValueEx = winreg.QueryValueEx\n    try:\n        return RegQueryValueEx(key,name)\n    except:\n        return default\n\ndef win32_ver(release='',version='',csd='',ptype=''):\n\n    \"\"\" Get additional version information from the Windows Registry\n        and return a tuple (version,csd,ptype) referring to version\n        number, CSD level (service pack), and OS type (multi/single\n        processor).\n\n        As a hint: ptype returns 'Uniprocessor Free' on single\n        processor NT machines and 'Multiprocessor Free' on multi\n        processor machines. The 'Free' refers to the OS version being\n        free of debugging code. It could also state 'Checked' which\n        means the OS version uses debugging code, i.e. code that\n        checks arguments, ranges, etc. (Thomas Heller).\n\n        Note: this function works best with Mark Hammond's win32\n        package installed, but also on Python 2.3 and later. It\n        obviously only runs on Win32 compatible platforms.\n\n    \"\"\"\n    # XXX Is there any way to find out the processor type on WinXX ?\n    # XXX Is win32 available on Windows CE ?\n    #\n    # Adapted from code posted by Karl Putland to comp.lang.python.\n    #\n    # The mappings between reg. values and release names can be found\n    # here: http://msdn.microsoft.com/library/en-us/sysinfo/base/osversioninfo_str.asp\n\n    # Import the needed APIs\n    try:\n        import win32api\n        from win32api import RegQueryValueEx, RegOpenKeyEx, \\\n             RegCloseKey, GetVersionEx\n        from win32con import HKEY_LOCAL_MACHINE, VER_PLATFORM_WIN32_NT, \\\n             VER_PLATFORM_WIN32_WINDOWS, VER_NT_WORKSTATION\n    except ImportError:\n        # Emulate the win32api module using Python APIs\n        try:\n            sys.getwindowsversion\n        except AttributeError:\n            # No emulation possible, so return the defaults...\n            return release,version,csd,ptype\n        else:\n            # Emulation using winreg (added in Python 2.0) and\n            # sys.getwindowsversion() (added in Python 2.3)\n            import winreg\n            GetVersionEx = sys.getwindowsversion\n            RegQueryValueEx = winreg.QueryValueEx\n            RegOpenKeyEx = winreg.OpenKeyEx\n            RegCloseKey = winreg.CloseKey\n            HKEY_LOCAL_MACHINE = winreg.HKEY_LOCAL_MACHINE\n            VER_PLATFORM_WIN32_WINDOWS = 1\n            VER_PLATFORM_WIN32_NT = 2\n            VER_NT_WORKSTATION = 1\n            VER_NT_SERVER = 3\n            REG_SZ = 1\n\n    # Find out the registry key and some general version infos\n    winver = GetVersionEx()\n    maj,min,buildno,plat,csd = winver\n    version = '%i.%i.%i' % (maj,min,buildno & 0xFFFF)\n    if hasattr(winver, \"service_pack\"):\n        if winver.service_pack != \"\":\n            csd = 'SP%s' % winver.service_pack_major\n    else:\n        if csd[:13] == 'Service Pack ':\n            csd = 'SP' + csd[13:]\n\n    if plat == VER_PLATFORM_WIN32_WINDOWS:\n        regkey = 'SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion'\n        # Try to guess the release name\n        if maj == 4:\n            if min == 0:\n                release = '95'\n            elif min == 10:\n                release = '98'\n            elif min == 90:\n                release = 'Me'\n            else:\n                release = 'postMe'\n        elif maj == 5:\n            release = '2000'\n\n    elif plat == VER_PLATFORM_WIN32_NT:\n        regkey = 'SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion'\n        if maj <= 4:\n            release = 'NT'\n        elif maj == 5:\n            if min == 0:\n                release = '2000'\n            elif min == 1:\n                release = 'XP'\n            elif min == 2:\n                release = '2003Server'\n            else:\n                release = 'post2003'\n        elif maj == 6:\n            if hasattr(winver, \"product_type\"):\n                product_type = winver.product_type\n            else:\n                product_type = VER_NT_WORKSTATION\n                # Without an OSVERSIONINFOEX capable sys.getwindowsversion(),\n                # or help from the registry, we cannot properly identify\n                # non-workstation versions.\n                try:\n                    key = RegOpenKeyEx(HKEY_LOCAL_MACHINE, regkey)\n                    name, type = RegQueryValueEx(key, \"ProductName\")\n                    # Discard any type that isn't REG_SZ\n                    if type == REG_SZ and name.find(\"Server\") != -1:\n                        product_type = VER_NT_SERVER\n                except WindowsError:\n                    # Use default of VER_NT_WORKSTATION\n                    pass\n\n            if min == 0:\n                if product_type == VER_NT_WORKSTATION:\n                    release = 'Vista'\n                else:\n                    release = '2008Server'\n            elif min == 1:\n                if product_type == VER_NT_WORKSTATION:\n                    release = '7'\n                else:\n                    release = '2008ServerR2'\n            elif min == 2:\n                if product_type == VER_NT_WORKSTATION:\n                    release = '8'\n                else:\n                    release = '2012Server'\n            else:\n                release = 'post2012Server'\n\n    else:\n        if not release:\n            # E.g. Win3.1 with win32s\n            release = '%i.%i' % (maj,min)\n        return release,version,csd,ptype\n\n    # Open the registry key\n    try:\n        keyCurVer = RegOpenKeyEx(HKEY_LOCAL_MACHINE, regkey)\n        # Get a value to make sure the key exists...\n        RegQueryValueEx(keyCurVer, 'SystemRoot')\n    except:\n        return release,version,csd,ptype\n\n    # Parse values\n    #subversion = _win32_getvalue(keyCurVer,\n    #                            'SubVersionNumber',\n    #                            ('',1))[0]\n    #if subversion:\n    #   release = release + subversion # 95a, 95b, etc.\n    build = _win32_getvalue(keyCurVer,\n                            'CurrentBuildNumber',\n                            ('',1))[0]\n    ptype = _win32_getvalue(keyCurVer,\n                           'CurrentType',\n                           (ptype,1))[0]\n\n    # Normalize version\n    version = _norm_version(version,build)\n\n    # Close key\n    RegCloseKey(keyCurVer)\n    return release,version,csd,ptype\n\ndef _mac_ver_lookup(selectors,default=None):\n\n    from _gestalt import gestalt\n    l = []\n    append = l.append\n    for selector in selectors:\n        try:\n            append(gestalt(selector))\n        except (RuntimeError, OSError):\n            append(default)\n    return l\n\ndef _bcd2str(bcd):\n\n    return hex(bcd)[2:]\n\ndef _mac_ver_gestalt():\n    \"\"\"\n        Thanks to Mark R. Levinson for mailing documentation links and\n        code examples for this function. Documentation for the\n        gestalt() API is available online at:\n\n           http://www.rgaros.nl/gestalt/\n    \"\"\"\n    # Check whether the version info module is available\n    try:\n        import _gestalt\n    except ImportError:\n        return None\n    # Get the infos\n    sysv, sysa = _mac_ver_lookup(('sysv','sysa'))\n    # Decode the infos\n    if sysv:\n        major = (sysv & 0xFF00) >> 8\n        minor = (sysv & 0x00F0) >> 4\n        patch = (sysv & 0x000F)\n\n        if (major, minor) >= (10, 4):\n            # the 'sysv' gestald cannot return patchlevels\n            # higher than 9. Apple introduced 3 new\n            # gestalt codes in 10.4 to deal with this\n            # issue (needed because patch levels can\n            # run higher than 9, such as 10.4.11)\n            major,minor,patch = _mac_ver_lookup(('sys1','sys2','sys3'))\n            release = '%i.%i.%i' %(major, minor, patch)\n        else:\n            release = '%s.%i.%i' % (_bcd2str(major),minor,patch)\n\n    if sysa:\n        machine = {0x1: '68k',\n                   0x2: 'PowerPC',\n                   0xa: 'i386'}.get(sysa,'')\n\n    versioninfo=('', '', '')\n    return release,versioninfo,machine\n\ndef _mac_ver_xml():\n    fn = '/System/Library/CoreServices/SystemVersion.plist'\n    if not os.path.exists(fn):\n        return None\n\n    try:\n        import plistlib\n    except ImportError:\n        return None\n\n    pl = plistlib.readPlist(fn)\n    release = pl['ProductVersion']\n    versioninfo=('', '', '')\n    machine = os.uname().machine\n    if machine in ('ppc', 'Power Macintosh'):\n        # for compatibility with the gestalt based code\n        machine = 'PowerPC'\n\n    return release,versioninfo,machine\n\n\ndef mac_ver(release='',versioninfo=('','',''),machine=''):\n\n    \"\"\" Get MacOS version information and return it as tuple (release,\n        versioninfo, machine) with versioninfo being a tuple (version,\n        dev_stage, non_release_version).\n\n        Entries which cannot be determined are set to the parameter values\n        which default to ''. All tuple entries are strings.\n    \"\"\"\n\n    # First try reading the information from an XML file which should\n    # always be present\n    info = _mac_ver_xml()\n    if info is not None:\n        return info\n\n    # If that doesn't work for some reason fall back to reading the\n    # information using gestalt calls.\n    info = _mac_ver_gestalt()\n    if info is not None:\n        return info\n\n    # If that also doesn't work return the default values\n    return release,versioninfo,machine\n\ndef _java_getprop(name,default):\n\n    from java.lang import System\n    try:\n        value = System.getProperty(name)\n        if value is None:\n            return default\n        return value\n    except AttributeError:\n        return default\n\ndef java_ver(release='',vendor='',vminfo=('','',''),osinfo=('','','')):\n\n    \"\"\" Version interface for Jython.\n\n        Returns a tuple (release,vendor,vminfo,osinfo) with vminfo being\n        a tuple (vm_name,vm_release,vm_vendor) and osinfo being a\n        tuple (os_name,os_version,os_arch).\n\n        Values which cannot be determined are set to the defaults\n        given as parameters (which all default to '').\n\n    \"\"\"\n    # Import the needed APIs\n    try:\n        import java.lang\n    except ImportError:\n        return release,vendor,vminfo,osinfo\n\n    vendor = _java_getprop('java.vendor', vendor)\n    release = _java_getprop('java.version', release)\n    vm_name, vm_release, vm_vendor = vminfo\n    vm_name = _java_getprop('java.vm.name', vm_name)\n    vm_vendor = _java_getprop('java.vm.vendor', vm_vendor)\n    vm_release = _java_getprop('java.vm.version', vm_release)\n    vminfo = vm_name, vm_release, vm_vendor\n    os_name, os_version, os_arch = osinfo\n    os_arch = _java_getprop('java.os.arch', os_arch)\n    os_name = _java_getprop('java.os.name', os_name)\n    os_version = _java_getprop('java.os.version', os_version)\n    osinfo = os_name, os_version, os_arch\n\n    return release, vendor, vminfo, osinfo\n\n### System name aliasing\n\ndef system_alias(system,release,version):\n\n    \"\"\" Returns (system,release,version) aliased to common\n        marketing names used for some systems.\n\n        It also does some reordering of the information in some cases\n        where it would otherwise cause confusion.\n\n    \"\"\"\n    if system == 'Rhapsody':\n        # Apple's BSD derivative\n        # XXX How can we determine the marketing release number ?\n        return 'MacOS X Server',system+release,version\n\n    elif system == 'SunOS':\n        # Sun's OS\n        if release < '5':\n            # These releases use the old name SunOS\n            return system,release,version\n        # Modify release (marketing release = SunOS release - 3)\n        l = release.split('.')\n        if l:\n            try:\n                major = int(l[0])\n            except ValueError:\n                pass\n            else:\n                major = major - 3\n                l[0] = str(major)\n                release = '.'.join(l)\n        if release < '6':\n            system = 'Solaris'\n        else:\n            # XXX Whatever the new SunOS marketing name is...\n            system = 'Solaris'\n\n    elif system == 'IRIX64':\n        # IRIX reports IRIX64 on platforms with 64-bit support; yet it\n        # is really a version and not a different platform, since 32-bit\n        # apps are also supported..\n        system = 'IRIX'\n        if version:\n            version = version + ' (64bit)'\n        else:\n            version = '64bit'\n\n    elif system in ('win32','win16'):\n        # In case one of the other tricks\n        system = 'Windows'\n\n    return system,release,version\n\n### Various internal helpers\n\ndef _platform(*args):\n\n    \"\"\" Helper to format the platform string in a filename\n        compatible format e.g. \"system-version-machine\".\n    \"\"\"\n    # Format the platform string\n    platform = '-'.join(x.strip() for x in filter(len, args))\n\n    # Cleanup some possible filename obstacles...\n    platform = platform.replace(' ','_')\n    platform = platform.replace('/','-')\n    platform = platform.replace('\\\\','-')\n    platform = platform.replace(':','-')\n    platform = platform.replace(';','-')\n    platform = platform.replace('\"','-')\n    platform = platform.replace('(','-')\n    platform = platform.replace(')','-')\n\n    # No need to report 'unknown' information...\n    platform = platform.replace('unknown','')\n\n    # Fold '--'s and remove trailing '-'\n    while 1:\n        cleaned = platform.replace('--','-')\n        if cleaned == platform:\n            break\n        platform = cleaned\n    while platform[-1] == '-':\n        platform = platform[:-1]\n\n    return platform\n\ndef _node(default=''):\n\n    \"\"\" Helper to determine the node name of this machine.\n    \"\"\"\n    try:\n        import socket\n    except ImportError:\n        # No sockets...\n        return default\n    try:\n        return socket.gethostname()\n    except socket.error:\n        # Still not working...\n        return default\n\ndef _follow_symlinks(filepath):\n\n    \"\"\" In case filepath is a symlink, follow it until a\n        real file is reached.\n    \"\"\"\n    filepath = os.path.abspath(filepath)\n    while os.path.islink(filepath):\n        filepath = os.path.normpath(\n            os.path.join(os.path.dirname(filepath),os.readlink(filepath)))\n    return filepath\n\ndef _syscmd_uname(option,default=''):\n\n    \"\"\" Interface to the system's uname command.\n    \"\"\"\n    if sys.platform in ('dos','win32','win16','os2'):\n        # XXX Others too ?\n        return default\n    try:\n        f = os.popen('uname %s 2> %s' % (option, DEV_NULL))\n    except (AttributeError,os.error):\n        return default\n    output = f.read().strip()\n    rc = f.close()\n    if not output or rc:\n        return default\n    else:\n        return output\n\ndef _syscmd_file(target,default=''):\n\n    \"\"\" Interface to the system's file command.\n\n        The function uses the -b option of the file command to have it\n        omit the filename in its output. Follow the symlinks. It returns\n        default in case the command should fail.\n\n    \"\"\"\n    if sys.platform in ('dos','win32','win16','os2'):\n        # XXX Others too ?\n        return default\n    target = _follow_symlinks(target)\n    try:\n        proc = subprocess.Popen(['file', target],\n                stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n\n    except (AttributeError,os.error):\n        return default\n    output = proc.communicate()[0].decode('latin-1')\n    rc = proc.wait()\n    if not output or rc:\n        return default\n    else:\n        return output\n\n### Information about the used architecture\n\n# Default values for architecture; non-empty strings override the\n# defaults given as parameters\n_default_architecture = {\n    'win32': ('','WindowsPE'),\n    'win16': ('','Windows'),\n    'dos': ('','MSDOS'),\n}\n\ndef architecture(executable=sys.executable,bits='',linkage=''):\n\n    \"\"\" Queries the given executable (defaults to the Python interpreter\n        binary) for various architecture information.\n\n        Returns a tuple (bits,linkage) which contains information about\n        the bit architecture and the linkage format used for the\n        executable. Both values are returned as strings.\n\n        Values that cannot be determined are returned as given by the\n        parameter presets. If bits is given as '', the sizeof(pointer)\n        (or sizeof(long) on Python version < 1.5.2) is used as\n        indicator for the supported pointer size.\n\n        The function relies on the system's \"file\" command to do the\n        actual work. This is available on most if not all Unix\n        platforms. On some non-Unix platforms where the \"file\" command\n        does not exist and the executable is set to the Python interpreter\n        binary defaults from _default_architecture are used.\n\n    \"\"\"\n    # Use the sizeof(pointer) as default number of bits if nothing\n    # else is given as default.\n    if not bits:\n        import struct\n        try:\n            size = struct.calcsize('P')\n        except struct.error:\n            # Older installations can only query longs\n            size = struct.calcsize('l')\n        bits = str(size*8) + 'bit'\n\n    # Get data from the 'file' system command\n    if executable:\n        fileout = _syscmd_file(executable, '')\n    else:\n        fileout = ''\n\n    if not fileout and \\\n       executable == sys.executable:\n        # \"file\" command did not return anything; we'll try to provide\n        # some sensible defaults then...\n        if sys.platform in _default_architecture:\n            b,l = _default_architecture[sys.platform]\n            if b:\n                bits = b\n            if l:\n                linkage = l\n        return bits,linkage\n\n    if 'executable' not in fileout:\n        # Format not supported\n        return bits,linkage\n\n    # Bits\n    if '32-bit' in fileout:\n        bits = '32bit'\n    elif 'N32' in fileout:\n        # On Irix only\n        bits = 'n32bit'\n    elif '64-bit' in fileout:\n        bits = '64bit'\n\n    # Linkage\n    if 'ELF' in fileout:\n        linkage = 'ELF'\n    elif 'PE' in fileout:\n        # E.g. Windows uses this format\n        if 'Windows' in fileout:\n            linkage = 'WindowsPE'\n        else:\n            linkage = 'PE'\n    elif 'COFF' in fileout:\n        linkage = 'COFF'\n    elif 'MS-DOS' in fileout:\n        linkage = 'MSDOS'\n    else:\n        # XXX the A.OUT format also falls under this class...\n        pass\n\n    return bits,linkage\n\n### Portable uname() interface\n\nuname_result = collections.namedtuple(\"uname_result\",\n                    \"system node release version machine processor\")\n\n_uname_cache = None\n\ndef uname():\n\n    \"\"\" Fairly portable uname interface. Returns a tuple\n        of strings (system,node,release,version,machine,processor)\n        identifying the underlying platform.\n\n        Note that unlike the os.uname function this also returns\n        possible processor information as an additional tuple entry.\n\n        Entries which cannot be determined are set to ''.\n\n    \"\"\"\n    global _uname_cache\n    no_os_uname = 0\n\n    if _uname_cache is not None:\n        return _uname_cache\n\n    processor = ''\n\n    # Get some infos from the builtin os.uname API...\n    try:\n        system,node,release,version,machine = os.uname()\n    except AttributeError:\n        no_os_uname = 1\n\n    if no_os_uname or not list(filter(None, (system, node, release, version, machine))):\n        # Hmm, no there is either no uname or uname has returned\n        #'unknowns'... we'll have to poke around the system then.\n        if no_os_uname:\n            system = sys.platform\n            release = ''\n            version = ''\n            node = _node()\n            machine = ''\n\n        use_syscmd_ver = 1\n\n        # Try win32_ver() on win32 platforms\n        if system == 'win32':\n            release,version,csd,ptype = win32_ver()\n            if release and version:\n                use_syscmd_ver = 0\n            # Try to use the PROCESSOR_* environment variables\n            # available on Win XP and later; see\n            # http://support.microsoft.com/kb/888731 and\n            # http://www.geocities.com/rick_lively/MANUALS/ENV/MSWIN/PROCESSI.HTM\n            if not machine:\n                # WOW64 processes mask the native architecture\n                if \"PROCESSOR_ARCHITEW6432\" in os.environ:\n                    machine = os.environ.get(\"PROCESSOR_ARCHITEW6432\", '')\n                else:\n                    machine = os.environ.get('PROCESSOR_ARCHITECTURE', '')\n            if not processor:\n                processor = os.environ.get('PROCESSOR_IDENTIFIER', machine)\n\n        # Try the 'ver' system command available on some\n        # platforms\n        if use_syscmd_ver:\n            system,release,version = _syscmd_ver(system)\n            # Normalize system to what win32_ver() normally returns\n            # (_syscmd_ver() tends to return the vendor name as well)\n            if system == 'Microsoft Windows':\n                system = 'Windows'\n            elif system == 'Microsoft' and release == 'Windows':\n                # Under Windows Vista and Windows Server 2008,\n                # Microsoft changed the output of the ver command. The\n                # release is no longer printed.  This causes the\n                # system and release to be misidentified.\n                system = 'Windows'\n                if '6.0' == version[:3]:\n                    release = 'Vista'\n                else:\n                    release = ''\n\n        # In case we still don't know anything useful, we'll try to\n        # help ourselves\n        if system in ('win32','win16'):\n            if not version:\n                if system == 'win32':\n                    version = '32bit'\n                else:\n                    version = '16bit'\n            system = 'Windows'\n\n        elif system[:4] == 'java':\n            release,vendor,vminfo,osinfo = java_ver()\n            system = 'Java'\n            version = ', '.join(vminfo)\n            if not version:\n                version = vendor\n\n    # System specific extensions\n    if system == 'OpenVMS':\n        # OpenVMS seems to have release and version mixed up\n        if not release or release == '0':\n            release = version\n            version = ''\n        # Get processor information\n        try:\n            import vms_lib\n        except ImportError:\n            pass\n        else:\n            csid, cpu_number = vms_lib.getsyi('SYI$_CPU',0)\n            if (cpu_number >= 128):\n                processor = 'Alpha'\n            else:\n                processor = 'VAX'\n    if not processor:\n        # Get processor information from the uname system command\n        processor = _syscmd_uname('-p','')\n\n    #If any unknowns still exist, replace them with ''s, which are more portable\n    if system == 'unknown':\n        system = ''\n    if node == 'unknown':\n        node = ''\n    if release == 'unknown':\n        release = ''\n    if version == 'unknown':\n        version = ''\n    if machine == 'unknown':\n        machine = ''\n    if processor == 'unknown':\n        processor = ''\n\n    #  normalize name\n    if system == 'Microsoft' and release == 'Windows':\n        system = 'Windows'\n        release = 'Vista'\n\n    _uname_cache = uname_result(system,node,release,version,machine,processor)\n    return _uname_cache\n\n### Direct interfaces to some of the uname() return values\n\ndef system():\n\n    \"\"\" Returns the system/OS name, e.g. 'Linux', 'Windows' or 'Java'.\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().system\n\ndef node():\n\n    \"\"\" Returns the computer's network name (which may not be fully\n        qualified)\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().node\n\ndef release():\n\n    \"\"\" Returns the system's release, e.g. '2.2.0' or 'NT'\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().release\n\ndef version():\n\n    \"\"\" Returns the system's release version, e.g. '#3 on degas'\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().version\n\ndef machine():\n\n    \"\"\" Returns the machine type, e.g. 'i386'\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().machine\n\ndef processor():\n\n    \"\"\" Returns the (true) processor name, e.g. 'amdk6'\n\n        An empty string is returned if the value cannot be\n        determined. Note that many platforms do not provide this\n        information or simply return the same value as for machine(),\n        e.g.  NetBSD does this.\n\n    \"\"\"\n    return uname().processor\n\n### Various APIs for extracting information from sys.version\n\n_sys_version_parser = re.compile(\n    r'([\\w.+]+)\\s*'\n    '\\(#?([^,]+),\\s*([\\w ]+),\\s*([\\w :]+)\\)\\s*'\n    '\\[([^\\]]+)\\]?', re.ASCII)\n\n_ironpython_sys_version_parser = re.compile(\n    r'IronPython\\s*'\n    '([\\d\\.]+)'\n    '(?: \\(([\\d\\.]+)\\))?'\n    ' on (.NET [\\d\\.]+)', re.ASCII)\n\n# IronPython covering 2.6 and 2.7\n_ironpython26_sys_version_parser = re.compile(\n    r'([\\d.]+)\\s*'\n    '\\(IronPython\\s*'\n    '[\\d.]+\\s*'\n    '\\(([\\d.]+)\\) on ([\\w.]+ [\\d.]+(?: \\(\\d+-bit\\))?)\\)'\n)\n\n_pypy_sys_version_parser = re.compile(\n    r'([\\w.+]+)\\s*'\n    '\\(#?([^,]+),\\s*([\\w ]+),\\s*([\\w :]+)\\)\\s*'\n    '\\[PyPy [^\\]]+\\]?')\n\n_sys_version_cache = {}\n\ndef _sys_version(sys_version=None):\n\n    \"\"\" Returns a parsed version of Python's sys.version as tuple\n        (name, version, branch, revision, buildno, builddate, compiler)\n        referring to the Python implementation name, version, branch,\n        revision, build number, build date/time as string and the compiler\n        identification string.\n\n        Note that unlike the Python sys.version, the returned value\n        for the Python version will always include the patchlevel (it\n        defaults to '.0').\n\n        The function returns empty strings for tuple entries that\n        cannot be determined.\n\n        sys_version may be given to parse an alternative version\n        string, e.g. if the version was read from a different Python\n        interpreter.\n\n    \"\"\"\n    # Get the Python version\n    if sys_version is None:\n        sys_version = sys.version\n\n    # Try the cache first\n    result = _sys_version_cache.get(sys_version, None)\n    if result is not None:\n        return result\n\n    # Parse it\n    if 'IronPython' in sys_version:\n        # IronPython\n        name = 'IronPython'\n        if sys_version.startswith('IronPython'):\n            match = _ironpython_sys_version_parser.match(sys_version)\n        else:\n            match = _ironpython26_sys_version_parser.match(sys_version)\n\n        if match is None:\n            raise ValueError(\n                'failed to parse IronPython sys.version: %s' %\n                repr(sys_version))\n\n        version, alt_version, compiler = match.groups()\n        buildno = ''\n        builddate = ''\n\n    elif sys.platform.startswith('java'):\n        # Jython\n        name = 'Jython'\n        match = _sys_version_parser.match(sys_version)\n        if match is None:\n            raise ValueError(\n                'failed to parse Jython sys.version: %s' %\n                repr(sys_version))\n        version, buildno, builddate, buildtime, _ = match.groups()\n        compiler = sys.platform\n\n    elif \"PyPy\" in sys_version:\n        # PyPy\n        name = \"PyPy\"\n        match = _pypy_sys_version_parser.match(sys_version)\n        if match is None:\n            raise ValueError(\"failed to parse PyPy sys.version: %s\" %\n                             repr(sys_version))\n        version, buildno, builddate, buildtime = match.groups()\n        compiler = \"\"\n\n    else:\n        # CPython\n        match = _sys_version_parser.match(sys_version)\n        if match is None:\n            raise ValueError(\n                'failed to parse CPython sys.version: %s' %\n                repr(sys_version))\n        version, buildno, builddate, buildtime, compiler = \\\n              match.groups()\n        name = 'CPython'\n        builddate = builddate + ' ' + buildtime\n\n    if hasattr(sys, '_mercurial'):\n        _, branch, revision = sys._mercurial\n    elif hasattr(sys, 'subversion'):\n        # sys.subversion was added in Python 2.5\n        _, branch, revision = sys.subversion\n    else:\n        branch = ''\n        revision = ''\n\n    # Add the patchlevel version if missing\n    l = version.split('.')\n    if len(l) == 2:\n        l.append('0')\n        version = '.'.join(l)\n\n    # Build and cache the result\n    result = (name, version, branch, revision, buildno, builddate, compiler)\n    _sys_version_cache[sys_version] = result\n    return result\n\ndef python_implementation():\n\n    \"\"\" Returns a string identifying the Python implementation.\n\n        Currently, the following implementations are identified:\n          'CPython' (C implementation of Python),\n          'IronPython' (.NET implementation of Python),\n          'Jython' (Java implementation of Python),\n          'PyPy' (Python implementation of Python).\n\n    \"\"\"\n    return _sys_version()[0]\n\ndef python_version():\n\n    \"\"\" Returns the Python version as string 'major.minor.patchlevel'\n\n        Note that unlike the Python sys.version, the returned value\n        will always include the patchlevel (it defaults to 0).\n\n    \"\"\"\n    return _sys_version()[1]\n\ndef python_version_tuple():\n\n    \"\"\" Returns the Python version as tuple (major, minor, patchlevel)\n        of strings.\n\n        Note that unlike the Python sys.version, the returned value\n        will always include the patchlevel (it defaults to 0).\n\n    \"\"\"\n    return tuple(_sys_version()[1].split('.'))\n\ndef python_branch():\n\n    \"\"\" Returns a string identifying the Python implementation\n        branch.\n\n        For CPython this is the Subversion branch from which the\n        Python binary was built.\n\n        If not available, an empty string is returned.\n\n    \"\"\"\n\n    return _sys_version()[2]\n\ndef python_revision():\n\n    \"\"\" Returns a string identifying the Python implementation\n        revision.\n\n        For CPython this is the Subversion revision from which the\n        Python binary was built.\n\n        If not available, an empty string is returned.\n\n    \"\"\"\n    return _sys_version()[3]\n\ndef python_build():\n\n    \"\"\" Returns a tuple (buildno, builddate) stating the Python\n        build number and date as strings.\n\n    \"\"\"\n    return _sys_version()[4:6]\n\ndef python_compiler():\n\n    \"\"\" Returns a string identifying the compiler used for compiling\n        Python.\n\n    \"\"\"\n    return _sys_version()[6]\n\n### The Opus Magnum of platform strings :-)\n\n_platform_cache = {}\n\ndef platform(aliased=0, terse=0):\n\n    \"\"\" Returns a single string identifying the underlying platform\n        with as much useful information as possible (but no more :).\n\n        The output is intended to be human readable rather than\n        machine parseable. It may look different on different\n        platforms and this is intended.\n\n        If \"aliased\" is true, the function will use aliases for\n        various platforms that report system names which differ from\n        their common names, e.g. SunOS will be reported as\n        Solaris. The system_alias() function is used to implement\n        this.\n\n        Setting terse to true causes the function to return only the\n        absolute minimum information needed to identify the platform.\n\n    \"\"\"\n    result = _platform_cache.get((aliased, terse), None)\n    if result is not None:\n        return result\n\n    # Get uname information and then apply platform specific cosmetics\n    # to it...\n    system,node,release,version,machine,processor = uname()\n    if machine == processor:\n        processor = ''\n    if aliased:\n        system,release,version = system_alias(system,release,version)\n\n    if system == 'Windows':\n        # MS platforms\n        rel,vers,csd,ptype = win32_ver(version)\n        if terse:\n            platform = _platform(system,release)\n        else:\n            platform = _platform(system,release,version,csd)\n\n    elif system in ('Linux',):\n        # Linux based systems\n        distname,distversion,distid = dist('')\n        if distname and not terse:\n            platform = _platform(system,release,machine,processor,\n                                 'with',\n                                 distname,distversion,distid)\n        else:\n            # If the distribution name is unknown check for libc vs. glibc\n            libcname,libcversion = libc_ver(sys.executable)\n            platform = _platform(system,release,machine,processor,\n                                 'with',\n                                 libcname+libcversion)\n    elif system == 'Java':\n        # Java platforms\n        r,v,vminfo,(os_name,os_version,os_arch) = java_ver()\n        if terse or not os_name:\n            platform = _platform(system,release,version)\n        else:\n            platform = _platform(system,release,version,\n                                 'on',\n                                 os_name,os_version,os_arch)\n\n    elif system == 'MacOS':\n        # MacOS platforms\n        if terse:\n            platform = _platform(system,release)\n        else:\n            platform = _platform(system,release,machine)\n\n    else:\n        # Generic handler\n        if terse:\n            platform = _platform(system,release)\n        else:\n            bits,linkage = architecture(sys.executable)\n            platform = _platform(system,release,machine,processor,bits,linkage)\n\n    _platform_cache[(aliased, terse)] = platform\n    return platform\n\n### Command line interface\n\nif __name__ == '__main__':\n    # Default is to print the aliased verbose platform string\n    terse = ('terse' in sys.argv or '--terse' in sys.argv)\n    aliased = (not 'nonaliased' in sys.argv and not '--nonaliased' in sys.argv)\n    print(platform(aliased,terse))\n    sys.exit(0)\n"], "html": [".py", "\"\"\"\nGeneral functions for HTML manipulation.\n\"\"\"\n\n\n_escape_map = {ord('&'): '&amp;', ord('<'): '&lt;', ord('>'): '&gt;'}\n_escape_map_full = {ord('&'): '&amp;', ord('<'): '&lt;', ord('>'): '&gt;',\n                    ord('\"'): '&quot;', ord('\\''): '&#x27;'}\n\n# NB: this is a candidate for a bytes/string polymorphic interface\n\ndef escape(s, quote=True):\n    \"\"\"\n    Replace special characters \"&\", \"<\" and \">\" to HTML-safe sequences.\n    If the optional flag quote is true (the default), the quotation mark\n    characters, both double quote (\") and single quote (') characters are also\n    translated.\n    \"\"\"\n    if quote:\n        return s.translate(_escape_map_full)\n    return s.translate(_escape_map)\n", 1], "collections": [".py", "#__all__ = ['deque', 'defaultdict', 'Counter']\n\nfrom _collections import deque, defaultdict\n\n#from itertools import repeat as _repeat, chain as _chain, starmap as _starmap\n\n__all__ = ['deque', 'defaultdict', 'namedtuple', 'UserDict', 'UserList',\n            'UserString', 'Counter', 'OrderedDict']\n# For bootstrapping reasons, the collection ABCs are defined in _abcoll.py.\n# They should however be considered an integral part of collections.py.\n\n# fixme brython.. there is an issue with _abcoll\n#from _abcoll import *\n#from _abcoll import Set\nfrom _abcoll import MutableMapping\n#import _abcoll\n#__all__ += _abcoll.__all__\n\nfrom collections.abc import *\nimport collections.abc\n__all__ += collections.abc.__all__\n\nfrom _collections import deque, defaultdict, namedtuple\nfrom operator import itemgetter as _itemgetter\nfrom keyword import iskeyword as _iskeyword\nimport sys as _sys\nimport heapq as _heapq\n#fixme brython\n#from weakref import proxy as _proxy\nfrom itertools import repeat as _repeat, chain as _chain, starmap as _starmap\nfrom reprlib import recursive_repr as _recursive_repr\n\nclass Set(set):\n    pass\n\nclass Sequence(list):\n    pass\n\ndef _proxy(obj):\n    return obj\n\n################################################################################\n### OrderedDict\n################################################################################\n\nclass _Link(object):\n    __slots__ = 'prev', 'next', 'key', '__weakref__'\n\nclass OrderedDict(dict):\n    'Dictionary that remembers insertion order'\n    # An inherited dict maps keys to values.\n    # The inherited dict provides __getitem__, __len__, __contains__, and get.\n    # The remaining methods are order-aware.\n    # Big-O running times for all methods are the same as regular dictionaries.\n\n    # The internal self.__map dict maps keys to links in a doubly linked list.\n    # The circular doubly linked list starts and ends with a sentinel element.\n    # The sentinel element never gets deleted (this simplifies the algorithm).\n    # The sentinel is in self.__hardroot with a weakref proxy in self.__root.\n    # The prev links are weakref proxies (to prevent circular references).\n    # Individual links are kept alive by the hard reference in self.__map.\n    # Those hard references disappear when a key is deleted from an OrderedDict.\n\n    def __init__(self, *args, **kwds):\n        '''Initialize an ordered dictionary.  The signature is the same as\n        regular dictionaries, but keyword arguments are not recommended because\n        their insertion order is arbitrary.\n\n        '''\n        if len(args) > 1:\n            raise TypeError('expected at most 1 arguments, got %d' % len(args))\n        try:\n            self.__root\n        except AttributeError:\n            self.__hardroot = _Link()\n            self.__root = root = _proxy(self.__hardroot)\n            root.prev = root.next = root\n            self.__map = {}\n        self.__update(*args, **kwds)\n\n    def __setitem__(self, key, value,\n                    dict_setitem=dict.__setitem__, proxy=_proxy, Link=_Link):\n        'od.__setitem__(i, y) <==> od[i]=y'\n        # Setting a new item creates a new link at the end of the linked list,\n        # and the inherited dictionary is updated with the new key/value pair.\n        if key not in self:\n            self.__map[key] = link = Link()\n            root = self.__root\n            last = root.prev\n            link.prev, link.next, link.key = last, root, key\n            last.next = link\n            root.prev = proxy(link)\n        dict_setitem(self, key, value)\n\n    def __delitem__(self, key, dict_delitem=dict.__delitem__):\n        'od.__delitem__(y) <==> del od[y]'\n        # Deleting an existing item uses self.__map to find the link which gets\n        # removed by updating the links in the predecessor and successor nodes.\n        dict_delitem(self, key)\n        link = self.__map.pop(key)\n        link_prev = link.prev\n        link_next = link.next\n        link_prev.next = link_next\n        link_next.prev = link_prev\n\n    def __iter__(self):\n        'od.__iter__() <==> iter(od)'\n        # Traverse the linked list in order.\n        root = self.__root\n        curr = root.next\n        while curr is not root:\n            yield curr.key\n            curr = curr.next\n\n    def __reversed__(self):\n        'od.__reversed__() <==> reversed(od)'\n        # Traverse the linked list in reverse order.\n        root = self.__root\n        curr = root.prev\n        while curr is not root:\n            yield curr.key\n            curr = curr.prev\n\n    def clear(self):\n        'od.clear() -> None.  Remove all items from od.'\n        root = self.__root\n        root.prev = root.next = root\n        self.__map.clear()\n        dict.clear(self)\n\n    def popitem(self, last=True):\n        '''od.popitem() -> (k, v), return and remove a (key, value) pair.\n        Pairs are returned in LIFO order if last is true or FIFO order if false.\n\n        '''\n        if not self:\n            raise KeyError('dictionary is empty')\n        root = self.__root\n        if last:\n            link = root.prev\n            link_prev = link.prev\n            link_prev.next = root\n            root.prev = link_prev\n        else:\n            link = root.next\n            link_next = link.next\n            root.next = link_next\n            link_next.prev = root\n        key = link.key\n        del self.__map[key]\n        value = dict.pop(self, key)\n        return key, value\n\n    def move_to_end(self, key, last=True):\n        '''Move an existing element to the end (or beginning if last==False).\n\n        Raises KeyError if the element does not exist.\n        When last=True, acts like a fast version of self[key]=self.pop(key).\n\n        '''\n        link = self.__map[key]\n        link_prev = link.prev\n        link_next = link.next\n        link_prev.next = link_next\n        link_next.prev = link_prev\n        root = self.__root\n        if last:\n            last = root.prev\n            link.prev = last\n            link.next = root\n            last.next = root.prev = link\n        else:\n            first = root.next\n            link.prev = root\n            link.next = first\n            root.next = first.prev = link\n\n    def __sizeof__(self):\n        sizeof = _sys.getsizeof\n        n = len(self) + 1                       # number of links including root\n        size = sizeof(self.__dict__)            # instance dictionary\n        size += sizeof(self.__map) * 2          # internal dict and inherited dict\n        size += sizeof(self.__hardroot) * n     # link objects\n        size += sizeof(self.__root) * n         # proxy objects\n        return size\n\n    #fixme brython..  Issue with _abcoll, which contains MutableMapping\n    update = __update = MutableMapping.update\n    keys = MutableMapping.keys\n    values = MutableMapping.values\n    items = MutableMapping.items\n    __ne__ = MutableMapping.__ne__\n\n    __marker = object()\n\n    def pop(self, key, default=__marker):\n        '''od.pop(k[,d]) -> v, remove specified key and return the corresponding\n        value.  If key is not found, d is returned if given, otherwise KeyError\n        is raised.\n\n        '''\n        if key in self:\n            result = self[key]\n            del self[key]\n            return result\n        if default is self.__marker:\n            raise KeyError(key)\n        return default\n\n    def setdefault(self, key, default=None):\n        'od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od'\n        if key in self:\n            return self[key]\n        self[key] = default\n        return default\n\n    #fixme, brython issue\n    #@_recursive_repr()\n    def __repr__(self):\n        'od.__repr__() <==> repr(od)'\n        if not self:\n            return '%s()' % (self.__class__.__name__,)\n        return '%s(%r)' % (self.__class__.__name__, list(self.items()))\n\n    def __reduce__(self):\n        'Return state information for pickling'\n        items = [[k, self[k]] for k in self]\n        inst_dict = vars(self).copy()\n        for k in vars(OrderedDict()):\n            inst_dict.pop(k, None)\n        if inst_dict:\n            return (self.__class__, (items,), inst_dict)\n        return self.__class__, (items,)\n\n    def copy(self):\n        'od.copy() -> a shallow copy of od'\n        return self.__class__(self)\n\n    @classmethod\n    def fromkeys(cls, iterable, value=None):\n        '''OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S.\n        If not specified, the value defaults to None.\n\n        '''\n        self = cls()\n        for key in iterable:\n            self[key] = value\n        return self\n\n    def __eq__(self, other):\n        '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive\n        while comparison to a regular mapping is order-insensitive.\n\n        '''\n        if isinstance(other, OrderedDict):\n            return len(self)==len(other) and \\\n                   all(p==q for p, q in zip(self.items(), other.items()))\n        return dict.__eq__(self, other)\n\n\n########################################################################\n###  Counter\n########################################################################\n\n\ndef _count_elements(mapping, iterable):\n    'Tally elements from the iterable.'\n    mapping_get = mapping.get\n    for elem in iterable:\n        mapping[elem] = mapping_get(elem, 0) + 1\n\n#try:                                    # Load C helper function if available\n#    from _collections import _count_elements\n#except ImportError:\n#    pass\n\nclass Counter(dict):\n    '''Dict subclass for counting hashable items.  Sometimes called a bag\n    or multiset.  Elements are stored as dictionary keys and their counts\n    are stored as dictionary values.\n\n    >>> c = Counter('abcdeabcdabcaba')  # count elements from a string\n\n    >>> c.most_common(3)                # three most common elements\n    [('a', 5), ('b', 4), ('c', 3)]\n    >>> sorted(c)                       # list all unique elements\n    ['a', 'b', 'c', 'd', 'e']\n    >>> ''.join(sorted(c.elements()))   # list elements with repetitions\n    'aaaaabbbbcccdde'\n    >>> sum(c.values())                 # total of all counts\n    15\n\n    >>> c['a']                          # count of letter 'a'\n    5\n    >>> for elem in 'shazam':           # update counts from an iterable\n    ...     c[elem] += 1                # by adding 1 to each element's count\n    >>> c['a']                          # now there are seven 'a'\n    7\n    >>> del c['b']                      # remove all 'b'\n    >>> c['b']                          # now there are zero 'b'\n    0\n\n    >>> d = Counter('simsalabim')       # make another counter\n    >>> c.update(d)                     # add in the second counter\n    >>> c['a']                          # now there are nine 'a'\n    9\n\n    >>> c.clear()                       # empty the counter\n    >>> c\n    Counter()\n\n    Note:  If a count is set to zero or reduced to zero, it will remain\n    in the counter until the entry is deleted or the counter is cleared:\n\n    >>> c = Counter('aaabbc')\n    >>> c['b'] -= 2                     # reduce the count of 'b' by two\n    >>> c.most_common()                 # 'b' is still in, but its count is zero\n    [('a', 3), ('c', 1), ('b', 0)]\n\n    '''\n    # References:\n    #   http://en.wikipedia.org/wiki/Multiset\n    #   http://www.gnu.org/software/smalltalk/manual-base/html_node/Bag.html\n    #   http://www.demo2s.com/Tutorial/Cpp/0380__set-multiset/Catalog0380__set-multiset.htm\n    #   http://code.activestate.com/recipes/259174/\n    #   Knuth, TAOCP Vol. II section 4.6.3\n\n    def __init__(self, iterable=None, **kwds):\n        '''Create a new, empty Counter object.  And if given, count elements\n        from an input iterable.  Or, initialize the count from another mapping\n        of elements to their counts.\n\n        >>> c = Counter()                           # a new, empty counter\n        >>> c = Counter('gallahad')                 # a new counter from an iterable\n        >>> c = Counter({'a': 4, 'b': 2})           # a new counter from a mapping\n        >>> c = Counter(a=4, b=2)                   # a new counter from keyword args\n\n        '''\n        #super().__init__()  #BE modified since super not supported\n        dict.__init__(self)\n        self.update(iterable, **kwds)\n\n    def __missing__(self, key):\n        'The count of elements not in the Counter is zero.'\n        # Needed so that self[missing_item] does not raise KeyError\n        return 0\n\n    def most_common(self, n=None):\n        '''List the n most common elements and their counts from the most\n        common to the least.  If n is None, then list all element counts.\n\n        >>> Counter('abcdeabcdabcaba').most_common(3)\n        [('a', 5), ('b', 4), ('c', 3)]\n\n        '''\n        # Emulate Bag.sortedByCount from Smalltalk\n        if n is None:\n            return sorted(self.items(), key=_itemgetter(1), reverse=True)\n        return _heapq.nlargest(n, self.items(), key=_itemgetter(1))\n\n    def elements(self):\n        '''Iterator over elements repeating each as many times as its count.\n\n        >>> c = Counter('ABCABC')\n        >>> sorted(c.elements())\n        ['A', 'A', 'B', 'B', 'C', 'C']\n\n        # Knuth's example for prime factors of 1836:  2**2 * 3**3 * 17**1\n        >>> prime_factors = Counter({2: 2, 3: 3, 17: 1})\n        >>> product = 1\n        >>> for factor in prime_factors.elements():     # loop over factors\n        ...     product *= factor                       # and multiply them\n        >>> product\n        1836\n\n        Note, if an element's count has been set to zero or is a negative\n        number, elements() will ignore it.\n\n        '''\n        # Emulate Bag.do from Smalltalk and Multiset.begin from C++.\n        return _chain.from_iterable(_starmap(_repeat, self.items()))\n\n    # Override dict methods where necessary\n\n    @classmethod\n    def fromkeys(cls, iterable, v=None):\n        # There is no equivalent method for counters because setting v=1\n        # means that no element can have a count greater than one.\n        raise NotImplementedError(\n            'Counter.fromkeys() is undefined.  Use Counter(iterable) instead.')\n\n    def update(self, iterable=None, **kwds):\n        '''Like dict.update() but add counts instead of replacing them.\n\n        Source can be an iterable, a dictionary, or another Counter instance.\n\n        >>> c = Counter('which')\n        >>> c.update('witch')           # add elements from another iterable\n        >>> d = Counter('watch')\n        >>> c.update(d)                 # add elements from another counter\n        >>> c['h']                      # four 'h' in which, witch, and watch\n        4\n\n        '''\n        # The regular dict.update() operation makes no sense here because the\n        # replace behavior results in the some of original untouched counts\n        # being mixed-in with all of the other counts for a mismash that\n        # doesn't have a straight-forward interpretation in most counting\n        # contexts.  Instead, we implement straight-addition.  Both the inputs\n        # and outputs are allowed to contain zero and negative counts.\n\n        if iterable is not None:\n            if isinstance(iterable, Mapping):\n                if self:\n                    self_get = self.get\n                    for elem, count in iterable.items():\n                        self[elem] = count + self_get(elem, 0)\n                else:\n                    super().update(iterable) # fast path when counter is empty\n            else:\n                _count_elements(self, iterable)\n        if kwds:\n            self.update(kwds)\n\n    def subtract(self, iterable=None, **kwds):\n        '''Like dict.update() but subtracts counts instead of replacing them.\n        Counts can be reduced below zero.  Both the inputs and outputs are\n        allowed to contain zero and negative counts.\n\n        Source can be an iterable, a dictionary, or another Counter instance.\n\n        >>> c = Counter('which')\n        >>> c.subtract('witch')             # subtract elements from another iterable\n        >>> c.subtract(Counter('watch'))    # subtract elements from another counter\n        >>> c['h']                          # 2 in which, minus 1 in witch, minus 1 in watch\n        0\n        >>> c['w']                          # 1 in which, minus 1 in witch, minus 1 in watch\n        -1\n\n        '''\n        if iterable is not None:\n            self_get = self.get\n            if isinstance(iterable, Mapping):\n                for elem, count in iterable.items():\n                    self[elem] = self_get(elem, 0) - count\n            else:\n                for elem in iterable:\n                    self[elem] = self_get(elem, 0) - 1\n        if kwds:\n            self.subtract(kwds)\n\n    def copy(self):\n        'Return a shallow copy.'\n        return self.__class__(self)\n\n    def __reduce__(self):\n        return self.__class__, (dict(self),)\n\n    def __delitem__(self, elem):\n        'Like dict.__delitem__() but does not raise KeyError for missing values.'\n        if elem in self:\n            super().__delitem__(elem)\n\n    def __repr__(self):\n        if not self:\n            return '%s()' % self.__class__.__name__\n        try:\n            items = ', '.join(map('%r: %r'.__mod__, self.most_common()))\n            return '%s({%s})' % (self.__class__.__name__, items)\n        except TypeError:\n            # handle case where values are not orderable\n            return '{0}({1!r})'.format(self.__class__.__name__, dict(self))\n\n    # Multiset-style mathematical operations discussed in:\n    #       Knuth TAOCP Volume II section 4.6.3 exercise 19\n    #       and at http://en.wikipedia.org/wiki/Multiset\n    #\n    # Outputs guaranteed to only include positive counts.\n    #\n    # To strip negative and zero counts, add-in an empty counter:\n    #       c += Counter()\n\n    def __add__(self, other):\n        '''Add counts from two counters.\n\n        >>> Counter('abbb') + Counter('bcc')\n        Counter({'b': 4, 'c': 2, 'a': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            newcount = count + other[elem]\n            if newcount > 0:\n                result[elem] = newcount\n        for elem, count in other.items():\n            if elem not in self and count > 0:\n                result[elem] = count\n        return result\n\n    def __sub__(self, other):\n        ''' Subtract count, but keep only results with positive counts.\n\n        >>> Counter('abbbc') - Counter('bccd')\n        Counter({'b': 2, 'a': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            newcount = count - other[elem]\n            if newcount > 0:\n                result[elem] = newcount\n        for elem, count in other.items():\n            if elem not in self and count < 0:\n                result[elem] = 0 - count\n        return result\n\n    def __or__(self, other):\n        '''Union is the maximum of value in either of the input counters.\n\n        >>> Counter('abbb') | Counter('bcc')\n        Counter({'b': 3, 'c': 2, 'a': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            other_count = other[elem]\n            newcount = other_count if count < other_count else count\n            if newcount > 0:\n                result[elem] = newcount\n        for elem, count in other.items():\n            if elem not in self and count > 0:\n                result[elem] = count\n        return result\n\n    def __and__(self, other):\n        ''' Intersection is the minimum of corresponding counts.\n    \n        >>> Counter('abbb') & Counter('bcc')\n        Counter({'b': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            other_count = other[elem]\n            newcount = count if count < other_count else other_count\n            if newcount > 0:\n                result[elem] = newcount\n        return result\n\n\n########################################################################\n###  ChainMap (helper for configparser)\n########################################################################\n\nclass ChainMap(MutableMapping):\n    ''' A ChainMap groups multiple dicts (or other mappings) together\n    to create a single, updateable view.\n\n    The underlying mappings are stored in a list.  That list is public and can\n    accessed or updated using the *maps* attribute.  There is no other state.\n\n    Lookups search the underlying mappings successively until a key is found.\n    In contrast, writes, updates, and deletions only operate on the first\n    mapping.\n\n    '''\n\n    def __init__(self, *maps):\n        '''Initialize a ChainMap by setting *maps* to the given mappings.\n        If no mappings are provided, a single empty dictionary is used.\n\n        '''\n        self.maps = list(maps) or [{}]          # always at least one map\n\n    def __missing__(self, key):\n        raise KeyError(key)\n\n    def __getitem__(self, key):\n        for mapping in self.maps:\n            try:\n                return mapping[key]             # can't use 'key in mapping' with defaultdict\n            except KeyError:\n                pass\n        return self.__missing__(key)            # support subclasses that define __missing__\n\n    def get(self, key, default=None):\n        return self[key] if key in self else default\n\n    def __len__(self):\n        return len(set().union(*self.maps))     # reuses stored hash values if possible\n\n    def __iter__(self):\n        return iter(set().union(*self.maps))\n\n    def __contains__(self, key):\n        return any(key in m for m in self.maps)\n\n    def __bool__(self):\n        return any(self.maps)\n\n    #fixme, brython\n    #@_recursive_repr()\n    def __repr__(self):\n        return '{0.__class__.__name__}({1})'.format(\n            self, ', '.join(map(repr, self.maps)))\n\n    def __repr__(self):\n        return ','.join(str(_map) for _map in self.maps)\n\n    @classmethod\n    def fromkeys(cls, iterable, *args):\n        'Create a ChainMap with a single dict created from the iterable.'\n        return cls(dict.fromkeys(iterable, *args))\n\n    def copy(self):\n        'New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]'\n        return self.__class__(self.maps[0].copy(), *self.maps[1:])\n\n    __copy__ = copy\n\n    def new_child(self):                        # like Django's Context.push()\n        'New ChainMap with a new dict followed by all previous maps.'\n        return self.__class__({}, *self.maps)\n\n    @property\n    def parents(self):                          # like Django's Context.pop()\n        'New ChainMap from maps[1:].'\n        return self.__class__(*self.maps[1:])\n\n    def __setitem__(self, key, value):\n        self.maps[0][key] = value\n\n    def __delitem__(self, key):\n        try:\n            del self.maps[0][key]\n        except KeyError:\n            raise KeyError('Key not found in the first mapping: {!r}'.format(key))\n\n    def popitem(self):\n        'Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.'\n        try:\n            return self.maps[0].popitem()\n        except KeyError:\n            raise KeyError('No keys found in the first mapping.')\n\n    def pop(self, key, *args):\n        'Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].'\n        try:\n            return self.maps[0].pop(key, *args)\n        except KeyError:\n            #raise KeyError('Key not found in the first mapping: {!r}'.format(key))\n            raise KeyError('Key not found in the first mapping: %s' % key)\n\n    def clear(self):\n        'Clear maps[0], leaving maps[1:] intact.'\n        self.maps[0].clear()\n\n\n################################################################################\n### UserDict\n################################################################################\n\nclass UserDict(MutableMapping):\n\n    # Start by filling-out the abstract methods\n    def __init__(self, dict=None, **kwargs):\n        self.data = {}\n        if dict is not None:\n            self.update(dict)\n        if len(kwargs):\n            self.update(kwargs)\n    def __len__(self): return len(self.data)\n    def __getitem__(self, key):\n        if key in self.data:\n            return self.data[key]\n        if hasattr(self.__class__, \"__missing__\"):\n            return self.__class__.__missing__(self, key)\n        raise KeyError(key)\n    def __setitem__(self, key, item): self.data[key] = item\n    def __delitem__(self, key): del self.data[key]\n    def __iter__(self):\n        return iter(self.data)\n\n    # Modify __contains__ to work correctly when __missing__ is present\n    def __contains__(self, key):\n        return key in self.data\n\n    # Now, add the methods in dicts but not in MutableMapping\n    def __repr__(self): return repr(self.data)\n    def copy(self):\n        if self.__class__ is UserDict:\n            return UserDict(self.data.copy())\n        import copy\n        data = self.data\n        try:\n            self.data = {}\n            c = copy.copy(self)\n        finally:\n            self.data = data\n        c.update(self)\n        return c\n    @classmethod\n    def fromkeys(cls, iterable, value=None):\n        d = cls()\n        for key in iterable:\n            d[key] = value\n        return d\n\n\n\n################################################################################\n### UserList\n################################################################################\n\n\n\n################################################################################\n### UserString\n################################################################################\n", 1], "browser.html": [".py", "from _html import *"], "unittest.main": [".py", "\"\"\"Unittest main program\"\"\"\n\nimport sys\nimport optparse\nimport os\n\nfrom . import loader, runner\nfrom .signals import installHandler\n\n__unittest = True\n\nFAILFAST     = \"  -f, --failfast   Stop on first failure\\n\"\nCATCHBREAK   = \"  -c, --catch      Catch control-C and display results\\n\"\nBUFFEROUTPUT = \"  -b, --buffer     Buffer stdout and stderr during test runs\\n\"\n\nUSAGE_AS_MAIN = \"\"\"\\\nUsage: %(progName)s [options] [tests]\n\nOptions:\n  -h, --help       Show this message\n  -v, --verbose    Verbose output\n  -q, --quiet      Minimal output\n%(failfast)s%(catchbreak)s%(buffer)s\nExamples:\n  %(progName)s test_module               - run tests from test_module\n  %(progName)s module.TestClass          - run tests from module.TestClass\n  %(progName)s module.Class.test_method  - run specified test method\n\n[tests] can be a list of any number of test modules, classes and test\nmethods.\n\nAlternative Usage: %(progName)s discover [options]\n\nOptions:\n  -v, --verbose    Verbose output\n%(failfast)s%(catchbreak)s%(buffer)s  -s directory     Directory to start discovery ('.' default)\n  -p pattern       Pattern to match test files ('test*.py' default)\n  -t directory     Top level directory of project (default to\n                   start directory)\n\nFor test discovery all test modules must be importable from the top\nlevel directory of the project.\n\"\"\"\n\nUSAGE_FROM_MODULE = \"\"\"\\\nUsage: %(progName)s [options] [test] [...]\n\nOptions:\n  -h, --help       Show this message\n  -v, --verbose    Verbose output\n  -q, --quiet      Minimal output\n%(failfast)s%(catchbreak)s%(buffer)s\nExamples:\n  %(progName)s                               - run default set of tests\n  %(progName)s MyTestSuite                   - run suite 'MyTestSuite'\n  %(progName)s MyTestCase.testSomething      - run MyTestCase.testSomething\n  %(progName)s MyTestCase                    - run all 'test*' test methods\n                                               in MyTestCase\n\"\"\"\n\ndef _convert_name(name):\n    # on Linux / Mac OS X 'foo.PY' is not importable, but on\n    # Windows it is. Simpler to do a case insensitive match\n    # a better check would be to check that the name is a\n    # valid Python module name.\n    if os.path.isfile(name) and name.lower().endswith('.py'):\n        if os.path.isabs(name):\n            rel_path = os.path.relpath(name, os.getcwd())\n            if os.path.isabs(rel_path) or rel_path.startswith(os.pardir):\n                return name\n            name = rel_path\n        # on Windows both '\\' and '/' are used as path\n        # separators. Better to replace both than rely on os.path.sep\n        return name[:-3].replace('\\\\', '.').replace('/', '.')\n    return name\n\ndef _convert_names(names):\n    return [_convert_name(name) for name in names]\n\n\nclass TestProgram(object):\n    \"\"\"A command-line program that runs a set of tests; this is primarily\n       for making test modules conveniently executable.\n    \"\"\"\n    USAGE = USAGE_FROM_MODULE\n\n    # defaults for testing\n    failfast = catchbreak = buffer = progName = warnings = None\n\n    def __init__(self, module='__main__', defaultTest=None, argv=None,\n                    testRunner=None, testLoader=loader.defaultTestLoader,\n                    exit=True, verbosity=1, failfast=None, catchbreak=None,\n                    buffer=None, warnings=None):\n        if isinstance(module, str):\n            self.module = __import__(module)\n            for part in module.split('.')[1:]:\n                self.module = getattr(self.module, part)\n        else:\n            self.module = module\n        if argv is None:\n            argv = sys.argv\n\n        self.exit = exit\n        self.failfast = failfast\n        self.catchbreak = catchbreak\n        self.verbosity = verbosity\n        self.buffer = buffer\n        if warnings is None and not sys.warnoptions:\n            # even if DreprecationWarnings are ignored by default\n            # print them anyway unless other warnings settings are\n            # specified by the warnings arg or the -W python flag\n            self.warnings = 'default'\n        else:\n            # here self.warnings is set either to the value passed\n            # to the warnings args or to None.\n            # If the user didn't pass a value self.warnings will\n            # be None. This means that the behavior is unchanged\n            # and depends on the values passed to -W.\n            self.warnings = warnings\n        self.defaultTest = defaultTest\n        self.testRunner = testRunner\n        self.testLoader = testLoader\n        self.progName = os.path.basename(argv[0])\n        self.parseArgs(argv)\n        self.runTests()\n\n    def usageExit(self, msg=None):\n        if msg:\n            print(msg)\n        usage = {'progName': self.progName, 'catchbreak': '', 'failfast': '',\n                 'buffer': ''}\n        if self.failfast != False:\n            usage['failfast'] = FAILFAST\n        if self.catchbreak != False:\n            usage['catchbreak'] = CATCHBREAK\n        if self.buffer != False:\n            usage['buffer'] = BUFFEROUTPUT\n        print(self.USAGE % usage)\n        sys.exit(2)\n\n    def parseArgs(self, argv):\n        if ((len(argv) > 1 and argv[1].lower() == 'discover') or\n            (len(argv) == 1 and self.module is None)):\n            self._do_discovery(argv[2:])\n            return\n\n        parser = self._getOptParser()\n        options, args = parser.parse_args(argv[1:])\n        self._setAttributesFromOptions(options)\n\n        if len(args) == 0 and self.module is None:\n            # this allows \"python -m unittest -v\" to still work for\n            # test discovery. This means -c / -b / -v / -f options will\n            # be handled twice, which is harmless but not ideal.\n            self._do_discovery(argv[1:])\n            return\n\n        if len(args) == 0 and self.defaultTest is None:\n            # createTests will load tests from self.module\n            self.testNames = None\n        elif len(args) > 0:\n            self.testNames = _convert_names(args)\n            if __name__ == '__main__':\n                # to support python -m unittest ...\n                self.module = None\n        else:\n            self.testNames = (self.defaultTest,)\n        self.createTests()\n\n    def createTests(self):\n        if self.testNames is None:\n            self.test = self.testLoader.loadTestsFromModule(self.module)\n        else:\n            self.test = self.testLoader.loadTestsFromNames(self.testNames,\n                                                           self.module)\n\n    def _getOptParser(self):\n        import optparse\n        parser = optparse.OptionParser()\n        parser.prog = self.progName\n        parser.add_option('-v', '--verbose', dest='verbose', default=False,\n                          help='Verbose output', action='store_true')\n        parser.add_option('-q', '--quiet', dest='quiet', default=False,\n                          help='Quiet output', action='store_true')\n\n        if self.failfast != False:\n            parser.add_option('-f', '--failfast', dest='failfast', default=False,\n                              help='Stop on first fail or error',\n                              action='store_true')\n        if self.catchbreak != False:\n            parser.add_option('-c', '--catch', dest='catchbreak', default=False,\n                              help='Catch ctrl-C and display results so far',\n                              action='store_true')\n        if self.buffer != False:\n            parser.add_option('-b', '--buffer', dest='buffer', default=False,\n                              help='Buffer stdout and stderr during tests',\n                              action='store_true')\n        return parser\n\n    def _setAttributesFromOptions(self, options):\n        # only set options from the parsing here\n        # if they weren't set explicitly in the constructor\n        if self.failfast is None:\n            self.failfast = options.failfast\n        if self.catchbreak is None:\n            self.catchbreak = options.catchbreak\n        if self.buffer is None:\n            self.buffer = options.buffer\n\n        if options.verbose:\n            self.verbosity = 2\n        elif options.quiet:\n            self.verbosity = 0\n\n    def _addDiscoveryOptions(self, parser):\n        parser.add_option('-s', '--start-directory', dest='start', default='.',\n                          help=\"Directory to start discovery ('.' default)\")\n        parser.add_option('-p', '--pattern', dest='pattern', default='test*.py',\n                          help=\"Pattern to match tests ('test*.py' default)\")\n        parser.add_option('-t', '--top-level-directory', dest='top', default=None,\n                          help='Top level directory of project (defaults to start directory)')\n\n    def _do_discovery(self, argv, Loader=None):\n        if Loader is None:\n            Loader = lambda: self.testLoader\n\n        # handle command line args for test discovery\n        self.progName = '%s discover' % self.progName\n        parser = self._getOptParser()\n        self._addDiscoveryOptions(parser)\n\n        options, args = parser.parse_args(argv)\n        if len(args) > 3:\n            self.usageExit()\n\n        for name, value in zip(('start', 'pattern', 'top'), args):\n            setattr(options, name, value)\n\n        self._setAttributesFromOptions(options)\n\n        start_dir = options.start\n        pattern = options.pattern\n        top_level_dir = options.top\n\n        loader = Loader()\n        self.test = loader.discover(start_dir, pattern, top_level_dir)\n\n    def runTests(self):\n        if self.catchbreak:\n            installHandler()\n        if self.testRunner is None:\n            self.testRunner = runner.TextTestRunner\n        if isinstance(self.testRunner, type):\n            try:\n                testRunner = self.testRunner(verbosity=self.verbosity,\n                                             failfast=self.failfast,\n                                             buffer=self.buffer,\n                                             warnings=self.warnings)\n            except TypeError:\n                # didn't accept the verbosity, buffer or failfast arguments\n                testRunner = self.testRunner()\n        else:\n            # it is assumed to be a TestRunner instance\n            testRunner = self.testRunner\n        self.result = testRunner.run(self.test)\n        if self.exit:\n            sys.exit(not self.result.wasSuccessful())\n\nmain = TestProgram\n"], "ui.progressbar": [".py", "from . import widget\nfrom browser import html\n\nclass ProgressBar(widget.Widget):\n  def __init__(self, id=None, label=False):\n      self._div_shell=html.DIV(Class=\"ui-progressbar ui-widget ui-widget-content ui-corner-all\")\n      widget.Widget.__init__(self, self._div_shell, 'progressbar', id)\n\n      self._show_label=label\n      if label:\n         self._label=html.DIV(Class='progress-label')\n         self._div_shell <= self._label\n\n      self._bar=html.DIV(Class=\"ui-progressbar-value ui-widget-header ui-corner-left\",\n                         style={'width': '0px'})\n      self._div_shell <= self._bar\n\n  def set_progress(self, percent):\n      self._bar.style.width='%s%%' % percent\n      if self._show_label:\n         self._label.text='%s%%' % percent\n"], "unittest.test.testmock.testsentinel": [".py", "import unittest\nfrom unittest.mock import sentinel, DEFAULT\n\n\nclass SentinelTest(unittest.TestCase):\n\n    def testSentinels(self):\n        self.assertEqual(sentinel.whatever, sentinel.whatever,\n                         'sentinel not stored')\n        self.assertNotEqual(sentinel.whatever, sentinel.whateverelse,\n                            'sentinel should be unique')\n\n\n    def testSentinelName(self):\n        self.assertEqual(str(sentinel.whatever), 'sentinel.whatever',\n                         'sentinel name incorrect')\n\n\n    def testDEFAULT(self):\n        self.assertTrue(DEFAULT is sentinel.DEFAULT)\n\n    def testBases(self):\n        # If this doesn't raise an AttributeError then help(mock) is broken\n        self.assertRaises(AttributeError, lambda: sentinel.__bases__)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"], "unittest.test.test_setups": [".py", "import io\nimport sys\n\nimport unittest\n\n\ndef resultFactory(*_):\n    return unittest.TestResult()\n\n\nclass TestSetups(unittest.TestCase):\n\n    def getRunner(self):\n        return unittest.TextTestRunner(resultclass=resultFactory,\n                                          stream=io.StringIO())\n    def runTests(self, *cases):\n        suite = unittest.TestSuite()\n        for case in cases:\n            tests = unittest.defaultTestLoader.loadTestsFromTestCase(case)\n            suite.addTests(tests)\n\n        runner = self.getRunner()\n\n        # creating a nested suite exposes some potential bugs\n        realSuite = unittest.TestSuite()\n        realSuite.addTest(suite)\n        # adding empty suites to the end exposes potential bugs\n        suite.addTest(unittest.TestSuite())\n        realSuite.addTest(unittest.TestSuite())\n        return runner.run(realSuite)\n\n    def test_setup_class(self):\n        class Test(unittest.TestCase):\n            setUpCalled = 0\n            @classmethod\n            def setUpClass(cls):\n                Test.setUpCalled += 1\n                unittest.TestCase.setUpClass()\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        result = self.runTests(Test)\n\n        self.assertEqual(Test.setUpCalled, 1)\n        self.assertEqual(result.testsRun, 2)\n        self.assertEqual(len(result.errors), 0)\n\n    def test_teardown_class(self):\n        class Test(unittest.TestCase):\n            tearDownCalled = 0\n            @classmethod\n            def tearDownClass(cls):\n                Test.tearDownCalled += 1\n                unittest.TestCase.tearDownClass()\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        result = self.runTests(Test)\n\n        self.assertEqual(Test.tearDownCalled, 1)\n        self.assertEqual(result.testsRun, 2)\n        self.assertEqual(len(result.errors), 0)\n\n    def test_teardown_class_two_classes(self):\n        class Test(unittest.TestCase):\n            tearDownCalled = 0\n            @classmethod\n            def tearDownClass(cls):\n                Test.tearDownCalled += 1\n                unittest.TestCase.tearDownClass()\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        class Test2(unittest.TestCase):\n            tearDownCalled = 0\n            @classmethod\n            def tearDownClass(cls):\n                Test2.tearDownCalled += 1\n                unittest.TestCase.tearDownClass()\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        result = self.runTests(Test, Test2)\n\n        self.assertEqual(Test.tearDownCalled, 1)\n        self.assertEqual(Test2.tearDownCalled, 1)\n        self.assertEqual(result.testsRun, 4)\n        self.assertEqual(len(result.errors), 0)\n\n    def test_error_in_setupclass(self):\n        class BrokenTest(unittest.TestCase):\n            @classmethod\n            def setUpClass(cls):\n                raise TypeError('foo')\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        result = self.runTests(BrokenTest)\n\n        self.assertEqual(result.testsRun, 0)\n        self.assertEqual(len(result.errors), 1)\n        error, _ = result.errors[0]\n        self.assertEqual(str(error),\n                    'setUpClass (%s.BrokenTest)' % __name__)\n\n    def test_error_in_teardown_class(self):\n        class Test(unittest.TestCase):\n            tornDown = 0\n            @classmethod\n            def tearDownClass(cls):\n                Test.tornDown += 1\n                raise TypeError('foo')\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        class Test2(unittest.TestCase):\n            tornDown = 0\n            @classmethod\n            def tearDownClass(cls):\n                Test2.tornDown += 1\n                raise TypeError('foo')\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        result = self.runTests(Test, Test2)\n        self.assertEqual(result.testsRun, 4)\n        self.assertEqual(len(result.errors), 2)\n        self.assertEqual(Test.tornDown, 1)\n        self.assertEqual(Test2.tornDown, 1)\n\n        error, _ = result.errors[0]\n        self.assertEqual(str(error),\n                    'tearDownClass (%s.Test)' % __name__)\n\n    def test_class_not_torndown_when_setup_fails(self):\n        class Test(unittest.TestCase):\n            tornDown = False\n            @classmethod\n            def setUpClass(cls):\n                raise TypeError\n            @classmethod\n            def tearDownClass(cls):\n                Test.tornDown = True\n                raise TypeError('foo')\n            def test_one(self):\n                pass\n\n        self.runTests(Test)\n        self.assertFalse(Test.tornDown)\n\n    def test_class_not_setup_or_torndown_when_skipped(self):\n        class Test(unittest.TestCase):\n            classSetUp = False\n            tornDown = False\n            @classmethod\n            def setUpClass(cls):\n                Test.classSetUp = True\n            @classmethod\n            def tearDownClass(cls):\n                Test.tornDown = True\n            def test_one(self):\n                pass\n\n        Test = unittest.skip(\"hop\")(Test)\n        self.runTests(Test)\n        self.assertFalse(Test.classSetUp)\n        self.assertFalse(Test.tornDown)\n\n    def test_setup_teardown_order_with_pathological_suite(self):\n        results = []\n\n        class Module1(object):\n            @staticmethod\n            def setUpModule():\n                results.append('Module1.setUpModule')\n            @staticmethod\n            def tearDownModule():\n                results.append('Module1.tearDownModule')\n\n        class Module2(object):\n            @staticmethod\n            def setUpModule():\n                results.append('Module2.setUpModule')\n            @staticmethod\n            def tearDownModule():\n                results.append('Module2.tearDownModule')\n\n        class Test1(unittest.TestCase):\n            @classmethod\n            def setUpClass(cls):\n                results.append('setup 1')\n            @classmethod\n            def tearDownClass(cls):\n                results.append('teardown 1')\n            def testOne(self):\n                results.append('Test1.testOne')\n            def testTwo(self):\n                results.append('Test1.testTwo')\n\n        class Test2(unittest.TestCase):\n            @classmethod\n            def setUpClass(cls):\n                results.append('setup 2')\n            @classmethod\n            def tearDownClass(cls):\n                results.append('teardown 2')\n            def testOne(self):\n                results.append('Test2.testOne')\n            def testTwo(self):\n                results.append('Test2.testTwo')\n\n        class Test3(unittest.TestCase):\n            @classmethod\n            def setUpClass(cls):\n                results.append('setup 3')\n            @classmethod\n            def tearDownClass(cls):\n                results.append('teardown 3')\n            def testOne(self):\n                results.append('Test3.testOne')\n            def testTwo(self):\n                results.append('Test3.testTwo')\n\n        Test1.__module__ = Test2.__module__ = 'Module'\n        Test3.__module__ = 'Module2'\n        sys.modules['Module'] = Module1\n        sys.modules['Module2'] = Module2\n\n        first = unittest.TestSuite((Test1('testOne'),))\n        second = unittest.TestSuite((Test1('testTwo'),))\n        third = unittest.TestSuite((Test2('testOne'),))\n        fourth = unittest.TestSuite((Test2('testTwo'),))\n        fifth = unittest.TestSuite((Test3('testOne'),))\n        sixth = unittest.TestSuite((Test3('testTwo'),))\n        suite = unittest.TestSuite((first, second, third, fourth, fifth, sixth))\n\n        runner = self.getRunner()\n        result = runner.run(suite)\n        self.assertEqual(result.testsRun, 6)\n        self.assertEqual(len(result.errors), 0)\n\n        self.assertEqual(results,\n                         ['Module1.setUpModule', 'setup 1',\n                          'Test1.testOne', 'Test1.testTwo', 'teardown 1',\n                          'setup 2', 'Test2.testOne', 'Test2.testTwo',\n                          'teardown 2', 'Module1.tearDownModule',\n                          'Module2.setUpModule', 'setup 3',\n                          'Test3.testOne', 'Test3.testTwo',\n                          'teardown 3', 'Module2.tearDownModule'])\n\n    def test_setup_module(self):\n        class Module(object):\n            moduleSetup = 0\n            @staticmethod\n            def setUpModule():\n                Module.moduleSetup += 1\n\n        class Test(unittest.TestCase):\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n        Test.__module__ = 'Module'\n        sys.modules['Module'] = Module\n\n        result = self.runTests(Test)\n        self.assertEqual(Module.moduleSetup, 1)\n        self.assertEqual(result.testsRun, 2)\n        self.assertEqual(len(result.errors), 0)\n\n    def test_error_in_setup_module(self):\n        class Module(object):\n            moduleSetup = 0\n            moduleTornDown = 0\n            @staticmethod\n            def setUpModule():\n                Module.moduleSetup += 1\n                raise TypeError('foo')\n            @staticmethod\n            def tearDownModule():\n                Module.moduleTornDown += 1\n\n        class Test(unittest.TestCase):\n            classSetUp = False\n            classTornDown = False\n            @classmethod\n            def setUpClass(cls):\n                Test.classSetUp = True\n            @classmethod\n            def tearDownClass(cls):\n                Test.classTornDown = True\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        class Test2(unittest.TestCase):\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n        Test.__module__ = 'Module'\n        Test2.__module__ = 'Module'\n        sys.modules['Module'] = Module\n\n        result = self.runTests(Test, Test2)\n        self.assertEqual(Module.moduleSetup, 1)\n        self.assertEqual(Module.moduleTornDown, 0)\n        self.assertEqual(result.testsRun, 0)\n        self.assertFalse(Test.classSetUp)\n        self.assertFalse(Test.classTornDown)\n        self.assertEqual(len(result.errors), 1)\n        error, _ = result.errors[0]\n        self.assertEqual(str(error), 'setUpModule (Module)')\n\n    def test_testcase_with_missing_module(self):\n        class Test(unittest.TestCase):\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n        Test.__module__ = 'Module'\n        sys.modules.pop('Module', None)\n\n        result = self.runTests(Test)\n        self.assertEqual(result.testsRun, 2)\n\n    def test_teardown_module(self):\n        class Module(object):\n            moduleTornDown = 0\n            @staticmethod\n            def tearDownModule():\n                Module.moduleTornDown += 1\n\n        class Test(unittest.TestCase):\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n        Test.__module__ = 'Module'\n        sys.modules['Module'] = Module\n\n        result = self.runTests(Test)\n        self.assertEqual(Module.moduleTornDown, 1)\n        self.assertEqual(result.testsRun, 2)\n        self.assertEqual(len(result.errors), 0)\n\n    def test_error_in_teardown_module(self):\n        class Module(object):\n            moduleTornDown = 0\n            @staticmethod\n            def tearDownModule():\n                Module.moduleTornDown += 1\n                raise TypeError('foo')\n\n        class Test(unittest.TestCase):\n            classSetUp = False\n            classTornDown = False\n            @classmethod\n            def setUpClass(cls):\n                Test.classSetUp = True\n            @classmethod\n            def tearDownClass(cls):\n                Test.classTornDown = True\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        class Test2(unittest.TestCase):\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n        Test.__module__ = 'Module'\n        Test2.__module__ = 'Module'\n        sys.modules['Module'] = Module\n\n        result = self.runTests(Test, Test2)\n        self.assertEqual(Module.moduleTornDown, 1)\n        self.assertEqual(result.testsRun, 4)\n        self.assertTrue(Test.classSetUp)\n        self.assertTrue(Test.classTornDown)\n        self.assertEqual(len(result.errors), 1)\n        error, _ = result.errors[0]\n        self.assertEqual(str(error), 'tearDownModule (Module)')\n\n    def test_skiptest_in_setupclass(self):\n        class Test(unittest.TestCase):\n            @classmethod\n            def setUpClass(cls):\n                raise unittest.SkipTest('foo')\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        result = self.runTests(Test)\n        self.assertEqual(result.testsRun, 0)\n        self.assertEqual(len(result.errors), 0)\n        self.assertEqual(len(result.skipped), 1)\n        skipped = result.skipped[0][0]\n        self.assertEqual(str(skipped), 'setUpClass (%s.Test)' % __name__)\n\n    def test_skiptest_in_setupmodule(self):\n        class Test(unittest.TestCase):\n            def test_one(self):\n                pass\n            def test_two(self):\n                pass\n\n        class Module(object):\n            @staticmethod\n            def setUpModule():\n                raise unittest.SkipTest('foo')\n\n        Test.__module__ = 'Module'\n        sys.modules['Module'] = Module\n\n        result = self.runTests(Test)\n        self.assertEqual(result.testsRun, 0)\n        self.assertEqual(len(result.errors), 0)\n        self.assertEqual(len(result.skipped), 1)\n        skipped = result.skipped[0][0]\n        self.assertEqual(str(skipped), 'setUpModule (Module)')\n\n    def test_suite_debug_executes_setups_and_teardowns(self):\n        ordering = []\n\n        class Module(object):\n            @staticmethod\n            def setUpModule():\n                ordering.append('setUpModule')\n            @staticmethod\n            def tearDownModule():\n                ordering.append('tearDownModule')\n\n        class Test(unittest.TestCase):\n            @classmethod\n            def setUpClass(cls):\n                ordering.append('setUpClass')\n            @classmethod\n            def tearDownClass(cls):\n                ordering.append('tearDownClass')\n            def test_something(self):\n                ordering.append('test_something')\n\n        Test.__module__ = 'Module'\n        sys.modules['Module'] = Module\n\n        suite = unittest.defaultTestLoader.loadTestsFromTestCase(Test)\n        suite.debug()\n        expectedOrder = ['setUpModule', 'setUpClass', 'test_something', 'tearDownClass', 'tearDownModule']\n        self.assertEqual(ordering, expectedOrder)\n\n    def test_suite_debug_propagates_exceptions(self):\n        class Module(object):\n            @staticmethod\n            def setUpModule():\n                if phase == 0:\n                    raise Exception('setUpModule')\n            @staticmethod\n            def tearDownModule():\n                if phase == 1:\n                    raise Exception('tearDownModule')\n\n        class Test(unittest.TestCase):\n            @classmethod\n            def setUpClass(cls):\n                if phase == 2:\n                    raise Exception('setUpClass')\n            @classmethod\n            def tearDownClass(cls):\n                if phase == 3:\n                    raise Exception('tearDownClass')\n            def test_something(self):\n                if phase == 4:\n                    raise Exception('test_something')\n\n        Test.__module__ = 'Module'\n        sys.modules['Module'] = Module\n\n        _suite = unittest.defaultTestLoader.loadTestsFromTestCase(Test)\n        suite = unittest.TestSuite()\n        suite.addTest(_suite)\n\n        messages = ('setUpModule', 'tearDownModule', 'setUpClass', 'tearDownClass', 'test_something')\n        for phase, msg in enumerate(messages):\n            with self.assertRaisesRegex(Exception, msg):\n                suite.debug()\n\nif __name__ == '__main__':\n    unittest.main()\n"], "browser.object_storage": [".py", "import pickle\n\nclass __UnProvided():\n    pass\n\n\nclass ObjectStorage():\n\n    def __init__(self, storage):\n        self.storage = storage\n\n    def __delitem__(self, key):\n        del self.storage[pickle.dumps(key)]\n\n    def __getitem__(self, key):\n        return pickle.loads(self.storage[pickle.dumps(key)])\n\n    def __setitem__(self, key, value):\n        self.storage[pickle.dumps(key)] = pickle.dumps(value)\n\n    def __contains__(self, key):\n        return pickle.dumps(key) in self.storage\n\n    def get(self, key, default=None):\n        if pickle.dumps(key) in self.storage:\n            return self.storage[pickle.dumps(key)]\n        return default\n\n    def pop(self, key, default=__UnProvided()):\n        if type(default) is __UnProvided or pickle.dumps(key) in self.storage:\n            return pickle.loads(self.storage.pop(pickle.dumps(key)))\n        return default\n\n    def __iter__(self):\n        keys = self.keys()\n        return keys.__iter__()\n\n    def keys(self):\n        return [pickle.loads(key) for key in self.storage.keys()]\n\n    def values(self):\n        return [pickle.loads(val) for val in self.storage.values()]\n\n    def items(self):\n        return list(zip(self.keys(), self.values()))\n\n    def clear(self):\n        self.storage.clear()\n\n    def __len__(self):\n        return len(self.storage)\n"], "string": [".py", "\"\"\"A collection of string constants.\n\nPublic module variables:\n\nwhitespace -- a string containing all ASCII whitespace\nascii_lowercase -- a string containing all ASCII lowercase letters\nascii_uppercase -- a string containing all ASCII uppercase letters\nascii_letters -- a string containing all ASCII letters\ndigits -- a string containing all ASCII decimal digits\nhexdigits -- a string containing all ASCII hexadecimal digits\noctdigits -- a string containing all ASCII octal digits\npunctuation -- a string containing all ASCII punctuation characters\nprintable -- a string containing all ASCII characters considered printable\n\n\"\"\"\n\nimport _string\n\n# Some strings for ctype-style character classification\nwhitespace = ' \\t\\n\\r\\v\\f'\nascii_lowercase = 'abcdefghijklmnopqrstuvwxyz'\nascii_uppercase = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\nascii_letters = ascii_lowercase + ascii_uppercase\ndigits = '0123456789'\nhexdigits = digits + 'abcdef' + 'ABCDEF'\noctdigits = '01234567'\npunctuation = \"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"\nprintable = digits + ascii_letters + punctuation + whitespace\n\n# Functions which aren't available as string methods.\n\n# Capitalize the words in a string, e.g. \" aBc  dEf \" -> \"Abc Def\".\ndef capwords(s, sep=None):\n    \"\"\"capwords(s [,sep]) -> string\n\n    Split the argument into words using split, capitalize each\n    word using capitalize, and join the capitalized words using\n    join.  If the optional second argument sep is absent or None,\n    runs of whitespace characters are replaced by a single space\n    and leading and trailing whitespace are removed, otherwise\n    sep is used to split and join the words.\n\n    \"\"\"\n    return (sep or ' ').join(x.capitalize() for x in s.split(sep))\n\n\n####################################################################\nimport re as _re\nfrom collections import ChainMap\n\nclass _TemplateMetaclass(type):\n    pattern = r\"\"\"\n    %(delim)s(?:\n      (?P<escaped>%(delim)s) |   # Escape sequence of two delimiters\n      (?P<named>%(id)s)      |   # delimiter and a Python identifier\n      {(?P<braced>%(id)s)}   |   # delimiter and a braced identifier\n      (?P<invalid>)              # Other ill-formed delimiter exprs\n    )\n    \"\"\"\n\n    def __init__(cls, name, bases, dct):\n        super(_TemplateMetaclass, cls).__init__(name, bases, dct)\n        if 'pattern' in dct:\n            pattern = cls.pattern\n        else:\n            pattern = _TemplateMetaclass.pattern % {\n                'delim' : _re.escape(cls.delimiter),\n                'id'    : cls.idpattern,\n                }\n        cls.pattern = _re.compile(pattern, cls.flags | _re.VERBOSE)\n\n\nclass Template(metaclass=_TemplateMetaclass):\n    \"\"\"A string class for supporting $-substitutions.\"\"\"\n\n    delimiter = '$'\n    idpattern = r'[_a-z][_a-z0-9]*'\n    flags = _re.IGNORECASE\n\n    def __init__(self, template):\n        self.template = template\n\n    # Search for $$, $identifier, ${identifier}, and any bare $'s\n\n    def _invalid(self, mo):\n        i = mo.start('invalid')\n        lines = self.template[:i].splitlines(keepends=True)\n        if not lines:\n            colno = 1\n            lineno = 1\n        else:\n            colno = i - len(''.join(lines[:-1]))\n            lineno = len(lines)\n        raise ValueError('Invalid placeholder in string: line %d, col %d' %\n                         (lineno, colno))\n\n    def substitute(self, *args, **kws):\n        if len(args) > 1:\n            raise TypeError('Too many positional arguments')\n        if not args:\n            mapping = kws\n        elif kws:\n            mapping = ChainMap(kws, args[0])\n        else:\n            mapping = args[0]\n        # Helper function for .sub()\n        def convert(mo):\n            # Check the most common path first.\n            named = mo.group('named') or mo.group('braced')\n            if named is not None:\n                val = mapping[named]\n                # We use this idiom instead of str() because the latter will\n                # fail if val is a Unicode containing non-ASCII characters.\n                return '%s' % (val,)\n            if mo.group('escaped') is not None:\n                return self.delimiter\n            if mo.group('invalid') is not None:\n                self._invalid(mo)\n            raise ValueError('Unrecognized named group in pattern',\n                             self.pattern)\n        return self.pattern.sub(convert, self.template)\n\n    def safe_substitute(self, *args, **kws):\n        if len(args) > 1:\n            raise TypeError('Too many positional arguments')\n        if not args:\n            mapping = kws\n        elif kws:\n            mapping = ChainMap(kws, args[0])\n        else:\n            mapping = args[0]\n        # Helper function for .sub()\n        def convert(mo):\n            named = mo.group('named') or mo.group('braced')\n            if named is not None:\n                try:\n                    # We use this idiom instead of str() because the latter\n                    # will fail if val is a Unicode containing non-ASCII\n                    return '%s' % (mapping[named],)\n                except KeyError:\n                    return mo.group()\n            if mo.group('escaped') is not None:\n                return self.delimiter\n            if mo.group('invalid') is not None:\n                return mo.group()\n            raise ValueError('Unrecognized named group in pattern',\n                             self.pattern)\n        return self.pattern.sub(convert, self.template)\n\n\n\n########################################################################\n# the Formatter class\n# see PEP 3101 for details and purpose of this class\n\n# The hard parts are reused from the C implementation.  They're exposed as \"_\"\n# prefixed methods of str.\n\n# The overall parser is implemented in _string.formatter_parser.\n# The field name parser is implemented in _string.formatter_field_name_split\n\nclass Formatter:\n    def format(self, format_string, *args, **kwargs):\n        return self.vformat(format_string, args, kwargs)\n\n    def vformat(self, format_string, args, kwargs):\n        used_args = set()\n        result = self._vformat(format_string, args, kwargs, used_args, 2)\n        self.check_unused_args(used_args, args, kwargs)\n        return result\n\n    def _vformat(self, format_string, args, kwargs, used_args, recursion_depth):\n        if recursion_depth < 0:\n            raise ValueError('Max string recursion exceeded')\n        result = []\n        for literal_text, field_name, format_spec, conversion in \\\n                self.parse(format_string):\n\n            # output the literal text\n            if literal_text:\n                result.append(literal_text)\n\n            # if there's a field, output it\n            if field_name is not None:\n                # this is some markup, find the object and do\n                #  the formatting\n\n                # given the field_name, find the object it references\n                #  and the argument it came from\n                obj, arg_used = self.get_field(field_name, args, kwargs)\n                used_args.add(arg_used)\n\n                # do any conversion on the resulting object\n                obj = self.convert_field(obj, conversion)\n\n                # expand the format spec, if needed\n                format_spec = self._vformat(format_spec, args, kwargs,\n                                            used_args, recursion_depth-1)\n\n                # format the object and append to the result\n                result.append(self.format_field(obj, format_spec))\n\n        return ''.join(result)\n\n\n    def get_value(self, key, args, kwargs):\n        if isinstance(key, int):\n            return args[key]\n        else:\n            return kwargs[key]\n\n\n    def check_unused_args(self, used_args, args, kwargs):\n        pass\n\n\n    def format_field(self, value, format_spec):\n        return format(value, format_spec)\n\n\n    def convert_field(self, value, conversion):\n        # do any conversion on the resulting object\n        if conversion is None:\n            return value\n        elif conversion == 's':\n            return str(value)\n        elif conversion == 'r':\n            return repr(value)\n        elif conversion == 'a':\n            return ascii(value)\n        raise ValueError(\"Unknown conversion specifier {0!s}\".format(conversion))\n\n\n    # returns an iterable that contains tuples of the form:\n    # (literal_text, field_name, format_spec, conversion)\n    # literal_text can be zero length\n    # field_name can be None, in which case there's no\n    #  object to format and output\n    # if field_name is not None, it is looked up, formatted\n    #  with format_spec and conversion and then used\n    def parse(self, format_string):\n        return _string.formatter_parser(format_string)\n\n\n    # given a field_name, find the object it references.\n    #  field_name:   the field being looked up, e.g. \"0.name\"\n    #                 or \"lookup[3]\"\n    #  used_args:    a set of which args have been used\n    #  args, kwargs: as passed in to vformat\n    def get_field(self, field_name, args, kwargs):\n        first, rest = _string.formatter_field_name_split(field_name)\n\n        obj = self.get_value(first, args, kwargs)\n\n        # loop through the rest of the field_name, doing\n        #  getattr or getitem as needed\n        for is_attr, i in rest:\n            if is_attr:\n                obj = getattr(obj, i)\n            else:\n                obj = obj[i]\n\n        return obj, first\n"], "browser.local_storage": [".py", "# local storage in browser\n\nfrom javascript import JSObject\n\nclass __UnProvided():\n    pass\n\nclass LocalStorage():\n    storage_type = \"local_storage\"\n\n    def __init__(self):\n        self.store = JSObject(__BRYTHON__.local_storage)\n\n    def __delitem__(self, key):\n        if (not isinstance(key, str)):\n            raise TypeError(\"key must be string\")\n        if key not in self:\n            raise KeyError(key)\n        self.store.removeItem(key)\n\n    def __getitem__(self, key):\n        if (not isinstance(key, str)):\n            raise TypeError(\"key must be string\")\n        res = __BRYTHON__.JSObject(self.store.getItem(key))\n        if res:\n            return res\n        raise KeyError(key)\n\n    def __setitem__(self, key, value):\n        if (not isinstance(key, str)):\n            raise TypeError(\"key must be string\")\n        if (not isinstance(value, str)):\n            raise TypeError(\"value must be string\")\n        self.store.setItem(key, value)\n\n    # implement \"in\" functionality\n    def __contains__(self, key):\n        if (not isinstance(key, str)):\n            raise TypeError(\"key must be string\")\n        res = __BRYTHON__.JSObject(self.store.getItem(key))\n        if res is None:\n            return False\n        return True\n\n    def __iter__(self):\n        keys = self.keys()\n        return keys.__iter__()\n\n    def get(self, key, default=None):\n        if (not isinstance(key, str)):\n            raise TypeError(\"key must be string\")\n        return __BRYTHON__.JSObject(self.store.getItem(key)) or default\n\n    def pop(self, key, default=__UnProvided()):\n        if (not isinstance(key, str)):\n            raise TypeError(\"key must be string\")\n        if type(default) is __UnProvided:\n            ret = self.get(key)\n            del self[key]  # will throw key error if doesn't exist\n            return ret\n        else:\n            if key in self:\n                ret = self.get(key)\n                del self[key]\n                return ret\n            else:\n                return default\n\n    # while a real dict provides a view, returning a generator would less helpful than simply returning a list\n    # and creating a custom iterator is overkill and would likely result in slower performance\n    def keys(self):\n        return [__BRYTHON__.JSObject(self.store.key(i)) for i in range(self.store.length)]\n\n    def values(self):\n        return [__BRYTHON__.JSObject(self.__getitem__(k)) for k in self.keys()]\n\n    def items(self):\n        return list(zip(self.keys(), self.values()))\n\n    def clear(self):\n        self.store.clear()\n\n    def __len__(self):\n        return self.store.length\n\nstorage = LocalStorage()\n"], "multiprocessing.dummy": [".py", "#\n# Support for the API of the multiprocessing package using threads\n#\n# multiprocessing/dummy/__init__.py\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n# 3. Neither the name of author nor the names of any contributors may be\n#    used to endorse or promote products derived from this software\n#    without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS \"AS IS\" AND\n# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE\n# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n# OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n# SUCH DAMAGE.\n#\n\n__all__ = [\n    'Process', 'current_process', 'active_children', 'freeze_support',\n    'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Condition',\n    'Event', 'Barrier', 'Queue', 'Manager', 'Pipe', 'Pool', 'JoinableQueue'\n    ]\n\n#\n# Imports\n#\n\nimport threading\nimport sys\nimport weakref\n#brython fix me\n#import array\n\nfrom multiprocessing.dummy.connection import Pipe\nfrom threading import Lock, RLock, Semaphore, BoundedSemaphore\nfrom threading import Event, Condition, Barrier\nfrom queue import Queue\n\n#\n#\n#\n\nclass DummyProcess(threading.Thread):\n\n    def __init__(self, group=None, target=None, name=None, args=(), kwargs={}):\n        threading.Thread.__init__(self, group, target, name, args, kwargs)\n        self._pid = None\n        self._children = weakref.WeakKeyDictionary()\n        self._start_called = False\n        self._parent = current_process()\n\n    def start(self):\n        assert self._parent is current_process()\n        self._start_called = True\n        if hasattr(self._parent, '_children'):\n            self._parent._children[self] = None\n        threading.Thread.start(self)\n\n    @property\n    def exitcode(self):\n        if self._start_called and not self.is_alive():\n            return 0\n        else:\n            return None\n\n#\n#\n#\n\nProcess = DummyProcess\ncurrent_process = threading.current_thread\ncurrent_process()._children = weakref.WeakKeyDictionary()\n\ndef active_children():\n    children = current_process()._children\n    for p in list(children):\n        if not p.is_alive():\n            children.pop(p, None)\n    return list(children)\n\ndef freeze_support():\n    pass\n\n#\n#\n#\n\nclass Namespace(object):\n    def __init__(self, **kwds):\n        self.__dict__.update(kwds)\n    def __repr__(self):\n        items = list(self.__dict__.items())\n        temp = []\n        for name, value in items:\n            if not name.startswith('_'):\n                temp.append('%s=%r' % (name, value))\n        temp.sort()\n        return 'Namespace(%s)' % str.join(', ', temp)\n\ndict = dict\nlist = list\n\n#brython fix me\n#def Array(typecode, sequence, lock=True):\n#    return array.array(typecode, sequence)\n\nclass Value(object):\n    def __init__(self, typecode, value, lock=True):\n        self._typecode = typecode\n        self._value = value\n    def _get(self):\n        return self._value\n    def _set(self, value):\n        self._value = value\n    value = property(_get, _set)\n    def __repr__(self):\n        return '<%r(%r, %r)>'%(type(self).__name__,self._typecode,self._value)\n\ndef Manager():\n    return sys.modules[__name__]\n\ndef shutdown():\n    pass\n\ndef Pool(processes=None, initializer=None, initargs=()):\n    from multiprocessing.pool import ThreadPool\n    return ThreadPool(processes, initializer, initargs)\n\nJoinableQueue = Queue\n", 1], "xml.dom.expatbuilder": [".py", "\"\"\"Facility to use the Expat parser to load a minidom instance\nfrom a string or file.\n\nThis avoids all the overhead of SAX and pulldom to gain performance.\n\"\"\"\n\n# Warning!\n#\n# This module is tightly bound to the implementation details of the\n# minidom DOM and can't be used with other DOM implementations.  This\n# is due, in part, to a lack of appropriate methods in the DOM (there is\n# no way to create Entity and Notation nodes via the DOM Level 2\n# interface), and for performance.  The later is the cause of some fairly\n# cryptic code.\n#\n# Performance hacks:\n#\n#   -  .character_data_handler() has an extra case in which continuing\n#      data is appended to an existing Text node; this can be a\n#      speedup since pyexpat can break up character data into multiple\n#      callbacks even though we set the buffer_text attribute on the\n#      parser.  This also gives us the advantage that we don't need a\n#      separate normalization pass.\n#\n#   -  Determining that a node exists is done using an identity comparison\n#      with None rather than a truth test; this avoids searching for and\n#      calling any methods on the node object if it exists.  (A rather\n#      nice speedup is achieved this way as well!)\n\nfrom xml.dom import xmlbuilder, minidom, Node\nfrom xml.dom import EMPTY_NAMESPACE, EMPTY_PREFIX, XMLNS_NAMESPACE\nfrom xml.parsers import expat\nfrom xml.dom.minidom import _append_child, _set_attribute_node\nfrom xml.dom.NodeFilter import NodeFilter\n\nTEXT_NODE = Node.TEXT_NODE\nCDATA_SECTION_NODE = Node.CDATA_SECTION_NODE\nDOCUMENT_NODE = Node.DOCUMENT_NODE\n\nFILTER_ACCEPT = xmlbuilder.DOMBuilderFilter.FILTER_ACCEPT\nFILTER_REJECT = xmlbuilder.DOMBuilderFilter.FILTER_REJECT\nFILTER_SKIP = xmlbuilder.DOMBuilderFilter.FILTER_SKIP\nFILTER_INTERRUPT = xmlbuilder.DOMBuilderFilter.FILTER_INTERRUPT\n\ntheDOMImplementation = minidom.getDOMImplementation()\n\n# Expat typename -> TypeInfo\n_typeinfo_map = {\n    \"CDATA\":    minidom.TypeInfo(None, \"cdata\"),\n    \"ENUM\":     minidom.TypeInfo(None, \"enumeration\"),\n    \"ENTITY\":   minidom.TypeInfo(None, \"entity\"),\n    \"ENTITIES\": minidom.TypeInfo(None, \"entities\"),\n    \"ID\":       minidom.TypeInfo(None, \"id\"),\n    \"IDREF\":    minidom.TypeInfo(None, \"idref\"),\n    \"IDREFS\":   minidom.TypeInfo(None, \"idrefs\"),\n    \"NMTOKEN\":  minidom.TypeInfo(None, \"nmtoken\"),\n    \"NMTOKENS\": minidom.TypeInfo(None, \"nmtokens\"),\n    }\n\nclass ElementInfo(object):\n    __slots__ = '_attr_info', '_model', 'tagName'\n\n    def __init__(self, tagName, model=None):\n        self.tagName = tagName\n        self._attr_info = []\n        self._model = model\n\n    def __getstate__(self):\n        return self._attr_info, self._model, self.tagName\n\n    def __setstate__(self, state):\n        self._attr_info, self._model, self.tagName = state\n\n    def getAttributeType(self, aname):\n        for info in self._attr_info:\n            if info[1] == aname:\n                t = info[-2]\n                if t[0] == \"(\":\n                    return _typeinfo_map[\"ENUM\"]\n                else:\n                    return _typeinfo_map[info[-2]]\n        return minidom._no_type\n\n    def getAttributeTypeNS(self, namespaceURI, localName):\n        return minidom._no_type\n\n    def isElementContent(self):\n        if self._model:\n            type = self._model[0]\n            return type not in (expat.model.XML_CTYPE_ANY,\n                                expat.model.XML_CTYPE_MIXED)\n        else:\n            return False\n\n    def isEmpty(self):\n        if self._model:\n            return self._model[0] == expat.model.XML_CTYPE_EMPTY\n        else:\n            return False\n\n    def isId(self, aname):\n        for info in self._attr_info:\n            if info[1] == aname:\n                return info[-2] == \"ID\"\n        return False\n\n    def isIdNS(self, euri, ename, auri, aname):\n        # not sure this is meaningful\n        return self.isId((auri, aname))\n\ndef _intern(builder, s):\n    return builder._intern_setdefault(s, s)\n\ndef _parse_ns_name(builder, name):\n    assert ' ' in name\n    parts = name.split(' ')\n    intern = builder._intern_setdefault\n    if len(parts) == 3:\n        uri, localname, prefix = parts\n        prefix = intern(prefix, prefix)\n        qname = \"%s:%s\" % (prefix, localname)\n        qname = intern(qname, qname)\n        localname = intern(localname, localname)\n    else:\n        uri, localname = parts\n        prefix = EMPTY_PREFIX\n        qname = localname = intern(localname, localname)\n    return intern(uri, uri), localname, prefix, qname\n\n\nclass ExpatBuilder:\n    \"\"\"Document builder that uses Expat to build a ParsedXML.DOM document\n    instance.\"\"\"\n\n    def __init__(self, options=None):\n        if options is None:\n            options = xmlbuilder.Options()\n        self._options = options\n        if self._options.filter is not None:\n            self._filter = FilterVisibilityController(self._options.filter)\n        else:\n            self._filter = None\n            # This *really* doesn't do anything in this case, so\n            # override it with something fast & minimal.\n            self._finish_start_element = id\n        self._parser = None\n        self.reset()\n\n    def createParser(self):\n        \"\"\"Create a new parser object.\"\"\"\n        return expat.ParserCreate()\n\n    def getParser(self):\n        \"\"\"Return the parser object, creating a new one if needed.\"\"\"\n        if not self._parser:\n            self._parser = self.createParser()\n            self._intern_setdefault = self._parser.intern.setdefault\n            self._parser.buffer_text = True\n            self._parser.ordered_attributes = True\n            self._parser.specified_attributes = True\n            self.install(self._parser)\n        return self._parser\n\n    def reset(self):\n        \"\"\"Free all data structures used during DOM construction.\"\"\"\n        self.document = theDOMImplementation.createDocument(\n            EMPTY_NAMESPACE, None, None)\n        self.curNode = self.document\n        self._elem_info = self.document._elem_info\n        self._cdata = False\n\n    def install(self, parser):\n        \"\"\"Install the callbacks needed to build the DOM into the parser.\"\"\"\n        # This creates circular references!\n        parser.StartDoctypeDeclHandler = self.start_doctype_decl_handler\n        parser.StartElementHandler = self.first_element_handler\n        parser.EndElementHandler = self.end_element_handler\n        parser.ProcessingInstructionHandler = self.pi_handler\n        if self._options.entities:\n            parser.EntityDeclHandler = self.entity_decl_handler\n        parser.NotationDeclHandler = self.notation_decl_handler\n        if self._options.comments:\n            parser.CommentHandler = self.comment_handler\n        if self._options.cdata_sections:\n            parser.StartCdataSectionHandler = self.start_cdata_section_handler\n            parser.EndCdataSectionHandler = self.end_cdata_section_handler\n            parser.CharacterDataHandler = self.character_data_handler_cdata\n        else:\n            parser.CharacterDataHandler = self.character_data_handler\n        parser.ExternalEntityRefHandler = self.external_entity_ref_handler\n        parser.XmlDeclHandler = self.xml_decl_handler\n        parser.ElementDeclHandler = self.element_decl_handler\n        parser.AttlistDeclHandler = self.attlist_decl_handler\n\n    def parseFile(self, file):\n        \"\"\"Parse a document from a file object, returning the document\n        node.\"\"\"\n        parser = self.getParser()\n        first_buffer = True\n        try:\n            while 1:\n                buffer = file.read(16*1024)\n                if not buffer:\n                    break\n                parser.Parse(buffer, 0)\n                if first_buffer and self.document.documentElement:\n                    self._setup_subset(buffer)\n                first_buffer = False\n            parser.Parse(\"\", True)\n        except ParseEscape:\n            pass\n        doc = self.document\n        self.reset()\n        self._parser = None\n        return doc\n\n    def parseString(self, string):\n        \"\"\"Parse a document from a string, returning the document node.\"\"\"\n        parser = self.getParser()\n        try:\n            parser.Parse(string, True)\n            self._setup_subset(string)\n        except ParseEscape:\n            pass\n        doc = self.document\n        self.reset()\n        self._parser = None\n        return doc\n\n    def _setup_subset(self, buffer):\n        \"\"\"Load the internal subset if there might be one.\"\"\"\n        if self.document.doctype:\n            extractor = InternalSubsetExtractor()\n            extractor.parseString(buffer)\n            subset = extractor.getSubset()\n            self.document.doctype.internalSubset = subset\n\n    def start_doctype_decl_handler(self, doctypeName, systemId, publicId,\n                                   has_internal_subset):\n        doctype = self.document.implementation.createDocumentType(\n            doctypeName, publicId, systemId)\n        doctype.ownerDocument = self.document\n        _append_child(self.document, doctype)\n        self.document.doctype = doctype\n        if self._filter and self._filter.acceptNode(doctype) == FILTER_REJECT:\n            self.document.doctype = None\n            del self.document.childNodes[-1]\n            doctype = None\n            self._parser.EntityDeclHandler = None\n            self._parser.NotationDeclHandler = None\n        if has_internal_subset:\n            if doctype is not None:\n                doctype.entities._seq = []\n                doctype.notations._seq = []\n            self._parser.CommentHandler = None\n            self._parser.ProcessingInstructionHandler = None\n            self._parser.EndDoctypeDeclHandler = self.end_doctype_decl_handler\n\n    def end_doctype_decl_handler(self):\n        if self._options.comments:\n            self._parser.CommentHandler = self.comment_handler\n        self._parser.ProcessingInstructionHandler = self.pi_handler\n        if not (self._elem_info or self._filter):\n            self._finish_end_element = id\n\n    def pi_handler(self, target, data):\n        node = self.document.createProcessingInstruction(target, data)\n        _append_child(self.curNode, node)\n        if self._filter and self._filter.acceptNode(node) == FILTER_REJECT:\n            self.curNode.removeChild(node)\n\n    def character_data_handler_cdata(self, data):\n        childNodes = self.curNode.childNodes\n        if self._cdata:\n            if (  self._cdata_continue\n                  and childNodes[-1].nodeType == CDATA_SECTION_NODE):\n                childNodes[-1].appendData(data)\n                return\n            node = self.document.createCDATASection(data)\n            self._cdata_continue = True\n        elif childNodes and childNodes[-1].nodeType == TEXT_NODE:\n            node = childNodes[-1]\n            value = node.data + data\n            node.data = value\n            return\n        else:\n            node = minidom.Text()\n            node.data = data\n            node.ownerDocument = self.document\n        _append_child(self.curNode, node)\n\n    def character_data_handler(self, data):\n        childNodes = self.curNode.childNodes\n        if childNodes and childNodes[-1].nodeType == TEXT_NODE:\n            node = childNodes[-1]\n            node.data = node.data + data\n            return\n        node = minidom.Text()\n        node.data = node.data + data\n        node.ownerDocument = self.document\n        _append_child(self.curNode, node)\n\n    def entity_decl_handler(self, entityName, is_parameter_entity, value,\n                            base, systemId, publicId, notationName):\n        if is_parameter_entity:\n            # we don't care about parameter entities for the DOM\n            return\n        if not self._options.entities:\n            return\n        node = self.document._create_entity(entityName, publicId,\n                                            systemId, notationName)\n        if value is not None:\n            # internal entity\n            # node *should* be readonly, but we'll cheat\n            child = self.document.createTextNode(value)\n            node.childNodes.append(child)\n        self.document.doctype.entities._seq.append(node)\n        if self._filter and self._filter.acceptNode(node) == FILTER_REJECT:\n            del self.document.doctype.entities._seq[-1]\n\n    def notation_decl_handler(self, notationName, base, systemId, publicId):\n        node = self.document._create_notation(notationName, publicId, systemId)\n        self.document.doctype.notations._seq.append(node)\n        if self._filter and self._filter.acceptNode(node) == FILTER_ACCEPT:\n            del self.document.doctype.notations._seq[-1]\n\n    def comment_handler(self, data):\n        node = self.document.createComment(data)\n        _append_child(self.curNode, node)\n        if self._filter and self._filter.acceptNode(node) == FILTER_REJECT:\n            self.curNode.removeChild(node)\n\n    def start_cdata_section_handler(self):\n        self._cdata = True\n        self._cdata_continue = False\n\n    def end_cdata_section_handler(self):\n        self._cdata = False\n        self._cdata_continue = False\n\n    def external_entity_ref_handler(self, context, base, systemId, publicId):\n        return 1\n\n    def first_element_handler(self, name, attributes):\n        if self._filter is None and not self._elem_info:\n            self._finish_end_element = id\n        self.getParser().StartElementHandler = self.start_element_handler\n        self.start_element_handler(name, attributes)\n\n    def start_element_handler(self, name, attributes):\n        node = self.document.createElement(name)\n        _append_child(self.curNode, node)\n        self.curNode = node\n\n        if attributes:\n            for i in range(0, len(attributes), 2):\n                a = minidom.Attr(attributes[i], EMPTY_NAMESPACE,\n                                 None, EMPTY_PREFIX)\n                value = attributes[i+1]\n                a.value = value\n                a.ownerDocument = self.document\n                _set_attribute_node(node, a)\n\n        if node is not self.document.documentElement:\n            self._finish_start_element(node)\n\n    def _finish_start_element(self, node):\n        if self._filter:\n            # To be general, we'd have to call isSameNode(), but this\n            # is sufficient for minidom:\n            if node is self.document.documentElement:\n                return\n            filt = self._filter.startContainer(node)\n            if filt == FILTER_REJECT:\n                # ignore this node & all descendents\n                Rejecter(self)\n            elif filt == FILTER_SKIP:\n                # ignore this node, but make it's children become\n                # children of the parent node\n                Skipper(self)\n            else:\n                return\n            self.curNode = node.parentNode\n            node.parentNode.removeChild(node)\n            node.unlink()\n\n    # If this ever changes, Namespaces.end_element_handler() needs to\n    # be changed to match.\n    #\n    def end_element_handler(self, name):\n        curNode = self.curNode\n        self.curNode = curNode.parentNode\n        self._finish_end_element(curNode)\n\n    def _finish_end_element(self, curNode):\n        info = self._elem_info.get(curNode.tagName)\n        if info:\n            self._handle_white_text_nodes(curNode, info)\n        if self._filter:\n            if curNode is self.document.documentElement:\n                return\n            if self._filter.acceptNode(curNode) == FILTER_REJECT:\n                self.curNode.removeChild(curNode)\n                curNode.unlink()\n\n    def _handle_white_text_nodes(self, node, info):\n        if (self._options.whitespace_in_element_content\n            or not info.isElementContent()):\n            return\n\n        # We have element type information and should remove ignorable\n        # whitespace; identify for text nodes which contain only\n        # whitespace.\n        L = []\n        for child in node.childNodes:\n            if child.nodeType == TEXT_NODE and not child.data.strip():\n                L.append(child)\n\n        # Remove ignorable whitespace from the tree.\n        for child in L:\n            node.removeChild(child)\n\n    def element_decl_handler(self, name, model):\n        info = self._elem_info.get(name)\n        if info is None:\n            self._elem_info[name] = ElementInfo(name, model)\n        else:\n            assert info._model is None\n            info._model = model\n\n    def attlist_decl_handler(self, elem, name, type, default, required):\n        info = self._elem_info.get(elem)\n        if info is None:\n            info = ElementInfo(elem)\n            self._elem_info[elem] = info\n        info._attr_info.append(\n            [None, name, None, None, default, 0, type, required])\n\n    def xml_decl_handler(self, version, encoding, standalone):\n        self.document.version = version\n        self.document.encoding = encoding\n        # This is still a little ugly, thanks to the pyexpat API. ;-(\n        if standalone >= 0:\n            if standalone:\n                self.document.standalone = True\n            else:\n                self.document.standalone = False\n\n\n# Don't include FILTER_INTERRUPT, since that's checked separately\n# where allowed.\n_ALLOWED_FILTER_RETURNS = (FILTER_ACCEPT, FILTER_REJECT, FILTER_SKIP)\n\nclass FilterVisibilityController(object):\n    \"\"\"Wrapper around a DOMBuilderFilter which implements the checks\n    to make the whatToShow filter attribute work.\"\"\"\n\n    __slots__ = 'filter',\n\n    def __init__(self, filter):\n        self.filter = filter\n\n    def startContainer(self, node):\n        mask = self._nodetype_mask[node.nodeType]\n        if self.filter.whatToShow & mask:\n            val = self.filter.startContainer(node)\n            if val == FILTER_INTERRUPT:\n                raise ParseEscape\n            if val not in _ALLOWED_FILTER_RETURNS:\n                raise ValueError(\n                      \"startContainer() returned illegal value: \" + repr(val))\n            return val\n        else:\n            return FILTER_ACCEPT\n\n    def acceptNode(self, node):\n        mask = self._nodetype_mask[node.nodeType]\n        if self.filter.whatToShow & mask:\n            val = self.filter.acceptNode(node)\n            if val == FILTER_INTERRUPT:\n                raise ParseEscape\n            if val == FILTER_SKIP:\n                # move all child nodes to the parent, and remove this node\n                parent = node.parentNode\n                for child in node.childNodes[:]:\n                    parent.appendChild(child)\n                # node is handled by the caller\n                return FILTER_REJECT\n            if val not in _ALLOWED_FILTER_RETURNS:\n                raise ValueError(\n                      \"acceptNode() returned illegal value: \" + repr(val))\n            return val\n        else:\n            return FILTER_ACCEPT\n\n    _nodetype_mask = {\n        Node.ELEMENT_NODE:                NodeFilter.SHOW_ELEMENT,\n        Node.ATTRIBUTE_NODE:              NodeFilter.SHOW_ATTRIBUTE,\n        Node.TEXT_NODE:                   NodeFilter.SHOW_TEXT,\n        Node.CDATA_SECTION_NODE:          NodeFilter.SHOW_CDATA_SECTION,\n        Node.ENTITY_REFERENCE_NODE:       NodeFilter.SHOW_ENTITY_REFERENCE,\n        Node.ENTITY_NODE:                 NodeFilter.SHOW_ENTITY,\n        Node.PROCESSING_INSTRUCTION_NODE: NodeFilter.SHOW_PROCESSING_INSTRUCTION,\n        Node.COMMENT_NODE:                NodeFilter.SHOW_COMMENT,\n        Node.DOCUMENT_NODE:               NodeFilter.SHOW_DOCUMENT,\n        Node.DOCUMENT_TYPE_NODE:          NodeFilter.SHOW_DOCUMENT_TYPE,\n        Node.DOCUMENT_FRAGMENT_NODE:      NodeFilter.SHOW_DOCUMENT_FRAGMENT,\n        Node.NOTATION_NODE:               NodeFilter.SHOW_NOTATION,\n        }\n\n\nclass FilterCrutch(object):\n    __slots__ = '_builder', '_level', '_old_start', '_old_end'\n\n    def __init__(self, builder):\n        self._level = 0\n        self._builder = builder\n        parser = builder._parser\n        self._old_start = parser.StartElementHandler\n        self._old_end = parser.EndElementHandler\n        parser.StartElementHandler = self.start_element_handler\n        parser.EndElementHandler = self.end_element_handler\n\nclass Rejecter(FilterCrutch):\n    __slots__ = ()\n\n    def __init__(self, builder):\n        FilterCrutch.__init__(self, builder)\n        parser = builder._parser\n        for name in (\"ProcessingInstructionHandler\",\n                     \"CommentHandler\",\n                     \"CharacterDataHandler\",\n                     \"StartCdataSectionHandler\",\n                     \"EndCdataSectionHandler\",\n                     \"ExternalEntityRefHandler\",\n                     ):\n            setattr(parser, name, None)\n\n    def start_element_handler(self, *args):\n        self._level = self._level + 1\n\n    def end_element_handler(self, *args):\n        if self._level == 0:\n            # restore the old handlers\n            parser = self._builder._parser\n            self._builder.install(parser)\n            parser.StartElementHandler = self._old_start\n            parser.EndElementHandler = self._old_end\n        else:\n            self._level = self._level - 1\n\nclass Skipper(FilterCrutch):\n    __slots__ = ()\n\n    def start_element_handler(self, *args):\n        node = self._builder.curNode\n        self._old_start(*args)\n        if self._builder.curNode is not node:\n            self._level = self._level + 1\n\n    def end_element_handler(self, *args):\n        if self._level == 0:\n            # We're popping back out of the node we're skipping, so we\n            # shouldn't need to do anything but reset the handlers.\n            self._builder._parser.StartElementHandler = self._old_start\n            self._builder._parser.EndElementHandler = self._old_end\n            self._builder = None\n        else:\n            self._level = self._level - 1\n            self._old_end(*args)\n\n\n# framework document used by the fragment builder.\n# Takes a string for the doctype, subset string, and namespace attrs string.\n\n_FRAGMENT_BUILDER_INTERNAL_SYSTEM_ID = \\\n    \"http://xml.python.org/entities/fragment-builder/internal\"\n\n_FRAGMENT_BUILDER_TEMPLATE = (\n    '''\\\n<!DOCTYPE wrapper\n  %%s [\n  <!ENTITY fragment-builder-internal\n    SYSTEM \"%s\">\n%%s\n]>\n<wrapper %%s\n>&fragment-builder-internal;</wrapper>'''\n    % _FRAGMENT_BUILDER_INTERNAL_SYSTEM_ID)\n\n\nclass FragmentBuilder(ExpatBuilder):\n    \"\"\"Builder which constructs document fragments given XML source\n    text and a context node.\n\n    The context node is expected to provide information about the\n    namespace declarations which are in scope at the start of the\n    fragment.\n    \"\"\"\n\n    def __init__(self, context, options=None):\n        if context.nodeType == DOCUMENT_NODE:\n            self.originalDocument = context\n            self.context = context\n        else:\n            self.originalDocument = context.ownerDocument\n            self.context = context\n        ExpatBuilder.__init__(self, options)\n\n    def reset(self):\n        ExpatBuilder.reset(self)\n        self.fragment = None\n\n    def parseFile(self, file):\n        \"\"\"Parse a document fragment from a file object, returning the\n        fragment node.\"\"\"\n        return self.parseString(file.read())\n\n    def parseString(self, string):\n        \"\"\"Parse a document fragment from a string, returning the\n        fragment node.\"\"\"\n        self._source = string\n        parser = self.getParser()\n        doctype = self.originalDocument.doctype\n        ident = \"\"\n        if doctype:\n            subset = doctype.internalSubset or self._getDeclarations()\n            if doctype.publicId:\n                ident = ('PUBLIC \"%s\" \"%s\"'\n                         % (doctype.publicId, doctype.systemId))\n            elif doctype.systemId:\n                ident = 'SYSTEM \"%s\"' % doctype.systemId\n        else:\n            subset = \"\"\n        nsattrs = self._getNSattrs() # get ns decls from node's ancestors\n        document = _FRAGMENT_BUILDER_TEMPLATE % (ident, subset, nsattrs)\n        try:\n            parser.Parse(document, 1)\n        except:\n            self.reset()\n            raise\n        fragment = self.fragment\n        self.reset()\n##         self._parser = None\n        return fragment\n\n    def _getDeclarations(self):\n        \"\"\"Re-create the internal subset from the DocumentType node.\n\n        This is only needed if we don't already have the\n        internalSubset as a string.\n        \"\"\"\n        doctype = self.context.ownerDocument.doctype\n        s = \"\"\n        if doctype:\n            for i in range(doctype.notations.length):\n                notation = doctype.notations.item(i)\n                if s:\n                    s = s + \"\\n  \"\n                s = \"%s<!NOTATION %s\" % (s, notation.nodeName)\n                if notation.publicId:\n                    s = '%s PUBLIC \"%s\"\\n             \"%s\">' \\\n                        % (s, notation.publicId, notation.systemId)\n                else:\n                    s = '%s SYSTEM \"%s\">' % (s, notation.systemId)\n            for i in range(doctype.entities.length):\n                entity = doctype.entities.item(i)\n                if s:\n                    s = s + \"\\n  \"\n                s = \"%s<!ENTITY %s\" % (s, entity.nodeName)\n                if entity.publicId:\n                    s = '%s PUBLIC \"%s\"\\n             \"%s\"' \\\n                        % (s, entity.publicId, entity.systemId)\n                elif entity.systemId:\n                    s = '%s SYSTEM \"%s\"' % (s, entity.systemId)\n                else:\n                    s = '%s \"%s\"' % (s, entity.firstChild.data)\n                if entity.notationName:\n                    s = \"%s NOTATION %s\" % (s, entity.notationName)\n                s = s + \">\"\n        return s\n\n    def _getNSattrs(self):\n        return \"\"\n\n    def external_entity_ref_handler(self, context, base, systemId, publicId):\n        if systemId == _FRAGMENT_BUILDER_INTERNAL_SYSTEM_ID:\n            # this entref is the one that we made to put the subtree\n            # in; all of our given input is parsed in here.\n            old_document = self.document\n            old_cur_node = self.curNode\n            parser = self._parser.ExternalEntityParserCreate(context)\n            # put the real document back, parse into the fragment to return\n            self.document = self.originalDocument\n            self.fragment = self.document.createDocumentFragment()\n            self.curNode = self.fragment\n            try:\n                parser.Parse(self._source, 1)\n            finally:\n                self.curNode = old_cur_node\n                self.document = old_document\n                self._source = None\n            return -1\n        else:\n            return ExpatBuilder.external_entity_ref_handler(\n                self, context, base, systemId, publicId)\n\n\nclass Namespaces:\n    \"\"\"Mix-in class for builders; adds support for namespaces.\"\"\"\n\n    def _initNamespaces(self):\n        # list of (prefix, uri) ns declarations.  Namespace attrs are\n        # constructed from this and added to the element's attrs.\n        self._ns_ordered_prefixes = []\n\n    def createParser(self):\n        \"\"\"Create a new namespace-handling parser.\"\"\"\n        parser = expat.ParserCreate(namespace_separator=\" \")\n        parser.namespace_prefixes = True\n        return parser\n\n    def install(self, parser):\n        \"\"\"Insert the namespace-handlers onto the parser.\"\"\"\n        ExpatBuilder.install(self, parser)\n        if self._options.namespace_declarations:\n            parser.StartNamespaceDeclHandler = (\n                self.start_namespace_decl_handler)\n\n    def start_namespace_decl_handler(self, prefix, uri):\n        \"\"\"Push this namespace declaration on our storage.\"\"\"\n        self._ns_ordered_prefixes.append((prefix, uri))\n\n    def start_element_handler(self, name, attributes):\n        if ' ' in name:\n            uri, localname, prefix, qname = _parse_ns_name(self, name)\n        else:\n            uri = EMPTY_NAMESPACE\n            qname = name\n            localname = None\n            prefix = EMPTY_PREFIX\n        node = minidom.Element(qname, uri, prefix, localname)\n        node.ownerDocument = self.document\n        _append_child(self.curNode, node)\n        self.curNode = node\n\n        if self._ns_ordered_prefixes:\n            for prefix, uri in self._ns_ordered_prefixes:\n                if prefix:\n                    a = minidom.Attr(_intern(self, 'xmlns:' + prefix),\n                                     XMLNS_NAMESPACE, prefix, \"xmlns\")\n                else:\n                    a = minidom.Attr(\"xmlns\", XMLNS_NAMESPACE,\n                                     \"xmlns\", EMPTY_PREFIX)\n                a.value = uri\n                a.ownerDocument = self.document\n                _set_attribute_node(node, a)\n            del self._ns_ordered_prefixes[:]\n\n        if attributes:\n            node._ensure_attributes()\n            _attrs = node._attrs\n            _attrsNS = node._attrsNS\n            for i in range(0, len(attributes), 2):\n                aname = attributes[i]\n                value = attributes[i+1]\n                if ' ' in aname:\n                    uri, localname, prefix, qname = _parse_ns_name(self, aname)\n                    a = minidom.Attr(qname, uri, localname, prefix)\n                    _attrs[qname] = a\n                    _attrsNS[(uri, localname)] = a\n                else:\n                    a = minidom.Attr(aname, EMPTY_NAMESPACE,\n                                     aname, EMPTY_PREFIX)\n                    _attrs[aname] = a\n                    _attrsNS[(EMPTY_NAMESPACE, aname)] = a\n                a.ownerDocument = self.document\n                a.value = value\n                a.ownerElement = node\n\n    if __debug__:\n        # This only adds some asserts to the original\n        # end_element_handler(), so we only define this when -O is not\n        # used.  If changing one, be sure to check the other to see if\n        # it needs to be changed as well.\n        #\n        def end_element_handler(self, name):\n            curNode = self.curNode\n            if ' ' in name:\n                uri, localname, prefix, qname = _parse_ns_name(self, name)\n                assert (curNode.namespaceURI == uri\n                        and curNode.localName == localname\n                        and curNode.prefix == prefix), \\\n                        \"element stack messed up! (namespace)\"\n            else:\n                assert curNode.nodeName == name, \\\n                       \"element stack messed up - bad nodeName\"\n                assert curNode.namespaceURI == EMPTY_NAMESPACE, \\\n                       \"element stack messed up - bad namespaceURI\"\n            self.curNode = curNode.parentNode\n            self._finish_end_element(curNode)\n\n\nclass ExpatBuilderNS(Namespaces, ExpatBuilder):\n    \"\"\"Document builder that supports namespaces.\"\"\"\n\n    def reset(self):\n        ExpatBuilder.reset(self)\n        self._initNamespaces()\n\n\nclass FragmentBuilderNS(Namespaces, FragmentBuilder):\n    \"\"\"Fragment builder that supports namespaces.\"\"\"\n\n    def reset(self):\n        FragmentBuilder.reset(self)\n        self._initNamespaces()\n\n    def _getNSattrs(self):\n        \"\"\"Return string of namespace attributes from this element and\n        ancestors.\"\"\"\n        # XXX This needs to be re-written to walk the ancestors of the\n        # context to build up the namespace information from\n        # declarations, elements, and attributes found in context.\n        # Otherwise we have to store a bunch more data on the DOM\n        # (though that *might* be more reliable -- not clear).\n        attrs = \"\"\n        context = self.context\n        L = []\n        while context:\n            if hasattr(context, '_ns_prefix_uri'):\n                for prefix, uri in context._ns_prefix_uri.items():\n                    # add every new NS decl from context to L and attrs string\n                    if prefix in L:\n                        continue\n                    L.append(prefix)\n                    if prefix:\n                        declname = \"xmlns:\" + prefix\n                    else:\n                        declname = \"xmlns\"\n                    if attrs:\n                        attrs = \"%s\\n    %s='%s'\" % (attrs, declname, uri)\n                    else:\n                        attrs = \" %s='%s'\" % (declname, uri)\n            context = context.parentNode\n        return attrs\n\n\nclass ParseEscape(Exception):\n    \"\"\"Exception raised to short-circuit parsing in InternalSubsetExtractor.\"\"\"\n    pass\n\nclass InternalSubsetExtractor(ExpatBuilder):\n    \"\"\"XML processor which can rip out the internal document type subset.\"\"\"\n\n    subset = None\n\n    def getSubset(self):\n        \"\"\"Return the internal subset as a string.\"\"\"\n        return self.subset\n\n    def parseFile(self, file):\n        try:\n            ExpatBuilder.parseFile(self, file)\n        except ParseEscape:\n            pass\n\n    def parseString(self, string):\n        try:\n            ExpatBuilder.parseString(self, string)\n        except ParseEscape:\n            pass\n\n    def install(self, parser):\n        parser.StartDoctypeDeclHandler = self.start_doctype_decl_handler\n        parser.StartElementHandler = self.start_element_handler\n\n    def start_doctype_decl_handler(self, name, publicId, systemId,\n                                   has_internal_subset):\n        if has_internal_subset:\n            parser = self.getParser()\n            self.subset = []\n            parser.DefaultHandler = self.subset.append\n            parser.EndDoctypeDeclHandler = self.end_doctype_decl_handler\n        else:\n            raise ParseEscape()\n\n    def end_doctype_decl_handler(self):\n        s = ''.join(self.subset).replace('\\r\\n', '\\n').replace('\\r', '\\n')\n        self.subset = s\n        raise ParseEscape()\n\n    def start_element_handler(self, name, attrs):\n        raise ParseEscape()\n\n\ndef parse(file, namespaces=True):\n    \"\"\"Parse a document, returning the resulting Document node.\n\n    'file' may be either a file name or an open file object.\n    \"\"\"\n    if namespaces:\n        builder = ExpatBuilderNS()\n    else:\n        builder = ExpatBuilder()\n\n    if isinstance(file, str):\n        fp = open(file, 'rb')\n        try:\n            result = builder.parseFile(fp)\n        finally:\n            fp.close()\n    else:\n        result = builder.parseFile(file)\n    return result\n\n\ndef parseString(string, namespaces=True):\n    \"\"\"Parse a document from a string, returning the resulting\n    Document node.\n    \"\"\"\n    if namespaces:\n        builder = ExpatBuilderNS()\n    else:\n        builder = ExpatBuilder()\n    return builder.parseString(string)\n\n\ndef parseFragment(file, context, namespaces=True):\n    \"\"\"Parse a fragment of a document, given the context from which it\n    was originally extracted.  context should be the parent of the\n    node(s) which are in the fragment.\n\n    'file' may be either a file name or an open file object.\n    \"\"\"\n    if namespaces:\n        builder = FragmentBuilderNS(context)\n    else:\n        builder = FragmentBuilder(context)\n\n    if isinstance(file, str):\n        fp = open(file, 'rb')\n        try:\n            result = builder.parseFile(fp)\n        finally:\n            fp.close()\n    else:\n        result = builder.parseFile(file)\n    return result\n\n\ndef parseFragmentString(string, context, namespaces=True):\n    \"\"\"Parse a fragment of a document from a string, given the context\n    from which it was originally extracted.  context should be the\n    parent of the node(s) which are in the fragment.\n    \"\"\"\n    if namespaces:\n        builder = FragmentBuilderNS(context)\n    else:\n        builder = FragmentBuilder(context)\n    return builder.parseString(string)\n\n\ndef makeBuilder(options):\n    \"\"\"Create a builder based on an Options object.\"\"\"\n    if options.namespaces:\n        return ExpatBuilderNS(options)\n    else:\n        return ExpatBuilder(options)\n"], "unittest.test.testmock.testmock": [".py", "import copy\nimport sys\n\nimport unittest\nfrom unittest.test.testmock.support import is_instance\nfrom unittest import mock\nfrom unittest.mock import (\n    call, DEFAULT, patch, sentinel,\n    MagicMock, Mock, NonCallableMock,\n    NonCallableMagicMock, _CallList,\n    create_autospec\n)\n\n\nclass Iter(object):\n    def __init__(self):\n        self.thing = iter(['this', 'is', 'an', 'iter'])\n\n    def __iter__(self):\n        return self\n\n    def next(self):\n        return next(self.thing)\n\n    __next__ = next\n\n\n\nclass MockTest(unittest.TestCase):\n\n    def test_all(self):\n        # if __all__ is badly defined then import * will raise an error\n        # We have to exec it because you can't import * inside a method\n        # in Python 3\n        exec(\"from unittest.mock import *\")\n\n\n    def test_constructor(self):\n        mock = Mock()\n\n        self.assertFalse(mock.called, \"called not initialised correctly\")\n        self.assertEqual(mock.call_count, 0,\n                         \"call_count not initialised correctly\")\n        self.assertTrue(is_instance(mock.return_value, Mock),\n                        \"return_value not initialised correctly\")\n\n        self.assertEqual(mock.call_args, None,\n                         \"call_args not initialised correctly\")\n        self.assertEqual(mock.call_args_list, [],\n                         \"call_args_list not initialised correctly\")\n        self.assertEqual(mock.method_calls, [],\n                          \"method_calls not initialised correctly\")\n\n        # Can't use hasattr for this test as it always returns True on a mock\n        self.assertFalse('_items' in mock.__dict__,\n                         \"default mock should not have '_items' attribute\")\n\n        self.assertIsNone(mock._mock_parent,\n                          \"parent not initialised correctly\")\n        self.assertIsNone(mock._mock_methods,\n                          \"methods not initialised correctly\")\n        self.assertEqual(mock._mock_children, {},\n                         \"children not initialised incorrectly\")\n\n\n    def test_return_value_in_constructor(self):\n        mock = Mock(return_value=None)\n        self.assertIsNone(mock.return_value,\n                          \"return value in constructor not honoured\")\n\n\n    def test_repr(self):\n        mock = Mock(name='foo')\n        self.assertIn('foo', repr(mock))\n        self.assertIn(\"'%s'\" % id(mock), repr(mock))\n\n        mocks = [(Mock(), 'mock'), (Mock(name='bar'), 'bar')]\n        for mock, name in mocks:\n            self.assertIn('%s.bar' % name, repr(mock.bar))\n            self.assertIn('%s.foo()' % name, repr(mock.foo()))\n            self.assertIn('%s.foo().bing' % name, repr(mock.foo().bing))\n            self.assertIn('%s()' % name, repr(mock()))\n            self.assertIn('%s()()' % name, repr(mock()()))\n            self.assertIn('%s()().foo.bar.baz().bing' % name,\n                          repr(mock()().foo.bar.baz().bing))\n\n\n    def test_repr_with_spec(self):\n        class X(object):\n            pass\n\n        mock = Mock(spec=X)\n        self.assertIn(\" spec='X' \", repr(mock))\n\n        mock = Mock(spec=X())\n        self.assertIn(\" spec='X' \", repr(mock))\n\n        mock = Mock(spec_set=X)\n        self.assertIn(\" spec_set='X' \", repr(mock))\n\n        mock = Mock(spec_set=X())\n        self.assertIn(\" spec_set='X' \", repr(mock))\n\n        mock = Mock(spec=X, name='foo')\n        self.assertIn(\" spec='X' \", repr(mock))\n        self.assertIn(\" name='foo' \", repr(mock))\n\n        mock = Mock(name='foo')\n        self.assertNotIn(\"spec\", repr(mock))\n\n        mock = Mock()\n        self.assertNotIn(\"spec\", repr(mock))\n\n        mock = Mock(spec=['foo'])\n        self.assertNotIn(\"spec\", repr(mock))\n\n\n    def test_side_effect(self):\n        mock = Mock()\n\n        def effect(*args, **kwargs):\n            raise SystemError('kablooie')\n\n        mock.side_effect = effect\n        self.assertRaises(SystemError, mock, 1, 2, fish=3)\n        mock.assert_called_with(1, 2, fish=3)\n\n        results = [1, 2, 3]\n        def effect():\n            return results.pop()\n        mock.side_effect = effect\n\n        self.assertEqual([mock(), mock(), mock()], [3, 2, 1],\n                          \"side effect not used correctly\")\n\n        mock = Mock(side_effect=sentinel.SideEffect)\n        self.assertEqual(mock.side_effect, sentinel.SideEffect,\n                          \"side effect in constructor not used\")\n\n        def side_effect():\n            return DEFAULT\n        mock = Mock(side_effect=side_effect, return_value=sentinel.RETURN)\n        self.assertEqual(mock(), sentinel.RETURN)\n\n\n    @unittest.skipUnless('java' in sys.platform,\n                          'This test only applies to Jython')\n    def test_java_exception_side_effect(self):\n        import java\n        mock = Mock(side_effect=java.lang.RuntimeException(\"Boom!\"))\n\n        # can't use assertRaises with java exceptions\n        try:\n            mock(1, 2, fish=3)\n        except java.lang.RuntimeException:\n            pass\n        else:\n            self.fail('java exception not raised')\n        mock.assert_called_with(1,2, fish=3)\n\n\n    def test_reset_mock(self):\n        parent = Mock()\n        spec = [\"something\"]\n        mock = Mock(name=\"child\", parent=parent, spec=spec)\n        mock(sentinel.Something, something=sentinel.SomethingElse)\n        something = mock.something\n        mock.something()\n        mock.side_effect = sentinel.SideEffect\n        return_value = mock.return_value\n        return_value()\n\n        mock.reset_mock()\n\n        self.assertEqual(mock._mock_name, \"child\",\n                         \"name incorrectly reset\")\n        self.assertEqual(mock._mock_parent, parent,\n                         \"parent incorrectly reset\")\n        self.assertEqual(mock._mock_methods, spec,\n                         \"methods incorrectly reset\")\n\n        self.assertFalse(mock.called, \"called not reset\")\n        self.assertEqual(mock.call_count, 0, \"call_count not reset\")\n        self.assertEqual(mock.call_args, None, \"call_args not reset\")\n        self.assertEqual(mock.call_args_list, [], \"call_args_list not reset\")\n        self.assertEqual(mock.method_calls, [],\n                        \"method_calls not initialised correctly: %r != %r\" %\n                        (mock.method_calls, []))\n        self.assertEqual(mock.mock_calls, [])\n\n        self.assertEqual(mock.side_effect, sentinel.SideEffect,\n                          \"side_effect incorrectly reset\")\n        self.assertEqual(mock.return_value, return_value,\n                          \"return_value incorrectly reset\")\n        self.assertFalse(return_value.called, \"return value mock not reset\")\n        self.assertEqual(mock._mock_children, {'something': something},\n                          \"children reset incorrectly\")\n        self.assertEqual(mock.something, something,\n                          \"children incorrectly cleared\")\n        self.assertFalse(mock.something.called, \"child not reset\")\n\n\n    def test_reset_mock_recursion(self):\n        mock = Mock()\n        mock.return_value = mock\n\n        # used to cause recursion\n        mock.reset_mock()\n\n\n    def test_call(self):\n        mock = Mock()\n        self.assertTrue(is_instance(mock.return_value, Mock),\n                        \"Default return_value should be a Mock\")\n\n        result = mock()\n        self.assertEqual(mock(), result,\n                         \"different result from consecutive calls\")\n        mock.reset_mock()\n\n        ret_val = mock(sentinel.Arg)\n        self.assertTrue(mock.called, \"called not set\")\n        self.assertEqual(mock.call_count, 1, \"call_count incoreect\")\n        self.assertEqual(mock.call_args, ((sentinel.Arg,), {}),\n                         \"call_args not set\")\n        self.assertEqual(mock.call_args_list, [((sentinel.Arg,), {})],\n                         \"call_args_list not initialised correctly\")\n\n        mock.return_value = sentinel.ReturnValue\n        ret_val = mock(sentinel.Arg, key=sentinel.KeyArg)\n        self.assertEqual(ret_val, sentinel.ReturnValue,\n                         \"incorrect return value\")\n\n        self.assertEqual(mock.call_count, 2, \"call_count incorrect\")\n        self.assertEqual(mock.call_args,\n                         ((sentinel.Arg,), {'key': sentinel.KeyArg}),\n                         \"call_args not set\")\n        self.assertEqual(mock.call_args_list, [\n            ((sentinel.Arg,), {}),\n            ((sentinel.Arg,), {'key': sentinel.KeyArg})\n        ],\n            \"call_args_list not set\")\n\n\n    def test_call_args_comparison(self):\n        mock = Mock()\n        mock()\n        mock(sentinel.Arg)\n        mock(kw=sentinel.Kwarg)\n        mock(sentinel.Arg, kw=sentinel.Kwarg)\n        self.assertEqual(mock.call_args_list, [\n            (),\n            ((sentinel.Arg,),),\n            ({\"kw\": sentinel.Kwarg},),\n            ((sentinel.Arg,), {\"kw\": sentinel.Kwarg})\n        ])\n        self.assertEqual(mock.call_args,\n                         ((sentinel.Arg,), {\"kw\": sentinel.Kwarg}))\n\n\n    def test_assert_called_with(self):\n        mock = Mock()\n        mock()\n\n        # Will raise an exception if it fails\n        mock.assert_called_with()\n        self.assertRaises(AssertionError, mock.assert_called_with, 1)\n\n        mock.reset_mock()\n        self.assertRaises(AssertionError, mock.assert_called_with)\n\n        mock(1, 2, 3, a='fish', b='nothing')\n        mock.assert_called_with(1, 2, 3, a='fish', b='nothing')\n\n\n    def test_assert_called_once_with(self):\n        mock = Mock()\n        mock()\n\n        # Will raise an exception if it fails\n        mock.assert_called_once_with()\n\n        mock()\n        self.assertRaises(AssertionError, mock.assert_called_once_with)\n\n        mock.reset_mock()\n        self.assertRaises(AssertionError, mock.assert_called_once_with)\n\n        mock('foo', 'bar', baz=2)\n        mock.assert_called_once_with('foo', 'bar', baz=2)\n\n        mock.reset_mock()\n        mock('foo', 'bar', baz=2)\n        self.assertRaises(\n            AssertionError,\n            lambda: mock.assert_called_once_with('bob', 'bar', baz=2)\n        )\n\n\n    def test_attribute_access_returns_mocks(self):\n        mock = Mock()\n        something = mock.something\n        self.assertTrue(is_instance(something, Mock), \"attribute isn't a mock\")\n        self.assertEqual(mock.something, something,\n                         \"different attributes returned for same name\")\n\n        # Usage example\n        mock = Mock()\n        mock.something.return_value = 3\n\n        self.assertEqual(mock.something(), 3, \"method returned wrong value\")\n        self.assertTrue(mock.something.called,\n                        \"method didn't record being called\")\n\n\n    def test_attributes_have_name_and_parent_set(self):\n        mock = Mock()\n        something = mock.something\n\n        self.assertEqual(something._mock_name, \"something\",\n                         \"attribute name not set correctly\")\n        self.assertEqual(something._mock_parent, mock,\n                         \"attribute parent not set correctly\")\n\n\n    def test_method_calls_recorded(self):\n        mock = Mock()\n        mock.something(3, fish=None)\n        mock.something_else.something(6, cake=sentinel.Cake)\n\n        self.assertEqual(mock.something_else.method_calls,\n                          [(\"something\", (6,), {'cake': sentinel.Cake})],\n                          \"method calls not recorded correctly\")\n        self.assertEqual(mock.method_calls, [\n            (\"something\", (3,), {'fish': None}),\n            (\"something_else.something\", (6,), {'cake': sentinel.Cake})\n        ],\n            \"method calls not recorded correctly\")\n\n\n    def test_method_calls_compare_easily(self):\n        mock = Mock()\n        mock.something()\n        self.assertEqual(mock.method_calls, [('something',)])\n        self.assertEqual(mock.method_calls, [('something', (), {})])\n\n        mock = Mock()\n        mock.something('different')\n        self.assertEqual(mock.method_calls, [('something', ('different',))])\n        self.assertEqual(mock.method_calls,\n                         [('something', ('different',), {})])\n\n        mock = Mock()\n        mock.something(x=1)\n        self.assertEqual(mock.method_calls, [('something', {'x': 1})])\n        self.assertEqual(mock.method_calls, [('something', (), {'x': 1})])\n\n        mock = Mock()\n        mock.something('different', some='more')\n        self.assertEqual(mock.method_calls, [\n            ('something', ('different',), {'some': 'more'})\n        ])\n\n\n    def test_only_allowed_methods_exist(self):\n        for spec in ['something'], ('something',):\n            for arg in 'spec', 'spec_set':\n                mock = Mock(**{arg: spec})\n\n                # this should be allowed\n                mock.something\n                self.assertRaisesRegex(\n                    AttributeError,\n                    \"Mock object has no attribute 'something_else'\",\n                    getattr, mock, 'something_else'\n                )\n\n\n    def test_from_spec(self):\n        class Something(object):\n            x = 3\n            __something__ = None\n            def y(self):\n                pass\n\n        def test_attributes(mock):\n            # should work\n            mock.x\n            mock.y\n            mock.__something__\n            self.assertRaisesRegex(\n                AttributeError,\n                \"Mock object has no attribute 'z'\",\n                getattr, mock, 'z'\n            )\n            self.assertRaisesRegex(\n                AttributeError,\n                \"Mock object has no attribute '__foobar__'\",\n                getattr, mock, '__foobar__'\n            )\n\n        test_attributes(Mock(spec=Something))\n        test_attributes(Mock(spec=Something()))\n\n\n    def test_wraps_calls(self):\n        real = Mock()\n\n        mock = Mock(wraps=real)\n        self.assertEqual(mock(), real())\n\n        real.reset_mock()\n\n        mock(1, 2, fish=3)\n        real.assert_called_with(1, 2, fish=3)\n\n\n    def test_wraps_call_with_nondefault_return_value(self):\n        real = Mock()\n\n        mock = Mock(wraps=real)\n        mock.return_value = 3\n\n        self.assertEqual(mock(), 3)\n        self.assertFalse(real.called)\n\n\n    def test_wraps_attributes(self):\n        class Real(object):\n            attribute = Mock()\n\n        real = Real()\n\n        mock = Mock(wraps=real)\n        self.assertEqual(mock.attribute(), real.attribute())\n        self.assertRaises(AttributeError, lambda: mock.fish)\n\n        self.assertNotEqual(mock.attribute, real.attribute)\n        result = mock.attribute.frog(1, 2, fish=3)\n        Real.attribute.frog.assert_called_with(1, 2, fish=3)\n        self.assertEqual(result, Real.attribute.frog())\n\n\n    def test_exceptional_side_effect(self):\n        mock = Mock(side_effect=AttributeError)\n        self.assertRaises(AttributeError, mock)\n\n        mock = Mock(side_effect=AttributeError('foo'))\n        self.assertRaises(AttributeError, mock)\n\n\n    def test_baseexceptional_side_effect(self):\n        mock = Mock(side_effect=KeyboardInterrupt)\n        self.assertRaises(KeyboardInterrupt, mock)\n\n        mock = Mock(side_effect=KeyboardInterrupt('foo'))\n        self.assertRaises(KeyboardInterrupt, mock)\n\n\n    def test_assert_called_with_message(self):\n        mock = Mock()\n        self.assertRaisesRegex(AssertionError, 'Not called',\n                                mock.assert_called_with)\n\n\n    def test__name__(self):\n        mock = Mock()\n        self.assertRaises(AttributeError, lambda: mock.__name__)\n\n        mock.__name__ = 'foo'\n        self.assertEqual(mock.__name__, 'foo')\n\n\n    def test_spec_list_subclass(self):\n        class Sub(list):\n            pass\n        mock = Mock(spec=Sub(['foo']))\n\n        mock.append(3)\n        mock.append.assert_called_with(3)\n        self.assertRaises(AttributeError, getattr, mock, 'foo')\n\n\n    def test_spec_class(self):\n        class X(object):\n            pass\n\n        mock = Mock(spec=X)\n        self.assertTrue(isinstance(mock, X))\n\n        mock = Mock(spec=X())\n        self.assertTrue(isinstance(mock, X))\n\n        self.assertIs(mock.__class__, X)\n        self.assertEqual(Mock().__class__.__name__, 'Mock')\n\n        mock = Mock(spec_set=X)\n        self.assertTrue(isinstance(mock, X))\n\n        mock = Mock(spec_set=X())\n        self.assertTrue(isinstance(mock, X))\n\n\n    def test_setting_attribute_with_spec_set(self):\n        class X(object):\n            y = 3\n\n        mock = Mock(spec=X)\n        mock.x = 'foo'\n\n        mock = Mock(spec_set=X)\n        def set_attr():\n            mock.x = 'foo'\n\n        mock.y = 'foo'\n        self.assertRaises(AttributeError, set_attr)\n\n\n    def test_copy(self):\n        current = sys.getrecursionlimit()\n        self.addCleanup(sys.setrecursionlimit, current)\n\n        # can't use sys.maxint as this doesn't exist in Python 3\n        sys.setrecursionlimit(int(10e8))\n        # this segfaults without the fix in place\n        copy.copy(Mock())\n\n\n    def test_subclass_with_properties(self):\n        class SubClass(Mock):\n            def _get(self):\n                return 3\n            def _set(self, value):\n                raise NameError('strange error')\n            some_attribute = property(_get, _set)\n\n        s = SubClass(spec_set=SubClass)\n        self.assertEqual(s.some_attribute, 3)\n\n        def test():\n            s.some_attribute = 3\n        self.assertRaises(NameError, test)\n\n        def test():\n            s.foo = 'bar'\n        self.assertRaises(AttributeError, test)\n\n\n    def test_setting_call(self):\n        mock = Mock()\n        def __call__(self, a):\n            return self._mock_call(a)\n\n        type(mock).__call__ = __call__\n        mock('one')\n        mock.assert_called_with('one')\n\n        self.assertRaises(TypeError, mock, 'one', 'two')\n\n\n    def test_dir(self):\n        mock = Mock()\n        attrs = set(dir(mock))\n        type_attrs = set([m for m in dir(Mock) if not m.startswith('_')])\n\n        # all public attributes from the type are included\n        self.assertEqual(set(), type_attrs - attrs)\n\n        # creates these attributes\n        mock.a, mock.b\n        self.assertIn('a', dir(mock))\n        self.assertIn('b', dir(mock))\n\n        # instance attributes\n        mock.c = mock.d = None\n        self.assertIn('c', dir(mock))\n        self.assertIn('d', dir(mock))\n\n        # magic methods\n        mock.__iter__ = lambda s: iter([])\n        self.assertIn('__iter__', dir(mock))\n\n\n    def test_dir_from_spec(self):\n        mock = Mock(spec=unittest.TestCase)\n        testcase_attrs = set(dir(unittest.TestCase))\n        attrs = set(dir(mock))\n\n        # all attributes from the spec are included\n        self.assertEqual(set(), testcase_attrs - attrs)\n\n        # shadow a sys attribute\n        mock.version = 3\n        self.assertEqual(dir(mock).count('version'), 1)\n\n\n    def test_filter_dir(self):\n        patcher = patch.object(mock, 'FILTER_DIR', False)\n        patcher.start()\n        try:\n            attrs = set(dir(Mock()))\n            type_attrs = set(dir(Mock))\n\n            # ALL attributes from the type are included\n            self.assertEqual(set(), type_attrs - attrs)\n        finally:\n            patcher.stop()\n\n\n    def test_configure_mock(self):\n        mock = Mock(foo='bar')\n        self.assertEqual(mock.foo, 'bar')\n\n        mock = MagicMock(foo='bar')\n        self.assertEqual(mock.foo, 'bar')\n\n        kwargs = {'side_effect': KeyError, 'foo.bar.return_value': 33,\n                  'foo': MagicMock()}\n        mock = Mock(**kwargs)\n        self.assertRaises(KeyError, mock)\n        self.assertEqual(mock.foo.bar(), 33)\n        self.assertIsInstance(mock.foo, MagicMock)\n\n        mock = Mock()\n        mock.configure_mock(**kwargs)\n        self.assertRaises(KeyError, mock)\n        self.assertEqual(mock.foo.bar(), 33)\n        self.assertIsInstance(mock.foo, MagicMock)\n\n\n    def assertRaisesWithMsg(self, exception, message, func, *args, **kwargs):\n        # needed because assertRaisesRegex doesn't work easily with newlines\n        try:\n            func(*args, **kwargs)\n        except:\n            instance = sys.exc_info()[1]\n            self.assertIsInstance(instance, exception)\n        else:\n            self.fail('Exception %r not raised' % (exception,))\n\n        msg = str(instance)\n        self.assertEqual(msg, message)\n\n\n    def test_assert_called_with_failure_message(self):\n        mock = NonCallableMock()\n\n        expected = \"mock(1, '2', 3, bar='foo')\"\n        message = 'Expected call: %s\\nNot called'\n        self.assertRaisesWithMsg(\n            AssertionError, message % (expected,),\n            mock.assert_called_with, 1, '2', 3, bar='foo'\n        )\n\n        mock.foo(1, '2', 3, foo='foo')\n\n\n        asserters = [\n            mock.foo.assert_called_with, mock.foo.assert_called_once_with\n        ]\n        for meth in asserters:\n            actual = \"foo(1, '2', 3, foo='foo')\"\n            expected = \"foo(1, '2', 3, bar='foo')\"\n            message = 'Expected call: %s\\nActual call: %s'\n            self.assertRaisesWithMsg(\n                AssertionError, message % (expected, actual),\n                meth, 1, '2', 3, bar='foo'\n            )\n\n        # just kwargs\n        for meth in asserters:\n            actual = \"foo(1, '2', 3, foo='foo')\"\n            expected = \"foo(bar='foo')\"\n            message = 'Expected call: %s\\nActual call: %s'\n            self.assertRaisesWithMsg(\n                AssertionError, message % (expected, actual),\n                meth, bar='foo'\n            )\n\n        # just args\n        for meth in asserters:\n            actual = \"foo(1, '2', 3, foo='foo')\"\n            expected = \"foo(1, 2, 3)\"\n            message = 'Expected call: %s\\nActual call: %s'\n            self.assertRaisesWithMsg(\n                AssertionError, message % (expected, actual),\n                meth, 1, 2, 3\n            )\n\n        # empty\n        for meth in asserters:\n            actual = \"foo(1, '2', 3, foo='foo')\"\n            expected = \"foo()\"\n            message = 'Expected call: %s\\nActual call: %s'\n            self.assertRaisesWithMsg(\n                AssertionError, message % (expected, actual), meth\n            )\n\n\n    def test_mock_calls(self):\n        mock = MagicMock()\n\n        # need to do this because MagicMock.mock_calls used to just return\n        # a MagicMock which also returned a MagicMock when __eq__ was called\n        self.assertIs(mock.mock_calls == [], True)\n\n        mock = MagicMock()\n        mock()\n        expected = [('', (), {})]\n        self.assertEqual(mock.mock_calls, expected)\n\n        mock.foo()\n        expected.append(call.foo())\n        self.assertEqual(mock.mock_calls, expected)\n        # intermediate mock_calls work too\n        self.assertEqual(mock.foo.mock_calls, [('', (), {})])\n\n        mock = MagicMock()\n        mock().foo(1, 2, 3, a=4, b=5)\n        expected = [\n            ('', (), {}), ('().foo', (1, 2, 3), dict(a=4, b=5))\n        ]\n        self.assertEqual(mock.mock_calls, expected)\n        self.assertEqual(mock.return_value.foo.mock_calls,\n                         [('', (1, 2, 3), dict(a=4, b=5))])\n        self.assertEqual(mock.return_value.mock_calls,\n                         [('foo', (1, 2, 3), dict(a=4, b=5))])\n\n        mock = MagicMock()\n        mock().foo.bar().baz()\n        expected = [\n            ('', (), {}), ('().foo.bar', (), {}),\n            ('().foo.bar().baz', (), {})\n        ]\n        self.assertEqual(mock.mock_calls, expected)\n        self.assertEqual(mock().mock_calls,\n                         call.foo.bar().baz().call_list())\n\n        for kwargs in dict(), dict(name='bar'):\n            mock = MagicMock(**kwargs)\n            int(mock.foo)\n            expected = [('foo.__int__', (), {})]\n            self.assertEqual(mock.mock_calls, expected)\n\n            mock = MagicMock(**kwargs)\n            mock.a()()\n            expected = [('a', (), {}), ('a()', (), {})]\n            self.assertEqual(mock.mock_calls, expected)\n            self.assertEqual(mock.a().mock_calls, [call()])\n\n            mock = MagicMock(**kwargs)\n            mock(1)(2)(3)\n            self.assertEqual(mock.mock_calls, call(1)(2)(3).call_list())\n            self.assertEqual(mock().mock_calls, call(2)(3).call_list())\n            self.assertEqual(mock()().mock_calls, call(3).call_list())\n\n            mock = MagicMock(**kwargs)\n            mock(1)(2)(3).a.b.c(4)\n            self.assertEqual(mock.mock_calls,\n                             call(1)(2)(3).a.b.c(4).call_list())\n            self.assertEqual(mock().mock_calls,\n                             call(2)(3).a.b.c(4).call_list())\n            self.assertEqual(mock()().mock_calls,\n                             call(3).a.b.c(4).call_list())\n\n            mock = MagicMock(**kwargs)\n            int(mock().foo.bar().baz())\n            last_call = ('().foo.bar().baz().__int__', (), {})\n            self.assertEqual(mock.mock_calls[-1], last_call)\n            self.assertEqual(mock().mock_calls,\n                             call.foo.bar().baz().__int__().call_list())\n            self.assertEqual(mock().foo.bar().mock_calls,\n                             call.baz().__int__().call_list())\n            self.assertEqual(mock().foo.bar().baz.mock_calls,\n                             call().__int__().call_list())\n\n\n    def test_subclassing(self):\n        class Subclass(Mock):\n            pass\n\n        mock = Subclass()\n        self.assertIsInstance(mock.foo, Subclass)\n        self.assertIsInstance(mock(), Subclass)\n\n        class Subclass(Mock):\n            def _get_child_mock(self, **kwargs):\n                return Mock(**kwargs)\n\n        mock = Subclass()\n        self.assertNotIsInstance(mock.foo, Subclass)\n        self.assertNotIsInstance(mock(), Subclass)\n\n\n    def test_arg_lists(self):\n        mocks = [\n            Mock(),\n            MagicMock(),\n            NonCallableMock(),\n            NonCallableMagicMock()\n        ]\n\n        def assert_attrs(mock):\n            names = 'call_args_list', 'method_calls', 'mock_calls'\n            for name in names:\n                attr = getattr(mock, name)\n                self.assertIsInstance(attr, _CallList)\n                self.assertIsInstance(attr, list)\n                self.assertEqual(attr, [])\n\n        for mock in mocks:\n            assert_attrs(mock)\n\n            if callable(mock):\n                mock()\n                mock(1, 2)\n                mock(a=3)\n\n                mock.reset_mock()\n                assert_attrs(mock)\n\n            mock.foo()\n            mock.foo.bar(1, a=3)\n            mock.foo(1).bar().baz(3)\n\n            mock.reset_mock()\n            assert_attrs(mock)\n\n\n    def test_call_args_two_tuple(self):\n        mock = Mock()\n        mock(1, a=3)\n        mock(2, b=4)\n\n        self.assertEqual(len(mock.call_args), 2)\n        args, kwargs = mock.call_args\n        self.assertEqual(args, (2,))\n        self.assertEqual(kwargs, dict(b=4))\n\n        expected_list = [((1,), dict(a=3)), ((2,), dict(b=4))]\n        for expected, call_args in zip(expected_list, mock.call_args_list):\n            self.assertEqual(len(call_args), 2)\n            self.assertEqual(expected[0], call_args[0])\n            self.assertEqual(expected[1], call_args[1])\n\n\n    def test_side_effect_iterator(self):\n        mock = Mock(side_effect=iter([1, 2, 3]))\n        self.assertEqual([mock(), mock(), mock()], [1, 2, 3])\n        self.assertRaises(StopIteration, mock)\n\n        mock = MagicMock(side_effect=['a', 'b', 'c'])\n        self.assertEqual([mock(), mock(), mock()], ['a', 'b', 'c'])\n        self.assertRaises(StopIteration, mock)\n\n        mock = Mock(side_effect='ghi')\n        self.assertEqual([mock(), mock(), mock()], ['g', 'h', 'i'])\n        self.assertRaises(StopIteration, mock)\n\n        class Foo(object):\n            pass\n        mock = MagicMock(side_effect=Foo)\n        self.assertIsInstance(mock(), Foo)\n\n        mock = Mock(side_effect=Iter())\n        self.assertEqual([mock(), mock(), mock(), mock()],\n                         ['this', 'is', 'an', 'iter'])\n        self.assertRaises(StopIteration, mock)\n\n\n    def test_side_effect_iterator_exceptions(self):\n        for Klass in Mock, MagicMock:\n            iterable = (ValueError, 3, KeyError, 6)\n            m = Klass(side_effect=iterable)\n            self.assertRaises(ValueError, m)\n            self.assertEqual(m(), 3)\n            self.assertRaises(KeyError, m)\n            self.assertEqual(m(), 6)\n\n\n    def test_side_effect_setting_iterator(self):\n        mock = Mock()\n        mock.side_effect = iter([1, 2, 3])\n        self.assertEqual([mock(), mock(), mock()], [1, 2, 3])\n        self.assertRaises(StopIteration, mock)\n        side_effect = mock.side_effect\n        self.assertIsInstance(side_effect, type(iter([])))\n\n        mock.side_effect = ['a', 'b', 'c']\n        self.assertEqual([mock(), mock(), mock()], ['a', 'b', 'c'])\n        self.assertRaises(StopIteration, mock)\n        side_effect = mock.side_effect\n        self.assertIsInstance(side_effect, type(iter([])))\n\n        this_iter = Iter()\n        mock.side_effect = this_iter\n        self.assertEqual([mock(), mock(), mock(), mock()],\n                         ['this', 'is', 'an', 'iter'])\n        self.assertRaises(StopIteration, mock)\n        self.assertIs(mock.side_effect, this_iter)\n\n\n    def test_assert_has_calls_any_order(self):\n        mock = Mock()\n        mock(1, 2)\n        mock(a=3)\n        mock(3, 4)\n        mock(b=6)\n        mock(b=6)\n\n        kalls = [\n            call(1, 2), ({'a': 3},),\n            ((3, 4),), ((), {'a': 3}),\n            ('', (1, 2)), ('', {'a': 3}),\n            ('', (1, 2), {}), ('', (), {'a': 3})\n        ]\n        for kall in kalls:\n            mock.assert_has_calls([kall], any_order=True)\n\n        for kall in call(1, '2'), call(b=3), call(), 3, None, 'foo':\n            self.assertRaises(\n                AssertionError, mock.assert_has_calls,\n                [kall], any_order=True\n            )\n\n        kall_lists = [\n            [call(1, 2), call(b=6)],\n            [call(3, 4), call(1, 2)],\n            [call(b=6), call(b=6)],\n        ]\n\n        for kall_list in kall_lists:\n            mock.assert_has_calls(kall_list, any_order=True)\n\n        kall_lists = [\n            [call(b=6), call(b=6), call(b=6)],\n            [call(1, 2), call(1, 2)],\n            [call(3, 4), call(1, 2), call(5, 7)],\n            [call(b=6), call(3, 4), call(b=6), call(1, 2), call(b=6)],\n        ]\n        for kall_list in kall_lists:\n            self.assertRaises(\n                AssertionError, mock.assert_has_calls,\n                kall_list, any_order=True\n            )\n\n    def test_assert_has_calls(self):\n        kalls1 = [\n                call(1, 2), ({'a': 3},),\n                ((3, 4),), call(b=6),\n                ('', (1,), {'b': 6}),\n        ]\n        kalls2 = [call.foo(), call.bar(1)]\n        kalls2.extend(call.spam().baz(a=3).call_list())\n        kalls2.extend(call.bam(set(), foo={}).fish([1]).call_list())\n\n        mocks = []\n        for mock in Mock(), MagicMock():\n            mock(1, 2)\n            mock(a=3)\n            mock(3, 4)\n            mock(b=6)\n            mock(1, b=6)\n            mocks.append((mock, kalls1))\n\n        mock = Mock()\n        mock.foo()\n        mock.bar(1)\n        mock.spam().baz(a=3)\n        mock.bam(set(), foo={}).fish([1])\n        mocks.append((mock, kalls2))\n\n        for mock, kalls in mocks:\n            for i in range(len(kalls)):\n                for step in 1, 2, 3:\n                    these = kalls[i:i+step]\n                    mock.assert_has_calls(these)\n\n                    if len(these) > 1:\n                        self.assertRaises(\n                            AssertionError,\n                            mock.assert_has_calls,\n                            list(reversed(these))\n                        )\n\n\n    def test_assert_any_call(self):\n        mock = Mock()\n        mock(1, 2)\n        mock(a=3)\n        mock(1, b=6)\n\n        mock.assert_any_call(1, 2)\n        mock.assert_any_call(a=3)\n        mock.assert_any_call(1, b=6)\n\n        self.assertRaises(\n            AssertionError,\n            mock.assert_any_call\n        )\n        self.assertRaises(\n            AssertionError,\n            mock.assert_any_call,\n            1, 3\n        )\n        self.assertRaises(\n            AssertionError,\n            mock.assert_any_call,\n            a=4\n        )\n\n\n    def test_mock_calls_create_autospec(self):\n        def f(a, b):\n            pass\n        obj = Iter()\n        obj.f = f\n\n        funcs = [\n            create_autospec(f),\n            create_autospec(obj).f\n        ]\n        for func in funcs:\n            func(1, 2)\n            func(3, 4)\n\n            self.assertEqual(\n                func.mock_calls, [call(1, 2), call(3, 4)]\n            )\n\n\n    def test_mock_add_spec(self):\n        class _One(object):\n            one = 1\n        class _Two(object):\n            two = 2\n        class Anything(object):\n            one = two = three = 'four'\n\n        klasses = [\n            Mock, MagicMock, NonCallableMock, NonCallableMagicMock\n        ]\n        for Klass in list(klasses):\n            klasses.append(lambda K=Klass: K(spec=Anything))\n            klasses.append(lambda K=Klass: K(spec_set=Anything))\n\n        for Klass in klasses:\n            for kwargs in dict(), dict(spec_set=True):\n                mock = Klass()\n                #no error\n                mock.one, mock.two, mock.three\n\n                for One, Two in [(_One, _Two), (['one'], ['two'])]:\n                    for kwargs in dict(), dict(spec_set=True):\n                        mock.mock_add_spec(One, **kwargs)\n\n                        mock.one\n                        self.assertRaises(\n                            AttributeError, getattr, mock, 'two'\n                        )\n                        self.assertRaises(\n                            AttributeError, getattr, mock, 'three'\n                        )\n                        if 'spec_set' in kwargs:\n                            self.assertRaises(\n                                AttributeError, setattr, mock, 'three', None\n                            )\n\n                        mock.mock_add_spec(Two, **kwargs)\n                        self.assertRaises(\n                            AttributeError, getattr, mock, 'one'\n                        )\n                        mock.two\n                        self.assertRaises(\n                            AttributeError, getattr, mock, 'three'\n                        )\n                        if 'spec_set' in kwargs:\n                            self.assertRaises(\n                                AttributeError, setattr, mock, 'three', None\n                            )\n            # note that creating a mock, setting an instance attribute, and\n            # *then* setting a spec doesn't work. Not the intended use case\n\n\n    def test_mock_add_spec_magic_methods(self):\n        for Klass in MagicMock, NonCallableMagicMock:\n            mock = Klass()\n            int(mock)\n\n            mock.mock_add_spec(object)\n            self.assertRaises(TypeError, int, mock)\n\n            mock = Klass()\n            mock['foo']\n            mock.__int__.return_value =4\n\n            mock.mock_add_spec(int)\n            self.assertEqual(int(mock), 4)\n            self.assertRaises(TypeError, lambda: mock['foo'])\n\n\n    def test_adding_child_mock(self):\n        for Klass in NonCallableMock, Mock, MagicMock, NonCallableMagicMock:\n            mock = Klass()\n\n            mock.foo = Mock()\n            mock.foo()\n\n            self.assertEqual(mock.method_calls, [call.foo()])\n            self.assertEqual(mock.mock_calls, [call.foo()])\n\n            mock = Klass()\n            mock.bar = Mock(name='name')\n            mock.bar()\n            self.assertEqual(mock.method_calls, [])\n            self.assertEqual(mock.mock_calls, [])\n\n            # mock with an existing _new_parent but no name\n            mock = Klass()\n            mock.baz = MagicMock()()\n            mock.baz()\n            self.assertEqual(mock.method_calls, [])\n            self.assertEqual(mock.mock_calls, [])\n\n\n    def test_adding_return_value_mock(self):\n        for Klass in Mock, MagicMock:\n            mock = Klass()\n            mock.return_value = MagicMock()\n\n            mock()()\n            self.assertEqual(mock.mock_calls, [call(), call()()])\n\n\n    def test_manager_mock(self):\n        class Foo(object):\n            one = 'one'\n            two = 'two'\n        manager = Mock()\n        p1 = patch.object(Foo, 'one')\n        p2 = patch.object(Foo, 'two')\n\n        mock_one = p1.start()\n        self.addCleanup(p1.stop)\n        mock_two = p2.start()\n        self.addCleanup(p2.stop)\n\n        manager.attach_mock(mock_one, 'one')\n        manager.attach_mock(mock_two, 'two')\n\n        Foo.two()\n        Foo.one()\n\n        self.assertEqual(manager.mock_calls, [call.two(), call.one()])\n\n\n    def test_magic_methods_mock_calls(self):\n        for Klass in Mock, MagicMock:\n            m = Klass()\n            m.__int__ = Mock(return_value=3)\n            m.__float__ = MagicMock(return_value=3.0)\n            int(m)\n            float(m)\n\n            self.assertEqual(m.mock_calls, [call.__int__(), call.__float__()])\n            self.assertEqual(m.method_calls, [])\n\n\n    def test_attribute_deletion(self):\n        # this behaviour isn't *useful*, but at least it's now tested...\n        for Klass in Mock, MagicMock, NonCallableMagicMock, NonCallableMock:\n            m = Klass()\n            original = m.foo\n            m.foo = 3\n            del m.foo\n            self.assertEqual(m.foo, original)\n\n            new = m.foo = Mock()\n            del m.foo\n            self.assertEqual(m.foo, new)\n\n\n    def test_mock_parents(self):\n        for Klass in Mock, MagicMock:\n            m = Klass()\n            original_repr = repr(m)\n            m.return_value = m\n            self.assertIs(m(), m)\n            self.assertEqual(repr(m), original_repr)\n\n            m.reset_mock()\n            self.assertIs(m(), m)\n            self.assertEqual(repr(m), original_repr)\n\n            m = Klass()\n            m.b = m.a\n            self.assertIn(\"name='mock.a'\", repr(m.b))\n            self.assertIn(\"name='mock.a'\", repr(m.a))\n            m.reset_mock()\n            self.assertIn(\"name='mock.a'\", repr(m.b))\n            self.assertIn(\"name='mock.a'\", repr(m.a))\n\n            m = Klass()\n            original_repr = repr(m)\n            m.a = m()\n            m.a.return_value = m\n\n            self.assertEqual(repr(m), original_repr)\n            self.assertEqual(repr(m.a()), original_repr)\n\n\n    def test_attach_mock(self):\n        classes = Mock, MagicMock, NonCallableMagicMock, NonCallableMock\n        for Klass in classes:\n            for Klass2 in classes:\n                m = Klass()\n\n                m2 = Klass2(name='foo')\n                m.attach_mock(m2, 'bar')\n\n                self.assertIs(m.bar, m2)\n                self.assertIn(\"name='mock.bar'\", repr(m2))\n\n                m.bar.baz(1)\n                self.assertEqual(m.mock_calls, [call.bar.baz(1)])\n                self.assertEqual(m.method_calls, [call.bar.baz(1)])\n\n\n    def test_attach_mock_return_value(self):\n        classes = Mock, MagicMock, NonCallableMagicMock, NonCallableMock\n        for Klass in Mock, MagicMock:\n            for Klass2 in classes:\n                m = Klass()\n\n                m2 = Klass2(name='foo')\n                m.attach_mock(m2, 'return_value')\n\n                self.assertIs(m(), m2)\n                self.assertIn(\"name='mock()'\", repr(m2))\n\n                m2.foo()\n                self.assertEqual(m.mock_calls, call().foo().call_list())\n\n\n    def test_attribute_deletion(self):\n        for mock in Mock(), MagicMock():\n            self.assertTrue(hasattr(mock, 'm'))\n\n            del mock.m\n            self.assertFalse(hasattr(mock, 'm'))\n\n            del mock.f\n            self.assertFalse(hasattr(mock, 'f'))\n            self.assertRaises(AttributeError, getattr, mock, 'f')\n\n\n    def test_class_assignable(self):\n        for mock in Mock(), MagicMock():\n            self.assertNotIsInstance(mock, int)\n\n            mock.__class__ = int\n            self.assertIsInstance(mock, int)\n            mock.foo\n\n\n\nif __name__ == '__main__':\n    unittest.main()\n"], "textwrap": [".py", "\"\"\"Text wrapping and filling.\n\"\"\"\n\n# Copyright (C) 1999-2001 Gregory P. Ward.\n# Copyright (C) 2002, 2003 Python Software Foundation.\n# Written by Greg Ward <gward@python.net>\n\nimport re\n\n__all__ = ['TextWrapper', 'wrap', 'fill', 'dedent', 'indent']\n\n# Hardcode the recognized whitespace characters to the US-ASCII\n# whitespace characters.  The main reason for doing this is that in\n# ISO-8859-1, 0xa0 is non-breaking whitespace, so in certain locales\n# that character winds up in string.whitespace.  Respecting\n# string.whitespace in those cases would 1) make textwrap treat 0xa0 the\n# same as any other whitespace char, which is clearly wrong (it's a\n# *non-breaking* space), 2) possibly cause problems with Unicode,\n# since 0xa0 is not in range(128).\n_whitespace = '\\t\\n\\x0b\\x0c\\r '\n\nclass TextWrapper:\n    \"\"\"\n    Object for wrapping/filling text.  The public interface consists of\n    the wrap() and fill() methods; the other methods are just there for\n    subclasses to override in order to tweak the default behaviour.\n    If you want to completely replace the main wrapping algorithm,\n    you'll probably have to override _wrap_chunks().\n\n    Several instance attributes control various aspects of wrapping:\n      width (default: 70)\n        the maximum width of wrapped lines (unless break_long_words\n        is false)\n      initial_indent (default: \"\")\n        string that will be prepended to the first line of wrapped\n        output.  Counts towards the line's width.\n      subsequent_indent (default: \"\")\n        string that will be prepended to all lines save the first\n        of wrapped output; also counts towards each line's width.\n      expand_tabs (default: true)\n        Expand tabs in input text to spaces before further processing.\n        Each tab will become 0 .. 'tabsize' spaces, depending on its position\n        in its line.  If false, each tab is treated as a single character.\n      tabsize (default: 8)\n        Expand tabs in input text to 0 .. 'tabsize' spaces, unless\n        'expand_tabs' is false.\n      replace_whitespace (default: true)\n        Replace all whitespace characters in the input text by spaces\n        after tab expansion.  Note that if expand_tabs is false and\n        replace_whitespace is true, every tab will be converted to a\n        single space!\n      fix_sentence_endings (default: false)\n        Ensure that sentence-ending punctuation is always followed\n        by two spaces.  Off by default because the algorithm is\n        (unavoidably) imperfect.\n      break_long_words (default: true)\n        Break words longer than 'width'.  If false, those words will not\n        be broken, and some lines might be longer than 'width'.\n      break_on_hyphens (default: true)\n        Allow breaking hyphenated words. If true, wrapping will occur\n        preferably on whitespaces and right after hyphens part of\n        compound words.\n      drop_whitespace (default: true)\n        Drop leading and trailing whitespace from lines.\n    \"\"\"\n\n    unicode_whitespace_trans = {}\n    uspace = ord(' ')\n    for x in _whitespace:\n        unicode_whitespace_trans[ord(x)] = uspace\n\n    # This funky little regex is just the trick for splitting\n    # text up into word-wrappable chunks.  E.g.\n    #   \"Hello there -- you goof-ball, use the -b option!\"\n    # splits into\n    #   Hello/ /there/ /--/ /you/ /goof-/ball,/ /use/ /the/ /-b/ /option!\n    # (after stripping out empty strings).\n    wordsep_re = re.compile(\n        r'(\\s+|'                                  # any whitespace\n        r'[^\\s\\w]*\\w+[^0-9\\W]-(?=\\w+[^0-9\\W])|'   # hyphenated words\n        r'(?<=[\\w\\!\\\"\\'\\&\\.\\,\\?])-{2,}(?=\\w))')   # em-dash\n\n    # This less funky little regex just split on recognized spaces. E.g.\n    #   \"Hello there -- you goof-ball, use the -b option!\"\n    # splits into\n    #   Hello/ /there/ /--/ /you/ /goof-ball,/ /use/ /the/ /-b/ /option!/\n    wordsep_simple_re = re.compile(r'(\\s+)')\n\n    # XXX this is not locale- or charset-aware -- string.lowercase\n    # is US-ASCII only (and therefore English-only)\n    sentence_end_re = re.compile(r'[a-z]'             # lowercase letter\n                                 r'[\\.\\!\\?]'          # sentence-ending punct.\n                                 r'[\\\"\\']?'           # optional end-of-quote\n                                 r'\\Z')               # end of chunk\n\n\n    def __init__(self,\n                 width=70,\n                 initial_indent=\"\",\n                 subsequent_indent=\"\",\n                 expand_tabs=True,\n                 replace_whitespace=True,\n                 fix_sentence_endings=False,\n                 break_long_words=True,\n                 drop_whitespace=True,\n                 break_on_hyphens=True,\n                 tabsize=8):\n        self.width = width\n        self.initial_indent = initial_indent\n        self.subsequent_indent = subsequent_indent\n        self.expand_tabs = expand_tabs\n        self.replace_whitespace = replace_whitespace\n        self.fix_sentence_endings = fix_sentence_endings\n        self.break_long_words = break_long_words\n        self.drop_whitespace = drop_whitespace\n        self.break_on_hyphens = break_on_hyphens\n        self.tabsize = tabsize\n\n\n    # -- Private methods -----------------------------------------------\n    # (possibly useful for subclasses to override)\n\n    def _munge_whitespace(self, text):\n        \"\"\"_munge_whitespace(text : string) -> string\n\n        Munge whitespace in text: expand tabs and convert all other\n        whitespace characters to spaces.  Eg. \" foo\\tbar\\n\\nbaz\"\n        becomes \" foo    bar  baz\".\n        \"\"\"\n        if self.expand_tabs:\n            text = text.expandtabs(self.tabsize)\n        if self.replace_whitespace:\n            text = text.translate(self.unicode_whitespace_trans)\n        return text\n\n\n    def _split(self, text):\n        \"\"\"_split(text : string) -> [string]\n\n        Split the text to wrap into indivisible chunks.  Chunks are\n        not quite the same as words; see _wrap_chunks() for full\n        details.  As an example, the text\n          Look, goof-ball -- use the -b option!\n        breaks into the following chunks:\n          'Look,', ' ', 'goof-', 'ball', ' ', '--', ' ',\n          'use', ' ', 'the', ' ', '-b', ' ', 'option!'\n        if break_on_hyphens is True, or in:\n          'Look,', ' ', 'goof-ball', ' ', '--', ' ',\n          'use', ' ', 'the', ' ', '-b', ' ', option!'\n        otherwise.\n        \"\"\"\n        if self.break_on_hyphens is True:\n            chunks = self.wordsep_re.split(text)\n        else:\n            chunks = self.wordsep_simple_re.split(text)\n        chunks = [c for c in chunks if c]\n        return chunks\n\n    def _fix_sentence_endings(self, chunks):\n        \"\"\"_fix_sentence_endings(chunks : [string])\n\n        Correct for sentence endings buried in 'chunks'.  Eg. when the\n        original text contains \"... foo.\\nBar ...\", munge_whitespace()\n        and split() will convert that to [..., \"foo.\", \" \", \"Bar\", ...]\n        which has one too few spaces; this method simply changes the one\n        space to two.\n        \"\"\"\n        i = 0\n        patsearch = self.sentence_end_re.search\n        while i < len(chunks)-1:\n            if chunks[i+1] == \" \" and patsearch(chunks[i]):\n                chunks[i+1] = \"  \"\n                i += 2\n            else:\n                i += 1\n\n    def _handle_long_word(self, reversed_chunks, cur_line, cur_len, width):\n        \"\"\"_handle_long_word(chunks : [string],\n                             cur_line : [string],\n                             cur_len : int, width : int)\n\n        Handle a chunk of text (most likely a word, not whitespace) that\n        is too long to fit in any line.\n        \"\"\"\n        # Figure out when indent is larger than the specified width, and make\n        # sure at least one character is stripped off on every pass\n        if width < 1:\n            space_left = 1\n        else:\n            space_left = width - cur_len\n\n        # If we're allowed to break long words, then do so: put as much\n        # of the next chunk onto the current line as will fit.\n        if self.break_long_words:\n            cur_line.append(reversed_chunks[-1][:space_left])\n            reversed_chunks[-1] = reversed_chunks[-1][space_left:]\n\n        # Otherwise, we have to preserve the long word intact.  Only add\n        # it to the current line if there's nothing already there --\n        # that minimizes how much we violate the width constraint.\n        elif not cur_line:\n            cur_line.append(reversed_chunks.pop())\n\n        # If we're not allowed to break long words, and there's already\n        # text on the current line, do nothing.  Next time through the\n        # main loop of _wrap_chunks(), we'll wind up here again, but\n        # cur_len will be zero, so the next line will be entirely\n        # devoted to the long word that we can't handle right now.\n\n    def _wrap_chunks(self, chunks):\n        \"\"\"_wrap_chunks(chunks : [string]) -> [string]\n\n        Wrap a sequence of text chunks and return a list of lines of\n        length 'self.width' or less.  (If 'break_long_words' is false,\n        some lines may be longer than this.)  Chunks correspond roughly\n        to words and the whitespace between them: each chunk is\n        indivisible (modulo 'break_long_words'), but a line break can\n        come between any two chunks.  Chunks should not have internal\n        whitespace; ie. a chunk is either all whitespace or a \"word\".\n        Whitespace chunks will be removed from the beginning and end of\n        lines, but apart from that whitespace is preserved.\n        \"\"\"\n        lines = []\n        if self.width <= 0:\n            raise ValueError(\"invalid width %r (must be > 0)\" % self.width)\n\n        # Arrange in reverse order so items can be efficiently popped\n        # from a stack of chucks.\n        chunks.reverse()\n\n        while chunks:\n\n            # Start the list of chunks that will make up the current line.\n            # cur_len is just the length of all the chunks in cur_line.\n            cur_line = []\n            cur_len = 0\n\n            # Figure out which static string will prefix this line.\n            if lines:\n                indent = self.subsequent_indent\n            else:\n                indent = self.initial_indent\n\n            # Maximum width for this line.\n            width = self.width - len(indent)\n\n            # First chunk on line is whitespace -- drop it, unless this\n            # is the very beginning of the text (ie. no lines started yet).\n            if self.drop_whitespace and chunks[-1].strip() == '' and lines:\n                del chunks[-1]\n\n            while chunks:\n                l = len(chunks[-1])\n\n                # Can at least squeeze this chunk onto the current line.\n                if cur_len + l <= width:\n                    cur_line.append(chunks.pop())\n                    cur_len += l\n\n                # Nope, this line is full.\n                else:\n                    break\n\n            # The current line is full, and the next chunk is too big to\n            # fit on *any* line (not just this one).\n            if chunks and len(chunks[-1]) > width:\n                self._handle_long_word(chunks, cur_line, cur_len, width)\n\n            # If the last chunk on this line is all whitespace, drop it.\n            if self.drop_whitespace and cur_line and cur_line[-1].strip() == '':\n                del cur_line[-1]\n\n            # Convert current line back to a string and store it in list\n            # of all lines (return value).\n            if cur_line:\n                lines.append(indent + ''.join(cur_line))\n\n        return lines\n\n\n    # -- Public interface ----------------------------------------------\n\n    def wrap(self, text):\n        \"\"\"wrap(text : string) -> [string]\n\n        Reformat the single paragraph in 'text' so it fits in lines of\n        no more than 'self.width' columns, and return a list of wrapped\n        lines.  Tabs in 'text' are expanded with string.expandtabs(),\n        and all other whitespace characters (including newline) are\n        converted to space.\n        \"\"\"\n        text = self._munge_whitespace(text)\n        chunks = self._split(text)\n        if self.fix_sentence_endings:\n            self._fix_sentence_endings(chunks)\n        return self._wrap_chunks(chunks)\n\n    def fill(self, text):\n        \"\"\"fill(text : string) -> string\n\n        Reformat the single paragraph in 'text' to fit in lines of no\n        more than 'self.width' columns, and return a new string\n        containing the entire wrapped paragraph.\n        \"\"\"\n        return \"\\n\".join(self.wrap(text))\n\n\n# -- Convenience interface ---------------------------------------------\n\ndef wrap(text, width=70, **kwargs):\n    \"\"\"Wrap a single paragraph of text, returning a list of wrapped lines.\n\n    Reformat the single paragraph in 'text' so it fits in lines of no\n    more than 'width' columns, and return a list of wrapped lines.  By\n    default, tabs in 'text' are expanded with string.expandtabs(), and\n    all other whitespace characters (including newline) are converted to\n    space.  See TextWrapper class for available keyword args to customize\n    wrapping behaviour.\n    \"\"\"\n    w = TextWrapper(width=width, **kwargs)\n    return w.wrap(text)\n\ndef fill(text, width=70, **kwargs):\n    \"\"\"Fill a single paragraph of text, returning a new string.\n\n    Reformat the single paragraph in 'text' to fit in lines of no more\n    than 'width' columns, and return a new string containing the entire\n    wrapped paragraph.  As with wrap(), tabs are expanded and other\n    whitespace characters converted to space.  See TextWrapper class for\n    available keyword args to customize wrapping behaviour.\n    \"\"\"\n    w = TextWrapper(width=width, **kwargs)\n    return w.fill(text)\n\n\n# -- Loosely related functionality -------------------------------------\n\n_whitespace_only_re = re.compile('^[ \\t]+$', re.MULTILINE)\n_leading_whitespace_re = re.compile('(^[ \\t]*)(?:[^ \\t\\n])', re.MULTILINE)\n\ndef dedent(text):\n    \"\"\"Remove any common leading whitespace from every line in `text`.\n\n    This can be used to make triple-quoted strings line up with the left\n    edge of the display, while still presenting them in the source code\n    in indented form.\n\n    Note that tabs and spaces are both treated as whitespace, but they\n    are not equal: the lines \"  hello\" and \"\\thello\" are\n    considered to have no common leading whitespace.  (This behaviour is\n    new in Python 2.5; older versions of this module incorrectly\n    expanded tabs before searching for common leading whitespace.)\n    \"\"\"\n    # Look for the longest leading string of spaces and tabs common to\n    # all lines.\n    margin = None\n    text = _whitespace_only_re.sub('', text)\n    indents = _leading_whitespace_re.findall(text)\n    for indent in indents:\n        if margin is None:\n            margin = indent\n\n        # Current line more deeply indented than previous winner:\n        # no change (previous winner is still on top).\n        elif indent.startswith(margin):\n            pass\n\n        # Current line consistent with and no deeper than previous winner:\n        # it's the new winner.\n        elif margin.startswith(indent):\n            margin = indent\n\n        # Current line and previous winner have no common whitespace:\n        # there is no margin.\n        else:\n            margin = \"\"\n            break\n\n    # sanity check (testing/debugging only)\n    if 0 and margin:\n        for line in text.split(\"\\n\"):\n            assert not line or line.startswith(margin), \\\n                   \"line = %r, margin = %r\" % (line, margin)\n\n    if margin:\n        text = re.sub(r'(?m)^' + margin, '', text)\n    return text\n\n\ndef indent(text, prefix, predicate=None):\n    \"\"\"Adds 'prefix' to the beginning of selected lines in 'text'.\n\n    If 'predicate' is provided, 'prefix' will only be added to the lines\n    where 'predicate(line)' is True. If 'predicate' is not provided,\n    it will default to adding 'prefix' to all non-empty lines that do not\n    consist solely of whitespace characters.\n    \"\"\"\n    if predicate is None:\n        def predicate(line):\n            return line.strip()\n\n    def prefixed_lines():\n        for line in text.splitlines(True):\n            yield (prefix + line if predicate(line) else line)\n    return ''.join(prefixed_lines())\n\n\nif __name__ == \"__main__\":\n    #print dedent(\"\\tfoo\\n\\tbar\")\n    #print dedent(\"  \\thello there\\n  \\t  how are you?\")\n    print(dedent(\"Hello there.\\n  This is indented.\"))\n"], "antigravity": [".py", "\nimport webbrowser\nimport hashlib\n\nwebbrowser.open(\"http://xkcd.com/353/\")\n\ndef geohash(latitude, longitude, datedow):\n    '''Compute geohash() using the Munroe algorithm.\n\n    >>> geohash(37.421542, -122.085589, b'2005-05-26-10458.68')\n    37.857713 -122.544543\n\n    '''\n    # http://xkcd.com/426/\n    h = hashlib.md5(datedow).hexdigest()\n    p, q = [('%f' % float.fromhex('0.' + x)) for x in (h[:16], h[16:32])]\n    print('%d%s %d%s' % (latitude, p[1:], longitude, q[1:]))\n"], "collections.abc": [".py", "# Copyright 2007 Google, Inc. All Rights Reserved.\n# Licensed to PSF under a Contributor Agreement.\n\n\"\"\"Abstract Base Classes (ABCs) for collections, according to PEP 3119.\n\nUnit tests are in test_collections.\n\"\"\"\n\nfrom abc import ABCMeta, abstractmethod\nimport sys\n\n__all__ = [\"Hashable\", \"Iterable\", \"Iterator\",\n           \"Sized\", \"Container\", \"Callable\",\n           \"Set\", \"MutableSet\",\n           \"Mapping\", \"MutableMapping\",\n           \"MappingView\", \"KeysView\", \"ItemsView\", \"ValuesView\",\n           \"Sequence\", \"MutableSequence\",\n           \"ByteString\",\n           ]\n\n# Private list of types that we want to register with the various ABCs\n# so that they will pass tests like:\n#       it = iter(somebytearray)\n#       assert isinstance(it, Iterable)\n# Note:  in other implementations, these types many not be distinct\n# and they make have their own implementation specific types that\n# are not included on this list.\nbytes_iterator = type(iter(b''))\nbytearray_iterator = type(iter(bytearray()))\n#callable_iterator = ???\ndict_keyiterator = type(iter({}.keys()))\ndict_valueiterator = type(iter({}.values()))\ndict_itemiterator = type(iter({}.items()))\nlist_iterator = type(iter([]))\nlist_reverseiterator = type(iter(reversed([])))\nrange_iterator = type(iter(range(0)))\nset_iterator = type(iter(set()))\nstr_iterator = type(iter(\"\"))\ntuple_iterator = type(iter(()))\nzip_iterator = type(iter(zip()))\n## views ##\ndict_keys = type({}.keys())\ndict_values = type({}.values())\ndict_items = type({}.items())\n## misc ##\nmappingproxy = type(type.__dict__)\n\n\n### ONE-TRICK PONIES ###\n\nclass Hashable(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __hash__(self):\n        return 0\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Hashable:\n            for B in C.__mro__:\n                if \"__hash__\" in B.__dict__:\n                    if B.__dict__[\"__hash__\"]:\n                        return True\n                    break\n        return NotImplemented\n\n\nclass Iterable(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __iter__(self):\n        while False:\n            yield None\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Iterable:\n            if any(\"__iter__\" in B.__dict__ for B in C.__mro__):\n                return True\n        return NotImplemented\n\n\nclass Iterator(Iterable):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __next__(self):\n        raise StopIteration\n\n    def __iter__(self):\n        return self\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Iterator:\n            if (any(\"__next__\" in B.__dict__ for B in C.__mro__) and\n                any(\"__iter__\" in B.__dict__ for B in C.__mro__)):\n                return True\n        return NotImplemented\n\nIterator.register(bytes_iterator)\nIterator.register(bytearray_iterator)\n#Iterator.register(callable_iterator)\nIterator.register(dict_keyiterator)\nIterator.register(dict_valueiterator)\nIterator.register(dict_itemiterator)\nIterator.register(list_iterator)\nIterator.register(list_reverseiterator)\nIterator.register(range_iterator)\nIterator.register(set_iterator)\nIterator.register(str_iterator)\nIterator.register(tuple_iterator)\nIterator.register(zip_iterator)\n\nclass Sized(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __len__(self):\n        return 0\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Sized:\n            if any(\"__len__\" in B.__dict__ for B in C.__mro__):\n                return True\n        return NotImplemented\n\n\nclass Container(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __contains__(self, x):\n        return False\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Container:\n            if any(\"__contains__\" in B.__dict__ for B in C.__mro__):\n                return True\n        return NotImplemented\n\n\nclass Callable(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __call__(self, *args, **kwds):\n        return False\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Callable:\n            if any(\"__call__\" in B.__dict__ for B in C.__mro__):\n                return True\n        return NotImplemented\n\n\n### SETS ###\n\n\nclass Set(Sized, Iterable, Container):\n\n    \"\"\"A set is a finite, iterable container.\n\n    This class provides concrete generic implementations of all\n    methods except for __contains__, __iter__ and __len__.\n\n    To override the comparisons (presumably for speed, as the\n    semantics are fixed), all you have to do is redefine __le__ and\n    then the other operations will automatically follow suit.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __le__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        if len(self) > len(other):\n            return False\n        for elem in self:\n            if elem not in other:\n                return False\n        return True\n\n    def __lt__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        return len(self) < len(other) and self.__le__(other)\n\n    def __gt__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        return other < self\n\n    def __ge__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        return other <= self\n\n    def __eq__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        return len(self) == len(other) and self.__le__(other)\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    @classmethod\n    def _from_iterable(cls, it):\n        '''Construct an instance of the class from any iterable input.\n\n        Must override this method if the class constructor signature\n        does not accept an iterable for an input.\n        '''\n        return cls(it)\n\n    def __and__(self, other):\n        if not isinstance(other, Iterable):\n            return NotImplemented\n        return self._from_iterable(value for value in other if value in self)\n\n    def isdisjoint(self, other):\n        for value in other:\n            if value in self:\n                return False\n        return True\n\n    def __or__(self, other):\n        if not isinstance(other, Iterable):\n            return NotImplemented\n        chain = (e for s in (self, other) for e in s)\n        return self._from_iterable(chain)\n\n    def __sub__(self, other):\n        if not isinstance(other, Set):\n            if not isinstance(other, Iterable):\n                return NotImplemented\n            other = self._from_iterable(other)\n        return self._from_iterable(value for value in self\n                                   if value not in other)\n\n    def __xor__(self, other):\n        if not isinstance(other, Set):\n            if not isinstance(other, Iterable):\n                return NotImplemented\n            other = self._from_iterable(other)\n        return (self - other) | (other - self)\n\n    def _hash(self):\n        \"\"\"Compute the hash value of a set.\n\n        Note that we don't define __hash__: not all sets are hashable.\n        But if you define a hashable set type, its __hash__ should\n        call this function.\n\n        This must be compatible __eq__.\n\n        All sets ought to compare equal if they contain the same\n        elements, regardless of how they are implemented, and\n        regardless of the order of the elements; so there's not much\n        freedom for __eq__ or __hash__.  We match the algorithm used\n        by the built-in frozenset type.\n        \"\"\"\n        MAX = sys.maxsize\n        MASK = 2 * MAX + 1\n        n = len(self)\n        h = 1927868237 * (n + 1)\n        h &= MASK\n        for x in self:\n            hx = hash(x)\n            h ^= (hx ^ (hx << 16) ^ 89869747)  * 3644798167\n            h &= MASK\n        h = h * 69069 + 907133923\n        h &= MASK\n        if h > MAX:\n            h -= MASK + 1\n        if h == -1:\n            h = 590923713\n        return h\n\nSet.register(frozenset)\n\n\nclass MutableSet(Set):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def add(self, value):\n        \"\"\"Add an element.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def discard(self, value):\n        \"\"\"Remove an element.  Do not raise an exception if absent.\"\"\"\n        raise NotImplementedError\n\n    def remove(self, value):\n        \"\"\"Remove an element. If not a member, raise a KeyError.\"\"\"\n        if value not in self:\n            raise KeyError(value)\n        self.discard(value)\n\n    def pop(self):\n        \"\"\"Return the popped value.  Raise KeyError if empty.\"\"\"\n        it = iter(self)\n        try:\n            value = next(it)\n        except StopIteration:\n            raise KeyError\n        self.discard(value)\n        return value\n\n    def clear(self):\n        \"\"\"This is slow (creates N new iterators!) but effective.\"\"\"\n        try:\n            while True:\n                self.pop()\n        except KeyError:\n            pass\n\n    def __ior__(self, it):\n        for value in it:\n            self.add(value)\n        return self\n\n    def __iand__(self, it):\n        for value in (self - it):\n            self.discard(value)\n        return self\n\n    def __ixor__(self, it):\n        if it is self:\n            self.clear()\n        else:\n            if not isinstance(it, Set):\n                it = self._from_iterable(it)\n            for value in it:\n                if value in self:\n                    self.discard(value)\n                else:\n                    self.add(value)\n        return self\n\n    def __isub__(self, it):\n        if it is self:\n            self.clear()\n        else:\n            for value in it:\n                self.discard(value)\n        return self\n\nMutableSet.register(set)\n\n\n### MAPPINGS ###\n\n\nclass Mapping(Sized, Iterable, Container):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __getitem__(self, key):\n        raise KeyError\n\n    def get(self, key, default=None):\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def __contains__(self, key):\n        try:\n            self[key]\n        except KeyError:\n            return False\n        else:\n            return True\n\n    def keys(self):\n        return KeysView(self)\n\n    def items(self):\n        return ItemsView(self)\n\n    def values(self):\n        return ValuesView(self)\n\n    def __eq__(self, other):\n        if not isinstance(other, Mapping):\n            return NotImplemented\n        return dict(self.items()) == dict(other.items())\n\n    def __ne__(self, other):\n        return not (self == other)\n\nMapping.register(mappingproxy)\n\n\nclass MappingView(Sized):\n\n    def __init__(self, mapping):\n        self._mapping = mapping\n\n    def __len__(self):\n        return len(self._mapping)\n\n    def __repr__(self):\n        return '{0.__class__.__name__}({0._mapping!r})'.format(self)\n\n\nclass KeysView(MappingView, Set):\n\n    @classmethod\n    def _from_iterable(self, it):\n        return set(it)\n\n    def __contains__(self, key):\n        return key in self._mapping\n\n    def __iter__(self):\n        for key in self._mapping:\n            yield key\n\nKeysView.register(dict_keys)\n\n\nclass ItemsView(MappingView, Set):\n\n    @classmethod\n    def _from_iterable(self, it):\n        return set(it)\n\n    def __contains__(self, item):\n        key, value = item\n        try:\n            v = self._mapping[key]\n        except KeyError:\n            return False\n        else:\n            return v == value\n\n    def __iter__(self):\n        for key in self._mapping:\n            yield (key, self._mapping[key])\n\nItemsView.register(dict_items)\n\n\nclass ValuesView(MappingView):\n\n    def __contains__(self, value):\n        for key in self._mapping:\n            if value == self._mapping[key]:\n                return True\n        return False\n\n    def __iter__(self):\n        for key in self._mapping:\n            yield self._mapping[key]\n\nValuesView.register(dict_values)\n\n\nclass MutableMapping(Mapping):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __setitem__(self, key, value):\n        raise KeyError\n\n    @abstractmethod\n    def __delitem__(self, key):\n        raise KeyError\n\n    __marker = object()\n\n    def pop(self, key, default=__marker):\n        try:\n            value = self[key]\n        except KeyError:\n            if default is self.__marker:\n                raise\n            return default\n        else:\n            del self[key]\n            return value\n\n    def popitem(self):\n        try:\n            key = next(iter(self))\n        except StopIteration:\n            raise KeyError\n        value = self[key]\n        del self[key]\n        return key, value\n\n    def clear(self):\n        try:\n            while True:\n                self.popitem()\n        except KeyError:\n            pass\n\n    def update(*args, **kwds):\n        if len(args) > 2:\n            raise TypeError(\"update() takes at most 2 positional \"\n                            \"arguments ({} given)\".format(len(args)))\n        elif not args:\n            raise TypeError(\"update() takes at least 1 argument (0 given)\")\n        self = args[0]\n        other = args[1] if len(args) >= 2 else ()\n\n        if isinstance(other, Mapping):\n            for key in other:\n                self[key] = other[key]\n        elif hasattr(other, \"keys\"):\n            for key in other.keys():\n                self[key] = other[key]\n        else:\n            for key, value in other:\n                self[key] = value\n        for key, value in kwds.items():\n            self[key] = value\n\n    def setdefault(self, key, default=None):\n        try:\n            return self[key]\n        except KeyError:\n            self[key] = default\n        return default\n\nMutableMapping.register(dict)\n\n\n### SEQUENCES ###\n\n\nclass Sequence(Sized, Iterable, Container):\n\n    \"\"\"All the operations on a read-only sequence.\n\n    Concrete subclasses must override __new__ or __init__,\n    __getitem__, and __len__.\n    \"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __getitem__(self, index):\n        raise IndexError\n\n    def __iter__(self):\n        i = 0\n        try:\n            while True:\n                v = self[i]\n                yield v\n                i += 1\n        except IndexError:\n            return\n\n    def __contains__(self, value):\n        for v in self:\n            if v == value:\n                return True\n        return False\n\n    def __reversed__(self):\n        for i in reversed(range(len(self))):\n            yield self[i]\n\n    def index(self, value):\n        for i, v in enumerate(self):\n            if v == value:\n                return i\n        raise ValueError\n\n    def count(self, value):\n        return sum(1 for v in self if v == value)\n\nSequence.register(tuple)\nSequence.register(str)\nSequence.register(range)\n\n\nclass ByteString(Sequence):\n\n    \"\"\"This unifies bytes and bytearray.\n\n    XXX Should add all their methods.\n    \"\"\"\n\n    __slots__ = ()\n\nByteString.register(bytes)\nByteString.register(bytearray)\n\n\nclass MutableSequence(Sequence):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __setitem__(self, index, value):\n        raise IndexError\n\n    @abstractmethod\n    def __delitem__(self, index):\n        raise IndexError\n\n    @abstractmethod\n    def insert(self, index, value):\n        raise IndexError\n\n    def append(self, value):\n        self.insert(len(self), value)\n\n    def clear(self):\n        try:\n            while True:\n                self.pop()\n        except IndexError:\n            pass\n\n    def reverse(self):\n        n = len(self)\n        for i in range(n//2):\n            self[i], self[n-i-1] = self[n-i-1], self[i]\n\n    def extend(self, values):\n        for v in values:\n            self.append(v)\n\n    def pop(self, index=-1):\n        v = self[index]\n        del self[index]\n        return v\n\n    def remove(self, value):\n        del self[self.index(value)]\n\n    def __iadd__(self, values):\n        self.extend(values)\n        return self\n\nMutableSequence.register(list)\nMutableSequence.register(bytearray)  # Multiply inheriting, see ByteString\n"], "importlib.abc": [".py", "\"\"\"Abstract base classes related to import.\"\"\"\nfrom . import _bootstrap\nfrom . import machinery\ntry:\n    import _frozen_importlib\nexcept ImportError as exc:\n    if exc.name != '_frozen_importlib':\n        raise\n    _frozen_importlib = None\nimport abc\nimport imp\nimport marshal\nimport sys\nimport tokenize\nimport warnings\n\n\ndef _register(abstract_cls, *classes):\n    for cls in classes:\n        abstract_cls.register(cls)\n        if _frozen_importlib is not None:\n            frozen_cls = getattr(_frozen_importlib, cls.__name__)\n            abstract_cls.register(frozen_cls)\n\n\nclass Finder(metaclass=abc.ABCMeta):\n\n    \"\"\"Legacy abstract base class for import finders.\n\n    It may be subclassed for compatibility with legacy third party\n    reimplementations of the import system.  Otherwise, finder\n    implementations should derive from the more specific MetaPathFinder\n    or PathEntryFinder ABCs.\n    \"\"\"\n\n    @abc.abstractmethod\n    def find_module(self, fullname, path=None):\n        \"\"\"An abstract method that should find a module.\n        The fullname is a str and the optional path is a str or None.\n        Returns a Loader object.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass MetaPathFinder(Finder):\n\n    \"\"\"Abstract base class for import finders on sys.meta_path.\"\"\"\n\n    @abc.abstractmethod\n    def find_module(self, fullname, path):\n        \"\"\"Abstract method which, when implemented, should find a module.\n        The fullname is a str and the path is a str or None.\n        Returns a Loader object.\n        \"\"\"\n        raise NotImplementedError\n\n    def invalidate_caches(self):\n        \"\"\"An optional method for clearing the finder's cache, if any.\n        This method is used by importlib.invalidate_caches().\n        \"\"\"\n        return NotImplemented\n\n_register(MetaPathFinder, machinery.BuiltinImporter, machinery.FrozenImporter,\n          machinery.PathFinder, machinery.WindowsRegistryFinder)\n\n\nclass PathEntryFinder(Finder):\n\n    \"\"\"Abstract base class for path entry finders used by PathFinder.\"\"\"\n\n    @abc.abstractmethod\n    def find_loader(self, fullname):\n        \"\"\"Abstract method which, when implemented, returns a module loader.\n        The fullname is a str.  Returns a 2-tuple of (Loader, portion) where\n        portion is a sequence of file system locations contributing to part of\n        a namespace package.  The sequence may be empty and the loader may be\n        None.\n        \"\"\"\n        raise NotImplementedError\n\n    find_module = _bootstrap._find_module_shim\n\n    def invalidate_caches(self):\n        \"\"\"An optional method for clearing the finder's cache, if any.\n        This method is used by PathFinder.invalidate_caches().\n        \"\"\"\n        return NotImplemented\n\n_register(PathEntryFinder, machinery.FileFinder)\n\n\nclass Loader(metaclass=abc.ABCMeta):\n\n    \"\"\"Abstract base class for import loaders.\"\"\"\n\n    @abc.abstractmethod\n    def load_module(self, fullname):\n        \"\"\"Abstract method which when implemented should load a module.\n        The fullname is a str.\"\"\"\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def module_repr(self, module):\n        \"\"\"Abstract method which when implemented calculates and returns the\n        given module's repr.\"\"\"\n        raise NotImplementedError\n\n\nclass ResourceLoader(Loader):\n\n    \"\"\"Abstract base class for loaders which can return data from their\n    back-end storage.\n\n    This ABC represents one of the optional protocols specified by PEP 302.\n\n    \"\"\"\n\n    @abc.abstractmethod\n    def get_data(self, path):\n        \"\"\"Abstract method which when implemented should return the bytes for\n        the specified path.  The path must be a str.\"\"\"\n        raise NotImplementedError\n\n\nclass InspectLoader(Loader):\n\n    \"\"\"Abstract base class for loaders which support inspection about the\n    modules they can load.\n\n    This ABC represents one of the optional protocols specified by PEP 302.\n\n    \"\"\"\n\n    @abc.abstractmethod\n    def is_package(self, fullname):\n        \"\"\"Abstract method which when implemented should return whether the\n        module is a package.  The fullname is a str.  Returns a bool.\"\"\"\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def get_code(self, fullname):\n        \"\"\"Abstract method which when implemented should return the code object\n        for the module.  The fullname is a str.  Returns a types.CodeType.\"\"\"\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def get_source(self, fullname):\n        \"\"\"Abstract method which should return the source code for the\n        module.  The fullname is a str.  Returns a str.\"\"\"\n        raise NotImplementedError\n\n_register(InspectLoader, machinery.BuiltinImporter, machinery.FrozenImporter,\n            machinery.ExtensionFileLoader)\n\n\nclass ExecutionLoader(InspectLoader):\n\n    \"\"\"Abstract base class for loaders that wish to support the execution of\n    modules as scripts.\n\n    This ABC represents one of the optional protocols specified in PEP 302.\n\n    \"\"\"\n\n    @abc.abstractmethod\n    def get_filename(self, fullname):\n        \"\"\"Abstract method which should return the value that __file__ is to be\n        set to.\"\"\"\n        raise NotImplementedError\n\n\nclass FileLoader(_bootstrap.FileLoader, ResourceLoader, ExecutionLoader):\n\n    \"\"\"Abstract base class partially implementing the ResourceLoader and\n    ExecutionLoader ABCs.\"\"\"\n\n_register(FileLoader, machinery.SourceFileLoader,\n            machinery.SourcelessFileLoader)\n\n\nclass SourceLoader(_bootstrap.SourceLoader, ResourceLoader, ExecutionLoader):\n\n    \"\"\"Abstract base class for loading source code (and optionally any\n    corresponding bytecode).\n\n    To support loading from source code, the abstractmethods inherited from\n    ResourceLoader and ExecutionLoader need to be implemented. To also support\n    loading from bytecode, the optional methods specified directly by this ABC\n    is required.\n\n    Inherited abstractmethods not implemented in this ABC:\n\n        * ResourceLoader.get_data\n        * ExecutionLoader.get_filename\n\n    \"\"\"\n\n    def path_mtime(self, path):\n        \"\"\"Return the (int) modification time for the path (str).\"\"\"\n        if self.path_stats.__func__ is SourceLoader.path_stats:\n            raise NotImplementedError\n        return int(self.path_stats(path)['mtime'])\n\n    def path_stats(self, path):\n        \"\"\"Return a metadata dict for the source pointed to by the path (str).\n        Possible keys:\n        - 'mtime' (mandatory) is the numeric timestamp of last source\n          code modification;\n        - 'size' (optional) is the size in bytes of the source code.\n        \"\"\"\n        if self.path_mtime.__func__ is SourceLoader.path_mtime:\n            raise NotImplementedError\n        return {'mtime': self.path_mtime(path)}\n\n    def set_data(self, path, data):\n        \"\"\"Write the bytes to the path (if possible).\n\n        Accepts a str path and data as bytes.\n\n        Any needed intermediary directories are to be created. If for some\n        reason the file cannot be written because of permissions, fail\n        silently.\n\n        \"\"\"\n        raise NotImplementedError\n\n_register(SourceLoader, machinery.SourceFileLoader)\n\nclass PyLoader(SourceLoader):\n\n    \"\"\"Implement the deprecated PyLoader ABC in terms of SourceLoader.\n\n    This class has been deprecated! It is slated for removal in Python 3.4.\n    If compatibility with Python 3.1 is not needed then implement the\n    SourceLoader ABC instead of this class. If Python 3.1 compatibility is\n    needed, then use the following idiom to have a single class that is\n    compatible with Python 3.1 onwards::\n\n        try:\n            from importlib.abc import SourceLoader\n        except ImportError:\n            from importlib.abc import PyLoader as SourceLoader\n\n\n        class CustomLoader(SourceLoader):\n            def get_filename(self, fullname):\n                # Implement ...\n\n            def source_path(self, fullname):\n                '''Implement source_path in terms of get_filename.'''\n                try:\n                    return self.get_filename(fullname)\n                except ImportError:\n                    return None\n\n            def is_package(self, fullname):\n                filename = os.path.basename(self.get_filename(fullname))\n                return os.path.splitext(filename)[0] == '__init__'\n\n    \"\"\"\n\n    @abc.abstractmethod\n    def is_package(self, fullname):\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def source_path(self, fullname):\n        \"\"\"Abstract method.  Accepts a str module name and returns the path to\n        the source code for the module.\"\"\"\n        raise NotImplementedError\n\n    def get_filename(self, fullname):\n        \"\"\"Implement get_filename in terms of source_path.\n\n        As get_filename should only return a source file path there is no\n        chance of the path not existing but loading still being possible, so\n        ImportError should propagate instead of being turned into returning\n        None.\n\n        \"\"\"\n        warnings.warn(\"importlib.abc.PyLoader is deprecated and is \"\n                            \"slated for removal in Python 3.4; \"\n                            \"use SourceLoader instead. \"\n                            \"See the importlib documentation on how to be \"\n                            \"compatible with Python 3.1 onwards.\",\n                        DeprecationWarning)\n        path = self.source_path(fullname)\n        if path is None:\n            raise ImportError(name=fullname)\n        else:\n            return path\n\n\nclass PyPycLoader(PyLoader):\n\n    \"\"\"Abstract base class to assist in loading source and bytecode by\n    requiring only back-end storage methods to be implemented.\n\n    This class has been deprecated! Removal is slated for Python 3.4. Implement\n    the SourceLoader ABC instead. If Python 3.1 compatibility is needed, see\n    PyLoader.\n\n    The methods get_code, get_source, and load_module are implemented for the\n    user.\n\n    \"\"\"\n\n    def get_filename(self, fullname):\n        \"\"\"Return the source or bytecode file path.\"\"\"\n        path = self.source_path(fullname)\n        if path is not None:\n            return path\n        path = self.bytecode_path(fullname)\n        if path is not None:\n            return path\n        raise ImportError(\"no source or bytecode path available for \"\n                            \"{0!r}\".format(fullname), name=fullname)\n\n    def get_code(self, fullname):\n        \"\"\"Get a code object from source or bytecode.\"\"\"\n        warnings.warn(\"importlib.abc.PyPycLoader is deprecated and slated for \"\n                            \"removal in Python 3.4; use SourceLoader instead. \"\n                            \"If Python 3.1 compatibility is required, see the \"\n                            \"latest documentation for PyLoader.\",\n                        DeprecationWarning)\n        source_timestamp = self.source_mtime(fullname)\n        # Try to use bytecode if it is available.\n        bytecode_path = self.bytecode_path(fullname)\n        if bytecode_path:\n            data = self.get_data(bytecode_path)\n            try:\n                magic = data[:4]\n                if len(magic) < 4:\n                    raise ImportError(\n                        \"bad magic number in {}\".format(fullname),\n                        name=fullname, path=bytecode_path)\n                raw_timestamp = data[4:8]\n                if len(raw_timestamp) < 4:\n                    raise EOFError(\"bad timestamp in {}\".format(fullname))\n                pyc_timestamp = _bootstrap._r_long(raw_timestamp)\n                raw_source_size = data[8:12]\n                if len(raw_source_size) != 4:\n                    raise EOFError(\"bad file size in {}\".format(fullname))\n                # Source size is unused as the ABC does not provide a way to\n                # get the size of the source ahead of reading it.\n                bytecode = data[12:]\n                # Verify that the magic number is valid.\n                if imp.get_magic() != magic:\n                    raise ImportError(\n                        \"bad magic number in {}\".format(fullname),\n                        name=fullname, path=bytecode_path)\n                # Verify that the bytecode is not stale (only matters when\n                # there is source to fall back on.\n                if source_timestamp:\n                    if pyc_timestamp < source_timestamp:\n                        raise ImportError(\"bytecode is stale\", name=fullname,\n                                          path=bytecode_path)\n            except (ImportError, EOFError):\n                # If source is available give it a shot.\n                if source_timestamp is not None:\n                    pass\n                else:\n                    raise\n            else:\n                # Bytecode seems fine, so try to use it.\n                return marshal.loads(bytecode)\n        elif source_timestamp is None:\n            raise ImportError(\"no source or bytecode available to create code \"\n                              \"object for {0!r}\".format(fullname),\n                              name=fullname)\n        # Use the source.\n        source_path = self.source_path(fullname)\n        if source_path is None:\n            message = \"a source path must exist to load {0}\".format(fullname)\n            raise ImportError(message, name=fullname)\n        source = self.get_data(source_path)\n        code_object = compile(source, source_path, 'exec', dont_inherit=True)\n        # Generate bytecode and write it out.\n        if not sys.dont_write_bytecode:\n            data = bytearray(imp.get_magic())\n            data.extend(_bootstrap._w_long(source_timestamp))\n            data.extend(_bootstrap._w_long(len(source) & 0xFFFFFFFF))\n            data.extend(marshal.dumps(code_object))\n            self.write_bytecode(fullname, data)\n        return code_object\n\n    @abc.abstractmethod\n    def source_mtime(self, fullname):\n        \"\"\"Abstract method. Accepts a str filename and returns an int\n        modification time for the source of the module.\"\"\"\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def bytecode_path(self, fullname):\n        \"\"\"Abstract method. Accepts a str filename and returns the str pathname\n        to the bytecode for the module.\"\"\"\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def write_bytecode(self, fullname, bytecode):\n        \"\"\"Abstract method.  Accepts a str filename and bytes object\n        representing the bytecode for the module.  Returns a boolean\n        representing whether the bytecode was written or not.\"\"\"\n        raise NotImplementedError\n"], "xml.sax._exceptions": [".py", "\"\"\"Different kinds of SAX Exceptions\"\"\"\nimport sys\nif sys.platform[:4] == \"java\":\n    from java.lang import Exception\ndel sys\n\n# ===== SAXEXCEPTION =====\n\nclass SAXException(Exception):\n    \"\"\"Encapsulate an XML error or warning. This class can contain\n    basic error or warning information from either the XML parser or\n    the application: you can subclass it to provide additional\n    functionality, or to add localization. Note that although you will\n    receive a SAXException as the argument to the handlers in the\n    ErrorHandler interface, you are not actually required to raise\n    the exception; instead, you can simply read the information in\n    it.\"\"\"\n\n    def __init__(self, msg, exception=None):\n        \"\"\"Creates an exception. The message is required, but the exception\n        is optional.\"\"\"\n        self._msg = msg\n        self._exception = exception\n        Exception.__init__(self, msg)\n\n    def getMessage(self):\n        \"Return a message for this exception.\"\n        return self._msg\n\n    def getException(self):\n        \"Return the embedded exception, or None if there was none.\"\n        return self._exception\n\n    def __str__(self):\n        \"Create a string representation of the exception.\"\n        return self._msg\n\n    def __getitem__(self, ix):\n        \"\"\"Avoids weird error messages if someone does exception[ix] by\n        mistake, since Exception has __getitem__ defined.\"\"\"\n        raise AttributeError(\"__getitem__\")\n\n\n# ===== SAXPARSEEXCEPTION =====\n\nclass SAXParseException(SAXException):\n    \"\"\"Encapsulate an XML parse error or warning.\n\n    This exception will include information for locating the error in\n    the original XML document. Note that although the application will\n    receive a SAXParseException as the argument to the handlers in the\n    ErrorHandler interface, the application is not actually required\n    to raise the exception; instead, it can simply read the\n    information in it and take a different action.\n\n    Since this exception is a subclass of SAXException, it inherits\n    the ability to wrap another exception.\"\"\"\n\n    def __init__(self, msg, exception, locator):\n        \"Creates the exception. The exception parameter is allowed to be None.\"\n        SAXException.__init__(self, msg, exception)\n        self._locator = locator\n\n        # We need to cache this stuff at construction time.\n        # If this exception is raised, the objects through which we must\n        # traverse to get this information may be deleted by the time\n        # it gets caught.\n        self._systemId = self._locator.getSystemId()\n        self._colnum = self._locator.getColumnNumber()\n        self._linenum = self._locator.getLineNumber()\n\n    def getColumnNumber(self):\n        \"\"\"The column number of the end of the text where the exception\n        occurred.\"\"\"\n        return self._colnum\n\n    def getLineNumber(self):\n        \"The line number of the end of the text where the exception occurred.\"\n        return self._linenum\n\n    def getPublicId(self):\n        \"Get the public identifier of the entity where the exception occurred.\"\n        return self._locator.getPublicId()\n\n    def getSystemId(self):\n        \"Get the system identifier of the entity where the exception occurred.\"\n        return self._systemId\n\n    def __str__(self):\n        \"Create a string representation of the exception.\"\n        sysid = self.getSystemId()\n        if sysid is None:\n            sysid = \"<unknown>\"\n        linenum = self.getLineNumber()\n        if linenum is None:\n            linenum = \"?\"\n        colnum = self.getColumnNumber()\n        if colnum is None:\n            colnum = \"?\"\n        return \"%s:%s:%s: %s\" % (sysid, linenum, colnum, self._msg)\n\n\n# ===== SAXNOTRECOGNIZEDEXCEPTION =====\n\nclass SAXNotRecognizedException(SAXException):\n    \"\"\"Exception class for an unrecognized identifier.\n\n    An XMLReader will raise this exception when it is confronted with an\n    unrecognized feature or property. SAX applications and extensions may\n    use this class for similar purposes.\"\"\"\n    pass\n\n\n# ===== SAXNOTSUPPORTEDEXCEPTION =====\n\nclass SAXNotSupportedException(SAXException):\n    \"\"\"Exception class for an unsupported operation.\n\n    An XMLReader will raise this exception when a service it cannot\n    perform is requested (specifically setting a state or value). SAX\n    applications and extensions may use this class for similar\n    purposes.\"\"\"\n\n    pass\n# ===== SAXNOTSUPPORTEDEXCEPTION =====\n\nclass SAXReaderNotAvailable(SAXNotSupportedException):\n    \"\"\"Exception class for a missing driver.\n\n    An XMLReader module (driver) should raise this exception when it\n    is first imported, e.g. when a support module cannot be imported.\n    It also may be raised during parsing, e.g. if executing an external\n    program is not permitted.\"\"\"\n\n    pass\n"], "ui": [".py", "from browser import html, document\nfrom .dialog import *\nfrom .progressbar import *\nfrom .slider import *\n\ndef add_stylesheet():\n    _link=html.LINK(Href='/src/Lib/ui/css/smoothness/jquery-ui-1.10.3.custom.min.css')\n    _link.rel='stylesheet'\n\n    document <= _link\n", 1], "xml.dom.domreg": [".py", "\"\"\"Registration facilities for DOM. This module should not be used\ndirectly. Instead, the functions getDOMImplementation and\nregisterDOMImplementation should be imported from xml.dom.\"\"\"\n\n# This is a list of well-known implementations.  Well-known names\n# should be published by posting to xml-sig@python.org, and are\n# subsequently recorded in this file.\n\nwell_known_implementations = {\n    'minidom':'xml.dom.minidom',\n    '4DOM': 'xml.dom.DOMImplementation',\n    }\n\n# DOM implementations not officially registered should register\n# themselves with their\n\nregistered = {}\n\ndef registerDOMImplementation(name, factory):\n    \"\"\"registerDOMImplementation(name, factory)\n\n    Register the factory function with the name. The factory function\n    should return an object which implements the DOMImplementation\n    interface. The factory function can either return the same object,\n    or a new one (e.g. if that implementation supports some\n    customization).\"\"\"\n\n    registered[name] = factory\n\ndef _good_enough(dom, features):\n    \"_good_enough(dom, features) -> Return 1 if the dom offers the features\"\n    for f,v in features:\n        if not dom.hasFeature(f,v):\n            return 0\n    return 1\n\ndef getDOMImplementation(name=None, features=()):\n    \"\"\"getDOMImplementation(name = None, features = ()) -> DOM implementation.\n\n    Return a suitable DOM implementation. The name is either\n    well-known, the module name of a DOM implementation, or None. If\n    it is not None, imports the corresponding module and returns\n    DOMImplementation object if the import succeeds.\n\n    If name is not given, consider the available implementations to\n    find one with the required feature set. If no implementation can\n    be found, raise an ImportError. The features list must be a sequence\n    of (feature, version) pairs which are passed to hasFeature.\"\"\"\n\n    import os\n    creator = None\n    mod = well_known_implementations.get(name)\n    if mod:\n        mod = __import__(mod, {}, {}, ['getDOMImplementation'])\n        return mod.getDOMImplementation()\n    elif name:\n        return registered[name]()\n    elif \"PYTHON_DOM\" in os.environ:\n        return getDOMImplementation(name = os.environ[\"PYTHON_DOM\"])\n\n    # User did not specify a name, try implementations in arbitrary\n    # order, returning the one that has the required features\n    if isinstance(features, str):\n        features = _parse_feature_string(features)\n    for creator in registered.values():\n        dom = creator()\n        if _good_enough(dom, features):\n            return dom\n\n    for creator in well_known_implementations.keys():\n        try:\n            dom = getDOMImplementation(name = creator)\n        except Exception: # typically ImportError, or AttributeError\n            continue\n        if _good_enough(dom, features):\n            return dom\n\n    raise ImportError(\"no suitable DOM implementation found\")\n\ndef _parse_feature_string(s):\n    features = []\n    parts = s.split()\n    i = 0\n    length = len(parts)\n    while i < length:\n        feature = parts[i]\n        if feature[0] in \"0123456789\":\n            raise ValueError(\"bad feature name: %r\" % (feature,))\n        i = i + 1\n        version = None\n        if i < length:\n            v = parts[i]\n            if v[0] in \"0123456789\":\n                i = i + 1\n                version = v\n        features.append((feature, version))\n    return tuple(features)\n"], "subprocess": [".py", "# subprocess - Subprocesses with accessible I/O streams\n#\n# For more information about this module, see PEP 324.\n#\n# Copyright (c) 2003-2005 by Peter Astrand <astrand@lysator.liu.se>\n#\n# Licensed to PSF under a Contributor Agreement.\n# See http://www.python.org/2.4/license for licensing details.\n\nr\"\"\"subprocess - Subprocesses with accessible I/O streams\n\nThis module allows you to spawn processes, connect to their\ninput/output/error pipes, and obtain their return codes.  This module\nintends to replace several other, older modules and functions, like:\n\nos.system\nos.spawn*\n\nInformation about how the subprocess module can be used to replace these\nmodules and functions can be found below.\n\n\n\nUsing the subprocess module\n===========================\nThis module defines one class called Popen:\n\nclass Popen(args, bufsize=-1, executable=None,\n            stdin=None, stdout=None, stderr=None,\n            preexec_fn=None, close_fds=True, shell=False,\n            cwd=None, env=None, universal_newlines=False,\n            startupinfo=None, creationflags=0,\n            restore_signals=True, start_new_session=False, pass_fds=()):\n\n\nArguments are:\n\nargs should be a string, or a sequence of program arguments.  The\nprogram to execute is normally the first item in the args sequence or\nstring, but can be explicitly set by using the executable argument.\n\nOn POSIX, with shell=False (default): In this case, the Popen class\nuses os.execvp() to execute the child program.  args should normally\nbe a sequence.  A string will be treated as a sequence with the string\nas the only item (the program to execute).\n\nOn POSIX, with shell=True: If args is a string, it specifies the\ncommand string to execute through the shell.  If args is a sequence,\nthe first item specifies the command string, and any additional items\nwill be treated as additional shell arguments.\n\nOn Windows: the Popen class uses CreateProcess() to execute the child\nprogram, which operates on strings.  If args is a sequence, it will be\nconverted to a string using the list2cmdline method.  Please note that\nnot all MS Windows applications interpret the command line the same\nway: The list2cmdline is designed for applications using the same\nrules as the MS C runtime.\n\nbufsize will be supplied as the corresponding argument to the io.open()\nfunction when creating the stdin/stdout/stderr pipe file objects:\n0 means unbuffered (read & write are one system call and can return short),\n1 means line buffered, any other positive value means use a buffer of\napproximately that size.  A negative bufsize, the default, means the system\ndefault of io.DEFAULT_BUFFER_SIZE will be used.\n\nstdin, stdout and stderr specify the executed programs' standard\ninput, standard output and standard error file handles, respectively.\nValid values are PIPE, an existing file descriptor (a positive\ninteger), an existing file object, and None.  PIPE indicates that a\nnew pipe to the child should be created.  With None, no redirection\nwill occur; the child's file handles will be inherited from the\nparent.  Additionally, stderr can be STDOUT, which indicates that the\nstderr data from the applications should be captured into the same\nfile handle as for stdout.\n\nOn POSIX, if preexec_fn is set to a callable object, this object will be\ncalled in the child process just before the child is executed.  The use\nof preexec_fn is not thread safe, using it in the presence of threads\ncould lead to a deadlock in the child process before the new executable\nis executed.\n\nIf close_fds is true, all file descriptors except 0, 1 and 2 will be\nclosed before the child process is executed.  The default for close_fds\nvaries by platform:  Always true on POSIX.  True when stdin/stdout/stderr\nare None on Windows, false otherwise.\n\npass_fds is an optional sequence of file descriptors to keep open between the\nparent and child.  Providing any pass_fds implicitly sets close_fds to true.\n\nif shell is true, the specified command will be executed through the\nshell.\n\nIf cwd is not None, the current directory will be changed to cwd\nbefore the child is executed.\n\nOn POSIX, if restore_signals is True all signals that Python sets to\nSIG_IGN are restored to SIG_DFL in the child process before the exec.\nCurrently this includes the SIGPIPE, SIGXFZ and SIGXFSZ signals.  This\nparameter does nothing on Windows.\n\nOn POSIX, if start_new_session is True, the setsid() system call will be made\nin the child process prior to executing the command.\n\nIf env is not None, it defines the environment variables for the new\nprocess.\n\nIf universal_newlines is false, the file objects stdin, stdout and stderr\nare opened as binary files, and no line ending conversion is done.\n\nIf universal_newlines is true, the file objects stdout and stderr are\nopened as a text files, but lines may be terminated by any of '\\n',\nthe Unix end-of-line convention, '\\r', the old Macintosh convention or\n'\\r\\n', the Windows convention.  All of these external representations\nare seen as '\\n' by the Python program.  Also, the newlines attribute\nof the file objects stdout, stdin and stderr are not updated by the\ncommunicate() method.\n\nThe startupinfo and creationflags, if given, will be passed to the\nunderlying CreateProcess() function.  They can specify things such as\nappearance of the main window and priority for the new process.\n(Windows only)\n\n\nThis module also defines some shortcut functions:\n\ncall(*popenargs, **kwargs):\n    Run command with arguments.  Wait for command to complete, then\n    return the returncode attribute.\n\n    The arguments are the same as for the Popen constructor.  Example:\n\n    >>> retcode = subprocess.call([\"ls\", \"-l\"])\n\ncheck_call(*popenargs, **kwargs):\n    Run command with arguments.  Wait for command to complete.  If the\n    exit code was zero then return, otherwise raise\n    CalledProcessError.  The CalledProcessError object will have the\n    return code in the returncode attribute.\n\n    The arguments are the same as for the Popen constructor.  Example:\n\n    >>> subprocess.check_call([\"ls\", \"-l\"])\n    0\n\ngetstatusoutput(cmd):\n    Return (status, output) of executing cmd in a shell.\n\n    Execute the string 'cmd' in a shell with os.popen() and return a 2-tuple\n    (status, output).  cmd is actually run as '{ cmd ; } 2>&1', so that the\n    returned output will contain output or error messages. A trailing newline\n    is stripped from the output. The exit status for the command can be\n    interpreted according to the rules for the C function wait().  Example:\n\n    >>> subprocess.getstatusoutput('ls /bin/ls')\n    (0, '/bin/ls')\n    >>> subprocess.getstatusoutput('cat /bin/junk')\n    (256, 'cat: /bin/junk: No such file or directory')\n    >>> subprocess.getstatusoutput('/bin/junk')\n    (256, 'sh: /bin/junk: not found')\n\ngetoutput(cmd):\n    Return output (stdout or stderr) of executing cmd in a shell.\n\n    Like getstatusoutput(), except the exit status is ignored and the return\n    value is a string containing the command's output.  Example:\n\n    >>> subprocess.getoutput('ls /bin/ls')\n    '/bin/ls'\n\ncheck_output(*popenargs, **kwargs):\n    Run command with arguments and return its output.\n\n    If the exit code was non-zero it raises a CalledProcessError.  The\n    CalledProcessError object will have the return code in the returncode\n    attribute and output in the output attribute.\n\n    The arguments are the same as for the Popen constructor.  Example:\n\n    >>> output = subprocess.check_output([\"ls\", \"-l\", \"/dev/null\"])\n\n\nExceptions\n----------\nExceptions raised in the child process, before the new program has\nstarted to execute, will be re-raised in the parent.  Additionally,\nthe exception object will have one extra attribute called\n'child_traceback', which is a string containing traceback information\nfrom the child's point of view.\n\nThe most common exception raised is OSError.  This occurs, for\nexample, when trying to execute a non-existent file.  Applications\nshould prepare for OSErrors.\n\nA ValueError will be raised if Popen is called with invalid arguments.\n\nExceptions defined within this module inherit from SubprocessError.\ncheck_call() and check_output() will raise CalledProcessError if the\ncalled process returns a non-zero return code.  TimeoutExpired\nbe raised if a timeout was specified and expired.\n\n\nSecurity\n--------\nUnlike some other popen functions, this implementation will never call\n/bin/sh implicitly.  This means that all characters, including shell\nmetacharacters, can safely be passed to child processes.\n\n\nPopen objects\n=============\nInstances of the Popen class have the following methods:\n\npoll()\n    Check if child process has terminated.  Returns returncode\n    attribute.\n\nwait()\n    Wait for child process to terminate.  Returns returncode attribute.\n\ncommunicate(input=None)\n    Interact with process: Send data to stdin.  Read data from stdout\n    and stderr, until end-of-file is reached.  Wait for process to\n    terminate.  The optional input argument should be a string to be\n    sent to the child process, or None, if no data should be sent to\n    the child.\n\n    communicate() returns a tuple (stdout, stderr).\n\n    Note: The data read is buffered in memory, so do not use this\n    method if the data size is large or unlimited.\n\nThe following attributes are also available:\n\nstdin\n    If the stdin argument is PIPE, this attribute is a file object\n    that provides input to the child process.  Otherwise, it is None.\n\nstdout\n    If the stdout argument is PIPE, this attribute is a file object\n    that provides output from the child process.  Otherwise, it is\n    None.\n\nstderr\n    If the stderr argument is PIPE, this attribute is file object that\n    provides error output from the child process.  Otherwise, it is\n    None.\n\npid\n    The process ID of the child process.\n\nreturncode\n    The child return code.  A None value indicates that the process\n    hasn't terminated yet.  A negative value -N indicates that the\n    child was terminated by signal N (POSIX only).\n\n\nReplacing older functions with the subprocess module\n====================================================\nIn this section, \"a ==> b\" means that b can be used as a replacement\nfor a.\n\nNote: All functions in this section fail (more or less) silently if\nthe executed program cannot be found; this module raises an OSError\nexception.\n\nIn the following examples, we assume that the subprocess module is\nimported with \"from subprocess import *\".\n\n\nReplacing /bin/sh shell backquote\n---------------------------------\noutput=`mycmd myarg`\n==>\noutput = Popen([\"mycmd\", \"myarg\"], stdout=PIPE).communicate()[0]\n\n\nReplacing shell pipe line\n-------------------------\noutput=`dmesg | grep hda`\n==>\np1 = Popen([\"dmesg\"], stdout=PIPE)\np2 = Popen([\"grep\", \"hda\"], stdin=p1.stdout, stdout=PIPE)\noutput = p2.communicate()[0]\n\n\nReplacing os.system()\n---------------------\nsts = os.system(\"mycmd\" + \" myarg\")\n==>\np = Popen(\"mycmd\" + \" myarg\", shell=True)\npid, sts = os.waitpid(p.pid, 0)\n\nNote:\n\n* Calling the program through the shell is usually not required.\n\n* It's easier to look at the returncode attribute than the\n  exitstatus.\n\nA more real-world example would look like this:\n\ntry:\n    retcode = call(\"mycmd\" + \" myarg\", shell=True)\n    if retcode < 0:\n        print(\"Child was terminated by signal\", -retcode, file=sys.stderr)\n    else:\n        print(\"Child returned\", retcode, file=sys.stderr)\nexcept OSError as e:\n    print(\"Execution failed:\", e, file=sys.stderr)\n\n\nReplacing os.spawn*\n-------------------\nP_NOWAIT example:\n\npid = os.spawnlp(os.P_NOWAIT, \"/bin/mycmd\", \"mycmd\", \"myarg\")\n==>\npid = Popen([\"/bin/mycmd\", \"myarg\"]).pid\n\n\nP_WAIT example:\n\nretcode = os.spawnlp(os.P_WAIT, \"/bin/mycmd\", \"mycmd\", \"myarg\")\n==>\nretcode = call([\"/bin/mycmd\", \"myarg\"])\n\n\nVector example:\n\nos.spawnvp(os.P_NOWAIT, path, args)\n==>\nPopen([path] + args[1:])\n\n\nEnvironment example:\n\nos.spawnlpe(os.P_NOWAIT, \"/bin/mycmd\", \"mycmd\", \"myarg\", env)\n==>\nPopen([\"/bin/mycmd\", \"myarg\"], env={\"PATH\": \"/usr/bin\"})\n\"\"\"\n\nimport sys\nmswindows = (sys.platform == \"win32\")\n\nimport io\nimport os\nimport time\nimport traceback\nimport gc\nimport signal\nimport builtins\nimport warnings\nimport errno\ntry:\n    from time import monotonic as _time\nexcept ImportError:\n    from time import time as _time\n\n# Exception classes used by this module.\nclass SubprocessError(Exception): pass\n\n\nclass CalledProcessError(SubprocessError):\n    \"\"\"This exception is raised when a process run by check_call() or\n    check_output() returns a non-zero exit status.\n    The exit status will be stored in the returncode attribute;\n    check_output() will also store the output in the output attribute.\n    \"\"\"\n    def __init__(self, returncode, cmd, output=None):\n        self.returncode = returncode\n        self.cmd = cmd\n        self.output = output\n    def __str__(self):\n        return \"Command '%s' returned non-zero exit status %d\" % (self.cmd, self.returncode)\n\n\nclass TimeoutExpired(SubprocessError):\n    \"\"\"This exception is raised when the timeout expires while waiting for a\n    child process.\n    \"\"\"\n    def __init__(self, cmd, timeout, output=None):\n        self.cmd = cmd\n        self.timeout = timeout\n        self.output = output\n\n    def __str__(self):\n        return (\"Command '%s' timed out after %s seconds\" %\n                (self.cmd, self.timeout))\n\n\nif mswindows:\n    import threading\n    import msvcrt\n    import _winapi\n    class STARTUPINFO:\n        dwFlags = 0\n        hStdInput = None\n        hStdOutput = None\n        hStdError = None\n        wShowWindow = 0\n    class pywintypes:\n        error = IOError\nelse:\n    import select\n    _has_poll = hasattr(select, 'poll')\n    import _posixsubprocess\n    _create_pipe = _posixsubprocess.cloexec_pipe\n\n    # When select or poll has indicated that the file is writable,\n    # we can write up to _PIPE_BUF bytes without risk of blocking.\n    # POSIX defines PIPE_BUF as >= 512.\n    _PIPE_BUF = getattr(select, 'PIPE_BUF', 512)\n\n\n__all__ = [\"Popen\", \"PIPE\", \"STDOUT\", \"call\", \"check_call\", \"getstatusoutput\",\n           \"getoutput\", \"check_output\", \"CalledProcessError\", \"DEVNULL\"]\n\nif mswindows:\n    from _winapi import (CREATE_NEW_CONSOLE, CREATE_NEW_PROCESS_GROUP,\n                         STD_INPUT_HANDLE, STD_OUTPUT_HANDLE,\n                         STD_ERROR_HANDLE, SW_HIDE,\n                         STARTF_USESTDHANDLES, STARTF_USESHOWWINDOW)\n\n    __all__.extend([\"CREATE_NEW_CONSOLE\", \"CREATE_NEW_PROCESS_GROUP\",\n                    \"STD_INPUT_HANDLE\", \"STD_OUTPUT_HANDLE\",\n                    \"STD_ERROR_HANDLE\", \"SW_HIDE\",\n                    \"STARTF_USESTDHANDLES\", \"STARTF_USESHOWWINDOW\"])\n\n    class Handle(int):\n        closed = False\n\n        def Close(self, CloseHandle=_winapi.CloseHandle):\n            if not self.closed:\n                self.closed = True\n                CloseHandle(self)\n\n        def Detach(self):\n            if not self.closed:\n                self.closed = True\n                return int(self)\n            raise ValueError(\"already closed\")\n\n        def __repr__(self):\n            return \"Handle(%d)\" % int(self)\n\n        __del__ = Close\n        __str__ = __repr__\n\ntry:\n    MAXFD = os.sysconf(\"SC_OPEN_MAX\")\nexcept:\n    MAXFD = 256\n\n# This lists holds Popen instances for which the underlying process had not\n# exited at the time its __del__ method got called: those processes are wait()ed\n# for synchronously from _cleanup() when a new Popen object is created, to avoid\n# zombie processes.\n_active = []\n\ndef _cleanup():\n    for inst in _active[:]:\n        res = inst._internal_poll(_deadstate=sys.maxsize)\n        if res is not None:\n            try:\n                _active.remove(inst)\n            except ValueError:\n                # This can happen if two threads create a new Popen instance.\n                # It's harmless that it was already removed, so ignore.\n                pass\n\nPIPE = -1\nSTDOUT = -2\nDEVNULL = -3\n\n\ndef _eintr_retry_call(func, *args):\n    while True:\n        try:\n            return func(*args)\n        except InterruptedError:\n            continue\n\n\n# XXX This function is only used by multiprocessing and the test suite,\n# but it's here so that it can be imported when Python is compiled without\n# threads.\n\ndef _args_from_interpreter_flags():\n    \"\"\"Return a list of command-line arguments reproducing the current\n    settings in sys.flags and sys.warnoptions.\"\"\"\n    flag_opt_map = {\n        'debug': 'd',\n        # 'inspect': 'i',\n        # 'interactive': 'i',\n        'optimize': 'O',\n        'dont_write_bytecode': 'B',\n        'no_user_site': 's',\n        'no_site': 'S',\n        'ignore_environment': 'E',\n        'verbose': 'v',\n        'bytes_warning': 'b',\n        'quiet': 'q',\n        'hash_randomization': 'R',\n    }\n    args = []\n    for flag, opt in flag_opt_map.items():\n        v = getattr(sys.flags, flag)\n        if v > 0:\n            args.append('-' + opt * v)\n    for opt in sys.warnoptions:\n        args.append('-W' + opt)\n    return args\n\n\ndef call(*popenargs, timeout=None, **kwargs):\n    \"\"\"Run command with arguments.  Wait for command to complete or\n    timeout, then return the returncode attribute.\n\n    The arguments are the same as for the Popen constructor.  Example:\n\n    retcode = call([\"ls\", \"-l\"])\n    \"\"\"\n    with Popen(*popenargs, **kwargs) as p:\n        try:\n            return p.wait(timeout=timeout)\n        except:\n            p.kill()\n            p.wait()\n            raise\n\n\ndef check_call(*popenargs, **kwargs):\n    \"\"\"Run command with arguments.  Wait for command to complete.  If\n    the exit code was zero then return, otherwise raise\n    CalledProcessError.  The CalledProcessError object will have the\n    return code in the returncode attribute.\n\n    The arguments are the same as for the call function.  Example:\n\n    check_call([\"ls\", \"-l\"])\n    \"\"\"\n    retcode = call(*popenargs, **kwargs)\n    if retcode:\n        cmd = kwargs.get(\"args\")\n        if cmd is None:\n            cmd = popenargs[0]\n        raise CalledProcessError(retcode, cmd)\n    return 0\n\n\ndef check_output(*popenargs, timeout=None, **kwargs):\n    r\"\"\"Run command with arguments and return its output.\n\n    If the exit code was non-zero it raises a CalledProcessError.  The\n    CalledProcessError object will have the return code in the returncode\n    attribute and output in the output attribute.\n\n    The arguments are the same as for the Popen constructor.  Example:\n\n    >>> check_output([\"ls\", \"-l\", \"/dev/null\"])\n    b'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\\n'\n\n    The stdout argument is not allowed as it is used internally.\n    To capture standard error in the result, use stderr=STDOUT.\n\n    >>> check_output([\"/bin/sh\", \"-c\",\n    ...               \"ls -l non_existent_file ; exit 0\"],\n    ...              stderr=STDOUT)\n    b'ls: non_existent_file: No such file or directory\\n'\n\n    If universal_newlines=True is passed, the return value will be a\n    string rather than bytes.\n    \"\"\"\n    if 'stdout' in kwargs:\n        raise ValueError('stdout argument not allowed, it will be overridden.')\n    with Popen(*popenargs, stdout=PIPE, **kwargs) as process:\n        try:\n            output, unused_err = process.communicate(timeout=timeout)\n        except TimeoutExpired:\n            process.kill()\n            output, unused_err = process.communicate()\n            raise TimeoutExpired(process.args, timeout, output=output)\n        except:\n            process.kill()\n            process.wait()\n            raise\n        retcode = process.poll()\n        if retcode:\n            raise CalledProcessError(retcode, process.args, output=output)\n    return output\n\n\ndef list2cmdline(seq):\n    \"\"\"\n    Translate a sequence of arguments into a command line\n    string, using the same rules as the MS C runtime:\n\n    1) Arguments are delimited by white space, which is either a\n       space or a tab.\n\n    2) A string surrounded by double quotation marks is\n       interpreted as a single argument, regardless of white space\n       contained within.  A quoted string can be embedded in an\n       argument.\n\n    3) A double quotation mark preceded by a backslash is\n       interpreted as a literal double quotation mark.\n\n    4) Backslashes are interpreted literally, unless they\n       immediately precede a double quotation mark.\n\n    5) If backslashes immediately precede a double quotation mark,\n       every pair of backslashes is interpreted as a literal\n       backslash.  If the number of backslashes is odd, the last\n       backslash escapes the next double quotation mark as\n       described in rule 3.\n    \"\"\"\n\n    # See\n    # http://msdn.microsoft.com/en-us/library/17w5ykft.aspx\n    # or search http://msdn.microsoft.com for\n    # \"Parsing C++ Command-Line Arguments\"\n    result = []\n    needquote = False\n    for arg in seq:\n        bs_buf = []\n\n        # Add a space to separate this argument from the others\n        if result:\n            result.append(' ')\n\n        needquote = (\" \" in arg) or (\"\\t\" in arg) or not arg\n        if needquote:\n            result.append('\"')\n\n        for c in arg:\n            if c == '\\\\':\n                # Don't know if we need to double yet.\n                bs_buf.append(c)\n            elif c == '\"':\n                # Double backslashes.\n                result.append('\\\\' * len(bs_buf)*2)\n                bs_buf = []\n                result.append('\\\\\"')\n            else:\n                # Normal char\n                if bs_buf:\n                    result.extend(bs_buf)\n                    bs_buf = []\n                result.append(c)\n\n        # Add remaining backslashes, if any.\n        if bs_buf:\n            result.extend(bs_buf)\n\n        if needquote:\n            result.extend(bs_buf)\n            result.append('\"')\n\n    return ''.join(result)\n\n\n# Various tools for executing commands and looking at their output and status.\n#\n# NB This only works (and is only relevant) for POSIX.\n\ndef getstatusoutput(cmd):\n    \"\"\"Return (status, output) of executing cmd in a shell.\n\n    Execute the string 'cmd' in a shell with os.popen() and return a 2-tuple\n    (status, output).  cmd is actually run as '{ cmd ; } 2>&1', so that the\n    returned output will contain output or error messages.  A trailing newline\n    is stripped from the output.  The exit status for the command can be\n    interpreted according to the rules for the C function wait().  Example:\n\n    >>> import subprocess\n    >>> subprocess.getstatusoutput('ls /bin/ls')\n    (0, '/bin/ls')\n    >>> subprocess.getstatusoutput('cat /bin/junk')\n    (256, 'cat: /bin/junk: No such file or directory')\n    >>> subprocess.getstatusoutput('/bin/junk')\n    (256, 'sh: /bin/junk: not found')\n    \"\"\"\n    with os.popen('{ ' + cmd + '; } 2>&1', 'r') as pipe:\n        try:\n            text = pipe.read()\n            sts = pipe.close()\n        except:\n            process = pipe._proc\n            process.kill()\n            process.wait()\n            raise\n    if sts is None:\n        sts = 0\n    if text[-1:] == '\\n':\n        text = text[:-1]\n    return sts, text\n\n\ndef getoutput(cmd):\n    \"\"\"Return output (stdout or stderr) of executing cmd in a shell.\n\n    Like getstatusoutput(), except the exit status is ignored and the return\n    value is a string containing the command's output.  Example:\n\n    >>> import subprocess\n    >>> subprocess.getoutput('ls /bin/ls')\n    '/bin/ls'\n    \"\"\"\n    return getstatusoutput(cmd)[1]\n\n\n_PLATFORM_DEFAULT_CLOSE_FDS = object()\n\n\nclass Popen(object):\n    def __init__(self, args, bufsize=-1, executable=None,\n                 stdin=None, stdout=None, stderr=None,\n                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,\n                 shell=False, cwd=None, env=None, universal_newlines=False,\n                 startupinfo=None, creationflags=0,\n                 restore_signals=True, start_new_session=False,\n                 pass_fds=()):\n        \"\"\"Create new Popen instance.\"\"\"\n        _cleanup()\n\n        self._child_created = False\n        self._input = None\n        self._communication_started = False\n        if bufsize is None:\n            bufsize = -1  # Restore default\n        if not isinstance(bufsize, int):\n            raise TypeError(\"bufsize must be an integer\")\n\n        if mswindows:\n            if preexec_fn is not None:\n                raise ValueError(\"preexec_fn is not supported on Windows \"\n                                 \"platforms\")\n            any_stdio_set = (stdin is not None or stdout is not None or\n                             stderr is not None)\n            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:\n                if any_stdio_set:\n                    close_fds = False\n                else:\n                    close_fds = True\n            elif close_fds and any_stdio_set:\n                raise ValueError(\n                        \"close_fds is not supported on Windows platforms\"\n                        \" if you redirect stdin/stdout/stderr\")\n        else:\n            # POSIX\n            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:\n                close_fds = True\n            if pass_fds and not close_fds:\n                warnings.warn(\"pass_fds overriding close_fds.\", RuntimeWarning)\n                close_fds = True\n            if startupinfo is not None:\n                raise ValueError(\"startupinfo is only supported on Windows \"\n                                 \"platforms\")\n            if creationflags != 0:\n                raise ValueError(\"creationflags is only supported on Windows \"\n                                 \"platforms\")\n\n        self.args = args\n        self.stdin = None\n        self.stdout = None\n        self.stderr = None\n        self.pid = None\n        self.returncode = None\n        self.universal_newlines = universal_newlines\n\n        # Input and output objects. The general principle is like\n        # this:\n        #\n        # Parent                   Child\n        # ------                   -----\n        # p2cwrite   ---stdin--->  p2cread\n        # c2pread    <--stdout---  c2pwrite\n        # errread    <--stderr---  errwrite\n        #\n        # On POSIX, the child objects are file descriptors.  On\n        # Windows, these are Windows file handles.  The parent objects\n        # are file descriptors on both platforms.  The parent objects\n        # are -1 when not using PIPEs. The child objects are -1\n        # when not redirecting.\n\n        (p2cread, p2cwrite,\n         c2pread, c2pwrite,\n         errread, errwrite) = self._get_handles(stdin, stdout, stderr)\n\n        # We wrap OS handles *before* launching the child, otherwise a\n        # quickly terminating child could make our fds unwrappable\n        # (see #8458).\n        \n        #fix me brython  syntax error\n        #if mswindows:\n        #    if p2cwrite != -1:\n        #        p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)\n        #    if c2pread != -1:\n        #        c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)\n        #    if errread != -1:\n        #        errread = msvcrt.open_osfhandle(errread.Detach(), 0)\n        \n        if p2cwrite != -1:\n            self.stdin = io.open(p2cwrite, 'wb', bufsize)\n            if universal_newlines:\n                self.stdin = io.TextIOWrapper(self.stdin, write_through=True)\n        if c2pread != -1:\n            self.stdout = io.open(c2pread, 'rb', bufsize)\n            if universal_newlines:\n                self.stdout = io.TextIOWrapper(self.stdout)\n        if errread != -1:\n            self.stderr = io.open(errread, 'rb', bufsize)\n            if universal_newlines:\n                self.stderr = io.TextIOWrapper(self.stderr)\n\n        self._closed_child_pipe_fds = False\n        try:\n            self._execute_child(args, executable, preexec_fn, close_fds,\n                                pass_fds, cwd, env,\n                                startupinfo, creationflags, shell,\n                                p2cread, p2cwrite,\n                                c2pread, c2pwrite,\n                                errread, errwrite,\n                                restore_signals, start_new_session)\n        except:\n            # Cleanup if the child failed starting.\n            for f in filter(None, (self.stdin, self.stdout, self.stderr)):\n                try:\n                    f.close()\n                except EnvironmentError:\n                    pass  # Ignore EBADF or other errors.\n\n            if not self._closed_child_pipe_fds:\n                to_close = []\n                if stdin == PIPE:\n                    to_close.append(p2cread)\n                if stdout == PIPE:\n                    to_close.append(c2pwrite)\n                if stderr == PIPE:\n                    to_close.append(errwrite)\n                if hasattr(self, '_devnull'):\n                    to_close.append(self._devnull)\n                for fd in to_close:\n                    try:\n                        os.close(fd)\n                    except EnvironmentError:\n                        pass\n\n            raise\n\n\n    def _translate_newlines(self, data, encoding):\n        data = data.decode(encoding)\n        return data.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, traceback):\n        if self.stdout:\n            self.stdout.close()\n        if self.stderr:\n            self.stderr.close()\n        if self.stdin:\n            self.stdin.close()\n        # Wait for the process to terminate, to avoid zombies.\n        self.wait()\n\n    def __del__(self, _maxsize=sys.maxsize, _active=_active):\n        # If __init__ hasn't had a chance to execute (e.g. if it\n        # was passed an undeclared keyword argument), we don't\n        # have a _child_created attribute at all.\n        if not getattr(self, '_child_created', False):\n            # We didn't get to successfully create a child process.\n            return\n        # In case the child hasn't been waited on, check if it's done.\n        self._internal_poll(_deadstate=_maxsize)\n        if self.returncode is None and _active is not None:\n            # Child is still running, keep us alive until we can wait on it.\n            _active.append(self)\n\n    def _get_devnull(self):\n        if not hasattr(self, '_devnull'):\n            self._devnull = os.open(os.devnull, os.O_RDWR)\n        return self._devnull\n\n    def communicate(self, input=None, timeout=None):\n        \"\"\"Interact with process: Send data to stdin.  Read data from\n        stdout and stderr, until end-of-file is reached.  Wait for\n        process to terminate.  The optional input argument should be\n        bytes to be sent to the child process, or None, if no data\n        should be sent to the child.\n\n        communicate() returns a tuple (stdout, stderr).\"\"\"\n\n        if self._communication_started and input:\n            raise ValueError(\"Cannot send input after starting communication\")\n\n        # Optimization: If we are not worried about timeouts, we haven't\n        # started communicating, and we have one or zero pipes, using select()\n        # or threads is unnecessary.\n        if (timeout is None and not self._communication_started and\n            [self.stdin, self.stdout, self.stderr].count(None) >= 2):\n            stdout = None\n            stderr = None\n            if self.stdin:\n                if input:\n                    try:\n                        self.stdin.write(input)\n                    except IOError as e:\n                        if e.errno != errno.EPIPE and e.errno != errno.EINVAL:\n                            raise\n                self.stdin.close()\n            elif self.stdout:\n                stdout = _eintr_retry_call(self.stdout.read)\n                self.stdout.close()\n            elif self.stderr:\n                stderr = _eintr_retry_call(self.stderr.read)\n                self.stderr.close()\n            self.wait()\n        else:\n            if timeout is not None:\n                endtime = _time() + timeout\n            else:\n                endtime = None\n\n            try:\n                stdout, stderr = self._communicate(input, endtime, timeout)\n            finally:\n                self._communication_started = True\n\n            sts = self.wait(timeout=self._remaining_time(endtime))\n\n        return (stdout, stderr)\n\n\n    def poll(self):\n        return self._internal_poll()\n\n\n    def _remaining_time(self, endtime):\n        \"\"\"Convenience for _communicate when computing timeouts.\"\"\"\n        if endtime is None:\n            return None\n        else:\n            return endtime - _time()\n\n\n    def _check_timeout(self, endtime, orig_timeout):\n        \"\"\"Convenience for checking if a timeout has expired.\"\"\"\n        if endtime is None:\n            return\n        if _time() > endtime:\n            raise TimeoutExpired(self.args, orig_timeout)\n\n\n    if mswindows:\n        #\n        # Windows methods\n        #\n        def _get_handles(self, stdin, stdout, stderr):\n            \"\"\"Construct and return tuple with IO objects:\n            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite\n            \"\"\"\n            if stdin is None and stdout is None and stderr is None:\n                return (-1, -1, -1, -1, -1, -1)\n\n            p2cread, p2cwrite = -1, -1\n            c2pread, c2pwrite = -1, -1\n            errread, errwrite = -1, -1\n\n            if stdin is None:\n                p2cread = _winapi.GetStdHandle(_winapi.STD_INPUT_HANDLE)\n                if p2cread is None:\n                    p2cread, _ = _winapi.CreatePipe(None, 0)\n                    p2cread = Handle(p2cread)\n                    _winapi.CloseHandle(_)\n            elif stdin == PIPE:\n                p2cread, p2cwrite = _winapi.CreatePipe(None, 0)\n                p2cread, p2cwrite = Handle(p2cread), Handle(p2cwrite)\n            elif stdin == DEVNULL:\n                p2cread = msvcrt.get_osfhandle(self._get_devnull())\n            elif isinstance(stdin, int):\n                p2cread = msvcrt.get_osfhandle(stdin)\n            else:\n                # Assuming file-like object\n                p2cread = msvcrt.get_osfhandle(stdin.fileno())\n            p2cread = self._make_inheritable(p2cread)\n\n            if stdout is None:\n                c2pwrite = _winapi.GetStdHandle(_winapi.STD_OUTPUT_HANDLE)\n                if c2pwrite is None:\n                    _, c2pwrite = _winapi.CreatePipe(None, 0)\n                    c2pwrite = Handle(c2pwrite)\n                    _winapi.CloseHandle(_)\n            elif stdout == PIPE:\n                c2pread, c2pwrite = _winapi.CreatePipe(None, 0)\n                c2pread, c2pwrite = Handle(c2pread), Handle(c2pwrite)\n            elif stdout == DEVNULL:\n                c2pwrite = msvcrt.get_osfhandle(self._get_devnull())\n            elif isinstance(stdout, int):\n                c2pwrite = msvcrt.get_osfhandle(stdout)\n            else:\n                # Assuming file-like object\n                c2pwrite = msvcrt.get_osfhandle(stdout.fileno())\n            c2pwrite = self._make_inheritable(c2pwrite)\n\n            if stderr is None:\n                errwrite = _winapi.GetStdHandle(_winapi.STD_ERROR_HANDLE)\n                if errwrite is None:\n                    _, errwrite = _winapi.CreatePipe(None, 0)\n                    errwrite = Handle(errwrite)\n                    _winapi.CloseHandle(_)\n            elif stderr == PIPE:\n                errread, errwrite = _winapi.CreatePipe(None, 0)\n                errread, errwrite = Handle(errread), Handle(errwrite)\n            elif stderr == STDOUT:\n                errwrite = c2pwrite\n            elif stderr == DEVNULL:\n                errwrite = msvcrt.get_osfhandle(self._get_devnull())\n            elif isinstance(stderr, int):\n                errwrite = msvcrt.get_osfhandle(stderr)\n            else:\n                # Assuming file-like object\n                errwrite = msvcrt.get_osfhandle(stderr.fileno())\n            errwrite = self._make_inheritable(errwrite)\n\n            return (p2cread, p2cwrite,\n                    c2pread, c2pwrite,\n                    errread, errwrite)\n\n\n        def _make_inheritable(self, handle):\n            \"\"\"Return a duplicate of handle, which is inheritable\"\"\"\n            h = _winapi.DuplicateHandle(\n                _winapi.GetCurrentProcess(), handle,\n                _winapi.GetCurrentProcess(), 0, 1,\n                _winapi.DUPLICATE_SAME_ACCESS)\n            return Handle(h)\n\n\n        def _find_w9xpopen(self):\n            \"\"\"Find and return absolut path to w9xpopen.exe\"\"\"\n            w9xpopen = os.path.join(\n                            os.path.dirname(_winapi.GetModuleFileName(0)),\n                                    \"w9xpopen.exe\")\n            if not os.path.exists(w9xpopen):\n                # Eeek - file-not-found - possibly an embedding\n                # situation - see if we can locate it in sys.exec_prefix\n                w9xpopen = os.path.join(os.path.dirname(sys.base_exec_prefix),\n                                        \"w9xpopen.exe\")\n                if not os.path.exists(w9xpopen):\n                    raise RuntimeError(\"Cannot locate w9xpopen.exe, which is \"\n                                       \"needed for Popen to work with your \"\n                                       \"shell or platform.\")\n            return w9xpopen\n\n\n        def _execute_child(self, args, executable, preexec_fn, close_fds,\n                           pass_fds, cwd, env,\n                           startupinfo, creationflags, shell,\n                           p2cread, p2cwrite,\n                           c2pread, c2pwrite,\n                           errread, errwrite,\n                           unused_restore_signals, unused_start_new_session):\n            \"\"\"Execute program (MS Windows version)\"\"\"\n\n            assert not pass_fds, \"pass_fds not supported on Windows.\"\n\n            if not isinstance(args, str):\n                args = list2cmdline(args)\n\n            # Process startup details\n            if startupinfo is None:\n                startupinfo = STARTUPINFO()\n            if -1 not in (p2cread, c2pwrite, errwrite):\n                startupinfo.dwFlags |= _winapi.STARTF_USESTDHANDLES\n                startupinfo.hStdInput = p2cread\n                startupinfo.hStdOutput = c2pwrite\n                startupinfo.hStdError = errwrite\n\n            if shell:\n                startupinfo.dwFlags |= _winapi.STARTF_USESHOWWINDOW\n                startupinfo.wShowWindow = _winapi.SW_HIDE\n                comspec = os.environ.get(\"COMSPEC\", \"cmd.exe\")\n                args = '{} /c \"{}\"'.format (comspec, args)\n                if (_winapi.GetVersion() >= 0x80000000 or\n                        os.path.basename(comspec).lower() == \"command.com\"):\n                    # Win9x, or using command.com on NT. We need to\n                    # use the w9xpopen intermediate program. For more\n                    # information, see KB Q150956\n                    # (http://web.archive.org/web/20011105084002/http://support.microsoft.com/support/kb/articles/Q150/9/56.asp)\n                    w9xpopen = self._find_w9xpopen()\n                    args = '\"%s\" %s' % (w9xpopen, args)\n                    # Not passing CREATE_NEW_CONSOLE has been known to\n                    # cause random failures on win9x.  Specifically a\n                    # dialog: \"Your program accessed mem currently in\n                    # use at xxx\" and a hopeful warning about the\n                    # stability of your system.  Cost is Ctrl+C won't\n                    # kill children.\n                    creationflags |= _winapi.CREATE_NEW_CONSOLE\n\n            # Start the process\n            try:\n                hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n                                         # no special security\n                                         None, None,\n                                         int(not close_fds),\n                                         creationflags,\n                                         env,\n                                         cwd,\n                                         startupinfo)\n            except pywintypes.error as e:\n                # Translate pywintypes.error to WindowsError, which is\n                # a subclass of OSError.  FIXME: We should really\n                # translate errno using _sys_errlist (or similar), but\n                # how can this be done from Python?\n                raise WindowsError(*e.args)\n            finally:\n                # Child is launched. Close the parent's copy of those pipe\n                # handles that only the child should have open.  You need\n                # to make sure that no handles to the write end of the\n                # output pipe are maintained in this process or else the\n                # pipe will not close when the child process exits and the\n                # ReadFile will hang.\n                if p2cread != -1:\n                    p2cread.Close()\n                if c2pwrite != -1:\n                    c2pwrite.Close()\n                if errwrite != -1:\n                    errwrite.Close()\n                if hasattr(self, '_devnull'):\n                    os.close(self._devnull)\n\n            # Retain the process handle, but close the thread handle\n            self._child_created = True\n            self._handle = Handle(hp)\n            self.pid = pid\n            _winapi.CloseHandle(ht)\n\n        def _internal_poll(self, _deadstate=None,\n                _WaitForSingleObject=_winapi.WaitForSingleObject,\n                _WAIT_OBJECT_0=_winapi.WAIT_OBJECT_0,\n                _GetExitCodeProcess=_winapi.GetExitCodeProcess):\n            \"\"\"Check if child process has terminated.  Returns returncode\n            attribute.\n\n            This method is called by __del__, so it can only refer to objects\n            in its local scope.\n\n            \"\"\"\n            if self.returncode is None:\n                if _WaitForSingleObject(self._handle, 0) == _WAIT_OBJECT_0:\n                    self.returncode = _GetExitCodeProcess(self._handle)\n            return self.returncode\n\n\n        def wait(self, timeout=None, endtime=None):\n            \"\"\"Wait for child process to terminate.  Returns returncode\n            attribute.\"\"\"\n            if endtime is not None:\n                timeout = self._remaining_time(endtime)\n            if timeout is None:\n                timeout_millis = _winapi.INFINITE\n            else:\n                timeout_millis = int(timeout * 1000)\n            if self.returncode is None:\n                result = _winapi.WaitForSingleObject(self._handle,\n                                                    timeout_millis)\n                if result == _winapi.WAIT_TIMEOUT:\n                    raise TimeoutExpired(self.args, timeout)\n                self.returncode = _winapi.GetExitCodeProcess(self._handle)\n            return self.returncode\n\n\n        def _readerthread(self, fh, buffer):\n            buffer.append(fh.read())\n            fh.close()\n\n\n        def _communicate(self, input, endtime, orig_timeout):\n            # Start reader threads feeding into a list hanging off of this\n            # object, unless they've already been started.\n            if self.stdout and not hasattr(self, \"_stdout_buff\"):\n                self._stdout_buff = []\n                self.stdout_thread = \\\n                        threading.Thread(target=self._readerthread,\n                                         args=(self.stdout, self._stdout_buff))\n                self.stdout_thread.daemon = True\n                self.stdout_thread.start()\n            if self.stderr and not hasattr(self, \"_stderr_buff\"):\n                self._stderr_buff = []\n                self.stderr_thread = \\\n                        threading.Thread(target=self._readerthread,\n                                         args=(self.stderr, self._stderr_buff))\n                self.stderr_thread.daemon = True\n                self.stderr_thread.start()\n\n            if self.stdin:\n                if input is not None:\n                    try:\n                        self.stdin.write(input)\n                    except IOError as e:\n                        if e.errno != errno.EPIPE:\n                            raise\n                self.stdin.close()\n\n            # Wait for the reader threads, or time out.  If we time out, the\n            # threads remain reading and the fds left open in case the user\n            # calls communicate again.\n            if self.stdout is not None:\n                self.stdout_thread.join(self._remaining_time(endtime))\n                if self.stdout_thread.is_alive():\n                    raise TimeoutExpired(self.args, orig_timeout)\n            if self.stderr is not None:\n                self.stderr_thread.join(self._remaining_time(endtime))\n                if self.stderr_thread.is_alive():\n                    raise TimeoutExpired(self.args, orig_timeout)\n\n            # Collect the output from and close both pipes, now that we know\n            # both have been read successfully.\n            stdout = None\n            stderr = None\n            if self.stdout:\n                stdout = self._stdout_buff\n                self.stdout.close()\n            if self.stderr:\n                stderr = self._stderr_buff\n                self.stderr.close()\n\n            # All data exchanged.  Translate lists into strings.\n            if stdout is not None:\n                stdout = stdout[0]\n            if stderr is not None:\n                stderr = stderr[0]\n\n            return (stdout, stderr)\n\n        def send_signal(self, sig):\n            \"\"\"Send a signal to the process\n            \"\"\"\n            if sig == signal.SIGTERM:\n                self.terminate()\n            elif sig == signal.CTRL_C_EVENT:\n                os.kill(self.pid, signal.CTRL_C_EVENT)\n            elif sig == signal.CTRL_BREAK_EVENT:\n                os.kill(self.pid, signal.CTRL_BREAK_EVENT)\n            else:\n                raise ValueError(\"Unsupported signal: {}\".format(sig))\n\n        def terminate(self):\n            \"\"\"Terminates the process\n            \"\"\"\n            try:\n                _winapi.TerminateProcess(self._handle, 1)\n            except PermissionError:\n                # ERROR_ACCESS_DENIED (winerror 5) is received when the\n                # process already died.\n                rc = _winapi.GetExitCodeProcess(self._handle)\n                if rc == _winapi.STILL_ACTIVE:\n                    raise\n                self.returncode = rc\n\n        kill = terminate\n\n    else:\n        #\n        # POSIX methods\n        #\n        def _get_handles(self, stdin, stdout, stderr):\n            \"\"\"Construct and return tuple with IO objects:\n            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite\n            \"\"\"\n            p2cread, p2cwrite = -1, -1\n            c2pread, c2pwrite = -1, -1\n            errread, errwrite = -1, -1\n\n            if stdin is None:\n                pass\n            elif stdin == PIPE:\n                p2cread, p2cwrite = _create_pipe()\n            elif stdin == DEVNULL:\n                p2cread = self._get_devnull()\n            elif isinstance(stdin, int):\n                p2cread = stdin\n            else:\n                # Assuming file-like object\n                p2cread = stdin.fileno()\n\n            if stdout is None:\n                pass\n            elif stdout == PIPE:\n                c2pread, c2pwrite = _create_pipe()\n            elif stdout == DEVNULL:\n                c2pwrite = self._get_devnull()\n            elif isinstance(stdout, int):\n                c2pwrite = stdout\n            else:\n                # Assuming file-like object\n                c2pwrite = stdout.fileno()\n\n            if stderr is None:\n                pass\n            elif stderr == PIPE:\n                errread, errwrite = _create_pipe()\n            elif stderr == STDOUT:\n                errwrite = c2pwrite\n            elif stderr == DEVNULL:\n                errwrite = self._get_devnull()\n            elif isinstance(stderr, int):\n                errwrite = stderr\n            else:\n                # Assuming file-like object\n                errwrite = stderr.fileno()\n\n            return (p2cread, p2cwrite,\n                    c2pread, c2pwrite,\n                    errread, errwrite)\n\n\n        def _close_fds(self, fds_to_keep):\n            start_fd = 3\n            for fd in sorted(fds_to_keep):\n                if fd >= start_fd:\n                    os.closerange(start_fd, fd)\n                    start_fd = fd + 1\n            if start_fd <= MAXFD:\n                os.closerange(start_fd, MAXFD)\n\n\n        def _execute_child(self, args, executable, preexec_fn, close_fds,\n                           pass_fds, cwd, env,\n                           startupinfo, creationflags, shell,\n                           p2cread, p2cwrite,\n                           c2pread, c2pwrite,\n                           errread, errwrite,\n                           restore_signals, start_new_session):\n            \"\"\"Execute program (POSIX version)\"\"\"\n\n            if isinstance(args, (str, bytes)):\n                args = [args]\n            else:\n                args = list(args)\n\n            if shell:\n                args = [\"/bin/sh\", \"-c\"] + args\n                if executable:\n                    args[0] = executable\n\n            if executable is None:\n                executable = args[0]\n            orig_executable = executable\n\n            # For transferring possible exec failure from child to parent.\n            # Data format: \"exception name:hex errno:description\"\n            # Pickle is not used; it is complex and involves memory allocation.\n            errpipe_read, errpipe_write = _create_pipe()\n            try:\n                try:\n                    # We must avoid complex work that could involve\n                    # malloc or free in the child process to avoid\n                    # potential deadlocks, thus we do all this here.\n                    # and pass it to fork_exec()\n\n                    if env is not None:\n                        env_list = [os.fsencode(k) + b'=' + os.fsencode(v)\n                                    for k, v in env.items()]\n                    else:\n                        env_list = None  # Use execv instead of execve.\n                    executable = os.fsencode(executable)\n                    if os.path.dirname(executable):\n                        executable_list = (executable,)\n                    else:\n                        # This matches the behavior of os._execvpe().\n                        executable_list = tuple(\n                            os.path.join(os.fsencode(dir), executable)\n                            for dir in os.get_exec_path(env))\n                    fds_to_keep = set(pass_fds)\n                    fds_to_keep.add(errpipe_write)\n                    self.pid = _posixsubprocess.fork_exec(\n                            args, executable_list,\n                            close_fds, sorted(fds_to_keep), cwd, env_list,\n                            p2cread, p2cwrite, c2pread, c2pwrite,\n                            errread, errwrite,\n                            errpipe_read, errpipe_write,\n                            restore_signals, start_new_session, preexec_fn)\n                    self._child_created = True\n                finally:\n                    # be sure the FD is closed no matter what\n                    os.close(errpipe_write)\n\n                # self._devnull is not always defined.\n                devnull_fd = getattr(self, '_devnull', None)\n                if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:\n                    os.close(p2cread)\n                if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:\n                    os.close(c2pwrite)\n                if errwrite != -1 and errread != -1 and errwrite != devnull_fd:\n                    os.close(errwrite)\n                if devnull_fd is not None:\n                    os.close(devnull_fd)\n                # Prevent a double close of these fds from __init__ on error.\n                self._closed_child_pipe_fds = True\n\n                # Wait for exec to fail or succeed; possibly raising an\n                # exception (limited in size)\n                errpipe_data = bytearray()\n                while True:\n                    part = _eintr_retry_call(os.read, errpipe_read, 50000)\n                    errpipe_data += part\n                    if not part or len(errpipe_data) > 50000:\n                        break\n            finally:\n                # be sure the FD is closed no matter what\n                os.close(errpipe_read)\n\n            if errpipe_data:\n                try:\n                    _eintr_retry_call(os.waitpid, self.pid, 0)\n                except OSError as e:\n                    if e.errno != errno.ECHILD:\n                        raise\n                try:\n                    exception_name, hex_errno, err_msg = (\n                            errpipe_data.split(b':', 2))\n                except ValueError:\n                    exception_name = b'RuntimeError'\n                    hex_errno = b'0'\n                    err_msg = (b'Bad exception data from child: ' +\n                               repr(errpipe_data))\n                child_exception_type = getattr(\n                        builtins, exception_name.decode('ascii'),\n                        RuntimeError)\n                err_msg = err_msg.decode(errors=\"surrogatepass\")\n                if issubclass(child_exception_type, OSError) and hex_errno:\n                    errno_num = int(hex_errno, 16)\n                    child_exec_never_called = (err_msg == \"noexec\")\n                    if child_exec_never_called:\n                        err_msg = \"\"\n                    if errno_num != 0:\n                        err_msg = os.strerror(errno_num)\n                        if errno_num == errno.ENOENT:\n                            if child_exec_never_called:\n                                # The error must be from chdir(cwd).\n                                err_msg += ': ' + repr(cwd)\n                            else:\n                                err_msg += ': ' + repr(orig_executable)\n                    raise child_exception_type(errno_num, err_msg)\n                raise child_exception_type(err_msg)\n\n\n        def _handle_exitstatus(self, sts, _WIFSIGNALED=os.WIFSIGNALED,\n                _WTERMSIG=os.WTERMSIG, _WIFEXITED=os.WIFEXITED,\n                _WEXITSTATUS=os.WEXITSTATUS):\n            # This method is called (indirectly) by __del__, so it cannot\n            # refer to anything outside of its local scope.\"\"\"\n            if _WIFSIGNALED(sts):\n                self.returncode = -_WTERMSIG(sts)\n            elif _WIFEXITED(sts):\n                self.returncode = _WEXITSTATUS(sts)\n            else:\n                # Should never happen\n                raise RuntimeError(\"Unknown child exit status!\")\n\n\n        def _internal_poll(self, _deadstate=None, _waitpid=os.waitpid,\n                _WNOHANG=os.WNOHANG, _os_error=os.error, _ECHILD=errno.ECHILD):\n            \"\"\"Check if child process has terminated.  Returns returncode\n            attribute.\n\n            This method is called by __del__, so it cannot reference anything\n            outside of the local scope (nor can any methods it calls).\n\n            \"\"\"\n            if self.returncode is None:\n                try:\n                    pid, sts = _waitpid(self.pid, _WNOHANG)\n                    if pid == self.pid:\n                        self._handle_exitstatus(sts)\n                except _os_error as e:\n                    if _deadstate is not None:\n                        self.returncode = _deadstate\n                    elif e.errno == _ECHILD:\n                        # This happens if SIGCLD is set to be ignored or\n                        # waiting for child processes has otherwise been\n                        # disabled for our process.  This child is dead, we\n                        # can't get the status.\n                        # http://bugs.python.org/issue15756\n                        self.returncode = 0\n            return self.returncode\n\n\n        def _try_wait(self, wait_flags):\n            try:\n                (pid, sts) = _eintr_retry_call(os.waitpid, self.pid, wait_flags)\n            except OSError as e:\n                if e.errno != errno.ECHILD:\n                    raise\n                # This happens if SIGCLD is set to be ignored or waiting\n                # for child processes has otherwise been disabled for our\n                # process.  This child is dead, we can't get the status.\n                pid = self.pid\n                sts = 0\n            return (pid, sts)\n\n\n        def wait(self, timeout=None, endtime=None):\n            \"\"\"Wait for child process to terminate.  Returns returncode\n            attribute.\"\"\"\n            if self.returncode is not None:\n                return self.returncode\n\n            # endtime is preferred to timeout.  timeout is only used for\n            # printing.\n            if endtime is not None or timeout is not None:\n                if endtime is None:\n                    endtime = _time() + timeout\n                elif timeout is None:\n                    timeout = self._remaining_time(endtime)\n\n            if endtime is not None:\n                # Enter a busy loop if we have a timeout.  This busy loop was\n                # cribbed from Lib/threading.py in Thread.wait() at r71065.\n                delay = 0.0005 # 500 us -> initial delay of 1 ms\n                while True:\n                    (pid, sts) = self._try_wait(os.WNOHANG)\n                    assert pid == self.pid or pid == 0\n                    if pid == self.pid:\n                        self._handle_exitstatus(sts)\n                        break\n                    remaining = self._remaining_time(endtime)\n                    if remaining <= 0:\n                        raise TimeoutExpired(self.args, timeout)\n                    delay = min(delay * 2, remaining, .05)\n                    time.sleep(delay)\n            else:\n                while self.returncode is None:\n                    (pid, sts) = self._try_wait(0)\n                    # Check the pid and loop as waitpid has been known to return\n                    # 0 even without WNOHANG in odd situations.  issue14396.\n                    if pid == self.pid:\n                        self._handle_exitstatus(sts)\n            return self.returncode\n\n\n        def _communicate(self, input, endtime, orig_timeout):\n            if self.stdin and not self._communication_started:\n                # Flush stdio buffer.  This might block, if the user has\n                # been writing to .stdin in an uncontrolled fashion.\n                self.stdin.flush()\n                if not input:\n                    self.stdin.close()\n\n            if _has_poll:\n                stdout, stderr = self._communicate_with_poll(input, endtime,\n                                                             orig_timeout)\n            else:\n                stdout, stderr = self._communicate_with_select(input, endtime,\n                                                               orig_timeout)\n\n            self.wait(timeout=self._remaining_time(endtime))\n\n            # All data exchanged.  Translate lists into strings.\n            if stdout is not None:\n                stdout = b''.join(stdout)\n            if stderr is not None:\n                stderr = b''.join(stderr)\n\n            # Translate newlines, if requested.\n            # This also turns bytes into strings.\n            if self.universal_newlines:\n                if stdout is not None:\n                    stdout = self._translate_newlines(stdout,\n                                                      self.stdout.encoding)\n                if stderr is not None:\n                    stderr = self._translate_newlines(stderr,\n                                                      self.stderr.encoding)\n\n            return (stdout, stderr)\n\n\n        def _save_input(self, input):\n            # This method is called from the _communicate_with_*() methods\n            # so that if we time out while communicating, we can continue\n            # sending input if we retry.\n            if self.stdin and self._input is None:\n                self._input_offset = 0\n                self._input = input\n                if self.universal_newlines and input is not None:\n                    self._input = self._input.encode(self.stdin.encoding)\n\n\n        def _communicate_with_poll(self, input, endtime, orig_timeout):\n            stdout = None # Return\n            stderr = None # Return\n\n            if not self._communication_started:\n                self._fd2file = {}\n\n            poller = select.poll()\n            def register_and_append(file_obj, eventmask):\n                poller.register(file_obj.fileno(), eventmask)\n                self._fd2file[file_obj.fileno()] = file_obj\n\n            def close_unregister_and_remove(fd):\n                poller.unregister(fd)\n                self._fd2file[fd].close()\n                self._fd2file.pop(fd)\n\n            if self.stdin and input:\n                register_and_append(self.stdin, select.POLLOUT)\n\n            # Only create this mapping if we haven't already.\n            if not self._communication_started:\n                self._fd2output = {}\n                if self.stdout:\n                    self._fd2output[self.stdout.fileno()] = []\n                if self.stderr:\n                    self._fd2output[self.stderr.fileno()] = []\n\n            select_POLLIN_POLLPRI = select.POLLIN | select.POLLPRI\n            if self.stdout:\n                register_and_append(self.stdout, select_POLLIN_POLLPRI)\n                stdout = self._fd2output[self.stdout.fileno()]\n            if self.stderr:\n                register_and_append(self.stderr, select_POLLIN_POLLPRI)\n                stderr = self._fd2output[self.stderr.fileno()]\n\n            self._save_input(input)\n\n            while self._fd2file:\n                timeout = self._remaining_time(endtime)\n                if timeout is not None and timeout < 0:\n                    raise TimeoutExpired(self.args, orig_timeout)\n                try:\n                    ready = poller.poll(timeout)\n                except select.error as e:\n                    if e.args[0] == errno.EINTR:\n                        continue\n                    raise\n                self._check_timeout(endtime, orig_timeout)\n\n                # XXX Rewrite these to use non-blocking I/O on the\n                # file objects; they are no longer using C stdio!\n\n                for fd, mode in ready:\n                    if mode & select.POLLOUT:\n                        chunk = self._input[self._input_offset :\n                                            self._input_offset + _PIPE_BUF]\n                        try:\n                            self._input_offset += os.write(fd, chunk)\n                        except OSError as e:\n                            if e.errno == errno.EPIPE:\n                                close_unregister_and_remove(fd)\n                            else:\n                                raise\n                        else:\n                            if self._input_offset >= len(self._input):\n                                close_unregister_and_remove(fd)\n                    elif mode & select_POLLIN_POLLPRI:\n                        data = os.read(fd, 4096)\n                        if not data:\n                            close_unregister_and_remove(fd)\n                        self._fd2output[fd].append(data)\n                    else:\n                        # Ignore hang up or errors.\n                        close_unregister_and_remove(fd)\n\n            return (stdout, stderr)\n\n\n        def _communicate_with_select(self, input, endtime, orig_timeout):\n            if not self._communication_started:\n                self._read_set = []\n                self._write_set = []\n                if self.stdin and input:\n                    self._write_set.append(self.stdin)\n                if self.stdout:\n                    self._read_set.append(self.stdout)\n                if self.stderr:\n                    self._read_set.append(self.stderr)\n\n            self._save_input(input)\n\n            stdout = None # Return\n            stderr = None # Return\n\n            if self.stdout:\n                if not self._communication_started:\n                    self._stdout_buff = []\n                stdout = self._stdout_buff\n            if self.stderr:\n                if not self._communication_started:\n                    self._stderr_buff = []\n                stderr = self._stderr_buff\n\n            while self._read_set or self._write_set:\n                timeout = self._remaining_time(endtime)\n                if timeout is not None and timeout < 0:\n                    raise TimeoutExpired(self.args, orig_timeout)\n                try:\n                    (rlist, wlist, xlist) = \\\n                        select.select(self._read_set, self._write_set, [],\n                                      timeout)\n                except select.error as e:\n                    if e.args[0] == errno.EINTR:\n                        continue\n                    raise\n\n                # According to the docs, returning three empty lists indicates\n                # that the timeout expired.\n                if not (rlist or wlist or xlist):\n                    raise TimeoutExpired(self.args, orig_timeout)\n                # We also check what time it is ourselves for good measure.\n                self._check_timeout(endtime, orig_timeout)\n\n                # XXX Rewrite these to use non-blocking I/O on the\n                # file objects; they are no longer using C stdio!\n\n                if self.stdin in wlist:\n                    chunk = self._input[self._input_offset :\n                                        self._input_offset + _PIPE_BUF]\n                    try:\n                        bytes_written = os.write(self.stdin.fileno(), chunk)\n                    except OSError as e:\n                        if e.errno == errno.EPIPE:\n                            self.stdin.close()\n                            self._write_set.remove(self.stdin)\n                        else:\n                            raise\n                    else:\n                        self._input_offset += bytes_written\n                        if self._input_offset >= len(self._input):\n                            self.stdin.close()\n                            self._write_set.remove(self.stdin)\n\n                if self.stdout in rlist:\n                    data = os.read(self.stdout.fileno(), 1024)\n                    if not data:\n                        self.stdout.close()\n                        self._read_set.remove(self.stdout)\n                    stdout.append(data)\n\n                if self.stderr in rlist:\n                    data = os.read(self.stderr.fileno(), 1024)\n                    if not data:\n                        self.stderr.close()\n                        self._read_set.remove(self.stderr)\n                    stderr.append(data)\n\n            return (stdout, stderr)\n\n\n        def send_signal(self, sig):\n            \"\"\"Send a signal to the process\n            \"\"\"\n            os.kill(self.pid, sig)\n\n        def terminate(self):\n            \"\"\"Terminate the process with SIGTERM\n            \"\"\"\n            self.send_signal(signal.SIGTERM)\n\n        def kill(self):\n            \"\"\"Kill the process with SIGKILL\n            \"\"\"\n            self.send_signal(signal.SIGKILL)\n"], "urllib.parse": [".py", "\"\"\"Parse (absolute and relative) URLs.\n\nurlparse module is based upon the following RFC specifications.\n\nRFC 3986 (STD66): \"Uniform Resource Identifiers\" by T. Berners-Lee, R. Fielding\nand L.  Masinter, January 2005.\n\nRFC 2732 : \"Format for Literal IPv6 Addresses in URL's by R.Hinden, B.Carpenter\nand L.Masinter, December 1999.\n\nRFC 2396:  \"Uniform Resource Identifiers (URI)\": Generic Syntax by T.\nBerners-Lee, R. Fielding, and L. Masinter, August 1998.\n\nRFC 2368: \"The mailto URL scheme\", by P.Hoffman , L Masinter, J. Zawinski, July 1998.\n\nRFC 1808: \"Relative Uniform Resource Locators\", by R. Fielding, UC Irvine, June\n1995.\n\nRFC 1738: \"Uniform Resource Locators (URL)\" by T. Berners-Lee, L. Masinter, M.\nMcCahill, December 1994\n\nRFC 3986 is considered the current standard and any future changes to\nurlparse module should conform with it.  The urlparse module is\ncurrently not entirely compliant with this RFC due to defacto\nscenarios for parsing, and for backward compatibility purposes, some\nparsing quirks from older RFCs are retained. The testcases in\ntest_urlparse.py provides a good indicator of parsing behavior.\n\"\"\"\n\nimport re\nimport sys\nimport collections\n\n__all__ = [\"urlparse\", \"urlunparse\", \"urljoin\", \"urldefrag\",\n           \"urlsplit\", \"urlunsplit\", \"urlencode\", \"parse_qs\",\n           \"parse_qsl\", \"quote\", \"quote_plus\", \"quote_from_bytes\",\n           \"unquote\", \"unquote_plus\", \"unquote_to_bytes\"]\n\n# A classification of schemes ('' means apply by default)\nuses_relative = ['ftp', 'http', 'gopher', 'nntp', 'imap',\n                 'wais', 'file', 'https', 'shttp', 'mms',\n                 'prospero', 'rtsp', 'rtspu', '', 'sftp',\n                 'svn', 'svn+ssh']\nuses_netloc = ['ftp', 'http', 'gopher', 'nntp', 'telnet',\n               'imap', 'wais', 'file', 'mms', 'https', 'shttp',\n               'snews', 'prospero', 'rtsp', 'rtspu', 'rsync', '',\n               'svn', 'svn+ssh', 'sftp', 'nfs', 'git', 'git+ssh']\nuses_params = ['ftp', 'hdl', 'prospero', 'http', 'imap',\n               'https', 'shttp', 'rtsp', 'rtspu', 'sip', 'sips',\n               'mms', '', 'sftp', 'tel']\n\n# These are not actually used anymore, but should stay for backwards\n# compatibility.  (They are undocumented, but have a public-looking name.)\nnon_hierarchical = ['gopher', 'hdl', 'mailto', 'news',\n                    'telnet', 'wais', 'imap', 'snews', 'sip', 'sips']\nuses_query = ['http', 'wais', 'imap', 'https', 'shttp', 'mms',\n              'gopher', 'rtsp', 'rtspu', 'sip', 'sips', '']\nuses_fragment = ['ftp', 'hdl', 'http', 'gopher', 'news',\n                 'nntp', 'wais', 'https', 'shttp', 'snews',\n                 'file', 'prospero', '']\n\n# Characters valid in scheme names\nscheme_chars = ('abcdefghijklmnopqrstuvwxyz'\n                'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n                '0123456789'\n                '+-.')\n\n# XXX: Consider replacing with functools.lru_cache\nMAX_CACHE_SIZE = 20\n_parse_cache = {}\n\ndef clear_cache():\n    \"\"\"Clear the parse cache and the quoters cache.\"\"\"\n    _parse_cache.clear()\n    _safe_quoters.clear()\n\n\n# Helpers for bytes handling\n# For 3.2, we deliberately require applications that\n# handle improperly quoted URLs to do their own\n# decoding and encoding. If valid use cases are\n# presented, we may relax this by using latin-1\n# decoding internally for 3.3\n_implicit_encoding = 'ascii'\n_implicit_errors = 'strict'\n\ndef _noop(obj):\n    return obj\n\ndef _encode_result(obj, encoding=_implicit_encoding,\n                        errors=_implicit_errors):\n    return obj.encode(encoding, errors)\n\ndef _decode_args(args, encoding=_implicit_encoding,\n                       errors=_implicit_errors):\n    return tuple(x.decode(encoding, errors) if x else '' for x in args)\n\ndef _coerce_args(*args):\n    # Invokes decode if necessary to create str args\n    # and returns the coerced inputs along with\n    # an appropriate result coercion function\n    #   - noop for str inputs\n    #   - encoding function otherwise\n    str_input = isinstance(args[0], str)\n    for arg in args[1:]:\n        # We special-case the empty string to support the\n        # \"scheme=''\" default argument to some functions\n        if arg and isinstance(arg, str) != str_input:\n            raise TypeError(\"Cannot mix str and non-str arguments\")\n    if str_input:\n        return args + (_noop,)\n    return _decode_args(args) + (_encode_result,)\n\n# Result objects are more helpful than simple tuples\nclass _ResultMixinStr(object):\n    \"\"\"Standard approach to encoding parsed results from str to bytes\"\"\"\n    __slots__ = ()\n\n    def encode(self, encoding='ascii', errors='strict'):\n        return self._encoded_counterpart(*(x.encode(encoding, errors) for x in self))\n\n\nclass _ResultMixinBytes(object):\n    \"\"\"Standard approach to decoding parsed results from bytes to str\"\"\"\n    __slots__ = ()\n\n    def decode(self, encoding='ascii', errors='strict'):\n        return self._decoded_counterpart(*(x.decode(encoding, errors) for x in self))\n\n\nclass _NetlocResultMixinBase(object):\n    \"\"\"Shared methods for the parsed result objects containing a netloc element\"\"\"\n    __slots__ = ()\n\n    @property\n    def username(self):\n        return self._userinfo[0]\n\n    @property\n    def password(self):\n        return self._userinfo[1]\n\n    @property\n    def hostname(self):\n        hostname = self._hostinfo[0]\n        if not hostname:\n            hostname = None\n        elif hostname is not None:\n            hostname = hostname.lower()\n        return hostname\n\n    @property\n    def port(self):\n        port = self._hostinfo[1]\n        if port is not None:\n            port = int(port, 10)\n            # Return None on an illegal port\n            if not ( 0 <= port <= 65535):\n                return None\n        return port\n\n\nclass _NetlocResultMixinStr(_NetlocResultMixinBase, _ResultMixinStr):\n    __slots__ = ()\n\n    @property\n    def _userinfo(self):\n        netloc = self.netloc\n        userinfo, have_info, hostinfo = netloc.rpartition('@')\n        if have_info:\n            username, have_password, password = userinfo.partition(':')\n            if not have_password:\n                password = None\n        else:\n            username = password = None\n        return username, password\n\n    @property\n    def _hostinfo(self):\n        netloc = self.netloc\n        _, _, hostinfo = netloc.rpartition('@')\n        _, have_open_br, bracketed = hostinfo.partition('[')\n        if have_open_br:\n            hostname, _, port = bracketed.partition(']')\n            _, have_port, port = port.partition(':')\n        else:\n            hostname, have_port, port = hostinfo.partition(':')\n        if not have_port:\n            port = None\n        return hostname, port\n\n\nclass _NetlocResultMixinBytes(_NetlocResultMixinBase, _ResultMixinBytes):\n    __slots__ = ()\n\n    @property\n    def _userinfo(self):\n        netloc = self.netloc\n        userinfo, have_info, hostinfo = netloc.rpartition(b'@')\n        if have_info:\n            username, have_password, password = userinfo.partition(b':')\n            if not have_password:\n                password = None\n        else:\n            username = password = None\n        return username, password\n\n    @property\n    def _hostinfo(self):\n        netloc = self.netloc\n        _, _, hostinfo = netloc.rpartition(b'@')\n        _, have_open_br, bracketed = hostinfo.partition(b'[')\n        if have_open_br:\n            hostname, _, port = bracketed.partition(b']')\n            _, have_port, port = port.partition(b':')\n        else:\n            hostname, have_port, port = hostinfo.partition(b':')\n        if not have_port:\n            port = None\n        return hostname, port\n\n\nfrom collections import namedtuple\n\n_DefragResultBase = namedtuple('DefragResult', 'url fragment')\n_SplitResultBase = namedtuple('SplitResult', 'scheme netloc path query fragment')\n_ParseResultBase = namedtuple('ParseResult', 'scheme netloc path params query fragment')\n\n# For backwards compatibility, alias _NetlocResultMixinStr\n# ResultBase is no longer part of the documented API, but it is\n# retained since deprecating it isn't worth the hassle\nResultBase = _NetlocResultMixinStr\n\n# Structured result objects for string data\nclass DefragResult(_DefragResultBase, _ResultMixinStr):\n    __slots__ = ()\n    def geturl(self):\n        if self.fragment:\n            return self.url + '#' + self.fragment\n        else:\n            return self.url\n\nclass SplitResult(_SplitResultBase, _NetlocResultMixinStr):\n    __slots__ = ()\n    def geturl(self):\n        return urlunsplit(self)\n\nclass ParseResult(_ParseResultBase, _NetlocResultMixinStr):\n    __slots__ = ()\n    def geturl(self):\n        return urlunparse(self)\n\n# Structured result objects for bytes data\nclass DefragResultBytes(_DefragResultBase, _ResultMixinBytes):\n    __slots__ = ()\n    def geturl(self):\n        if self.fragment:\n            return self.url + b'#' + self.fragment\n        else:\n            return self.url\n\nclass SplitResultBytes(_SplitResultBase, _NetlocResultMixinBytes):\n    __slots__ = ()\n    def geturl(self):\n        return urlunsplit(self)\n\nclass ParseResultBytes(_ParseResultBase, _NetlocResultMixinBytes):\n    __slots__ = ()\n    def geturl(self):\n        return urlunparse(self)\n\n# Set up the encode/decode result pairs\ndef _fix_result_transcoding():\n    _result_pairs = (\n        (DefragResult, DefragResultBytes),\n        (SplitResult, SplitResultBytes),\n        (ParseResult, ParseResultBytes),\n    )\n    for _decoded, _encoded in _result_pairs:\n        _decoded._encoded_counterpart = _encoded\n        _encoded._decoded_counterpart = _decoded\n\n_fix_result_transcoding()\ndel _fix_result_transcoding\n\ndef urlparse(url, scheme='', allow_fragments=True):\n    \"\"\"Parse a URL into 6 components:\n    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\n    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    splitresult = urlsplit(url, scheme, allow_fragments)\n    scheme, netloc, url, query, fragment = splitresult\n    if scheme in uses_params and ';' in url:\n        url, params = _splitparams(url)\n    else:\n        params = ''\n    result = ParseResult(scheme, netloc, url, params, query, fragment)\n    return _coerce_result(result)\n\ndef _splitparams(url):\n    if '/'  in url:\n        i = url.find(';', url.rfind('/'))\n        if i < 0:\n            return url, ''\n    else:\n        i = url.find(';')\n    return url[:i], url[i+1:]\n\ndef _splitnetloc(url, start=0):\n    delim = len(url)   # position of end of domain part of url, default is end\n    for c in '/?#':    # look for delimiters; the order is NOT important\n        wdelim = url.find(c, start)        # find first of this delim\n        if wdelim >= 0:                    # if found\n            delim = min(delim, wdelim)     # use earliest delim position\n    return url[start:delim], url[delim:]   # return (domain, rest)\n\ndef urlsplit(url, scheme='', allow_fragments=True):\n    \"\"\"Parse a URL into 5 components:\n    <scheme>://<netloc>/<path>?<query>#<fragment>\n    Return a 5-tuple: (scheme, netloc, path, query, fragment).\n    Note that we don't break the components up in smaller bits\n    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    allow_fragments = bool(allow_fragments)\n    key = url, scheme, allow_fragments, type(url), type(scheme)\n    cached = _parse_cache.get(key, None)\n    if cached:\n        return _coerce_result(cached)\n    if len(_parse_cache) >= MAX_CACHE_SIZE: # avoid runaway growth\n        clear_cache()\n    netloc = query = fragment = ''\n    i = url.find(':')\n    if i > 0:\n        if url[:i] == 'http': # optimize the common case\n            scheme = url[:i].lower()\n            url = url[i+1:]\n            if url[:2] == '//':\n                netloc, url = _splitnetloc(url, 2)\n                if (('[' in netloc and ']' not in netloc) or\n                        (']' in netloc and '[' not in netloc)):\n                    raise ValueError(\"Invalid IPv6 URL\")\n            if allow_fragments and '#' in url:\n                url, fragment = url.split('#', 1)\n            if '?' in url:\n                url, query = url.split('?', 1)\n            v = SplitResult(scheme, netloc, url, query, fragment)\n            _parse_cache[key] = v\n            return _coerce_result(v)\n        for c in url[:i]:\n            if c not in scheme_chars:\n                break\n        else:\n            # make sure \"url\" is not actually a port number (in which case\n            # \"scheme\" is really part of the path)\n            rest = url[i+1:]\n            if not rest or any(c not in '0123456789' for c in rest):\n                # not a port number\n                scheme, url = url[:i].lower(), rest\n\n    if url[:2] == '//':\n        netloc, url = _splitnetloc(url, 2)\n        if (('[' in netloc and ']' not in netloc) or\n                (']' in netloc and '[' not in netloc)):\n            raise ValueError(\"Invalid IPv6 URL\")\n    if allow_fragments and '#' in url:\n        url, fragment = url.split('#', 1)\n    if '?' in url:\n        url, query = url.split('?', 1)\n    v = SplitResult(scheme, netloc, url, query, fragment)\n    _parse_cache[key] = v\n    return _coerce_result(v)\n\ndef urlunparse(components):\n    \"\"\"Put a parsed URL back together again.  This may result in a\n    slightly different, but equivalent URL, if the URL that was parsed\n    originally had redundant delimiters, e.g. a ? with an empty query\n    (the draft states that these are equivalent).\"\"\"\n    scheme, netloc, url, params, query, fragment, _coerce_result = (\n                                                  _coerce_args(*components))\n    if params:\n        url = \"%s;%s\" % (url, params)\n    return _coerce_result(urlunsplit((scheme, netloc, url, query, fragment)))\n\ndef urlunsplit(components):\n    \"\"\"Combine the elements of a tuple as returned by urlsplit() into a\n    complete URL as a string. The data argument can be any five-item iterable.\n    This may result in a slightly different, but equivalent URL, if the URL that\n    was parsed originally had unnecessary delimiters (for example, a ? with an\n    empty query; the RFC states that these are equivalent).\"\"\"\n    scheme, netloc, url, query, fragment, _coerce_result = (\n                                          _coerce_args(*components))\n    if netloc or (scheme and scheme in uses_netloc and url[:2] != '//'):\n        if url and url[:1] != '/': url = '/' + url\n        url = '//' + (netloc or '') + url\n    if scheme:\n        url = scheme + ':' + url\n    if query:\n        url = url + '?' + query\n    if fragment:\n        url = url + '#' + fragment\n    return _coerce_result(url)\n\ndef urljoin(base, url, allow_fragments=True):\n    \"\"\"Join a base URL and a possibly relative URL to form an absolute\n    interpretation of the latter.\"\"\"\n    if not base:\n        return url\n    if not url:\n        return base\n    base, url, _coerce_result = _coerce_args(base, url)\n    bscheme, bnetloc, bpath, bparams, bquery, bfragment = \\\n            urlparse(base, '', allow_fragments)\n    scheme, netloc, path, params, query, fragment = \\\n            urlparse(url, bscheme, allow_fragments)\n    if scheme != bscheme or scheme not in uses_relative:\n        return _coerce_result(url)\n    if scheme in uses_netloc:\n        if netloc:\n            return _coerce_result(urlunparse((scheme, netloc, path,\n                                              params, query, fragment)))\n        netloc = bnetloc\n    if path[:1] == '/':\n        return _coerce_result(urlunparse((scheme, netloc, path,\n                                          params, query, fragment)))\n    if not path and not params:\n        path = bpath\n        params = bparams\n        if not query:\n            query = bquery\n        return _coerce_result(urlunparse((scheme, netloc, path,\n                                          params, query, fragment)))\n    segments = bpath.split('/')[:-1] + path.split('/')\n    # XXX The stuff below is bogus in various ways...\n    if segments[-1] == '.':\n        segments[-1] = ''\n    while '.' in segments:\n        segments.remove('.')\n    while 1:\n        i = 1\n        n = len(segments) - 1\n        while i < n:\n            if (segments[i] == '..'\n                and segments[i-1] not in ('', '..')):\n                del segments[i-1:i+1]\n                break\n            i = i+1\n        else:\n            break\n    if segments == ['', '..']:\n        segments[-1] = ''\n    elif len(segments) >= 2 and segments[-1] == '..':\n        segments[-2:] = ['']\n    return _coerce_result(urlunparse((scheme, netloc, '/'.join(segments),\n                                      params, query, fragment)))\n\ndef urldefrag(url):\n    \"\"\"Removes any existing fragment from URL.\n\n    Returns a tuple of the defragmented URL and the fragment.  If\n    the URL contained no fragments, the second element is the\n    empty string.\n    \"\"\"\n    url, _coerce_result = _coerce_args(url)\n    if '#' in url:\n        s, n, p, a, q, frag = urlparse(url)\n        defrag = urlunparse((s, n, p, a, q, ''))\n    else:\n        frag = ''\n        defrag = url\n    return _coerce_result(DefragResult(defrag, frag))\n\n_hexdig = '0123456789ABCDEFabcdef'\n_hextobyte = {(a + b).encode(): bytes([int(a + b, 16)])\n              for a in _hexdig for b in _hexdig}\n\ndef unquote_to_bytes(string):\n    \"\"\"unquote_to_bytes('abc%20def') -> b'abc def'.\"\"\"\n    # Note: strings are encoded as UTF-8. This is only an issue if it contains\n    # unescaped non-ASCII characters, which URIs should not.\n    if not string:\n        # Is it a string-like object?\n        string.split\n        return b''\n    if isinstance(string, str):\n        string = string.encode('utf-8')\n    bits = string.split(b'%')\n    if len(bits) == 1:\n        return string\n    res = [bits[0]]\n    append = res.append\n    for item in bits[1:]:\n        try:\n            append(_hextobyte[item[:2]])\n            append(item[2:])\n        except KeyError:\n            append(b'%')\n            append(item)\n    return b''.join(res)\n\n_asciire = re.compile('([\\x00-\\x7f]+)')\n\ndef unquote(string, encoding='utf-8', errors='replace'):\n    \"\"\"Replace %xx escapes by their single-character equivalent. The optional\n    encoding and errors parameters specify how to decode percent-encoded\n    sequences into Unicode characters, as accepted by the bytes.decode()\n    method.\n    By default, percent-encoded sequences are decoded with UTF-8, and invalid\n    sequences are replaced by a placeholder character.\n\n    unquote('abc%20def') -> 'abc def'.\n    \"\"\"\n    if '%' not in string:\n        string.split\n        return string\n    if encoding is None:\n        encoding = 'utf-8'\n    if errors is None:\n        errors = 'replace'\n    bits = _asciire.split(string)\n    res = [bits[0]]\n    append = res.append\n    for i in range(1, len(bits), 2):\n        append(unquote_to_bytes(bits[i]).decode(encoding, errors))\n        append(bits[i + 1])\n    return ''.join(res)\n\ndef parse_qs(qs, keep_blank_values=False, strict_parsing=False,\n             encoding='utf-8', errors='replace'):\n    \"\"\"Parse a query given as a string argument.\n\n        Arguments:\n\n        qs: percent-encoded query string to be parsed\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded queries should be treated as blank strings.\n            A true value indicates that blanks should be retained as\n            blank strings.  The default false value indicates that\n            blank values are to be ignored and treated as if they were\n            not included.\n\n        strict_parsing: flag indicating what to do with parsing errors.\n            If false (the default), errors are silently ignored.\n            If true, errors raise a ValueError exception.\n\n        encoding and errors: specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the bytes.decode() method.\n    \"\"\"\n    parsed_result = {}\n    pairs = parse_qsl(qs, keep_blank_values, strict_parsing,\n                      encoding=encoding, errors=errors)\n    for name, value in pairs:\n        if name in parsed_result:\n            parsed_result[name].append(value)\n        else:\n            parsed_result[name] = [value]\n    return parsed_result\n\ndef parse_qsl(qs, keep_blank_values=False, strict_parsing=False,\n              encoding='utf-8', errors='replace'):\n    \"\"\"Parse a query given as a string argument.\n\n    Arguments:\n\n    qs: percent-encoded query string to be parsed\n\n    keep_blank_values: flag indicating whether blank values in\n        percent-encoded queries should be treated as blank strings.  A\n        true value indicates that blanks should be retained as blank\n        strings.  The default false value indicates that blank values\n        are to be ignored and treated as if they were  not included.\n\n    strict_parsing: flag indicating what to do with parsing errors. If\n        false (the default), errors are silently ignored. If true,\n        errors raise a ValueError exception.\n\n    encoding and errors: specify how to decode percent-encoded sequences\n        into Unicode characters, as accepted by the bytes.decode() method.\n\n    Returns a list, as G-d intended.\n    \"\"\"\n    qs, _coerce_result = _coerce_args(qs)\n    pairs = [s2 for s1 in qs.split('&') for s2 in s1.split(';')]\n    r = []\n    for name_value in pairs:\n        if not name_value and not strict_parsing:\n            continue\n        nv = name_value.split('=', 1)\n        if len(nv) != 2:\n            if strict_parsing:\n                raise ValueError(\"bad query field: %r\" % (name_value,))\n            # Handle case of a control-name with no equal sign\n            if keep_blank_values:\n                nv.append('')\n            else:\n                continue\n        if len(nv[1]) or keep_blank_values:\n            name = nv[0].replace('+', ' ')\n            name = unquote(name, encoding=encoding, errors=errors)\n            name = _coerce_result(name)\n            value = nv[1].replace('+', ' ')\n            value = unquote(value, encoding=encoding, errors=errors)\n            value = _coerce_result(value)\n            r.append((name, value))\n    return r\n\ndef unquote_plus(string, encoding='utf-8', errors='replace'):\n    \"\"\"Like unquote(), but also replace plus signs by spaces, as required for\n    unquoting HTML form values.\n\n    unquote_plus('%7e/abc+def') -> '~/abc def'\n    \"\"\"\n    string = string.replace('+', ' ')\n    return unquote(string, encoding, errors)\n\n_ALWAYS_SAFE = frozenset(b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n                         b'abcdefghijklmnopqrstuvwxyz'\n                         b'0123456789'\n                         b'_.-')\n_ALWAYS_SAFE_BYTES = bytes(_ALWAYS_SAFE)\n_safe_quoters = {}\n\nclass Quoter(collections.defaultdict):\n    \"\"\"A mapping from bytes (in range(0,256)) to strings.\n\n    String values are percent-encoded byte values, unless the key < 128, and\n    in the \"safe\" set (either the specified safe set, or default set).\n    \"\"\"\n    # Keeps a cache internally, using defaultdict, for efficiency (lookups\n    # of cached keys don't call Python code at all).\n    def __init__(self, safe):\n        \"\"\"safe: bytes object.\"\"\"\n        self.safe = _ALWAYS_SAFE.union(safe)\n\n    def __repr__(self):\n        # Without this, will just display as a defaultdict\n        return \"<Quoter %r>\" % dict(self)\n\n    def __missing__(self, b):\n        # Handle a cache miss. Store quoted string in cache and return.\n        res = chr(b) if b in self.safe else '%{:02X}'.format(b)\n        self[b] = res\n        return res\n\ndef quote(string, safe='/', encoding=None, errors=None):\n    \"\"\"quote('abc def') -> 'abc%20def'\n\n    Each part of a URL, e.g. the path info, the query, etc., has a\n    different set of reserved characters that must be quoted.\n\n    RFC 2396 Uniform Resource Identifiers (URI): Generic Syntax lists\n    the following reserved characters.\n\n    reserved    = \";\" | \"/\" | \"?\" | \":\" | \"@\" | \"&\" | \"=\" | \"+\" |\n                  \"$\" | \",\"\n\n    Each of these characters is reserved in some component of a URL,\n    but not necessarily in all of them.\n\n    By default, the quote function is intended for quoting the path\n    section of a URL.  Thus, it will not encode '/'.  This character\n    is reserved, but in typical usage the quote function is being\n    called on a path where the existing slash characters are used as\n    reserved characters.\n\n    string and safe may be either str or bytes objects. encoding must\n    not be specified if string is a str.\n\n    The optional encoding and errors parameters specify how to deal with\n    non-ASCII characters, as accepted by the str.encode method.\n    By default, encoding='utf-8' (characters are encoded with UTF-8), and\n    errors='strict' (unsupported characters raise a UnicodeEncodeError).\n    \"\"\"\n    if isinstance(string, str):\n        if not string:\n            return string\n        if encoding is None:\n            encoding = 'utf-8'\n        if errors is None:\n            errors = 'strict'\n        string = string.encode(encoding, errors)\n    else:\n        if encoding is not None:\n            raise TypeError(\"quote() doesn't support 'encoding' for bytes\")\n        if errors is not None:\n            raise TypeError(\"quote() doesn't support 'errors' for bytes\")\n    return quote_from_bytes(string, safe)\n\ndef quote_plus(string, safe='', encoding=None, errors=None):\n    \"\"\"Like quote(), but also replace ' ' with '+', as required for quoting\n    HTML form values. Plus signs in the original string are escaped unless\n    they are included in safe. It also does not have safe default to '/'.\n    \"\"\"\n    # Check if ' ' in string, where string may either be a str or bytes.  If\n    # there are no spaces, the regular quote will produce the right answer.\n    if ((isinstance(string, str) and ' ' not in string) or\n        (isinstance(string, bytes) and b' ' not in string)):\n        return quote(string, safe, encoding, errors)\n    if isinstance(safe, str):\n        space = ' '\n    else:\n        space = b' '\n    string = quote(string, safe + space, encoding, errors)\n    return string.replace(' ', '+')\n\ndef quote_from_bytes(bs, safe='/'):\n    \"\"\"Like quote(), but accepts a bytes object rather than a str, and does\n    not perform string-to-bytes encoding.  It always returns an ASCII string.\n    quote_from_bytes(b'abc def\\x3f') -> 'abc%20def%3f'\n    \"\"\"\n    if not isinstance(bs, (bytes, bytearray)):\n        raise TypeError(\"quote_from_bytes() expected bytes\")\n    if not bs:\n        return ''\n    if isinstance(safe, str):\n        # Normalize 'safe' by converting to bytes and removing non-ASCII chars\n        safe = safe.encode('ascii', 'ignore')\n    else:\n        safe = bytes([c for c in safe if c < 128])\n    if not bs.rstrip(_ALWAYS_SAFE_BYTES + safe):\n        return bs.decode()\n    try:\n        quoter = _safe_quoters[safe]\n    except KeyError:\n        _safe_quoters[safe] = quoter = Quoter(safe).__getitem__\n    return ''.join([quoter(char) for char in bs])\n\ndef urlencode(query, doseq=False, safe='', encoding=None, errors=None):\n    \"\"\"Encode a sequence of two-element tuples or dictionary into a URL query string.\n\n    If any values in the query arg are sequences and doseq is true, each\n    sequence element is converted to a separate parameter.\n\n    If the query arg is a sequence of two-element tuples, the order of the\n    parameters in the output will match the order of parameters in the\n    input.\n\n    The query arg may be either a string or a bytes type. When query arg is a\n    string, the safe, encoding and error parameters are sent the quote_plus for\n    encoding.\n    \"\"\"\n\n    if hasattr(query, \"items\"):\n        query = query.items()\n    else:\n        # It's a bother at times that strings and string-like objects are\n        # sequences.\n        try:\n            # non-sequence items should not work with len()\n            # non-empty strings will fail this\n            if len(query) and not isinstance(query[0], tuple):\n                raise TypeError\n            # Zero-length sequences of all types will get here and succeed,\n            # but that's a minor nit.  Since the original implementation\n            # allowed empty dicts that type of behavior probably should be\n            # preserved for consistency\n        except TypeError:\n            ty, va, tb = sys.exc_info()\n            raise TypeError(\"not a valid non-string sequence \"\n                            \"or mapping object\").with_traceback(tb)\n\n    l = []\n    if not doseq:\n        for k, v in query:\n            if isinstance(k, bytes):\n                k = quote_plus(k, safe)\n            else:\n                k = quote_plus(str(k), safe, encoding, errors)\n\n            if isinstance(v, bytes):\n                v = quote_plus(v, safe)\n            else:\n                v = quote_plus(str(v), safe, encoding, errors)\n            l.append(k + '=' + v)\n    else:\n        for k, v in query:\n            if isinstance(k, bytes):\n                k = quote_plus(k, safe)\n            else:\n                k = quote_plus(str(k), safe, encoding, errors)\n\n            if isinstance(v, bytes):\n                v = quote_plus(v, safe)\n                l.append(k + '=' + v)\n            elif isinstance(v, str):\n                v = quote_plus(v, safe, encoding, errors)\n                l.append(k + '=' + v)\n            else:\n                try:\n                    # Is this a sufficient test for sequence-ness?\n                    x = len(v)\n                except TypeError:\n                    # not a sequence\n                    v = quote_plus(str(v), safe, encoding, errors)\n                    l.append(k + '=' + v)\n                else:\n                    # loop over the sequence\n                    for elt in v:\n                        if isinstance(elt, bytes):\n                            elt = quote_plus(elt, safe)\n                        else:\n                            elt = quote_plus(str(elt), safe, encoding, errors)\n                        l.append(k + '=' + elt)\n    return '&'.join(l)\n\n# Utilities to parse URLs (most of these return None for missing parts):\n# unwrap('<URL:type://host/path>') --> 'type://host/path'\n# splittype('type:opaquestring') --> 'type', 'opaquestring'\n# splithost('//host[:port]/path') --> 'host[:port]', '/path'\n# splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'\n# splitpasswd('user:passwd') -> 'user', 'passwd'\n# splitport('host:port') --> 'host', 'port'\n# splitquery('/path?query') --> '/path', 'query'\n# splittag('/path#tag') --> '/path', 'tag'\n# splitattr('/path;attr1=value1;attr2=value2;...') ->\n#   '/path', ['attr1=value1', 'attr2=value2', ...]\n# splitvalue('attr=value') --> 'attr', 'value'\n# urllib.parse.unquote('abc%20def') -> 'abc def'\n# quote('abc def') -> 'abc%20def')\n\ndef to_bytes(url):\n    \"\"\"to_bytes(u\"URL\") --> 'URL'.\"\"\"\n    # Most URL schemes require ASCII. If that changes, the conversion\n    # can be relaxed.\n    # XXX get rid of to_bytes()\n    if isinstance(url, str):\n        try:\n            url = url.encode(\"ASCII\").decode()\n        except UnicodeError:\n            raise UnicodeError(\"URL \" + repr(url) +\n                               \" contains non-ASCII characters\")\n    return url\n\ndef unwrap(url):\n    \"\"\"unwrap('<URL:type://host/path>') --> 'type://host/path'.\"\"\"\n    url = str(url).strip()\n    if url[:1] == '<' and url[-1:] == '>':\n        url = url[1:-1].strip()\n    if url[:4] == 'URL:': url = url[4:].strip()\n    return url\n\n_typeprog = None\ndef splittype(url):\n    \"\"\"splittype('type:opaquestring') --> 'type', 'opaquestring'.\"\"\"\n    global _typeprog\n    if _typeprog is None:\n        import re\n        _typeprog = re.compile('^([^/:]+):')\n\n    match = _typeprog.match(url)\n    if match:\n        scheme = match.group(1)\n        return scheme.lower(), url[len(scheme) + 1:]\n    return None, url\n\n_hostprog = None\ndef splithost(url):\n    \"\"\"splithost('//host[:port]/path') --> 'host[:port]', '/path'.\"\"\"\n    global _hostprog\n    if _hostprog is None:\n        import re\n        _hostprog = re.compile('^//([^/?]*)(.*)$')\n\n    match = _hostprog.match(url)\n    if match:\n        host_port = match.group(1)\n        path = match.group(2)\n        if path and not path.startswith('/'):\n            path = '/' + path\n        return host_port, path\n    return None, url\n\n_userprog = None\ndef splituser(host):\n    \"\"\"splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'.\"\"\"\n    global _userprog\n    if _userprog is None:\n        import re\n        _userprog = re.compile('^(.*)@(.*)$')\n\n    match = _userprog.match(host)\n    if match: return match.group(1, 2)\n    return None, host\n\n_passwdprog = None\ndef splitpasswd(user):\n    \"\"\"splitpasswd('user:passwd') -> 'user', 'passwd'.\"\"\"\n    global _passwdprog\n    if _passwdprog is None:\n        import re\n        _passwdprog = re.compile('^([^:]*):(.*)$',re.S)\n\n    match = _passwdprog.match(user)\n    if match: return match.group(1, 2)\n    return user, None\n\n# splittag('/path#tag') --> '/path', 'tag'\n_portprog = None\ndef splitport(host):\n    \"\"\"splitport('host:port') --> 'host', 'port'.\"\"\"\n    global _portprog\n    if _portprog is None:\n        import re\n        _portprog = re.compile('^(.*):([0-9]+)$')\n\n    match = _portprog.match(host)\n    if match: return match.group(1, 2)\n    return host, None\n\n_nportprog = None\ndef splitnport(host, defport=-1):\n    \"\"\"Split host and port, returning numeric port.\n    Return given default port if no ':' found; defaults to -1.\n    Return numerical port if a valid number are found after ':'.\n    Return None if ':' but not a valid number.\"\"\"\n    global _nportprog\n    if _nportprog is None:\n        import re\n        _nportprog = re.compile('^(.*):(.*)$')\n\n    match = _nportprog.match(host)\n    if match:\n        host, port = match.group(1, 2)\n        try:\n            if not port: raise ValueError(\"no digits\")\n            nport = int(port)\n        except ValueError:\n            nport = None\n        return host, nport\n    return host, defport\n\n_queryprog = None\ndef splitquery(url):\n    \"\"\"splitquery('/path?query') --> '/path', 'query'.\"\"\"\n    global _queryprog\n    if _queryprog is None:\n        import re\n        _queryprog = re.compile('^(.*)\\?([^?]*)$')\n\n    match = _queryprog.match(url)\n    if match: return match.group(1, 2)\n    return url, None\n\n_tagprog = None\ndef splittag(url):\n    \"\"\"splittag('/path#tag') --> '/path', 'tag'.\"\"\"\n    global _tagprog\n    if _tagprog is None:\n        import re\n        _tagprog = re.compile('^(.*)#([^#]*)$')\n\n    match = _tagprog.match(url)\n    if match: return match.group(1, 2)\n    return url, None\n\ndef splitattr(url):\n    \"\"\"splitattr('/path;attr1=value1;attr2=value2;...') ->\n        '/path', ['attr1=value1', 'attr2=value2', ...].\"\"\"\n    words = url.split(';')\n    return words[0], words[1:]\n\n_valueprog = None\ndef splitvalue(attr):\n    \"\"\"splitvalue('attr=value') --> 'attr', 'value'.\"\"\"\n    global _valueprog\n    if _valueprog is None:\n        import re\n        _valueprog = re.compile('^([^=]*)=(.*)$')\n\n    match = _valueprog.match(attr)\n    if match: return match.group(1, 2)\n    return attr, None\n"], "unittest.mock": [".py", "# mock.py\n# Test tools for mocking and patching.\n# Maintained by Michael Foord\n# Backport for other versions of Python available from\n# http://pypi.python.org/pypi/mock\n\n__all__ = (\n    'Mock',\n    'MagicMock',\n    'patch',\n    'sentinel',\n    'DEFAULT',\n    'ANY',\n    'call',\n    'create_autospec',\n    'FILTER_DIR',\n    'NonCallableMock',\n    'NonCallableMagicMock',\n    'mock_open',\n    'PropertyMock',\n)\n\n\n__version__ = '1.0'\n\n\nimport inspect\nimport pprint\nimport sys\nfrom functools import wraps\n\n\nBaseExceptions = (BaseException,)\nif 'java' in sys.platform:\n    # jython\n    import java\n    BaseExceptions = (BaseException, java.lang.Throwable)\n\n\nFILTER_DIR = True\n\n# Workaround for issue #12370\n# Without this, the __class__ properties wouldn't be set correctly\n_safe_super = super\n\ndef _is_instance_mock(obj):\n    # can't use isinstance on Mock objects because they override __class__\n    # The base class for all mocks is NonCallableMock\n    return issubclass(type(obj), NonCallableMock)\n\n\ndef _is_exception(obj):\n    return (\n        isinstance(obj, BaseExceptions) or\n        isinstance(obj, type) and issubclass(obj, BaseExceptions)\n    )\n\n\nclass _slotted(object):\n    __slots__ = ['a']\n\n\nDescriptorTypes = (\n    type(_slotted.a),\n    property,\n)\n\n\ndef _getsignature(func, skipfirst, instance=False):\n    if isinstance(func, type) and not instance:\n        try:\n            func = func.__init__\n        except AttributeError:\n            return\n        skipfirst = True\n    elif not isinstance(func, FunctionTypes):\n        # for classes where instance is True we end up here too\n        try:\n            func = func.__call__\n        except AttributeError:\n            return\n\n    try:\n        argspec = inspect.getfullargspec(func)\n    except TypeError:\n        # C function / method, possibly inherited object().__init__\n        return\n\n    regargs, varargs, varkw, defaults, kwonly, kwonlydef, ann = argspec\n\n\n    # instance methods and classmethods need to lose the self argument\n    if getattr(func, '__self__', None) is not None:\n        regargs = regargs[1:]\n    if skipfirst:\n        # this condition and the above one are never both True - why?\n        regargs = regargs[1:]\n\n    signature = inspect.formatargspec(\n        regargs, varargs, varkw, defaults,\n        kwonly, kwonlydef, ann, formatvalue=lambda value: \"\")\n    return signature[1:-1], func\n\n\ndef _check_signature(func, mock, skipfirst, instance=False):\n    if not _callable(func):\n        return\n\n    result = _getsignature(func, skipfirst, instance)\n    if result is None:\n        return\n    signature, func = result\n\n    # can't use self because \"self\" is common as an argument name\n    # unfortunately even not in the first place\n    src = \"lambda _mock_self, %s: None\" % signature\n    checksig = eval(src, {})\n    _copy_func_details(func, checksig)\n    type(mock)._mock_check_sig = checksig\n\n\ndef _copy_func_details(func, funcopy):\n    funcopy.__name__ = func.__name__\n    funcopy.__doc__ = func.__doc__\n    # we explicitly don't copy func.__dict__ into this copy as it would\n    # expose original attributes that should be mocked\n    funcopy.__module__ = func.__module__\n    funcopy.__defaults__ = func.__defaults__\n    funcopy.__kwdefaults__ = func.__kwdefaults__\n\n\ndef _callable(obj):\n    if isinstance(obj, type):\n        return True\n    if getattr(obj, '__call__', None) is not None:\n        return True\n    return False\n\n\ndef _is_list(obj):\n    # checks for list or tuples\n    # XXXX badly named!\n    return type(obj) in (list, tuple)\n\n\ndef _instance_callable(obj):\n    \"\"\"Given an object, return True if the object is callable.\n    For classes, return True if instances would be callable.\"\"\"\n    if not isinstance(obj, type):\n        # already an instance\n        return getattr(obj, '__call__', None) is not None\n\n    # *could* be broken by a class overriding __mro__ or __dict__ via\n    # a metaclass\n    for base in (obj,) + obj.__mro__:\n        if base.__dict__.get('__call__') is not None:\n            return True\n    return False\n\n\ndef _set_signature(mock, original, instance=False):\n    # creates a function with signature (*args, **kwargs) that delegates to a\n    # mock. It still does signature checking by calling a lambda with the same\n    # signature as the original.\n    if not _callable(original):\n        return\n\n    skipfirst = isinstance(original, type)\n    result = _getsignature(original, skipfirst, instance)\n    if result is None:\n        # was a C function (e.g. object().__init__ ) that can't be mocked\n        return\n\n    signature, func = result\n\n    src = \"lambda %s: None\" % signature\n    checksig = eval(src, {})\n    _copy_func_details(func, checksig)\n\n    name = original.__name__\n    if not name.isidentifier():\n        name = 'funcopy'\n    context = {'_checksig_': checksig, 'mock': mock}\n    src = \"\"\"def %s(*args, **kwargs):\n    _checksig_(*args, **kwargs)\n    return mock(*args, **kwargs)\"\"\" % name\n    exec (src, context)\n    funcopy = context[name]\n    _setup_func(funcopy, mock)\n    return funcopy\n\n\ndef _setup_func(funcopy, mock):\n    funcopy.mock = mock\n\n    # can't use isinstance with mocks\n    if not _is_instance_mock(mock):\n        return\n\n    def assert_called_with(*args, **kwargs):\n        return mock.assert_called_with(*args, **kwargs)\n    def assert_called_once_with(*args, **kwargs):\n        return mock.assert_called_once_with(*args, **kwargs)\n    def assert_has_calls(*args, **kwargs):\n        return mock.assert_has_calls(*args, **kwargs)\n    def assert_any_call(*args, **kwargs):\n        return mock.assert_any_call(*args, **kwargs)\n    def reset_mock():\n        funcopy.method_calls = _CallList()\n        funcopy.mock_calls = _CallList()\n        mock.reset_mock()\n        ret = funcopy.return_value\n        if _is_instance_mock(ret) and not ret is mock:\n            ret.reset_mock()\n\n    funcopy.called = False\n    funcopy.call_count = 0\n    funcopy.call_args = None\n    funcopy.call_args_list = _CallList()\n    funcopy.method_calls = _CallList()\n    funcopy.mock_calls = _CallList()\n\n    funcopy.return_value = mock.return_value\n    funcopy.side_effect = mock.side_effect\n    funcopy._mock_children = mock._mock_children\n\n    funcopy.assert_called_with = assert_called_with\n    funcopy.assert_called_once_with = assert_called_once_with\n    funcopy.assert_has_calls = assert_has_calls\n    funcopy.assert_any_call = assert_any_call\n    funcopy.reset_mock = reset_mock\n\n    mock._mock_delegate = funcopy\n\n\ndef _is_magic(name):\n    return '__%s__' % name[2:-2] == name\n\n\nclass _SentinelObject(object):\n    \"A unique, named, sentinel object.\"\n    def __init__(self, name):\n        self.name = name\n\n    def __repr__(self):\n        return 'sentinel.%s' % self.name\n\n\nclass _Sentinel(object):\n    \"\"\"Access attributes to return a named object, usable as a sentinel.\"\"\"\n    def __init__(self):\n        self._sentinels = {}\n\n    def __getattr__(self, name):\n        if name == '__bases__':\n            # Without this help(unittest.mock) raises an exception\n            raise AttributeError\n        return self._sentinels.setdefault(name, _SentinelObject(name))\n\n\nsentinel = _Sentinel()\n\nDEFAULT = sentinel.DEFAULT\n_missing = sentinel.MISSING\n_deleted = sentinel.DELETED\n\n\ndef _copy(value):\n    if type(value) in (dict, list, tuple, set):\n        return type(value)(value)\n    return value\n\n\n_allowed_names = set(\n    [\n        'return_value', '_mock_return_value', 'side_effect',\n        '_mock_side_effect', '_mock_parent', '_mock_new_parent',\n        '_mock_name', '_mock_new_name'\n    ]\n)\n\n\ndef _delegating_property(name):\n    _allowed_names.add(name)\n    _the_name = '_mock_' + name\n    def _get(self, name=name, _the_name=_the_name):\n        sig = self._mock_delegate\n        if sig is None:\n            return getattr(self, _the_name)\n        return getattr(sig, name)\n    def _set(self, value, name=name, _the_name=_the_name):\n        sig = self._mock_delegate\n        if sig is None:\n            self.__dict__[_the_name] = value\n        else:\n            setattr(sig, name, value)\n\n    return property(_get, _set)\n\n\n\nclass _CallList(list):\n\n    def __contains__(self, value):\n        if not isinstance(value, list):\n            return list.__contains__(self, value)\n        len_value = len(value)\n        len_self = len(self)\n        if len_value > len_self:\n            return False\n\n        for i in range(0, len_self - len_value + 1):\n            sub_list = self[i:i+len_value]\n            if sub_list == value:\n                return True\n        return False\n\n    def __repr__(self):\n        return pprint.pformat(list(self))\n\n\ndef _check_and_set_parent(parent, value, name, new_name):\n    if not _is_instance_mock(value):\n        return False\n    if ((value._mock_name or value._mock_new_name) or\n        (value._mock_parent is not None) or\n        (value._mock_new_parent is not None)):\n        return False\n\n    _parent = parent\n    while _parent is not None:\n        # setting a mock (value) as a child or return value of itself\n        # should not modify the mock\n        if _parent is value:\n            return False\n        _parent = _parent._mock_new_parent\n\n    if new_name:\n        value._mock_new_parent = parent\n        value._mock_new_name = new_name\n    if name:\n        value._mock_parent = parent\n        value._mock_name = name\n    return True\n\n\n\nclass Base(object):\n    _mock_return_value = DEFAULT\n    _mock_side_effect = None\n    def __init__(self, *args, **kwargs):\n        pass\n\n\n\nclass NonCallableMock(Base):\n    \"\"\"A non-callable version of `Mock`\"\"\"\n\n    def __new__(cls, *args, **kw):\n        # every instance has its own class\n        # so we can create magic methods on the\n        # class without stomping on other mocks\n        new = type(cls.__name__, (cls,), {'__doc__': cls.__doc__})\n        instance = object.__new__(new)\n        return instance\n\n\n    def __init__(\n            self, spec=None, wraps=None, name=None, spec_set=None,\n            parent=None, _spec_state=None, _new_name='', _new_parent=None,\n            **kwargs\n        ):\n        if _new_parent is None:\n            _new_parent = parent\n\n        __dict__ = self.__dict__\n        __dict__['_mock_parent'] = parent\n        __dict__['_mock_name'] = name\n        __dict__['_mock_new_name'] = _new_name\n        __dict__['_mock_new_parent'] = _new_parent\n\n        if spec_set is not None:\n            spec = spec_set\n            spec_set = True\n\n        self._mock_add_spec(spec, spec_set)\n\n        __dict__['_mock_children'] = {}\n        __dict__['_mock_wraps'] = wraps\n        __dict__['_mock_delegate'] = None\n\n        __dict__['_mock_called'] = False\n        __dict__['_mock_call_args'] = None\n        __dict__['_mock_call_count'] = 0\n        __dict__['_mock_call_args_list'] = _CallList()\n        __dict__['_mock_mock_calls'] = _CallList()\n\n        __dict__['method_calls'] = _CallList()\n\n        if kwargs:\n            self.configure_mock(**kwargs)\n\n        _safe_super(NonCallableMock, self).__init__(\n            spec, wraps, name, spec_set, parent,\n            _spec_state\n        )\n\n\n    def attach_mock(self, mock, attribute):\n        \"\"\"\n        Attach a mock as an attribute of this one, replacing its name and\n        parent. Calls to the attached mock will be recorded in the\n        `method_calls` and `mock_calls` attributes of this one.\"\"\"\n        mock._mock_parent = None\n        mock._mock_new_parent = None\n        mock._mock_name = ''\n        mock._mock_new_name = None\n\n        setattr(self, attribute, mock)\n\n\n    def mock_add_spec(self, spec, spec_set=False):\n        \"\"\"Add a spec to a mock. `spec` can either be an object or a\n        list of strings. Only attributes on the `spec` can be fetched as\n        attributes from the mock.\n\n        If `spec_set` is True then only attributes on the spec can be set.\"\"\"\n        self._mock_add_spec(spec, spec_set)\n\n\n    def _mock_add_spec(self, spec, spec_set):\n        _spec_class = None\n\n        if spec is not None and not _is_list(spec):\n            if isinstance(spec, type):\n                _spec_class = spec\n            else:\n                _spec_class = _get_class(spec)\n\n            spec = dir(spec)\n\n        __dict__ = self.__dict__\n        __dict__['_spec_class'] = _spec_class\n        __dict__['_spec_set'] = spec_set\n        __dict__['_mock_methods'] = spec\n\n\n    def __get_return_value(self):\n        ret = self._mock_return_value\n        if self._mock_delegate is not None:\n            ret = self._mock_delegate.return_value\n\n        if ret is DEFAULT:\n            ret = self._get_child_mock(\n                _new_parent=self, _new_name='()'\n            )\n            self.return_value = ret\n        return ret\n\n\n    def __set_return_value(self, value):\n        if self._mock_delegate is not None:\n            self._mock_delegate.return_value = value\n        else:\n            self._mock_return_value = value\n            _check_and_set_parent(self, value, None, '()')\n\n    __return_value_doc = \"The value to be returned when the mock is called.\"\n    return_value = property(__get_return_value, __set_return_value,\n                            __return_value_doc)\n\n\n    @property\n    def __class__(self):\n        if self._spec_class is None:\n            return type(self)\n        return self._spec_class\n\n    called = _delegating_property('called')\n    call_count = _delegating_property('call_count')\n    call_args = _delegating_property('call_args')\n    call_args_list = _delegating_property('call_args_list')\n    mock_calls = _delegating_property('mock_calls')\n\n\n    def __get_side_effect(self):\n        delegated = self._mock_delegate\n        if delegated is None:\n            return self._mock_side_effect\n        return delegated.side_effect\n\n    def __set_side_effect(self, value):\n        value = _try_iter(value)\n        delegated = self._mock_delegate\n        if delegated is None:\n            self._mock_side_effect = value\n        else:\n            delegated.side_effect = value\n\n    side_effect = property(__get_side_effect, __set_side_effect)\n\n\n    def reset_mock(self):\n        \"Restore the mock object to its initial state.\"\n        self.called = False\n        self.call_args = None\n        self.call_count = 0\n        self.mock_calls = _CallList()\n        self.call_args_list = _CallList()\n        self.method_calls = _CallList()\n\n        for child in self._mock_children.values():\n            if isinstance(child, _SpecState):\n                continue\n            child.reset_mock()\n\n        ret = self._mock_return_value\n        if _is_instance_mock(ret) and ret is not self:\n            ret.reset_mock()\n\n\n    def configure_mock(self, **kwargs):\n        \"\"\"Set attributes on the mock through keyword arguments.\n\n        Attributes plus return values and side effects can be set on child\n        mocks using standard dot notation and unpacking a dictionary in the\n        method call:\n\n        >>> attrs = {'method.return_value': 3, 'other.side_effect': KeyError}\n        >>> mock.configure_mock(**attrs)\"\"\"\n        for arg, val in sorted(kwargs.items(),\n                               # we sort on the number of dots so that\n                               # attributes are set before we set attributes on\n                               # attributes\n                               key=lambda entry: entry[0].count('.')):\n            args = arg.split('.')\n            final = args.pop()\n            obj = self\n            for entry in args:\n                obj = getattr(obj, entry)\n            setattr(obj, final, val)\n\n\n    def __getattr__(self, name):\n        if name == '_mock_methods':\n            raise AttributeError(name)\n        elif self._mock_methods is not None:\n            if name not in self._mock_methods or name in _all_magics:\n                raise AttributeError(\"Mock object has no attribute %r\" % name)\n        elif _is_magic(name):\n            raise AttributeError(name)\n\n        result = self._mock_children.get(name)\n        if result is _deleted:\n            raise AttributeError(name)\n        elif result is None:\n            wraps = None\n            if self._mock_wraps is not None:\n                # XXXX should we get the attribute without triggering code\n                # execution?\n                wraps = getattr(self._mock_wraps, name)\n\n            result = self._get_child_mock(\n                parent=self, name=name, wraps=wraps, _new_name=name,\n                _new_parent=self\n            )\n            self._mock_children[name]  = result\n\n        elif isinstance(result, _SpecState):\n            result = create_autospec(\n                result.spec, result.spec_set, result.instance,\n                result.parent, result.name\n            )\n            self._mock_children[name]  = result\n\n        return result\n\n\n    def __repr__(self):\n        _name_list = [self._mock_new_name]\n        _parent = self._mock_new_parent\n        last = self\n\n        dot = '.'\n        if _name_list == ['()']:\n            dot = ''\n        seen = set()\n        while _parent is not None:\n            last = _parent\n\n            _name_list.append(_parent._mock_new_name + dot)\n            dot = '.'\n            if _parent._mock_new_name == '()':\n                dot = ''\n\n            _parent = _parent._mock_new_parent\n\n            # use ids here so as not to call __hash__ on the mocks\n            if id(_parent) in seen:\n                break\n            seen.add(id(_parent))\n\n        _name_list = list(reversed(_name_list))\n        _first = last._mock_name or 'mock'\n        if len(_name_list) > 1:\n            if _name_list[1] not in ('()', '().'):\n                _first += '.'\n        _name_list[0] = _first\n        name = ''.join(_name_list)\n\n        name_string = ''\n        if name not in ('mock', 'mock.'):\n            name_string = ' name=%r' % name\n\n        spec_string = ''\n        if self._spec_class is not None:\n            spec_string = ' spec=%r'\n            if self._spec_set:\n                spec_string = ' spec_set=%r'\n            spec_string = spec_string % self._spec_class.__name__\n        return \"<%s%s%s id='%s'>\" % (\n            type(self).__name__,\n            name_string,\n            spec_string,\n            id(self)\n        )\n\n\n    def __dir__(self):\n        \"\"\"Filter the output of `dir(mock)` to only useful members.\"\"\"\n        if not FILTER_DIR:\n            return object.__dir__(self)\n\n        extras = self._mock_methods or []\n        from_type = dir(type(self))\n        from_dict = list(self.__dict__)\n\n        from_type = [e for e in from_type if not e.startswith('_')]\n        from_dict = [e for e in from_dict if not e.startswith('_') or\n                     _is_magic(e)]\n        return sorted(set(extras + from_type + from_dict +\n                          list(self._mock_children)))\n\n\n    def __setattr__(self, name, value):\n        if name in _allowed_names:\n            # property setters go through here\n            return object.__setattr__(self, name, value)\n        elif (self._spec_set and self._mock_methods is not None and\n            name not in self._mock_methods and\n            name not in self.__dict__):\n            raise AttributeError(\"Mock object has no attribute '%s'\" % name)\n        elif name in _unsupported_magics:\n            msg = 'Attempting to set unsupported magic method %r.' % name\n            raise AttributeError(msg)\n        elif name in _all_magics:\n            if self._mock_methods is not None and name not in self._mock_methods:\n                raise AttributeError(\"Mock object has no attribute '%s'\" % name)\n\n            if not _is_instance_mock(value):\n                setattr(type(self), name, _get_method(name, value))\n                original = value\n                value = lambda *args, **kw: original(self, *args, **kw)\n            else:\n                # only set _new_name and not name so that mock_calls is tracked\n                # but not method calls\n                _check_and_set_parent(self, value, None, name)\n                setattr(type(self), name, value)\n                self._mock_children[name] = value\n        elif name == '__class__':\n            self._spec_class = value\n            return\n        else:\n            if _check_and_set_parent(self, value, name, name):\n                self._mock_children[name] = value\n        return object.__setattr__(self, name, value)\n\n\n    def __delattr__(self, name):\n        if name in _all_magics and name in type(self).__dict__:\n            delattr(type(self), name)\n            if name not in self.__dict__:\n                # for magic methods that are still MagicProxy objects and\n                # not set on the instance itself\n                return\n\n        if name in self.__dict__:\n            object.__delattr__(self, name)\n\n        obj = self._mock_children.get(name, _missing)\n        if obj is _deleted:\n            raise AttributeError(name)\n        if obj is not _missing:\n            del self._mock_children[name]\n        self._mock_children[name] = _deleted\n\n\n\n    def _format_mock_call_signature(self, args, kwargs):\n        name = self._mock_name or 'mock'\n        return _format_call_signature(name, args, kwargs)\n\n\n    def _format_mock_failure_message(self, args, kwargs):\n        message = 'Expected call: %s\\nActual call: %s'\n        expected_string = self._format_mock_call_signature(args, kwargs)\n        call_args = self.call_args\n        if len(call_args) == 3:\n            call_args = call_args[1:]\n        actual_string = self._format_mock_call_signature(*call_args)\n        return message % (expected_string, actual_string)\n\n\n    def assert_called_with(_mock_self, *args, **kwargs):\n        \"\"\"assert that the mock was called with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        self = _mock_self\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            raise AssertionError('Expected call: %s\\nNot called' % (expected,))\n\n        if self.call_args != (args, kwargs):\n            msg = self._format_mock_failure_message(args, kwargs)\n            raise AssertionError(msg)\n\n\n    def assert_called_once_with(_mock_self, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and with the specified\n        arguments.\"\"\"\n        self = _mock_self\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.\" %\n                   (self._mock_name or 'mock', self.call_count))\n            raise AssertionError(msg)\n        return self.assert_called_with(*args, **kwargs)\n\n\n    def assert_has_calls(self, calls, any_order=False):\n        \"\"\"assert the mock has been called with the specified calls.\n        The `mock_calls` list is checked for the calls.\n\n        If `any_order` is False (the default) then the calls must be\n        sequential. There can be extra calls before or after the\n        specified calls.\n\n        If `any_order` is True then the calls can be in any order, but\n        they must all appear in `mock_calls`.\"\"\"\n        if not any_order:\n            if calls not in self.mock_calls:\n                raise AssertionError(\n                    'Calls not found.\\nExpected: %r\\n'\n                    'Actual: %r' % (calls, self.mock_calls)\n                )\n            return\n\n        all_calls = list(self.mock_calls)\n\n        not_found = []\n        for kall in calls:\n            try:\n                all_calls.remove(kall)\n            except ValueError:\n                not_found.append(kall)\n        if not_found:\n            raise AssertionError(\n                '%r not all found in call list' % (tuple(not_found),)\n            )\n\n\n    def assert_any_call(self, *args, **kwargs):\n        \"\"\"assert the mock has been called with the specified arguments.\n\n        The assert passes if the mock has *ever* been called, unlike\n        `assert_called_with` and `assert_called_once_with` that only pass if\n        the call is the most recent one.\"\"\"\n        kall = call(*args, **kwargs)\n        if kall not in self.call_args_list:\n            expected_string = self._format_mock_call_signature(args, kwargs)\n            raise AssertionError(\n                '%s call not found' % expected_string\n            )\n\n\n    def _get_child_mock(self, **kw):\n        \"\"\"Create the child mocks for attributes and return value.\n        By default child mocks will be the same type as the parent.\n        Subclasses of Mock may want to override this to customize the way\n        child mocks are made.\n\n        For non-callable mocks the callable variant will be used (rather than\n        any custom subclass).\"\"\"\n        _type = type(self)\n        if not issubclass(_type, CallableMixin):\n            if issubclass(_type, NonCallableMagicMock):\n                klass = MagicMock\n            elif issubclass(_type, NonCallableMock) :\n                klass = Mock\n        else:\n            klass = _type.__mro__[1]\n        return klass(**kw)\n\n\n\ndef _try_iter(obj):\n    if obj is None:\n        return obj\n    if _is_exception(obj):\n        return obj\n    if _callable(obj):\n        return obj\n    try:\n        return iter(obj)\n    except TypeError:\n        # XXXX backwards compatibility\n        # but this will blow up on first call - so maybe we should fail early?\n        return obj\n\n\n\nclass CallableMixin(Base):\n\n    def __init__(self, spec=None, side_effect=None, return_value=DEFAULT,\n                 wraps=None, name=None, spec_set=None, parent=None,\n                 _spec_state=None, _new_name='', _new_parent=None, **kwargs):\n        self.__dict__['_mock_return_value'] = return_value\n\n        _safe_super(CallableMixin, self).__init__(\n            spec, wraps, name, spec_set, parent,\n            _spec_state, _new_name, _new_parent, **kwargs\n        )\n\n        self.side_effect = side_effect\n\n\n    def _mock_check_sig(self, *args, **kwargs):\n        # stub method that can be replaced with one with a specific signature\n        pass\n\n\n    def __call__(_mock_self, *args, **kwargs):\n        # can't use self in-case a function / method we are mocking uses self\n        # in the signature\n        _mock_self._mock_check_sig(*args, **kwargs)\n        return _mock_self._mock_call(*args, **kwargs)\n\n\n    def _mock_call(_mock_self, *args, **kwargs):\n        self = _mock_self\n        self.called = True\n        self.call_count += 1\n        self.call_args = _Call((args, kwargs), two=True)\n        self.call_args_list.append(_Call((args, kwargs), two=True))\n\n        _new_name = self._mock_new_name\n        _new_parent = self._mock_new_parent\n        self.mock_calls.append(_Call(('', args, kwargs)))\n\n        seen = set()\n        skip_next_dot = _new_name == '()'\n        do_method_calls = self._mock_parent is not None\n        name = self._mock_name\n        while _new_parent is not None:\n            this_mock_call = _Call((_new_name, args, kwargs))\n            if _new_parent._mock_new_name:\n                dot = '.'\n                if skip_next_dot:\n                    dot = ''\n\n                skip_next_dot = False\n                if _new_parent._mock_new_name == '()':\n                    skip_next_dot = True\n\n                _new_name = _new_parent._mock_new_name + dot + _new_name\n\n            if do_method_calls:\n                if _new_name == name:\n                    this_method_call = this_mock_call\n                else:\n                    this_method_call = _Call((name, args, kwargs))\n                _new_parent.method_calls.append(this_method_call)\n\n                do_method_calls = _new_parent._mock_parent is not None\n                if do_method_calls:\n                    name = _new_parent._mock_name + '.' + name\n\n            _new_parent.mock_calls.append(this_mock_call)\n            _new_parent = _new_parent._mock_new_parent\n\n            # use ids here so as not to call __hash__ on the mocks\n            _new_parent_id = id(_new_parent)\n            if _new_parent_id in seen:\n                break\n            seen.add(_new_parent_id)\n\n        ret_val = DEFAULT\n        effect = self.side_effect\n        if effect is not None:\n            if _is_exception(effect):\n                raise effect\n\n            if not _callable(effect):\n                result = next(effect)\n                if _is_exception(result):\n                    raise result\n                if result is DEFAULT:\n                    result = self.return_value\n                return result\n\n            ret_val = effect(*args, **kwargs)\n            if ret_val is DEFAULT:\n                ret_val = self.return_value\n\n        if (self._mock_wraps is not None and\n             self._mock_return_value is DEFAULT):\n            return self._mock_wraps(*args, **kwargs)\n        if ret_val is DEFAULT:\n            ret_val = self.return_value\n        return ret_val\n\n\n\nclass Mock(CallableMixin, NonCallableMock):\n    \"\"\"\n    Create a new `Mock` object. `Mock` takes several optional arguments\n    that specify the behaviour of the Mock object:\n\n    * `spec`: This can be either a list of strings or an existing object (a\n      class or instance) that acts as the specification for the mock object. If\n      you pass in an object then a list of strings is formed by calling dir on\n      the object (excluding unsupported magic attributes and methods). Accessing\n      any attribute not in this list will raise an `AttributeError`.\n\n      If `spec` is an object (rather than a list of strings) then\n      `mock.__class__` returns the class of the spec object. This allows mocks\n      to pass `isinstance` tests.\n\n    * `spec_set`: A stricter variant of `spec`. If used, attempting to *set*\n      or get an attribute on the mock that isn't on the object passed as\n      `spec_set` will raise an `AttributeError`.\n\n    * `side_effect`: A function to be called whenever the Mock is called. See\n      the `side_effect` attribute. Useful for raising exceptions or\n      dynamically changing return values. The function is called with the same\n      arguments as the mock, and unless it returns `DEFAULT`, the return\n      value of this function is used as the return value.\n\n      If `side_effect` is an iterable then each call to the mock will return\n      the next value from the iterable. If any of the members of the iterable\n      are exceptions they will be raised instead of returned.\n\n    * `return_value`: The value returned when the mock is called. By default\n      this is a new Mock (created on first access). See the\n      `return_value` attribute.\n\n    * `wraps`: Item for the mock object to wrap. If `wraps` is not None then\n      calling the Mock will pass the call through to the wrapped object\n      (returning the real result). Attribute access on the mock will return a\n      Mock object that wraps the corresponding attribute of the wrapped object\n      (so attempting to access an attribute that doesn't exist will raise an\n      `AttributeError`).\n\n      If the mock has an explicit `return_value` set then calls are not passed\n      to the wrapped object and the `return_value` is returned instead.\n\n    * `name`: If the mock has a name then it will be used in the repr of the\n      mock. This can be useful for debugging. The name is propagated to child\n      mocks.\n\n    Mocks can also be called with arbitrary keyword arguments. These will be\n    used to set attributes on the mock after it is created.\n    \"\"\"\n\n\n\ndef _dot_lookup(thing, comp, import_path):\n    try:\n        return getattr(thing, comp)\n    except AttributeError:\n        __import__(import_path)\n        return getattr(thing, comp)\n\n\ndef _importer(target):\n    components = target.split('.')\n    import_path = components.pop(0)\n    thing = __import__(import_path)\n\n    for comp in components:\n        import_path += \".%s\" % comp\n        thing = _dot_lookup(thing, comp, import_path)\n    return thing\n\n\ndef _is_started(patcher):\n    # XXXX horrible\n    return hasattr(patcher, 'is_local')\n\n\nclass _patch(object):\n\n    attribute_name = None\n    _active_patches = set()\n\n    def __init__(\n            self, getter, attribute, new, spec, create,\n            spec_set, autospec, new_callable, kwargs\n        ):\n        if new_callable is not None:\n            if new is not DEFAULT:\n                raise ValueError(\n                    \"Cannot use 'new' and 'new_callable' together\"\n                )\n            if autospec is not None:\n                raise ValueError(\n                    \"Cannot use 'autospec' and 'new_callable' together\"\n                )\n\n        self.getter = getter\n        self.attribute = attribute\n        self.new = new\n        self.new_callable = new_callable\n        self.spec = spec\n        self.create = create\n        self.has_local = False\n        self.spec_set = spec_set\n        self.autospec = autospec\n        self.kwargs = kwargs\n        self.additional_patchers = []\n\n\n    def copy(self):\n        patcher = _patch(\n            self.getter, self.attribute, self.new, self.spec,\n            self.create, self.spec_set,\n            self.autospec, self.new_callable, self.kwargs\n        )\n        patcher.attribute_name = self.attribute_name\n        patcher.additional_patchers = [\n            p.copy() for p in self.additional_patchers\n        ]\n        return patcher\n\n\n    def __call__(self, func):\n        if isinstance(func, type):\n            return self.decorate_class(func)\n        return self.decorate_callable(func)\n\n\n    def decorate_class(self, klass):\n        for attr in dir(klass):\n            if not attr.startswith(patch.TEST_PREFIX):\n                continue\n\n            attr_value = getattr(klass, attr)\n            if not hasattr(attr_value, \"__call__\"):\n                continue\n\n            patcher = self.copy()\n            setattr(klass, attr, patcher(attr_value))\n        return klass\n\n\n    def decorate_callable(self, func):\n        if hasattr(func, 'patchings'):\n            func.patchings.append(self)\n            return func\n\n        @wraps(func)\n        def patched(*args, **keywargs):\n            extra_args = []\n            entered_patchers = []\n\n            exc_info = tuple()\n            try:\n                for patching in patched.patchings:\n                    arg = patching.__enter__()\n                    entered_patchers.append(patching)\n                    if patching.attribute_name is not None:\n                        keywargs.update(arg)\n                    elif patching.new is DEFAULT:\n                        extra_args.append(arg)\n\n                args += tuple(extra_args)\n                return func(*args, **keywargs)\n            except:\n                if (patching not in entered_patchers and\n                    _is_started(patching)):\n                    # the patcher may have been started, but an exception\n                    # raised whilst entering one of its additional_patchers\n                    entered_patchers.append(patching)\n                # Pass the exception to __exit__\n                exc_info = sys.exc_info()\n                # re-raise the exception\n                raise\n            finally:\n                for patching in reversed(entered_patchers):\n                    patching.__exit__(*exc_info)\n\n        patched.patchings = [self]\n        return patched\n\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n\n        original = DEFAULT\n        local = False\n\n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n\n        if not self.create and original is DEFAULT:\n            raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\n        return original, local\n\n\n    def __enter__(self):\n        \"\"\"Perform the patch.\"\"\"\n        new, spec, spec_set = self.new, self.spec, self.spec_set\n        autospec, kwargs = self.autospec, self.kwargs\n        new_callable = self.new_callable\n        self.target = self.getter()\n\n        # normalise False to None\n        if spec is False:\n            spec = None\n        if spec_set is False:\n            spec_set = None\n        if autospec is False:\n            autospec = None\n\n        if spec is not None and autospec is not None:\n            raise TypeError(\"Can't specify spec and autospec\")\n        if ((spec is not None or autospec is not None) and\n            spec_set not in (True, None)):\n            raise TypeError(\"Can't provide explicit spec_set *and* spec or autospec\")\n\n        original, local = self.get_original()\n\n        if new is DEFAULT and autospec is None:\n            inherit = False\n            if spec is True:\n                # set spec to the object we are replacing\n                spec = original\n                if spec_set is True:\n                    spec_set = original\n                    spec = None\n            elif spec is not None:\n                if spec_set is True:\n                    spec_set = spec\n                    spec = None\n            elif spec_set is True:\n                spec_set = original\n\n            if spec is not None or spec_set is not None:\n                if original is DEFAULT:\n                    raise TypeError(\"Can't use 'spec' with create=True\")\n                if isinstance(original, type):\n                    # If we're patching out a class and there is a spec\n                    inherit = True\n\n            Klass = MagicMock\n            _kwargs = {}\n            if new_callable is not None:\n                Klass = new_callable\n            elif spec is not None or spec_set is not None:\n                this_spec = spec\n                if spec_set is not None:\n                    this_spec = spec_set\n                if _is_list(this_spec):\n                    not_callable = '__call__' not in this_spec\n                else:\n                    not_callable = not callable(this_spec)\n                if not_callable:\n                    Klass = NonCallableMagicMock\n\n            if spec is not None:\n                _kwargs['spec'] = spec\n            if spec_set is not None:\n                _kwargs['spec_set'] = spec_set\n\n            # add a name to mocks\n            if (isinstance(Klass, type) and\n                issubclass(Klass, NonCallableMock) and self.attribute):\n                _kwargs['name'] = self.attribute\n\n            _kwargs.update(kwargs)\n            new = Klass(**_kwargs)\n\n            if inherit and _is_instance_mock(new):\n                # we can only tell if the instance should be callable if the\n                # spec is not a list\n                this_spec = spec\n                if spec_set is not None:\n                    this_spec = spec_set\n                if (not _is_list(this_spec) and not\n                    _instance_callable(this_spec)):\n                    Klass = NonCallableMagicMock\n\n                _kwargs.pop('name')\n                new.return_value = Klass(_new_parent=new, _new_name='()',\n                                         **_kwargs)\n        elif autospec is not None:\n            # spec is ignored, new *must* be default, spec_set is treated\n            # as a boolean. Should we check spec is not None and that spec_set\n            # is a bool?\n            if new is not DEFAULT:\n                raise TypeError(\n                    \"autospec creates the mock for you. Can't specify \"\n                    \"autospec and new.\"\n                )\n            if original is DEFAULT:\n                raise TypeError(\"Can't use 'autospec' with create=True\")\n            spec_set = bool(spec_set)\n            if autospec is True:\n                autospec = original\n\n            new = create_autospec(autospec, spec_set=spec_set,\n                                  _name=self.attribute, **kwargs)\n        elif kwargs:\n            # can't set keyword args when we aren't creating the mock\n            # XXXX If new is a Mock we could call new.configure_mock(**kwargs)\n            raise TypeError(\"Can't pass kwargs to a mock we aren't creating\")\n\n        new_attr = new\n\n        self.temp_original = original\n        self.is_local = local\n        setattr(self.target, self.attribute, new_attr)\n        if self.attribute_name is not None:\n            extra_args = {}\n            if self.new is DEFAULT:\n                extra_args[self.attribute_name] =  new\n            for patching in self.additional_patchers:\n                arg = patching.__enter__()\n                if patching.new is DEFAULT:\n                    extra_args.update(arg)\n            return extra_args\n\n        return new\n\n\n    def __exit__(self, *exc_info):\n        \"\"\"Undo the patch.\"\"\"\n        if not _is_started(self):\n            raise RuntimeError('stop called on unstarted patcher')\n\n        if self.is_local and self.temp_original is not DEFAULT:\n            setattr(self.target, self.attribute, self.temp_original)\n        else:\n            delattr(self.target, self.attribute)\n            if not self.create and not hasattr(self.target, self.attribute):\n                # needed for proxy objects like django settings\n                setattr(self.target, self.attribute, self.temp_original)\n\n        del self.temp_original\n        del self.is_local\n        del self.target\n        for patcher in reversed(self.additional_patchers):\n            if _is_started(patcher):\n                patcher.__exit__(*exc_info)\n\n\n    def start(self):\n        \"\"\"Activate a patch, returning any created mock.\"\"\"\n        result = self.__enter__()\n        self._active_patches.add(self)\n        return result\n\n\n    def stop(self):\n        \"\"\"Stop an active patch.\"\"\"\n        self._active_patches.discard(self)\n        return self.__exit__()\n\n\n\ndef _get_target(target):\n    try:\n        target, attribute = target.rsplit('.', 1)\n    except (TypeError, ValueError):\n        raise TypeError(\"Need a valid target to patch. You supplied: %r\" %\n                        (target,))\n    getter = lambda: _importer(target)\n    return getter, attribute\n\n\ndef _patch_object(\n        target, attribute, new=DEFAULT, spec=None,\n        create=False, spec_set=None, autospec=None,\n        new_callable=None, **kwargs\n    ):\n    \"\"\"\n    patch the named member (`attribute`) on an object (`target`) with a mock\n    object.\n\n    `patch.object` can be used as a decorator, class decorator or a context\n    manager. Arguments `new`, `spec`, `create`, `spec_set`,\n    `autospec` and `new_callable` have the same meaning as for `patch`. Like\n    `patch`, `patch.object` takes arbitrary keyword arguments for configuring\n    the mock object it creates.\n\n    When used as a class decorator `patch.object` honours `patch.TEST_PREFIX`\n    for choosing which methods to wrap.\n    \"\"\"\n    getter = lambda: target\n    return _patch(\n        getter, attribute, new, spec, create,\n        spec_set, autospec, new_callable, kwargs\n    )\n\n\ndef _patch_multiple(target, spec=None, create=False, spec_set=None,\n                    autospec=None, new_callable=None, **kwargs):\n    \"\"\"Perform multiple patches in a single call. It takes the object to be\n    patched (either as an object or a string to fetch the object by importing)\n    and keyword arguments for the patches::\n\n        with patch.multiple(settings, FIRST_PATCH='one', SECOND_PATCH='two'):\n            ...\n\n    Use `DEFAULT` as the value if you want `patch.multiple` to create\n    mocks for you. In this case the created mocks are passed into a decorated\n    function by keyword, and a dictionary is returned when `patch.multiple` is\n    used as a context manager.\n\n    `patch.multiple` can be used as a decorator, class decorator or a context\n    manager. The arguments `spec`, `spec_set`, `create`,\n    `autospec` and `new_callable` have the same meaning as for `patch`. These\n    arguments will be applied to *all* patches done by `patch.multiple`.\n\n    When used as a class decorator `patch.multiple` honours `patch.TEST_PREFIX`\n    for choosing which methods to wrap.\n    \"\"\"\n    if type(target) is str:\n        getter = lambda: _importer(target)\n    else:\n        getter = lambda: target\n\n    if not kwargs:\n        raise ValueError(\n            'Must supply at least one keyword argument with patch.multiple'\n        )\n    # need to wrap in a list for python 3, where items is a view\n    items = list(kwargs.items())\n    attribute, new = items[0]\n    patcher = _patch(\n        getter, attribute, new, spec, create, spec_set,\n        autospec, new_callable, {}\n    )\n    patcher.attribute_name = attribute\n    for attribute, new in items[1:]:\n        this_patcher = _patch(\n            getter, attribute, new, spec, create, spec_set,\n            autospec, new_callable, {}\n        )\n        this_patcher.attribute_name = attribute\n        patcher.additional_patchers.append(this_patcher)\n    return patcher\n\n\ndef patch(\n        target, new=DEFAULT, spec=None, create=False,\n        spec_set=None, autospec=None, new_callable=None, **kwargs\n    ):\n    \"\"\"\n    `patch` acts as a function decorator, class decorator or a context\n    manager. Inside the body of the function or with statement, the `target`\n    is patched with a `new` object. When the function/with statement exits\n    the patch is undone.\n\n    If `new` is omitted, then the target is replaced with a\n    `MagicMock`. If `patch` is used as a decorator and `new` is\n    omitted, the created mock is passed in as an extra argument to the\n    decorated function. If `patch` is used as a context manager the created\n    mock is returned by the context manager.\n\n    `target` should be a string in the form `'package.module.ClassName'`. The\n    `target` is imported and the specified object replaced with the `new`\n    object, so the `target` must be importable from the environment you are\n    calling `patch` from. The target is imported when the decorated function\n    is executed, not at decoration time.\n\n    The `spec` and `spec_set` keyword arguments are passed to the `MagicMock`\n    if patch is creating one for you.\n\n    In addition you can pass `spec=True` or `spec_set=True`, which causes\n    patch to pass in the object being mocked as the spec/spec_set object.\n\n    `new_callable` allows you to specify a different class, or callable object,\n    that will be called to create the `new` object. By default `MagicMock` is\n    used.\n\n    A more powerful form of `spec` is `autospec`. If you set `autospec=True`\n    then the mock with be created with a spec from the object being replaced.\n    All attributes of the mock will also have the spec of the corresponding\n    attribute of the object being replaced. Methods and functions being\n    mocked will have their arguments checked and will raise a `TypeError` if\n    they are called with the wrong signature. For mocks replacing a class,\n    their return value (the 'instance') will have the same spec as the class.\n\n    Instead of `autospec=True` you can pass `autospec=some_object` to use an\n    arbitrary object as the spec instead of the one being replaced.\n\n    By default `patch` will fail to replace attributes that don't exist. If\n    you pass in `create=True`, and the attribute doesn't exist, patch will\n    create the attribute for you when the patched function is called, and\n    delete it again afterwards. This is useful for writing tests against\n    attributes that your production code creates at runtime. It is off by\n    default because it can be dangerous. With it switched on you can write\n    passing tests against APIs that don't actually exist!\n\n    Patch can be used as a `TestCase` class decorator. It works by\n    decorating each test method in the class. This reduces the boilerplate\n    code when your test methods share a common patchings set. `patch` finds\n    tests by looking for method names that start with `patch.TEST_PREFIX`.\n    By default this is `test`, which matches the way `unittest` finds tests.\n    You can specify an alternative prefix by setting `patch.TEST_PREFIX`.\n\n    Patch can be used as a context manager, with the with statement. Here the\n    patching applies to the indented block after the with statement. If you\n    use \"as\" then the patched object will be bound to the name after the\n    \"as\"; very useful if `patch` is creating a mock object for you.\n\n    `patch` takes arbitrary keyword arguments. These will be passed to\n    the `Mock` (or `new_callable`) on construction.\n\n    `patch.dict(...)`, `patch.multiple(...)` and `patch.object(...)` are\n    available for alternate use-cases.\n    \"\"\"\n    getter, attribute = _get_target(target)\n    return _patch(\n        getter, attribute, new, spec, create,\n        spec_set, autospec, new_callable, kwargs\n    )\n\n\nclass _patch_dict(object):\n    \"\"\"\n    Patch a dictionary, or dictionary like object, and restore the dictionary\n    to its original state after the test.\n\n    `in_dict` can be a dictionary or a mapping like container. If it is a\n    mapping then it must at least support getting, setting and deleting items\n    plus iterating over keys.\n\n    `in_dict` can also be a string specifying the name of the dictionary, which\n    will then be fetched by importing it.\n\n    `values` can be a dictionary of values to set in the dictionary. `values`\n    can also be an iterable of `(key, value)` pairs.\n\n    If `clear` is True then the dictionary will be cleared before the new\n    values are set.\n\n    `patch.dict` can also be called with arbitrary keyword arguments to set\n    values in the dictionary::\n\n        with patch.dict('sys.modules', mymodule=Mock(), other_module=Mock()):\n            ...\n\n    `patch.dict` can be used as a context manager, decorator or class\n    decorator. When used as a class decorator `patch.dict` honours\n    `patch.TEST_PREFIX` for choosing which methods to wrap.\n    \"\"\"\n\n    def __init__(self, in_dict, values=(), clear=False, **kwargs):\n        if isinstance(in_dict, str):\n            in_dict = _importer(in_dict)\n        self.in_dict = in_dict\n        # support any argument supported by dict(...) constructor\n        self.values = dict(values)\n        self.values.update(kwargs)\n        self.clear = clear\n        self._original = None\n\n\n    def __call__(self, f):\n        if isinstance(f, type):\n            return self.decorate_class(f)\n        @wraps(f)\n        def _inner(*args, **kw):\n            self._patch_dict()\n            try:\n                return f(*args, **kw)\n            finally:\n                self._unpatch_dict()\n\n        return _inner\n\n\n    def decorate_class(self, klass):\n        for attr in dir(klass):\n            attr_value = getattr(klass, attr)\n            if (attr.startswith(patch.TEST_PREFIX) and\n                 hasattr(attr_value, \"__call__\")):\n                decorator = _patch_dict(self.in_dict, self.values, self.clear)\n                decorated = decorator(attr_value)\n                setattr(klass, attr, decorated)\n        return klass\n\n\n    def __enter__(self):\n        \"\"\"Patch the dict.\"\"\"\n        self._patch_dict()\n\n\n    def _patch_dict(self):\n        values = self.values\n        in_dict = self.in_dict\n        clear = self.clear\n\n        try:\n            original = in_dict.copy()\n        except AttributeError:\n            # dict like object with no copy method\n            # must support iteration over keys\n            original = {}\n            for key in in_dict:\n                original[key] = in_dict[key]\n        self._original = original\n\n        if clear:\n            _clear_dict(in_dict)\n\n        try:\n            in_dict.update(values)\n        except AttributeError:\n            # dict like object with no update method\n            for key in values:\n                in_dict[key] = values[key]\n\n\n    def _unpatch_dict(self):\n        in_dict = self.in_dict\n        original = self._original\n\n        _clear_dict(in_dict)\n\n        try:\n            in_dict.update(original)\n        except AttributeError:\n            for key in original:\n                in_dict[key] = original[key]\n\n\n    def __exit__(self, *args):\n        \"\"\"Unpatch the dict.\"\"\"\n        self._unpatch_dict()\n        return False\n\n    start = __enter__\n    stop = __exit__\n\n\ndef _clear_dict(in_dict):\n    try:\n        in_dict.clear()\n    except AttributeError:\n        keys = list(in_dict)\n        for key in keys:\n            del in_dict[key]\n\n\ndef _patch_stopall():\n    \"\"\"Stop all active patches.\"\"\"\n    for patch in list(_patch._active_patches):\n        patch.stop()\n\n\npatch.object = _patch_object\npatch.dict = _patch_dict\npatch.multiple = _patch_multiple\npatch.stopall = _patch_stopall\npatch.TEST_PREFIX = 'test'\n\nmagic_methods = (\n    \"lt le gt ge eq ne \"\n    \"getitem setitem delitem \"\n    \"len contains iter \"\n    \"hash str sizeof \"\n    \"enter exit \"\n    \"divmod neg pos abs invert \"\n    \"complex int float index \"\n    \"trunc floor ceil \"\n    \"bool next \"\n)\n\nnumerics = \"add sub mul div floordiv mod lshift rshift and xor or pow \"\ninplace = ' '.join('i%s' % n for n in numerics.split())\nright = ' '.join('r%s' % n for n in numerics.split())\n\n# not including __prepare__, __instancecheck__, __subclasscheck__\n# (as they are metaclass methods)\n# __del__ is not supported at all as it causes problems if it exists\n\n_non_defaults = set('__%s__' % method for method in [\n    'get', 'set', 'delete', 'reversed', 'missing', 'reduce', 'reduce_ex',\n    'getinitargs', 'getnewargs', 'getstate', 'setstate', 'getformat',\n    'setformat', 'repr', 'dir', 'subclasses', 'format',\n])\n\n\ndef _get_method(name, func):\n    \"Turns a callable object (like a mock) into a real function\"\n    def method(self, *args, **kw):\n        return func(self, *args, **kw)\n    method.__name__ = name\n    return method\n\n\n_magics = set(\n    '__%s__' % method for method in\n    ' '.join([magic_methods, numerics, inplace, right]).split()\n)\n\n_all_magics = _magics | _non_defaults\n\n_unsupported_magics = set([\n    '__getattr__', '__setattr__',\n    '__init__', '__new__', '__prepare__'\n    '__instancecheck__', '__subclasscheck__',\n    '__del__'\n])\n\n_calculate_return_value = {\n    '__hash__': lambda self: object.__hash__(self),\n    '__str__': lambda self: object.__str__(self),\n    '__sizeof__': lambda self: object.__sizeof__(self),\n}\n\n_return_values = {\n    '__lt__': NotImplemented,\n    '__gt__': NotImplemented,\n    '__le__': NotImplemented,\n    '__ge__': NotImplemented,\n    '__int__': 1,\n    '__contains__': False,\n    '__len__': 0,\n    '__exit__': False,\n    '__complex__': 1j,\n    '__float__': 1.0,\n    '__bool__': True,\n    '__index__': 1,\n}\n\n\ndef _get_eq(self):\n    def __eq__(other):\n        ret_val = self.__eq__._mock_return_value\n        if ret_val is not DEFAULT:\n            return ret_val\n        return self is other\n    return __eq__\n\ndef _get_ne(self):\n    def __ne__(other):\n        if self.__ne__._mock_return_value is not DEFAULT:\n            return DEFAULT\n        return self is not other\n    return __ne__\n\ndef _get_iter(self):\n    def __iter__():\n        ret_val = self.__iter__._mock_return_value\n        if ret_val is DEFAULT:\n            return iter([])\n        # if ret_val was already an iterator, then calling iter on it should\n        # return the iterator unchanged\n        return iter(ret_val)\n    return __iter__\n\n_side_effect_methods = {\n    '__eq__': _get_eq,\n    '__ne__': _get_ne,\n    '__iter__': _get_iter,\n}\n\n\n\ndef _set_return_value(mock, method, name):\n    fixed = _return_values.get(name, DEFAULT)\n    if fixed is not DEFAULT:\n        method.return_value = fixed\n        return\n\n    return_calulator = _calculate_return_value.get(name)\n    if return_calulator is not None:\n        try:\n            return_value = return_calulator(mock)\n        except AttributeError:\n            # XXXX why do we return AttributeError here?\n            #      set it as a side_effect instead?\n            return_value = AttributeError(name)\n        method.return_value = return_value\n        return\n\n    side_effector = _side_effect_methods.get(name)\n    if side_effector is not None:\n        method.side_effect = side_effector(mock)\n\n\n\nclass MagicMixin(object):\n    def __init__(self, *args, **kw):\n        _safe_super(MagicMixin, self).__init__(*args, **kw)\n        self._mock_set_magics()\n\n\n    def _mock_set_magics(self):\n        these_magics = _magics\n\n        if self._mock_methods is not None:\n            these_magics = _magics.intersection(self._mock_methods)\n\n            remove_magics = set()\n            remove_magics = _magics - these_magics\n\n            for entry in remove_magics:\n                if entry in type(self).__dict__:\n                    # remove unneeded magic methods\n                    delattr(self, entry)\n\n        # don't overwrite existing attributes if called a second time\n        these_magics = these_magics - set(type(self).__dict__)\n\n        _type = type(self)\n        for entry in these_magics:\n            setattr(_type, entry, MagicProxy(entry, self))\n\n\n\nclass NonCallableMagicMock(MagicMixin, NonCallableMock):\n    \"\"\"A version of `MagicMock` that isn't callable.\"\"\"\n    def mock_add_spec(self, spec, spec_set=False):\n        \"\"\"Add a spec to a mock. `spec` can either be an object or a\n        list of strings. Only attributes on the `spec` can be fetched as\n        attributes from the mock.\n\n        If `spec_set` is True then only attributes on the spec can be set.\"\"\"\n        self._mock_add_spec(spec, spec_set)\n        self._mock_set_magics()\n\n\n\nclass MagicMock(MagicMixin, Mock):\n    \"\"\"\n    MagicMock is a subclass of Mock with default implementations\n    of most of the magic methods. You can use MagicMock without having to\n    configure the magic methods yourself.\n\n    If you use the `spec` or `spec_set` arguments then *only* magic\n    methods that exist in the spec will be created.\n\n    Attributes and the return value of a `MagicMock` will also be `MagicMocks`.\n    \"\"\"\n    def mock_add_spec(self, spec, spec_set=False):\n        \"\"\"Add a spec to a mock. `spec` can either be an object or a\n        list of strings. Only attributes on the `spec` can be fetched as\n        attributes from the mock.\n\n        If `spec_set` is True then only attributes on the spec can be set.\"\"\"\n        self._mock_add_spec(spec, spec_set)\n        self._mock_set_magics()\n\n\n\nclass MagicProxy(object):\n    def __init__(self, name, parent):\n        self.name = name\n        self.parent = parent\n\n    def __call__(self, *args, **kwargs):\n        m = self.create_mock()\n        return m(*args, **kwargs)\n\n    def create_mock(self):\n        entry = self.name\n        parent = self.parent\n        m = parent._get_child_mock(name=entry, _new_name=entry,\n                                   _new_parent=parent)\n        setattr(parent, entry, m)\n        _set_return_value(parent, m, entry)\n        return m\n\n    def __get__(self, obj, _type=None):\n        return self.create_mock()\n\n\n\nclass _ANY(object):\n    \"A helper object that compares equal to everything.\"\n\n    def __eq__(self, other):\n        return True\n\n    def __ne__(self, other):\n        return False\n\n    def __repr__(self):\n        return '<ANY>'\n\nANY = _ANY()\n\n\n\ndef _format_call_signature(name, args, kwargs):\n    message = '%s(%%s)' % name\n    formatted_args = ''\n    args_string = ', '.join([repr(arg) for arg in args])\n    kwargs_string = ', '.join([\n        '%s=%r' % (key, value) for key, value in kwargs.items()\n    ])\n    if args_string:\n        formatted_args = args_string\n    if kwargs_string:\n        if formatted_args:\n            formatted_args += ', '\n        formatted_args += kwargs_string\n\n    return message % formatted_args\n\n\n\nclass _Call(tuple):\n    \"\"\"\n    A tuple for holding the results of a call to a mock, either in the form\n    `(args, kwargs)` or `(name, args, kwargs)`.\n\n    If args or kwargs are empty then a call tuple will compare equal to\n    a tuple without those values. This makes comparisons less verbose::\n\n        _Call(('name', (), {})) == ('name',)\n        _Call(('name', (1,), {})) == ('name', (1,))\n        _Call(((), {'a': 'b'})) == ({'a': 'b'},)\n\n    The `_Call` object provides a useful shortcut for comparing with call::\n\n        _Call(((1, 2), {'a': 3})) == call(1, 2, a=3)\n        _Call(('foo', (1, 2), {'a': 3})) == call.foo(1, 2, a=3)\n\n    If the _Call has no name then it will match any name.\n    \"\"\"\n    def __new__(cls, value=(), name=None, parent=None, two=False,\n                from_kall=True):\n        name = ''\n        args = ()\n        kwargs = {}\n        _len = len(value)\n        if _len == 3:\n            name, args, kwargs = value\n        elif _len == 2:\n            first, second = value\n            if isinstance(first, str):\n                name = first\n                if isinstance(second, tuple):\n                    args = second\n                else:\n                    kwargs = second\n            else:\n                args, kwargs = first, second\n        elif _len == 1:\n            value, = value\n            if isinstance(value, str):\n                name = value\n            elif isinstance(value, tuple):\n                args = value\n            else:\n                kwargs = value\n\n        if two:\n            return tuple.__new__(cls, (args, kwargs))\n\n        return tuple.__new__(cls, (name, args, kwargs))\n\n\n    def __init__(self, value=(), name=None, parent=None, two=False,\n                 from_kall=True):\n        self.name = name\n        self.parent = parent\n        self.from_kall = from_kall\n\n\n    def __eq__(self, other):\n        if other is ANY:\n            return True\n        try:\n            len_other = len(other)\n        except TypeError:\n            return False\n\n        self_name = ''\n        if len(self) == 2:\n            self_args, self_kwargs = self\n        else:\n            self_name, self_args, self_kwargs = self\n\n        other_name = ''\n        if len_other == 0:\n            other_args, other_kwargs = (), {}\n        elif len_other == 3:\n            other_name, other_args, other_kwargs = other\n        elif len_other == 1:\n            value, = other\n            if isinstance(value, tuple):\n                other_args = value\n                other_kwargs = {}\n            elif isinstance(value, str):\n                other_name = value\n                other_args, other_kwargs = (), {}\n            else:\n                other_args = ()\n                other_kwargs = value\n        else:\n            # len 2\n            # could be (name, args) or (name, kwargs) or (args, kwargs)\n            first, second = other\n            if isinstance(first, str):\n                other_name = first\n                if isinstance(second, tuple):\n                    other_args, other_kwargs = second, {}\n                else:\n                    other_args, other_kwargs = (), second\n            else:\n                other_args, other_kwargs = first, second\n\n        if self_name and other_name != self_name:\n            return False\n\n        # this order is important for ANY to work!\n        return (other_args, other_kwargs) == (self_args, self_kwargs)\n\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n\n    def __call__(self, *args, **kwargs):\n        if self.name is None:\n            return _Call(('', args, kwargs), name='()')\n\n        name = self.name + '()'\n        return _Call((self.name, args, kwargs), name=name, parent=self)\n\n\n    def __getattr__(self, attr):\n        if self.name is None:\n            return _Call(name=attr, from_kall=False)\n        name = '%s.%s' % (self.name, attr)\n        return _Call(name=name, parent=self, from_kall=False)\n\n\n    def __repr__(self):\n        if not self.from_kall:\n            name = self.name or 'call'\n            if name.startswith('()'):\n                name = 'call%s' % name\n            return name\n\n        if len(self) == 2:\n            name = 'call'\n            args, kwargs = self\n        else:\n            name, args, kwargs = self\n            if not name:\n                name = 'call'\n            elif not name.startswith('()'):\n                name = 'call.%s' % name\n            else:\n                name = 'call%s' % name\n        return _format_call_signature(name, args, kwargs)\n\n\n    def call_list(self):\n        \"\"\"For a call object that represents multiple calls, `call_list`\n        returns a list of all the intermediate calls as well as the\n        final call.\"\"\"\n        vals = []\n        thing = self\n        while thing is not None:\n            if thing.from_kall:\n                vals.append(thing)\n            thing = thing.parent\n        return _CallList(reversed(vals))\n\n\ncall = _Call(from_kall=False)\n\n\n\ndef create_autospec(spec, spec_set=False, instance=False, _parent=None,\n                    _name=None, **kwargs):\n    \"\"\"Create a mock object using another object as a spec. Attributes on the\n    mock will use the corresponding attribute on the `spec` object as their\n    spec.\n\n    Functions or methods being mocked will have their arguments checked\n    to check that they are called with the correct signature.\n\n    If `spec_set` is True then attempting to set attributes that don't exist\n    on the spec object will raise an `AttributeError`.\n\n    If a class is used as a spec then the return value of the mock (the\n    instance of the class) will have the same spec. You can use a class as the\n    spec for an instance object by passing `instance=True`. The returned mock\n    will only be callable if instances of the mock are callable.\n\n    `create_autospec` also takes arbitrary keyword arguments that are passed to\n    the constructor of the created mock.\"\"\"\n    if _is_list(spec):\n        # can't pass a list instance to the mock constructor as it will be\n        # interpreted as a list of strings\n        spec = type(spec)\n\n    is_type = isinstance(spec, type)\n\n    _kwargs = {'spec': spec}\n    if spec_set:\n        _kwargs = {'spec_set': spec}\n    elif spec is None:\n        # None we mock with a normal mock without a spec\n        _kwargs = {}\n\n    _kwargs.update(kwargs)\n\n    Klass = MagicMock\n    if type(spec) in DescriptorTypes:\n        # descriptors don't have a spec\n        # because we don't know what type they return\n        _kwargs = {}\n    elif not _callable(spec):\n        Klass = NonCallableMagicMock\n    elif is_type and instance and not _instance_callable(spec):\n        Klass = NonCallableMagicMock\n\n    _new_name = _name\n    if _parent is None:\n        # for a top level object no _new_name should be set\n        _new_name = ''\n\n    mock = Klass(parent=_parent, _new_parent=_parent, _new_name=_new_name,\n                 name=_name, **_kwargs)\n\n    if isinstance(spec, FunctionTypes):\n        # should only happen at the top level because we don't\n        # recurse for functions\n        mock = _set_signature(mock, spec)\n    else:\n        _check_signature(spec, mock, is_type, instance)\n\n    if _parent is not None and not instance:\n        _parent._mock_children[_name] = mock\n\n    if is_type and not instance and 'return_value' not in kwargs:\n        mock.return_value = create_autospec(spec, spec_set, instance=True,\n                                            _name='()', _parent=mock)\n\n    for entry in dir(spec):\n        if _is_magic(entry):\n            # MagicMock already does the useful magic methods for us\n            continue\n\n        # XXXX do we need a better way of getting attributes without\n        # triggering code execution (?) Probably not - we need the actual\n        # object to mock it so we would rather trigger a property than mock\n        # the property descriptor. Likewise we want to mock out dynamically\n        # provided attributes.\n        # XXXX what about attributes that raise exceptions other than\n        # AttributeError on being fetched?\n        # we could be resilient against it, or catch and propagate the\n        # exception when the attribute is fetched from the mock\n        try:\n            original = getattr(spec, entry)\n        except AttributeError:\n            continue\n\n        kwargs = {'spec': original}\n        if spec_set:\n            kwargs = {'spec_set': original}\n\n        if not isinstance(original, FunctionTypes):\n            new = _SpecState(original, spec_set, mock, entry, instance)\n            mock._mock_children[entry] = new\n        else:\n            parent = mock\n            if isinstance(spec, FunctionTypes):\n                parent = mock.mock\n\n            new = MagicMock(parent=parent, name=entry, _new_name=entry,\n                            _new_parent=parent, **kwargs)\n            mock._mock_children[entry] = new\n            skipfirst = _must_skip(spec, entry, is_type)\n            _check_signature(original, new, skipfirst=skipfirst)\n\n        # so functions created with _set_signature become instance attributes,\n        # *plus* their underlying mock exists in _mock_children of the parent\n        # mock. Adding to _mock_children may be unnecessary where we are also\n        # setting as an instance attribute?\n        if isinstance(new, FunctionTypes):\n            setattr(mock, entry, new)\n\n    return mock\n\n\ndef _must_skip(spec, entry, is_type):\n    if not isinstance(spec, type):\n        if entry in getattr(spec, '__dict__', {}):\n            # instance attribute - shouldn't skip\n            return False\n        spec = spec.__class__\n\n    for klass in spec.__mro__:\n        result = klass.__dict__.get(entry, DEFAULT)\n        if result is DEFAULT:\n            continue\n        if isinstance(result, (staticmethod, classmethod)):\n            return False\n        return is_type\n\n    # shouldn't get here unless function is a dynamically provided attribute\n    # XXXX untested behaviour\n    return is_type\n\n\ndef _get_class(obj):\n    try:\n        return obj.__class__\n    except AttributeError:\n        # it is possible for objects to have no __class__\n        return type(obj)\n\n\nclass _SpecState(object):\n\n    def __init__(self, spec, spec_set=False, parent=None,\n                 name=None, ids=None, instance=False):\n        self.spec = spec\n        self.ids = ids\n        self.spec_set = spec_set\n        self.parent = parent\n        self.instance = instance\n        self.name = name\n\n\nFunctionTypes = (\n    # python function\n    type(create_autospec),\n    # instance method\n    type(ANY.__eq__),\n)\n\n\nfile_spec = None\n\n\ndef mock_open(mock=None, read_data=''):\n    \"\"\"\n    A helper function to create a mock to replace the use of `open`. It works\n    for `open` called directly or used as a context manager.\n\n    The `mock` argument is the mock object to configure. If `None` (the\n    default) then a `MagicMock` will be created for you, with the API limited\n    to methods or attributes available on standard file handles.\n\n    `read_data` is a string for the `read` method of the file handle to return.\n    This is an empty string by default.\n    \"\"\"\n    global file_spec\n    if file_spec is None:\n        import _io\n        file_spec = list(set(dir(_io.TextIOWrapper)).union(set(dir(_io.BytesIO))))\n\n    if mock is None:\n        mock = MagicMock(name='open', spec=open)\n\n    handle = MagicMock(spec=file_spec)\n    handle.write.return_value = None\n    handle.__enter__.return_value = handle\n    handle.read.return_value = read_data\n\n    mock.return_value = handle\n    return mock\n\n\nclass PropertyMock(Mock):\n    \"\"\"\n    A mock intended to be used as a property, or other descriptor, on a class.\n    `PropertyMock` provides `__get__` and `__set__` methods so you can specify\n    a return value when it is fetched.\n\n    Fetching a `PropertyMock` instance from an object calls the mock, with\n    no args. Setting it calls the mock with the value being set.\n    \"\"\"\n    def _get_child_mock(self, **kwargs):\n        return MagicMock(**kwargs)\n\n    def __get__(self, obj, obj_type):\n        return self()\n    def __set__(self, obj, val):\n        self(val)\n"], "test.test_int": [".py", "import sys\n\nimport unittest\nfrom test.support import run_unittest\n\nL = [\n        ('0', 0),\n        ('1', 1),\n        ('9', 9),\n        ('10', 10),\n        ('99', 99),\n        ('100', 100),\n        ('314', 314),\n        (' 314', 314),\n        ('314 ', 314),\n        ('  \\t\\t  314  \\t\\t  ', 314),\n        (repr(sys.maxsize), sys.maxsize),\n        ('  1x', ValueError),\n        ('  1  ', 1),\n        ('  1\\02  ', ValueError),\n        ('', ValueError),\n        (' ', ValueError),\n        ('  \\t\\t  ', ValueError),\n        (\"\\u0200\", ValueError)\n]\n\nclass IntTestCases(unittest.TestCase):\n\n    def test_basic(self):\n        self.assertEqual(int(314), 314)\n        self.assertEqual(int(3.14), 3)\n        # Check that conversion from float truncates towards zero\n        self.assertEqual(int(-3.14), -3)\n        self.assertEqual(int(3.9), 3)\n        self.assertEqual(int(-3.9), -3)\n        self.assertEqual(int(3.5), 3)\n        self.assertEqual(int(-3.5), -3)\n        self.assertEqual(int(\"-3\"), -3)\n        self.assertEqual(int(\" -3 \"), -3)\n        self.assertEqual(int(\"\\N{EM SPACE}-3\\N{EN SPACE}\"), -3)\n        # Different base:\n        self.assertEqual(int(\"10\",16), 16)\n        # Test conversion from strings and various anomalies\n        for s, v in L:\n            for sign in \"\", \"+\", \"-\":\n                for prefix in \"\", \" \", \"\\t\", \"  \\t\\t  \":\n                    ss = prefix + sign + s\n                    vv = v\n                    if sign == \"-\" and v is not ValueError:\n                        vv = -v\n                    try:\n                        self.assertEqual(int(ss), vv)\n                    except ValueError:\n                        pass\n\n        s = repr(-1-sys.maxsize)\n        x = int(s)\n        self.assertEqual(x+1, -sys.maxsize)\n        self.assertIsInstance(x, int)\n        # should return int\n        self.assertEqual(int(s[1:]), sys.maxsize+1)\n\n        # should return int\n        x = int(1e100)\n        self.assertIsInstance(x, int)\n        x = int(-1e100)\n        self.assertIsInstance(x, int)\n\n\n        # SF bug 434186:  0x80000000/2 != 0x80000000>>1.\n        # Worked by accident in Windows release build, but failed in debug build.\n        # Failed in all Linux builds.\n        x = -1-sys.maxsize\n        self.assertEqual(x >> 1, x//2)\n\n        self.assertRaises(ValueError, int, '123\\0')\n        self.assertRaises(ValueError, int, '53', 40)\n\n        # SF bug 1545497: embedded NULs were not detected with\n        # explicit base\n        self.assertRaises(ValueError, int, '123\\0', 10)\n        self.assertRaises(ValueError, int, '123\\x00 245', 20)\n\n        x = int('1' * 600)\n        self.assertIsInstance(x, int)\n\n\n        self.assertRaises(TypeError, int, 1, 12)\n\n        self.assertEqual(int('0o123', 0), 83)\n        self.assertEqual(int('0x123', 16), 291)\n\n        # Bug 1679: \"0x\" is not a valid hex literal\n        self.assertRaises(ValueError, int, \"0x\", 16)\n        self.assertRaises(ValueError, int, \"0x\", 0)\n\n        self.assertRaises(ValueError, int, \"0o\", 8)\n        self.assertRaises(ValueError, int, \"0o\", 0)\n\n        self.assertRaises(ValueError, int, \"0b\", 2)\n        self.assertRaises(ValueError, int, \"0b\", 0)\n\n        # Bug #3236: Return small longs from PyLong_FromString\n        self.assertTrue(int(\"10\") is 10)\n        self.assertTrue(int(\"-1\") is -1)\n\n        # SF bug 1334662: int(string, base) wrong answers\n        # Various representations of 2**32 evaluated to 0\n        # rather than 2**32 in previous versions\n\n        self.assertEqual(int('100000000000000000000000000000000', 2), 4294967296)\n        self.assertEqual(int('102002022201221111211', 3), 4294967296)\n        self.assertEqual(int('10000000000000000', 4), 4294967296)\n        self.assertEqual(int('32244002423141', 5), 4294967296)\n        self.assertEqual(int('1550104015504', 6), 4294967296)\n        self.assertEqual(int('211301422354', 7), 4294967296)\n        self.assertEqual(int('40000000000', 8), 4294967296)\n        self.assertEqual(int('12068657454', 9), 4294967296)\n        self.assertEqual(int('4294967296', 10), 4294967296)\n        self.assertEqual(int('1904440554', 11), 4294967296)\n        self.assertEqual(int('9ba461594', 12), 4294967296)\n        self.assertEqual(int('535a79889', 13), 4294967296)\n        self.assertEqual(int('2ca5b7464', 14), 4294967296)\n        self.assertEqual(int('1a20dcd81', 15), 4294967296)\n        self.assertEqual(int('100000000', 16), 4294967296)\n        self.assertEqual(int('a7ffda91', 17), 4294967296)\n        self.assertEqual(int('704he7g4', 18), 4294967296)\n        self.assertEqual(int('4f5aff66', 19), 4294967296)\n        self.assertEqual(int('3723ai4g', 20), 4294967296)\n        self.assertEqual(int('281d55i4', 21), 4294967296)\n        self.assertEqual(int('1fj8b184', 22), 4294967296)\n        self.assertEqual(int('1606k7ic', 23), 4294967296)\n        self.assertEqual(int('mb994ag', 24), 4294967296)\n        self.assertEqual(int('hek2mgl', 25), 4294967296)\n        self.assertEqual(int('dnchbnm', 26), 4294967296)\n        self.assertEqual(int('b28jpdm', 27), 4294967296)\n        self.assertEqual(int('8pfgih4', 28), 4294967296)\n        self.assertEqual(int('76beigg', 29), 4294967296)\n        self.assertEqual(int('5qmcpqg', 30), 4294967296)\n        self.assertEqual(int('4q0jto4', 31), 4294967296)\n        self.assertEqual(int('4000000', 32), 4294967296)\n        self.assertEqual(int('3aokq94', 33), 4294967296)\n        self.assertEqual(int('2qhxjli', 34), 4294967296)\n        self.assertEqual(int('2br45qb', 35), 4294967296)\n        self.assertEqual(int('1z141z4', 36), 4294967296)\n\n        # tests with base 0\n        # this fails on 3.0, but in 2.x the old octal syntax is allowed\n        self.assertEqual(int(' 0o123  ', 0), 83)\n        self.assertEqual(int(' 0o123  ', 0), 83)\n        self.assertEqual(int('000', 0), 0)\n        self.assertEqual(int('0o123', 0), 83)\n        self.assertEqual(int('0x123', 0), 291)\n        self.assertEqual(int('0b100', 0), 4)\n        self.assertEqual(int(' 0O123   ', 0), 83)\n        self.assertEqual(int(' 0X123  ', 0), 291)\n        self.assertEqual(int(' 0B100 ', 0), 4)\n\n        # without base still base 10\n        self.assertEqual(int('0123'), 123)\n        self.assertEqual(int('0123', 10), 123)\n\n        # tests with prefix and base != 0\n        self.assertEqual(int('0x123', 16), 291)\n        self.assertEqual(int('0o123', 8), 83)\n        self.assertEqual(int('0b100', 2), 4)\n        self.assertEqual(int('0X123', 16), 291)\n        self.assertEqual(int('0O123', 8), 83)\n        self.assertEqual(int('0B100', 2), 4)\n\n        # the code has special checks for the first character after the\n        #  type prefix\n        self.assertRaises(ValueError, int, '0b2', 2)\n        self.assertRaises(ValueError, int, '0b02', 2)\n        self.assertRaises(ValueError, int, '0B2', 2)\n        self.assertRaises(ValueError, int, '0B02', 2)\n        self.assertRaises(ValueError, int, '0o8', 8)\n        self.assertRaises(ValueError, int, '0o08', 8)\n        self.assertRaises(ValueError, int, '0O8', 8)\n        self.assertRaises(ValueError, int, '0O08', 8)\n        self.assertRaises(ValueError, int, '0xg', 16)\n        self.assertRaises(ValueError, int, '0x0g', 16)\n        self.assertRaises(ValueError, int, '0Xg', 16)\n        self.assertRaises(ValueError, int, '0X0g', 16)\n\n        # SF bug 1334662: int(string, base) wrong answers\n        # Checks for proper evaluation of 2**32 + 1\n        self.assertEqual(int('100000000000000000000000000000001', 2), 4294967297)\n        self.assertEqual(int('102002022201221111212', 3), 4294967297)\n        self.assertEqual(int('10000000000000001', 4), 4294967297)\n        self.assertEqual(int('32244002423142', 5), 4294967297)\n        self.assertEqual(int('1550104015505', 6), 4294967297)\n        self.assertEqual(int('211301422355', 7), 4294967297)\n        self.assertEqual(int('40000000001', 8), 4294967297)\n        self.assertEqual(int('12068657455', 9), 4294967297)\n        self.assertEqual(int('4294967297', 10), 4294967297)\n        self.assertEqual(int('1904440555', 11), 4294967297)\n        self.assertEqual(int('9ba461595', 12), 4294967297)\n        self.assertEqual(int('535a7988a', 13), 4294967297)\n        self.assertEqual(int('2ca5b7465', 14), 4294967297)\n        self.assertEqual(int('1a20dcd82', 15), 4294967297)\n        self.assertEqual(int('100000001', 16), 4294967297)\n        self.assertEqual(int('a7ffda92', 17), 4294967297)\n        self.assertEqual(int('704he7g5', 18), 4294967297)\n        self.assertEqual(int('4f5aff67', 19), 4294967297)\n        self.assertEqual(int('3723ai4h', 20), 4294967297)\n        self.assertEqual(int('281d55i5', 21), 4294967297)\n        self.assertEqual(int('1fj8b185', 22), 4294967297)\n        self.assertEqual(int('1606k7id', 23), 4294967297)\n        self.assertEqual(int('mb994ah', 24), 4294967297)\n        self.assertEqual(int('hek2mgm', 25), 4294967297)\n        self.assertEqual(int('dnchbnn', 26), 4294967297)\n        self.assertEqual(int('b28jpdn', 27), 4294967297)\n        self.assertEqual(int('8pfgih5', 28), 4294967297)\n        self.assertEqual(int('76beigh', 29), 4294967297)\n        self.assertEqual(int('5qmcpqh', 30), 4294967297)\n        self.assertEqual(int('4q0jto5', 31), 4294967297)\n        self.assertEqual(int('4000001', 32), 4294967297)\n        self.assertEqual(int('3aokq95', 33), 4294967297)\n        self.assertEqual(int('2qhxjlj', 34), 4294967297)\n        self.assertEqual(int('2br45qc', 35), 4294967297)\n        self.assertEqual(int('1z141z5', 36), 4294967297)\n\n    def test_intconversion(self):\n        # Test __int__()\n        class ClassicMissingMethods:\n            pass\n        self.assertRaises(TypeError, int, ClassicMissingMethods())\n\n        class MissingMethods(object):\n            pass\n        self.assertRaises(TypeError, int, MissingMethods())\n\n        class Foo0:\n            def __int__(self):\n                return 42\n\n        class Foo1(object):\n            def __int__(self):\n                return 42\n\n        class Foo2(int):\n            def __int__(self):\n                return 42\n\n        class Foo3(int):\n            def __int__(self):\n                return self\n\n        class Foo4(int):\n            def __int__(self):\n                return 42\n\n        class Foo5(int):\n            def __int__(self):\n                return 42.\n\n        self.assertEqual(int(Foo0()), 42)\n        self.assertEqual(int(Foo1()), 42)\n        self.assertEqual(int(Foo2()), 42)\n        self.assertEqual(int(Foo3()), 0)\n        self.assertEqual(int(Foo4()), 42)\n        self.assertRaises(TypeError, int, Foo5())\n\n        class Classic:\n            pass\n        for base in (object, Classic):\n            class IntOverridesTrunc(base):\n                def __int__(self):\n                    return 42\n                def __trunc__(self):\n                    return -12\n            self.assertEqual(int(IntOverridesTrunc()), 42)\n\n            class JustTrunc(base):\n                def __trunc__(self):\n                    return 42\n            self.assertEqual(int(JustTrunc()), 42)\n\n            for trunc_result_base in (object, Classic):\n                class Integral(trunc_result_base):\n                    def __int__(self):\n                        return 42\n\n                class TruncReturnsNonInt(base):\n                    def __trunc__(self):\n                        return Integral()\n                self.assertEqual(int(TruncReturnsNonInt()), 42)\n\n                class NonIntegral(trunc_result_base):\n                    def __trunc__(self):\n                        # Check that we avoid infinite recursion.\n                        return NonIntegral()\n\n                class TruncReturnsNonIntegral(base):\n                    def __trunc__(self):\n                        return NonIntegral()\n                try:\n                    int(TruncReturnsNonIntegral())\n                except TypeError as e:\n                    self.assertEqual(str(e),\n                                      \"__trunc__ returned non-Integral\"\n                                      \" (type NonIntegral)\")\n                else:\n                    self.fail(\"Failed to raise TypeError with %s\" %\n                              ((base, trunc_result_base),))\n\n    def test_error_message(self):\n        testlist = ('\\xbd', '123\\xbd', '  123 456  ')\n        for s in testlist:\n            try:\n                int(s)\n            except ValueError as e:\n                self.assertIn(s.strip(), e.args[0])\n            else:\n                self.fail(\"Expected int(%r) to raise a ValueError\", s)\n\ndef test_main():\n    run_unittest(IntTestCases)\n\nif __name__ == \"__main__\":\n    test_main()\n"], "_os": [".js", "var $module=(function($B){\n\n    var _b_ = $B.builtins\n    return {\n        random:function(){return _b_.float(Math.random())},\n        randint:function(a,b){return _b_.int(Math.floor(Math.random()*(b-a)+a))}\n    }\n})(__BRYTHON__)\n"], "browser.websocket": [".py", "from _websocket import *"], "_imp": [".py", "\"\"\"(Extremely) low-level import machinery bits as used by importlib and imp.\"\"\"\n\n\nclass __loader__(object):pass\n\ndef _fix_co_filename(*args,**kw):\n    raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:_fix_co_filename'))\n\ndef acquire_lock(*args,**kw):\n    \"\"\"acquire_lock() -> None    Acquires the interpreter's import lock for the current thread.\n    This lock should be used by import hooks to ensure thread-safety\n    when importing modules.\n    On platforms without threads, this function does nothing.\"\"\"\n    raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:acquire_lock'))\n\ndef extension_suffixes(*args,**kw):\n    \"\"\"extension_suffixes() -> list of strings    Returns the list of file suffixes used to identify extension modules.\"\"\"\n    return ['.pyd']\n\ndef get_frozen_object(*args,**kw):\n    raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:get_frozen_object'))\n\ndef init_builtin(module,*args,**kw):\n    return __import__(module)\n\ndef init_frozen(*args,**kw):\n    raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:init_frozen'))\n\ndef is_builtin(*args,**kw):\n    raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:is_builtin'))\n\ndef is_frozen(*args,**kw):\n    raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:is_frozen'))\n\ndef is_frozen_package(*args,**kw):\n    raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:is_frozen_package'))\n\ndef load_dynamic(*args,**kw):\n    raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:load_dynamic'))\n\ndef lock_held(*args,**kw):\n    \"\"\"lock_held() -> boolean    Return True if the import lock is currently held, else False.\n    On platforms without threads, return False.\"\"\"\n\n    raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:lock_held'))\n\ndef release_lock(*args,**kw):\n    \"\"\"release_lock() -> None    Release the interpreter's import lock.\n    On platforms without threads, this function does nothing.\"\"\"\n\n    raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:release_lock'))\n"], "bisect": [".py", "\"\"\"Bisection algorithms.\"\"\"\n\ndef insort_right(a, x, lo=0, hi=None):\n    \"\"\"Insert item x in list a, and keep it sorted assuming a is sorted.\n\n    If x is already in a, insert it to the right of the rightmost x.\n\n    Optional args lo (default 0) and hi (default len(a)) bound the\n    slice of a to be searched.\n    \"\"\"\n\n    if lo < 0:\n        raise ValueError('lo must be non-negative')\n    if hi is None:\n        hi = len(a)\n    while lo < hi:\n        mid = (lo+hi)//2\n        if x < a[mid]: hi = mid\n        else: lo = mid+1\n    a.insert(lo, x)\n\ninsort = insort_right   # backward compatibility\n\ndef bisect_right(a, x, lo=0, hi=None):\n    \"\"\"Return the index where to insert item x in list a, assuming a is sorted.\n\n    The return value i is such that all e in a[:i] have e <= x, and all e in\n    a[i:] have e > x.  So if x already appears in the list, a.insert(x) will\n    insert just after the rightmost x already there.\n\n    Optional args lo (default 0) and hi (default len(a)) bound the\n    slice of a to be searched.\n    \"\"\"\n\n    if lo < 0:\n        raise ValueError('lo must be non-negative')\n    if hi is None:\n        hi = len(a)\n    while lo < hi:\n        mid = (lo+hi)//2\n        if x < a[mid]: hi = mid\n        else: lo = mid+1\n    return lo\n\nbisect = bisect_right   # backward compatibility\n\ndef insort_left(a, x, lo=0, hi=None):\n    \"\"\"Insert item x in list a, and keep it sorted assuming a is sorted.\n\n    If x is already in a, insert it to the left of the leftmost x.\n\n    Optional args lo (default 0) and hi (default len(a)) bound the\n    slice of a to be searched.\n    \"\"\"\n\n    if lo < 0:\n        raise ValueError('lo must be non-negative')\n    if hi is None:\n        hi = len(a)\n    while lo < hi:\n        mid = (lo+hi)//2\n        if a[mid] < x: lo = mid+1\n        else: hi = mid\n    a.insert(lo, x)\n\n\ndef bisect_left(a, x, lo=0, hi=None):\n    \"\"\"Return the index where to insert item x in list a, assuming a is sorted.\n\n    The return value i is such that all e in a[:i] have e < x, and all e in\n    a[i:] have e >= x.  So if x already appears in the list, a.insert(x) will\n    insert just before the leftmost x already there.\n\n    Optional args lo (default 0) and hi (default len(a)) bound the\n    slice of a to be searched.\n    \"\"\"\n\n    if lo < 0:\n        raise ValueError('lo must be non-negative')\n    if hi is None:\n        hi = len(a)\n    while lo < hi:\n        mid = (lo+hi)//2\n        if a[mid] < x: lo = mid+1\n        else: hi = mid\n    return lo\n\n# Overwrite above definitions with a fast C implementation\ntry:\n    from _bisect import *\nexcept ImportError:\n    pass\n"], "signal": [".py", "\"\"\"This module provides mechanisms to use signal handlers in Python.\n\nFunctions:\n\nalarm() -- cause SIGALRM after a specified time [Unix only]\nsetitimer() -- cause a signal (described below) after a specified\n               float time and the timer may restart then [Unix only]\ngetitimer() -- get current value of timer [Unix only]\nsignal() -- set the action for a given signal\ngetsignal() -- get the signal action for a given signal\npause() -- wait until a signal arrives [Unix only]\ndefault_int_handler() -- default SIGINT handler\n\nsignal constants:\nSIG_DFL -- used to refer to the system default handler\nSIG_IGN -- used to ignore the signal\nNSIG -- number of defined signals\nSIGINT, SIGTERM, etc. -- signal numbers\n\nitimer constants:\nITIMER_REAL -- decrements in real time, and delivers SIGALRM upon\n               expiration\nITIMER_VIRTUAL -- decrements only when the process is executing,\n               and delivers SIGVTALRM upon expiration\nITIMER_PROF -- decrements both when the process is executing and\n               when the system is executing on behalf of the process.\n               Coupled with ITIMER_VIRTUAL, this timer is usually\n               used to profile the time spent by the application\n               in user and kernel space. SIGPROF is delivered upon\n               expiration.\n\n\n*** IMPORTANT NOTICE ***\nA signal handler function is called with two arguments:\nthe first is the signal number, the second is the interrupted stack frame.\"\"\"\n\nCTRL_BREAK_EVENT=1\nCTRL_C_EVENT=0\nNSIG=23\nSIGABRT=22\nSIGBREAK=21\nSIGFPE=8\nSIGILL=4\nSIGINT=2\nSIGSEGV=11\nSIGTERM=15\nSIG_DFL=0\nSIG_IGN=1\n\ndef signal(signalnum, handler) :\n    pass\n"], "_html": [".js", "// creation of an HTML element\nvar $module = (function($B){\n\nvar _b_ = $B.builtins\nvar $TagSumDict = $B.$TagSum.$dict\n\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\n//for(var $py_builtin in _b_) eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")\n\nfunction makeTagDict(tagName){\n    // return the dictionary for the class associated with tagName\n    var dict = {__class__:$B.$type,\n        __name__:tagName\n        }\n\n    dict.__init__ = function(){\n        var $ns=$B.$MakeArgs('pow',arguments,['self'],[],'args','kw')\n        var self = $ns['self']\n        var args = $ns['args']\n        if(args.length==1){\n            var first=args[0]\n            if(isinstance(first,[str,int,float])){\n                self.elt.appendChild(document.createTextNode(str(first)))\n            } else if(first.__class__===$TagSumDict){\n                for(var i=0;i<first.children.length;i++){\n                    self.elt.appendChild(first.children[i].elt)\n                }\n            } else { // argument is another DOMNode instance\n                try{self.elt.appendChild(first.elt)}\n                catch(err){throw ValueError('wrong element '+first)}\n            }\n        }\n\n        // attributes\n        for(var i=0;i<$ns['kw'].$keys.length;i++){\n            // keyword arguments\n            var arg = $ns['kw'].$keys[i]\n            var value = $ns['kw'].$values[i]\n            if(arg.toLowerCase().substr(0,2)===\"on\"){ \n                // Event binding passed as argument \"onclick\", \"onfocus\"...\n                // Better use method bind of DOMNode objects\n                var js = '$B.DOMNode.bind(self,\"'\n                js += arg.toLowerCase().substr(2)\n                eval(js+'\",function(){'+value+'})')\n            }else if(arg.toLowerCase()==\"style\"){\n                $B.DOMNode.set_style(self,value)\n            } else {\n                if(value!==false){\n                    // option.selected=false sets it to true :-)\n                    try{\n                        arg = arg.toLowerCase()\n                        self.elt.setAttribute(arg,value)\n                        if(arg==\"class\"){ // for IE\n                            self.elt.setAttribute(\"className\",value)\n                        }\n                    }catch(err){\n                        throw ValueError(\"can't set attribute \"+arg)\n                    }\n                }\n            }\n        }\n    }\n\n    dict.__mro__ = [dict,$B.DOMNode,$B.builtins.object.$dict]\n\n    dict.__new__ = function(cls){\n        // __new__ must be defined explicitely : it returns an instance of\n        // DOMNode for the specified tagName\n        var res = $B.$DOMNode(document.createElement(tagName))\n        res.__class__ = cls.$dict\n        return res\n    }\n\n    return dict\n}\n\n\n// the classes used for tag sums, $TagSum and $TagSumClass \n// are defined in py_dom.js\n\nfunction makeFactory(tagName){\n    var factory = function(){\n        var res = $B.$DOMNode(document.createElement(tagName))\n        res.__class__ = dicts[tagName]\n        // apply __init__\n        var args = [res]\n        for(var i=0;i<arguments.length;i++){args.push(arguments[i])}\n        dicts[tagName].__init__.apply(null,args)\n        return res\n    }\n    factory.__class__=$B.$factory\n    factory.$dict = dicts[tagName]\n    return factory\n}\n\n// All HTML 4, 5.x extracted from\n// https://w3c.github.io/elements-of-html/\n// HTML4.01 tags\nvar $tags = ['A','ABBR','ACRONYM','ADDRESS','APPLET','AREA','B','BASE',\n            'BASEFONT','BDO','BIG','BLOCKQUOTE','BODY','BR','BUTTON',\n            'CAPTION','CENTER','CITE','CODE','COL','COLGROUP','DD',\n            'DEL','DFN','DIR','DIV','DL','DT','EM','FIELDSET','FONT',\n            'FORM','FRAME','FRAMESET','H1','H2','H3','H4','H5','H6',\n            'HEAD','HR','HTML','I','IFRAME','IMG','INPUT','INS',\n            'ISINDEX','KBD','LABEL','LEGEND','LI','LINK','MAP','MENU',\n            'META','NOFRAMES','NOSCRIPT','OBJECT','OL','OPTGROUP',\n            'OPTION','P','PARAM','PRE','Q','S','SAMP','SCRIPT','SELECT',\n            'SMALL','SPAN','STRIKE','STRONG','STYLE','SUB','SUP',\n            'TABLE','TBODY','TD','TEXTAREA','TFOOT','TH','THEAD',\n            'TITLE','TR','TT','U','UL','VAR',\n            // HTML5 tags\n            'ARTICLE','ASIDE','AUDIO','BDI','CANVAS','COMMAND','DATA',\n            'DATALIST','EMBED','FIGCAPTION','FIGURE','FOOTER','HEADER',\n            'KEYGEN','MAIN','MARK','MATH','METER','NAV','OUTPUT',\n            'PROGRESS','RB','RP','RT','RTC','RUBY','SECTION','SOURCE',\n            'TEMPLATE','TIME','TRACK','VIDEO','WBR',\n             // HTML5.1 tags\n            'DETAILS','DIALOG','MENUITEM','PICTURE','SUMMARY']\n\n// create classes\nvar obj = new Object()\nvar dicts = {}\nfor(var i=0;i<$tags.length;i++){\n    var tag = $tags[i]\n    dicts[tag]=makeTagDict(tag)\n    obj[tag] = makeFactory(tag)\n    dicts[tag].$factory = obj[tag]\n}\nreturn obj\n})(__BRYTHON__)\n"], "_sys": [".js", "var $module=(function($B){\n\n    return {\n        modules :\n            {'__get__':function(){return $B.builtins.dict($B.JSObject($B.imported))},\n             '__set__':0 // data descriptor, to force use of __get__\n            },\n        stderr : $B.stderr,\n        stdout : $B.stdout,\n        stdin : $B.stdin,\n    }\n})(__BRYTHON__)\n"], "browser.session_storage": [".py", "# session storage in browser\nfrom javascript import JSObject\nfrom .local_storage import LocalStorage\n\nclass SessionStorage(LocalStorage):\n\n    storage_type = \"session_storage\"\n\n    def __init__(self):\n        self.store = JSObject(__BRYTHON__.session_storage)\n\nstorage = SessionStorage()\n"], "pydoc": [".py", "#!/usr/bin/env python3\n\"\"\"Generate Python documentation in HTML or text for interactive use.\n\nIn the Python interpreter, do \"from pydoc import help\" to provide\nhelp.  Calling help(thing) on a Python object documents the object.\n\nOr, at the shell command line outside of Python:\n\nRun \"pydoc <name>\" to show documentation on something.  <name> may be\nthe name of a function, module, package, or a dotted reference to a\nclass or function within a module or module in a package.  If the\nargument contains a path segment delimiter (e.g. slash on Unix,\nbackslash on Windows) it is treated as the path to a Python source file.\n\nRun \"pydoc -k <keyword>\" to search for a keyword in the synopsis lines\nof all available modules.\n\nRun \"pydoc -p <port>\" to start an HTTP server on the given port on the\nlocal machine.  Port number 0 can be used to get an arbitrary unused port.\n\nRun \"pydoc -b\" to start an HTTP server on an arbitrary unused port and\nopen a Web browser to interactively browse documentation.  The -p option\ncan be used with the -b option to explicitly specify the server port.\n\nRun \"pydoc -w <name>\" to write out the HTML documentation for a module\nto a file named \"<name>.html\".\n\nModule docs for core modules are assumed to be in\n\n    http://docs.python.org/X.Y/library/\n\nThis can be overridden by setting the PYTHONDOCS environment variable\nto a different URL or to a local directory containing the Library\nReference Manual pages.\n\"\"\"\n__all__ = ['help']\n__author__ = \"Ka-Ping Yee <ping@lfw.org>\"\n__date__ = \"26 February 2001\"\n\n__credits__ = \"\"\"Guido van Rossum, for an excellent programming language.\nTommy Burnette, the original creator of manpy.\nPaul Prescod, for all his work on onlinehelp.\nRichard Chamberlain, for the first implementation of textdoc.\n\"\"\"\n\n# Known bugs that can't be fixed here:\n#   - imp.load_module() cannot be prevented from clobbering existing\n#     loaded modules, so calling synopsis() on a binary module file\n#     changes the contents of any existing module with the same name.\n#   - If the __file__ attribute on a module is a relative path and\n#     the current directory is changed with os.chdir(), an incorrect\n#     path will be displayed.\n\nimport builtins\nimport imp\nimport importlib.machinery\n#brython fix me\nimport inspect\nimport io\nimport os\n#brython fix me\n#import pkgutil\nimport platform\nimport re\nimport sys\nimport time\nimport tokenize\nimport warnings\nfrom collections import deque\nfrom reprlib import Repr\n#fix me brython\n#from traceback import extract_tb, format_exception_only\n\n\n# --------------------------------------------------------- common routines\n\ndef pathdirs():\n    \"\"\"Convert sys.path into a list of absolute, existing, unique paths.\"\"\"\n    dirs = []\n    normdirs = []\n    for dir in sys.path:\n        dir = os.path.abspath(dir or '.')\n        normdir = os.path.normcase(dir)\n        if normdir not in normdirs and os.path.isdir(dir):\n            dirs.append(dir)\n            normdirs.append(normdir)\n    return dirs\n\ndef getdoc(object):\n    \"\"\"Get the doc string or comments for an object.\"\"\"\n    result = inspect.getdoc(object) or inspect.getcomments(object)\n    return result and re.sub('^ *\\n', '', result.rstrip()) or ''\n\ndef splitdoc(doc):\n    \"\"\"Split a doc string into a synopsis line (if any) and the rest.\"\"\"\n    lines = doc.strip().split('\\n')\n    if len(lines) == 1:\n        return lines[0], ''\n    elif len(lines) >= 2 and not lines[1].rstrip():\n        return lines[0], '\\n'.join(lines[2:])\n    return '', '\\n'.join(lines)\n\ndef classname(object, modname):\n    \"\"\"Get a class name and qualify it with a module name if necessary.\"\"\"\n    name = object.__name__\n    if object.__module__ != modname:\n        name = object.__module__ + '.' + name\n    return name\n\ndef isdata(object):\n    \"\"\"Check if an object is of a type that probably means it's data.\"\"\"\n    return not (inspect.ismodule(object) or inspect.isclass(object) or\n                inspect.isroutine(object) or inspect.isframe(object) or\n                inspect.istraceback(object) or inspect.iscode(object))\n\ndef replace(text, *pairs):\n    \"\"\"Do a series of global replacements on a string.\"\"\"\n    while pairs:\n        text = pairs[1].join(text.split(pairs[0]))\n        pairs = pairs[2:]\n    return text\n\ndef cram(text, maxlen):\n    \"\"\"Omit part of a string if needed to make it fit in a maximum length.\"\"\"\n    if len(text) > maxlen:\n        pre = max(0, (maxlen-3)//2)\n        post = max(0, maxlen-3-pre)\n        return text[:pre] + '...' + text[len(text)-post:]\n    return text\n\n_re_stripid = re.compile(r' at 0x[0-9a-f]{6,16}(>+)$', re.IGNORECASE)\ndef stripid(text):\n    \"\"\"Remove the hexadecimal id from a Python object representation.\"\"\"\n    # The behaviour of %p is implementation-dependent in terms of case.\n    #fix me brython\n    #return _re_stripid.sub(r'\\1', text)\n    return text\n\ndef _is_some_method(obj):\n    return (inspect.isfunction(obj) or\n            inspect.ismethod(obj) or\n            inspect.isbuiltin(obj) or\n            inspect.ismethoddescriptor(obj))\n\ndef allmethods(cl):\n    methods = {}\n    for key, value in inspect.getmembers(cl, _is_some_method):\n        methods[key] = 1\n    for base in cl.__bases__:\n        methods.update(allmethods(base)) # all your base are belong to us\n    for key in methods.keys():\n        methods[key] = getattr(cl, key)\n    return methods\n\ndef _split_list(s, predicate):\n    \"\"\"Split sequence s via predicate, and return pair ([true], [false]).\n\n    The return value is a 2-tuple of lists,\n        ([x for x in s if predicate(x)],\n         [x for x in s if not predicate(x)])\n    \"\"\"\n\n    yes = []\n    no = []\n    for x in s:\n        if predicate(x):\n            yes.append(x)\n        else:\n            no.append(x)\n    return yes, no\n\ndef visiblename(name, all=None, obj=None):\n    \"\"\"Decide whether to show documentation on a variable.\"\"\"\n    # Certain special names are redundant or internal.\n    if name in {'__author__', '__builtins__', '__cached__', '__credits__',\n                '__date__', '__doc__', '__file__', '__initializing__',\n                '__loader__', '__module__', '__name__', '__package__',\n                '__path__', '__qualname__', '__slots__', '__version__'}:\n        return 0\n    # Private names are hidden, but special names are displayed.\n    if name.startswith('__') and name.endswith('__'): return 1\n    # Namedtuples have public fields and methods with a single leading underscore\n    if name.startswith('_') and hasattr(obj, '_fields'):\n        return True\n    if all is not None:\n        # only document that which the programmer exported in __all__\n        return name in all\n    else:\n        return not name.startswith('_')\n\ndef classify_class_attrs(object):\n    \"\"\"Wrap inspect.classify_class_attrs, with fixup for data descriptors.\"\"\"\n    results = []\n    for (name, kind, cls, value) in inspect.classify_class_attrs(object):\n        if inspect.isdatadescriptor(value):\n            kind = 'data descriptor'\n        results.append((name, kind, cls, value))\n    return results\n\n# ----------------------------------------------------- module manipulation\n\ndef ispackage(path):\n    \"\"\"Guess whether a path refers to a package directory.\"\"\"\n    if os.path.isdir(path):\n        for ext in ('.py', '.pyc', '.pyo'):\n            if os.path.isfile(os.path.join(path, '__init__' + ext)):\n                return True\n    return False\n\ndef source_synopsis(file):\n    line = file.readline()\n    while line[:1] == '#' or not line.strip():\n        line = file.readline()\n        if not line: break\n    line = line.strip()\n    if line[:4] == 'r\"\"\"': line = line[1:]\n    if line[:3] == '\"\"\"':\n        line = line[3:]\n        if line[-1:] == '\\\\': line = line[:-1]\n        while not line.strip():\n            line = file.readline()\n            if not line: break\n        result = line.split('\"\"\"')[0].strip()\n    else: result = None\n    return result\n\ndef synopsis(filename, cache={}):\n    \"\"\"Get the one-line summary out of a module file.\"\"\"\n    mtime = os.stat(filename).st_mtime\n    lastupdate, result = cache.get(filename, (None, None))\n    if lastupdate is None or lastupdate < mtime:\n        try:\n            file = tokenize.open(filename)\n        except IOError:\n            # module can't be opened, so skip it\n            return None\n        binary_suffixes = importlib.machinery.BYTECODE_SUFFIXES[:]\n        binary_suffixes += importlib.machinery.EXTENSION_SUFFIXES[:]\n        if any(filename.endswith(x) for x in binary_suffixes):\n            # binary modules have to be imported\n            file.close()\n            if any(filename.endswith(x) for x in\n                    importlib.machinery.BYTECODE_SUFFIXES):\n                loader = importlib.machinery.SourcelessFileLoader('__temp__',\n                                                                  filename)\n            else:\n                loader = importlib.machinery.ExtensionFileLoader('__temp__',\n                                                                 filename)\n            try:\n                module = loader.load_module('__temp__')\n            except:\n                return None\n            result = (module.__doc__ or '').splitlines()[0]\n            del sys.modules['__temp__']\n        else:\n            # text modules can be directly examined\n            result = source_synopsis(file)\n            file.close()\n\n        cache[filename] = (mtime, result)\n    return result\n\nclass ErrorDuringImport(Exception):\n    \"\"\"Errors that occurred while trying to import something to document it.\"\"\"\n    def __init__(self, filename, exc_info):\n        self.filename = filename\n        self.exc, self.value, self.tb = exc_info\n\n    def __str__(self):\n        exc = self.exc.__name__\n        return 'problem in %s - %s: %s' % (self.filename, exc, self.value)\n\ndef importfile(path):\n    \"\"\"Import a Python source file or compiled file given its path.\"\"\"\n    magic = imp.get_magic()\n    with open(path, 'rb') as file:\n        if file.read(len(magic)) == magic:\n            kind = imp.PY_COMPILED\n        else:\n            kind = imp.PY_SOURCE\n        file.seek(0)\n        filename = os.path.basename(path)\n        name, ext = os.path.splitext(filename)\n        try:\n            module = imp.load_module(name, file, path, (ext, 'r', kind))\n        except:\n            raise ErrorDuringImport(path, sys.exc_info())\n    return module\n\ndef safeimport(path, forceload=0, cache={}):\n    \"\"\"Import a module; handle errors; return None if the module isn't found.\n\n    If the module *is* found but an exception occurs, it's wrapped in an\n    ErrorDuringImport exception and reraised.  Unlike __import__, if a\n    package path is specified, the module at the end of the path is returned,\n    not the package at the beginning.  If the optional 'forceload' argument\n    is 1, we reload the module from disk (unless it's a dynamic extension).\"\"\"\n    try:\n        # If forceload is 1 and the module has been previously loaded from\n        # disk, we always have to reload the module.  Checking the file's\n        # mtime isn't good enough (e.g. the module could contain a class\n        # that inherits from another module that has changed).\n        if forceload and path in sys.modules:\n            if path not in sys.builtin_module_names:\n                # Remove the module from sys.modules and re-import to try\n                # and avoid problems with partially loaded modules.\n                # Also remove any submodules because they won't appear\n                # in the newly loaded module's namespace if they're already\n                # in sys.modules.\n                subs = [m for m in sys.modules if m.startswith(path + '.')]\n                for key in [path] + subs:\n                    # Prevent garbage collection.\n                    cache[key] = sys.modules[key]\n                    del sys.modules[key]\n        module = __import__(path)\n    except:\n        # Did the error occur before or after the module was found?\n        (exc, value, tb) = info = sys.exc_info()\n        if path in sys.modules:\n            # An error occurred while executing the imported module.\n            raise ErrorDuringImport(sys.modules[path].__file__, info)\n        elif exc is SyntaxError:\n            # A SyntaxError occurred before we could execute the module.\n            raise ErrorDuringImport(value.filename, info)\n        #fix me brython\n        #elif exc is ImportError and value.name == path:\n        elif exc is ImportError and str(value) == str(path):\n            # No such module in the path.\n            return None\n        else:\n            # Some other error occurred during the importing process.\n            raise ErrorDuringImport(path, sys.exc_info())\n    for part in path.split('.')[1:]:\n        try: module = getattr(module, part)\n        except AttributeError: return None\n    return module\n\n# ---------------------------------------------------- formatter base class\n\nclass Doc:\n\n    PYTHONDOCS = os.environ.get(\"PYTHONDOCS\",\n                                \"http://docs.python.org/%d.%d/library\"\n                                % sys.version_info[:2])\n\n    def document(self, object, name=None, *args):\n        \"\"\"Generate documentation for an object.\"\"\"\n        args = (object, name) + args\n        # 'try' clause is to attempt to handle the possibility that inspect\n        # identifies something in a way that pydoc itself has issues handling;\n        # think 'super' and how it is a descriptor (which raises the exception\n        # by lacking a __name__ attribute) and an instance.\n        if inspect.isgetsetdescriptor(object): return self.docdata(*args)\n        if inspect.ismemberdescriptor(object): return self.docdata(*args)\n        try:\n            if inspect.ismodule(object): return self.docmodule(*args)\n            if inspect.isclass(object): return self.docclass(*args)\n            if inspect.isroutine(object): return self.docroutine(*args)\n        except AttributeError:\n            pass\n        if isinstance(object, property): return self.docproperty(*args)\n        return self.docother(*args)\n\n    def fail(self, object, name=None, *args):\n        \"\"\"Raise an exception for unimplemented types.\"\"\"\n        message = \"don't know how to document object%s of type %s\" % (\n            name and ' ' + repr(name), type(object).__name__)\n        raise TypeError(message)\n\n    docmodule = docclass = docroutine = docother = docproperty = docdata = fail\n\n    def getdocloc(self, object):\n        \"\"\"Return the location of module docs or None\"\"\"\n\n        try:\n            file = inspect.getabsfile(object)\n        except TypeError:\n            file = '(built-in)'\n\n        docloc = os.environ.get(\"PYTHONDOCS\", self.PYTHONDOCS)\n\n        basedir = os.path.join(sys.base_exec_prefix, \"lib\",\n                               \"python%d.%d\" %  sys.version_info[:2])\n        if (isinstance(object, type(os)) and\n            (object.__name__ in ('errno', 'exceptions', 'gc', 'imp',\n                                 'marshal', 'posix', 'signal', 'sys',\n                                 '_thread', 'zipimport') or\n             (file.startswith(basedir) and\n              not file.startswith(os.path.join(basedir, 'site-packages')))) and\n            object.__name__ not in ('xml.etree', 'test.pydoc_mod')):\n            if docloc.startswith(\"http://\"):\n                docloc = \"%s/%s\" % (docloc.rstrip(\"/\"), object.__name__)\n            else:\n                docloc = os.path.join(docloc, object.__name__ + \".html\")\n        else:\n            docloc = None\n        return docloc\n\n# -------------------------------------------- HTML documentation generator\n\nclass HTMLRepr(Repr):\n    \"\"\"Class for safely making an HTML representation of a Python object.\"\"\"\n    def __init__(self):\n        Repr.__init__(self)\n        self.maxlist = self.maxtuple = 20\n        self.maxdict = 10\n        self.maxstring = self.maxother = 100\n\n    def escape(self, text):\n        return replace(text, '&', '&amp;', '<', '&lt;', '>', '&gt;')\n\n    def repr(self, object):\n        return Repr.repr(self, object)\n\n    def repr1(self, x, level):\n        if hasattr(type(x), '__name__'):\n            methodname = 'repr_' + '_'.join(type(x).__name__.split())\n            if hasattr(self, methodname):\n                return getattr(self, methodname)(x, level)\n        return self.escape(cram(stripid(repr(x)), self.maxother))\n\n    def repr_string(self, x, level):\n        test = cram(x, self.maxstring)\n        testrepr = repr(test)\n        if '\\\\' in test and '\\\\' not in replace(testrepr, r'\\\\', ''):\n            # Backslashes are only literal in the string and are never\n            # needed to make any special characters, so show a raw string.\n            return 'r' + testrepr[0] + self.escape(test) + testrepr[0]\n        return re.sub(r'((\\\\[\\\\abfnrtv\\'\"]|\\\\[0-9]..|\\\\x..|\\\\u....)+)',\n                      r'<font color=\"#c040c0\">\\1</font>',\n                      self.escape(testrepr))\n\n    repr_str = repr_string\n\n    def repr_instance(self, x, level):\n        try:\n            return self.escape(cram(stripid(repr(x)), self.maxstring))\n        except:\n            return self.escape('<%s instance>' % x.__class__.__name__)\n\n    repr_unicode = repr_string\n\nclass HTMLDoc(Doc):\n    \"\"\"Formatter class for HTML documentation.\"\"\"\n\n    # ------------------------------------------- HTML formatting utilities\n\n    _repr_instance = HTMLRepr()\n    repr = _repr_instance.repr\n    escape = _repr_instance.escape\n\n    def page(self, title, contents):\n        \"\"\"Format an HTML page.\"\"\"\n        return '''\\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<html><head><title>Python: %s</title>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n</head><body bgcolor=\"#f0f0f8\">\n%s\n</body></html>''' % (title, contents)\n\n    def heading(self, title, fgcol, bgcol, extras=''):\n        \"\"\"Format a page heading.\"\"\"\n        return '''\n<table width=\"100%%\" cellspacing=0 cellpadding=2 border=0 summary=\"heading\">\n<tr bgcolor=\"%s\">\n<td valign=bottom>&nbsp;<br>\n<font color=\"%s\" face=\"helvetica, arial\">&nbsp;<br>%s</font></td\n><td align=right valign=bottom\n><font color=\"%s\" face=\"helvetica, arial\">%s</font></td></tr></table>\n    ''' % (bgcol, fgcol, title, fgcol, extras or '&nbsp;')\n\n    def section(self, title, fgcol, bgcol, contents, width=6,\n                prelude='', marginalia=None, gap='&nbsp;'):\n        \"\"\"Format a section with a heading.\"\"\"\n        if marginalia is None:\n            marginalia = '<tt>' + '&nbsp;' * width + '</tt>'\n        result = '''<p>\n<table width=\"100%%\" cellspacing=0 cellpadding=2 border=0 summary=\"section\">\n<tr bgcolor=\"%s\">\n<td colspan=3 valign=bottom>&nbsp;<br>\n<font color=\"%s\" face=\"helvetica, arial\">%s</font></td></tr>\n    ''' % (bgcol, fgcol, title)\n        if prelude:\n            result = result + '''\n<tr bgcolor=\"%s\"><td rowspan=2>%s</td>\n<td colspan=2>%s</td></tr>\n<tr><td>%s</td>''' % (bgcol, marginalia, prelude, gap)\n        else:\n            result = result + '''\n<tr><td bgcolor=\"%s\">%s</td><td>%s</td>''' % (bgcol, marginalia, gap)\n\n        return result + '\\n<td width=\"100%%\">%s</td></tr></table>' % contents\n\n    def bigsection(self, title, *args):\n        \"\"\"Format a section with a big heading.\"\"\"\n        title = '<big><strong>%s</strong></big>' % title\n        return self.section(title, *args)\n\n    def preformat(self, text):\n        \"\"\"Format literal preformatted text.\"\"\"\n        text = self.escape(text.expandtabs())\n        return replace(text, '\\n\\n', '\\n \\n', '\\n\\n', '\\n \\n',\n                             ' ', '&nbsp;', '\\n', '<br>\\n')\n\n    def multicolumn(self, list, format, cols=4):\n        \"\"\"Format a list of items into a multi-column list.\"\"\"\n        result = ''\n        rows = (len(list)+cols-1)//cols\n        for col in range(cols):\n            result = result + '<td width=\"%d%%\" valign=top>' % (100//cols)\n            for i in range(rows*col, rows*col+rows):\n                if i < len(list):\n                    result = result + format(list[i]) + '<br>\\n'\n            result = result + '</td>'\n        return '<table width=\"100%%\" summary=\"list\"><tr>%s</tr></table>' % result\n\n    def grey(self, text): return '<font color=\"#909090\">%s</font>' % text\n\n    def namelink(self, name, *dicts):\n        \"\"\"Make a link for an identifier, given name-to-URL mappings.\"\"\"\n        for dict in dicts:\n            if name in dict:\n                return '<a href=\"%s\">%s</a>' % (dict[name], name)\n        return name\n\n    def classlink(self, object, modname):\n        \"\"\"Make a link for a class.\"\"\"\n        name, module = object.__name__, sys.modules.get(object.__module__)\n        if hasattr(module, name) and getattr(module, name) is object:\n            return '<a href=\"%s.html#%s\">%s</a>' % (\n                module.__name__, name, classname(object, modname))\n        return classname(object, modname)\n\n    def modulelink(self, object):\n        \"\"\"Make a link for a module.\"\"\"\n        return '<a href=\"%s.html\">%s</a>' % (object.__name__, object.__name__)\n\n    def modpkglink(self, modpkginfo):\n        \"\"\"Make a link for a module or package to display in an index.\"\"\"\n        name, path, ispackage, shadowed = modpkginfo\n        if shadowed:\n            return self.grey(name)\n        if path:\n            url = '%s.%s.html' % (path, name)\n        else:\n            url = '%s.html' % name\n        if ispackage:\n            text = '<strong>%s</strong>&nbsp;(package)' % name\n        else:\n            text = name\n        return '<a href=\"%s\">%s</a>' % (url, text)\n\n    def filelink(self, url, path):\n        \"\"\"Make a link to source file.\"\"\"\n        return '<a href=\"file:%s\">%s</a>' % (url, path)\n\n    def markup(self, text, escape=None, funcs={}, classes={}, methods={}):\n        \"\"\"Mark up some plain text, given a context of symbols to look for.\n        Each context dictionary maps object names to anchor names.\"\"\"\n        escape = escape or self.escape\n        results = []\n        here = 0\n        pattern = re.compile(r'\\b((http|ftp)://\\S+[\\w/]|'\n                                r'RFC[- ]?(\\d+)|'\n                                r'PEP[- ]?(\\d+)|'\n                                r'(self\\.)?(\\w+))')\n        while True:\n            match = pattern.search(text, here)\n            if not match: break\n            start, end = match.span()\n            results.append(escape(text[here:start]))\n\n            all, scheme, rfc, pep, selfdot, name = match.groups()\n            if scheme:\n                url = escape(all).replace('\"', '&quot;')\n                results.append('<a href=\"%s\">%s</a>' % (url, url))\n            elif rfc:\n                url = 'http://www.rfc-editor.org/rfc/rfc%d.txt' % int(rfc)\n                results.append('<a href=\"%s\">%s</a>' % (url, escape(all)))\n            elif pep:\n                url = 'http://www.python.org/dev/peps/pep-%04d/' % int(pep)\n                results.append('<a href=\"%s\">%s</a>' % (url, escape(all)))\n            elif text[end:end+1] == '(':\n                results.append(self.namelink(name, methods, funcs, classes))\n            elif selfdot:\n                results.append('self.<strong>%s</strong>' % name)\n            else:\n                results.append(self.namelink(name, classes))\n            here = end\n        results.append(escape(text[here:]))\n        return ''.join(results)\n\n    # ---------------------------------------------- type-specific routines\n\n    def formattree(self, tree, modname, parent=None):\n        \"\"\"Produce HTML for a class tree as given by inspect.getclasstree().\"\"\"\n        result = ''\n        for entry in tree:\n            if type(entry) is type(()):\n                c, bases = entry\n                result = result + '<dt><font face=\"helvetica, arial\">'\n                result = result + self.classlink(c, modname)\n                if bases and bases != (parent,):\n                    parents = []\n                    for base in bases:\n                        parents.append(self.classlink(base, modname))\n                    result = result + '(' + ', '.join(parents) + ')'\n                result = result + '\\n</font></dt>'\n            elif type(entry) is type([]):\n                result = result + '<dd>\\n%s</dd>\\n' % self.formattree(\n                    entry, modname, c)\n        return '<dl>\\n%s</dl>\\n' % result\n\n    def docmodule(self, object, name=None, mod=None, *ignored):\n        \"\"\"Produce HTML documentation for a module object.\"\"\"\n        name = object.__name__ # ignore the passed-in name\n        try:\n            all = object.__all__\n        except AttributeError:\n            all = None\n        parts = name.split('.')\n        links = []\n        for i in range(len(parts)-1):\n            links.append(\n                '<a href=\"%s.html\"><font color=\"#ffffff\">%s</font></a>' %\n                ('.'.join(parts[:i+1]), parts[i]))\n        linkedname = '.'.join(links + parts[-1:])\n        head = '<big><big><strong>%s</strong></big></big>' % linkedname\n        try:\n            path = inspect.getabsfile(object)\n            url = path\n            if sys.platform == 'win32':\n                import nturl2path\n                url = nturl2path.pathname2url(path)\n            filelink = self.filelink(url, path)\n        except TypeError:\n            filelink = '(built-in)'\n        info = []\n        if hasattr(object, '__version__'):\n            version = str(object.__version__)\n            if version[:11] == '$' + 'Revision: ' and version[-1:] == '$':\n                version = version[11:-1].strip()\n            info.append('version %s' % self.escape(version))\n        if hasattr(object, '__date__'):\n            info.append(self.escape(str(object.__date__)))\n        if info:\n            head = head + ' (%s)' % ', '.join(info)\n        docloc = self.getdocloc(object)\n        if docloc is not None:\n            docloc = '<br><a href=\"%(docloc)s\">Module Reference</a>' % locals()\n        else:\n            docloc = ''\n        result = self.heading(\n            head, '#ffffff', '#7799ee',\n            '<a href=\".\">index</a><br>' + filelink + docloc)\n\n        modules = inspect.getmembers(object, inspect.ismodule)\n\n        classes, cdict = [], {}\n        for key, value in inspect.getmembers(object, inspect.isclass):\n            # if __all__ exists, believe it.  Otherwise use old heuristic.\n            if (all is not None or\n                (inspect.getmodule(value) or object) is object):\n                if visiblename(key, all, object):\n                    classes.append((key, value))\n                    cdict[key] = cdict[value] = '#' + key\n        for key, value in classes:\n            for base in value.__bases__:\n                key, modname = base.__name__, base.__module__\n                module = sys.modules.get(modname)\n                if modname != name and module and hasattr(module, key):\n                    if getattr(module, key) is base:\n                        if not key in cdict:\n                            cdict[key] = cdict[base] = modname + '.html#' + key\n        funcs, fdict = [], {}\n        for key, value in inspect.getmembers(object, inspect.isroutine):\n            # if __all__ exists, believe it.  Otherwise use old heuristic.\n            if (all is not None or\n                inspect.isbuiltin(value) or inspect.getmodule(value) is object):\n                if visiblename(key, all, object):\n                    funcs.append((key, value))\n                    fdict[key] = '#-' + key\n                    if inspect.isfunction(value): fdict[value] = fdict[key]\n        data = []\n        for key, value in inspect.getmembers(object, isdata):\n            if visiblename(key, all, object):\n                data.append((key, value))\n\n        doc = self.markup(getdoc(object), self.preformat, fdict, cdict)\n        doc = doc and '<tt>%s</tt>' % doc\n        result = result + '<p>%s</p>\\n' % doc\n\n        if hasattr(object, '__path__'):\n            modpkgs = []\n            for importer, modname, ispkg in pkgutil.iter_modules(object.__path__):\n                modpkgs.append((modname, name, ispkg, 0))\n            modpkgs.sort()\n            contents = self.multicolumn(modpkgs, self.modpkglink)\n            result = result + self.bigsection(\n                'Package Contents', '#ffffff', '#aa55cc', contents)\n        elif modules:\n            contents = self.multicolumn(\n                modules, lambda t: self.modulelink(t[1]))\n            result = result + self.bigsection(\n                'Modules', '#ffffff', '#aa55cc', contents)\n\n        if classes:\n            classlist = [value for (key, value) in classes]\n            contents = [\n                self.formattree(inspect.getclasstree(classlist, 1), name)]\n            for key, value in classes:\n                contents.append(self.document(value, key, name, fdict, cdict))\n            result = result + self.bigsection(\n                'Classes', '#ffffff', '#ee77aa', ' '.join(contents))\n        if funcs:\n            contents = []\n            for key, value in funcs:\n                contents.append(self.document(value, key, name, fdict, cdict))\n            result = result + self.bigsection(\n                'Functions', '#ffffff', '#eeaa77', ' '.join(contents))\n        if data:\n            contents = []\n            for key, value in data:\n                contents.append(self.document(value, key))\n            result = result + self.bigsection(\n                'Data', '#ffffff', '#55aa55', '<br>\\n'.join(contents))\n        if hasattr(object, '__author__'):\n            contents = self.markup(str(object.__author__), self.preformat)\n            result = result + self.bigsection(\n                'Author', '#ffffff', '#7799ee', contents)\n        if hasattr(object, '__credits__'):\n            contents = self.markup(str(object.__credits__), self.preformat)\n            result = result + self.bigsection(\n                'Credits', '#ffffff', '#7799ee', contents)\n\n        return result\n\n    def docclass(self, object, name=None, mod=None, funcs={}, classes={},\n                 *ignored):\n        \"\"\"Produce HTML documentation for a class object.\"\"\"\n        print('docclass')\n        realname = object.__name__\n        name = name or realname\n        bases = object.__bases__\n\n        contents = []\n        push = contents.append\n\n        # Cute little class to pump out a horizontal rule between sections.\n        class HorizontalRule:\n            def __init__(self):\n                self.needone = 0\n            def maybe(self):\n                if self.needone:\n                    push('<hr>\\n')\n                self.needone = 1\n        hr = HorizontalRule()\n\n        # List the mro, if non-trivial.\n        mro = deque(inspect.getmro(object))\n        if len(mro) > 2:\n            hr.maybe()\n            push('<dl><dt>Method resolution order:</dt>\\n')\n            for base in mro:\n                push('<dd>%s</dd>\\n' % self.classlink(base,\n                                                      object.__module__))\n            push('</dl>\\n')\n\n        def spill(msg, attrs, predicate):\n            ok, attrs = _split_list(attrs, predicate)\n            if ok:\n                hr.maybe()\n                push(msg)\n                for name, kind, homecls, value in ok:\n                    try:\n                        value = getattr(object, name)\n                    except Exception:\n                        # Some descriptors may meet a failure in their __get__.\n                        # (bug #1785)\n                        push(self._docdescriptor(name, value, mod))\n                    else:\n                        push(self.document(value, name, mod,\n                                        funcs, classes, mdict, object))\n                    push('\\n')\n            return attrs\n\n        def spilldescriptors(msg, attrs, predicate):\n            ok, attrs = _split_list(attrs, predicate)\n            if ok:\n                hr.maybe()\n                push(msg)\n                for name, kind, homecls, value in ok:\n                    push(self._docdescriptor(name, value, mod))\n            return attrs\n\n        def spilldata(msg, attrs, predicate):\n            ok, attrs = _split_list(attrs, predicate)\n            if ok:\n                hr.maybe()\n                push(msg)\n                for name, kind, homecls, value in ok:\n                    base = self.docother(getattr(object, name), name, mod)\n                    if callable(value) or inspect.isdatadescriptor(value):\n                        doc = getattr(value, \"__doc__\", None)\n                    else:\n                        doc = None\n                    if doc is None:\n                        push('<dl><dt>%s</dl>\\n' % base)\n                    else:\n                        doc = self.markup(getdoc(value), self.preformat,\n                                          funcs, classes, mdict)\n                        doc = '<dd><tt>%s</tt>' % doc\n                        push('<dl><dt>%s%s</dl>\\n' % (base, doc))\n                    push('\\n')\n            return attrs\n\n        attrs = [(name, kind, cls, value)\n                 for name, kind, cls, value in classify_class_attrs(object)\n                 if visiblename(name, obj=object)]\n\n        mdict = {}\n        for key, kind, homecls, value in attrs:\n            mdict[key] = anchor = '#' + name + '-' + key\n            try:\n                value = getattr(object, name)\n            except Exception:\n                # Some descriptors may meet a failure in their __get__.\n                # (bug #1785)\n                pass\n            try:\n                # The value may not be hashable (e.g., a data attr with\n                # a dict or list value).\n                mdict[value] = anchor\n            except TypeError:\n                pass\n\n        while attrs:\n            if mro:\n                thisclass = mro.popleft()\n            else:\n                thisclass = attrs[0][2]\n            attrs, inherited = _split_list(attrs, lambda t: t[2] is thisclass)\n\n            if thisclass is builtins.object:\n                attrs = inherited\n                continue\n            elif thisclass is object:\n                tag = 'defined here'\n            else:\n                tag = 'inherited from %s' % self.classlink(thisclass,\n                                                           object.__module__)\n            tag += ':<br>\\n'\n\n            # Sort attrs by name.\n            attrs.sort(key=lambda t: t[0])\n\n            # Pump out the attrs, segregated by kind.\n            attrs = spill('Methods %s' % tag, attrs,\n                          lambda t: t[1] == 'method')\n            attrs = spill('Class methods %s' % tag, attrs,\n                          lambda t: t[1] == 'class method')\n            attrs = spill('Static methods %s' % tag, attrs,\n                          lambda t: t[1] == 'static method')\n            attrs = spilldescriptors('Data descriptors %s' % tag, attrs,\n                                     lambda t: t[1] == 'data descriptor')\n            attrs = spilldata('Data and other attributes %s' % tag, attrs,\n                              lambda t: t[1] == 'data')\n            assert attrs == []\n            attrs = inherited\n\n        contents = ''.join(contents)\n\n        if name == realname:\n            title = '<a name=\"%s\">class <strong>%s</strong></a>' % (\n                name, realname)\n        else:\n            title = '<strong>%s</strong> = <a name=\"%s\">class %s</a>' % (\n                name, name, realname)\n        if bases:\n            parents = []\n            for base in bases:\n                parents.append(self.classlink(base, object.__module__))\n            title = title + '(%s)' % ', '.join(parents)\n        doc = self.markup(getdoc(object), self.preformat, funcs, classes, mdict)\n        doc = doc and '<tt>%s<br>&nbsp;</tt>' % doc\n\n        return self.section(title, '#000000', '#ffc8d8', contents, 3, doc)\n\n    def formatvalue(self, object):\n        \"\"\"Format an argument default value as text.\"\"\"\n        return self.grey('=' + self.repr(object))\n\n    def docroutine(self, object, name=None, mod=None,\n                   funcs={}, classes={}, methods={}, cl=None):\n        \"\"\"Produce HTML documentation for a function or method object.\"\"\"\n        realname = object.__name__\n        name = name or realname\n        anchor = (cl and cl.__name__ or '') + '-' + name\n        note = ''\n        skipdocs = 0\n        if inspect.ismethod(object):\n            imclass = object.__self__.__class__\n            if cl:\n                if imclass is not cl:\n                    note = ' from ' + self.classlink(imclass, mod)\n            else:\n                if object.__self__ is not None:\n                    note = ' method of %s instance' % self.classlink(\n                        object.__self__.__class__, mod)\n                else:\n                    note = ' unbound %s method' % self.classlink(imclass,mod)\n            object = object.__func__\n\n        if name == realname:\n            title = '<a name=\"%s\"><strong>%s</strong></a>' % (anchor, realname)\n        else:\n            if (cl and realname in cl.__dict__ and\n                cl.__dict__[realname] is object):\n                reallink = '<a href=\"#%s\">%s</a>' % (\n                    cl.__name__ + '-' + realname, realname)\n                skipdocs = 1\n            else:\n                reallink = realname\n            title = '<a name=\"%s\"><strong>%s</strong></a> = %s' % (\n                anchor, name, reallink)\n        if inspect.isfunction(object):\n            args, varargs, kwonlyargs, kwdefaults, varkw, defaults, ann = \\\n                inspect.getfullargspec(object)\n            argspec = inspect.formatargspec(\n                args, varargs, kwonlyargs, kwdefaults, varkw, defaults, ann,\n                formatvalue=self.formatvalue,\n                formatannotation=inspect.formatannotationrelativeto(object))\n            if realname == '<lambda>':\n                title = '<strong>%s</strong> <em>lambda</em> ' % name\n                # XXX lambda's won't usually have func_annotations['return']\n                # since the syntax doesn't support but it is possible.\n                # So removing parentheses isn't truly safe.\n                argspec = argspec[1:-1] # remove parentheses\n        else:\n            argspec = '(...)'\n\n        decl = title + argspec + (note and self.grey(\n               '<font face=\"helvetica, arial\">%s</font>' % note))\n\n        if skipdocs:\n            return '<dl><dt>%s</dt></dl>\\n' % decl\n        else:\n            doc = self.markup(\n                getdoc(object), self.preformat, funcs, classes, methods)\n            doc = doc and '<dd><tt>%s</tt></dd>' % doc\n            return '<dl><dt>%s</dt>%s</dl>\\n' % (decl, doc)\n\n    def _docdescriptor(self, name, value, mod):\n        results = []\n        push = results.append\n\n        if name:\n            push('<dl><dt><strong>%s</strong></dt>\\n' % name)\n        if value.__doc__ is not None:\n            doc = self.markup(getdoc(value), self.preformat)\n            push('<dd><tt>%s</tt></dd>\\n' % doc)\n        push('</dl>\\n')\n\n        return ''.join(results)\n\n    def docproperty(self, object, name=None, mod=None, cl=None):\n        \"\"\"Produce html documentation for a property.\"\"\"\n        return self._docdescriptor(name, object, mod)\n\n    def docother(self, object, name=None, mod=None, *ignored):\n        \"\"\"Produce HTML documentation for a data object.\"\"\"\n        lhs = name and '<strong>%s</strong> = ' % name or ''\n        return lhs + self.repr(object)\n\n    def docdata(self, object, name=None, mod=None, cl=None):\n        \"\"\"Produce html documentation for a data descriptor.\"\"\"\n        return self._docdescriptor(name, object, mod)\n\n    def index(self, dir, shadowed=None):\n        \"\"\"Generate an HTML index for a directory of modules.\"\"\"\n        modpkgs = []\n        if shadowed is None: shadowed = {}\n        for importer, name, ispkg in pkgutil.iter_modules([dir]):\n            if any((0xD800 <= ord(ch) <= 0xDFFF) for ch in name):\n                # ignore a module if its name contains a surrogate character\n                continue\n            modpkgs.append((name, '', ispkg, name in shadowed))\n            shadowed[name] = 1\n\n        modpkgs.sort()\n        contents = self.multicolumn(modpkgs, self.modpkglink)\n        return self.bigsection(dir, '#ffffff', '#ee77aa', contents)\n\n# -------------------------------------------- text documentation generator\n\nclass TextRepr(Repr):\n    \"\"\"Class for safely making a text representation of a Python object.\"\"\"\n    def __init__(self):\n        Repr.__init__(self)\n        self.maxlist = self.maxtuple = 20\n        self.maxdict = 10\n        self.maxstring = self.maxother = 100\n\n    #def repr1(self, x, level):\n    #    if hasattr(type(x), '__name__'):\n    #        methodname = 'repr_' + '_'.join(type(x).__name__.split())\n    #        if hasattr(self, methodname):\n    #            return getattr(self, methodname)(x, level)\n    #    return cram(stripid(repr(x)), self.maxother)\n\n    def repr_string(self, x, level):\n        test = cram(x, self.maxstring)\n        testrepr = repr(test)\n        if '\\\\' in test and '\\\\' not in replace(testrepr, r'\\\\', ''):\n            # Backslashes are only literal in the string and are never\n            # needed to make any special characters, so show a raw string.\n            return 'r' + testrepr[0] + test + testrepr[0]\n        return testrepr\n\n    repr_str = repr_string\n\n    def repr_instance(self, x, level):\n        try:\n            return cram(stripid(repr(x)), self.maxstring)\n        except:\n            return '<%s instance>' % x.__class__.__name__\n\nclass TextDoc(Doc):\n    \"\"\"Formatter class for text documentation.\"\"\"\n\n    # ------------------------------------------- text formatting utilities\n\n    _repr_instance = TextRepr()\n    repr = _repr_instance.repr\n\n    def bold(self, text):\n        \"\"\"Format a string in bold by overstriking.\"\"\"\n        return ''.join(ch + '\\b' + ch for ch in text)\n\n    def indent(self, text, prefix='    '):\n        \"\"\"Indent text by prepending a given prefix to each line.\"\"\"\n        if not text: return ''\n        lines = [prefix + line for line in text.split('\\n')]\n        if lines: lines[-1] = lines[-1].rstrip()\n        return '\\n'.join(lines)\n\n    def section(self, title, contents):\n        \"\"\"Format a section with a given heading.\"\"\"\n        clean_contents = self.indent(contents).rstrip()\n        return self.bold(title) + '\\n' + clean_contents + '\\n\\n'\n\n    # ---------------------------------------------- type-specific routines\n\n    def formattree(self, tree, modname, parent=None, prefix=''):\n        \"\"\"Render in text a class tree as returned by inspect.getclasstree().\"\"\"\n        result = ''\n        for entry in tree:\n            if type(entry) is type(()):\n                c, bases = entry\n                result = result + prefix + classname(c, modname)\n                if bases and bases != (parent,):\n                    parents = (classname(c, modname) for c in bases)\n                    result = result + '(%s)' % ', '.join(parents)\n                result = result + '\\n'\n            elif type(entry) is type([]):\n                result = result + self.formattree(\n                    entry, modname, c, prefix + '    ')\n        return result\n\n    def docmodule(self, object, name=None, mod=None):\n        \"\"\"Produce text documentation for a given module object.\"\"\"\n        name = object.__name__ # ignore the passed-in name\n        synop, desc = splitdoc(getdoc(object))\n        result = self.section('NAME', name + (synop and ' - ' + synop))\n        all = getattr(object, '__all__', None)\n        docloc = self.getdocloc(object)\n        if docloc is not None:\n            result = result + self.section('MODULE REFERENCE', docloc + \"\"\"\n\nThe following documentation is automatically generated from the Python\nsource files.  It may be incomplete, incorrect or include features that\nare considered implementation detail and may vary between Python\nimplementations.  When in doubt, consult the module reference at the\nlocation listed above.\n\"\"\")\n\n        if desc:\n            result = result + self.section('DESCRIPTION', desc)\n\n        classes = []\n        for key, value in inspect.getmembers(object, inspect.isclass):\n            # if __all__ exists, believe it.  Otherwise use old heuristic.\n            if (all is not None\n                or (inspect.getmodule(value) or object) is object):\n                if visiblename(key, all, object):\n                    classes.append((key, value))\n        funcs = []\n        for key, value in inspect.getmembers(object, inspect.isroutine):\n            # if __all__ exists, believe it.  Otherwise use old heuristic.\n            if (all is not None or\n                inspect.isbuiltin(value) or inspect.getmodule(value) is object):\n                if visiblename(key, all, object):\n                    funcs.append((key, value))\n        data = []\n        for key, value in inspect.getmembers(object, isdata):\n            if visiblename(key, all, object):\n                data.append((key, value))\n\n        modpkgs = []\n        modpkgs_names = set()\n        if hasattr(object, '__path__'):\n            for importer, modname, ispkg in pkgutil.iter_modules(object.__path__):\n                modpkgs_names.add(modname)\n                if ispkg:\n                    modpkgs.append(modname + ' (package)')\n                else:\n                    modpkgs.append(modname)\n\n            modpkgs.sort()\n            result = result + self.section(\n                'PACKAGE CONTENTS', '\\n'.join(modpkgs))\n\n        # Detect submodules as sometimes created by C extensions\n        submodules = []\n        for key, value in inspect.getmembers(object, inspect.ismodule):\n            if value.__name__.startswith(name + '.') and key not in modpkgs_names:\n                submodules.append(key)\n        if submodules:\n            submodules.sort()\n            result = result + self.section(\n                'SUBMODULES', '\\n'.join(submodules))\n\n        if classes:\n            classlist = [value for key, value in classes]\n            contents = [self.formattree(\n                inspect.getclasstree(classlist, 1), name)]\n            for key, value in classes:\n                contents.append(self.document(value, key, name))\n            result = result + self.section('CLASSES', '\\n'.join(contents))\n\n        if funcs:\n            contents = []\n            for key, value in funcs:\n                contents.append(self.document(value, key, name))\n            result = result + self.section('FUNCTIONS', '\\n'.join(contents))\n\n        if data:\n            contents = []\n            for key, value in data:\n                contents.append(self.docother(value, key, name, maxlen=70))\n            result = result + self.section('DATA', '\\n'.join(contents))\n\n        if hasattr(object, '__version__'):\n            version = str(object.__version__)\n            if version[:11] == '$' + 'Revision: ' and version[-1:] == '$':\n                version = version[11:-1].strip()\n            result = result + self.section('VERSION', version)\n        if hasattr(object, '__date__'):\n            result = result + self.section('DATE', str(object.__date__))\n        if hasattr(object, '__author__'):\n            result = result + self.section('AUTHOR', str(object.__author__))\n        if hasattr(object, '__credits__'):\n            result = result + self.section('CREDITS', str(object.__credits__))\n        try:\n            file = inspect.getabsfile(object)\n        except TypeError:\n            file = '(built-in)'\n        result = result + self.section('FILE', file)\n        return result\n\n    def docclass(self, object, name=None, mod=None, *ignored):\n        \"\"\"Produce text documentation for a given class object.\"\"\"\n        realname = object.__name__\n        name = name or realname\n        bases = object.__bases__\n\n        def makename(c, m=object.__module__):\n            return classname(c, m)\n\n        if name == realname:\n            title = 'class ' + self.bold(realname)\n        else:\n            title = self.bold(name) + ' = class ' + realname\n        if bases:\n            parents = map(makename, bases)\n            title = title + '(%s)' % ', '.join(parents)\n\n        doc = getdoc(object)\n        contents = doc and [doc + '\\n'] or []\n        push = contents.append\n\n        # List the mro, if non-trivial.\n        mro = deque(inspect.getmro(object))\n        if len(mro) > 2:\n            push(\"Method resolution order:\")\n            for base in mro:\n                push('    ' + makename(base))\n            push('')\n\n        # Cute little class to pump out a horizontal rule between sections.\n        class HorizontalRule:\n            def __init__(self):\n                self.needone = 0\n            def maybe(self):\n                if self.needone:\n                    push('-' * 70)\n                self.needone = 1\n        hr = HorizontalRule()\n\n        def spill(msg, attrs, predicate):\n            ok, attrs = _split_list(attrs, predicate)\n            if ok:\n                hr.maybe()\n                push(msg)\n                for name, kind, homecls, value in ok:\n                    try:\n                        value = getattr(object, name)\n                    except Exception:\n                        # Some descriptors may meet a failure in their __get__.\n                        # (bug #1785)\n                        push(self._docdescriptor(name, value, mod))\n                    else:\n                        push(self.document(value,\n                                        name, mod, object))\n            return attrs\n\n        def spilldescriptors(msg, attrs, predicate):\n            ok, attrs = _split_list(attrs, predicate)\n            if ok:\n                hr.maybe()\n                push(msg)\n                for name, kind, homecls, value in ok:\n                    push(self._docdescriptor(name, value, mod))\n            return attrs\n\n        def spilldata(msg, attrs, predicate):\n            ok, attrs = _split_list(attrs, predicate)\n            if ok:\n                hr.maybe()\n                push(msg)\n                for name, kind, homecls, value in ok:\n                    if callable(value) or inspect.isdatadescriptor(value):\n                        doc = getdoc(value)\n                    else:\n                        doc = None\n                    push(self.docother(getattr(object, name),\n                                       name, mod, maxlen=70, doc=doc) + '\\n')\n            return attrs\n\n        attrs = [(name, kind, cls, value)\n                 for name, kind, cls, value in classify_class_attrs(object)\n                 if visiblename(name, obj=object)]\n\n        while attrs:\n            if mro:\n                thisclass = mro.popleft()\n            else:\n                thisclass = attrs[0][2]\n            attrs, inherited = _split_list(attrs, lambda t: t[2] is thisclass)\n\n            if thisclass is builtins.object:\n                attrs = inherited\n                continue\n            elif thisclass is object:\n                tag = \"defined here\"\n            else:\n                tag = \"inherited from %s\" % classname(thisclass,\n                                                      object.__module__)\n\n            # Sort attrs by name.\n            attrs.sort()\n\n            # Pump out the attrs, segregated by kind.\n            attrs = spill(\"Methods %s:\\n\" % tag, attrs,\n                          lambda t: t[1] == 'method')\n            attrs = spill(\"Class methods %s:\\n\" % tag, attrs,\n                          lambda t: t[1] == 'class method')\n            attrs = spill(\"Static methods %s:\\n\" % tag, attrs,\n                          lambda t: t[1] == 'static method')\n            attrs = spilldescriptors(\"Data descriptors %s:\\n\" % tag, attrs,\n                                     lambda t: t[1] == 'data descriptor')\n            attrs = spilldata(\"Data and other attributes %s:\\n\" % tag, attrs,\n                              lambda t: t[1] == 'data')\n            assert attrs == []\n            attrs = inherited\n\n        contents = '\\n'.join(contents)\n        if not contents:\n            return title + '\\n'\n        return title + '\\n' + self.indent(contents.rstrip(), ' |  ') + '\\n'\n\n    def formatvalue(self, object):\n        \"\"\"Format an argument default value as text.\"\"\"\n        return '=' + self.repr(object)\n\n    def docroutine(self, object, name=None, mod=None, cl=None):\n        \"\"\"Produce text documentation for a function or method object.\"\"\"\n        realname = object.__name__\n        name = name or realname\n        note = ''\n        skipdocs = 0\n        if inspect.ismethod(object):\n            imclass = object.__self__.__class__\n            if cl:\n                if imclass is not cl:\n                    note = ' from ' + classname(imclass, mod)\n            else:\n                if object.__self__ is not None:\n                    note = ' method of %s instance' % classname(\n                        object.__self__.__class__, mod)\n                else:\n                    note = ' unbound %s method' % classname(imclass,mod)\n            object = object.__func__\n\n        if name == realname:\n            title = self.bold(realname)\n        else:\n            if (cl and realname in cl.__dict__ and\n                cl.__dict__[realname] is object):\n                skipdocs = 1\n            title = self.bold(name) + ' = ' + realname\n        if inspect.isfunction(object):\n            args, varargs, varkw, defaults, kwonlyargs, kwdefaults, ann = \\\n              inspect.getfullargspec(object)\n            argspec = inspect.formatargspec(\n                args, varargs, varkw, defaults, kwonlyargs, kwdefaults, ann,\n                formatvalue=self.formatvalue,\n                formatannotation=inspect.formatannotationrelativeto(object))\n            if realname == '<lambda>':\n                title = self.bold(name) + ' lambda '\n                # XXX lambda's won't usually have func_annotations['return']\n                # since the syntax doesn't support but it is possible.\n                # So removing parentheses isn't truly safe.\n                argspec = argspec[1:-1] # remove parentheses\n        else:\n            argspec = '(...)'\n        decl = title + argspec + note\n\n        if skipdocs:\n            return decl + '\\n'\n        else:\n            doc = getdoc(object) or ''\n            return decl + '\\n' + (doc and self.indent(doc).rstrip() + '\\n')\n\n    def _docdescriptor(self, name, value, mod):\n        results = []\n        push = results.append\n\n        if name:\n            push(self.bold(name))\n            push('\\n')\n        doc = getdoc(value) or ''\n        if doc:\n            push(self.indent(doc))\n            push('\\n')\n        return ''.join(results)\n\n    def docproperty(self, object, name=None, mod=None, cl=None):\n        \"\"\"Produce text documentation for a property.\"\"\"\n        return self._docdescriptor(name, object, mod)\n\n    def docdata(self, object, name=None, mod=None, cl=None):\n        \"\"\"Produce text documentation for a data descriptor.\"\"\"\n        return self._docdescriptor(name, object, mod)\n\n    def docother(self, object, name=None, mod=None, parent=None, maxlen=None, doc=None):\n        \"\"\"Produce text documentation for a data object.\"\"\"\n        repr = self.repr(object)\n        if maxlen:\n            line = (name and name + ' = ' or '') + repr\n            chop = maxlen - len(line)\n            if chop < 0: repr = repr[:chop] + '...'\n        line = (name and self.bold(name) + ' = ' or '') + repr\n        if doc is not None:\n            line += '\\n' + self.indent(str(doc))\n        return line\n\nclass _PlainTextDoc(TextDoc):\n    \"\"\"Subclass of TextDoc which overrides string styling\"\"\"\n    def bold(self, text):\n        return text\n\n# --------------------------------------------------------- user interfaces\n\ndef pager(text):\n    \"\"\"The first time this is called, determine what kind of pager to use.\"\"\"\n    global pager\n    pager = getpager()\n    pager(text)\n\ndef getpager():\n    \"\"\"Decide what method to use for paging through text.\"\"\"\n    if not hasattr(sys.stdout, \"isatty\"):\n        return plainpager\n    if not sys.stdin.isatty() or not sys.stdout.isatty():\n        return plainpager\n    if 'PAGER' in os.environ:\n        if sys.platform == 'win32': # pipes completely broken in Windows\n            return lambda text: tempfilepager(plain(text), os.environ['PAGER'])\n        elif os.environ.get('TERM') in ('dumb', 'emacs'):\n            return lambda text: pipepager(plain(text), os.environ['PAGER'])\n        else:\n            return lambda text: pipepager(text, os.environ['PAGER'])\n    if os.environ.get('TERM') in ('dumb', 'emacs'):\n        return plainpager\n    if sys.platform == 'win32' or sys.platform.startswith('os2'):\n        return lambda text: tempfilepager(plain(text), 'more <')\n    if hasattr(os, 'system') and os.system('(less) 2>/dev/null') == 0:\n        return lambda text: pipepager(text, 'less')\n\n    import tempfile\n    (fd, filename) = tempfile.mkstemp()\n    os.close(fd)\n    try:\n        if hasattr(os, 'system') and os.system('more \"%s\"' % filename) == 0:\n            return lambda text: pipepager(text, 'more')\n        else:\n            return ttypager\n    finally:\n        os.unlink(filename)\n\ndef plain(text):\n    \"\"\"Remove boldface formatting from text.\"\"\"\n    return re.sub('.\\b', '', text)\n\ndef pipepager(text, cmd):\n    \"\"\"Page through text by feeding it to another program.\"\"\"\n    pipe = os.popen(cmd, 'w')\n    try:\n        pipe.write(text)\n        pipe.close()\n    except IOError:\n        pass # Ignore broken pipes caused by quitting the pager program.\n\ndef tempfilepager(text, cmd):\n    \"\"\"Page through text by invoking a program on a temporary file.\"\"\"\n    import tempfile\n    filename = tempfile.mktemp()\n    file = open(filename, 'w')\n    file.write(text)\n    file.close()\n    try:\n        os.system(cmd + ' \"' + filename + '\"')\n    finally:\n        os.unlink(filename)\n\ndef ttypager(text):\n    \"\"\"Page through text on a text terminal.\"\"\"\n    lines = plain(text).split('\\n')\n    try:\n        import tty\n        fd = sys.stdin.fileno()\n        old = tty.tcgetattr(fd)\n        tty.setcbreak(fd)\n        getchar = lambda: sys.stdin.read(1)\n    except (ImportError, AttributeError):\n        tty = None\n        getchar = lambda: sys.stdin.readline()[:-1][:1]\n\n    try:\n        r = inc = os.environ.get('LINES', 25) - 1\n        sys.stdout.write('\\n'.join(lines[:inc]) + '\\n')\n        while lines[r:]:\n            sys.stdout.write('-- more --')\n            sys.stdout.flush()\n            c = getchar()\n\n            if c in ('q', 'Q'):\n                sys.stdout.write('\\r          \\r')\n                break\n            elif c in ('\\r', '\\n'):\n                sys.stdout.write('\\r          \\r' + lines[r] + '\\n')\n                r = r + 1\n                continue\n            if c in ('b', 'B', '\\x1b'):\n                r = r - inc - inc\n                if r < 0: r = 0\n            sys.stdout.write('\\n' + '\\n'.join(lines[r:r+inc]) + '\\n')\n            r = r + inc\n\n    finally:\n        if tty:\n            tty.tcsetattr(fd, tty.TCSAFLUSH, old)\n\ndef plainpager(text):\n    \"\"\"Simply print unformatted text.  This is the ultimate fallback.\"\"\"\n    sys.stdout.write(plain(text))\n\ndef describe(thing):\n    \"\"\"Produce a short description of the given thing.\"\"\"\n    if inspect.ismodule(thing):\n        if thing.__name__ in sys.builtin_module_names:\n            return 'built-in module ' + thing.__name__\n        if hasattr(thing, '__path__'):\n            return 'package ' + thing.__name__\n        else:\n            return 'module ' + thing.__name__\n    if inspect.isbuiltin(thing):\n        return 'built-in function ' + thing.__name__\n    if inspect.isgetsetdescriptor(thing):\n        return 'getset descriptor %s.%s.%s' % (\n            thing.__objclass__.__module__, thing.__objclass__.__name__,\n            thing.__name__)\n    if inspect.ismemberdescriptor(thing):\n        return 'member descriptor %s.%s.%s' % (\n            thing.__objclass__.__module__, thing.__objclass__.__name__,\n            thing.__name__)\n    if inspect.isclass(thing):\n        return 'class ' + thing.__name__\n    if inspect.isfunction(thing):\n        return 'function ' + thing.__name__\n    if inspect.ismethod(thing):\n        return 'method ' + thing.__name__\n    return type(thing).__name__\n\ndef locate(path, forceload=0):\n    \"\"\"Locate an object by name or dotted path, importing as necessary.\"\"\"\n    parts = [part for part in path.split('.') if part]\n    module, n = None, 0\n    while n < len(parts):\n        nextmodule = safeimport('.'.join(parts[:n+1]), forceload)\n        if nextmodule: module, n = nextmodule, n + 1\n        else: break\n    if module:\n        object = module\n    else:\n        object = builtins\n    for part in parts[n:]:\n        try:\n            object = getattr(object, part)\n        except AttributeError:\n            return None\n    return object\n\n# --------------------------------------- interactive interpreter interface\n\ntext = TextDoc()\nplaintext = _PlainTextDoc()\nhtml = HTMLDoc()\n\ndef resolve(thing, forceload=0):\n    \"\"\"Given an object or a path to an object, get the object and its name.\"\"\"\n    if isinstance(thing, str):\n        object = locate(thing, forceload)\n        if not object:\n            raise ImportError('no Python documentation found for %r' % thing)\n        return object, thing\n    else:\n        name = getattr(thing, '__name__', None)\n        return thing, name if isinstance(name, str) else None\n\ndef render_doc(thing, title='Python Library Documentation: %s', forceload=0,\n        renderer=None):\n    \"\"\"Render text documentation, given an object or a path to an object.\"\"\"\n    if renderer is None:\n        renderer = text\n    object, name = resolve(thing, forceload)\n    desc = describe(object)\n    module = inspect.getmodule(object)\n    if name and '.' in name:\n        desc += ' in ' + name[:name.rfind('.')]\n    elif module and module is not object:\n        desc += ' in module ' + module.__name__\n\n    if not (inspect.ismodule(object) or\n              inspect.isclass(object) or\n              inspect.isroutine(object) or\n              inspect.isgetsetdescriptor(object) or\n              inspect.ismemberdescriptor(object) or\n              isinstance(object, property)):\n        # If the passed object is a piece of data or an instance,\n        # document its available methods instead of its value.\n        object = type(object)\n        desc += ' object'\n    return title % desc + '\\n\\n' + renderer.document(object, name)\n\ndef doc(thing, title='Python Library Documentation: %s', forceload=0,\n        output=None):\n    \"\"\"Display text documentation, given an object or a path to an object.\"\"\"\n    try:\n        if output is None:\n            pager(render_doc(thing, title, forceload))\n        else:\n            output.write(render_doc(thing, title, forceload, plaintext))\n    except (ImportError, ErrorDuringImport) as value:\n        print(value)\n\ndef writedoc(thing, forceload=0):\n    \"\"\"Write HTML documentation to a file in the current directory.\"\"\"\n    try:\n        object, name = resolve(thing, forceload)\n        page = html.page(describe(object), html.document(object, name))\n        file = open(name + '.html', 'w', encoding='utf-8')\n        file.write(page)\n        file.close()\n        print('wrote', name + '.html')\n    except (ImportError, ErrorDuringImport) as value:\n        print(value)\n\ndef writedocs(dir, pkgpath='', done=None):\n    \"\"\"Write out HTML documentation for all modules in a directory tree.\"\"\"\n    if done is None: done = {}\n    for importer, modname, ispkg in pkgutil.walk_packages([dir], pkgpath):\n        writedoc(modname)\n    return\n\nclass Helper:\n\n    # These dictionaries map a topic name to either an alias, or a tuple\n    # (label, seealso-items).  The \"label\" is the label of the corresponding\n    # section in the .rst file under Doc/ and an index into the dictionary\n    # in pydoc_data/topics.py.\n    #\n    # CAUTION: if you change one of these dictionaries, be sure to adapt the\n    #          list of needed labels in Doc/tools/sphinxext/pyspecific.py and\n    #          regenerate the pydoc_data/topics.py file by running\n    #              make pydoc-topics\n    #          in Doc/ and copying the output file into the Lib/ directory.\n\n    keywords = {\n        'False': '',\n        'None': '',\n        'True': '',\n        'and': 'BOOLEAN',\n        'as': 'with',\n        'assert': ('assert', ''),\n        'break': ('break', 'while for'),\n        'class': ('class', 'CLASSES SPECIALMETHODS'),\n        'continue': ('continue', 'while for'),\n        'def': ('function', ''),\n        'del': ('del', 'BASICMETHODS'),\n        'elif': 'if',\n        'else': ('else', 'while for'),\n        'except': 'try',\n        'finally': 'try',\n        'for': ('for', 'break continue while'),\n        'from': 'import',\n        'global': ('global', 'nonlocal NAMESPACES'),\n        'if': ('if', 'TRUTHVALUE'),\n        'import': ('import', 'MODULES'),\n        'in': ('in', 'SEQUENCEMETHODS'),\n        'is': 'COMPARISON',\n        'lambda': ('lambda', 'FUNCTIONS'),\n        'nonlocal': ('nonlocal', 'global NAMESPACES'),\n        'not': 'BOOLEAN',\n        'or': 'BOOLEAN',\n        'pass': ('pass', ''),\n        'raise': ('raise', 'EXCEPTIONS'),\n        'return': ('return', 'FUNCTIONS'),\n        'try': ('try', 'EXCEPTIONS'),\n        'while': ('while', 'break continue if TRUTHVALUE'),\n        'with': ('with', 'CONTEXTMANAGERS EXCEPTIONS yield'),\n        'yield': ('yield', ''),\n    }\n    # Either add symbols to this dictionary or to the symbols dictionary\n    # directly: Whichever is easier. They are merged later.\n    _symbols_inverse = {\n        'STRINGS' : (\"'\", \"'''\", \"r'\", \"b'\", '\"\"\"', '\"', 'r\"', 'b\"'),\n        'OPERATORS' : ('+', '-', '*', '**', '/', '//', '%', '<<', '>>', '&',\n                       '|', '^', '~', '<', '>', '<=', '>=', '==', '!=', '<>'),\n        'COMPARISON' : ('<', '>', '<=', '>=', '==', '!=', '<>'),\n        'UNARY' : ('-', '~'),\n        'AUGMENTEDASSIGNMENT' : ('+=', '-=', '*=', '/=', '%=', '&=', '|=',\n                                '^=', '<<=', '>>=', '**=', '//='),\n        'BITWISE' : ('<<', '>>', '&', '|', '^', '~'),\n        'COMPLEX' : ('j', 'J')\n    }\n    symbols = {\n        '%': 'OPERATORS FORMATTING',\n        '**': 'POWER',\n        ',': 'TUPLES LISTS FUNCTIONS',\n        '.': 'ATTRIBUTES FLOAT MODULES OBJECTS',\n        '...': 'ELLIPSIS',\n        ':': 'SLICINGS DICTIONARYLITERALS',\n        '@': 'def class',\n        '\\\\': 'STRINGS',\n        '_': 'PRIVATENAMES',\n        '__': 'PRIVATENAMES SPECIALMETHODS',\n        '`': 'BACKQUOTES',\n        '(': 'TUPLES FUNCTIONS CALLS',\n        ')': 'TUPLES FUNCTIONS CALLS',\n        '[': 'LISTS SUBSCRIPTS SLICINGS',\n        ']': 'LISTS SUBSCRIPTS SLICINGS'\n    }\n    for topic, symbols_ in _symbols_inverse.items():\n        for symbol in symbols_:\n            topics = symbols.get(symbol, topic)\n            if topic not in topics:\n                topics = topics + ' ' + topic\n            symbols[symbol] = topics\n\n    topics = {\n        'TYPES': ('types', 'STRINGS UNICODE NUMBERS SEQUENCES MAPPINGS '\n                  'FUNCTIONS CLASSES MODULES FILES inspect'),\n        'STRINGS': ('strings', 'str UNICODE SEQUENCES STRINGMETHODS '\n                    'FORMATTING TYPES'),\n        'STRINGMETHODS': ('string-methods', 'STRINGS FORMATTING'),\n        'FORMATTING': ('formatstrings', 'OPERATORS'),\n        'UNICODE': ('strings', 'encodings unicode SEQUENCES STRINGMETHODS '\n                    'FORMATTING TYPES'),\n        'NUMBERS': ('numbers', 'INTEGER FLOAT COMPLEX TYPES'),\n        'INTEGER': ('integers', 'int range'),\n        'FLOAT': ('floating', 'float math'),\n        'COMPLEX': ('imaginary', 'complex cmath'),\n        'SEQUENCES': ('typesseq', 'STRINGMETHODS FORMATTING range LISTS'),\n        'MAPPINGS': 'DICTIONARIES',\n        'FUNCTIONS': ('typesfunctions', 'def TYPES'),\n        'METHODS': ('typesmethods', 'class def CLASSES TYPES'),\n        'CODEOBJECTS': ('bltin-code-objects', 'compile FUNCTIONS TYPES'),\n        'TYPEOBJECTS': ('bltin-type-objects', 'types TYPES'),\n        'FRAMEOBJECTS': 'TYPES',\n        'TRACEBACKS': 'TYPES',\n        'NONE': ('bltin-null-object', ''),\n        'ELLIPSIS': ('bltin-ellipsis-object', 'SLICINGS'),\n        'FILES': ('bltin-file-objects', ''),\n        'SPECIALATTRIBUTES': ('specialattrs', ''),\n        'CLASSES': ('types', 'class SPECIALMETHODS PRIVATENAMES'),\n        'MODULES': ('typesmodules', 'import'),\n        'PACKAGES': 'import',\n        'EXPRESSIONS': ('operator-summary', 'lambda or and not in is BOOLEAN '\n                        'COMPARISON BITWISE SHIFTING BINARY FORMATTING POWER '\n                        'UNARY ATTRIBUTES SUBSCRIPTS SLICINGS CALLS TUPLES '\n                        'LISTS DICTIONARIES'),\n        'OPERATORS': 'EXPRESSIONS',\n        'PRECEDENCE': 'EXPRESSIONS',\n        'OBJECTS': ('objects', 'TYPES'),\n        'SPECIALMETHODS': ('specialnames', 'BASICMETHODS ATTRIBUTEMETHODS '\n                           'CALLABLEMETHODS SEQUENCEMETHODS MAPPINGMETHODS '\n                           'NUMBERMETHODS CLASSES'),\n        'BASICMETHODS': ('customization', 'hash repr str SPECIALMETHODS'),\n        'ATTRIBUTEMETHODS': ('attribute-access', 'ATTRIBUTES SPECIALMETHODS'),\n        'CALLABLEMETHODS': ('callable-types', 'CALLS SPECIALMETHODS'),\n        'SEQUENCEMETHODS': ('sequence-types', 'SEQUENCES SEQUENCEMETHODS '\n                             'SPECIALMETHODS'),\n        'MAPPINGMETHODS': ('sequence-types', 'MAPPINGS SPECIALMETHODS'),\n        'NUMBERMETHODS': ('numeric-types', 'NUMBERS AUGMENTEDASSIGNMENT '\n                          'SPECIALMETHODS'),\n        'EXECUTION': ('execmodel', 'NAMESPACES DYNAMICFEATURES EXCEPTIONS'),\n        'NAMESPACES': ('naming', 'global nonlocal ASSIGNMENT DELETION DYNAMICFEATURES'),\n        'DYNAMICFEATURES': ('dynamic-features', ''),\n        'SCOPING': 'NAMESPACES',\n        'FRAMES': 'NAMESPACES',\n        'EXCEPTIONS': ('exceptions', 'try except finally raise'),\n        'CONVERSIONS': ('conversions', ''),\n        'IDENTIFIERS': ('identifiers', 'keywords SPECIALIDENTIFIERS'),\n        'SPECIALIDENTIFIERS': ('id-classes', ''),\n        'PRIVATENAMES': ('atom-identifiers', ''),\n        'LITERALS': ('atom-literals', 'STRINGS NUMBERS TUPLELITERALS '\n                     'LISTLITERALS DICTIONARYLITERALS'),\n        'TUPLES': 'SEQUENCES',\n        'TUPLELITERALS': ('exprlists', 'TUPLES LITERALS'),\n        'LISTS': ('typesseq-mutable', 'LISTLITERALS'),\n        'LISTLITERALS': ('lists', 'LISTS LITERALS'),\n        'DICTIONARIES': ('typesmapping', 'DICTIONARYLITERALS'),\n        'DICTIONARYLITERALS': ('dict', 'DICTIONARIES LITERALS'),\n        'ATTRIBUTES': ('attribute-references', 'getattr hasattr setattr ATTRIBUTEMETHODS'),\n        'SUBSCRIPTS': ('subscriptions', 'SEQUENCEMETHODS'),\n        'SLICINGS': ('slicings', 'SEQUENCEMETHODS'),\n        'CALLS': ('calls', 'EXPRESSIONS'),\n        'POWER': ('power', 'EXPRESSIONS'),\n        'UNARY': ('unary', 'EXPRESSIONS'),\n        'BINARY': ('binary', 'EXPRESSIONS'),\n        'SHIFTING': ('shifting', 'EXPRESSIONS'),\n        'BITWISE': ('bitwise', 'EXPRESSIONS'),\n        'COMPARISON': ('comparisons', 'EXPRESSIONS BASICMETHODS'),\n        'BOOLEAN': ('booleans', 'EXPRESSIONS TRUTHVALUE'),\n        'ASSERTION': 'assert',\n        'ASSIGNMENT': ('assignment', 'AUGMENTEDASSIGNMENT'),\n        'AUGMENTEDASSIGNMENT': ('augassign', 'NUMBERMETHODS'),\n        'DELETION': 'del',\n        'RETURNING': 'return',\n        'IMPORTING': 'import',\n        'CONDITIONAL': 'if',\n        'LOOPING': ('compound', 'for while break continue'),\n        'TRUTHVALUE': ('truth', 'if while and or not BASICMETHODS'),\n        'DEBUGGING': ('debugger', 'pdb'),\n        'CONTEXTMANAGERS': ('context-managers', 'with'),\n    }\n\n    def __init__(self, input=None, output=None):\n        self._input = input\n        self._output = output\n\n        #fix me brython\n        self.input = self._input or sys.stdin \n        self.output = self._output or sys.stdout \n\n    #fix me brython\n    #input  = property(lambda self: self._input or sys.stdin)\n    #output = property(lambda self: self._output or sys.stdout)\n\n    def __repr__(self):\n        if inspect.stack()[1][3] == '?':\n            self()\n            return ''\n        return '<pydoc.Helper instance>'\n\n    _GoInteractive = object()\n    def __call__(self, request=_GoInteractive):\n        if request is not self._GoInteractive:\n            self.help(request)\n        else:\n            self.intro()\n            self.interact()\n            self.output.write('''\nYou are now leaving help and returning to the Python interpreter.\nIf you want to ask for help on a particular object directly from the\ninterpreter, you can type \"help(object)\".  Executing \"help('string')\"\nhas the same effect as typing a particular string at the help> prompt.\n''')\n\n    def interact(self):\n        self.output.write('\\n')\n        while True:\n            try:\n                request = self.getline('help> ')\n                if not request: break\n            except (KeyboardInterrupt, EOFError):\n                break\n            request = replace(request, '\"', '', \"'\", '').strip()\n            if request.lower() in ('q', 'quit'): break\n            self.help(request)\n\n    def getline(self, prompt):\n        \"\"\"Read one line, using input() when appropriate.\"\"\"\n        if self.input is sys.stdin:\n            return input(prompt)\n        else:\n            self.output.write(prompt)\n            self.output.flush()\n            return self.input.readline()\n\n    def help(self, request):\n        if type(request) is type(''):\n            request = request.strip()\n            if request == 'help': self.intro()\n            elif request == 'keywords': self.listkeywords()\n            elif request == 'symbols': self.listsymbols()\n            elif request == 'topics': self.listtopics()\n            elif request == 'modules': self.listmodules()\n            elif request[:8] == 'modules ':\n                self.listmodules(request.split()[1])\n            elif request in self.symbols: self.showsymbol(request)\n            elif request in ['True', 'False', 'None']:\n                # special case these keywords since they are objects too\n                doc(eval(request), 'Help on %s:')\n            elif request in self.keywords: self.showtopic(request)\n            elif request in self.topics: self.showtopic(request)\n            elif request: doc(request, 'Help on %s:', output=self._output)\n        elif isinstance(request, Helper): self()\n        else: doc(request, 'Help on %s:', output=self._output)\n        self.output.write('\\n')\n\n    def intro(self):\n        self.output.write('''\nWelcome to Python %s!  This is the interactive help utility.\n\nIf this is your first time using Python, you should definitely check out\nthe tutorial on the Internet at http://docs.python.org/%s/tutorial/.\n\nEnter the name of any module, keyword, or topic to get help on writing\nPython programs and using Python modules.  To quit this help utility and\nreturn to the interpreter, just type \"quit\".\n\nTo get a list of available modules, keywords, or topics, type \"modules\",\n\"keywords\", or \"topics\".  Each module also comes with a one-line summary\nof what it does; to list the modules whose summaries contain a given word\nsuch as \"spam\", type \"modules spam\".\n''' % tuple([sys.version[:3]]*2))\n\n    def list(self, items, columns=4, width=80):\n        items = list(sorted(items))\n        colw = width // columns\n        rows = (len(items) + columns - 1) // columns\n        for row in range(rows):\n            for col in range(columns):\n                i = col * rows + row\n                if i < len(items):\n                    self.output.write(items[i])\n                    if col < columns - 1:\n                        self.output.write(' ' + ' ' * (colw - 1 - len(items[i])))\n            self.output.write('\\n')\n\n    def listkeywords(self):\n        self.output.write('''\nHere is a list of the Python keywords.  Enter any keyword to get more help.\n\n''')\n        self.list(self.keywords.keys())\n\n    def listsymbols(self):\n        self.output.write('''\nHere is a list of the punctuation symbols which Python assigns special meaning\nto. Enter any symbol to get more help.\n\n''')\n        self.list(self.symbols.keys())\n\n    def listtopics(self):\n        self.output.write('''\nHere is a list of available topics.  Enter any topic name to get more help.\n\n''')\n        self.list(self.topics.keys())\n\n    def showtopic(self, topic, more_xrefs=''):\n        try:\n            import pydoc_data.topics\n        except ImportError:\n            self.output.write('''\nSorry, topic and keyword documentation is not available because the\nmodule \"pydoc_data.topics\" could not be found.\n''')\n            return\n        target = self.topics.get(topic, self.keywords.get(topic))\n        if not target:\n            self.output.write('no documentation found for %s\\n' % repr(topic))\n            return\n        if type(target) is type(''):\n            return self.showtopic(target, more_xrefs)\n\n        label, xrefs = target\n        try:\n            doc = pydoc_data.topics.topics[label]\n        except KeyError:\n            self.output.write('no documentation found for %s\\n' % repr(topic))\n            return\n        pager(doc.strip() + '\\n')\n        if more_xrefs:\n            xrefs = (xrefs or '') + ' ' + more_xrefs\n        if xrefs:\n            import formatter\n            buffer = io.StringIO()\n            formatter.DumbWriter(buffer).send_flowing_data(\n                'Related help topics: ' + ', '.join(xrefs.split()) + '\\n')\n            self.output.write('\\n%s\\n' % buffer.getvalue())\n\n    def _gettopic(self, topic, more_xrefs=''):\n        \"\"\"Return unbuffered tuple of (topic, xrefs).\n\n        If an error occurs here, the exception is caught and displayed by\n        the url handler.\n\n        This function duplicates the showtopic method but returns its\n        result directly so it can be formatted for display in an html page.\n        \"\"\"\n        try:\n            import pydoc_data.topics\n        except ImportError:\n            return('''\nSorry, topic and keyword documentation is not available because the\nmodule \"pydoc_data.topics\" could not be found.\n''' , '')\n        target = self.topics.get(topic, self.keywords.get(topic))\n        if not target:\n            raise ValueError('could not find topic')\n        if isinstance(target, str):\n            return self._gettopic(target, more_xrefs)\n        label, xrefs = target\n        doc = pydoc_data.topics.topics[label]\n        if more_xrefs:\n            xrefs = (xrefs or '') + ' ' + more_xrefs\n        return doc, xrefs\n\n    def showsymbol(self, symbol):\n        target = self.symbols[symbol]\n        topic, _, xrefs = target.partition(' ')\n        self.showtopic(topic, xrefs)\n\n    def listmodules(self, key=''):\n        if key:\n            self.output.write('''\nHere is a list of matching modules.  Enter any module name to get more help.\n\n''')\n            apropos(key)\n        else:\n            self.output.write('''\nPlease wait a moment while I gather a list of all available modules...\n\n''')\n            modules = {}\n            def callback(path, modname, desc, modules=modules):\n                if modname and modname[-9:] == '.__init__':\n                    modname = modname[:-9] + ' (package)'\n                if modname.find('.') < 0:\n                    modules[modname] = 1\n            def onerror(modname):\n                callback(None, modname, None)\n            ModuleScanner().run(callback, onerror=onerror)\n            self.list(modules.keys())\n            self.output.write('''\nEnter any module name to get more help.  Or, type \"modules spam\" to search\nfor modules whose descriptions contain the word \"spam\".\n''')\n\nhelp = Helper()\n\nclass Scanner:\n    \"\"\"A generic tree iterator.\"\"\"\n    def __init__(self, roots, children, descendp):\n        self.roots = roots[:]\n        self.state = []\n        self.children = children\n        self.descendp = descendp\n\n    def next(self):\n        if not self.state:\n            if not self.roots:\n                return None\n            root = self.roots.pop(0)\n            self.state = [(root, self.children(root))]\n        node, children = self.state[-1]\n        if not children:\n            self.state.pop()\n            return self.next()\n        child = children.pop(0)\n        if self.descendp(child):\n            self.state.append((child, self.children(child)))\n        return child\n\n\nclass ModuleScanner:\n    \"\"\"An interruptible scanner that searches module synopses.\"\"\"\n\n    def run(self, callback, key=None, completer=None, onerror=None):\n        if key: key = key.lower()\n        self.quit = False\n        seen = {}\n\n        for modname in sys.builtin_module_names:\n            if modname != '__main__':\n                seen[modname] = 1\n                if key is None:\n                    callback(None, modname, '')\n                else:\n                    name = __import__(modname).__doc__ or ''\n                    desc = name.split('\\n')[0]\n                    name = modname + ' - ' + desc\n                    if name.lower().find(key) >= 0:\n                        callback(None, modname, desc)\n\n        for importer, modname, ispkg in pkgutil.walk_packages(onerror=onerror):\n            if self.quit:\n                break\n\n            if key is None:\n                callback(None, modname, '')\n            else:\n                try:\n                    loader = importer.find_module(modname)\n                except SyntaxError:\n                    # raised by tests for bad coding cookies or BOM\n                    continue\n                if hasattr(loader, 'get_source'):\n                    try:\n                        source = loader.get_source(modname)\n                    except Exception:\n                        if onerror:\n                            onerror(modname)\n                        continue\n                    desc = source_synopsis(io.StringIO(source)) or ''\n                    if hasattr(loader, 'get_filename'):\n                        path = loader.get_filename(modname)\n                    else:\n                        path = None\n                else:\n                    try:\n                        module = loader.load_module(modname)\n                    except ImportError:\n                        if onerror:\n                            onerror(modname)\n                        continue\n                    desc = (module.__doc__ or '').splitlines()[0]\n                    path = getattr(module,'__file__',None)\n                name = modname + ' - ' + desc\n                if name.lower().find(key) >= 0:\n                    callback(path, modname, desc)\n\n        if completer:\n            completer()\n\ndef apropos(key):\n    \"\"\"Print all the one-line module summaries that contain a substring.\"\"\"\n    def callback(path, modname, desc):\n        if modname[-9:] == '.__init__':\n            modname = modname[:-9] + ' (package)'\n        print(modname, desc and '- ' + desc)\n    def onerror(modname):\n        pass\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore') # ignore problems during import\n        ModuleScanner().run(callback, key, onerror=onerror)\n\n# --------------------------------------- enhanced Web browser interface\n\ndef _start_server(urlhandler, port):\n    \"\"\"Start an HTTP server thread on a specific port.\n\n    Start an HTML/text server thread, so HTML or text documents can be\n    browsed dynamically and interactively with a Web browser.  Example use:\n\n        >>> import time\n        >>> import pydoc\n\n        Define a URL handler.  To determine what the client is asking\n        for, check the URL and content_type.\n\n        Then get or generate some text or HTML code and return it.\n\n        >>> def my_url_handler(url, content_type):\n        ...     text = 'the URL sent was: (%s, %s)' % (url, content_type)\n        ...     return text\n\n        Start server thread on port 0.\n        If you use port 0, the server will pick a random port number.\n        You can then use serverthread.port to get the port number.\n\n        >>> port = 0\n        >>> serverthread = pydoc._start_server(my_url_handler, port)\n\n        Check that the server is really started.  If it is, open browser\n        and get first page.  Use serverthread.url as the starting page.\n\n        >>> if serverthread.serving:\n        ...    import webbrowser\n\n        The next two lines are commented out so a browser doesn't open if\n        doctest is run on this module.\n\n        #...    webbrowser.open(serverthread.url)\n        #True\n\n        Let the server do its thing. We just need to monitor its status.\n        Use time.sleep so the loop doesn't hog the CPU.\n\n        >>> starttime = time.time()\n        >>> timeout = 1                    #seconds\n\n        This is a short timeout for testing purposes.\n\n        >>> while serverthread.serving:\n        ...     time.sleep(.01)\n        ...     if serverthread.serving and time.time() - starttime > timeout:\n        ...          serverthread.stop()\n        ...          break\n\n        Print any errors that may have occurred.\n\n        >>> print(serverthread.error)\n        None\n   \"\"\"\n    import http.server\n    import email.message\n    import select\n    import threading\n\n    class DocHandler(http.server.BaseHTTPRequestHandler):\n\n        def do_GET(self):\n            \"\"\"Process a request from an HTML browser.\n\n            The URL received is in self.path.\n            Get an HTML page from self.urlhandler and send it.\n            \"\"\"\n            if self.path.endswith('.css'):\n                content_type = 'text/css'\n            else:\n                content_type = 'text/html'\n            self.send_response(200)\n            self.send_header('Content-Type', '%s; charset=UTF-8' % content_type)\n            self.end_headers()\n            self.wfile.write(self.urlhandler(\n                self.path, content_type).encode('utf-8'))\n\n        def log_message(self, *args):\n            # Don't log messages.\n            pass\n\n    class DocServer(http.server.HTTPServer):\n\n        def __init__(self, port, callback):\n            self.host = (sys.platform == 'mac') and '127.0.0.1' or 'localhost'\n            self.address = ('', port)\n            self.callback = callback\n            self.base.__init__(self, self.address, self.handler)\n            self.quit = False\n\n        def serve_until_quit(self):\n            while not self.quit:\n                rd, wr, ex = select.select([self.socket.fileno()], [], [], 1)\n                if rd:\n                    self.handle_request()\n            self.server_close()\n\n        def server_activate(self):\n            self.base.server_activate(self)\n            if self.callback:\n                self.callback(self)\n\n    class ServerThread(threading.Thread):\n\n        def __init__(self, urlhandler, port):\n            self.urlhandler = urlhandler\n            self.port = int(port)\n            threading.Thread.__init__(self)\n            self.serving = False\n            self.error = None\n\n        def run(self):\n            \"\"\"Start the server.\"\"\"\n            try:\n                DocServer.base = http.server.HTTPServer\n                DocServer.handler = DocHandler\n                DocHandler.MessageClass = email.message.Message\n                DocHandler.urlhandler = staticmethod(self.urlhandler)\n                docsvr = DocServer(self.port, self.ready)\n                self.docserver = docsvr\n                docsvr.serve_until_quit()\n            except Exception as e:\n                self.error = e\n\n        def ready(self, server):\n            self.serving = True\n            self.host = server.host\n            self.port = server.server_port\n            self.url = 'http://%s:%d/' % (self.host, self.port)\n\n        def stop(self):\n            \"\"\"Stop the server and this thread nicely\"\"\"\n            self.docserver.quit = True\n            self.serving = False\n            self.url = None\n\n    thread = ServerThread(urlhandler, port)\n    thread.start()\n    # Wait until thread.serving is True to make sure we are\n    # really up before returning.\n    while not thread.error and not thread.serving:\n        time.sleep(.01)\n    return thread\n\n\ndef _url_handler(url, content_type=\"text/html\"):\n    \"\"\"The pydoc url handler for use with the pydoc server.\n\n    If the content_type is 'text/css', the _pydoc.css style\n    sheet is read and returned if it exits.\n\n    If the content_type is 'text/html', then the result of\n    get_html_page(url) is returned.\n    \"\"\"\n    class _HTMLDoc(HTMLDoc):\n\n        def page(self, title, contents):\n            \"\"\"Format an HTML page.\"\"\"\n            css_path = \"pydoc_data/_pydoc.css\"\n            css_link = (\n                '<link rel=\"stylesheet\" type=\"text/css\" href=\"%s\">' %\n                css_path)\n            return '''\\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<html><head><title>Pydoc: %s</title>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n%s</head><body bgcolor=\"#f0f0f8\">%s<div style=\"clear:both;padding-top:.5em;\">%s</div>\n</body></html>''' % (title, css_link, html_navbar(), contents)\n\n        def filelink(self, url, path):\n            return '<a href=\"getfile?key=%s\">%s</a>' % (url, path)\n\n\n    html = _HTMLDoc()\n\n    def html_navbar():\n        version = html.escape(\"%s [%s, %s]\" % (platform.python_version(),\n                                               platform.python_build()[0],\n                                               platform.python_compiler()))\n        return \"\"\"\n            <div style='float:left'>\n                Python %s<br>%s\n            </div>\n            <div style='float:right'>\n                <div style='text-align:center'>\n                  <a href=\"index.html\">Module Index</a>\n                  : <a href=\"topics.html\">Topics</a>\n                  : <a href=\"keywords.html\">Keywords</a>\n                </div>\n                <div>\n                    <form action=\"get\" style='display:inline;'>\n                      <input type=text name=key size=15>\n                      <input type=submit value=\"Get\">\n                    </form>&nbsp;\n                    <form action=\"search\" style='display:inline;'>\n                      <input type=text name=key size=15>\n                      <input type=submit value=\"Search\">\n                    </form>\n                </div>\n            </div>\n            \"\"\" % (version, html.escape(platform.platform(terse=True)))\n\n    def html_index():\n        \"\"\"Module Index page.\"\"\"\n\n        def bltinlink(name):\n            return '<a href=\"%s.html\">%s</a>' % (name, name)\n\n        heading = html.heading(\n            '<big><big><strong>Index of Modules</strong></big></big>',\n            '#ffffff', '#7799ee')\n        names = [name for name in sys.builtin_module_names\n                 if name != '__main__']\n        contents = html.multicolumn(names, bltinlink)\n        contents = [heading, '<p>' + html.bigsection(\n            'Built-in Modules', '#ffffff', '#ee77aa', contents)]\n\n        seen = {}\n        for dir in sys.path:\n            contents.append(html.index(dir, seen))\n\n        contents.append(\n            '<p align=right><font color=\"#909090\" face=\"helvetica,'\n            'arial\"><strong>pydoc</strong> by Ka-Ping Yee'\n            '&lt;ping@lfw.org&gt;</font>')\n        return 'Index of Modules', ''.join(contents)\n\n    def html_search(key):\n        \"\"\"Search results page.\"\"\"\n        # scan for modules\n        search_result = []\n\n        def callback(path, modname, desc):\n            if modname[-9:] == '.__init__':\n                modname = modname[:-9] + ' (package)'\n            search_result.append((modname, desc and '- ' + desc))\n\n        with warnings.catch_warnings():\n            warnings.filterwarnings('ignore') # ignore problems during import\n            ModuleScanner().run(callback, key)\n\n        # format page\n        def bltinlink(name):\n            return '<a href=\"%s.html\">%s</a>' % (name, name)\n\n        results = []\n        heading = html.heading(\n            '<big><big><strong>Search Results</strong></big></big>',\n            '#ffffff', '#7799ee')\n        for name, desc in search_result:\n            results.append(bltinlink(name) + desc)\n        contents = heading + html.bigsection(\n            'key = %s' % key, '#ffffff', '#ee77aa', '<br>'.join(results))\n        return 'Search Results', contents\n\n    def html_getfile(path):\n        \"\"\"Get and display a source file listing safely.\"\"\"\n        path = path.replace('%20', ' ')\n        with tokenize.open(path) as fp:\n            lines = html.escape(fp.read())\n        body = '<pre>%s</pre>' % lines\n        heading = html.heading(\n            '<big><big><strong>File Listing</strong></big></big>',\n            '#ffffff', '#7799ee')\n        contents = heading + html.bigsection(\n            'File: %s' % path, '#ffffff', '#ee77aa', body)\n        return 'getfile %s' % path, contents\n\n    def html_topics():\n        \"\"\"Index of topic texts available.\"\"\"\n\n        def bltinlink(name):\n            return '<a href=\"topic?key=%s\">%s</a>' % (name, name)\n\n        heading = html.heading(\n            '<big><big><strong>INDEX</strong></big></big>',\n            '#ffffff', '#7799ee')\n        names = sorted(Helper.topics.keys())\n\n        contents = html.multicolumn(names, bltinlink)\n        contents = heading + html.bigsection(\n            'Topics', '#ffffff', '#ee77aa', contents)\n        return 'Topics', contents\n\n    def html_keywords():\n        \"\"\"Index of keywords.\"\"\"\n        heading = html.heading(\n            '<big><big><strong>INDEX</strong></big></big>',\n            '#ffffff', '#7799ee')\n        names = sorted(Helper.keywords.keys())\n\n        def bltinlink(name):\n            return '<a href=\"topic?key=%s\">%s</a>' % (name, name)\n\n        contents = html.multicolumn(names, bltinlink)\n        contents = heading + html.bigsection(\n            'Keywords', '#ffffff', '#ee77aa', contents)\n        return 'Keywords', contents\n\n    def html_topicpage(topic):\n        \"\"\"Topic or keyword help page.\"\"\"\n        buf = io.StringIO()\n        htmlhelp = Helper(buf, buf)\n        contents, xrefs = htmlhelp._gettopic(topic)\n        if topic in htmlhelp.keywords:\n            title = 'KEYWORD'\n        else:\n            title = 'TOPIC'\n        heading = html.heading(\n            '<big><big><strong>%s</strong></big></big>' % title,\n            '#ffffff', '#7799ee')\n        contents = '<pre>%s</pre>' % html.markup(contents)\n        contents = html.bigsection(topic , '#ffffff','#ee77aa', contents)\n        if xrefs:\n            xrefs = sorted(xrefs.split())\n\n            def bltinlink(name):\n                return '<a href=\"topic?key=%s\">%s</a>' % (name, name)\n\n            xrefs = html.multicolumn(xrefs, bltinlink)\n            xrefs = html.section('Related help topics: ',\n                                 '#ffffff', '#ee77aa', xrefs)\n        return ('%s %s' % (title, topic),\n                ''.join((heading, contents, xrefs)))\n\n    def html_getobj(url):\n        obj = locate(url, forceload=1)\n        if obj is None and url != 'None':\n            raise ValueError('could not find object')\n        title = describe(obj)\n        content = html.document(obj, url)\n        return title, content\n\n    def html_error(url, exc):\n        heading = html.heading(\n            '<big><big><strong>Error</strong></big></big>',\n            '#ffffff', '#7799ee')\n        contents = '<br>'.join(html.escape(line) for line in\n                               format_exception_only(type(exc), exc))\n        contents = heading + html.bigsection(url, '#ffffff', '#bb0000',\n                                             contents)\n        return \"Error - %s\" % url, contents\n\n    def get_html_page(url):\n        \"\"\"Generate an HTML page for url.\"\"\"\n        complete_url = url\n        if url.endswith('.html'):\n            url = url[:-5]\n        try:\n            if url in (\"\", \"index\"):\n                title, content = html_index()\n            elif url == \"topics\":\n                title, content = html_topics()\n            elif url == \"keywords\":\n                title, content = html_keywords()\n            elif '=' in url:\n                op, _, url = url.partition('=')\n                if op == \"search?key\":\n                    title, content = html_search(url)\n                elif op == \"getfile?key\":\n                    title, content = html_getfile(url)\n                elif op == \"topic?key\":\n                    # try topics first, then objects.\n                    try:\n                        title, content = html_topicpage(url)\n                    except ValueError:\n                        title, content = html_getobj(url)\n                elif op == \"get?key\":\n                    # try objects first, then topics.\n                    if url in (\"\", \"index\"):\n                        title, content = html_index()\n                    else:\n                        try:\n                            title, content = html_getobj(url)\n                        except ValueError:\n                            title, content = html_topicpage(url)\n                else:\n                    raise ValueError('bad pydoc url')\n            else:\n                title, content = html_getobj(url)\n        except Exception as exc:\n            # Catch any errors and display them in an error page.\n            title, content = html_error(complete_url, exc)\n        return html.page(title, content)\n\n    if url.startswith('/'):\n        url = url[1:]\n    if content_type == 'text/css':\n        path_here = os.path.dirname(os.path.realpath(__file__))\n        css_path = os.path.join(path_here, url)\n        with open(css_path) as fp:\n            return ''.join(fp.readlines())\n    elif content_type == 'text/html':\n        return get_html_page(url)\n    # Errors outside the url handler are caught by the server.\n    raise TypeError('unknown content type %r for url %s' % (content_type, url))\n\n\ndef browse(port=0, *, open_browser=True):\n    \"\"\"Start the enhanced pydoc Web server and open a Web browser.\n\n    Use port '0' to start the server on an arbitrary port.\n    Set open_browser to False to suppress opening a browser.\n    \"\"\"\n    import webbrowser\n    serverthread = _start_server(_url_handler, port)\n    if serverthread.error:\n        print(serverthread.error)\n        return\n    if serverthread.serving:\n        server_help_msg = 'Server commands: [b]rowser, [q]uit'\n        if open_browser:\n            webbrowser.open(serverthread.url)\n        try:\n            print('Server ready at', serverthread.url)\n            print(server_help_msg)\n            while serverthread.serving:\n                cmd = input('server> ')\n                cmd = cmd.lower()\n                if cmd == 'q':\n                    break\n                elif cmd == 'b':\n                    webbrowser.open(serverthread.url)\n                else:\n                    print(server_help_msg)\n        except (KeyboardInterrupt, EOFError):\n            print()\n        finally:\n            if serverthread.serving:\n                serverthread.stop()\n                print('Server stopped')\n\n\n# -------------------------------------------------- command-line interface\n\ndef ispath(x):\n    return isinstance(x, str) and x.find(os.sep) >= 0\n\ndef cli():\n    \"\"\"Command-line interface (looks at sys.argv to decide what to do).\"\"\"\n    import getopt\n    class BadUsage(Exception): pass\n\n    # Scripts don't get the current directory in their path by default\n    # unless they are run with the '-m' switch\n    if '' not in sys.path:\n        scriptdir = os.path.dirname(sys.argv[0])\n        if scriptdir in sys.path:\n            sys.path.remove(scriptdir)\n        sys.path.insert(0, '.')\n\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], 'bk:p:w')\n        writing = False\n        start_server = False\n        open_browser = False\n        port = None\n        for opt, val in opts:\n            if opt == '-b':\n                start_server = True\n                open_browser = True\n            if opt == '-k':\n                apropos(val)\n                return\n            if opt == '-p':\n                start_server = True\n                port = val\n            if opt == '-w':\n                writing = True\n\n        if start_server:\n            if port is None:\n                port = 0\n            browse(port, open_browser=open_browser)\n            return\n\n        if not args: raise BadUsage\n        for arg in args:\n            if ispath(arg) and not os.path.exists(arg):\n                print('file %r does not exist' % arg)\n                break\n            try:\n                if ispath(arg) and os.path.isfile(arg):\n                    arg = importfile(arg)\n                if writing:\n                    if ispath(arg) and os.path.isdir(arg):\n                        writedocs(arg)\n                    else:\n                        writedoc(arg)\n                else:\n                    help.help(arg)\n            except ErrorDuringImport as value:\n                print(value)\n\n    except (getopt.error, BadUsage):\n        cmd = os.path.splitext(os.path.basename(sys.argv[0]))[0]\n        print(\"\"\"pydoc - the Python documentation tool\n\n{cmd} <name> ...\n    Show text documentation on something.  <name> may be the name of a\n    Python keyword, topic, function, module, or package, or a dotted\n    reference to a class or function within a module or module in a\n    package.  If <name> contains a '{sep}', it is used as the path to a\n    Python source file to document. If name is 'keywords', 'topics',\n    or 'modules', a listing of these things is displayed.\n\n{cmd} -k <keyword>\n    Search for a keyword in the synopsis lines of all available modules.\n\n{cmd} -p <port>\n    Start an HTTP server on the given port on the local machine.  Port\n    number 0 can be used to get an arbitrary unused port.\n\n{cmd} -b\n    Start an HTTP server on an arbitrary unused port and open a Web browser\n    to interactively browse documentation.  The -p option can be used with\n    the -b option to explicitly specify the server port.\n\n{cmd} -w <name> ...\n    Write out the HTML documentation for a module to a file in the current\n    directory.  If <name> contains a '{sep}', it is treated as a filename; if\n    it names a directory, documentation is written for all the contents.\n\"\"\".format(cmd=cmd, sep=os.sep))\n\nif __name__ == '__main__':\n    cli()\n"], "threading": [".py", "\"\"\"Thread module emulating a subset of Java's threading model.\"\"\"\n\nimport sys as _sys\nimport _thread\n\nfrom time import sleep as _sleep\ntry:\n    from time import monotonic as _time\nexcept ImportError:\n    from time import time as _time\nfrom traceback import format_exc as _format_exc\nfrom _weakrefset import WeakSet\n\n# Note regarding PEP 8 compliant names\n#  This threading model was originally inspired by Java, and inherited\n# the convention of camelCase function and method names from that\n# language. Those original names are not in any imminent danger of\n# being deprecated (even for Py3k),so this module provides them as an\n# alias for the PEP 8 compliant names\n# Note that using the new PEP 8 compliant names facilitates substitution\n# with the multiprocessing module, which doesn't provide the old\n# Java inspired names.\n\n__all__ = ['active_count', 'Condition', 'current_thread', 'enumerate', 'Event',\n           'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Thread', 'Barrier',\n           'Timer', 'ThreadError', 'setprofile', 'settrace', 'local', 'stack_size']\n\n# Rename some stuff so \"from threading import *\" is safe\n_start_new_thread = _thread.start_new_thread\n_allocate_lock = _thread.allocate_lock\nget_ident = _thread.get_ident\nThreadError = _thread.error\ntry:\n    _CRLock = _thread.RLock\nexcept AttributeError:\n    _CRLock = None\nTIMEOUT_MAX = _thread.TIMEOUT_MAX\ndel _thread\n\n\n# Support for profile and trace hooks\n\n_profile_hook = None\n_trace_hook = None\n\ndef setprofile(func):\n    \"\"\"Set a profile function for all threads started from the threading module.\n\n    The func will be passed to sys.setprofile() for each thread, before its\n    run() method is called.\n\n    \"\"\"\n    global _profile_hook\n    _profile_hook = func\n\ndef settrace(func):\n    \"\"\"Set a trace function for all threads started from the threading module.\n\n    The func will be passed to sys.settrace() for each thread, before its run()\n    method is called.\n\n    \"\"\"\n    global _trace_hook\n    _trace_hook = func\n\n# Synchronization classes\n\nLock = _allocate_lock\n\ndef RLock(*args, **kwargs):\n    \"\"\"Factory function that returns a new reentrant lock.\n\n    A reentrant lock must be released by the thread that acquired it. Once a\n    thread has acquired a reentrant lock, the same thread may acquire it again\n    without blocking; the thread must release it once for each time it has\n    acquired it.\n\n    \"\"\"\n    if _CRLock is None:\n        return _PyRLock(*args, **kwargs)\n    return _CRLock(*args, **kwargs)\n\nclass _RLock:\n    \"\"\"This class implements reentrant lock objects.\n\n    A reentrant lock must be released by the thread that acquired it. Once a\n    thread has acquired a reentrant lock, the same thread may acquire it\n    again without blocking; the thread must release it once for each time it\n    has acquired it.\n\n    \"\"\"\n\n    def __init__(self):\n        self._block = _allocate_lock()\n        self._owner = None\n        self._count = 0\n\n    def __repr__(self):\n        owner = self._owner\n        try:\n            owner = _active[owner].name\n        except KeyError:\n            pass\n        return \"<%s owner=%r count=%d>\" % (\n                self.__class__.__name__, owner, self._count)\n\n    def acquire(self, blocking=True, timeout=-1):\n        \"\"\"Acquire a lock, blocking or non-blocking.\n\n        When invoked without arguments: if this thread already owns the lock,\n        increment the recursion level by one, and return immediately. Otherwise,\n        if another thread owns the lock, block until the lock is unlocked. Once\n        the lock is unlocked (not owned by any thread), then grab ownership, set\n        the recursion level to one, and return. If more than one thread is\n        blocked waiting until the lock is unlocked, only one at a time will be\n        able to grab ownership of the lock. There is no return value in this\n        case.\n\n        When invoked with the blocking argument set to true, do the same thing\n        as when called without arguments, and return true.\n\n        When invoked with the blocking argument set to false, do not block. If a\n        call without an argument would block, return false immediately;\n        otherwise, do the same thing as when called without arguments, and\n        return true.\n\n        When invoked with the floating-point timeout argument set to a positive\n        value, block for at most the number of seconds specified by timeout\n        and as long as the lock cannot be acquired.  Return true if the lock has\n        been acquired, false if the timeout has elapsed.\n\n        \"\"\"\n        me = get_ident()\n        if self._owner == me:\n            self._count = self._count + 1\n            return 1\n        rc = self._block.acquire(blocking, timeout)\n        if rc:\n            self._owner = me\n            self._count = 1\n        return rc\n\n    __enter__ = acquire\n\n    def release(self):\n        \"\"\"Release a lock, decrementing the recursion level.\n\n        If after the decrement it is zero, reset the lock to unlocked (not owned\n        by any thread), and if any other threads are blocked waiting for the\n        lock to become unlocked, allow exactly one of them to proceed. If after\n        the decrement the recursion level is still nonzero, the lock remains\n        locked and owned by the calling thread.\n\n        Only call this method when the calling thread owns the lock. A\n        RuntimeError is raised if this method is called when the lock is\n        unlocked.\n\n        There is no return value.\n\n        \"\"\"\n        if self._owner != get_ident():\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        self._count = count = self._count - 1\n        if not count:\n            self._owner = None\n            self._block.release()\n\n    def __exit__(self, t, v, tb):\n        self.release()\n\n    # Internal methods used by condition variables\n\n    def _acquire_restore(self, state):\n        self._block.acquire()\n        self._count, self._owner = state\n\n    def _release_save(self):\n        if self._count == 0:\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        count = self._count\n        self._count = 0\n        owner = self._owner\n        self._owner = None\n        self._block.release()\n        return (count, owner)\n\n    def _is_owned(self):\n        return self._owner == get_ident()\n\n_PyRLock = _RLock\n\n\nclass Condition:\n    \"\"\"Class that implements a condition variable.\n\n    A condition variable allows one or more threads to wait until they are\n    notified by another thread.\n\n    If the lock argument is given and not None, it must be a Lock or RLock\n    object, and it is used as the underlying lock. Otherwise, a new RLock object\n    is created and used as the underlying lock.\n\n    \"\"\"\n\n    def __init__(self, lock=None):\n        if lock is None:\n            lock = RLock()\n        self._lock = lock\n        # Export the lock's acquire() and release() methods\n        self.acquire = lock.acquire\n        self.release = lock.release\n        # If the lock defines _release_save() and/or _acquire_restore(),\n        # these override the default implementations (which just call\n        # release() and acquire() on the lock).  Ditto for _is_owned().\n        try:\n            self._release_save = lock._release_save\n        except AttributeError:\n            pass\n        try:\n            self._acquire_restore = lock._acquire_restore\n        except AttributeError:\n            pass\n        try:\n            self._is_owned = lock._is_owned\n        except AttributeError:\n            pass\n        self._waiters = []\n\n    def __enter__(self):\n        return self._lock.__enter__()\n\n    def __exit__(self, *args):\n        return self._lock.__exit__(*args)\n\n    def __repr__(self):\n        return \"<Condition(%s, %d)>\" % (self._lock, len(self._waiters))\n\n    def _release_save(self):\n        self._lock.release()           # No state to save\n\n    def _acquire_restore(self, x):\n        self._lock.acquire()           # Ignore saved state\n\n    def _is_owned(self):\n        # Return True if lock is owned by current_thread.\n        # This method is called only if __lock doesn't have _is_owned().\n        if self._lock.acquire(0):\n            self._lock.release()\n            return False\n        else:\n            return True\n\n    def wait(self, timeout=None):\n        \"\"\"Wait until notified or until a timeout occurs.\n\n        If the calling thread has not acquired the lock when this method is\n        called, a RuntimeError is raised.\n\n        This method releases the underlying lock, and then blocks until it is\n        awakened by a notify() or notify_all() call for the same condition\n        variable in another thread, or until the optional timeout occurs. Once\n        awakened or timed out, it re-acquires the lock and returns.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof).\n\n        When the underlying lock is an RLock, it is not released using its\n        release() method, since this may not actually unlock the lock when it\n        was acquired multiple times recursively. Instead, an internal interface\n        of the RLock class is used, which really unlocks it even when it has\n        been recursively acquired several times. Another internal interface is\n        then used to restore the recursion level when the lock is reacquired.\n\n        \"\"\"\n        if not self._is_owned():\n            raise RuntimeError(\"cannot wait on un-acquired lock\")\n        waiter = _allocate_lock()\n        waiter.acquire()\n        self._waiters.append(waiter)\n        saved_state = self._release_save()\n        try:    # restore state no matter what (e.g., KeyboardInterrupt)\n            if timeout is None:\n                waiter.acquire()\n                gotit = True\n            else:\n                if timeout > 0:\n                    gotit = waiter.acquire(True, timeout)\n                else:\n                    gotit = waiter.acquire(False)\n                if not gotit:\n                    try:\n                        self._waiters.remove(waiter)\n                    except ValueError:\n                        pass\n            return gotit\n        finally:\n            self._acquire_restore(saved_state)\n\n    def wait_for(self, predicate, timeout=None):\n        \"\"\"Wait until a condition evaluates to True.\n\n        predicate should be a callable which result will be interpreted as a\n        boolean value.  A timeout may be provided giving the maximum time to\n        wait.\n\n        \"\"\"\n        endtime = None\n        waittime = timeout\n        result = predicate()\n        while not result:\n            if waittime is not None:\n                if endtime is None:\n                    endtime = _time() + waittime\n                else:\n                    waittime = endtime - _time()\n                    if waittime <= 0:\n                        break\n            self.wait(waittime)\n            result = predicate()\n        return result\n\n    def notify(self, n=1):\n        \"\"\"Wake up one or more threads waiting on this condition, if any.\n\n        If the calling thread has not acquired the lock when this method is\n        called, a RuntimeError is raised.\n\n        This method wakes up at most n of the threads waiting for the condition\n        variable; it is a no-op if no threads are waiting.\n\n        \"\"\"\n        if not self._is_owned():\n            raise RuntimeError(\"cannot notify on un-acquired lock\")\n        __waiters = self._waiters\n        waiters = __waiters[:n]\n        if not waiters:\n            return\n        for waiter in waiters:\n            waiter.release()\n            try:\n                __waiters.remove(waiter)\n            except ValueError:\n                pass\n\n    def notify_all(self):\n        \"\"\"Wake up all threads waiting on this condition.\n\n        If the calling thread has not acquired the lock when this method\n        is called, a RuntimeError is raised.\n\n        \"\"\"\n        self.notify(len(self._waiters))\n\n    notifyAll = notify_all\n\n\nclass Semaphore:\n    \"\"\"This class implements semaphore objects.\n\n    Semaphores manage a counter representing the number of release() calls minus\n    the number of acquire() calls, plus an initial value. The acquire() method\n    blocks if necessary until it can return without making the counter\n    negative. If not given, value defaults to 1.\n\n    \"\"\"\n\n    # After Tim Peters' semaphore class, but not quite the same (no maximum)\n\n    def __init__(self, value=1):\n        if value < 0:\n            raise ValueError(\"semaphore initial value must be >= 0\")\n        self._cond = Condition(Lock())\n        self._value = value\n\n    def acquire(self, blocking=True, timeout=None):\n        \"\"\"Acquire a semaphore, decrementing the internal counter by one.\n\n        When invoked without arguments: if the internal counter is larger than\n        zero on entry, decrement it by one and return immediately. If it is zero\n        on entry, block, waiting until some other thread has called release() to\n        make it larger than zero. This is done with proper interlocking so that\n        if multiple acquire() calls are blocked, release() will wake exactly one\n        of them up. The implementation may pick one at random, so the order in\n        which blocked threads are awakened should not be relied on. There is no\n        return value in this case.\n\n        When invoked with blocking set to true, do the same thing as when called\n        without arguments, and return true.\n\n        When invoked with blocking set to false, do not block. If a call without\n        an argument would block, return false immediately; otherwise, do the\n        same thing as when called without arguments, and return true.\n\n        When invoked with a timeout other than None, it will block for at\n        most timeout seconds.  If acquire does not complete successfully in\n        that interval, return false.  Return true otherwise.\n\n        \"\"\"\n        if not blocking and timeout is not None:\n            raise ValueError(\"can't specify timeout for non-blocking acquire\")\n        rc = False\n        endtime = None\n        with self._cond:\n            while self._value == 0:\n                if not blocking:\n                    break\n                if timeout is not None:\n                    if endtime is None:\n                        endtime = _time() + timeout\n                    else:\n                        timeout = endtime - _time()\n                        if timeout <= 0:\n                            break\n                self._cond.wait(timeout)\n            else:\n                self._value = self._value - 1\n                rc = True\n        return rc\n\n    __enter__ = acquire\n\n    def release(self):\n        \"\"\"Release a semaphore, incrementing the internal counter by one.\n\n        When the counter is zero on entry and another thread is waiting for it\n        to become larger than zero again, wake up that thread.\n\n        \"\"\"\n        with self._cond:\n            self._value = self._value + 1\n            self._cond.notify()\n\n    def __exit__(self, t, v, tb):\n        self.release()\n\n\nclass BoundedSemaphore(Semaphore):\n    \"\"\"Implements a bounded semaphore.\n\n    A bounded semaphore checks to make sure its current value doesn't exceed its\n    initial value. If it does, ValueError is raised. In most situations\n    semaphores are used to guard resources with limited capacity.\n\n    If the semaphore is released too many times it's a sign of a bug. If not\n    given, value defaults to 1.\n\n    Like regular semaphores, bounded semaphores manage a counter representing\n    the number of release() calls minus the number of acquire() calls, plus an\n    initial value. The acquire() method blocks if necessary until it can return\n    without making the counter negative. If not given, value defaults to 1.\n\n    \"\"\"\n\n    def __init__(self, value=1):\n        Semaphore.__init__(self, value)\n        self._initial_value = value\n\n    def release(self):\n        \"\"\"Release a semaphore, incrementing the internal counter by one.\n\n        When the counter is zero on entry and another thread is waiting for it\n        to become larger than zero again, wake up that thread.\n\n        If the number of releases exceeds the number of acquires,\n        raise a ValueError.\n\n        \"\"\"\n        with self._cond:\n            if self._value >= self._initial_value:\n                raise ValueError(\"Semaphore released too many times\")\n            self._value += 1\n            self._cond.notify()\n\n\nclass Event:\n    \"\"\"Class implementing event objects.\n\n    Events manage a flag that can be set to true with the set() method and reset\n    to false with the clear() method. The wait() method blocks until the flag is\n    true.  The flag is initially false.\n\n    \"\"\"\n\n    # After Tim Peters' event class (without is_posted())\n\n    def __init__(self):\n        self._cond = Condition(Lock())\n        self._flag = False\n\n    def _reset_internal_locks(self):\n        # private!  called by Thread._reset_internal_locks by _after_fork()\n        self._cond.__init__()\n\n    def is_set(self):\n        \"\"\"Return true if and only if the internal flag is true.\"\"\"\n        return self._flag\n\n    isSet = is_set\n\n    def set(self):\n        \"\"\"Set the internal flag to true.\n\n        All threads waiting for it to become true are awakened. Threads\n        that call wait() once the flag is true will not block at all.\n\n        \"\"\"\n        self._cond.acquire()\n        try:\n            self._flag = True\n            self._cond.notify_all()\n        finally:\n            self._cond.release()\n\n    def clear(self):\n        \"\"\"Reset the internal flag to false.\n\n        Subsequently, threads calling wait() will block until set() is called to\n        set the internal flag to true again.\n\n        \"\"\"\n        self._cond.acquire()\n        try:\n            self._flag = False\n        finally:\n            self._cond.release()\n\n    def wait(self, timeout=None):\n        \"\"\"Block until the internal flag is true.\n\n        If the internal flag is true on entry, return immediately. Otherwise,\n        block until another thread calls set() to set the flag to true, or until\n        the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof).\n\n        This method returns the internal flag on exit, so it will always return\n        True except if a timeout is given and the operation times out.\n\n        \"\"\"\n        self._cond.acquire()\n        try:\n            signaled = self._flag\n            if not signaled:\n                signaled = self._cond.wait(timeout)\n            return signaled\n        finally:\n            self._cond.release()\n\n\n# A barrier class.  Inspired in part by the pthread_barrier_* api and\n# the CyclicBarrier class from Java.  See\n# http://sourceware.org/pthreads-win32/manual/pthread_barrier_init.html and\n# http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/\n#        CyclicBarrier.html\n# for information.\n# We maintain two main states, 'filling' and 'draining' enabling the barrier\n# to be cyclic.  Threads are not allowed into it until it has fully drained\n# since the previous cycle.  In addition, a 'resetting' state exists which is\n# similar to 'draining' except that threads leave with a BrokenBarrierError,\n# and a 'broken' state in which all threads get the exception.\nclass Barrier:\n    \"\"\"Implements a Barrier.\n\n    Useful for synchronizing a fixed number of threads at known synchronization\n    points.  Threads block on 'wait()' and are simultaneously once they have all\n    made that call.\n\n    \"\"\"\n\n    def __init__(self, parties, action=None, timeout=None):\n        \"\"\"Create a barrier, initialised to 'parties' threads.\n\n        'action' is a callable which, when supplied, will be called by one of\n        the threads after they have all entered the barrier and just prior to\n        releasing them all. If a 'timeout' is provided, it is uses as the\n        default for all subsequent 'wait()' calls.\n\n        \"\"\"\n        self._cond = Condition(Lock())\n        self._action = action\n        self._timeout = timeout\n        self._parties = parties\n        self._state = 0 #0 filling, 1, draining, -1 resetting, -2 broken\n        self._count = 0\n\n    def wait(self, timeout=None):\n        \"\"\"Wait for the barrier.\n\n        When the specified number of threads have started waiting, they are all\n        simultaneously awoken. If an 'action' was provided for the barrier, one\n        of the threads will have executed that callback prior to returning.\n        Returns an individual index number from 0 to 'parties-1'.\n\n        \"\"\"\n        if timeout is None:\n            timeout = self._timeout\n        with self._cond:\n            self._enter() # Block while the barrier drains.\n            index = self._count\n            self._count += 1\n            try:\n                if index + 1 == self._parties:\n                    # We release the barrier\n                    self._release()\n                else:\n                    # We wait until someone releases us\n                    self._wait(timeout)\n                return index\n            finally:\n                self._count -= 1\n                # Wake up any threads waiting for barrier to drain.\n                self._exit()\n\n    # Block until the barrier is ready for us, or raise an exception\n    # if it is broken.\n    def _enter(self):\n        while self._state in (-1, 1):\n            # It is draining or resetting, wait until done\n            self._cond.wait()\n        #see if the barrier is in a broken state\n        if self._state < 0:\n            raise BrokenBarrierError\n        assert self._state == 0\n\n    # Optionally run the 'action' and release the threads waiting\n    # in the barrier.\n    def _release(self):\n        try:\n            if self._action:\n                self._action()\n            # enter draining state\n            self._state = 1\n            self._cond.notify_all()\n        except:\n            #an exception during the _action handler.  Break and reraise\n            self._break()\n            raise\n\n    # Wait in the barrier until we are relased.  Raise an exception\n    # if the barrier is reset or broken.\n    def _wait(self, timeout):\n        if not self._cond.wait_for(lambda : self._state != 0, timeout):\n            #timed out.  Break the barrier\n            self._break()\n            raise BrokenBarrierError\n        if self._state < 0:\n            raise BrokenBarrierError\n        assert self._state == 1\n\n    # If we are the last thread to exit the barrier, signal any threads\n    # waiting for the barrier to drain.\n    def _exit(self):\n        if self._count == 0:\n            if self._state in (-1, 1):\n                #resetting or draining\n                self._state = 0\n                self._cond.notify_all()\n\n    def reset(self):\n        \"\"\"Reset the barrier to the initial state.\n\n        Any threads currently waiting will get the BrokenBarrier exception\n        raised.\n\n        \"\"\"\n        with self._cond:\n            if self._count > 0:\n                if self._state == 0:\n                    #reset the barrier, waking up threads\n                    self._state = -1\n                elif self._state == -2:\n                    #was broken, set it to reset state\n                    #which clears when the last thread exits\n                    self._state = -1\n            else:\n                self._state = 0\n            self._cond.notify_all()\n\n    def abort(self):\n        \"\"\"Place the barrier into a 'broken' state.\n\n        Useful in case of error.  Any currently waiting threads and threads\n        attempting to 'wait()' will have BrokenBarrierError raised.\n\n        \"\"\"\n        with self._cond:\n            self._break()\n\n    def _break(self):\n        # An internal error was detected.  The barrier is set to\n        # a broken state all parties awakened.\n        self._state = -2\n        self._cond.notify_all()\n\n    @property\n    def parties(self):\n        \"\"\"Return the number of threads required to trip the barrier.\"\"\"\n        return self._parties\n\n    @property\n    def n_waiting(self):\n        \"\"\"Return the number of threads currently waiting at the barrier.\"\"\"\n        # We don't need synchronization here since this is an ephemeral result\n        # anyway.  It returns the correct value in the steady state.\n        if self._state == 0:\n            return self._count\n        return 0\n\n    @property\n    def broken(self):\n        \"\"\"Return True if the barrier is in a broken state.\"\"\"\n        return self._state == -2\n\n# exception raised by the Barrier class\nclass BrokenBarrierError(RuntimeError):\n    pass\n\n\n# Helper to generate new thread names\n_counter = 0\ndef _newname(template=\"Thread-%d\"):\n    global _counter\n    _counter = _counter + 1\n    return template % _counter\n\n# Active thread administration\n_active_limbo_lock = _allocate_lock()\n_active = {}    # maps thread id to Thread object\n_limbo = {}\n\n# For debug and leak testing\n_dangling = WeakSet()\n\n# Main class for threads\n\nclass Thread:\n    \"\"\"A class that represents a thread of control.\n\n    This class can be safely subclassed in a limited fashion. There are two ways\n    to specify the activity: by passing a callable object to the constructor, or\n    by overriding the run() method in a subclass.\n\n    \"\"\"\n\n    __initialized = False\n    # Need to store a reference to sys.exc_info for printing\n    # out exceptions when a thread tries to use a global var. during interp.\n    # shutdown and thus raises an exception about trying to perform some\n    # operation on/with a NoneType\n    __exc_info = _sys.exc_info\n    # Keep sys.exc_clear too to clear the exception just before\n    # allowing .join() to return.\n    #XXX __exc_clear = _sys.exc_clear\n\n    def __init__(self, group=None, target=None, name=None,\n                 args=(), kwargs=None, *, daemon=None):\n        \"\"\"This constructor should always be called with keyword arguments. Arguments are:\n\n        *group* should be None; reserved for future extension when a ThreadGroup\n        class is implemented.\n\n        *target* is the callable object to be invoked by the run()\n        method. Defaults to None, meaning nothing is called.\n\n        *name* is the thread name. By default, a unique name is constructed of\n        the form \"Thread-N\" where N is a small decimal number.\n\n        *args* is the argument tuple for the target invocation. Defaults to ().\n\n        *kwargs* is a dictionary of keyword arguments for the target\n        invocation. Defaults to {}.\n\n        If a subclass overrides the constructor, it must make sure to invoke\n        the base class constructor (Thread.__init__()) before doing anything\n        else to the thread.\n\n        \"\"\"\n        assert group is None, \"group argument must be None for now\"\n        if kwargs is None:\n            kwargs = {}\n        self._target = target\n        self._name = str(name or _newname())\n        self._args = args\n        self._kwargs = kwargs\n        if daemon is not None:\n            self._daemonic = daemon\n        else:\n            self._daemonic = current_thread().daemon\n        self._ident = None\n        self._started = Event()\n        self._stopped = False\n        self._block = Condition(Lock())\n        self._initialized = True\n        # sys.stderr is not stored in the class like\n        # sys.exc_info since it can be changed between instances\n        self._stderr = _sys.stderr\n        _dangling.add(self)\n\n    def _reset_internal_locks(self):\n        # private!  Called by _after_fork() to reset our internal locks as\n        # they may be in an invalid state leading to a deadlock or crash.\n        if hasattr(self, '_block'):  # DummyThread deletes _block\n            self._block.__init__()\n        self._started._reset_internal_locks()\n\n    def __repr__(self):\n        assert self._initialized, \"Thread.__init__() was not called\"\n        status = \"initial\"\n        if self._started.is_set():\n            status = \"started\"\n        if self._stopped:\n            status = \"stopped\"\n        if self._daemonic:\n            status += \" daemon\"\n        if self._ident is not None:\n            status += \" %s\" % self._ident\n        return \"<%s(%s, %s)>\" % (self.__class__.__name__, self._name, status)\n\n    def start(self):\n        \"\"\"Start the thread's activity.\n\n        It must be called at most once per thread object. It arranges for the\n        object's run() method to be invoked in a separate thread of control.\n\n        This method will raise a RuntimeError if called more than once on the\n        same thread object.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"thread.__init__() not called\")\n\n        if self._started.is_set():\n            raise RuntimeError(\"threads can only be started once\")\n        with _active_limbo_lock:\n            _limbo[self] = self\n        try:\n            _start_new_thread(self._bootstrap, ())\n        except Exception:\n            with _active_limbo_lock:\n                del _limbo[self]\n            raise\n        self._started.wait()\n\n    def run(self):\n        \"\"\"Method representing the thread's activity.\n\n        You may override this method in a subclass. The standard run() method\n        invokes the callable object passed to the object's constructor as the\n        target argument, if any, with sequential and keyword arguments taken\n        from the args and kwargs arguments, respectively.\n\n        \"\"\"\n        try:\n            if self._target:\n                self._target(*self._args, **self._kwargs)\n        finally:\n            # Avoid a refcycle if the thread is running a function with\n            # an argument that has a member that points to the thread.\n            del self._target, self._args, self._kwargs\n\n    def _bootstrap(self):\n        # Wrapper around the real bootstrap code that ignores\n        # exceptions during interpreter cleanup.  Those typically\n        # happen when a daemon thread wakes up at an unfortunate\n        # moment, finds the world around it destroyed, and raises some\n        # random exception *** while trying to report the exception in\n        # _bootstrap_inner() below ***.  Those random exceptions\n        # don't help anybody, and they confuse users, so we suppress\n        # them.  We suppress them only when it appears that the world\n        # indeed has already been destroyed, so that exceptions in\n        # _bootstrap_inner() during normal business hours are properly\n        # reported.  Also, we only suppress them for daemonic threads;\n        # if a non-daemonic encounters this, something else is wrong.\n        try:\n            self._bootstrap_inner()\n        except:\n            if self._daemonic and _sys is None:\n                return\n            raise\n\n    def _set_ident(self):\n        self._ident = get_ident()\n\n    def _bootstrap_inner(self):\n        try:\n            self._set_ident()\n            self._started.set()\n            with _active_limbo_lock:\n                _active[self._ident] = self\n                del _limbo[self]\n\n            if _trace_hook:\n                _sys.settrace(_trace_hook)\n            if _profile_hook:\n                _sys.setprofile(_profile_hook)\n\n            try:\n                self.run()\n            except SystemExit:\n                pass\n            except:\n                # If sys.stderr is no more (most likely from interpreter\n                # shutdown) use self._stderr.  Otherwise still use sys (as in\n                # _sys) in case sys.stderr was redefined since the creation of\n                # self.\n                if _sys:\n                    _sys.stderr.write(\"Exception in thread %s:\\n%s\\n\" %\n                                      (self.name, _format_exc()))\n                else:\n                    # Do the best job possible w/o a huge amt. of code to\n                    # approximate a traceback (code ideas from\n                    # Lib/traceback.py)\n                    exc_type, exc_value, exc_tb = self._exc_info()\n                    try:\n                        print((\n                            \"Exception in thread \" + self.name +\n                            \" (most likely raised during interpreter shutdown):\"), file=self._stderr)\n                        print((\n                            \"Traceback (most recent call last):\"), file=self._stderr)\n                        while exc_tb:\n                            print((\n                                '  File \"%s\", line %s, in %s' %\n                                (exc_tb.tb_frame.f_code.co_filename,\n                                    exc_tb.tb_lineno,\n                                    exc_tb.tb_frame.f_code.co_name)), file=self._stderr)\n                            exc_tb = exc_tb.tb_next\n                        print((\"%s: %s\" % (exc_type, exc_value)), file=self._stderr)\n                    # Make sure that exc_tb gets deleted since it is a memory\n                    # hog; deleting everything else is just for thoroughness\n                    finally:\n                        del exc_type, exc_value, exc_tb\n            finally:\n                # Prevent a race in\n                # test_threading.test_no_refcycle_through_target when\n                # the exception keeps the target alive past when we\n                # assert that it's dead.\n                #XXX self.__exc_clear()\n                pass\n        finally:\n            with _active_limbo_lock:\n                self._stop()\n                try:\n                    # We don't call self._delete() because it also\n                    # grabs _active_limbo_lock.\n                    del _active[get_ident()]\n                except:\n                    pass\n\n    def _stop(self):\n        self._block.acquire()\n        self._stopped = True\n        self._block.notify_all()\n        self._block.release()\n\n    def _delete(self):\n        \"Remove current thread from the dict of currently running threads.\"\n\n        # Notes about running with _dummy_thread:\n        #\n        # Must take care to not raise an exception if _dummy_thread is being\n        # used (and thus this module is being used as an instance of\n        # dummy_threading).  _dummy_thread.get_ident() always returns -1 since\n        # there is only one thread if _dummy_thread is being used.  Thus\n        # len(_active) is always <= 1 here, and any Thread instance created\n        # overwrites the (if any) thread currently registered in _active.\n        #\n        # An instance of _MainThread is always created by 'threading'.  This\n        # gets overwritten the instant an instance of Thread is created; both\n        # threads return -1 from _dummy_thread.get_ident() and thus have the\n        # same key in the dict.  So when the _MainThread instance created by\n        # 'threading' tries to clean itself up when atexit calls this method\n        # it gets a KeyError if another Thread instance was created.\n        #\n        # This all means that KeyError from trying to delete something from\n        # _active if dummy_threading is being used is a red herring.  But\n        # since it isn't if dummy_threading is *not* being used then don't\n        # hide the exception.\n\n        try:\n            with _active_limbo_lock:\n                del _active[get_ident()]\n                # There must not be any python code between the previous line\n                # and after the lock is released.  Otherwise a tracing function\n                # could try to acquire the lock again in the same thread, (in\n                # current_thread()), and would block.\n        except KeyError:\n            if 'dummy_threading' not in _sys.modules:\n                raise\n\n    def join(self, timeout=None):\n        \"\"\"Wait until the thread terminates.\n\n        This blocks the calling thread until the thread whose join() method is\n        called terminates -- either normally or through an unhandled exception\n        or until the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof). As join() always returns None, you must call\n        isAlive() after join() to decide whether a timeout happened -- if the\n        thread is still alive, the join() call timed out.\n\n        When the timeout argument is not present or None, the operation will\n        block until the thread terminates.\n\n        A thread can be join()ed many times.\n\n        join() raises a RuntimeError if an attempt is made to join the current\n        thread as that would cause a deadlock. It is also an error to join() a\n        thread before it has been started and attempts to do so raises the same\n        exception.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if not self._started.is_set():\n            raise RuntimeError(\"cannot join thread before it is started\")\n        if self is current_thread():\n            raise RuntimeError(\"cannot join current thread\")\n\n        self._block.acquire()\n        try:\n            if timeout is None:\n                while not self._stopped:\n                    self._block.wait()\n            else:\n                deadline = _time() + timeout\n                while not self._stopped:\n                    delay = deadline - _time()\n                    if delay <= 0:\n                        break\n                    self._block.wait(delay)\n        finally:\n            self._block.release()\n\n    @property\n    def name(self):\n        \"\"\"A string used for identification purposes only.\n\n        It has no semantics. Multiple threads may be given the same name. The\n        initial name is set by the constructor.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._name\n\n    @name.setter\n    def name(self, name):\n        assert self._initialized, \"Thread.__init__() not called\"\n        self._name = str(name)\n\n    @property\n    def ident(self):\n        \"\"\"Thread identifier of this thread or None if it has not been started.\n\n        This is a nonzero integer. See the thread.get_ident() function. Thread\n        identifiers may be recycled when a thread exits and another thread is\n        created. The identifier is available even after the thread has exited.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._ident\n\n    def is_alive(self):\n        \"\"\"Return whether the thread is alive.\n\n        This method returns True just before the run() method starts until just\n        after the run() method terminates. The module function enumerate()\n        returns a list of all alive threads.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._started.is_set() and not self._stopped\n\n    isAlive = is_alive\n\n    @property\n    def daemon(self):\n        \"\"\"A boolean value indicating whether this thread is a daemon thread.\n\n        This must be set before start() is called, otherwise RuntimeError is\n        raised. Its initial value is inherited from the creating thread; the\n        main thread is not a daemon thread and therefore all threads created in\n        the main thread default to daemon = False.\n\n        The entire Python program exits when no alive non-daemon threads are\n        left.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._daemonic\n\n    @daemon.setter\n    def daemon(self, daemonic):\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if self._started.is_set():\n            raise RuntimeError(\"cannot set daemon status of active thread\");\n        self._daemonic = daemonic\n\n    def isDaemon(self):\n        return self.daemon\n\n    def setDaemon(self, daemonic):\n        self.daemon = daemonic\n\n    def getName(self):\n        return self.name\n\n    def setName(self, name):\n        self.name = name\n\n# The timer class was contributed by Itamar Shtull-Trauring\n\nclass Timer(Thread):\n    \"\"\"Call a function after a specified number of seconds:\n\n            t = Timer(30.0, f, args=None, kwargs=None)\n            t.start()\n            t.cancel()     # stop the timer's action if it's still waiting\n\n    \"\"\"\n\n    def __init__(self, interval, function, args=None, kwargs=None):\n        Thread.__init__(self)\n        self.interval = interval\n        self.function = function\n        self.args = args if args is not None else []\n        self.kwargs = kwargs if kwargs is not None else {}\n        self.finished = Event()\n\n    def cancel(self):\n        \"\"\"Stop the timer if it hasn't finished yet.\"\"\"\n        self.finished.set()\n\n    def run(self):\n        self.finished.wait(self.interval)\n        if not self.finished.is_set():\n            self.function(*self.args, **self.kwargs)\n        self.finished.set()\n\n# Special thread class to represent the main thread\n# This is garbage collected through an exit handler\n\nclass _MainThread(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=\"MainThread\", daemon=False)\n        self._started.set()\n        self._set_ident()\n        with _active_limbo_lock:\n            _active[self._ident] = self\n\n    def _exitfunc(self):\n        self._stop()\n        t = _pickSomeNonDaemonThread()\n        while t:\n            t.join()\n            t = _pickSomeNonDaemonThread()\n        self._delete()\n\ndef _pickSomeNonDaemonThread():\n    for t in enumerate():\n        if not t.daemon and t.is_alive():\n            return t\n    return None\n\n\n# Dummy thread class to represent threads not started here.\n# These aren't garbage collected when they die, nor can they be waited for.\n# If they invoke anything in threading.py that calls current_thread(), they\n# leave an entry in the _active dict forever after.\n# Their purpose is to return *something* from current_thread().\n# They are marked as daemon threads so we won't wait for them\n# when we exit (conform previous semantics).\n\nclass _DummyThread(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=_newname(\"Dummy-%d\"), daemon=True)\n\n        # Thread._block consumes an OS-level locking primitive, which\n        # can never be used by a _DummyThread.  Since a _DummyThread\n        # instance is immortal, that's bad, so release this resource.\n        del self._block\n\n        self._started.set()\n        self._set_ident()\n        with _active_limbo_lock:\n            _active[self._ident] = self\n\n    def _stop(self):\n        pass\n\n    def join(self, timeout=None):\n        assert False, \"cannot join a dummy thread\"\n\n\n# Global API functions\n\ndef current_thread():\n    \"\"\"Return the current Thread object, corresponding to the caller's thread of control.\n\n    If the caller's thread of control was not created through the threading\n    module, a dummy thread object with limited functionality is returned.\n\n    \"\"\"\n    try:\n        return _active[get_ident()]\n    except KeyError:\n        return _DummyThread()\n\ncurrentThread = current_thread\n\ndef active_count():\n    \"\"\"Return the number of Thread objects currently alive.\n\n    The returned count is equal to the length of the list returned by\n    enumerate().\n\n    \"\"\"\n    with _active_limbo_lock:\n        return len(_active) + len(_limbo)\n\nactiveCount = active_count\n\ndef _enumerate():\n    # Same as enumerate(), but without the lock. Internal use only.\n    return list(_active.values()) + list(_limbo.values())\n\ndef enumerate():\n    \"\"\"Return a list of all Thread objects currently alive.\n\n    The list includes daemonic threads, dummy thread objects created by\n    current_thread(), and the main thread. It excludes terminated threads and\n    threads that have not yet been started.\n\n    \"\"\"\n    with _active_limbo_lock:\n        return list(_active.values()) + list(_limbo.values())\n\nfrom _thread import stack_size\n\n# Create the main thread object,\n# and make it available for the interpreter\n# (Py_Main) as threading._shutdown.\n\n_shutdown = _MainThread()._exitfunc\n\n# get thread-local implementation, either from the thread\n# module, or from the python fallback\n\ntry:\n    from _thread import _local as local\nexcept ImportError:\n    from _threading_local import local\n\n\ndef _after_fork():\n    # This function is called by Python/ceval.c:PyEval_ReInitThreads which\n    # is called from PyOS_AfterFork.  Here we cleanup threading module state\n    # that should not exist after a fork.\n\n    # Reset _active_limbo_lock, in case we forked while the lock was held\n    # by another (non-forked) thread.  http://bugs.python.org/issue874900\n    global _active_limbo_lock\n    _active_limbo_lock = _allocate_lock()\n\n    # fork() only copied the current thread; clear references to others.\n    new_active = {}\n    current = current_thread()\n    with _active_limbo_lock:\n        for thread in _enumerate():\n            # Any lock/condition variable may be currently locked or in an\n            # invalid state, so we reinitialize them.\n            thread._reset_internal_locks()\n            if thread is current:\n                # There is only one active thread. We reset the ident to\n                # its new value since it can have changed.\n                ident = get_ident()\n                thread._ident = ident\n                new_active[ident] = thread\n            else:\n                # All the others are already stopped.\n                thread._stop()\n\n        _limbo.clear()\n        _active.clear()\n        _active.update(new_active)\n        assert len(_active) == 1\n"], "token": [".py", "\"\"\"Token constants (from \"token.h\").\"\"\"\n\n__all__ = ['tok_name', 'ISTERMINAL', 'ISNONTERMINAL', 'ISEOF']\n\n#  This file is automatically generated; please don't muck it up!\n#\n#  To update the symbols in this file, 'cd' to the top directory of\n#  the python source tree after building the interpreter and run:\n#\n#    ./python Lib/token.py\n\n#--start constants--\nENDMARKER = 0\nNAME = 1\nNUMBER = 2\nSTRING = 3\nNEWLINE = 4\nINDENT = 5\nDEDENT = 6\nLPAR = 7\nRPAR = 8\nLSQB = 9\nRSQB = 10\nCOLON = 11\nCOMMA = 12\nSEMI = 13\nPLUS = 14\nMINUS = 15\nSTAR = 16\nSLASH = 17\nVBAR = 18\nAMPER = 19\nLESS = 20\nGREATER = 21\nEQUAL = 22\nDOT = 23\nPERCENT = 24\nLBRACE = 25\nRBRACE = 26\nEQEQUAL = 27\nNOTEQUAL = 28\nLESSEQUAL = 29\nGREATEREQUAL = 30\nTILDE = 31\nCIRCUMFLEX = 32\nLEFTSHIFT = 33\nRIGHTSHIFT = 34\nDOUBLESTAR = 35\nPLUSEQUAL = 36\nMINEQUAL = 37\nSTAREQUAL = 38\nSLASHEQUAL = 39\nPERCENTEQUAL = 40\nAMPEREQUAL = 41\nVBAREQUAL = 42\nCIRCUMFLEXEQUAL = 43\nLEFTSHIFTEQUAL = 44\nRIGHTSHIFTEQUAL = 45\nDOUBLESTAREQUAL = 46\nDOUBLESLASH = 47\nDOUBLESLASHEQUAL = 48\nAT = 49\nRARROW = 50\nELLIPSIS = 51\nOP = 52\nERRORTOKEN = 53\nN_TOKENS = 54\nNT_OFFSET = 256\n#--end constants--\n\ntok_name = {value: name\n            for name, value in globals().items()\n            if isinstance(value, int) and not name.startswith('_')}\n__all__.extend(tok_name.values())\n\ndef ISTERMINAL(x):\n    return x < NT_OFFSET\n\ndef ISNONTERMINAL(x):\n    return x >= NT_OFFSET\n\ndef ISEOF(x):\n    return x == ENDMARKER\n\n\ndef _main():\n    import re\n    import sys\n    args = sys.argv[1:]\n    inFileName = args and args[0] or \"Include/token.h\"\n    outFileName = \"Lib/token.py\"\n    if len(args) > 1:\n        outFileName = args[1]\n    try:\n        fp = open(inFileName)\n    except IOError as err:\n        sys.stdout.write(\"I/O error: %s\\n\" % str(err))\n        sys.exit(1)\n    lines = fp.read().split(\"\\n\")\n    fp.close()\n    prog = re.compile(\n        \"#define[ \\t][ \\t]*([A-Z0-9][A-Z0-9_]*)[ \\t][ \\t]*([0-9][0-9]*)\",\n        re.IGNORECASE)\n    tokens = {}\n    for line in lines:\n        match = prog.match(line)\n        if match:\n            name, val = match.group(1, 2)\n            val = int(val)\n            tokens[val] = name          # reverse so we can sort them...\n    keys = sorted(tokens.keys())\n    # load the output skeleton from the target:\n    try:\n        fp = open(outFileName)\n    except IOError as err:\n        sys.stderr.write(\"I/O error: %s\\n\" % str(err))\n        sys.exit(2)\n    format = fp.read().split(\"\\n\")\n    fp.close()\n    try:\n        start = format.index(\"#--start constants--\") + 1\n        end = format.index(\"#--end constants--\")\n    except ValueError:\n        sys.stderr.write(\"target does not contain format markers\")\n        sys.exit(3)\n    lines = []\n    for val in keys:\n        lines.append(\"%s = %d\" % (tokens[val], val))\n    format[start:end] = lines\n    try:\n        fp = open(outFileName, 'w')\n    except IOError as err:\n        sys.stderr.write(\"I/O error: %s\\n\" % str(err))\n        sys.exit(4)\n    fp.write(\"\\n\".join(format))\n    fp.close()\n\n\nif __name__ == \"__main__\":\n    _main()\n"], "multiprocessing.dummy.connection": [".py", "#\n# Analogue of `multiprocessing.connection` which uses queues instead of sockets\n#\n# multiprocessing/dummy/connection.py\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#\n# 1. Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n# 2. Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n# 3. Neither the name of author nor the names of any contributors may be\n#    used to endorse or promote products derived from this software\n#    without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS \"AS IS\" AND\n# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE\n# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n# OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n# SUCH DAMAGE.\n#\n\n__all__ = [ 'Client', 'Listener', 'Pipe' ]\n\nfrom queue import Queue\n\n\nfamilies = [None]\n\n\nclass Listener(object):\n\n    def __init__(self, address=None, family=None, backlog=1):\n        self._backlog_queue = Queue(backlog)\n\n    def accept(self):\n        return Connection(*self._backlog_queue.get())\n\n    def close(self):\n        self._backlog_queue = None\n\n    address = property(lambda self: self._backlog_queue)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, exc_tb):\n        self.close()\n\n\ndef Client(address):\n    _in, _out = Queue(), Queue()\n    address.put((_out, _in))\n    return Connection(_in, _out)\n\n\ndef Pipe(duplex=True):\n    a, b = Queue(), Queue()\n    return Connection(a, b), Connection(b, a)\n\n\nclass Connection(object):\n\n    def __init__(self, _in, _out):\n        self._out = _out\n        self._in = _in\n        self.send = self.send_bytes = _out.put\n        self.recv = self.recv_bytes = _in.get\n\n    def poll(self, timeout=0.0):\n        if self._in.qsize() > 0:\n            return True\n        if timeout <= 0.0:\n            return False\n        self._in.not_empty.acquire()\n        self._in.not_empty.wait(timeout)\n        self._in.not_empty.release()\n        return self._in.qsize() > 0\n\n    def close(self):\n        pass\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, exc_tb):\n        self.close()\n"], "multiprocessing.pool": [".py", "#\n# Module providing the `Pool` class for managing a process pool\n#\n# multiprocessing/pool.py\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# Licensed to PSF under a Contributor Agreement.\n#\n\n__all__ = ['Pool']\n\n#\n# Imports\n#\n\nimport threading\nimport queue\nimport itertools\nimport collections\nimport time\n\nfrom multiprocessing import Process, cpu_count, TimeoutError\nfrom multiprocessing.util import Finalize, debug\n\n#\n# Constants representing the state of a pool\n#\n\nRUN = 0\nCLOSE = 1\nTERMINATE = 2\n\n#\n# Miscellaneous\n#\n\njob_counter = itertools.count()\n\ndef mapstar(args):\n    return list(map(*args))\n\ndef starmapstar(args):\n    return list(itertools.starmap(args[0], args[1]))\n\n#\n# Code run by worker processes\n#\n\nclass MaybeEncodingError(Exception):\n    \"\"\"Wraps possible unpickleable errors, so they can be\n    safely sent through the socket.\"\"\"\n\n    def __init__(self, exc, value):\n        self.exc = repr(exc)\n        self.value = repr(value)\n        super(MaybeEncodingError, self).__init__(self.exc, self.value)\n\n    def __str__(self):\n        return \"Error sending result: '%s'. Reason: '%s'\" % (self.value,\n                                                             self.exc)\n\n    def __repr__(self):\n        return \"<MaybeEncodingError: %s>\" % str(self)\n\n\ndef worker(inqueue, outqueue, initializer=None, initargs=(), maxtasks=None):\n    assert maxtasks is None or (type(maxtasks) == int and maxtasks > 0)\n    put = outqueue.put\n    get = inqueue.get\n    if hasattr(inqueue, '_writer'):\n        inqueue._writer.close()\n        outqueue._reader.close()\n\n    if initializer is not None:\n        initializer(*initargs)\n\n    completed = 0\n    while maxtasks is None or (maxtasks and completed < maxtasks):\n        try:\n            task = get()\n        except (EOFError, IOError):\n            debug('worker got EOFError or IOError -- exiting')\n            break\n\n        if task is None:\n            debug('worker got sentinel -- exiting')\n            break\n\n        job, i, func, args, kwds = task\n        try:\n            result = (True, func(*args, **kwds))\n        except Exception as e:\n            result = (False, e)\n        try:\n            put((job, i, result))\n        except Exception as e:\n            wrapped = MaybeEncodingError(e, result[1])\n            debug(\"Possible encoding error while sending result: %s\" % (\n                wrapped))\n            put((job, i, (False, wrapped)))\n        completed += 1\n    debug('worker exiting after %d tasks' % completed)\n\n#\n# Class representing a process pool\n#\n\nclass Pool(object):\n    '''\n    Class which supports an async version of applying functions to arguments.\n    '''\n    Process = Process\n\n    def __init__(self, processes=None, initializer=None, initargs=(),\n                 maxtasksperchild=None):\n        self._setup_queues()\n        self._taskqueue = queue.Queue()\n        self._cache = {}\n        self._state = RUN\n        self._maxtasksperchild = maxtasksperchild\n        self._initializer = initializer\n        self._initargs = initargs\n\n        if processes is None:\n            try:\n                processes = cpu_count()\n            except NotImplementedError:\n                processes = 1\n        if processes < 1:\n            raise ValueError(\"Number of processes must be at least 1\")\n\n        if initializer is not None and not callable(initializer):\n            raise TypeError('initializer must be a callable')\n\n        self._processes = processes\n        self._pool = []\n        self._repopulate_pool()\n\n        self._worker_handler = threading.Thread(\n            target=Pool._handle_workers,\n            args=(self, )\n            )\n        self._worker_handler.daemon = True\n        self._worker_handler._state = RUN\n        self._worker_handler.start()\n\n\n        self._task_handler = threading.Thread(\n            target=Pool._handle_tasks,\n            args=(self._taskqueue, self._quick_put, self._outqueue, self._pool)\n            )\n        self._task_handler.daemon = True\n        self._task_handler._state = RUN\n        self._task_handler.start()\n\n        self._result_handler = threading.Thread(\n            target=Pool._handle_results,\n            args=(self._outqueue, self._quick_get, self._cache)\n            )\n        self._result_handler.daemon = True\n        self._result_handler._state = RUN\n        self._result_handler.start()\n\n        self._terminate = Finalize(\n            self, self._terminate_pool,\n            args=(self._taskqueue, self._inqueue, self._outqueue, self._pool,\n                  self._worker_handler, self._task_handler,\n                  self._result_handler, self._cache),\n            exitpriority=15\n            )\n\n    def _join_exited_workers(self):\n        \"\"\"Cleanup after any worker processes which have exited due to reaching\n        their specified lifetime.  Returns True if any workers were cleaned up.\n        \"\"\"\n        cleaned = False\n        for i in reversed(range(len(self._pool))):\n            worker = self._pool[i]\n            if worker.exitcode is not None:\n                # worker exited\n                debug('cleaning up worker %d' % i)\n                worker.join()\n                cleaned = True\n                del self._pool[i]\n        return cleaned\n\n    def _repopulate_pool(self):\n        \"\"\"Bring the number of pool processes up to the specified number,\n        for use after reaping workers which have exited.\n        \"\"\"\n        for i in range(self._processes - len(self._pool)):\n            w = self.Process(target=worker,\n                             args=(self._inqueue, self._outqueue,\n                                   self._initializer,\n                                   self._initargs, self._maxtasksperchild)\n                            )\n            self._pool.append(w)\n            w.name = w.name.replace('Process', 'PoolWorker')\n            w.daemon = True\n            w.start()\n            debug('added worker')\n\n    def _maintain_pool(self):\n        \"\"\"Clean up any exited workers and start replacements for them.\n        \"\"\"\n        if self._join_exited_workers():\n            self._repopulate_pool()\n\n    def _setup_queues(self):\n        from .queues import SimpleQueue\n        self._inqueue = SimpleQueue()\n        self._outqueue = SimpleQueue()\n        self._quick_put = self._inqueue._writer.send\n        self._quick_get = self._outqueue._reader.recv\n\n    def apply(self, func, args=(), kwds={}):\n        '''\n        Equivalent of `func(*args, **kwds)`.\n        '''\n        assert self._state == RUN\n        return self.apply_async(func, args, kwds).get()\n\n    def map(self, func, iterable, chunksize=None):\n        '''\n        Apply `func` to each element in `iterable`, collecting the results\n        in a list that is returned.\n        '''\n        return self._map_async(func, iterable, mapstar, chunksize).get()\n\n    def starmap(self, func, iterable, chunksize=None):\n        '''\n        Like `map()` method but the elements of the `iterable` are expected to\n        be iterables as well and will be unpacked as arguments. Hence\n        `func` and (a, b) becomes func(a, b).\n        '''\n        return self._map_async(func, iterable, starmapstar, chunksize).get()\n\n    def starmap_async(self, func, iterable, chunksize=None, callback=None,\n            error_callback=None):\n        '''\n        Asynchronous version of `starmap()` method.\n        '''\n        return self._map_async(func, iterable, starmapstar, chunksize,\n                               callback, error_callback)\n\n    def imap(self, func, iterable, chunksize=1):\n        '''\n        Equivalent of `map()` -- can be MUCH slower than `Pool.map()`.\n        '''\n        if self._state != RUN:\n            raise ValueError(\"Pool not running\")\n        if chunksize == 1:\n            result = IMapIterator(self._cache)\n            self._taskqueue.put((((result._job, i, func, (x,), {})\n                         for i, x in enumerate(iterable)), result._set_length))\n            return result\n        else:\n            assert chunksize > 1\n            task_batches = Pool._get_tasks(func, iterable, chunksize)\n            result = IMapIterator(self._cache)\n            self._taskqueue.put((((result._job, i, mapstar, (x,), {})\n                     for i, x in enumerate(task_batches)), result._set_length))\n            return (item for chunk in result for item in chunk)\n\n    def imap_unordered(self, func, iterable, chunksize=1):\n        '''\n        Like `imap()` method but ordering of results is arbitrary.\n        '''\n        if self._state != RUN:\n            raise ValueError(\"Pool not running\")\n        if chunksize == 1:\n            result = IMapUnorderedIterator(self._cache)\n            self._taskqueue.put((((result._job, i, func, (x,), {})\n                         for i, x in enumerate(iterable)), result._set_length))\n            return result\n        else:\n            assert chunksize > 1\n            task_batches = Pool._get_tasks(func, iterable, chunksize)\n            result = IMapUnorderedIterator(self._cache)\n            self._taskqueue.put((((result._job, i, mapstar, (x,), {})\n                     for i, x in enumerate(task_batches)), result._set_length))\n            return (item for chunk in result for item in chunk)\n\n    def apply_async(self, func, args=(), kwds={}, callback=None,\n            error_callback=None):\n        '''\n        Asynchronous version of `apply()` method.\n        '''\n        if self._state != RUN:\n            raise ValueError(\"Pool not running\")\n        result = ApplyResult(self._cache, callback, error_callback)\n        self._taskqueue.put(([(result._job, None, func, args, kwds)], None))\n        return result\n\n    def map_async(self, func, iterable, chunksize=None, callback=None,\n            error_callback=None):\n        '''\n        Asynchronous version of `map()` method.\n        '''\n        return self._map_async(func, iterable, mapstar, chunksize, callback,\n            error_callback)\n\n    def _map_async(self, func, iterable, mapper, chunksize=None, callback=None,\n            error_callback=None):\n        '''\n        Helper function to implement map, starmap and their async counterparts.\n        '''\n        if self._state != RUN:\n            raise ValueError(\"Pool not running\")\n        if not hasattr(iterable, '__len__'):\n            iterable = list(iterable)\n\n        if chunksize is None:\n            chunksize, extra = divmod(len(iterable), len(self._pool) * 4)\n            if extra:\n                chunksize += 1\n        if len(iterable) == 0:\n            chunksize = 0\n\n        task_batches = Pool._get_tasks(func, iterable, chunksize)\n        result = MapResult(self._cache, chunksize, len(iterable), callback,\n                           error_callback=error_callback)\n        self._taskqueue.put((((result._job, i, mapper, (x,), {})\n                              for i, x in enumerate(task_batches)), None))\n        return result\n\n    @staticmethod\n    def _handle_workers(pool):\n        thread = threading.current_thread()\n\n        # Keep maintaining workers until the cache gets drained, unless the pool\n        # is terminated.\n        while thread._state == RUN or (pool._cache and thread._state != TERMINATE):\n            pool._maintain_pool()\n            time.sleep(0.1)\n        # send sentinel to stop workers\n        pool._taskqueue.put(None)\n        debug('worker handler exiting')\n\n    @staticmethod\n    def _handle_tasks(taskqueue, put, outqueue, pool):\n        thread = threading.current_thread()\n\n        for taskseq, set_length in iter(taskqueue.get, None):\n            i = -1\n            for i, task in enumerate(taskseq):\n                if thread._state:\n                    debug('task handler found thread._state != RUN')\n                    break\n                try:\n                    put(task)\n                except IOError:\n                    debug('could not put task on queue')\n                    break\n            else:\n                if set_length:\n                    debug('doing set_length()')\n                    set_length(i+1)\n                continue\n            break\n        else:\n            debug('task handler got sentinel')\n\n\n        try:\n            # tell result handler to finish when cache is empty\n            debug('task handler sending sentinel to result handler')\n            outqueue.put(None)\n\n            # tell workers there is no more work\n            debug('task handler sending sentinel to workers')\n            for p in pool:\n                put(None)\n        except IOError:\n            debug('task handler got IOError when sending sentinels')\n\n        debug('task handler exiting')\n\n    @staticmethod\n    def _handle_results(outqueue, get, cache):\n        thread = threading.current_thread()\n\n        while 1:\n            try:\n                task = get()\n            except (IOError, EOFError):\n                debug('result handler got EOFError/IOError -- exiting')\n                return\n\n            if thread._state:\n                assert thread._state == TERMINATE\n                debug('result handler found thread._state=TERMINATE')\n                break\n\n            if task is None:\n                debug('result handler got sentinel')\n                break\n\n            job, i, obj = task\n            try:\n                cache[job]._set(i, obj)\n            except KeyError:\n                pass\n\n        while cache and thread._state != TERMINATE:\n            try:\n                task = get()\n            except (IOError, EOFError):\n                debug('result handler got EOFError/IOError -- exiting')\n                return\n\n            if task is None:\n                debug('result handler ignoring extra sentinel')\n                continue\n            job, i, obj = task\n            try:\n                cache[job]._set(i, obj)\n            except KeyError:\n                pass\n\n        if hasattr(outqueue, '_reader'):\n            debug('ensuring that outqueue is not full')\n            # If we don't make room available in outqueue then\n            # attempts to add the sentinel (None) to outqueue may\n            # block.  There is guaranteed to be no more than 2 sentinels.\n            try:\n                for i in range(10):\n                    if not outqueue._reader.poll():\n                        break\n                    get()\n            except (IOError, EOFError):\n                pass\n\n        debug('result handler exiting: len(cache)=%s, thread._state=%s',\n              len(cache), thread._state)\n\n    @staticmethod\n    def _get_tasks(func, it, size):\n        it = iter(it)\n        while 1:\n            x = tuple(itertools.islice(it, size))\n            if not x:\n                return\n            yield (func, x)\n\n    def __reduce__(self):\n        raise NotImplementedError(\n              'pool objects cannot be passed between processes or pickled'\n              )\n\n    def close(self):\n        debug('closing pool')\n        if self._state == RUN:\n            self._state = CLOSE\n            self._worker_handler._state = CLOSE\n\n    def terminate(self):\n        debug('terminating pool')\n        self._state = TERMINATE\n        self._worker_handler._state = TERMINATE\n        self._terminate()\n\n    def join(self):\n        debug('joining pool')\n        assert self._state in (CLOSE, TERMINATE)\n        self._worker_handler.join()\n        self._task_handler.join()\n        self._result_handler.join()\n        for p in self._pool:\n            p.join()\n\n    @staticmethod\n    def _help_stuff_finish(inqueue, task_handler, size):\n        # task_handler may be blocked trying to put items on inqueue\n        debug('removing tasks from inqueue until task handler finished')\n        inqueue._rlock.acquire()\n        while task_handler.is_alive() and inqueue._reader.poll():\n            inqueue._reader.recv()\n            time.sleep(0)\n\n    @classmethod\n    def _terminate_pool(cls, taskqueue, inqueue, outqueue, pool,\n                        worker_handler, task_handler, result_handler, cache):\n        # this is guaranteed to only be called once\n        debug('finalizing pool')\n\n        worker_handler._state = TERMINATE\n        task_handler._state = TERMINATE\n\n        debug('helping task handler/workers to finish')\n        cls._help_stuff_finish(inqueue, task_handler, len(pool))\n\n        assert result_handler.is_alive() or len(cache) == 0\n\n        result_handler._state = TERMINATE\n        outqueue.put(None)                  # sentinel\n\n        # We must wait for the worker handler to exit before terminating\n        # workers because we don't want workers to be restarted behind our back.\n        debug('joining worker handler')\n        if threading.current_thread() is not worker_handler:\n            worker_handler.join()\n\n        # Terminate workers which haven't already finished.\n        if pool and hasattr(pool[0], 'terminate'):\n            debug('terminating workers')\n            for p in pool:\n                if p.exitcode is None:\n                    p.terminate()\n\n        debug('joining task handler')\n        if threading.current_thread() is not task_handler:\n            task_handler.join()\n\n        debug('joining result handler')\n        if threading.current_thread() is not result_handler:\n            result_handler.join()\n\n        if pool and hasattr(pool[0], 'terminate'):\n            debug('joining pool workers')\n            for p in pool:\n                if p.is_alive():\n                    # worker has not yet exited\n                    debug('cleaning up worker %d' % p.pid)\n                    p.join()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.terminate()\n\n#\n# Class whose instances are returned by `Pool.apply_async()`\n#\n\nclass ApplyResult(object):\n\n    def __init__(self, cache, callback, error_callback):\n        self._event = threading.Event()\n        self._job = next(job_counter)\n        self._cache = cache\n        self._callback = callback\n        self._error_callback = error_callback\n        cache[self._job] = self\n\n    def ready(self):\n        return self._event.is_set()\n\n    def successful(self):\n        assert self.ready()\n        return self._success\n\n    def wait(self, timeout=None):\n        self._event.wait(timeout)\n\n    def get(self, timeout=None):\n        self.wait(timeout)\n        if not self.ready():\n            raise TimeoutError\n        if self._success:\n            return self._value\n        else:\n            raise self._value\n\n    def _set(self, i, obj):\n        self._success, self._value = obj\n        if self._callback and self._success:\n            self._callback(self._value)\n        if self._error_callback and not self._success:\n            self._error_callback(self._value)\n        self._event.set()\n        del self._cache[self._job]\n\nAsyncResult = ApplyResult       # create alias -- see #17805\n\n#\n# Class whose instances are returned by `Pool.map_async()`\n#\n\nclass MapResult(ApplyResult):\n\n    def __init__(self, cache, chunksize, length, callback, error_callback):\n        ApplyResult.__init__(self, cache, callback,\n                             error_callback=error_callback)\n        self._success = True\n        self._value = [None] * length\n        self._chunksize = chunksize\n        if chunksize <= 0:\n            self._number_left = 0\n            self._event.set()\n            del cache[self._job]\n        else:\n            self._number_left = length//chunksize + bool(length % chunksize)\n\n    def _set(self, i, success_result):\n        success, result = success_result\n        if success:\n            self._value[i*self._chunksize:(i+1)*self._chunksize] = result\n            self._number_left -= 1\n            if self._number_left == 0:\n                if self._callback:\n                    self._callback(self._value)\n                del self._cache[self._job]\n                self._event.set()\n        else:\n            self._success = False\n            self._value = result\n            if self._error_callback:\n                self._error_callback(self._value)\n            del self._cache[self._job]\n            self._event.set()\n\n#\n# Class whose instances are returned by `Pool.imap()`\n#\n\nclass IMapIterator(object):\n\n    def __init__(self, cache):\n        self._cond = threading.Condition(threading.Lock())\n        self._job = next(job_counter)\n        self._cache = cache\n        self._items = collections.deque()\n        self._index = 0\n        self._length = None\n        self._unsorted = {}\n        cache[self._job] = self\n\n    def __iter__(self):\n        return self\n\n    def next(self, timeout=None):\n        self._cond.acquire()\n        try:\n            try:\n                item = self._items.popleft()\n            except IndexError:\n                if self._index == self._length:\n                    raise StopIteration\n                self._cond.wait(timeout)\n                try:\n                    item = self._items.popleft()\n                except IndexError:\n                    if self._index == self._length:\n                        raise StopIteration\n                    raise TimeoutError\n        finally:\n            self._cond.release()\n\n        success, value = item\n        if success:\n            return value\n        raise value\n\n    __next__ = next                    # XXX\n\n    def _set(self, i, obj):\n        self._cond.acquire()\n        try:\n            if self._index == i:\n                self._items.append(obj)\n                self._index += 1\n                while self._index in self._unsorted:\n                    obj = self._unsorted.pop(self._index)\n                    self._items.append(obj)\n                    self._index += 1\n                self._cond.notify()\n            else:\n                self._unsorted[i] = obj\n\n            if self._index == self._length:\n                del self._cache[self._job]\n        finally:\n            self._cond.release()\n\n    def _set_length(self, length):\n        self._cond.acquire()\n        try:\n            self._length = length\n            if self._index == self._length:\n                self._cond.notify()\n                del self._cache[self._job]\n        finally:\n            self._cond.release()\n\n#\n# Class whose instances are returned by `Pool.imap_unordered()`\n#\n\nclass IMapUnorderedIterator(IMapIterator):\n\n    def _set(self, i, obj):\n        self._cond.acquire()\n        try:\n            self._items.append(obj)\n            self._index += 1\n            self._cond.notify()\n            if self._index == self._length:\n                del self._cache[self._job]\n        finally:\n            self._cond.release()\n\n#\n#\n#\n\nclass ThreadPool(Pool):\n\n    from .dummy import Process\n\n    def __init__(self, processes=None, initializer=None, initargs=()):\n        Pool.__init__(self, processes, initializer, initargs)\n\n    def _setup_queues(self):\n        self._inqueue = queue.Queue()\n        self._outqueue = queue.Queue()\n        self._quick_put = self._inqueue.put\n        self._quick_get = self._outqueue.get\n\n    @staticmethod\n    def _help_stuff_finish(inqueue, task_handler, size):\n        # put sentinels at head of inqueue to make workers finish\n        inqueue.not_empty.acquire()\n        try:\n            inqueue.queue.clear()\n            inqueue.queue.extend([None] * size)\n            inqueue.not_empty.notify_all()\n        finally:\n            inqueue.not_empty.release()\n"], "decimal": [".py", "# Copyright (c) 2004 Python Software Foundation.\n# All rights reserved.\n\n# Written by Eric Price <eprice at tjhsst.edu>\n#    and Facundo Batista <facundo at taniquetil.com.ar>\n#    and Raymond Hettinger <python at rcn.com>\n#    and Aahz <aahz at pobox.com>\n#    and Tim Peters\n\n# This module should be kept in sync with the latest updates of the\n# IBM specification as it evolves.  Those updates will be treated\n# as bug fixes (deviation from the spec is a compatibility, usability\n# bug) and will be backported.  At this point the spec is stabilizing\n# and the updates are becoming fewer, smaller, and less significant.\n\n\"\"\"\nThis is an implementation of decimal floating point arithmetic based on\nthe General Decimal Arithmetic Specification:\n\n    http://speleotrove.com/decimal/decarith.html\n\nand IEEE standard 854-1987:\n\n    http://en.wikipedia.org/wiki/IEEE_854-1987\n\nDecimal floating point has finite precision with arbitrarily large bounds.\n\nThe purpose of this module is to support arithmetic using familiar\n\"schoolhouse\" rules and to avoid some of the tricky representation\nissues associated with binary floating point.  The package is especially\nuseful for financial applications or for contexts where users have\nexpectations that are at odds with binary floating point (for instance,\nin binary floating point, 1.00 % 0.1 gives 0.09999999999999995 instead\nof 0.0; Decimal('1.00') % Decimal('0.1') returns the expected\nDecimal('0.00')).\n\nHere are some examples of using the decimal module:\n\n>>> from decimal import *\n>>> setcontext(ExtendedContext)\n>>> Decimal(0)\nDecimal('0')\n>>> Decimal('1')\nDecimal('1')\n>>> Decimal('-.0123')\nDecimal('-0.0123')\n>>> Decimal(123456)\nDecimal('123456')\n>>> Decimal('123.45e12345678')\nDecimal('1.2345E+12345680')\n>>> Decimal('1.33') + Decimal('1.27')\nDecimal('2.60')\n>>> Decimal('12.34') + Decimal('3.87') - Decimal('18.41')\nDecimal('-2.20')\n>>> dig = Decimal(1)\n>>> print(dig / Decimal(3))\n0.333333333\n>>> getcontext().prec = 18\n>>> print(dig / Decimal(3))\n0.333333333333333333\n>>> print(dig.sqrt())\n1\n>>> print(Decimal(3).sqrt())\n1.73205080756887729\n>>> print(Decimal(3) ** 123)\n4.85192780976896427E+58\n>>> inf = Decimal(1) / Decimal(0)\n>>> print(inf)\nInfinity\n>>> neginf = Decimal(-1) / Decimal(0)\n>>> print(neginf)\n-Infinity\n>>> print(neginf + inf)\nNaN\n>>> print(neginf * inf)\n-Infinity\n>>> print(dig / 0)\nInfinity\n>>> getcontext().traps[DivisionByZero] = 1\n>>> print(dig / 0)\nTraceback (most recent call last):\n  ...\n  ...\n  ...\ndecimal.DivisionByZero: x / 0\n>>> c = Context()\n>>> c.traps[InvalidOperation] = 0\n>>> print(c.flags[InvalidOperation])\n0\n>>> c.divide(Decimal(0), Decimal(0))\nDecimal('NaN')\n>>> c.traps[InvalidOperation] = 1\n>>> print(c.flags[InvalidOperation])\n1\n>>> c.flags[InvalidOperation] = 0\n>>> print(c.flags[InvalidOperation])\n0\n>>> print(c.divide(Decimal(0), Decimal(0)))\nTraceback (most recent call last):\n  ...\n  ...\n  ...\ndecimal.InvalidOperation: 0 / 0\n>>> print(c.flags[InvalidOperation])\n1\n>>> c.flags[InvalidOperation] = 0\n>>> c.traps[InvalidOperation] = 0\n>>> print(c.divide(Decimal(0), Decimal(0)))\nNaN\n>>> print(c.flags[InvalidOperation])\n1\n>>>\n\"\"\"\n\n__all__ = [\n    # Two major classes\n    'Decimal', 'Context',\n\n    # Contexts\n    'DefaultContext', 'BasicContext', 'ExtendedContext',\n\n    # Exceptions\n    'DecimalException', 'Clamped', 'InvalidOperation', 'DivisionByZero',\n    'Inexact', 'Rounded', 'Subnormal', 'Overflow', 'Underflow',\n    'FloatOperation',\n\n    # Constants for use in setting up contexts\n    'ROUND_DOWN', 'ROUND_HALF_UP', 'ROUND_HALF_EVEN', 'ROUND_CEILING',\n    'ROUND_FLOOR', 'ROUND_UP', 'ROUND_HALF_DOWN', 'ROUND_05UP',\n\n    # Functions for manipulating contexts\n    'setcontext', 'getcontext', 'localcontext',\n\n    # Limits for the C version for compatibility\n    'MAX_PREC',  'MAX_EMAX', 'MIN_EMIN', 'MIN_ETINY',\n\n    # C version: compile time choice that enables the thread local context\n    'HAVE_THREADS'\n]\n\n__version__ = '1.70'    # Highest version of the spec this complies with\n                        # See http://speleotrove.com/decimal/\n\nimport copy as _copy\nimport math as _math\nimport numbers as _numbers\nimport sys\n\ntry:\n    from collections import namedtuple as _namedtuple\n    DecimalTuple = _namedtuple('DecimalTuple', 'sign digits exponent')\nexcept ImportError:\n    DecimalTuple = lambda *args: args\n\n# Rounding\nROUND_DOWN = 'ROUND_DOWN'\nROUND_HALF_UP = 'ROUND_HALF_UP'\nROUND_HALF_EVEN = 'ROUND_HALF_EVEN'\nROUND_CEILING = 'ROUND_CEILING'\nROUND_FLOOR = 'ROUND_FLOOR'\nROUND_UP = 'ROUND_UP'\nROUND_HALF_DOWN = 'ROUND_HALF_DOWN'\nROUND_05UP = 'ROUND_05UP'\n\n# Compatibility with the C version\nHAVE_THREADS = True\nif sys.maxsize == 2**63-1:\n    MAX_PREC = 999999999999999999\n    MAX_EMAX = 999999999999999999\n    MIN_EMIN = -999999999999999999\nelse:\n    MAX_PREC = 425000000\n    MAX_EMAX = 425000000\n    MIN_EMIN = -425000000\n\nMIN_ETINY = MIN_EMIN - (MAX_PREC-1)\n\n# Errors\n\nclass DecimalException(ArithmeticError):\n    \"\"\"Base exception class.\n\n    Used exceptions derive from this.\n    If an exception derives from another exception besides this (such as\n    Underflow (Inexact, Rounded, Subnormal) that indicates that it is only\n    called if the others are present.  This isn't actually used for\n    anything, though.\n\n    handle  -- Called when context._raise_error is called and the\n               trap_enabler is not set.  First argument is self, second is the\n               context.  More arguments can be given, those being after\n               the explanation in _raise_error (For example,\n               context._raise_error(NewError, '(-x)!', self._sign) would\n               call NewError().handle(context, self._sign).)\n\n    To define a new exception, it should be sufficient to have it derive\n    from DecimalException.\n    \"\"\"\n    def handle(self, context, *args):\n        pass\n\n\nclass Clamped(DecimalException):\n    \"\"\"Exponent of a 0 changed to fit bounds.\n\n    This occurs and signals clamped if the exponent of a result has been\n    altered in order to fit the constraints of a specific concrete\n    representation.  This may occur when the exponent of a zero result would\n    be outside the bounds of a representation, or when a large normal\n    number would have an encoded exponent that cannot be represented.  In\n    this latter case, the exponent is reduced to fit and the corresponding\n    number of zero digits are appended to the coefficient (\"fold-down\").\n    \"\"\"\n\n    #brython fixme\n    pass\n\nclass InvalidOperation(DecimalException):\n    \"\"\"An invalid operation was performed.\n\n    Various bad things cause this:\n\n    Something creates a signaling NaN\n    -INF + INF\n    0 * (+-)INF\n    (+-)INF / (+-)INF\n    x % 0\n    (+-)INF % x\n    x._rescale( non-integer )\n    sqrt(-x) , x > 0\n    0 ** 0\n    x ** (non-integer)\n    x ** (+-)INF\n    An operand is invalid\n\n    The result of the operation after these is a quiet positive NaN,\n    except when the cause is a signaling NaN, in which case the result is\n    also a quiet NaN, but with the original sign, and an optional\n    diagnostic information.\n    \"\"\"\n    def handle(self, context, *args):\n        if args:\n            ans = _dec_from_triple(args[0]._sign, args[0]._int, 'n', True)\n            return ans._fix_nan(context)\n        return _NaN\n\nclass ConversionSyntax(InvalidOperation):\n    \"\"\"Trying to convert badly formed string.\n\n    This occurs and signals invalid-operation if an string is being\n    converted to a number and it does not conform to the numeric string\n    syntax.  The result is [0,qNaN].\n    \"\"\"\n    def handle(self, context, *args):\n        return _NaN\n\nclass DivisionByZero(DecimalException, ZeroDivisionError):\n    \"\"\"Division by 0.\n\n    This occurs and signals division-by-zero if division of a finite number\n    by zero was attempted (during a divide-integer or divide operation, or a\n    power operation with negative right-hand operand), and the dividend was\n    not zero.\n\n    The result of the operation is [sign,inf], where sign is the exclusive\n    or of the signs of the operands for divide, or is 1 for an odd power of\n    -0, for power.\n    \"\"\"\n\n    def handle(self, context, sign, *args):\n        return _SignedInfinity[sign]\n\nclass DivisionImpossible(InvalidOperation):\n    \"\"\"Cannot perform the division adequately.\n\n    This occurs and signals invalid-operation if the integer result of a\n    divide-integer or remainder operation had too many digits (would be\n    longer than precision).  The result is [0,qNaN].\n    \"\"\"\n\n    def handle(self, context, *args):\n        return _NaN\n\nclass DivisionUndefined(InvalidOperation, ZeroDivisionError):\n    \"\"\"Undefined result of division.\n\n    This occurs and signals invalid-operation if division by zero was\n    attempted (during a divide-integer, divide, or remainder operation), and\n    the dividend is also zero.  The result is [0,qNaN].\n    \"\"\"\n\n    def handle(self, context, *args):\n        return _NaN\n\nclass Inexact(DecimalException):\n    \"\"\"Had to round, losing information.\n\n    This occurs and signals inexact whenever the result of an operation is\n    not exact (that is, it needed to be rounded and any discarded digits\n    were non-zero), or if an overflow or underflow condition occurs.  The\n    result in all cases is unchanged.\n\n    The inexact signal may be tested (or trapped) to determine if a given\n    operation (or sequence of operations) was inexact.\n    \"\"\"\n\n    #brython fix me\n    pass\n\nclass InvalidContext(InvalidOperation):\n    \"\"\"Invalid context.  Unknown rounding, for example.\n\n    This occurs and signals invalid-operation if an invalid context was\n    detected during an operation.  This can occur if contexts are not checked\n    on creation and either the precision exceeds the capability of the\n    underlying concrete representation or an unknown or unsupported rounding\n    was specified.  These aspects of the context need only be checked when\n    the values are required to be used.  The result is [0,qNaN].\n    \"\"\"\n\n    def handle(self, context, *args):\n        return _NaN\n\nclass Rounded(DecimalException):\n    \"\"\"Number got rounded (not  necessarily changed during rounding).\n\n    This occurs and signals rounded whenever the result of an operation is\n    rounded (that is, some zero or non-zero digits were discarded from the\n    coefficient), or if an overflow or underflow condition occurs.  The\n    result in all cases is unchanged.\n\n    The rounded signal may be tested (or trapped) to determine if a given\n    operation (or sequence of operations) caused a loss of precision.\n    \"\"\"\n    #brython fix me\n    pass\n\nclass Subnormal(DecimalException):\n    \"\"\"Exponent < Emin before rounding.\n\n    This occurs and signals subnormal whenever the result of a conversion or\n    operation is subnormal (that is, its adjusted exponent is less than\n    Emin, before any rounding).  The result in all cases is unchanged.\n\n    The subnormal signal may be tested (or trapped) to determine if a given\n    or operation (or sequence of operations) yielded a subnormal result.\n    \"\"\"\n    #brython fix me\n    pass\n\nclass Overflow(Inexact, Rounded):\n    \"\"\"Numerical overflow.\n\n    This occurs and signals overflow if the adjusted exponent of a result\n    (from a conversion or from an operation that is not an attempt to divide\n    by zero), after rounding, would be greater than the largest value that\n    can be handled by the implementation (the value Emax).\n\n    The result depends on the rounding mode:\n\n    For round-half-up and round-half-even (and for round-half-down and\n    round-up, if implemented), the result of the operation is [sign,inf],\n    where sign is the sign of the intermediate result.  For round-down, the\n    result is the largest finite number that can be represented in the\n    current precision, with the sign of the intermediate result.  For\n    round-ceiling, the result is the same as for round-down if the sign of\n    the intermediate result is 1, or is [0,inf] otherwise.  For round-floor,\n    the result is the same as for round-down if the sign of the intermediate\n    result is 0, or is [1,inf] otherwise.  In all cases, Inexact and Rounded\n    will also be raised.\n    \"\"\"\n\n    def handle(self, context, sign, *args):\n        if context.rounding in (ROUND_HALF_UP, ROUND_HALF_EVEN,\n                                ROUND_HALF_DOWN, ROUND_UP):\n            return _SignedInfinity[sign]\n        if sign == 0:\n            if context.rounding == ROUND_CEILING:\n                return _SignedInfinity[sign]\n            return _dec_from_triple(sign, '9'*context.prec,\n                            context.Emax-context.prec+1)\n        if sign == 1:\n            if context.rounding == ROUND_FLOOR:\n                return _SignedInfinity[sign]\n            return _dec_from_triple(sign, '9'*context.prec,\n                             context.Emax-context.prec+1)\n\n\nclass Underflow(Inexact, Rounded, Subnormal):\n    \"\"\"Numerical underflow with result rounded to 0.\n\n    This occurs and signals underflow if a result is inexact and the\n    adjusted exponent of the result would be smaller (more negative) than\n    the smallest value that can be handled by the implementation (the value\n    Emin).  That is, the result is both inexact and subnormal.\n\n    The result after an underflow will be a subnormal number rounded, if\n    necessary, so that its exponent is not less than Etiny.  This may result\n    in 0 with the sign of the intermediate result and an exponent of Etiny.\n\n    In all cases, Inexact, Rounded, and Subnormal will also be raised.\n    \"\"\"\n    #brython fix me\n    pass\n\nclass FloatOperation(DecimalException, TypeError):\n    \"\"\"Enable stricter semantics for mixing floats and Decimals.\n\n    If the signal is not trapped (default), mixing floats and Decimals is\n    permitted in the Decimal() constructor, context.create_decimal() and\n    all comparison operators. Both conversion and comparisons are exact.\n    Any occurrence of a mixed operation is silently recorded by setting\n    FloatOperation in the context flags.  Explicit conversions with\n    Decimal.from_float() or context.create_decimal_from_float() do not\n    set the flag.\n\n    Otherwise (the signal is trapped), only equality comparisons and explicit\n    conversions are silent. All other mixed operations raise FloatOperation.\n    \"\"\"\n    #brython fix me\n    pass\n\n# List of public traps and flags\n_signals = [Clamped, DivisionByZero, Inexact, Overflow, Rounded,\n            Underflow, InvalidOperation, Subnormal, FloatOperation]\n\n# Map conditions (per the spec) to signals\n_condition_map = {ConversionSyntax:InvalidOperation,\n                  DivisionImpossible:InvalidOperation,\n                  DivisionUndefined:InvalidOperation,\n                  InvalidContext:InvalidOperation}\n\n# Valid rounding modes\n_rounding_modes = (ROUND_DOWN, ROUND_HALF_UP, ROUND_HALF_EVEN, ROUND_CEILING,\n                   ROUND_FLOOR, ROUND_UP, ROUND_HALF_DOWN, ROUND_05UP)\n\n##### Context Functions ##################################################\n\n# The getcontext() and setcontext() function manage access to a thread-local\n# current context.  Py2.4 offers direct support for thread locals.  If that\n# is not available, use threading.current_thread() which is slower but will\n# work for older Pythons.  If threads are not part of the build, create a\n# mock threading object with threading.local() returning the module namespace.\n\ntry:\n    import threading\nexcept ImportError:\n    # Python was compiled without threads; create a mock object instead\n    class MockThreading(object):\n        def local(self, sys=sys):\n            return sys.modules[__name__]\n    threading = MockThreading()\n    del MockThreading\n\ntry:\n    threading.local\n\nexcept AttributeError:\n\n    # To fix reloading, force it to create a new context\n    # Old contexts have different exceptions in their dicts, making problems.\n    if hasattr(threading.current_thread(), '__decimal_context__'):\n        del threading.current_thread().__decimal_context__\n\n    def setcontext(context):\n        \"\"\"Set this thread's context to context.\"\"\"\n        if context in (DefaultContext, BasicContext, ExtendedContext):\n            context = context.copy()\n            context.clear_flags()\n        threading.current_thread().__decimal_context__ = context\n\n    def getcontext():\n        \"\"\"Returns this thread's context.\n\n        If this thread does not yet have a context, returns\n        a new context and sets this thread's context.\n        New contexts are copies of DefaultContext.\n        \"\"\"\n        try:\n            return threading.current_thread().__decimal_context__\n        except AttributeError:\n            context = Context()\n            threading.current_thread().__decimal_context__ = context\n            return context\n\nelse:\n\n    local = threading.local()\n    if hasattr(local, '__decimal_context__'):\n        del local.__decimal_context__\n\n    def getcontext(_local=local):\n        \"\"\"Returns this thread's context.\n\n        If this thread does not yet have a context, returns\n        a new context and sets this thread's context.\n        New contexts are copies of DefaultContext.\n        \"\"\"\n        try:\n            return _local.__decimal_context__\n        except AttributeError:\n            context = Context()\n            _local.__decimal_context__ = context\n            return context\n\n    def setcontext(context, _local=local):\n        \"\"\"Set this thread's context to context.\"\"\"\n        if context in (DefaultContext, BasicContext, ExtendedContext):\n            context = context.copy()\n            context.clear_flags()\n        _local.__decimal_context__ = context\n\n    del threading, local        # Don't contaminate the namespace\n\ndef localcontext(ctx=None):\n    \"\"\"Return a context manager for a copy of the supplied context\n\n    Uses a copy of the current context if no context is specified\n    The returned context manager creates a local decimal context\n    in a with statement:\n        def sin(x):\n             with localcontext() as ctx:\n                 ctx.prec += 2\n                 # Rest of sin calculation algorithm\n                 # uses a precision 2 greater than normal\n             return +s  # Convert result to normal precision\n\n         def sin(x):\n             with localcontext(ExtendedContext):\n                 # Rest of sin calculation algorithm\n                 # uses the Extended Context from the\n                 # General Decimal Arithmetic Specification\n             return +s  # Convert result to normal context\n\n    >>> setcontext(DefaultContext)\n    >>> print(getcontext().prec)\n    28\n    >>> with localcontext():\n    ...     ctx = getcontext()\n    ...     ctx.prec += 2\n    ...     print(ctx.prec)\n    ...\n    30\n    >>> with localcontext(ExtendedContext):\n    ...     print(getcontext().prec)\n    ...\n    9\n    >>> print(getcontext().prec)\n    28\n    \"\"\"\n    if ctx is None: ctx = getcontext()\n    return _ContextManager(ctx)\n\n\n##### Decimal class #######################################################\n\n# Do not subclass Decimal from numbers.Real and do not register it as such\n# (because Decimals are not interoperable with floats).  See the notes in\n# numbers.py for more detail.\n\nclass Decimal(object):\n    \"\"\"Floating point class for decimal arithmetic.\"\"\"\n\n    __slots__ = ('_exp','_int','_sign', '_is_special')\n    # Generally, the value of the Decimal instance is given by\n    #  (-1)**_sign * _int * 10**_exp\n    # Special values are signified by _is_special == True\n\n    # We're immutable, so use __new__ not __init__\n    def __new__(cls, value=\"0\", context=None):\n        \"\"\"Create a decimal point instance.\n\n        >>> Decimal('3.14')              # string input\n        Decimal('3.14')\n        >>> Decimal((0, (3, 1, 4), -2))  # tuple (sign, digit_tuple, exponent)\n        Decimal('3.14')\n        >>> Decimal(314)                 # int\n        Decimal('314')\n        >>> Decimal(Decimal(314))        # another decimal instance\n        Decimal('314')\n        >>> Decimal('  3.14  \\\\n')        # leading and trailing whitespace okay\n        Decimal('3.14')\n        \"\"\"\n\n        # Note that the coefficient, self._int, is actually stored as\n        # a string rather than as a tuple of digits.  This speeds up\n        # the \"digits to integer\" and \"integer to digits\" conversions\n        # that are used in almost every arithmetic operation on\n        # Decimals.  This is an internal detail: the as_tuple function\n        # and the Decimal constructor still deal with tuples of\n        # digits.\n\n        self = object.__new__(cls)\n\n        # From a string\n        # REs insist on real strings, so we can too.\n        if isinstance(value, str):\n            m = _parser(value.strip())\n            if m is None:\n                if context is None:\n                    context = getcontext()\n                return context._raise_error(ConversionSyntax,\n                                \"Invalid literal for Decimal: %r\" % value)\n\n            if m.group('sign') == \"-\":\n                self._sign = 1\n            else:\n                self._sign = 0\n            intpart = m.group('int')\n            if intpart is not None:\n                # finite number\n                fracpart = m.group('frac') or ''\n                exp = int(m.group('exp') or '0')\n                self._int = str(int(intpart+fracpart))\n                self._exp = exp - len(fracpart)\n                self._is_special = False\n            else:\n                diag = m.group('diag')\n                if diag is not None:\n                    # NaN\n                    self._int = str(int(diag or '0')).lstrip('0')\n                    if m.group('signal'):\n                        self._exp = 'N'\n                    else:\n                        self._exp = 'n'\n                else:\n                    # infinity\n                    self._int = '0'\n                    self._exp = 'F'\n                self._is_special = True\n            return self\n\n        # From an integer\n        if isinstance(value, int):\n            if value >= 0:\n                self._sign = 0\n            else:\n                self._sign = 1\n            self._exp = 0\n            self._int = str(abs(value))\n            self._is_special = False\n            return self\n\n        # From another decimal\n        if isinstance(value, Decimal):\n            self._exp  = value._exp\n            self._sign = value._sign\n            self._int  = value._int\n            self._is_special  = value._is_special\n            return self\n\n        # From an internal working value\n        if isinstance(value, _WorkRep):\n            self._sign = value.sign\n            self._int = str(value.int)\n            self._exp = int(value.exp)\n            self._is_special = False\n            return self\n\n        # tuple/list conversion (possibly from as_tuple())\n        if isinstance(value, (list,tuple)):\n            if len(value) != 3:\n                raise ValueError('Invalid tuple size in creation of Decimal '\n                                 'from list or tuple.  The list or tuple '\n                                 'should have exactly three elements.')\n            # process sign.  The isinstance test rejects floats\n            if not (isinstance(value[0], int) and value[0] in (0,1)):\n                raise ValueError(\"Invalid sign.  The first value in the tuple \"\n                                 \"should be an integer; either 0 for a \"\n                                 \"positive number or 1 for a negative number.\")\n            self._sign = value[0]\n            if value[2] == 'F':\n                # infinity: value[1] is ignored\n                self._int = '0'\n                self._exp = value[2]\n                self._is_special = True\n            else:\n                # process and validate the digits in value[1]\n                digits = []\n                for digit in value[1]:\n                    if isinstance(digit, int) and 0 <= digit <= 9:\n                        # skip leading zeros\n                        if digits or digit != 0:\n                            digits.append(digit)\n                    else:\n                        raise ValueError(\"The second value in the tuple must \"\n                                         \"be composed of integers in the range \"\n                                         \"0 through 9.\")\n                if value[2] in ('n', 'N'):\n                    # NaN: digits form the diagnostic\n                    self._int = ''.join(map(str, digits))\n                    self._exp = value[2]\n                    self._is_special = True\n                elif isinstance(value[2], int):\n                    # finite number: digits give the coefficient\n                    self._int = ''.join(map(str, digits or [0]))\n                    self._exp = value[2]\n                    self._is_special = False\n                else:\n                    raise ValueError(\"The third value in the tuple must \"\n                                     \"be an integer, or one of the \"\n                                     \"strings 'F', 'n', 'N'.\")\n            return self\n\n        if isinstance(value, float):\n            if context is None:\n                context = getcontext()\n            context._raise_error(FloatOperation,\n                \"strict semantics for mixing floats and Decimals are \"\n                \"enabled\")\n            value = Decimal.from_float(value)\n            self._exp  = value._exp\n            self._sign = value._sign\n            self._int  = value._int\n            self._is_special  = value._is_special\n            return self\n\n        raise TypeError(\"Cannot convert %r to Decimal\" % value)\n\n    # @classmethod, but @decorator is not valid Python 2.3 syntax, so\n    # don't use it (see notes on Py2.3 compatibility at top of file)\n    def from_float(cls, f):\n        \"\"\"Converts a float to a decimal number, exactly.\n\n        Note that Decimal.from_float(0.1) is not the same as Decimal('0.1').\n        Since 0.1 is not exactly representable in binary floating point, the\n        value is stored as the nearest representable value which is\n        0x1.999999999999ap-4.  The exact equivalent of the value in decimal\n        is 0.1000000000000000055511151231257827021181583404541015625.\n\n        >>> Decimal.from_float(0.1)\n        Decimal('0.1000000000000000055511151231257827021181583404541015625')\n        >>> Decimal.from_float(float('nan'))\n        Decimal('NaN')\n        >>> Decimal.from_float(float('inf'))\n        Decimal('Infinity')\n        >>> Decimal.from_float(-float('inf'))\n        Decimal('-Infinity')\n        >>> Decimal.from_float(-0.0)\n        Decimal('-0')\n\n        \"\"\"\n        if isinstance(f, int):                # handle integer inputs\n            return cls(f)\n        if not isinstance(f, float):\n            raise TypeError(\"argument must be int or float.\")\n        if _math.isinf(f) or _math.isnan(f):\n            return cls(repr(f))\n        if _math.copysign(1.0, f) == 1.0:\n            sign = 0\n        else:\n            sign = 1\n        n, d = abs(f).as_integer_ratio()\n        k = d.bit_length() - 1\n        result = _dec_from_triple(sign, str(n*5**k), -k)\n        if cls is Decimal:\n            return result\n        else:\n            return cls(result)\n    from_float = classmethod(from_float)\n\n    def _isnan(self):\n        \"\"\"Returns whether the number is not actually one.\n\n        0 if a number\n        1 if NaN\n        2 if sNaN\n        \"\"\"\n        if self._is_special:\n            exp = self._exp\n            if exp == 'n':\n                return 1\n            elif exp == 'N':\n                return 2\n        return 0\n\n    def _isinfinity(self):\n        \"\"\"Returns whether the number is infinite\n\n        0 if finite or not a number\n        1 if +INF\n        -1 if -INF\n        \"\"\"\n        if self._exp == 'F':\n            if self._sign:\n                return -1\n            return 1\n        return 0\n\n    def _check_nans(self, other=None, context=None):\n        \"\"\"Returns whether the number is not actually one.\n\n        if self, other are sNaN, signal\n        if self, other are NaN return nan\n        return 0\n\n        Done before operations.\n        \"\"\"\n\n        self_is_nan = self._isnan()\n        if other is None:\n            other_is_nan = False\n        else:\n            other_is_nan = other._isnan()\n\n        if self_is_nan or other_is_nan:\n            if context is None:\n                context = getcontext()\n\n            if self_is_nan == 2:\n                return context._raise_error(InvalidOperation, 'sNaN',\n                                        self)\n            if other_is_nan == 2:\n                return context._raise_error(InvalidOperation, 'sNaN',\n                                        other)\n            if self_is_nan:\n                return self._fix_nan(context)\n\n            return other._fix_nan(context)\n        return 0\n\n    def _compare_check_nans(self, other, context):\n        \"\"\"Version of _check_nans used for the signaling comparisons\n        compare_signal, __le__, __lt__, __ge__, __gt__.\n\n        Signal InvalidOperation if either self or other is a (quiet\n        or signaling) NaN.  Signaling NaNs take precedence over quiet\n        NaNs.\n\n        Return 0 if neither operand is a NaN.\n\n        \"\"\"\n        if context is None:\n            context = getcontext()\n\n        if self._is_special or other._is_special:\n            if self.is_snan():\n                return context._raise_error(InvalidOperation,\n                                            'comparison involving sNaN',\n                                            self)\n            elif other.is_snan():\n                return context._raise_error(InvalidOperation,\n                                            'comparison involving sNaN',\n                                            other)\n            elif self.is_qnan():\n                return context._raise_error(InvalidOperation,\n                                            'comparison involving NaN',\n                                            self)\n            elif other.is_qnan():\n                return context._raise_error(InvalidOperation,\n                                            'comparison involving NaN',\n                                            other)\n        return 0\n\n    def __bool__(self):\n        \"\"\"Return True if self is nonzero; otherwise return False.\n\n        NaNs and infinities are considered nonzero.\n        \"\"\"\n        return self._is_special or self._int != '0'\n\n    def _cmp(self, other):\n        \"\"\"Compare the two non-NaN decimal instances self and other.\n\n        Returns -1 if self < other, 0 if self == other and 1\n        if self > other.  This routine is for internal use only.\"\"\"\n\n        if self._is_special or other._is_special:\n            self_inf = self._isinfinity()\n            other_inf = other._isinfinity()\n            if self_inf == other_inf:\n                return 0\n            elif self_inf < other_inf:\n                return -1\n            else:\n                return 1\n\n        # check for zeros;  Decimal('0') == Decimal('-0')\n        if not self:\n            if not other:\n                return 0\n            else:\n                return -((-1)**other._sign)\n        if not other:\n            return (-1)**self._sign\n\n        # If different signs, neg one is less\n        if other._sign < self._sign:\n            return -1\n        if self._sign < other._sign:\n            return 1\n\n        self_adjusted = self.adjusted()\n        other_adjusted = other.adjusted()\n        if self_adjusted == other_adjusted:\n            self_padded = self._int + '0'*(self._exp - other._exp)\n            other_padded = other._int + '0'*(other._exp - self._exp)\n            if self_padded == other_padded:\n                return 0\n            elif self_padded < other_padded:\n                return -(-1)**self._sign\n            else:\n                return (-1)**self._sign\n        elif self_adjusted > other_adjusted:\n            return (-1)**self._sign\n        else: # self_adjusted < other_adjusted\n            return -((-1)**self._sign)\n\n    # Note: The Decimal standard doesn't cover rich comparisons for\n    # Decimals.  In particular, the specification is silent on the\n    # subject of what should happen for a comparison involving a NaN.\n    # We take the following approach:\n    #\n    #   == comparisons involving a quiet NaN always return False\n    #   != comparisons involving a quiet NaN always return True\n    #   == or != comparisons involving a signaling NaN signal\n    #      InvalidOperation, and return False or True as above if the\n    #      InvalidOperation is not trapped.\n    #   <, >, <= and >= comparisons involving a (quiet or signaling)\n    #      NaN signal InvalidOperation, and return False if the\n    #      InvalidOperation is not trapped.\n    #\n    # This behavior is designed to conform as closely as possible to\n    # that specified by IEEE 754.\n\n    def __eq__(self, other, context=None):\n        self, other = _convert_for_comparison(self, other, equality_op=True)\n        if other is NotImplemented:\n            return other\n        if self._check_nans(other, context):\n            return False\n        return self._cmp(other) == 0\n\n    def __ne__(self, other, context=None):\n        self, other = _convert_for_comparison(self, other, equality_op=True)\n        if other is NotImplemented:\n            return other\n        if self._check_nans(other, context):\n            return True\n        return self._cmp(other) != 0\n\n\n    def __lt__(self, other, context=None):\n        self, other = _convert_for_comparison(self, other)\n        if other is NotImplemented:\n            return other\n        ans = self._compare_check_nans(other, context)\n        if ans:\n            return False\n        return self._cmp(other) < 0\n\n    def __le__(self, other, context=None):\n        self, other = _convert_for_comparison(self, other)\n        if other is NotImplemented:\n            return other\n        ans = self._compare_check_nans(other, context)\n        if ans:\n            return False\n        return self._cmp(other) <= 0\n\n    def __gt__(self, other, context=None):\n        self, other = _convert_for_comparison(self, other)\n        if other is NotImplemented:\n            return other\n        ans = self._compare_check_nans(other, context)\n        if ans:\n            return False\n        return self._cmp(other) > 0\n\n    def __ge__(self, other, context=None):\n        self, other = _convert_for_comparison(self, other)\n        if other is NotImplemented:\n            return other\n        ans = self._compare_check_nans(other, context)\n        if ans:\n            return False\n        return self._cmp(other) >= 0\n\n    def compare(self, other, context=None):\n        \"\"\"Compares one to another.\n\n        -1 => a < b\n        0  => a = b\n        1  => a > b\n        NaN => one is NaN\n        Like __cmp__, but returns Decimal instances.\n        \"\"\"\n        other = _convert_other(other, raiseit=True)\n\n        # Compare(NaN, NaN) = NaN\n        if (self._is_special or other and other._is_special):\n            ans = self._check_nans(other, context)\n            if ans:\n                return ans\n\n        return Decimal(self._cmp(other))\n\n    def __hash__(self):\n        \"\"\"x.__hash__() <==> hash(x)\"\"\"\n\n        # In order to make sure that the hash of a Decimal instance\n        # agrees with the hash of a numerically equal integer, float\n        # or Fraction, we follow the rules for numeric hashes outlined\n        # in the documentation.  (See library docs, 'Built-in Types').\n        if self._is_special:\n            if self.is_snan():\n                raise TypeError('Cannot hash a signaling NaN value.')\n            elif self.is_nan():\n                return _PyHASH_NAN\n            else:\n                if self._sign:\n                    return -_PyHASH_INF\n                else:\n                    return _PyHASH_INF\n\n        if self._exp >= 0:\n            exp_hash = pow(10, self._exp, _PyHASH_MODULUS)\n        else:\n            exp_hash = pow(_PyHASH_10INV, -self._exp, _PyHASH_MODULUS)\n        hash_ = int(self._int) * exp_hash % _PyHASH_MODULUS\n        ans = hash_ if self >= 0 else -hash_\n        return -2 if ans == -1 else ans\n\n    def as_tuple(self):\n        \"\"\"Represents the number as a triple tuple.\n\n        To show the internals exactly as they are.\n        \"\"\"\n        return DecimalTuple(self._sign, tuple(map(int, self._int)), self._exp)\n\n    def __repr__(self):\n        \"\"\"Represents the number as an instance of Decimal.\"\"\"\n        # Invariant:  eval(repr(d)) == d\n        return \"Decimal('%s')\" % str(self)\n\n    def __str__(self, eng=False, context=None):\n        \"\"\"Return string representation of the number in scientific notation.\n\n        Captures all of the information in the underlying representation.\n        \"\"\"\n\n        sign = ['', '-'][self._sign]\n        if self._is_special:\n            if self._exp == 'F':\n                return sign + 'Infinity'\n            elif self._exp == 'n':\n                return sign + 'NaN' + self._int\n            else: # self._exp == 'N'\n                return sign + 'sNaN' + self._int\n\n        # number of digits of self._int to left of decimal point\n        leftdigits = self._exp + len(self._int)\n\n        # dotplace is number of digits of self._int to the left of the\n        # decimal point in the mantissa of the output string (that is,\n        # after adjusting the exponent)\n        if self._exp <= 0 and leftdigits > -6:\n            # no exponent required\n            dotplace = leftdigits\n        elif not eng:\n            # usual scientific notation: 1 digit on left of the point\n            dotplace = 1\n        elif self._int == '0':\n            # engineering notation, zero\n            dotplace = (leftdigits + 1) % 3 - 1\n        else:\n            # engineering notation, nonzero\n            dotplace = (leftdigits - 1) % 3 + 1\n\n        if dotplace <= 0:\n            intpart = '0'\n            fracpart = '.' + '0'*(-dotplace) + self._int\n        elif dotplace >= len(self._int):\n            intpart = self._int+'0'*(dotplace-len(self._int))\n            fracpart = ''\n        else:\n            intpart = self._int[:dotplace]\n            fracpart = '.' + self._int[dotplace:]\n        if leftdigits == dotplace:\n            exp = ''\n        else:\n            if context is None:\n                context = getcontext()\n            exp = ['e', 'E'][context.capitals] + \"%+d\" % (leftdigits-dotplace)\n\n        return sign + intpart + fracpart + exp\n\n    def to_eng_string(self, context=None):\n        \"\"\"Convert to engineering-type string.\n\n        Engineering notation has an exponent which is a multiple of 3, so there\n        are up to 3 digits left of the decimal place.\n\n        Same rules for when in exponential and when as a value as in __str__.\n        \"\"\"\n        return self.__str__(eng=True, context=context)\n\n    def __neg__(self, context=None):\n        \"\"\"Returns a copy with the sign switched.\n\n        Rounds, if it has reason.\n        \"\"\"\n        if self._is_special:\n            ans = self._check_nans(context=context)\n            if ans:\n                return ans\n\n        if context is None:\n            context = getcontext()\n\n        if not self and context.rounding != ROUND_FLOOR:\n            # -Decimal('0') is Decimal('0'), not Decimal('-0'), except\n            # in ROUND_FLOOR rounding mode.\n            ans = self.copy_abs()\n        else:\n            ans = self.copy_negate()\n\n        return ans._fix(context)\n\n    def __pos__(self, context=None):\n        \"\"\"Returns a copy, unless it is a sNaN.\n\n        Rounds the number (if more then precision digits)\n        \"\"\"\n        if self._is_special:\n            ans = self._check_nans(context=context)\n            if ans:\n                return ans\n\n        if context is None:\n            context = getcontext()\n\n        if not self and context.rounding != ROUND_FLOOR:\n            # + (-0) = 0, except in ROUND_FLOOR rounding mode.\n            ans = self.copy_abs()\n        else:\n            ans = Decimal(self)\n\n        return ans._fix(context)\n\n    def __abs__(self, round=True, context=None):\n        \"\"\"Returns the absolute value of self.\n\n        If the keyword argument 'round' is false, do not round.  The\n        expression self.__abs__(round=False) is equivalent to\n        self.copy_abs().\n        \"\"\"\n        if not round:\n            return self.copy_abs()\n\n        if self._is_special:\n            ans = self._check_nans(context=context)\n            if ans:\n                return ans\n\n        if self._sign:\n            ans = self.__neg__(context=context)\n        else:\n            ans = self.__pos__(context=context)\n\n        return ans\n\n    def __add__(self, other, context=None):\n        \"\"\"Returns self + other.\n\n        -INF + INF (or the reverse) cause InvalidOperation errors.\n        \"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n\n        if context is None:\n            context = getcontext()\n\n        if self._is_special or other._is_special:\n            ans = self._check_nans(other, context)\n            if ans:\n                return ans\n\n            if self._isinfinity():\n                # If both INF, same sign => same as both, opposite => error.\n                if self._sign != other._sign and other._isinfinity():\n                    return context._raise_error(InvalidOperation, '-INF + INF')\n                return Decimal(self)\n            if other._isinfinity():\n                return Decimal(other)  # Can't both be infinity here\n\n        exp = min(self._exp, other._exp)\n        negativezero = 0\n        if context.rounding == ROUND_FLOOR and self._sign != other._sign:\n            # If the answer is 0, the sign should be negative, in this case.\n            negativezero = 1\n\n        if not self and not other:\n            sign = min(self._sign, other._sign)\n            if negativezero:\n                sign = 1\n            ans = _dec_from_triple(sign, '0', exp)\n            ans = ans._fix(context)\n            return ans\n        if not self:\n            exp = max(exp, other._exp - context.prec-1)\n            ans = other._rescale(exp, context.rounding)\n            ans = ans._fix(context)\n            return ans\n        if not other:\n            exp = max(exp, self._exp - context.prec-1)\n            ans = self._rescale(exp, context.rounding)\n            ans = ans._fix(context)\n            return ans\n\n        op1 = _WorkRep(self)\n        op2 = _WorkRep(other)\n        op1, op2 = _normalize(op1, op2, context.prec)\n\n        result = _WorkRep()\n        if op1.sign != op2.sign:\n            # Equal and opposite\n            if op1.int == op2.int:\n                ans = _dec_from_triple(negativezero, '0', exp)\n                ans = ans._fix(context)\n                return ans\n            if op1.int < op2.int:\n                op1, op2 = op2, op1\n                # OK, now abs(op1) > abs(op2)\n            if op1.sign == 1:\n                result.sign = 1\n                op1.sign, op2.sign = op2.sign, op1.sign\n            else:\n                result.sign = 0\n                # So we know the sign, and op1 > 0.\n        elif op1.sign == 1:\n            result.sign = 1\n            op1.sign, op2.sign = (0, 0)\n        else:\n            result.sign = 0\n        # Now, op1 > abs(op2) > 0\n\n        if op2.sign == 0:\n            result.int = op1.int + op2.int\n        else:\n            result.int = op1.int - op2.int\n\n        result.exp = op1.exp\n        ans = Decimal(result)\n        ans = ans._fix(context)\n        return ans\n\n    __radd__ = __add__\n\n    def __sub__(self, other, context=None):\n        \"\"\"Return self - other\"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n\n        if self._is_special or other._is_special:\n            ans = self._check_nans(other, context=context)\n            if ans:\n                return ans\n\n        # self - other is computed as self + other.copy_negate()\n        return self.__add__(other.copy_negate(), context=context)\n\n    def __rsub__(self, other, context=None):\n        \"\"\"Return other - self\"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n\n        return other.__sub__(self, context=context)\n\n    def __mul__(self, other, context=None):\n        \"\"\"Return self * other.\n\n        (+-) INF * 0 (or its reverse) raise InvalidOperation.\n        \"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n\n        if context is None:\n            context = getcontext()\n\n        resultsign = self._sign ^ other._sign\n\n        if self._is_special or other._is_special:\n            ans = self._check_nans(other, context)\n            if ans:\n                return ans\n\n            if self._isinfinity():\n                if not other:\n                    return context._raise_error(InvalidOperation, '(+-)INF * 0')\n                return _SignedInfinity[resultsign]\n\n            if other._isinfinity():\n                if not self:\n                    return context._raise_error(InvalidOperation, '0 * (+-)INF')\n                return _SignedInfinity[resultsign]\n\n        resultexp = self._exp + other._exp\n\n        # Special case for multiplying by zero\n        if not self or not other:\n            ans = _dec_from_triple(resultsign, '0', resultexp)\n            # Fixing in case the exponent is out of bounds\n            ans = ans._fix(context)\n            return ans\n\n        # Special case for multiplying by power of 10\n        if self._int == '1':\n            ans = _dec_from_triple(resultsign, other._int, resultexp)\n            ans = ans._fix(context)\n            return ans\n        if other._int == '1':\n            ans = _dec_from_triple(resultsign, self._int, resultexp)\n            ans = ans._fix(context)\n            return ans\n\n        op1 = _WorkRep(self)\n        op2 = _WorkRep(other)\n\n        ans = _dec_from_triple(resultsign, str(op1.int * op2.int), resultexp)\n        ans = ans._fix(context)\n\n        return ans\n    __rmul__ = __mul__\n\n    def __truediv__(self, other, context=None):\n        \"\"\"Return self / other.\"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return NotImplemented\n\n        if context is None:\n            context = getcontext()\n\n        sign = self._sign ^ other._sign\n\n        if self._is_special or other._is_special:\n            ans = self._check_nans(other, context)\n            if ans:\n                return ans\n\n            if self._isinfinity() and other._isinfinity():\n                return context._raise_error(InvalidOperation, '(+-)INF/(+-)INF')\n\n            if self._isinfinity():\n                return _SignedInfinity[sign]\n\n            if other._isinfinity():\n                context._raise_error(Clamped, 'Division by infinity')\n                return _dec_from_triple(sign, '0', context.Etiny())\n\n        # Special cases for zeroes\n        if not other:\n            if not self:\n                return context._raise_error(DivisionUndefined, '0 / 0')\n            return context._raise_error(DivisionByZero, 'x / 0', sign)\n\n        if not self:\n            exp = self._exp - other._exp\n            coeff = 0\n        else:\n            # OK, so neither = 0, INF or NaN\n            shift = len(other._int) - len(self._int) + context.prec + 1\n            exp = self._exp - other._exp - shift\n            op1 = _WorkRep(self)\n            op2 = _WorkRep(other)\n            if shift >= 0:\n                coeff, remainder = divmod(op1.int * 10**shift, op2.int)\n            else:\n                coeff, remainder = divmod(op1.int, op2.int * 10**-shift)\n            if remainder:\n                # result is not exact; adjust to ensure correct rounding\n                if coeff % 5 == 0:\n                    coeff += 1\n            else:\n                # result is exact; get as close to ideal exponent as possible\n                ideal_exp = self._exp - other._exp\n                while exp < ideal_exp and coeff % 10 == 0:\n                    coeff //= 10\n                    exp += 1\n\n        ans = _dec_from_triple(sign, str(coeff), exp)\n        return ans._fix(context)\n\n    def _divide(self, other, context):\n        \"\"\"Return (self // other, self % other), to context.prec precision.\n\n        Assumes that neither self nor other is a NaN, that self is not\n        infinite and that other is nonzero.\n        \"\"\"\n        sign = self._sign ^ other._sign\n        if other._isinfinity():\n            ideal_exp = self._exp\n        else:\n            ideal_exp = min(self._exp, other._exp)\n\n        expdiff = self.adjusted() - other.adjusted()\n        if not self or other._isinfinity() or expdiff <= -2:\n            return (_dec_from_triple(sign, '0', 0),\n                    self._rescale(ideal_exp, context.rounding))\n        if expdiff <= context.prec:\n            op1 = _WorkRep(self)\n            op2 = _WorkRep(other)\n            if op1.exp >= op2.exp:\n                op1.int *= 10**(op1.exp - op2.exp)\n            else:\n                op2.int *= 10**(op2.exp - op1.exp)\n            q, r = divmod(op1.int, op2.int)\n            if q < 10**context.prec:\n                return (_dec_from_triple(sign, str(q), 0),\n                        _dec_from_triple(self._sign, str(r), ideal_exp))\n\n        # Here the quotient is too large to be representable\n        ans = context._raise_error(DivisionImpossible,\n                                   'quotient too large in //, % or divmod')\n        return ans, ans\n\n    def __rtruediv__(self, other, context=None):\n        \"\"\"Swaps self/other and returns __truediv__.\"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n        return other.__truediv__(self, context=context)\n\n    def __divmod__(self, other, context=None):\n        \"\"\"\n        Return (self // other, self % other)\n        \"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n\n        if context is None:\n            context = getcontext()\n\n        ans = self._check_nans(other, context)\n        if ans:\n            return (ans, ans)\n\n        sign = self._sign ^ other._sign\n        if self._isinfinity():\n            if other._isinfinity():\n                ans = context._raise_error(InvalidOperation, 'divmod(INF, INF)')\n                return ans, ans\n            else:\n                return (_SignedInfinity[sign],\n                        context._raise_error(InvalidOperation, 'INF % x'))\n\n        if not other:\n            if not self:\n                ans = context._raise_error(DivisionUndefined, 'divmod(0, 0)')\n                return ans, ans\n            else:\n                return (context._raise_error(DivisionByZero, 'x // 0', sign),\n                        context._raise_error(InvalidOperation, 'x % 0'))\n\n        quotient, remainder = self._divide(other, context)\n        remainder = remainder._fix(context)\n        return quotient, remainder\n\n    def __rdivmod__(self, other, context=None):\n        \"\"\"Swaps self/other and returns __divmod__.\"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n        return other.__divmod__(self, context=context)\n\n    def __mod__(self, other, context=None):\n        \"\"\"\n        self % other\n        \"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n\n        if context is None:\n            context = getcontext()\n\n        ans = self._check_nans(other, context)\n        if ans:\n            return ans\n\n        if self._isinfinity():\n            return context._raise_error(InvalidOperation, 'INF % x')\n        elif not other:\n            if self:\n                return context._raise_error(InvalidOperation, 'x % 0')\n            else:\n                return context._raise_error(DivisionUndefined, '0 % 0')\n\n        remainder = self._divide(other, context)[1]\n        remainder = remainder._fix(context)\n        return remainder\n\n    def __rmod__(self, other, context=None):\n        \"\"\"Swaps self/other and returns __mod__.\"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n        return other.__mod__(self, context=context)\n\n    def remainder_near(self, other, context=None):\n        \"\"\"\n        Remainder nearest to 0-  abs(remainder-near) <= other/2\n        \"\"\"\n        if context is None:\n            context = getcontext()\n\n        other = _convert_other(other, raiseit=True)\n\n        ans = self._check_nans(other, context)\n        if ans:\n            return ans\n\n        # self == +/-infinity -> InvalidOperation\n        if self._isinfinity():\n            return context._raise_error(InvalidOperation,\n                                        'remainder_near(infinity, x)')\n\n        # other == 0 -> either InvalidOperation or DivisionUndefined\n        if not other:\n            if self:\n                return context._raise_error(InvalidOperation,\n                                            'remainder_near(x, 0)')\n            else:\n                return context._raise_error(DivisionUndefined,\n                                            'remainder_near(0, 0)')\n\n        # other = +/-infinity -> remainder = self\n        if other._isinfinity():\n            ans = Decimal(self)\n            return ans._fix(context)\n\n        # self = 0 -> remainder = self, with ideal exponent\n        ideal_exponent = min(self._exp, other._exp)\n        if not self:\n            ans = _dec_from_triple(self._sign, '0', ideal_exponent)\n            return ans._fix(context)\n\n        # catch most cases of large or small quotient\n        expdiff = self.adjusted() - other.adjusted()\n        if expdiff >= context.prec + 1:\n            # expdiff >= prec+1 => abs(self/other) > 10**prec\n            return context._raise_error(DivisionImpossible)\n        if expdiff <= -2:\n            # expdiff <= -2 => abs(self/other) < 0.1\n            ans = self._rescale(ideal_exponent, context.rounding)\n            return ans._fix(context)\n\n        # adjust both arguments to have the same exponent, then divide\n        op1 = _WorkRep(self)\n        op2 = _WorkRep(other)\n        if op1.exp >= op2.exp:\n            op1.int *= 10**(op1.exp - op2.exp)\n        else:\n            op2.int *= 10**(op2.exp - op1.exp)\n        q, r = divmod(op1.int, op2.int)\n        # remainder is r*10**ideal_exponent; other is +/-op2.int *\n        # 10**ideal_exponent.   Apply correction to ensure that\n        # abs(remainder) <= abs(other)/2\n        if 2*r + (q&1) > op2.int:\n            r -= op2.int\n            q += 1\n\n        if q >= 10**context.prec:\n            return context._raise_error(DivisionImpossible)\n\n        # result has same sign as self unless r is negative\n        sign = self._sign\n        if r < 0:\n            sign = 1-sign\n            r = -r\n\n        ans = _dec_from_triple(sign, str(r), ideal_exponent)\n        return ans._fix(context)\n\n    def __floordiv__(self, other, context=None):\n        \"\"\"self // other\"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n\n        if context is None:\n            context = getcontext()\n\n        ans = self._check_nans(other, context)\n        if ans:\n            return ans\n\n        if self._isinfinity():\n            if other._isinfinity():\n                return context._raise_error(InvalidOperation, 'INF // INF')\n            else:\n                return _SignedInfinity[self._sign ^ other._sign]\n\n        if not other:\n            if self:\n                return context._raise_error(DivisionByZero, 'x // 0',\n                                            self._sign ^ other._sign)\n            else:\n                return context._raise_error(DivisionUndefined, '0 // 0')\n\n        return self._divide(other, context)[0]\n\n    def __rfloordiv__(self, other, context=None):\n        \"\"\"Swaps self/other and returns __floordiv__.\"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n        return other.__floordiv__(self, context=context)\n\n    def __float__(self):\n        \"\"\"Float representation.\"\"\"\n        if self._isnan():\n            if self.is_snan():\n                raise ValueError(\"Cannot convert signaling NaN to float\")\n            s = \"-nan\" if self._sign else \"nan\"\n        else:\n            s = str(self)\n        return float(s)\n\n    def __int__(self):\n        \"\"\"Converts self to an int, truncating if necessary.\"\"\"\n        if self._is_special:\n            if self._isnan():\n                raise ValueError(\"Cannot convert NaN to integer\")\n            elif self._isinfinity():\n                raise OverflowError(\"Cannot convert infinity to integer\")\n        s = (-1)**self._sign\n        if self._exp >= 0:\n            return s*int(self._int)*10**self._exp\n        else:\n            return s*int(self._int[:self._exp] or '0')\n\n    __trunc__ = __int__\n\n    def real(self):\n        return self\n    real = property(real)\n\n    def imag(self):\n        return Decimal(0)\n    imag = property(imag)\n\n    def conjugate(self):\n        return self\n\n    def __complex__(self):\n        return complex(float(self))\n\n    def _fix_nan(self, context):\n        \"\"\"Decapitate the payload of a NaN to fit the context\"\"\"\n        payload = self._int\n\n        # maximum length of payload is precision if clamp=0,\n        # precision-1 if clamp=1.\n        max_payload_len = context.prec - context.clamp\n        if len(payload) > max_payload_len:\n            payload = payload[len(payload)-max_payload_len:].lstrip('0')\n            return _dec_from_triple(self._sign, payload, self._exp, True)\n        return Decimal(self)\n\n    def _fix(self, context):\n        \"\"\"Round if it is necessary to keep self within prec precision.\n\n        Rounds and fixes the exponent.  Does not raise on a sNaN.\n\n        Arguments:\n        self - Decimal instance\n        context - context used.\n        \"\"\"\n\n        if self._is_special:\n            if self._isnan():\n                # decapitate payload if necessary\n                return self._fix_nan(context)\n            else:\n                # self is +/-Infinity; return unaltered\n                return Decimal(self)\n\n        # if self is zero then exponent should be between Etiny and\n        # Emax if clamp==0, and between Etiny and Etop if clamp==1.\n        Etiny = context.Etiny()\n        Etop = context.Etop()\n        if not self:\n            exp_max = [context.Emax, Etop][context.clamp]\n            new_exp = min(max(self._exp, Etiny), exp_max)\n            if new_exp != self._exp:\n                context._raise_error(Clamped)\n                return _dec_from_triple(self._sign, '0', new_exp)\n            else:\n                return Decimal(self)\n\n        # exp_min is the smallest allowable exponent of the result,\n        # equal to max(self.adjusted()-context.prec+1, Etiny)\n        exp_min = len(self._int) + self._exp - context.prec\n        if exp_min > Etop:\n            # overflow: exp_min > Etop iff self.adjusted() > Emax\n            ans = context._raise_error(Overflow, 'above Emax', self._sign)\n            context._raise_error(Inexact)\n            context._raise_error(Rounded)\n            return ans\n\n        self_is_subnormal = exp_min < Etiny\n        if self_is_subnormal:\n            exp_min = Etiny\n\n        # round if self has too many digits\n        if self._exp < exp_min:\n            digits = len(self._int) + self._exp - exp_min\n            if digits < 0:\n                self = _dec_from_triple(self._sign, '1', exp_min-1)\n                digits = 0\n            rounding_method = self._pick_rounding_function[context.rounding]\n            changed = rounding_method(self, digits)\n            coeff = self._int[:digits] or '0'\n            if changed > 0:\n                coeff = str(int(coeff)+1)\n                if len(coeff) > context.prec:\n                    coeff = coeff[:-1]\n                    exp_min += 1\n\n            # check whether the rounding pushed the exponent out of range\n            if exp_min > Etop:\n                ans = context._raise_error(Overflow, 'above Emax', self._sign)\n            else:\n                ans = _dec_from_triple(self._sign, coeff, exp_min)\n\n            # raise the appropriate signals, taking care to respect\n            # the precedence described in the specification\n            if changed and self_is_subnormal:\n                context._raise_error(Underflow)\n            if self_is_subnormal:\n                context._raise_error(Subnormal)\n            if changed:\n                context._raise_error(Inexact)\n            context._raise_error(Rounded)\n            if not ans:\n                # raise Clamped on underflow to 0\n                context._raise_error(Clamped)\n            return ans\n\n        if self_is_subnormal:\n            context._raise_error(Subnormal)\n\n        # fold down if clamp == 1 and self has too few digits\n        if context.clamp == 1 and self._exp > Etop:\n            context._raise_error(Clamped)\n            self_padded = self._int + '0'*(self._exp - Etop)\n            return _dec_from_triple(self._sign, self_padded, Etop)\n\n        # here self was representable to begin with; return unchanged\n        return Decimal(self)\n\n    # for each of the rounding functions below:\n    #   self is a finite, nonzero Decimal\n    #   prec is an integer satisfying 0 <= prec < len(self._int)\n    #\n    # each function returns either -1, 0, or 1, as follows:\n    #   1 indicates that self should be rounded up (away from zero)\n    #   0 indicates that self should be truncated, and that all the\n    #     digits to be truncated are zeros (so the value is unchanged)\n    #  -1 indicates that there are nonzero digits to be truncated\n\n    def _round_down(self, prec):\n        \"\"\"Also known as round-towards-0, truncate.\"\"\"\n        if _all_zeros(self._int, prec):\n            return 0\n        else:\n            return -1\n\n    def _round_up(self, prec):\n        \"\"\"Rounds away from 0.\"\"\"\n        return -self._round_down(prec)\n\n    def _round_half_up(self, prec):\n        \"\"\"Rounds 5 up (away from 0)\"\"\"\n        if self._int[prec] in '56789':\n            return 1\n        elif _all_zeros(self._int, prec):\n            return 0\n        else:\n            return -1\n\n    def _round_half_down(self, prec):\n        \"\"\"Round 5 down\"\"\"\n        if _exact_half(self._int, prec):\n            return -1\n        else:\n            return self._round_half_up(prec)\n\n    def _round_half_even(self, prec):\n        \"\"\"Round 5 to even, rest to nearest.\"\"\"\n        if _exact_half(self._int, prec) and \\\n                (prec == 0 or self._int[prec-1] in '02468'):\n            return -1\n        else:\n            return self._round_half_up(prec)\n\n    def _round_ceiling(self, prec):\n        \"\"\"Rounds up (not away from 0 if negative.)\"\"\"\n        if self._sign:\n            return self._round_down(prec)\n        else:\n            return -self._round_down(prec)\n\n    def _round_floor(self, prec):\n        \"\"\"Rounds down (not towards 0 if negative)\"\"\"\n        if not self._sign:\n            return self._round_down(prec)\n        else:\n            return -self._round_down(prec)\n\n    def _round_05up(self, prec):\n        \"\"\"Round down unless digit prec-1 is 0 or 5.\"\"\"\n        if prec and self._int[prec-1] not in '05':\n            return self._round_down(prec)\n        else:\n            return -self._round_down(prec)\n\n    _pick_rounding_function = dict(\n        ROUND_DOWN = _round_down,\n        ROUND_UP = _round_up,\n        ROUND_HALF_UP = _round_half_up,\n        ROUND_HALF_DOWN = _round_half_down,\n        ROUND_HALF_EVEN = _round_half_even,\n        ROUND_CEILING = _round_ceiling,\n        ROUND_FLOOR = _round_floor,\n        ROUND_05UP = _round_05up,\n    )\n\n    def __round__(self, n=None):\n        \"\"\"Round self to the nearest integer, or to a given precision.\n\n        If only one argument is supplied, round a finite Decimal\n        instance self to the nearest integer.  If self is infinite or\n        a NaN then a Python exception is raised.  If self is finite\n        and lies exactly halfway between two integers then it is\n        rounded to the integer with even last digit.\n\n        >>> round(Decimal('123.456'))\n        123\n        >>> round(Decimal('-456.789'))\n        -457\n        >>> round(Decimal('-3.0'))\n        -3\n        >>> round(Decimal('2.5'))\n        2\n        >>> round(Decimal('3.5'))\n        4\n        >>> round(Decimal('Inf'))\n        Traceback (most recent call last):\n          ...\n        OverflowError: cannot round an infinity\n        >>> round(Decimal('NaN'))\n        Traceback (most recent call last):\n          ...\n        ValueError: cannot round a NaN\n\n        If a second argument n is supplied, self is rounded to n\n        decimal places using the rounding mode for the current\n        context.\n\n        For an integer n, round(self, -n) is exactly equivalent to\n        self.quantize(Decimal('1En')).\n\n        >>> round(Decimal('123.456'), 0)\n        Decimal('123')\n        >>> round(Decimal('123.456'), 2)\n        Decimal('123.46')\n        >>> round(Decimal('123.456'), -2)\n        Decimal('1E+2')\n        >>> round(Decimal('-Infinity'), 37)\n        Decimal('NaN')\n        >>> round(Decimal('sNaN123'), 0)\n        Decimal('NaN123')\n\n        \"\"\"\n        if n is not None:\n            # two-argument form: use the equivalent quantize call\n            if not isinstance(n, int):\n                raise TypeError('Second argument to round should be integral')\n            exp = _dec_from_triple(0, '1', -n)\n            return self.quantize(exp)\n\n        # one-argument form\n        if self._is_special:\n            if self.is_nan():\n                raise ValueError(\"cannot round a NaN\")\n            else:\n                raise OverflowError(\"cannot round an infinity\")\n        return int(self._rescale(0, ROUND_HALF_EVEN))\n\n    def __floor__(self):\n        \"\"\"Return the floor of self, as an integer.\n\n        For a finite Decimal instance self, return the greatest\n        integer n such that n <= self.  If self is infinite or a NaN\n        then a Python exception is raised.\n\n        \"\"\"\n        if self._is_special:\n            if self.is_nan():\n                raise ValueError(\"cannot round a NaN\")\n            else:\n                raise OverflowError(\"cannot round an infinity\")\n        return int(self._rescale(0, ROUND_FLOOR))\n\n    def __ceil__(self):\n        \"\"\"Return the ceiling of self, as an integer.\n\n        For a finite Decimal instance self, return the least integer n\n        such that n >= self.  If self is infinite or a NaN then a\n        Python exception is raised.\n\n        \"\"\"\n        if self._is_special:\n            if self.is_nan():\n                raise ValueError(\"cannot round a NaN\")\n            else:\n                raise OverflowError(\"cannot round an infinity\")\n        return int(self._rescale(0, ROUND_CEILING))\n\n    def fma(self, other, third, context=None):\n        \"\"\"Fused multiply-add.\n\n        Returns self*other+third with no rounding of the intermediate\n        product self*other.\n\n        self and other are multiplied together, with no rounding of\n        the result.  The third operand is then added to the result,\n        and a single final rounding is performed.\n        \"\"\"\n\n        other = _convert_other(other, raiseit=True)\n        third = _convert_other(third, raiseit=True)\n\n        # compute product; raise InvalidOperation if either operand is\n        # a signaling NaN or if the product is zero times infinity.\n        if self._is_special or other._is_special:\n            if context is None:\n                context = getcontext()\n            if self._exp == 'N':\n                return context._raise_error(InvalidOperation, 'sNaN', self)\n            if other._exp == 'N':\n                return context._raise_error(InvalidOperation, 'sNaN', other)\n            if self._exp == 'n':\n                product = self\n            elif other._exp == 'n':\n                product = other\n            elif self._exp == 'F':\n                if not other:\n                    return context._raise_error(InvalidOperation,\n                                                'INF * 0 in fma')\n                product = _SignedInfinity[self._sign ^ other._sign]\n            elif other._exp == 'F':\n                if not self:\n                    return context._raise_error(InvalidOperation,\n                                                '0 * INF in fma')\n                product = _SignedInfinity[self._sign ^ other._sign]\n        else:\n            product = _dec_from_triple(self._sign ^ other._sign,\n                                       str(int(self._int) * int(other._int)),\n                                       self._exp + other._exp)\n\n        return product.__add__(third, context)\n\n    def _power_modulo(self, other, modulo, context=None):\n        \"\"\"Three argument version of __pow__\"\"\"\n\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n        modulo = _convert_other(modulo)\n        if modulo is NotImplemented:\n            return modulo\n\n        if context is None:\n            context = getcontext()\n\n        # deal with NaNs: if there are any sNaNs then first one wins,\n        # (i.e. behaviour for NaNs is identical to that of fma)\n        self_is_nan = self._isnan()\n        other_is_nan = other._isnan()\n        modulo_is_nan = modulo._isnan()\n        if self_is_nan or other_is_nan or modulo_is_nan:\n            if self_is_nan == 2:\n                return context._raise_error(InvalidOperation, 'sNaN',\n                                        self)\n            if other_is_nan == 2:\n                return context._raise_error(InvalidOperation, 'sNaN',\n                                        other)\n            if modulo_is_nan == 2:\n                return context._raise_error(InvalidOperation, 'sNaN',\n                                        modulo)\n            if self_is_nan:\n                return self._fix_nan(context)\n            if other_is_nan:\n                return other._fix_nan(context)\n            return modulo._fix_nan(context)\n\n        # check inputs: we apply same restrictions as Python's pow()\n        if not (self._isinteger() and\n                other._isinteger() and\n                modulo._isinteger()):\n            return context._raise_error(InvalidOperation,\n                                        'pow() 3rd argument not allowed '\n                                        'unless all arguments are integers')\n        if other < 0:\n            return context._raise_error(InvalidOperation,\n                                        'pow() 2nd argument cannot be '\n                                        'negative when 3rd argument specified')\n        if not modulo:\n            return context._raise_error(InvalidOperation,\n                                        'pow() 3rd argument cannot be 0')\n\n        # additional restriction for decimal: the modulus must be less\n        # than 10**prec in absolute value\n        if modulo.adjusted() >= context.prec:\n            return context._raise_error(InvalidOperation,\n                                        'insufficient precision: pow() 3rd '\n                                        'argument must not have more than '\n                                        'precision digits')\n\n        # define 0**0 == NaN, for consistency with two-argument pow\n        # (even though it hurts!)\n        if not other and not self:\n            return context._raise_error(InvalidOperation,\n                                        'at least one of pow() 1st argument '\n                                        'and 2nd argument must be nonzero ;'\n                                        '0**0 is not defined')\n\n        # compute sign of result\n        if other._iseven():\n            sign = 0\n        else:\n            sign = self._sign\n\n        # convert modulo to a Python integer, and self and other to\n        # Decimal integers (i.e. force their exponents to be >= 0)\n        modulo = abs(int(modulo))\n        base = _WorkRep(self.to_integral_value())\n        exponent = _WorkRep(other.to_integral_value())\n\n        # compute result using integer pow()\n        base = (base.int % modulo * pow(10, base.exp, modulo)) % modulo\n        for i in range(exponent.exp):\n            base = pow(base, 10, modulo)\n        base = pow(base, exponent.int, modulo)\n\n        return _dec_from_triple(sign, str(base), 0)\n\n    def _power_exact(self, other, p):\n        \"\"\"Attempt to compute self**other exactly.\n\n        Given Decimals self and other and an integer p, attempt to\n        compute an exact result for the power self**other, with p\n        digits of precision.  Return None if self**other is not\n        exactly representable in p digits.\n\n        Assumes that elimination of special cases has already been\n        performed: self and other must both be nonspecial; self must\n        be positive and not numerically equal to 1; other must be\n        nonzero.  For efficiency, other._exp should not be too large,\n        so that 10**abs(other._exp) is a feasible calculation.\"\"\"\n\n        # In the comments below, we write x for the value of self and y for the\n        # value of other.  Write x = xc*10**xe and abs(y) = yc*10**ye, with xc\n        # and yc positive integers not divisible by 10.\n\n        # The main purpose of this method is to identify the *failure*\n        # of x**y to be exactly representable with as little effort as\n        # possible.  So we look for cheap and easy tests that\n        # eliminate the possibility of x**y being exact.  Only if all\n        # these tests are passed do we go on to actually compute x**y.\n\n        # Here's the main idea.  Express y as a rational number m/n, with m and\n        # n relatively prime and n>0.  Then for x**y to be exactly\n        # representable (at *any* precision), xc must be the nth power of a\n        # positive integer and xe must be divisible by n.  If y is negative\n        # then additionally xc must be a power of either 2 or 5, hence a power\n        # of 2**n or 5**n.\n        #\n        # There's a limit to how small |y| can be: if y=m/n as above\n        # then:\n        #\n        #  (1) if xc != 1 then for the result to be representable we\n        #      need xc**(1/n) >= 2, and hence also xc**|y| >= 2.  So\n        #      if |y| <= 1/nbits(xc) then xc < 2**nbits(xc) <=\n        #      2**(1/|y|), hence xc**|y| < 2 and the result is not\n        #      representable.\n        #\n        #  (2) if xe != 0, |xe|*(1/n) >= 1, so |xe|*|y| >= 1.  Hence if\n        #      |y| < 1/|xe| then the result is not representable.\n        #\n        # Note that since x is not equal to 1, at least one of (1) and\n        # (2) must apply.  Now |y| < 1/nbits(xc) iff |yc|*nbits(xc) <\n        # 10**-ye iff len(str(|yc|*nbits(xc)) <= -ye.\n        #\n        # There's also a limit to how large y can be, at least if it's\n        # positive: the normalized result will have coefficient xc**y,\n        # so if it's representable then xc**y < 10**p, and y <\n        # p/log10(xc).  Hence if y*log10(xc) >= p then the result is\n        # not exactly representable.\n\n        # if len(str(abs(yc*xe)) <= -ye then abs(yc*xe) < 10**-ye,\n        # so |y| < 1/xe and the result is not representable.\n        # Similarly, len(str(abs(yc)*xc_bits)) <= -ye implies |y|\n        # < 1/nbits(xc).\n\n        x = _WorkRep(self)\n        xc, xe = x.int, x.exp\n        while xc % 10 == 0:\n            xc //= 10\n            xe += 1\n\n        y = _WorkRep(other)\n        yc, ye = y.int, y.exp\n        while yc % 10 == 0:\n            yc //= 10\n            ye += 1\n\n        # case where xc == 1: result is 10**(xe*y), with xe*y\n        # required to be an integer\n        if xc == 1:\n            xe *= yc\n            # result is now 10**(xe * 10**ye);  xe * 10**ye must be integral\n            while xe % 10 == 0:\n                xe //= 10\n                ye += 1\n            if ye < 0:\n                return None\n            exponent = xe * 10**ye\n            if y.sign == 1:\n                exponent = -exponent\n            # if other is a nonnegative integer, use ideal exponent\n            if other._isinteger() and other._sign == 0:\n                ideal_exponent = self._exp*int(other)\n                zeros = min(exponent-ideal_exponent, p-1)\n            else:\n                zeros = 0\n            return _dec_from_triple(0, '1' + '0'*zeros, exponent-zeros)\n\n        # case where y is negative: xc must be either a power\n        # of 2 or a power of 5.\n        if y.sign == 1:\n            last_digit = xc % 10\n            if last_digit in (2,4,6,8):\n                # quick test for power of 2\n                if xc & -xc != xc:\n                    return None\n                # now xc is a power of 2; e is its exponent\n                e = _nbits(xc)-1\n\n                # We now have:\n                #\n                #   x = 2**e * 10**xe, e > 0, and y < 0.\n                #\n                # The exact result is:\n                #\n                #   x**y = 5**(-e*y) * 10**(e*y + xe*y)\n                #\n                # provided that both e*y and xe*y are integers.  Note that if\n                # 5**(-e*y) >= 10**p, then the result can't be expressed\n                # exactly with p digits of precision.\n                #\n                # Using the above, we can guard against large values of ye.\n                # 93/65 is an upper bound for log(10)/log(5), so if\n                #\n                #   ye >= len(str(93*p//65))\n                #\n                # then\n                #\n                #   -e*y >= -y >= 10**ye > 93*p/65 > p*log(10)/log(5),\n                #\n                # so 5**(-e*y) >= 10**p, and the coefficient of the result\n                # can't be expressed in p digits.\n\n                # emax >= largest e such that 5**e < 10**p.\n                emax = p*93//65\n                if ye >= len(str(emax)):\n                    return None\n\n                # Find -e*y and -xe*y; both must be integers\n                e = _decimal_lshift_exact(e * yc, ye)\n                xe = _decimal_lshift_exact(xe * yc, ye)\n                if e is None or xe is None:\n                    return None\n\n                if e > emax:\n                    return None\n                xc = 5**e\n\n            elif last_digit == 5:\n                # e >= log_5(xc) if xc is a power of 5; we have\n                # equality all the way up to xc=5**2658\n                e = _nbits(xc)*28//65\n                xc, remainder = divmod(5**e, xc)\n                if remainder:\n                    return None\n                while xc % 5 == 0:\n                    xc //= 5\n                    e -= 1\n\n                # Guard against large values of ye, using the same logic as in\n                # the 'xc is a power of 2' branch.  10/3 is an upper bound for\n                # log(10)/log(2).\n                emax = p*10//3\n                if ye >= len(str(emax)):\n                    return None\n\n                e = _decimal_lshift_exact(e * yc, ye)\n                xe = _decimal_lshift_exact(xe * yc, ye)\n                if e is None or xe is None:\n                    return None\n\n                if e > emax:\n                    return None\n                xc = 2**e\n            else:\n                return None\n\n            if xc >= 10**p:\n                return None\n            xe = -e-xe\n            return _dec_from_triple(0, str(xc), xe)\n\n        # now y is positive; find m and n such that y = m/n\n        if ye >= 0:\n            m, n = yc*10**ye, 1\n        else:\n            if xe != 0 and len(str(abs(yc*xe))) <= -ye:\n                return None\n            xc_bits = _nbits(xc)\n            if xc != 1 and len(str(abs(yc)*xc_bits)) <= -ye:\n                return None\n            m, n = yc, 10**(-ye)\n            while m % 2 == n % 2 == 0:\n                m //= 2\n                n //= 2\n            while m % 5 == n % 5 == 0:\n                m //= 5\n                n //= 5\n\n        # compute nth root of xc*10**xe\n        if n > 1:\n            # if 1 < xc < 2**n then xc isn't an nth power\n            if xc != 1 and xc_bits <= n:\n                return None\n\n            xe, rem = divmod(xe, n)\n            if rem != 0:\n                return None\n\n            # compute nth root of xc using Newton's method\n            a = 1 << -(-_nbits(xc)//n) # initial estimate\n            while True:\n                q, r = divmod(xc, a**(n-1))\n                if a <= q:\n                    break\n                else:\n                    a = (a*(n-1) + q)//n\n            if not (a == q and r == 0):\n                return None\n            xc = a\n\n        # now xc*10**xe is the nth root of the original xc*10**xe\n        # compute mth power of xc*10**xe\n\n        # if m > p*100//_log10_lb(xc) then m > p/log10(xc), hence xc**m >\n        # 10**p and the result is not representable.\n        if xc > 1 and m > p*100//_log10_lb(xc):\n            return None\n        xc = xc**m\n        xe *= m\n        if xc > 10**p:\n            return None\n\n        # by this point the result *is* exactly representable\n        # adjust the exponent to get as close as possible to the ideal\n        # exponent, if necessary\n        str_xc = str(xc)\n        if other._isinteger() and other._sign == 0:\n            ideal_exponent = self._exp*int(other)\n            zeros = min(xe-ideal_exponent, p-len(str_xc))\n        else:\n            zeros = 0\n        return _dec_from_triple(0, str_xc+'0'*zeros, xe-zeros)\n\n    def __pow__(self, other, modulo=None, context=None):\n        \"\"\"Return self ** other [ % modulo].\n\n        With two arguments, compute self**other.\n\n        With three arguments, compute (self**other) % modulo.  For the\n        three argument form, the following restrictions on the\n        arguments hold:\n\n         - all three arguments must be integral\n         - other must be nonnegative\n         - either self or other (or both) must be nonzero\n         - modulo must be nonzero and must have at most p digits,\n           where p is the context precision.\n\n        If any of these restrictions is violated the InvalidOperation\n        flag is raised.\n\n        The result of pow(self, other, modulo) is identical to the\n        result that would be obtained by computing (self**other) %\n        modulo with unbounded precision, but is computed more\n        efficiently.  It is always exact.\n        \"\"\"\n\n        if modulo is not None:\n            return self._power_modulo(other, modulo, context)\n\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n\n        if context is None:\n            context = getcontext()\n\n        # either argument is a NaN => result is NaN\n        ans = self._check_nans(other, context)\n        if ans:\n            return ans\n\n        # 0**0 = NaN (!), x**0 = 1 for nonzero x (including +/-Infinity)\n        if not other:\n            if not self:\n                return context._raise_error(InvalidOperation, '0 ** 0')\n            else:\n                return _One\n\n        # result has sign 1 iff self._sign is 1 and other is an odd integer\n        result_sign = 0\n        if self._sign == 1:\n            if other._isinteger():\n                if not other._iseven():\n                    result_sign = 1\n            else:\n                # -ve**noninteger = NaN\n                # (-0)**noninteger = 0**noninteger\n                if self:\n                    return context._raise_error(InvalidOperation,\n                        'x ** y with x negative and y not an integer')\n            # negate self, without doing any unwanted rounding\n            self = self.copy_negate()\n\n        # 0**(+ve or Inf)= 0; 0**(-ve or -Inf) = Infinity\n        if not self:\n            if other._sign == 0:\n                return _dec_from_triple(result_sign, '0', 0)\n            else:\n                return _SignedInfinity[result_sign]\n\n        # Inf**(+ve or Inf) = Inf; Inf**(-ve or -Inf) = 0\n        if self._isinfinity():\n            if other._sign == 0:\n                return _SignedInfinity[result_sign]\n            else:\n                return _dec_from_triple(result_sign, '0', 0)\n\n        # 1**other = 1, but the choice of exponent and the flags\n        # depend on the exponent of self, and on whether other is a\n        # positive integer, a negative integer, or neither\n        if self == _One:\n            if other._isinteger():\n                # exp = max(self._exp*max(int(other), 0),\n                # 1-context.prec) but evaluating int(other) directly\n                # is dangerous until we know other is small (other\n                # could be 1e999999999)\n                if other._sign == 1:\n                    multiplier = 0\n                elif other > context.prec:\n                    multiplier = context.prec\n                else:\n                    multiplier = int(other)\n\n                exp = self._exp * multiplier\n                if exp < 1-context.prec:\n                    exp = 1-context.prec\n                    context._raise_error(Rounded)\n            else:\n                context._raise_error(Inexact)\n                context._raise_error(Rounded)\n                exp = 1-context.prec\n\n            return _dec_from_triple(result_sign, '1'+'0'*-exp, exp)\n\n        # compute adjusted exponent of self\n        self_adj = self.adjusted()\n\n        # self ** infinity is infinity if self > 1, 0 if self < 1\n        # self ** -infinity is infinity if self < 1, 0 if self > 1\n        if other._isinfinity():\n            if (other._sign == 0) == (self_adj < 0):\n                return _dec_from_triple(result_sign, '0', 0)\n            else:\n                return _SignedInfinity[result_sign]\n\n        # from here on, the result always goes through the call\n        # to _fix at the end of this function.\n        ans = None\n        exact = False\n\n        # crude test to catch cases of extreme overflow/underflow.  If\n        # log10(self)*other >= 10**bound and bound >= len(str(Emax))\n        # then 10**bound >= 10**len(str(Emax)) >= Emax+1 and hence\n        # self**other >= 10**(Emax+1), so overflow occurs.  The test\n        # for underflow is similar.\n        bound = self._log10_exp_bound() + other.adjusted()\n        if (self_adj >= 0) == (other._sign == 0):\n            # self > 1 and other +ve, or self < 1 and other -ve\n            # possibility of overflow\n            if bound >= len(str(context.Emax)):\n                ans = _dec_from_triple(result_sign, '1', context.Emax+1)\n        else:\n            # self > 1 and other -ve, or self < 1 and other +ve\n            # possibility of underflow to 0\n            Etiny = context.Etiny()\n            if bound >= len(str(-Etiny)):\n                ans = _dec_from_triple(result_sign, '1', Etiny-1)\n\n        # try for an exact result with precision +1\n        if ans is None:\n            ans = self._power_exact(other, context.prec + 1)\n            if ans is not None:\n                if result_sign == 1:\n                    ans = _dec_from_triple(1, ans._int, ans._exp)\n                exact = True\n\n        # usual case: inexact result, x**y computed directly as exp(y*log(x))\n        if ans is None:\n            p = context.prec\n            x = _WorkRep(self)\n            xc, xe = x.int, x.exp\n            y = _WorkRep(other)\n            yc, ye = y.int, y.exp\n            if y.sign == 1:\n                yc = -yc\n\n            # compute correctly rounded result:  start with precision +3,\n            # then increase precision until result is unambiguously roundable\n            extra = 3\n            while True:\n                coeff, exp = _dpower(xc, xe, yc, ye, p+extra)\n                if coeff % (5*10**(len(str(coeff))-p-1)):\n                    break\n                extra += 3\n\n            ans = _dec_from_triple(result_sign, str(coeff), exp)\n\n        # unlike exp, ln and log10, the power function respects the\n        # rounding mode; no need to switch to ROUND_HALF_EVEN here\n\n        # There's a difficulty here when 'other' is not an integer and\n        # the result is exact.  In this case, the specification\n        # requires that the Inexact flag be raised (in spite of\n        # exactness), but since the result is exact _fix won't do this\n        # for us.  (Correspondingly, the Underflow signal should also\n        # be raised for subnormal results.)  We can't directly raise\n        # these signals either before or after calling _fix, since\n        # that would violate the precedence for signals.  So we wrap\n        # the ._fix call in a temporary context, and reraise\n        # afterwards.\n        if exact and not other._isinteger():\n            # pad with zeros up to length context.prec+1 if necessary; this\n            # ensures that the Rounded signal will be raised.\n            if len(ans._int) <= context.prec:\n                expdiff = context.prec + 1 - len(ans._int)\n                ans = _dec_from_triple(ans._sign, ans._int+'0'*expdiff,\n                                       ans._exp-expdiff)\n\n            # create a copy of the current context, with cleared flags/traps\n            newcontext = context.copy()\n            newcontext.clear_flags()\n            for exception in _signals:\n                newcontext.traps[exception] = 0\n\n            # round in the new context\n            ans = ans._fix(newcontext)\n\n            # raise Inexact, and if necessary, Underflow\n            newcontext._raise_error(Inexact)\n            if newcontext.flags[Subnormal]:\n                newcontext._raise_error(Underflow)\n\n            # propagate signals to the original context; _fix could\n            # have raised any of Overflow, Underflow, Subnormal,\n            # Inexact, Rounded, Clamped.  Overflow needs the correct\n            # arguments.  Note that the order of the exceptions is\n            # important here.\n            if newcontext.flags[Overflow]:\n                context._raise_error(Overflow, 'above Emax', ans._sign)\n            for exception in Underflow, Subnormal, Inexact, Rounded, Clamped:\n                if newcontext.flags[exception]:\n                    context._raise_error(exception)\n\n        else:\n            ans = ans._fix(context)\n\n        return ans\n\n    def __rpow__(self, other, context=None):\n        \"\"\"Swaps self/other and returns __pow__.\"\"\"\n        other = _convert_other(other)\n        if other is NotImplemented:\n            return other\n        return other.__pow__(self, context=context)\n\n    def normalize(self, context=None):\n        \"\"\"Normalize- strip trailing 0s, change anything equal to 0 to 0e0\"\"\"\n\n        if context is None:\n            context = getcontext()\n\n        if self._is_special:\n            ans = self._check_nans(context=context)\n            if ans:\n                return ans\n\n        dup = self._fix(context)\n        if dup._isinfinity():\n            return dup\n\n        if not dup:\n            return _dec_from_triple(dup._sign, '0', 0)\n        exp_max = [context.Emax, context.Etop()][context.clamp]\n        end = len(dup._int)\n        exp = dup._exp\n        while dup._int[end-1] == '0' and exp < exp_max:\n            exp += 1\n            end -= 1\n        return _dec_from_triple(dup._sign, dup._int[:end], exp)\n\n    def quantize(self, exp, rounding=None, context=None, watchexp=True):\n        \"\"\"Quantize self so its exponent is the same as that of exp.\n\n        Similar to self._rescale(exp._exp) but with error checking.\n        \"\"\"\n        exp = _convert_other(exp, raiseit=True)\n\n        if context is None:\n            context = getcontext()\n        if rounding is None:\n            rounding = context.rounding\n\n        if self._is_special or exp._is_special:\n            ans = self._check_nans(exp, context)\n            if ans:\n                return ans\n\n            if exp._isinfinity() or self._isinfinity():\n                if exp._isinfinity() and self._isinfinity():\n                    return Decimal(self)  # if both are inf, it is OK\n                return context._raise_error(InvalidOperation,\n                                        'quantize with one INF')\n\n        # if we're not watching exponents, do a simple rescale\n        if not watchexp:\n            ans = self._rescale(exp._exp, rounding)\n            # raise Inexact and Rounded where appropriate\n            if ans._exp > self._exp:\n                context._raise_error(Rounded)\n                if ans != self:\n                    context._raise_error(Inexact)\n            return ans\n\n        # exp._exp should be between Etiny and Emax\n        if not (context.Etiny() <= exp._exp <= context.Emax):\n            return context._raise_error(InvalidOperation,\n                   'target exponent out of bounds in quantize')\n\n        if not self:\n            ans = _dec_from_triple(self._sign, '0', exp._exp)\n            return ans._fix(context)\n\n        self_adjusted = self.adjusted()\n        if self_adjusted > context.Emax:\n            return context._raise_error(InvalidOperation,\n                                        'exponent of quantize result too large for current context')\n        if self_adjusted - exp._exp + 1 > context.prec:\n            return context._raise_error(InvalidOperation,\n                                        'quantize result has too many digits for current context')\n\n        ans = self._rescale(exp._exp, rounding)\n        if ans.adjusted() > context.Emax:\n            return context._raise_error(InvalidOperation,\n                                        'exponent of quantize result too large for current context')\n        if len(ans._int) > context.prec:\n            return context._raise_error(InvalidOperation,\n                                        'quantize result has too many digits for current context')\n\n        # raise appropriate flags\n        if ans and ans.adjusted() < context.Emin:\n            context._raise_error(Subnormal)\n        if ans._exp > self._exp:\n            if ans != self:\n                context._raise_error(Inexact)\n            context._raise_error(Rounded)\n\n        # call to fix takes care of any necessary folddown, and\n        # signals Clamped if necessary\n        ans = ans._fix(context)\n        return ans\n\n    def same_quantum(self, other, context=None):\n        \"\"\"Return True if self and other have the same exponent; otherwise\n        return False.\n\n        If either operand is a special value, the following rules are used:\n           * return True if both operands are infinities\n           * return True if both operands are NaNs\n           * otherwise, return False.\n        \"\"\"\n        other = _convert_other(other, raiseit=True)\n        if self._is_special or other._is_special:\n            return (self.is_nan() and other.is_nan() or\n                    self.is_infinite() and other.is_infinite())\n        return self._exp == other._exp\n\n    def _rescale(self, exp, rounding):\n        \"\"\"Rescale self so that the exponent is exp, either by padding with zeros\n        or by truncating digits, using the given rounding mode.\n\n        Specials are returned without change.  This operation is\n        quiet: it raises no flags, and uses no information from the\n        context.\n\n        exp = exp to scale to (an integer)\n        rounding = rounding mode\n        \"\"\"\n        if self._is_special:\n            return Decimal(self)\n        if not self:\n            return _dec_from_triple(self._sign, '0', exp)\n\n        if self._exp >= exp:\n            # pad answer with zeros if necessary\n            return _dec_from_triple(self._sign,\n                                        self._int + '0'*(self._exp - exp), exp)\n\n        # too many digits; round and lose data.  If self.adjusted() <\n        # exp-1, replace self by 10**(exp-1) before rounding\n        digits = len(self._int) + self._exp - exp\n        if digits < 0:\n            self = _dec_from_triple(self._sign, '1', exp-1)\n            digits = 0\n        this_function = self._pick_rounding_function[rounding]\n        changed = this_function(self, digits)\n        coeff = self._int[:digits] or '0'\n        if changed == 1:\n            coeff = str(int(coeff)+1)\n        return _dec_from_triple(self._sign, coeff, exp)\n\n    def _round(self, places, rounding):\n        \"\"\"Round a nonzero, nonspecial Decimal to a fixed number of\n        significant figures, using the given rounding mode.\n\n        Infinities, NaNs and zeros are returned unaltered.\n\n        This operation is quiet: it raises no flags, and uses no\n        information from the context.\n\n        \"\"\"\n        if places <= 0:\n            raise ValueError(\"argument should be at least 1 in _round\")\n        if self._is_special or not self:\n            return Decimal(self)\n        ans = self._rescale(self.adjusted()+1-places, rounding)\n        # it can happen that the rescale alters the adjusted exponent;\n        # for example when rounding 99.97 to 3 significant figures.\n        # When this happens we end up with an extra 0 at the end of\n        # the number; a second rescale fixes this.\n        if ans.adjusted() != self.adjusted():\n            ans = ans._rescale(ans.adjusted()+1-places, rounding)\n        return ans\n\n    def to_integral_exact(self, rounding=None, context=None):\n        \"\"\"Rounds to a nearby integer.\n\n        If no rounding mode is specified, take the rounding mode from\n        the context.  This method raises the Rounded and Inexact flags\n        when appropriate.\n\n        See also: to_integral_value, which does exactly the same as\n        this method except that it doesn't raise Inexact or Rounded.\n        \"\"\"\n        if self._is_special:\n            ans = self._check_nans(context=context)\n            if ans:\n                return ans\n            return Decimal(self)\n        if self._exp >= 0:\n            return Decimal(self)\n        if not self:\n            return _dec_from_triple(self._sign, '0', 0)\n        if context is None:\n            context = getcontext()\n        if rounding is None:\n            rounding = context.rounding\n        ans = self._rescale(0, rounding)\n        if ans != self:\n            context._raise_error(Inexact)\n        context._raise_error(Rounded)\n        return ans\n\n    def to_integral_value(self, rounding=None, context=None):\n        \"\"\"Rounds to the nearest integer, without raising inexact, rounded.\"\"\"\n        if context is None:\n            context = getcontext()\n        if rounding is None:\n            rounding = context.rounding\n        if self._is_special:\n            ans = self._check_nans(context=context)\n            if ans:\n                return ans\n            return Decimal(self)\n        if self._exp >= 0:\n            return Decimal(self)\n        else:\n            return self._rescale(0, rounding)\n\n    # the method name changed, but we provide also the old one, for compatibility\n    to_integral = to_integral_value\n\n    def sqrt(self, context=None):\n        \"\"\"Return the square root of self.\"\"\"\n        if context is None:\n            context = getcontext()\n\n        if self._is_special:\n            ans = self._check_nans(context=context)\n            if ans:\n                return ans\n\n            if self._isinfinity() and self._sign == 0:\n                return Decimal(self)\n\n        if not self:\n            # exponent = self._exp // 2.  sqrt(-0) = -0\n            ans = _dec_from_triple(self._sign, '0', self._exp // 2)\n            return ans._fix(context)\n\n        if self._sign == 1:\n            return context._raise_error(InvalidOperation, 'sqrt(-x), x > 0')\n\n        # At this point self represents a positive number.  Let p be\n        # the desired precision and express self in the form c*100**e\n        # with c a positive real number and e an integer, c and e\n        # being chosen so that 100**(p-1) <= c < 100**p.  Then the\n        # (exact) square root of self is sqrt(c)*10**e, and 10**(p-1)\n        # <= sqrt(c) < 10**p, so the closest representable Decimal at\n        # precision p is n*10**e where n = round_half_even(sqrt(c)),\n        # the closest integer to sqrt(c) with the even integer chosen\n        # in the case of a tie.\n        #\n        # To ensure correct rounding in all cases, we use the\n        # following trick: we compute the square root to an extra\n        # place (precision p+1 instead of precision p), rounding down.\n        # Then, if the result is inexact and its last digit is 0 or 5,\n        # we increase the last digit to 1 or 6 respectively; if it's\n        # exact we leave the last digit alone.  Now the final round to\n        # p places (or fewer in the case of underflow) will round\n        # correctly and raise the appropriate flags.\n\n        # use an extra digit of precision\n        prec = context.prec+1\n\n        # write argument in the form c*100**e where e = self._exp//2\n        # is the 'ideal' exponent, to be used if the square root is\n        # exactly representable.  l is the number of 'digits' of c in\n        # base 100, so that 100**(l-1) <= c < 100**l.\n        op = _WorkRep(self)\n        e = op.exp >> 1\n        if op.exp & 1:\n            c = op.int * 10\n            l = (len(self._int) >> 1) + 1\n        else:\n            c = op.int\n            l = len(self._int)+1 >> 1\n\n        # rescale so that c has exactly prec base 100 'digits'\n        shift = prec-l\n        if shift >= 0:\n            c *= 100**shift\n            exact = True\n        else:\n            c, remainder = divmod(c, 100**-shift)\n            exact = not remainder\n        e -= shift\n\n        # find n = floor(sqrt(c)) using Newton's method\n        n = 10**prec\n        while True:\n            q = c//n\n            if n <= q:\n                break\n            else:\n                n = n + q >> 1\n        exact = exact and n*n == c\n\n        if exact:\n            # result is exact; rescale to use ideal exponent e\n            if shift >= 0:\n                # assert n % 10**shift == 0\n                n //= 10**shift\n            else:\n                n *= 10**-shift\n            e += shift\n        else:\n            # result is not exact; fix last digit as described above\n            if n % 5 == 0:\n                n += 1\n\n        ans = _dec_from_triple(0, str(n), e)\n\n        # round, and fit to current context\n        context = context._shallow_copy()\n        rounding = context._set_rounding(ROUND_HALF_EVEN)\n        ans = ans._fix(context)\n        context.rounding = rounding\n\n        return ans\n\n    def max(self, other, context=None):\n        \"\"\"Returns the larger value.\n\n        Like max(self, other) except if one is not a number, returns\n        NaN (and signals if one is sNaN).  Also rounds.\n        \"\"\"\n        other = _convert_other(other, raiseit=True)\n\n        if context is None:\n            context = getcontext()\n\n        if self._is_special or other._is_special:\n            # If one operand is a quiet NaN and the other is number, then the\n            # number is always returned\n            sn = self._isnan()\n            on = other._isnan()\n            if sn or on:\n                if on == 1 and sn == 0:\n                    return self._fix(context)\n                if sn == 1 and on == 0:\n                    return other._fix(context)\n                return self._check_nans(other, context)\n\n        c = self._cmp(other)\n        if c == 0:\n            # If both operands are finite and equal in numerical value\n            # then an ordering is applied:\n            #\n            # If the signs differ then max returns the operand with the\n            # positive sign and min returns the operand with the negative sign\n            #\n            # If the signs are the same then the exponent is used to select\n            # the result.  This is exactly the ordering used in compare_total.\n            c = self.compare_total(other)\n\n        if c == -1:\n            ans = other\n        else:\n            ans = self\n\n        return ans._fix(context)\n\n    def min(self, other, context=None):\n        \"\"\"Returns the smaller value.\n\n        Like min(self, other) except if one is not a number, returns\n        NaN (and signals if one is sNaN).  Also rounds.\n        \"\"\"\n        other = _convert_other(other, raiseit=True)\n\n        if context is None:\n            context = getcontext()\n\n        if self._is_special or other._is_special:\n            # If one operand is a quiet NaN and the other is number, then the\n            # number is always returned\n            sn = self._isnan()\n            on = other._isnan()\n            if sn or on:\n                if on == 1 and sn == 0:\n                    return self._fix(context)\n                if sn == 1 and on == 0:\n                    return other._fix(context)\n                return self._check_nans(other, context)\n\n        c = self._cmp(other)\n        if c == 0:\n            c = self.compare_total(other)\n\n        if c == -1:\n            ans = self\n        else:\n            ans = other\n\n        return ans._fix(context)\n\n    def _isinteger(self):\n        \"\"\"Returns whether self is an integer\"\"\"\n        if self._is_special:\n            return False\n        if self._exp >= 0:\n            return True\n        rest = self._int[self._exp:]\n        return rest == '0'*len(rest)\n\n    def _iseven(self):\n        \"\"\"Returns True if self is even.  Assumes self is an integer.\"\"\"\n        if not self or self._exp > 0:\n            return True\n        return self._int[-1+self._exp] in '02468'\n\n    def adjusted(self):\n        \"\"\"Return the adjusted exponent of self\"\"\"\n        try:\n            return self._exp + len(self._int) - 1\n        # If NaN or Infinity, self._exp is string\n        except TypeError:\n            return 0\n\n    def canonical(self):\n        \"\"\"Returns the same Decimal object.\n\n        As we do not have different encodings for the same number, the\n        received object already is in its canonical form.\n        \"\"\"\n        return self\n\n    def compare_signal(self, other, context=None):\n        \"\"\"Compares self to the other operand numerically.\n\n        It's pretty much like compare(), but all NaNs signal, with signaling\n        NaNs taking precedence over quiet NaNs.\n        \"\"\"\n        other = _convert_other(other, raiseit = True)\n        ans = self._compare_check_nans(other, context)\n        if ans:\n            return ans\n        return self.compare(other, context=context)\n\n    def compare_total(self, other, context=None):\n        \"\"\"Compares self to other using the abstract representations.\n\n        This is not like the standard compare, which use their numerical\n        value. Note that a total ordering is defined for all possible abstract\n        representations.\n        \"\"\"\n        other = _convert_other(other, raiseit=True)\n\n        # if one is negative and the other is positive, it's easy\n        if self._sign and not other._sign:\n            return _NegativeOne\n        if not self._sign and other._sign:\n            return _One\n        sign = self._sign\n\n        # let's handle both NaN types\n        self_nan = self._isnan()\n        other_nan = other._isnan()\n        if self_nan or other_nan:\n            if self_nan == other_nan:\n                # compare payloads as though they're integers\n                self_key = len(self._int), self._int\n                other_key = len(other._int), other._int\n                if self_key < other_key:\n                    if sign:\n                        return _One\n                    else:\n                        return _NegativeOne\n                if self_key > other_key:\n                    if sign:\n                        return _NegativeOne\n                    else:\n                        return _One\n                return _Zero\n\n            if sign:\n                if self_nan == 1:\n                    return _NegativeOne\n                if other_nan == 1:\n                    return _One\n                if self_nan == 2:\n                    return _NegativeOne\n                if other_nan == 2:\n                    return _One\n            else:\n                if self_nan == 1:\n                    return _One\n                if other_nan == 1:\n                    return _NegativeOne\n                if self_nan == 2:\n                    return _One\n                if other_nan == 2:\n                    return _NegativeOne\n\n        if self < other:\n            return _NegativeOne\n        if self > other:\n            return _One\n\n        if self._exp < other._exp:\n            if sign:\n                return _One\n            else:\n                return _NegativeOne\n        if self._exp > other._exp:\n            if sign:\n                return _NegativeOne\n            else:\n                return _One\n        return _Zero\n\n\n    def compare_total_mag(self, other, context=None):\n        \"\"\"Compares self to other using abstract repr., ignoring sign.\n\n        Like compare_total, but with operand's sign ignored and assumed to be 0.\n        \"\"\"\n        other = _convert_other(other, raiseit=True)\n\n        s = self.copy_abs()\n        o = other.copy_abs()\n        return s.compare_total(o)\n\n    def copy_abs(self):\n        \"\"\"Returns a copy with the sign set to 0. \"\"\"\n        return _dec_from_triple(0, self._int, self._exp, self._is_special)\n\n    def copy_negate(self):\n        \"\"\"Returns a copy with the sign inverted.\"\"\"\n        if self._sign:\n            return _dec_from_triple(0, self._int, self._exp, self._is_special)\n        else:\n            return _dec_from_triple(1, self._int, self._exp, self._is_special)\n\n    def copy_sign(self, other, context=None):\n        \"\"\"Returns self with the sign of other.\"\"\"\n        other = _convert_other(other, raiseit=True)\n        return _dec_from_triple(other._sign, self._int,\n                                self._exp, self._is_special)\n\n    def exp(self, context=None):\n        \"\"\"Returns e ** self.\"\"\"\n\n        if context is None:\n            context = getcontext()\n\n        # exp(NaN) = NaN\n        ans = self._check_nans(context=context)\n        if ans:\n            return ans\n\n        # exp(-Infinity) = 0\n        if self._isinfinity() == -1:\n            return _Zero\n\n        # exp(0) = 1\n        if not self:\n            return _One\n\n        # exp(Infinity) = Infinity\n        if self._isinfinity() == 1:\n            return Decimal(self)\n\n        # the result is now guaranteed to be inexact (the true\n        # mathematical result is transcendental). There's no need to\n        # raise Rounded and Inexact here---they'll always be raised as\n        # a result of the call to _fix.\n        p = context.prec\n        adj = self.adjusted()\n\n        # we only need to do any computation for quite a small range\n        # of adjusted exponents---for example, -29 <= adj <= 10 for\n        # the default context.  For smaller exponent the result is\n        # indistinguishable from 1 at the given precision, while for\n        # larger exponent the result either overflows or underflows.\n        if self._sign == 0 and adj > len(str((context.Emax+1)*3)):\n            # overflow\n            ans = _dec_from_triple(0, '1', context.Emax+1)\n        elif self._sign == 1 and adj > len(str((-context.Etiny()+1)*3)):\n            # underflow to 0\n            ans = _dec_from_triple(0, '1', context.Etiny()-1)\n        elif self._sign == 0 and adj < -p:\n            # p+1 digits; final round will raise correct flags\n            ans = _dec_from_triple(0, '1' + '0'*(p-1) + '1', -p)\n        elif self._sign == 1 and adj < -p-1:\n            # p+1 digits; final round will raise correct flags\n            ans = _dec_from_triple(0, '9'*(p+1), -p-1)\n        # general case\n        else:\n            op = _WorkRep(self)\n            c, e = op.int, op.exp\n            if op.sign == 1:\n                c = -c\n\n            # compute correctly rounded result: increase precision by\n            # 3 digits at a time until we get an unambiguously\n            # roundable result\n            extra = 3\n            while True:\n                coeff, exp = _dexp(c, e, p+extra)\n                if coeff % (5*10**(len(str(coeff))-p-1)):\n                    break\n                extra += 3\n\n            ans = _dec_from_triple(0, str(coeff), exp)\n\n        # at this stage, ans should round correctly with *any*\n        # rounding mode, not just with ROUND_HALF_EVEN\n        context = context._shallow_copy()\n        rounding = context._set_rounding(ROUND_HALF_EVEN)\n        ans = ans._fix(context)\n        context.rounding = rounding\n\n        return ans\n\n    def is_canonical(self):\n        \"\"\"Return True if self is canonical; otherwise return False.\n\n        Currently, the encoding of a Decimal instance is always\n        canonical, so this method returns True for any Decimal.\n        \"\"\"\n        return True\n\n    def is_finite(self):\n        \"\"\"Return True if self is finite; otherwise return False.\n\n        A Decimal instance is considered finite if it is neither\n        infinite nor a NaN.\n        \"\"\"\n        return not self._is_special\n\n    def is_infinite(self):\n        \"\"\"Return True if self is infinite; otherwise return False.\"\"\"\n        return self._exp == 'F'\n\n    def is_nan(self):\n        \"\"\"Return True if self is a qNaN or sNaN; otherwise return False.\"\"\"\n        return self._exp in ('n', 'N')\n\n    def is_normal(self, context=None):\n        \"\"\"Return True if self is a normal number; otherwise return False.\"\"\"\n        if self._is_special or not self:\n            return False\n        if context is None:\n            context = getcontext()\n        return context.Emin <= self.adjusted()\n\n    def is_qnan(self):\n        \"\"\"Return True if self is a quiet NaN; otherwise return False.\"\"\"\n        return self._exp == 'n'\n\n    def is_signed(self):\n        \"\"\"Return True if self is negative; otherwise return False.\"\"\"\n        return self._sign == 1\n\n    def is_snan(self):\n        \"\"\"Return True if self is a signaling NaN; otherwise return False.\"\"\"\n        return self._exp == 'N'\n\n    def is_subnormal(self, context=None):\n        \"\"\"Return True if self is subnormal; otherwise return False.\"\"\"\n        if self._is_special or not self:\n            return False\n        if context is None:\n            context = getcontext()\n        return self.adjusted() < context.Emin\n\n    def is_zero(self):\n        \"\"\"Return True if self is a zero; otherwise return False.\"\"\"\n        return not self._is_special and self._int == '0'\n\n    def _ln_exp_bound(self):\n        \"\"\"Compute a lower bound for the adjusted exponent of self.ln().\n        In other words, compute r such that self.ln() >= 10**r.  Assumes\n        that self is finite and positive and that self != 1.\n        \"\"\"\n\n        # for 0.1 <= x <= 10 we use the inequalities 1-1/x <= ln(x) <= x-1\n        adj = self._exp + len(self._int) - 1\n        if adj >= 1:\n            # argument >= 10; we use 23/10 = 2.3 as a lower bound for ln(10)\n            return len(str(adj*23//10)) - 1\n        if adj <= -2:\n            # argument <= 0.1\n            return len(str((-1-adj)*23//10)) - 1\n        op = _WorkRep(self)\n        c, e = op.int, op.exp\n        if adj == 0:\n            # 1 < self < 10\n            num = str(c-10**-e)\n            den = str(c)\n            return len(num) - len(den) - (num < den)\n        # adj == -1, 0.1 <= self < 1\n        return e + len(str(10**-e - c)) - 1\n\n\n    def ln(self, context=None):\n        \"\"\"Returns the natural (base e) logarithm of self.\"\"\"\n\n        if context is None:\n            context = getcontext()\n\n        # ln(NaN) = NaN\n        ans = self._check_nans(context=context)\n        if ans:\n            return ans\n\n        # ln(0.0) == -Infinity\n        if not self:\n            return _NegativeInfinity\n\n        # ln(Infinity) = Infinity\n        if self._isinfinity() == 1:\n            return _Infinity\n\n        # ln(1.0) == 0.0\n        if self == _One:\n            return _Zero\n\n        # ln(negative) raises InvalidOperation\n        if self._sign == 1:\n            return context._raise_error(InvalidOperation,\n                                        'ln of a negative value')\n\n        # result is irrational, so necessarily inexact\n        op = _WorkRep(self)\n        c, e = op.int, op.exp\n        p = context.prec\n\n        # correctly rounded result: repeatedly increase precision by 3\n        # until we get an unambiguously roundable result\n        places = p - self._ln_exp_bound() + 2 # at least p+3 places\n        while True:\n            coeff = _dlog(c, e, places)\n            # assert len(str(abs(coeff)))-p >= 1\n            if coeff % (5*10**(len(str(abs(coeff)))-p-1)):\n                break\n            places += 3\n        ans = _dec_from_triple(int(coeff<0), str(abs(coeff)), -places)\n\n        context = context._shallow_copy()\n        rounding = context._set_rounding(ROUND_HALF_EVEN)\n        ans = ans._fix(context)\n        context.rounding = rounding\n        return ans\n\n    def _log10_exp_bound(self):\n        \"\"\"Compute a lower bound for the adjusted exponent of self.log10().\n        In other words, find r such that self.log10() >= 10**r.\n        Assumes that self is finite and positive and that self != 1.\n        \"\"\"\n\n        # For x >= 10 or x < 0.1 we only need a bound on the integer\n        # part of log10(self), and this comes directly from the\n        # exponent of x.  For 0.1 <= x <= 10 we use the inequalities\n        # 1-1/x <= log(x) <= x-1. If x > 1 we have |log10(x)| >\n        # (1-1/x)/2.31 > 0.  If x < 1 then |log10(x)| > (1-x)/2.31 > 0\n\n        adj = self._exp + len(self._int) - 1\n        if adj >= 1:\n            # self >= 10\n            return len(str(adj))-1\n        if adj <= -2:\n            # self < 0.1\n            return len(str(-1-adj))-1\n        op = _WorkRep(self)\n        c, e = op.int, op.exp\n        if adj == 0:\n            # 1 < self < 10\n            num = str(c-10**-e)\n            den = str(231*c)\n            return len(num) - len(den) - (num < den) + 2\n        # adj == -1, 0.1 <= self < 1\n        num = str(10**-e-c)\n        return len(num) + e - (num < \"231\") - 1\n\n    def log10(self, context=None):\n        \"\"\"Returns the base 10 logarithm of self.\"\"\"\n\n        if context is None:\n            context = getcontext()\n\n        # log10(NaN) = NaN\n        ans = self._check_nans(context=context)\n        if ans:\n            return ans\n\n        # log10(0.0) == -Infinity\n        if not self:\n            return _NegativeInfinity\n\n        # log10(Infinity) = Infinity\n        if self._isinfinity() == 1:\n            return _Infinity\n\n        # log10(negative or -Infinity) raises InvalidOperation\n        if self._sign == 1:\n            return context._raise_error(InvalidOperation,\n                                        'log10 of a negative value')\n\n        # log10(10**n) = n\n        if self._int[0] == '1' and self._int[1:] == '0'*(len(self._int) - 1):\n            # answer may need rounding\n            ans = Decimal(self._exp + len(self._int) - 1)\n        else:\n            # result is irrational, so necessarily inexact\n            op = _WorkRep(self)\n            c, e = op.int, op.exp\n            p = context.prec\n\n            # correctly rounded result: repeatedly increase precision\n            # until result is unambiguously roundable\n            places = p-self._log10_exp_bound()+2\n            while True:\n                coeff = _dlog10(c, e, places)\n                # assert len(str(abs(coeff)))-p >= 1\n                if coeff % (5*10**(len(str(abs(coeff)))-p-1)):\n                    break\n                places += 3\n            ans = _dec_from_triple(int(coeff<0), str(abs(coeff)), -places)\n\n        context = context._shallow_copy()\n        rounding = context._set_rounding(ROUND_HALF_EVEN)\n        ans = ans._fix(context)\n        context.rounding = rounding\n        return ans\n\n    def logb(self, context=None):\n        \"\"\" Returns the exponent of the magnitude of self's MSD.\n\n        The result is the integer which is the exponent of the magnitude\n        of the most significant digit of self (as though it were truncated\n        to a single digit while maintaining the value of that digit and\n        without limiting the resulting exponent).\n        \"\"\"\n        # logb(NaN) = NaN\n        ans = self._check_nans(context=context)\n        if ans:\n            return ans\n\n        if context is None:\n            context = getcontext()\n\n        # logb(+/-Inf) = +Inf\n        if self._isinfinity():\n            return _Infinity\n\n        # logb(0) = -Inf, DivisionByZero\n        if not self:\n            return context._raise_error(DivisionByZero, 'logb(0)', 1)\n\n        # otherwise, simply return the adjusted exponent of self, as a\n        # Decimal.  Note that no attempt is made to fit the result\n        # into the current context.\n        ans = Decimal(self.adjusted())\n        return ans._fix(context)\n\n    def _islogical(self):\n        \"\"\"Return True if self is a logical operand.\n\n        For being logical, it must be a finite number with a sign of 0,\n        an exponent of 0, and a coefficient whose digits must all be\n        either 0 or 1.\n        \"\"\"\n        if self._sign != 0 or self._exp != 0:\n            return False\n        for dig in self._int:\n            if dig not in '01':\n                return False\n        return True\n\n    def _fill_logical(self, context, opa, opb):\n        dif = context.prec - len(opa)\n        if dif > 0:\n            opa = '0'*dif + opa\n        elif dif < 0:\n            opa = opa[-context.prec:]\n        dif = context.prec - len(opb)\n        if dif > 0:\n            opb = '0'*dif + opb\n        elif dif < 0:\n            opb = opb[-context.prec:]\n        return opa, opb\n\n    def logical_and(self, other, context=None):\n        \"\"\"Applies an 'and' operation between self and other's digits.\"\"\"\n        if context is None:\n            context = getcontext()\n\n        other = _convert_other(other, raiseit=True)\n\n        if not self._islogical() or not other._islogical():\n            return context._raise_error(InvalidOperation)\n\n        # fill to context.prec\n        (opa, opb) = self._fill_logical(context, self._int, other._int)\n\n        # make the operation, and clean starting zeroes\n        result = \"\".join([str(int(a)&int(b)) for a,b in zip(opa,opb)])\n        return _dec_from_triple(0, result.lstrip('0') or '0', 0)\n\n    def logical_invert(self, context=None):\n        \"\"\"Invert all its digits.\"\"\"\n        if context is None:\n            context = getcontext()\n        return self.logical_xor(_dec_from_triple(0,'1'*context.prec,0),\n                                context)\n\n    def logical_or(self, other, context=None):\n        \"\"\"Applies an 'or' operation between self and other's digits.\"\"\"\n        if context is None:\n            context = getcontext()\n\n        other = _convert_other(other, raiseit=True)\n\n        if not self._islogical() or not other._islogical():\n            return context._raise_error(InvalidOperation)\n\n        # fill to context.prec\n        (opa, opb) = self._fill_logical(context, self._int, other._int)\n\n        # make the operation, and clean starting zeroes\n        result = \"\".join([str(int(a)|int(b)) for a,b in zip(opa,opb)])\n        return _dec_from_triple(0, result.lstrip('0') or '0', 0)\n\n    def logical_xor(self, other, context=None):\n        \"\"\"Applies an 'xor' operation between self and other's digits.\"\"\"\n        if context is None:\n            context = getcontext()\n\n        other = _convert_other(other, raiseit=True)\n\n        if not self._islogical() or not other._islogical():\n            return context._raise_error(InvalidOperation)\n\n        # fill to context.prec\n        (opa, opb) = self._fill_logical(context, self._int, other._int)\n\n        # make the operation, and clean starting zeroes\n        result = \"\".join([str(int(a)^int(b)) for a,b in zip(opa,opb)])\n        return _dec_from_triple(0, result.lstrip('0') or '0', 0)\n\n    def max_mag(self, other, context=None):\n        \"\"\"Compares the values numerically with their sign ignored.\"\"\"\n        other = _convert_other(other, raiseit=True)\n\n        if context is None:\n            context = getcontext()\n\n        if self._is_special or other._is_special:\n            # If one operand is a quiet NaN and the other is number, then the\n            # number is always returned\n            sn = self._isnan()\n            on = other._isnan()\n            if sn or on:\n                if on == 1 and sn == 0:\n                    return self._fix(context)\n                if sn == 1 and on == 0:\n                    return other._fix(context)\n                return self._check_nans(other, context)\n\n        c = self.copy_abs()._cmp(other.copy_abs())\n        if c == 0:\n            c = self.compare_total(other)\n\n        if c == -1:\n            ans = other\n        else:\n            ans = self\n\n        return ans._fix(context)\n\n    def min_mag(self, other, context=None):\n        \"\"\"Compares the values numerically with their sign ignored.\"\"\"\n        other = _convert_other(other, raiseit=True)\n\n        if context is None:\n            context = getcontext()\n\n        if self._is_special or other._is_special:\n            # If one operand is a quiet NaN and the other is number, then the\n            # number is always returned\n            sn = self._isnan()\n            on = other._isnan()\n            if sn or on:\n                if on == 1 and sn == 0:\n                    return self._fix(context)\n                if sn == 1 and on == 0:\n                    return other._fix(context)\n                return self._check_nans(other, context)\n\n        c = self.copy_abs()._cmp(other.copy_abs())\n        if c == 0:\n            c = self.compare_total(other)\n\n        if c == -1:\n            ans = self\n        else:\n            ans = other\n\n        return ans._fix(context)\n\n    def next_minus(self, context=None):\n        \"\"\"Returns the largest representable number smaller than itself.\"\"\"\n        if context is None:\n            context = getcontext()\n\n        ans = self._check_nans(context=context)\n        if ans:\n            return ans\n\n        if self._isinfinity() == -1:\n            return _NegativeInfinity\n        if self._isinfinity() == 1:\n            return _dec_from_triple(0, '9'*context.prec, context.Etop())\n\n        context = context.copy()\n        context._set_rounding(ROUND_FLOOR)\n        context._ignore_all_flags()\n        new_self = self._fix(context)\n        if new_self != self:\n            return new_self\n        return self.__sub__(_dec_from_triple(0, '1', context.Etiny()-1),\n                            context)\n\n    def next_plus(self, context=None):\n        \"\"\"Returns the smallest representable number larger than itself.\"\"\"\n        if context is None:\n            context = getcontext()\n\n        ans = self._check_nans(context=context)\n        if ans:\n            return ans\n\n        if self._isinfinity() == 1:\n            return _Infinity\n        if self._isinfinity() == -1:\n            return _dec_from_triple(1, '9'*context.prec, context.Etop())\n\n        context = context.copy()\n        context._set_rounding(ROUND_CEILING)\n        context._ignore_all_flags()\n        new_self = self._fix(context)\n        if new_self != self:\n            return new_self\n        return self.__add__(_dec_from_triple(0, '1', context.Etiny()-1),\n                            context)\n\n    def next_toward(self, other, context=None):\n        \"\"\"Returns the number closest to self, in the direction towards other.\n\n        The result is the closest representable number to self\n        (excluding self) that is in the direction towards other,\n        unless both have the same value.  If the two operands are\n        numerically equal, then the result is a copy of self with the\n        sign set to be the same as the sign of other.\n        \"\"\"\n        other = _convert_other(other, raiseit=True)\n\n        if context is None:\n            context = getcontext()\n\n        ans = self._check_nans(other, context)\n        if ans:\n            return ans\n\n        comparison = self._cmp(other)\n        if comparison == 0:\n            return self.copy_sign(other)\n\n        if comparison == -1:\n            ans = self.next_plus(context)\n        else: # comparison == 1\n            ans = self.next_minus(context)\n\n        # decide which flags to raise using value of ans\n        if ans._isinfinity():\n            context._raise_error(Overflow,\n                                 'Infinite result from next_toward',\n                                 ans._sign)\n            context._raise_error(Inexact)\n            context._raise_error(Rounded)\n        elif ans.adjusted() < context.Emin:\n            context._raise_error(Underflow)\n            context._raise_error(Subnormal)\n            context._raise_error(Inexact)\n            context._raise_error(Rounded)\n            # if precision == 1 then we don't raise Clamped for a\n            # result 0E-Etiny.\n            if not ans:\n                context._raise_error(Clamped)\n\n        return ans\n\n    def number_class(self, context=None):\n        \"\"\"Returns an indication of the class of self.\n\n        The class is one of the following strings:\n          sNaN\n          NaN\n          -Infinity\n          -Normal\n          -Subnormal\n          -Zero\n          +Zero\n          +Subnormal\n          +Normal\n          +Infinity\n        \"\"\"\n        if self.is_snan():\n            return \"sNaN\"\n        if self.is_qnan():\n            return \"NaN\"\n        inf = self._isinfinity()\n        if inf == 1:\n            return \"+Infinity\"\n        if inf == -1:\n            return \"-Infinity\"\n        if self.is_zero():\n            if self._sign:\n                return \"-Zero\"\n            else:\n                return \"+Zero\"\n        if context is None:\n            context = getcontext()\n        if self.is_subnormal(context=context):\n            if self._sign:\n                return \"-Subnormal\"\n            else:\n                return \"+Subnormal\"\n        # just a normal, regular, boring number, :)\n        if self._sign:\n            return \"-Normal\"\n        else:\n            return \"+Normal\"\n\n    def radix(self):\n        \"\"\"Just returns 10, as this is Decimal, :)\"\"\"\n        return Decimal(10)\n\n    def rotate(self, other, context=None):\n        \"\"\"Returns a rotated copy of self, value-of-other times.\"\"\"\n        if context is None:\n            context = getcontext()\n\n        other = _convert_other(other, raiseit=True)\n\n        ans = self._check_nans(other, context)\n        if ans:\n            return ans\n\n        if other._exp != 0:\n            return context._raise_error(InvalidOperation)\n        if not (-context.prec <= int(other) <= context.prec):\n            return context._raise_error(InvalidOperation)\n\n        if self._isinfinity():\n            return Decimal(self)\n\n        # get values, pad if necessary\n        torot = int(other)\n        rotdig = self._int\n        topad = context.prec - len(rotdig)\n        if topad > 0:\n            rotdig = '0'*topad + rotdig\n        elif topad < 0:\n            rotdig = rotdig[-topad:]\n\n        # let's rotate!\n        rotated = rotdig[torot:] + rotdig[:torot]\n        return _dec_from_triple(self._sign,\n                                rotated.lstrip('0') or '0', self._exp)\n\n    def scaleb(self, other, context=None):\n        \"\"\"Returns self operand after adding the second value to its exp.\"\"\"\n        if context is None:\n            context = getcontext()\n\n        other = _convert_other(other, raiseit=True)\n\n        ans = self._check_nans(other, context)\n        if ans:\n            return ans\n\n        if other._exp != 0:\n            return context._raise_error(InvalidOperation)\n        liminf = -2 * (context.Emax + context.prec)\n        limsup =  2 * (context.Emax + context.prec)\n        if not (liminf <= int(other) <= limsup):\n            return context._raise_error(InvalidOperation)\n\n        if self._isinfinity():\n            return Decimal(self)\n\n        d = _dec_from_triple(self._sign, self._int, self._exp + int(other))\n        d = d._fix(context)\n        return d\n\n    def shift(self, other, context=None):\n        \"\"\"Returns a shifted copy of self, value-of-other times.\"\"\"\n        if context is None:\n            context = getcontext()\n\n        other = _convert_other(other, raiseit=True)\n\n        ans = self._check_nans(other, context)\n        if ans:\n            return ans\n\n        if other._exp != 0:\n            return context._raise_error(InvalidOperation)\n        if not (-context.prec <= int(other) <= context.prec):\n            return context._raise_error(InvalidOperation)\n\n        if self._isinfinity():\n            return Decimal(self)\n\n        # get values, pad if necessary\n        torot = int(other)\n        rotdig = self._int\n        topad = context.prec - len(rotdig)\n        if topad > 0:\n            rotdig = '0'*topad + rotdig\n        elif topad < 0:\n            rotdig = rotdig[-topad:]\n\n        # let's shift!\n        if torot < 0:\n            shifted = rotdig[:torot]\n        else:\n            shifted = rotdig + '0'*torot\n            shifted = shifted[-context.prec:]\n\n        return _dec_from_triple(self._sign,\n                                    shifted.lstrip('0') or '0', self._exp)\n\n    # Support for pickling, copy, and deepcopy\n    def __reduce__(self):\n        return (self.__class__, (str(self),))\n\n    def __copy__(self):\n        if type(self) is Decimal:\n            return self     # I'm immutable; therefore I am my own clone\n        return self.__class__(str(self))\n\n    def __deepcopy__(self, memo):\n        if type(self) is Decimal:\n            return self     # My components are also immutable\n        return self.__class__(str(self))\n\n    # PEP 3101 support.  the _localeconv keyword argument should be\n    # considered private: it's provided for ease of testing only.\n    def __format__(self, specifier, context=None, _localeconv=None):\n        \"\"\"Format a Decimal instance according to the given specifier.\n\n        The specifier should be a standard format specifier, with the\n        form described in PEP 3101.  Formatting types 'e', 'E', 'f',\n        'F', 'g', 'G', 'n' and '%' are supported.  If the formatting\n        type is omitted it defaults to 'g' or 'G', depending on the\n        value of context.capitals.\n        \"\"\"\n\n        # Note: PEP 3101 says that if the type is not present then\n        # there should be at least one digit after the decimal point.\n        # We take the liberty of ignoring this requirement for\n        # Decimal---it's presumably there to make sure that\n        # format(float, '') behaves similarly to str(float).\n        if context is None:\n            context = getcontext()\n\n        spec = _parse_format_specifier(specifier, _localeconv=_localeconv)\n\n        # special values don't care about the type or precision\n        if self._is_special:\n            sign = _format_sign(self._sign, spec)\n            body = str(self.copy_abs())\n            return _format_align(sign, body, spec)\n\n        # a type of None defaults to 'g' or 'G', depending on context\n        if spec['type'] is None:\n            spec['type'] = ['g', 'G'][context.capitals]\n\n        # if type is '%', adjust exponent of self accordingly\n        if spec['type'] == '%':\n            self = _dec_from_triple(self._sign, self._int, self._exp+2)\n\n        # round if necessary, taking rounding mode from the context\n        rounding = context.rounding\n        precision = spec['precision']\n        if precision is not None:\n            if spec['type'] in 'eE':\n                self = self._round(precision+1, rounding)\n            elif spec['type'] in 'fF%':\n                self = self._rescale(-precision, rounding)\n            elif spec['type'] in 'gG' and len(self._int) > precision:\n                self = self._round(precision, rounding)\n        # special case: zeros with a positive exponent can't be\n        # represented in fixed point; rescale them to 0e0.\n        if not self and self._exp > 0 and spec['type'] in 'fF%':\n            self = self._rescale(0, rounding)\n\n        # figure out placement of the decimal point\n        leftdigits = self._exp + len(self._int)\n        if spec['type'] in 'eE':\n            if not self and precision is not None:\n                dotplace = 1 - precision\n            else:\n                dotplace = 1\n        elif spec['type'] in 'fF%':\n            dotplace = leftdigits\n        elif spec['type'] in 'gG':\n            if self._exp <= 0 and leftdigits > -6:\n                dotplace = leftdigits\n            else:\n                dotplace = 1\n\n        # find digits before and after decimal point, and get exponent\n        if dotplace < 0:\n            intpart = '0'\n            fracpart = '0'*(-dotplace) + self._int\n        elif dotplace > len(self._int):\n            intpart = self._int + '0'*(dotplace-len(self._int))\n            fracpart = ''\n        else:\n            intpart = self._int[:dotplace] or '0'\n            fracpart = self._int[dotplace:]\n        exp = leftdigits-dotplace\n\n        # done with the decimal-specific stuff;  hand over the rest\n        # of the formatting to the _format_number function\n        return _format_number(self._sign, intpart, fracpart, exp, spec)\n\ndef _dec_from_triple(sign, coefficient, exponent, special=False):\n    \"\"\"Create a decimal instance directly, without any validation,\n    normalization (e.g. removal of leading zeros) or argument\n    conversion.\n\n    This function is for *internal use only*.\n    \"\"\"\n\n    self = object.__new__(Decimal)\n    self._sign = sign\n    self._int = coefficient\n    self._exp = exponent\n    self._is_special = special\n\n    return self\n\n# Register Decimal as a kind of Number (an abstract base class).\n# However, do not register it as Real (because Decimals are not\n# interoperable with floats).\n_numbers.Number.register(Decimal)\n\n\n##### Context class #######################################################\n\nclass _ContextManager(object):\n    \"\"\"Context manager class to support localcontext().\n\n      Sets a copy of the supplied context in __enter__() and restores\n      the previous decimal context in __exit__()\n    \"\"\"\n    def __init__(self, new_context):\n        self.new_context = new_context.copy()\n    def __enter__(self):\n        self.saved_context = getcontext()\n        setcontext(self.new_context)\n        return self.new_context\n    def __exit__(self, t, v, tb):\n        setcontext(self.saved_context)\n\nclass Context(object):\n    \"\"\"Contains the context for a Decimal instance.\n\n    Contains:\n    prec - precision (for use in rounding, division, square roots..)\n    rounding - rounding type (how you round)\n    traps - If traps[exception] = 1, then the exception is\n                    raised when it is caused.  Otherwise, a value is\n                    substituted in.\n    flags  - When an exception is caused, flags[exception] is set.\n             (Whether or not the trap_enabler is set)\n             Should be reset by user of Decimal instance.\n    Emin -   Minimum exponent\n    Emax -   Maximum exponent\n    capitals -      If 1, 1*10^1 is printed as 1E+1.\n                    If 0, printed as 1e1\n    clamp -  If 1, change exponents if too high (Default 0)\n    \"\"\"\n\n    def __init__(self, prec=None, rounding=None, Emin=None, Emax=None,\n                       capitals=None, clamp=None, flags=None, traps=None,\n                       _ignored_flags=None):\n        # Set defaults; for everything except flags and _ignored_flags,\n        # inherit from DefaultContext.\n        try:\n            dc = DefaultContext\n        except NameError:\n            pass\n\n        self.prec = prec if prec is not None else dc.prec\n        self.rounding = rounding if rounding is not None else dc.rounding\n        self.Emin = Emin if Emin is not None else dc.Emin\n        self.Emax = Emax if Emax is not None else dc.Emax\n        self.capitals = capitals if capitals is not None else dc.capitals\n        self.clamp = clamp if clamp is not None else dc.clamp\n\n        if _ignored_flags is None:\n            self._ignored_flags = []\n        else:\n            self._ignored_flags = _ignored_flags\n\n        if traps is None:\n            self.traps = dc.traps.copy()\n        elif not isinstance(traps, dict):\n            self.traps = dict((s, int(s in traps)) for s in _signals + traps)\n        else:\n            self.traps = traps\n\n        if flags is None:\n            self.flags = dict.fromkeys(_signals, 0)\n        elif not isinstance(flags, dict):\n            self.flags = dict((s, int(s in flags)) for s in _signals + flags)\n        else:\n            self.flags = flags\n\n    def _set_integer_check(self, name, value, vmin, vmax):\n        if not isinstance(value, int):\n            raise TypeError(\"%s must be an integer\" % name)\n        if vmin == '-inf':\n            if value > vmax:\n                raise ValueError(\"%s must be in [%s, %d]. got: %s\" % (name, vmin, vmax, value))\n        elif vmax == 'inf':\n            if value < vmin:\n                raise ValueError(\"%s must be in [%d, %s]. got: %s\" % (name, vmin, vmax, value))\n        else:\n            if value < vmin or value > vmax:\n                raise ValueError(\"%s must be in [%d, %d]. got %s\" % (name, vmin, vmax, value))\n        return object.__setattr__(self, name, value)\n\n    def _set_signal_dict(self, name, d):\n        if not isinstance(d, dict):\n            raise TypeError(\"%s must be a signal dict\" % d)\n        for key in d:\n            if not key in _signals:\n                raise KeyError(\"%s is not a valid signal dict\" % d)\n        for key in _signals:\n            if not key in d:\n                raise KeyError(\"%s is not a valid signal dict\" % d)\n        return object.__setattr__(self, name, d)\n\n    def __setattr__(self, name, value):\n        if name == 'prec':\n            return self._set_integer_check(name, value, 1, 'inf')\n        elif name == 'Emin':\n            return self._set_integer_check(name, value, '-inf', 0)\n        elif name == 'Emax':\n            return self._set_integer_check(name, value, 0, 'inf')\n        elif name == 'capitals':\n            return self._set_integer_check(name, value, 0, 1)\n        elif name == 'clamp':\n            return self._set_integer_check(name, value, 0, 1)\n        elif name == 'rounding':\n            if not value in _rounding_modes:\n                # raise TypeError even for strings to have consistency\n                # among various implementations.\n                raise TypeError(\"%s: invalid rounding mode\" % value)\n            return object.__setattr__(self, name, value)\n        elif name == 'flags' or name == 'traps':\n            return self._set_signal_dict(name, value)\n        elif name == '_ignored_flags':\n            return object.__setattr__(self, name, value)\n        else:\n            raise AttributeError(\n                \"'decimal.Context' object has no attribute '%s'\" % name)\n\n    def __delattr__(self, name):\n        raise AttributeError(\"%s cannot be deleted\" % name)\n\n    # Support for pickling, copy, and deepcopy\n    def __reduce__(self):\n        flags = [sig for sig, v in self.flags.items() if v]\n        traps = [sig for sig, v in self.traps.items() if v]\n        return (self.__class__,\n                (self.prec, self.rounding, self.Emin, self.Emax,\n                 self.capitals, self.clamp, flags, traps))\n\n    def __repr__(self):\n        \"\"\"Show the current context.\"\"\"\n        s = []\n        s.append('Context(prec=%(prec)d, rounding=%(rounding)s, '\n                 'Emin=%(Emin)d, Emax=%(Emax)d, capitals=%(capitals)d, '\n                 'clamp=%(clamp)d'\n                 % vars(self))\n        names = [f.__name__ for f, v in self.flags.items() if v]\n        s.append('flags=[' + ', '.join(names) + ']')\n        names = [t.__name__ for t, v in self.traps.items() if v]\n        s.append('traps=[' + ', '.join(names) + ']')\n        return ', '.join(s) + ')'\n\n    def clear_flags(self):\n        \"\"\"Reset all flags to zero\"\"\"\n        for flag in self.flags:\n            self.flags[flag] = 0\n\n    def clear_traps(self):\n        \"\"\"Reset all traps to zero\"\"\"\n        for flag in self.traps:\n            self.traps[flag] = 0\n\n    def _shallow_copy(self):\n        \"\"\"Returns a shallow copy from self.\"\"\"\n        nc = Context(self.prec, self.rounding, self.Emin, self.Emax,\n                     self.capitals, self.clamp, self.flags, self.traps,\n                     self._ignored_flags)\n        return nc\n\n    def copy(self):\n        \"\"\"Returns a deep copy from self.\"\"\"\n        nc = Context(self.prec, self.rounding, self.Emin, self.Emax,\n                     self.capitals, self.clamp,\n                     self.flags.copy(), self.traps.copy(),\n                     self._ignored_flags)\n        return nc\n    __copy__ = copy\n\n    def _raise_error(self, condition, explanation = None, *args):\n        \"\"\"Handles an error\n\n        If the flag is in _ignored_flags, returns the default response.\n        Otherwise, it sets the flag, then, if the corresponding\n        trap_enabler is set, it reraises the exception.  Otherwise, it returns\n        the default value after setting the flag.\n        \"\"\"\n        error = _condition_map.get(condition, condition)\n        if error in self._ignored_flags:\n            # Don't touch the flag\n            return error().handle(self, *args)\n\n        self.flags[error] = 1\n        if not self.traps[error]:\n            # The errors define how to handle themselves.\n            return condition().handle(self, *args)\n\n        # Errors should only be risked on copies of the context\n        # self._ignored_flags = []\n        raise error(explanation)\n\n    def _ignore_all_flags(self):\n        \"\"\"Ignore all flags, if they are raised\"\"\"\n        return self._ignore_flags(*_signals)\n\n    def _ignore_flags(self, *flags):\n        \"\"\"Ignore the flags, if they are raised\"\"\"\n        # Do not mutate-- This way, copies of a context leave the original\n        # alone.\n        self._ignored_flags = (self._ignored_flags + list(flags))\n        return list(flags)\n\n    def _regard_flags(self, *flags):\n        \"\"\"Stop ignoring the flags, if they are raised\"\"\"\n        if flags and isinstance(flags[0], (tuple,list)):\n            flags = flags[0]\n        for flag in flags:\n            self._ignored_flags.remove(flag)\n\n    # We inherit object.__hash__, so we must deny this explicitly\n    __hash__ = None\n\n    def Etiny(self):\n        \"\"\"Returns Etiny (= Emin - prec + 1)\"\"\"\n        return int(self.Emin - self.prec + 1)\n\n    def Etop(self):\n        \"\"\"Returns maximum exponent (= Emax - prec + 1)\"\"\"\n        return int(self.Emax - self.prec + 1)\n\n    def _set_rounding(self, type):\n        \"\"\"Sets the rounding type.\n\n        Sets the rounding type, and returns the current (previous)\n        rounding type.  Often used like:\n\n        context = context.copy()\n        # so you don't change the calling context\n        # if an error occurs in the middle.\n        rounding = context._set_rounding(ROUND_UP)\n        val = self.__sub__(other, context=context)\n        context._set_rounding(rounding)\n\n        This will make it round up for that operation.\n        \"\"\"\n        rounding = self.rounding\n        self.rounding= type\n        return rounding\n\n    def create_decimal(self, num='0'):\n        \"\"\"Creates a new Decimal instance but using self as context.\n\n        This method implements the to-number operation of the\n        IBM Decimal specification.\"\"\"\n\n        if isinstance(num, str) and num != num.strip():\n            return self._raise_error(ConversionSyntax,\n                                     \"no trailing or leading whitespace is \"\n                                     \"permitted.\")\n\n        d = Decimal(num, context=self)\n        if d._isnan() and len(d._int) > self.prec - self.clamp:\n            return self._raise_error(ConversionSyntax,\n                                     \"diagnostic info too long in NaN\")\n        return d._fix(self)\n\n    def create_decimal_from_float(self, f):\n        \"\"\"Creates a new Decimal instance from a float but rounding using self\n        as the context.\n\n        >>> context = Context(prec=5, rounding=ROUND_DOWN)\n        >>> context.create_decimal_from_float(3.1415926535897932)\n        Decimal('3.1415')\n        >>> context = Context(prec=5, traps=[Inexact])\n        >>> context.create_decimal_from_float(3.1415926535897932)\n        Traceback (most recent call last):\n            ...\n        decimal.Inexact: None\n\n        \"\"\"\n        d = Decimal.from_float(f)       # An exact conversion\n        return d._fix(self)             # Apply the context rounding\n\n    # Methods\n    def abs(self, a):\n        \"\"\"Returns the absolute value of the operand.\n\n        If the operand is negative, the result is the same as using the minus\n        operation on the operand.  Otherwise, the result is the same as using\n        the plus operation on the operand.\n\n        >>> ExtendedContext.abs(Decimal('2.1'))\n        Decimal('2.1')\n        >>> ExtendedContext.abs(Decimal('-100'))\n        Decimal('100')\n        >>> ExtendedContext.abs(Decimal('101.5'))\n        Decimal('101.5')\n        >>> ExtendedContext.abs(Decimal('-101.5'))\n        Decimal('101.5')\n        >>> ExtendedContext.abs(-1)\n        Decimal('1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.__abs__(context=self)\n\n    def add(self, a, b):\n        \"\"\"Return the sum of the two operands.\n\n        >>> ExtendedContext.add(Decimal('12'), Decimal('7.00'))\n        Decimal('19.00')\n        >>> ExtendedContext.add(Decimal('1E+2'), Decimal('1.01E+4'))\n        Decimal('1.02E+4')\n        >>> ExtendedContext.add(1, Decimal(2))\n        Decimal('3')\n        >>> ExtendedContext.add(Decimal(8), 5)\n        Decimal('13')\n        >>> ExtendedContext.add(5, 5)\n        Decimal('10')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        r = a.__add__(b, context=self)\n        if r is NotImplemented:\n            raise TypeError(\"Unable to convert %s to Decimal\" % b)\n        else:\n            return r\n\n    def _apply(self, a):\n        return str(a._fix(self))\n\n    def canonical(self, a):\n        \"\"\"Returns the same Decimal object.\n\n        As we do not have different encodings for the same number, the\n        received object already is in its canonical form.\n\n        >>> ExtendedContext.canonical(Decimal('2.50'))\n        Decimal('2.50')\n        \"\"\"\n        if not isinstance(a, Decimal):\n            raise TypeError(\"canonical requires a Decimal as an argument.\")\n        return a.canonical()\n\n    def compare(self, a, b):\n        \"\"\"Compares values numerically.\n\n        If the signs of the operands differ, a value representing each operand\n        ('-1' if the operand is less than zero, '0' if the operand is zero or\n        negative zero, or '1' if the operand is greater than zero) is used in\n        place of that operand for the comparison instead of the actual\n        operand.\n\n        The comparison is then effected by subtracting the second operand from\n        the first and then returning a value according to the result of the\n        subtraction: '-1' if the result is less than zero, '0' if the result is\n        zero or negative zero, or '1' if the result is greater than zero.\n\n        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('3'))\n        Decimal('-1')\n        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('2.1'))\n        Decimal('0')\n        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('2.10'))\n        Decimal('0')\n        >>> ExtendedContext.compare(Decimal('3'), Decimal('2.1'))\n        Decimal('1')\n        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('-3'))\n        Decimal('1')\n        >>> ExtendedContext.compare(Decimal('-3'), Decimal('2.1'))\n        Decimal('-1')\n        >>> ExtendedContext.compare(1, 2)\n        Decimal('-1')\n        >>> ExtendedContext.compare(Decimal(1), 2)\n        Decimal('-1')\n        >>> ExtendedContext.compare(1, Decimal(2))\n        Decimal('-1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.compare(b, context=self)\n\n    def compare_signal(self, a, b):\n        \"\"\"Compares the values of the two operands numerically.\n\n        It's pretty much like compare(), but all NaNs signal, with signaling\n        NaNs taking precedence over quiet NaNs.\n\n        >>> c = ExtendedContext\n        >>> c.compare_signal(Decimal('2.1'), Decimal('3'))\n        Decimal('-1')\n        >>> c.compare_signal(Decimal('2.1'), Decimal('2.1'))\n        Decimal('0')\n        >>> c.flags[InvalidOperation] = 0\n        >>> print(c.flags[InvalidOperation])\n        0\n        >>> c.compare_signal(Decimal('NaN'), Decimal('2.1'))\n        Decimal('NaN')\n        >>> print(c.flags[InvalidOperation])\n        1\n        >>> c.flags[InvalidOperation] = 0\n        >>> print(c.flags[InvalidOperation])\n        0\n        >>> c.compare_signal(Decimal('sNaN'), Decimal('2.1'))\n        Decimal('NaN')\n        >>> print(c.flags[InvalidOperation])\n        1\n        >>> c.compare_signal(-1, 2)\n        Decimal('-1')\n        >>> c.compare_signal(Decimal(-1), 2)\n        Decimal('-1')\n        >>> c.compare_signal(-1, Decimal(2))\n        Decimal('-1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.compare_signal(b, context=self)\n\n    def compare_total(self, a, b):\n        \"\"\"Compares two operands using their abstract representation.\n\n        This is not like the standard compare, which use their numerical\n        value. Note that a total ordering is defined for all possible abstract\n        representations.\n\n        >>> ExtendedContext.compare_total(Decimal('12.73'), Decimal('127.9'))\n        Decimal('-1')\n        >>> ExtendedContext.compare_total(Decimal('-127'),  Decimal('12'))\n        Decimal('-1')\n        >>> ExtendedContext.compare_total(Decimal('12.30'), Decimal('12.3'))\n        Decimal('-1')\n        >>> ExtendedContext.compare_total(Decimal('12.30'), Decimal('12.30'))\n        Decimal('0')\n        >>> ExtendedContext.compare_total(Decimal('12.3'),  Decimal('12.300'))\n        Decimal('1')\n        >>> ExtendedContext.compare_total(Decimal('12.3'),  Decimal('NaN'))\n        Decimal('-1')\n        >>> ExtendedContext.compare_total(1, 2)\n        Decimal('-1')\n        >>> ExtendedContext.compare_total(Decimal(1), 2)\n        Decimal('-1')\n        >>> ExtendedContext.compare_total(1, Decimal(2))\n        Decimal('-1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.compare_total(b)\n\n    def compare_total_mag(self, a, b):\n        \"\"\"Compares two operands using their abstract representation ignoring sign.\n\n        Like compare_total, but with operand's sign ignored and assumed to be 0.\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.compare_total_mag(b)\n\n    def copy_abs(self, a):\n        \"\"\"Returns a copy of the operand with the sign set to 0.\n\n        >>> ExtendedContext.copy_abs(Decimal('2.1'))\n        Decimal('2.1')\n        >>> ExtendedContext.copy_abs(Decimal('-100'))\n        Decimal('100')\n        >>> ExtendedContext.copy_abs(-1)\n        Decimal('1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.copy_abs()\n\n    def copy_decimal(self, a):\n        \"\"\"Returns a copy of the decimal object.\n\n        >>> ExtendedContext.copy_decimal(Decimal('2.1'))\n        Decimal('2.1')\n        >>> ExtendedContext.copy_decimal(Decimal('-1.00'))\n        Decimal('-1.00')\n        >>> ExtendedContext.copy_decimal(1)\n        Decimal('1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return Decimal(a)\n\n    def copy_negate(self, a):\n        \"\"\"Returns a copy of the operand with the sign inverted.\n\n        >>> ExtendedContext.copy_negate(Decimal('101.5'))\n        Decimal('-101.5')\n        >>> ExtendedContext.copy_negate(Decimal('-101.5'))\n        Decimal('101.5')\n        >>> ExtendedContext.copy_negate(1)\n        Decimal('-1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.copy_negate()\n\n    def copy_sign(self, a, b):\n        \"\"\"Copies the second operand's sign to the first one.\n\n        In detail, it returns a copy of the first operand with the sign\n        equal to the sign of the second operand.\n\n        >>> ExtendedContext.copy_sign(Decimal( '1.50'), Decimal('7.33'))\n        Decimal('1.50')\n        >>> ExtendedContext.copy_sign(Decimal('-1.50'), Decimal('7.33'))\n        Decimal('1.50')\n        >>> ExtendedContext.copy_sign(Decimal( '1.50'), Decimal('-7.33'))\n        Decimal('-1.50')\n        >>> ExtendedContext.copy_sign(Decimal('-1.50'), Decimal('-7.33'))\n        Decimal('-1.50')\n        >>> ExtendedContext.copy_sign(1, -2)\n        Decimal('-1')\n        >>> ExtendedContext.copy_sign(Decimal(1), -2)\n        Decimal('-1')\n        >>> ExtendedContext.copy_sign(1, Decimal(-2))\n        Decimal('-1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.copy_sign(b)\n\n    def divide(self, a, b):\n        \"\"\"Decimal division in a specified context.\n\n        >>> ExtendedContext.divide(Decimal('1'), Decimal('3'))\n        Decimal('0.333333333')\n        >>> ExtendedContext.divide(Decimal('2'), Decimal('3'))\n        Decimal('0.666666667')\n        >>> ExtendedContext.divide(Decimal('5'), Decimal('2'))\n        Decimal('2.5')\n        >>> ExtendedContext.divide(Decimal('1'), Decimal('10'))\n        Decimal('0.1')\n        >>> ExtendedContext.divide(Decimal('12'), Decimal('12'))\n        Decimal('1')\n        >>> ExtendedContext.divide(Decimal('8.00'), Decimal('2'))\n        Decimal('4.00')\n        >>> ExtendedContext.divide(Decimal('2.400'), Decimal('2.0'))\n        Decimal('1.20')\n        >>> ExtendedContext.divide(Decimal('1000'), Decimal('100'))\n        Decimal('10')\n        >>> ExtendedContext.divide(Decimal('1000'), Decimal('1'))\n        Decimal('1000')\n        >>> ExtendedContext.divide(Decimal('2.40E+6'), Decimal('2'))\n        Decimal('1.20E+6')\n        >>> ExtendedContext.divide(5, 5)\n        Decimal('1')\n        >>> ExtendedContext.divide(Decimal(5), 5)\n        Decimal('1')\n        >>> ExtendedContext.divide(5, Decimal(5))\n        Decimal('1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        r = a.__truediv__(b, context=self)\n        if r is NotImplemented:\n            raise TypeError(\"Unable to convert %s to Decimal\" % b)\n        else:\n            return r\n\n    def divide_int(self, a, b):\n        \"\"\"Divides two numbers and returns the integer part of the result.\n\n        >>> ExtendedContext.divide_int(Decimal('2'), Decimal('3'))\n        Decimal('0')\n        >>> ExtendedContext.divide_int(Decimal('10'), Decimal('3'))\n        Decimal('3')\n        >>> ExtendedContext.divide_int(Decimal('1'), Decimal('0.3'))\n        Decimal('3')\n        >>> ExtendedContext.divide_int(10, 3)\n        Decimal('3')\n        >>> ExtendedContext.divide_int(Decimal(10), 3)\n        Decimal('3')\n        >>> ExtendedContext.divide_int(10, Decimal(3))\n        Decimal('3')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        r = a.__floordiv__(b, context=self)\n        if r is NotImplemented:\n            raise TypeError(\"Unable to convert %s to Decimal\" % b)\n        else:\n            return r\n\n    def divmod(self, a, b):\n        \"\"\"Return (a // b, a % b).\n\n        >>> ExtendedContext.divmod(Decimal(8), Decimal(3))\n        (Decimal('2'), Decimal('2'))\n        >>> ExtendedContext.divmod(Decimal(8), Decimal(4))\n        (Decimal('2'), Decimal('0'))\n        >>> ExtendedContext.divmod(8, 4)\n        (Decimal('2'), Decimal('0'))\n        >>> ExtendedContext.divmod(Decimal(8), 4)\n        (Decimal('2'), Decimal('0'))\n        >>> ExtendedContext.divmod(8, Decimal(4))\n        (Decimal('2'), Decimal('0'))\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        r = a.__divmod__(b, context=self)\n        if r is NotImplemented:\n            raise TypeError(\"Unable to convert %s to Decimal\" % b)\n        else:\n            return r\n\n    def exp(self, a):\n        \"\"\"Returns e ** a.\n\n        >>> c = ExtendedContext.copy()\n        >>> c.Emin = -999\n        >>> c.Emax = 999\n        >>> c.exp(Decimal('-Infinity'))\n        Decimal('0')\n        >>> c.exp(Decimal('-1'))\n        Decimal('0.367879441')\n        >>> c.exp(Decimal('0'))\n        Decimal('1')\n        >>> c.exp(Decimal('1'))\n        Decimal('2.71828183')\n        >>> c.exp(Decimal('0.693147181'))\n        Decimal('2.00000000')\n        >>> c.exp(Decimal('+Infinity'))\n        Decimal('Infinity')\n        >>> c.exp(10)\n        Decimal('22026.4658')\n        \"\"\"\n        a =_convert_other(a, raiseit=True)\n        return a.exp(context=self)\n\n    def fma(self, a, b, c):\n        \"\"\"Returns a multiplied by b, plus c.\n\n        The first two operands are multiplied together, using multiply,\n        the third operand is then added to the result of that\n        multiplication, using add, all with only one final rounding.\n\n        >>> ExtendedContext.fma(Decimal('3'), Decimal('5'), Decimal('7'))\n        Decimal('22')\n        >>> ExtendedContext.fma(Decimal('3'), Decimal('-5'), Decimal('7'))\n        Decimal('-8')\n        >>> ExtendedContext.fma(Decimal('888565290'), Decimal('1557.96930'), Decimal('-86087.7578'))\n        Decimal('1.38435736E+12')\n        >>> ExtendedContext.fma(1, 3, 4)\n        Decimal('7')\n        >>> ExtendedContext.fma(1, Decimal(3), 4)\n        Decimal('7')\n        >>> ExtendedContext.fma(1, 3, Decimal(4))\n        Decimal('7')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.fma(b, c, context=self)\n\n    def is_canonical(self, a):\n        \"\"\"Return True if the operand is canonical; otherwise return False.\n\n        Currently, the encoding of a Decimal instance is always\n        canonical, so this method returns True for any Decimal.\n\n        >>> ExtendedContext.is_canonical(Decimal('2.50'))\n        True\n        \"\"\"\n        if not isinstance(a, Decimal):\n            raise TypeError(\"is_canonical requires a Decimal as an argument.\")\n        return a.is_canonical()\n\n    def is_finite(self, a):\n        \"\"\"Return True if the operand is finite; otherwise return False.\n\n        A Decimal instance is considered finite if it is neither\n        infinite nor a NaN.\n\n        >>> ExtendedContext.is_finite(Decimal('2.50'))\n        True\n        >>> ExtendedContext.is_finite(Decimal('-0.3'))\n        True\n        >>> ExtendedContext.is_finite(Decimal('0'))\n        True\n        >>> ExtendedContext.is_finite(Decimal('Inf'))\n        False\n        >>> ExtendedContext.is_finite(Decimal('NaN'))\n        False\n        >>> ExtendedContext.is_finite(1)\n        True\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.is_finite()\n\n    def is_infinite(self, a):\n        \"\"\"Return True if the operand is infinite; otherwise return False.\n\n        >>> ExtendedContext.is_infinite(Decimal('2.50'))\n        False\n        >>> ExtendedContext.is_infinite(Decimal('-Inf'))\n        True\n        >>> ExtendedContext.is_infinite(Decimal('NaN'))\n        False\n        >>> ExtendedContext.is_infinite(1)\n        False\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.is_infinite()\n\n    def is_nan(self, a):\n        \"\"\"Return True if the operand is a qNaN or sNaN;\n        otherwise return False.\n\n        >>> ExtendedContext.is_nan(Decimal('2.50'))\n        False\n        >>> ExtendedContext.is_nan(Decimal('NaN'))\n        True\n        >>> ExtendedContext.is_nan(Decimal('-sNaN'))\n        True\n        >>> ExtendedContext.is_nan(1)\n        False\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.is_nan()\n\n    def is_normal(self, a):\n        \"\"\"Return True if the operand is a normal number;\n        otherwise return False.\n\n        >>> c = ExtendedContext.copy()\n        >>> c.Emin = -999\n        >>> c.Emax = 999\n        >>> c.is_normal(Decimal('2.50'))\n        True\n        >>> c.is_normal(Decimal('0.1E-999'))\n        False\n        >>> c.is_normal(Decimal('0.00'))\n        False\n        >>> c.is_normal(Decimal('-Inf'))\n        False\n        >>> c.is_normal(Decimal('NaN'))\n        False\n        >>> c.is_normal(1)\n        True\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.is_normal(context=self)\n\n    def is_qnan(self, a):\n        \"\"\"Return True if the operand is a quiet NaN; otherwise return False.\n\n        >>> ExtendedContext.is_qnan(Decimal('2.50'))\n        False\n        >>> ExtendedContext.is_qnan(Decimal('NaN'))\n        True\n        >>> ExtendedContext.is_qnan(Decimal('sNaN'))\n        False\n        >>> ExtendedContext.is_qnan(1)\n        False\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.is_qnan()\n\n    def is_signed(self, a):\n        \"\"\"Return True if the operand is negative; otherwise return False.\n\n        >>> ExtendedContext.is_signed(Decimal('2.50'))\n        False\n        >>> ExtendedContext.is_signed(Decimal('-12'))\n        True\n        >>> ExtendedContext.is_signed(Decimal('-0'))\n        True\n        >>> ExtendedContext.is_signed(8)\n        False\n        >>> ExtendedContext.is_signed(-8)\n        True\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.is_signed()\n\n    def is_snan(self, a):\n        \"\"\"Return True if the operand is a signaling NaN;\n        otherwise return False.\n\n        >>> ExtendedContext.is_snan(Decimal('2.50'))\n        False\n        >>> ExtendedContext.is_snan(Decimal('NaN'))\n        False\n        >>> ExtendedContext.is_snan(Decimal('sNaN'))\n        True\n        >>> ExtendedContext.is_snan(1)\n        False\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.is_snan()\n\n    def is_subnormal(self, a):\n        \"\"\"Return True if the operand is subnormal; otherwise return False.\n\n        >>> c = ExtendedContext.copy()\n        >>> c.Emin = -999\n        >>> c.Emax = 999\n        >>> c.is_subnormal(Decimal('2.50'))\n        False\n        >>> c.is_subnormal(Decimal('0.1E-999'))\n        True\n        >>> c.is_subnormal(Decimal('0.00'))\n        False\n        >>> c.is_subnormal(Decimal('-Inf'))\n        False\n        >>> c.is_subnormal(Decimal('NaN'))\n        False\n        >>> c.is_subnormal(1)\n        False\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.is_subnormal(context=self)\n\n    def is_zero(self, a):\n        \"\"\"Return True if the operand is a zero; otherwise return False.\n\n        >>> ExtendedContext.is_zero(Decimal('0'))\n        True\n        >>> ExtendedContext.is_zero(Decimal('2.50'))\n        False\n        >>> ExtendedContext.is_zero(Decimal('-0E+2'))\n        True\n        >>> ExtendedContext.is_zero(1)\n        False\n        >>> ExtendedContext.is_zero(0)\n        True\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.is_zero()\n\n    def ln(self, a):\n        \"\"\"Returns the natural (base e) logarithm of the operand.\n\n        >>> c = ExtendedContext.copy()\n        >>> c.Emin = -999\n        >>> c.Emax = 999\n        >>> c.ln(Decimal('0'))\n        Decimal('-Infinity')\n        >>> c.ln(Decimal('1.000'))\n        Decimal('0')\n        >>> c.ln(Decimal('2.71828183'))\n        Decimal('1.00000000')\n        >>> c.ln(Decimal('10'))\n        Decimal('2.30258509')\n        >>> c.ln(Decimal('+Infinity'))\n        Decimal('Infinity')\n        >>> c.ln(1)\n        Decimal('0')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.ln(context=self)\n\n    def log10(self, a):\n        \"\"\"Returns the base 10 logarithm of the operand.\n\n        >>> c = ExtendedContext.copy()\n        >>> c.Emin = -999\n        >>> c.Emax = 999\n        >>> c.log10(Decimal('0'))\n        Decimal('-Infinity')\n        >>> c.log10(Decimal('0.001'))\n        Decimal('-3')\n        >>> c.log10(Decimal('1.000'))\n        Decimal('0')\n        >>> c.log10(Decimal('2'))\n        Decimal('0.301029996')\n        >>> c.log10(Decimal('10'))\n        Decimal('1')\n        >>> c.log10(Decimal('70'))\n        Decimal('1.84509804')\n        >>> c.log10(Decimal('+Infinity'))\n        Decimal('Infinity')\n        >>> c.log10(0)\n        Decimal('-Infinity')\n        >>> c.log10(1)\n        Decimal('0')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.log10(context=self)\n\n    def logb(self, a):\n        \"\"\" Returns the exponent of the magnitude of the operand's MSD.\n\n        The result is the integer which is the exponent of the magnitude\n        of the most significant digit of the operand (as though the\n        operand were truncated to a single digit while maintaining the\n        value of that digit and without limiting the resulting exponent).\n\n        >>> ExtendedContext.logb(Decimal('250'))\n        Decimal('2')\n        >>> ExtendedContext.logb(Decimal('2.50'))\n        Decimal('0')\n        >>> ExtendedContext.logb(Decimal('0.03'))\n        Decimal('-2')\n        >>> ExtendedContext.logb(Decimal('0'))\n        Decimal('-Infinity')\n        >>> ExtendedContext.logb(1)\n        Decimal('0')\n        >>> ExtendedContext.logb(10)\n        Decimal('1')\n        >>> ExtendedContext.logb(100)\n        Decimal('2')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.logb(context=self)\n\n    def logical_and(self, a, b):\n        \"\"\"Applies the logical operation 'and' between each operand's digits.\n\n        The operands must be both logical numbers.\n\n        >>> ExtendedContext.logical_and(Decimal('0'), Decimal('0'))\n        Decimal('0')\n        >>> ExtendedContext.logical_and(Decimal('0'), Decimal('1'))\n        Decimal('0')\n        >>> ExtendedContext.logical_and(Decimal('1'), Decimal('0'))\n        Decimal('0')\n        >>> ExtendedContext.logical_and(Decimal('1'), Decimal('1'))\n        Decimal('1')\n        >>> ExtendedContext.logical_and(Decimal('1100'), Decimal('1010'))\n        Decimal('1000')\n        >>> ExtendedContext.logical_and(Decimal('1111'), Decimal('10'))\n        Decimal('10')\n        >>> ExtendedContext.logical_and(110, 1101)\n        Decimal('100')\n        >>> ExtendedContext.logical_and(Decimal(110), 1101)\n        Decimal('100')\n        >>> ExtendedContext.logical_and(110, Decimal(1101))\n        Decimal('100')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.logical_and(b, context=self)\n\n    def logical_invert(self, a):\n        \"\"\"Invert all the digits in the operand.\n\n        The operand must be a logical number.\n\n        >>> ExtendedContext.logical_invert(Decimal('0'))\n        Decimal('111111111')\n        >>> ExtendedContext.logical_invert(Decimal('1'))\n        Decimal('111111110')\n        >>> ExtendedContext.logical_invert(Decimal('111111111'))\n        Decimal('0')\n        >>> ExtendedContext.logical_invert(Decimal('101010101'))\n        Decimal('10101010')\n        >>> ExtendedContext.logical_invert(1101)\n        Decimal('111110010')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.logical_invert(context=self)\n\n    def logical_or(self, a, b):\n        \"\"\"Applies the logical operation 'or' between each operand's digits.\n\n        The operands must be both logical numbers.\n\n        >>> ExtendedContext.logical_or(Decimal('0'), Decimal('0'))\n        Decimal('0')\n        >>> ExtendedContext.logical_or(Decimal('0'), Decimal('1'))\n        Decimal('1')\n        >>> ExtendedContext.logical_or(Decimal('1'), Decimal('0'))\n        Decimal('1')\n        >>> ExtendedContext.logical_or(Decimal('1'), Decimal('1'))\n        Decimal('1')\n        >>> ExtendedContext.logical_or(Decimal('1100'), Decimal('1010'))\n        Decimal('1110')\n        >>> ExtendedContext.logical_or(Decimal('1110'), Decimal('10'))\n        Decimal('1110')\n        >>> ExtendedContext.logical_or(110, 1101)\n        Decimal('1111')\n        >>> ExtendedContext.logical_or(Decimal(110), 1101)\n        Decimal('1111')\n        >>> ExtendedContext.logical_or(110, Decimal(1101))\n        Decimal('1111')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.logical_or(b, context=self)\n\n    def logical_xor(self, a, b):\n        \"\"\"Applies the logical operation 'xor' between each operand's digits.\n\n        The operands must be both logical numbers.\n\n        >>> ExtendedContext.logical_xor(Decimal('0'), Decimal('0'))\n        Decimal('0')\n        >>> ExtendedContext.logical_xor(Decimal('0'), Decimal('1'))\n        Decimal('1')\n        >>> ExtendedContext.logical_xor(Decimal('1'), Decimal('0'))\n        Decimal('1')\n        >>> ExtendedContext.logical_xor(Decimal('1'), Decimal('1'))\n        Decimal('0')\n        >>> ExtendedContext.logical_xor(Decimal('1100'), Decimal('1010'))\n        Decimal('110')\n        >>> ExtendedContext.logical_xor(Decimal('1111'), Decimal('10'))\n        Decimal('1101')\n        >>> ExtendedContext.logical_xor(110, 1101)\n        Decimal('1011')\n        >>> ExtendedContext.logical_xor(Decimal(110), 1101)\n        Decimal('1011')\n        >>> ExtendedContext.logical_xor(110, Decimal(1101))\n        Decimal('1011')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.logical_xor(b, context=self)\n\n    def max(self, a, b):\n        \"\"\"max compares two values numerically and returns the maximum.\n\n        If either operand is a NaN then the general rules apply.\n        Otherwise, the operands are compared as though by the compare\n        operation.  If they are numerically equal then the left-hand operand\n        is chosen as the result.  Otherwise the maximum (closer to positive\n        infinity) of the two operands is chosen as the result.\n\n        >>> ExtendedContext.max(Decimal('3'), Decimal('2'))\n        Decimal('3')\n        >>> ExtendedContext.max(Decimal('-10'), Decimal('3'))\n        Decimal('3')\n        >>> ExtendedContext.max(Decimal('1.0'), Decimal('1'))\n        Decimal('1')\n        >>> ExtendedContext.max(Decimal('7'), Decimal('NaN'))\n        Decimal('7')\n        >>> ExtendedContext.max(1, 2)\n        Decimal('2')\n        >>> ExtendedContext.max(Decimal(1), 2)\n        Decimal('2')\n        >>> ExtendedContext.max(1, Decimal(2))\n        Decimal('2')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.max(b, context=self)\n\n    def max_mag(self, a, b):\n        \"\"\"Compares the values numerically with their sign ignored.\n\n        >>> ExtendedContext.max_mag(Decimal('7'), Decimal('NaN'))\n        Decimal('7')\n        >>> ExtendedContext.max_mag(Decimal('7'), Decimal('-10'))\n        Decimal('-10')\n        >>> ExtendedContext.max_mag(1, -2)\n        Decimal('-2')\n        >>> ExtendedContext.max_mag(Decimal(1), -2)\n        Decimal('-2')\n        >>> ExtendedContext.max_mag(1, Decimal(-2))\n        Decimal('-2')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.max_mag(b, context=self)\n\n    def min(self, a, b):\n        \"\"\"min compares two values numerically and returns the minimum.\n\n        If either operand is a NaN then the general rules apply.\n        Otherwise, the operands are compared as though by the compare\n        operation.  If they are numerically equal then the left-hand operand\n        is chosen as the result.  Otherwise the minimum (closer to negative\n        infinity) of the two operands is chosen as the result.\n\n        >>> ExtendedContext.min(Decimal('3'), Decimal('2'))\n        Decimal('2')\n        >>> ExtendedContext.min(Decimal('-10'), Decimal('3'))\n        Decimal('-10')\n        >>> ExtendedContext.min(Decimal('1.0'), Decimal('1'))\n        Decimal('1.0')\n        >>> ExtendedContext.min(Decimal('7'), Decimal('NaN'))\n        Decimal('7')\n        >>> ExtendedContext.min(1, 2)\n        Decimal('1')\n        >>> ExtendedContext.min(Decimal(1), 2)\n        Decimal('1')\n        >>> ExtendedContext.min(1, Decimal(29))\n        Decimal('1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.min(b, context=self)\n\n    def min_mag(self, a, b):\n        \"\"\"Compares the values numerically with their sign ignored.\n\n        >>> ExtendedContext.min_mag(Decimal('3'), Decimal('-2'))\n        Decimal('-2')\n        >>> ExtendedContext.min_mag(Decimal('-3'), Decimal('NaN'))\n        Decimal('-3')\n        >>> ExtendedContext.min_mag(1, -2)\n        Decimal('1')\n        >>> ExtendedContext.min_mag(Decimal(1), -2)\n        Decimal('1')\n        >>> ExtendedContext.min_mag(1, Decimal(-2))\n        Decimal('1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.min_mag(b, context=self)\n\n    def minus(self, a):\n        \"\"\"Minus corresponds to unary prefix minus in Python.\n\n        The operation is evaluated using the same rules as subtract; the\n        operation minus(a) is calculated as subtract('0', a) where the '0'\n        has the same exponent as the operand.\n\n        >>> ExtendedContext.minus(Decimal('1.3'))\n        Decimal('-1.3')\n        >>> ExtendedContext.minus(Decimal('-1.3'))\n        Decimal('1.3')\n        >>> ExtendedContext.minus(1)\n        Decimal('-1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.__neg__(context=self)\n\n    def multiply(self, a, b):\n        \"\"\"multiply multiplies two operands.\n\n        If either operand is a special value then the general rules apply.\n        Otherwise, the operands are multiplied together\n        ('long multiplication'), resulting in a number which may be as long as\n        the sum of the lengths of the two operands.\n\n        >>> ExtendedContext.multiply(Decimal('1.20'), Decimal('3'))\n        Decimal('3.60')\n        >>> ExtendedContext.multiply(Decimal('7'), Decimal('3'))\n        Decimal('21')\n        >>> ExtendedContext.multiply(Decimal('0.9'), Decimal('0.8'))\n        Decimal('0.72')\n        >>> ExtendedContext.multiply(Decimal('0.9'), Decimal('-0'))\n        Decimal('-0.0')\n        >>> ExtendedContext.multiply(Decimal('654321'), Decimal('654321'))\n        Decimal('4.28135971E+11')\n        >>> ExtendedContext.multiply(7, 7)\n        Decimal('49')\n        >>> ExtendedContext.multiply(Decimal(7), 7)\n        Decimal('49')\n        >>> ExtendedContext.multiply(7, Decimal(7))\n        Decimal('49')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        r = a.__mul__(b, context=self)\n        if r is NotImplemented:\n            raise TypeError(\"Unable to convert %s to Decimal\" % b)\n        else:\n            return r\n\n    def next_minus(self, a):\n        \"\"\"Returns the largest representable number smaller than a.\n\n        >>> c = ExtendedContext.copy()\n        >>> c.Emin = -999\n        >>> c.Emax = 999\n        >>> ExtendedContext.next_minus(Decimal('1'))\n        Decimal('0.999999999')\n        >>> c.next_minus(Decimal('1E-1007'))\n        Decimal('0E-1007')\n        >>> ExtendedContext.next_minus(Decimal('-1.00000003'))\n        Decimal('-1.00000004')\n        >>> c.next_minus(Decimal('Infinity'))\n        Decimal('9.99999999E+999')\n        >>> c.next_minus(1)\n        Decimal('0.999999999')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.next_minus(context=self)\n\n    def next_plus(self, a):\n        \"\"\"Returns the smallest representable number larger than a.\n\n        >>> c = ExtendedContext.copy()\n        >>> c.Emin = -999\n        >>> c.Emax = 999\n        >>> ExtendedContext.next_plus(Decimal('1'))\n        Decimal('1.00000001')\n        >>> c.next_plus(Decimal('-1E-1007'))\n        Decimal('-0E-1007')\n        >>> ExtendedContext.next_plus(Decimal('-1.00000003'))\n        Decimal('-1.00000002')\n        >>> c.next_plus(Decimal('-Infinity'))\n        Decimal('-9.99999999E+999')\n        >>> c.next_plus(1)\n        Decimal('1.00000001')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.next_plus(context=self)\n\n    def next_toward(self, a, b):\n        \"\"\"Returns the number closest to a, in direction towards b.\n\n        The result is the closest representable number from the first\n        operand (but not the first operand) that is in the direction\n        towards the second operand, unless the operands have the same\n        value.\n\n        >>> c = ExtendedContext.copy()\n        >>> c.Emin = -999\n        >>> c.Emax = 999\n        >>> c.next_toward(Decimal('1'), Decimal('2'))\n        Decimal('1.00000001')\n        >>> c.next_toward(Decimal('-1E-1007'), Decimal('1'))\n        Decimal('-0E-1007')\n        >>> c.next_toward(Decimal('-1.00000003'), Decimal('0'))\n        Decimal('-1.00000002')\n        >>> c.next_toward(Decimal('1'), Decimal('0'))\n        Decimal('0.999999999')\n        >>> c.next_toward(Decimal('1E-1007'), Decimal('-100'))\n        Decimal('0E-1007')\n        >>> c.next_toward(Decimal('-1.00000003'), Decimal('-10'))\n        Decimal('-1.00000004')\n        >>> c.next_toward(Decimal('0.00'), Decimal('-0.0000'))\n        Decimal('-0.00')\n        >>> c.next_toward(0, 1)\n        Decimal('1E-1007')\n        >>> c.next_toward(Decimal(0), 1)\n        Decimal('1E-1007')\n        >>> c.next_toward(0, Decimal(1))\n        Decimal('1E-1007')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.next_toward(b, context=self)\n\n    def normalize(self, a):\n        \"\"\"normalize reduces an operand to its simplest form.\n\n        Essentially a plus operation with all trailing zeros removed from the\n        result.\n\n        >>> ExtendedContext.normalize(Decimal('2.1'))\n        Decimal('2.1')\n        >>> ExtendedContext.normalize(Decimal('-2.0'))\n        Decimal('-2')\n        >>> ExtendedContext.normalize(Decimal('1.200'))\n        Decimal('1.2')\n        >>> ExtendedContext.normalize(Decimal('-120'))\n        Decimal('-1.2E+2')\n        >>> ExtendedContext.normalize(Decimal('120.00'))\n        Decimal('1.2E+2')\n        >>> ExtendedContext.normalize(Decimal('0.00'))\n        Decimal('0')\n        >>> ExtendedContext.normalize(6)\n        Decimal('6')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.normalize(context=self)\n\n    def number_class(self, a):\n        \"\"\"Returns an indication of the class of the operand.\n\n        The class is one of the following strings:\n          -sNaN\n          -NaN\n          -Infinity\n          -Normal\n          -Subnormal\n          -Zero\n          +Zero\n          +Subnormal\n          +Normal\n          +Infinity\n\n        >>> c = ExtendedContext.copy()\n        >>> c.Emin = -999\n        >>> c.Emax = 999\n        >>> c.number_class(Decimal('Infinity'))\n        '+Infinity'\n        >>> c.number_class(Decimal('1E-10'))\n        '+Normal'\n        >>> c.number_class(Decimal('2.50'))\n        '+Normal'\n        >>> c.number_class(Decimal('0.1E-999'))\n        '+Subnormal'\n        >>> c.number_class(Decimal('0'))\n        '+Zero'\n        >>> c.number_class(Decimal('-0'))\n        '-Zero'\n        >>> c.number_class(Decimal('-0.1E-999'))\n        '-Subnormal'\n        >>> c.number_class(Decimal('-1E-10'))\n        '-Normal'\n        >>> c.number_class(Decimal('-2.50'))\n        '-Normal'\n        >>> c.number_class(Decimal('-Infinity'))\n        '-Infinity'\n        >>> c.number_class(Decimal('NaN'))\n        'NaN'\n        >>> c.number_class(Decimal('-NaN'))\n        'NaN'\n        >>> c.number_class(Decimal('sNaN'))\n        'sNaN'\n        >>> c.number_class(123)\n        '+Normal'\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.number_class(context=self)\n\n    def plus(self, a):\n        \"\"\"Plus corresponds to unary prefix plus in Python.\n\n        The operation is evaluated using the same rules as add; the\n        operation plus(a) is calculated as add('0', a) where the '0'\n        has the same exponent as the operand.\n\n        >>> ExtendedContext.plus(Decimal('1.3'))\n        Decimal('1.3')\n        >>> ExtendedContext.plus(Decimal('-1.3'))\n        Decimal('-1.3')\n        >>> ExtendedContext.plus(-1)\n        Decimal('-1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.__pos__(context=self)\n\n    def power(self, a, b, modulo=None):\n        \"\"\"Raises a to the power of b, to modulo if given.\n\n        With two arguments, compute a**b.  If a is negative then b\n        must be integral.  The result will be inexact unless b is\n        integral and the result is finite and can be expressed exactly\n        in 'precision' digits.\n\n        With three arguments, compute (a**b) % modulo.  For the\n        three argument form, the following restrictions on the\n        arguments hold:\n\n         - all three arguments must be integral\n         - b must be nonnegative\n         - at least one of a or b must be nonzero\n         - modulo must be nonzero and have at most 'precision' digits\n\n        The result of pow(a, b, modulo) is identical to the result\n        that would be obtained by computing (a**b) % modulo with\n        unbounded precision, but is computed more efficiently.  It is\n        always exact.\n\n        >>> c = ExtendedContext.copy()\n        >>> c.Emin = -999\n        >>> c.Emax = 999\n        >>> c.power(Decimal('2'), Decimal('3'))\n        Decimal('8')\n        >>> c.power(Decimal('-2'), Decimal('3'))\n        Decimal('-8')\n        >>> c.power(Decimal('2'), Decimal('-3'))\n        Decimal('0.125')\n        >>> c.power(Decimal('1.7'), Decimal('8'))\n        Decimal('69.7575744')\n        >>> c.power(Decimal('10'), Decimal('0.301029996'))\n        Decimal('2.00000000')\n        >>> c.power(Decimal('Infinity'), Decimal('-1'))\n        Decimal('0')\n        >>> c.power(Decimal('Infinity'), Decimal('0'))\n        Decimal('1')\n        >>> c.power(Decimal('Infinity'), Decimal('1'))\n        Decimal('Infinity')\n        >>> c.power(Decimal('-Infinity'), Decimal('-1'))\n        Decimal('-0')\n        >>> c.power(Decimal('-Infinity'), Decimal('0'))\n        Decimal('1')\n        >>> c.power(Decimal('-Infinity'), Decimal('1'))\n        Decimal('-Infinity')\n        >>> c.power(Decimal('-Infinity'), Decimal('2'))\n        Decimal('Infinity')\n        >>> c.power(Decimal('0'), Decimal('0'))\n        Decimal('NaN')\n\n        >>> c.power(Decimal('3'), Decimal('7'), Decimal('16'))\n        Decimal('11')\n        >>> c.power(Decimal('-3'), Decimal('7'), Decimal('16'))\n        Decimal('-11')\n        >>> c.power(Decimal('-3'), Decimal('8'), Decimal('16'))\n        Decimal('1')\n        >>> c.power(Decimal('3'), Decimal('7'), Decimal('-16'))\n        Decimal('11')\n        >>> c.power(Decimal('23E12345'), Decimal('67E189'), Decimal('123456789'))\n        Decimal('11729830')\n        >>> c.power(Decimal('-0'), Decimal('17'), Decimal('1729'))\n        Decimal('-0')\n        >>> c.power(Decimal('-23'), Decimal('0'), Decimal('65537'))\n        Decimal('1')\n        >>> ExtendedContext.power(7, 7)\n        Decimal('823543')\n        >>> ExtendedContext.power(Decimal(7), 7)\n        Decimal('823543')\n        >>> ExtendedContext.power(7, Decimal(7), 2)\n        Decimal('1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        r = a.__pow__(b, modulo, context=self)\n        if r is NotImplemented:\n            raise TypeError(\"Unable to convert %s to Decimal\" % b)\n        else:\n            return r\n\n    def quantize(self, a, b):\n        \"\"\"Returns a value equal to 'a' (rounded), having the exponent of 'b'.\n\n        The coefficient of the result is derived from that of the left-hand\n        operand.  It may be rounded using the current rounding setting (if the\n        exponent is being increased), multiplied by a positive power of ten (if\n        the exponent is being decreased), or is unchanged (if the exponent is\n        already equal to that of the right-hand operand).\n\n        Unlike other operations, if the length of the coefficient after the\n        quantize operation would be greater than precision then an Invalid\n        operation condition is raised.  This guarantees that, unless there is\n        an error condition, the exponent of the result of a quantize is always\n        equal to that of the right-hand operand.\n\n        Also unlike other operations, quantize will never raise Underflow, even\n        if the result is subnormal and inexact.\n\n        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.001'))\n        Decimal('2.170')\n        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.01'))\n        Decimal('2.17')\n        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.1'))\n        Decimal('2.2')\n        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('1e+0'))\n        Decimal('2')\n        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('1e+1'))\n        Decimal('0E+1')\n        >>> ExtendedContext.quantize(Decimal('-Inf'), Decimal('Infinity'))\n        Decimal('-Infinity')\n        >>> ExtendedContext.quantize(Decimal('2'), Decimal('Infinity'))\n        Decimal('NaN')\n        >>> ExtendedContext.quantize(Decimal('-0.1'), Decimal('1'))\n        Decimal('-0')\n        >>> ExtendedContext.quantize(Decimal('-0'), Decimal('1e+5'))\n        Decimal('-0E+5')\n        >>> ExtendedContext.quantize(Decimal('+35236450.6'), Decimal('1e-2'))\n        Decimal('NaN')\n        >>> ExtendedContext.quantize(Decimal('-35236450.6'), Decimal('1e-2'))\n        Decimal('NaN')\n        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e-1'))\n        Decimal('217.0')\n        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e-0'))\n        Decimal('217')\n        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e+1'))\n        Decimal('2.2E+2')\n        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e+2'))\n        Decimal('2E+2')\n        >>> ExtendedContext.quantize(1, 2)\n        Decimal('1')\n        >>> ExtendedContext.quantize(Decimal(1), 2)\n        Decimal('1')\n        >>> ExtendedContext.quantize(1, Decimal(2))\n        Decimal('1')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.quantize(b, context=self)\n\n    def radix(self):\n        \"\"\"Just returns 10, as this is Decimal, :)\n\n        >>> ExtendedContext.radix()\n        Decimal('10')\n        \"\"\"\n        return Decimal(10)\n\n    def remainder(self, a, b):\n        \"\"\"Returns the remainder from integer division.\n\n        The result is the residue of the dividend after the operation of\n        calculating integer division as described for divide-integer, rounded\n        to precision digits if necessary.  The sign of the result, if\n        non-zero, is the same as that of the original dividend.\n\n        This operation will fail under the same conditions as integer division\n        (that is, if integer division on the same two operands would fail, the\n        remainder cannot be calculated).\n\n        >>> ExtendedContext.remainder(Decimal('2.1'), Decimal('3'))\n        Decimal('2.1')\n        >>> ExtendedContext.remainder(Decimal('10'), Decimal('3'))\n        Decimal('1')\n        >>> ExtendedContext.remainder(Decimal('-10'), Decimal('3'))\n        Decimal('-1')\n        >>> ExtendedContext.remainder(Decimal('10.2'), Decimal('1'))\n        Decimal('0.2')\n        >>> ExtendedContext.remainder(Decimal('10'), Decimal('0.3'))\n        Decimal('0.1')\n        >>> ExtendedContext.remainder(Decimal('3.6'), Decimal('1.3'))\n        Decimal('1.0')\n        >>> ExtendedContext.remainder(22, 6)\n        Decimal('4')\n        >>> ExtendedContext.remainder(Decimal(22), 6)\n        Decimal('4')\n        >>> ExtendedContext.remainder(22, Decimal(6))\n        Decimal('4')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        r = a.__mod__(b, context=self)\n        if r is NotImplemented:\n            raise TypeError(\"Unable to convert %s to Decimal\" % b)\n        else:\n            return r\n\n    def remainder_near(self, a, b):\n        \"\"\"Returns to be \"a - b * n\", where n is the integer nearest the exact\n        value of \"x / b\" (if two integers are equally near then the even one\n        is chosen).  If the result is equal to 0 then its sign will be the\n        sign of a.\n\n        This operation will fail under the same conditions as integer division\n        (that is, if integer division on the same two operands would fail, the\n        remainder cannot be calculated).\n\n        >>> ExtendedContext.remainder_near(Decimal('2.1'), Decimal('3'))\n        Decimal('-0.9')\n        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('6'))\n        Decimal('-2')\n        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('3'))\n        Decimal('1')\n        >>> ExtendedContext.remainder_near(Decimal('-10'), Decimal('3'))\n        Decimal('-1')\n        >>> ExtendedContext.remainder_near(Decimal('10.2'), Decimal('1'))\n        Decimal('0.2')\n        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('0.3'))\n        Decimal('0.1')\n        >>> ExtendedContext.remainder_near(Decimal('3.6'), Decimal('1.3'))\n        Decimal('-0.3')\n        >>> ExtendedContext.remainder_near(3, 11)\n        Decimal('3')\n        >>> ExtendedContext.remainder_near(Decimal(3), 11)\n        Decimal('3')\n        >>> ExtendedContext.remainder_near(3, Decimal(11))\n        Decimal('3')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.remainder_near(b, context=self)\n\n    def rotate(self, a, b):\n        \"\"\"Returns a rotated copy of a, b times.\n\n        The coefficient of the result is a rotated copy of the digits in\n        the coefficient of the first operand.  The number of places of\n        rotation is taken from the absolute value of the second operand,\n        with the rotation being to the left if the second operand is\n        positive or to the right otherwise.\n\n        >>> ExtendedContext.rotate(Decimal('34'), Decimal('8'))\n        Decimal('400000003')\n        >>> ExtendedContext.rotate(Decimal('12'), Decimal('9'))\n        Decimal('12')\n        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('-2'))\n        Decimal('891234567')\n        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('0'))\n        Decimal('123456789')\n        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('+2'))\n        Decimal('345678912')\n        >>> ExtendedContext.rotate(1333333, 1)\n        Decimal('13333330')\n        >>> ExtendedContext.rotate(Decimal(1333333), 1)\n        Decimal('13333330')\n        >>> ExtendedContext.rotate(1333333, Decimal(1))\n        Decimal('13333330')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.rotate(b, context=self)\n\n    def same_quantum(self, a, b):\n        \"\"\"Returns True if the two operands have the same exponent.\n\n        The result is never affected by either the sign or the coefficient of\n        either operand.\n\n        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('0.001'))\n        False\n        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('0.01'))\n        True\n        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('1'))\n        False\n        >>> ExtendedContext.same_quantum(Decimal('Inf'), Decimal('-Inf'))\n        True\n        >>> ExtendedContext.same_quantum(10000, -1)\n        True\n        >>> ExtendedContext.same_quantum(Decimal(10000), -1)\n        True\n        >>> ExtendedContext.same_quantum(10000, Decimal(-1))\n        True\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.same_quantum(b)\n\n    def scaleb (self, a, b):\n        \"\"\"Returns the first operand after adding the second value its exp.\n\n        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('-2'))\n        Decimal('0.0750')\n        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('0'))\n        Decimal('7.50')\n        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('3'))\n        Decimal('7.50E+3')\n        >>> ExtendedContext.scaleb(1, 4)\n        Decimal('1E+4')\n        >>> ExtendedContext.scaleb(Decimal(1), 4)\n        Decimal('1E+4')\n        >>> ExtendedContext.scaleb(1, Decimal(4))\n        Decimal('1E+4')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.scaleb(b, context=self)\n\n    def shift(self, a, b):\n        \"\"\"Returns a shifted copy of a, b times.\n\n        The coefficient of the result is a shifted copy of the digits\n        in the coefficient of the first operand.  The number of places\n        to shift is taken from the absolute value of the second operand,\n        with the shift being to the left if the second operand is\n        positive or to the right otherwise.  Digits shifted into the\n        coefficient are zeros.\n\n        >>> ExtendedContext.shift(Decimal('34'), Decimal('8'))\n        Decimal('400000000')\n        >>> ExtendedContext.shift(Decimal('12'), Decimal('9'))\n        Decimal('0')\n        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('-2'))\n        Decimal('1234567')\n        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('0'))\n        Decimal('123456789')\n        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('+2'))\n        Decimal('345678900')\n        >>> ExtendedContext.shift(88888888, 2)\n        Decimal('888888800')\n        >>> ExtendedContext.shift(Decimal(88888888), 2)\n        Decimal('888888800')\n        >>> ExtendedContext.shift(88888888, Decimal(2))\n        Decimal('888888800')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.shift(b, context=self)\n\n    def sqrt(self, a):\n        \"\"\"Square root of a non-negative number to context precision.\n\n        If the result must be inexact, it is rounded using the round-half-even\n        algorithm.\n\n        >>> ExtendedContext.sqrt(Decimal('0'))\n        Decimal('0')\n        >>> ExtendedContext.sqrt(Decimal('-0'))\n        Decimal('-0')\n        >>> ExtendedContext.sqrt(Decimal('0.39'))\n        Decimal('0.624499800')\n        >>> ExtendedContext.sqrt(Decimal('100'))\n        Decimal('10')\n        >>> ExtendedContext.sqrt(Decimal('1'))\n        Decimal('1')\n        >>> ExtendedContext.sqrt(Decimal('1.0'))\n        Decimal('1.0')\n        >>> ExtendedContext.sqrt(Decimal('1.00'))\n        Decimal('1.0')\n        >>> ExtendedContext.sqrt(Decimal('7'))\n        Decimal('2.64575131')\n        >>> ExtendedContext.sqrt(Decimal('10'))\n        Decimal('3.16227766')\n        >>> ExtendedContext.sqrt(2)\n        Decimal('1.41421356')\n        >>> ExtendedContext.prec\n        9\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.sqrt(context=self)\n\n    def subtract(self, a, b):\n        \"\"\"Return the difference between the two operands.\n\n        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('1.07'))\n        Decimal('0.23')\n        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('1.30'))\n        Decimal('0.00')\n        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('2.07'))\n        Decimal('-0.77')\n        >>> ExtendedContext.subtract(8, 5)\n        Decimal('3')\n        >>> ExtendedContext.subtract(Decimal(8), 5)\n        Decimal('3')\n        >>> ExtendedContext.subtract(8, Decimal(5))\n        Decimal('3')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        r = a.__sub__(b, context=self)\n        if r is NotImplemented:\n            raise TypeError(\"Unable to convert %s to Decimal\" % b)\n        else:\n            return r\n\n    def to_eng_string(self, a):\n        \"\"\"Converts a number to a string, using scientific notation.\n\n        The operation is not affected by the context.\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.to_eng_string(context=self)\n\n    def to_sci_string(self, a):\n        \"\"\"Converts a number to a string, using scientific notation.\n\n        The operation is not affected by the context.\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.__str__(context=self)\n\n    def to_integral_exact(self, a):\n        \"\"\"Rounds to an integer.\n\n        When the operand has a negative exponent, the result is the same\n        as using the quantize() operation using the given operand as the\n        left-hand-operand, 1E+0 as the right-hand-operand, and the precision\n        of the operand as the precision setting; Inexact and Rounded flags\n        are allowed in this operation.  The rounding mode is taken from the\n        context.\n\n        >>> ExtendedContext.to_integral_exact(Decimal('2.1'))\n        Decimal('2')\n        >>> ExtendedContext.to_integral_exact(Decimal('100'))\n        Decimal('100')\n        >>> ExtendedContext.to_integral_exact(Decimal('100.0'))\n        Decimal('100')\n        >>> ExtendedContext.to_integral_exact(Decimal('101.5'))\n        Decimal('102')\n        >>> ExtendedContext.to_integral_exact(Decimal('-101.5'))\n        Decimal('-102')\n        >>> ExtendedContext.to_integral_exact(Decimal('10E+5'))\n        Decimal('1.0E+6')\n        >>> ExtendedContext.to_integral_exact(Decimal('7.89E+77'))\n        Decimal('7.89E+77')\n        >>> ExtendedContext.to_integral_exact(Decimal('-Inf'))\n        Decimal('-Infinity')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.to_integral_exact(context=self)\n\n    def to_integral_value(self, a):\n        \"\"\"Rounds to an integer.\n\n        When the operand has a negative exponent, the result is the same\n        as using the quantize() operation using the given operand as the\n        left-hand-operand, 1E+0 as the right-hand-operand, and the precision\n        of the operand as the precision setting, except that no flags will\n        be set.  The rounding mode is taken from the context.\n\n        >>> ExtendedContext.to_integral_value(Decimal('2.1'))\n        Decimal('2')\n        >>> ExtendedContext.to_integral_value(Decimal('100'))\n        Decimal('100')\n        >>> ExtendedContext.to_integral_value(Decimal('100.0'))\n        Decimal('100')\n        >>> ExtendedContext.to_integral_value(Decimal('101.5'))\n        Decimal('102')\n        >>> ExtendedContext.to_integral_value(Decimal('-101.5'))\n        Decimal('-102')\n        >>> ExtendedContext.to_integral_value(Decimal('10E+5'))\n        Decimal('1.0E+6')\n        >>> ExtendedContext.to_integral_value(Decimal('7.89E+77'))\n        Decimal('7.89E+77')\n        >>> ExtendedContext.to_integral_value(Decimal('-Inf'))\n        Decimal('-Infinity')\n        \"\"\"\n        a = _convert_other(a, raiseit=True)\n        return a.to_integral_value(context=self)\n\n    # the method name changed, but we provide also the old one, for compatibility\n    to_integral = to_integral_value\n\nclass _WorkRep(object):\n    __slots__ = ('sign','int','exp')\n    # sign: 0 or 1\n    # int:  int\n    # exp:  None, int, or string\n\n    def __init__(self, value=None):\n        if value is None:\n            self.sign = None\n            self.int = 0\n            self.exp = None\n        elif isinstance(value, Decimal):\n            self.sign = value._sign\n            self.int = int(value._int)\n            self.exp = value._exp\n        else:\n            # assert isinstance(value, tuple)\n            self.sign = value[0]\n            self.int = value[1]\n            self.exp = value[2]\n\n    def __repr__(self):\n        return \"(%r, %r, %r)\" % (self.sign, self.int, self.exp)\n\n    __str__ = __repr__\n\n\n\ndef _normalize(op1, op2, prec = 0):\n    \"\"\"Normalizes op1, op2 to have the same exp and length of coefficient.\n\n    Done during addition.\n    \"\"\"\n    if op1.exp < op2.exp:\n        tmp = op2\n        other = op1\n    else:\n        tmp = op1\n        other = op2\n\n    # Let exp = min(tmp.exp - 1, tmp.adjusted() - precision - 1).\n    # Then adding 10**exp to tmp has the same effect (after rounding)\n    # as adding any positive quantity smaller than 10**exp; similarly\n    # for subtraction.  So if other is smaller than 10**exp we replace\n    # it with 10**exp.  This avoids tmp.exp - other.exp getting too large.\n    tmp_len = len(str(tmp.int))\n    other_len = len(str(other.int))\n    exp = tmp.exp + min(-1, tmp_len - prec - 2)\n    if other_len + other.exp - 1 < exp:\n        other.int = 1\n        other.exp = exp\n\n    tmp.int *= 10 ** (tmp.exp - other.exp)\n    tmp.exp = other.exp\n    return op1, op2\n\n##### Integer arithmetic functions used by ln, log10, exp and __pow__ #####\n\n_nbits = int.bit_length\n\ndef _decimal_lshift_exact(n, e):\n    \"\"\" Given integers n and e, return n * 10**e if it's an integer, else None.\n\n    The computation is designed to avoid computing large powers of 10\n    unnecessarily.\n\n    >>> _decimal_lshift_exact(3, 4)\n    30000\n    >>> _decimal_lshift_exact(300, -999999999)  # returns None\n\n    \"\"\"\n    if n == 0:\n        return 0\n    elif e >= 0:\n        return n * 10**e\n    else:\n        # val_n = largest power of 10 dividing n.\n        str_n = str(abs(n))\n        val_n = len(str_n) - len(str_n.rstrip('0'))\n        return None if val_n < -e else n // 10**-e\n\ndef _sqrt_nearest(n, a):\n    \"\"\"Closest integer to the square root of the positive integer n.  a is\n    an initial approximation to the square root.  Any positive integer\n    will do for a, but the closer a is to the square root of n the\n    faster convergence will be.\n\n    \"\"\"\n    if n <= 0 or a <= 0:\n        raise ValueError(\"Both arguments to _sqrt_nearest should be positive.\")\n\n    b=0\n    while a != b:\n        b, a = a, a--n//a>>1\n    return a\n\ndef _rshift_nearest(x, shift):\n    \"\"\"Given an integer x and a nonnegative integer shift, return closest\n    integer to x / 2**shift; use round-to-even in case of a tie.\n\n    \"\"\"\n    b, q = 1 << shift, x >> shift\n    return q + (2*(x & (b-1)) + (q&1) > b)\n\ndef _div_nearest(a, b):\n    \"\"\"Closest integer to a/b, a and b positive integers; rounds to even\n    in the case of a tie.\n\n    \"\"\"\n    q, r = divmod(a, b)\n    return q + (2*r + (q&1) > b)\n\ndef _ilog(x, M, L = 8):\n    \"\"\"Integer approximation to M*log(x/M), with absolute error boundable\n    in terms only of x/M.\n\n    Given positive integers x and M, return an integer approximation to\n    M * log(x/M).  For L = 8 and 0.1 <= x/M <= 10 the difference\n    between the approximation and the exact result is at most 22.  For\n    L = 8 and 1.0 <= x/M <= 10.0 the difference is at most 15.  In\n    both cases these are upper bounds on the error; it will usually be\n    much smaller.\"\"\"\n\n    # The basic algorithm is the following: let log1p be the function\n    # log1p(x) = log(1+x).  Then log(x/M) = log1p((x-M)/M).  We use\n    # the reduction\n    #\n    #    log1p(y) = 2*log1p(y/(1+sqrt(1+y)))\n    #\n    # repeatedly until the argument to log1p is small (< 2**-L in\n    # absolute value).  For small y we can use the Taylor series\n    # expansion\n    #\n    #    log1p(y) ~ y - y**2/2 + y**3/3 - ... - (-y)**T/T\n    #\n    # truncating at T such that y**T is small enough.  The whole\n    # computation is carried out in a form of fixed-point arithmetic,\n    # with a real number z being represented by an integer\n    # approximation to z*M.  To avoid loss of precision, the y below\n    # is actually an integer approximation to 2**R*y*M, where R is the\n    # number of reductions performed so far.\n\n    y = x-M\n    # argument reduction; R = number of reductions performed\n    R = 0\n    while (R <= L and abs(y) << L-R >= M or\n           R > L and abs(y) >> R-L >= M):\n        y = _div_nearest((M*y) << 1,\n                         M + _sqrt_nearest(M*(M+_rshift_nearest(y, R)), M))\n        R += 1\n\n    # Taylor series with T terms\n    T = -int(-10*len(str(M))//(3*L))\n    yshift = _rshift_nearest(y, R)\n    w = _div_nearest(M, T)\n    for k in range(T-1, 0, -1):\n        w = _div_nearest(M, k) - _div_nearest(yshift*w, M)\n\n    return _div_nearest(w*y, M)\n\ndef _dlog10(c, e, p):\n    \"\"\"Given integers c, e and p with c > 0, p >= 0, compute an integer\n    approximation to 10**p * log10(c*10**e), with an absolute error of\n    at most 1.  Assumes that c*10**e is not exactly 1.\"\"\"\n\n    # increase precision by 2; compensate for this by dividing\n    # final result by 100\n    p += 2\n\n    # write c*10**e as d*10**f with either:\n    #   f >= 0 and 1 <= d <= 10, or\n    #   f <= 0 and 0.1 <= d <= 1.\n    # Thus for c*10**e close to 1, f = 0\n    l = len(str(c))\n    f = e+l - (e+l >= 1)\n\n    if p > 0:\n        M = 10**p\n        k = e+p-f\n        if k >= 0:\n            c *= 10**k\n        else:\n            c = _div_nearest(c, 10**-k)\n\n        log_d = _ilog(c, M) # error < 5 + 22 = 27\n        log_10 = _log10_digits(p) # error < 1\n        log_d = _div_nearest(log_d*M, log_10)\n        log_tenpower = f*M # exact\n    else:\n        log_d = 0  # error < 2.31\n        log_tenpower = _div_nearest(f, 10**-p) # error < 0.5\n\n    return _div_nearest(log_tenpower+log_d, 100)\n\ndef _dlog(c, e, p):\n    \"\"\"Given integers c, e and p with c > 0, compute an integer\n    approximation to 10**p * log(c*10**e), with an absolute error of\n    at most 1.  Assumes that c*10**e is not exactly 1.\"\"\"\n\n    # Increase precision by 2. The precision increase is compensated\n    # for at the end with a division by 100.\n    p += 2\n\n    # rewrite c*10**e as d*10**f with either f >= 0 and 1 <= d <= 10,\n    # or f <= 0 and 0.1 <= d <= 1.  Then we can compute 10**p * log(c*10**e)\n    # as 10**p * log(d) + 10**p*f * log(10).\n    l = len(str(c))\n    f = e+l - (e+l >= 1)\n\n    # compute approximation to 10**p*log(d), with error < 27\n    if p > 0:\n        k = e+p-f\n        if k >= 0:\n            c *= 10**k\n        else:\n            c = _div_nearest(c, 10**-k)  # error of <= 0.5 in c\n\n        # _ilog magnifies existing error in c by a factor of at most 10\n        log_d = _ilog(c, 10**p) # error < 5 + 22 = 27\n    else:\n        # p <= 0: just approximate the whole thing by 0; error < 2.31\n        log_d = 0\n\n    # compute approximation to f*10**p*log(10), with error < 11.\n    if f:\n        extra = len(str(abs(f)))-1\n        if p + extra >= 0:\n            # error in f * _log10_digits(p+extra) < |f| * 1 = |f|\n            # after division, error < |f|/10**extra + 0.5 < 10 + 0.5 < 11\n            f_log_ten = _div_nearest(f*_log10_digits(p+extra), 10**extra)\n        else:\n            f_log_ten = 0\n    else:\n        f_log_ten = 0\n\n    # error in sum < 11+27 = 38; error after division < 0.38 + 0.5 < 1\n    return _div_nearest(f_log_ten + log_d, 100)\n\nclass _Log10Memoize(object):\n    \"\"\"Class to compute, store, and allow retrieval of, digits of the\n    constant log(10) = 2.302585....  This constant is needed by\n    Decimal.ln, Decimal.log10, Decimal.exp and Decimal.__pow__.\"\"\"\n    def __init__(self):\n        self.digits = \"23025850929940456840179914546843642076011014886\"\n\n    def getdigits(self, p):\n        \"\"\"Given an integer p >= 0, return floor(10**p)*log(10).\n\n        For example, self.getdigits(3) returns 2302.\n        \"\"\"\n        # digits are stored as a string, for quick conversion to\n        # integer in the case that we've already computed enough\n        # digits; the stored digits should always be correct\n        # (truncated, not rounded to nearest).\n        if p < 0:\n            raise ValueError(\"p should be nonnegative\")\n\n        if p >= len(self.digits):\n            # compute p+3, p+6, p+9, ... digits; continue until at\n            # least one of the extra digits is nonzero\n            extra = 3\n            while True:\n                # compute p+extra digits, correct to within 1ulp\n                M = 10**(p+extra+2)\n                digits = str(_div_nearest(_ilog(10*M, M), 100))\n                if digits[-extra:] != '0'*extra:\n                    break\n                extra += 3\n            # keep all reliable digits so far; remove trailing zeros\n            # and next nonzero digit\n            self.digits = digits.rstrip('0')[:-1]\n        return int(self.digits[:p+1])\n\n_log10_digits = _Log10Memoize().getdigits\n\ndef _iexp(x, M, L=8):\n    \"\"\"Given integers x and M, M > 0, such that x/M is small in absolute\n    value, compute an integer approximation to M*exp(x/M).  For 0 <=\n    x/M <= 2.4, the absolute error in the result is bounded by 60 (and\n    is usually much smaller).\"\"\"\n\n    # Algorithm: to compute exp(z) for a real number z, first divide z\n    # by a suitable power R of 2 so that |z/2**R| < 2**-L.  Then\n    # compute expm1(z/2**R) = exp(z/2**R) - 1 using the usual Taylor\n    # series\n    #\n    #     expm1(x) = x + x**2/2! + x**3/3! + ...\n    #\n    # Now use the identity\n    #\n    #     expm1(2x) = expm1(x)*(expm1(x)+2)\n    #\n    # R times to compute the sequence expm1(z/2**R),\n    # expm1(z/2**(R-1)), ... , exp(z/2), exp(z).\n\n    # Find R such that x/2**R/M <= 2**-L\n    R = _nbits((x<<L)//M)\n\n    # Taylor series.  (2**L)**T > M\n    T = -int(-10*len(str(M))//(3*L))\n    y = _div_nearest(x, T)\n    Mshift = M<<R\n    for i in range(T-1, 0, -1):\n        y = _div_nearest(x*(Mshift + y), Mshift * i)\n\n    # Expansion\n    for k in range(R-1, -1, -1):\n        Mshift = M<<(k+2)\n        y = _div_nearest(y*(y+Mshift), Mshift)\n\n    return M+y\n\ndef _dexp(c, e, p):\n    \"\"\"Compute an approximation to exp(c*10**e), with p decimal places of\n    precision.\n\n    Returns integers d, f such that:\n\n      10**(p-1) <= d <= 10**p, and\n      (d-1)*10**f < exp(c*10**e) < (d+1)*10**f\n\n    In other words, d*10**f is an approximation to exp(c*10**e) with p\n    digits of precision, and with an error in d of at most 1.  This is\n    almost, but not quite, the same as the error being < 1ulp: when d\n    = 10**(p-1) the error could be up to 10 ulp.\"\"\"\n\n    # we'll call iexp with M = 10**(p+2), giving p+3 digits of precision\n    p += 2\n\n    # compute log(10) with extra precision = adjusted exponent of c*10**e\n    extra = max(0, e + len(str(c)) - 1)\n    q = p + extra\n\n    # compute quotient c*10**e/(log(10)) = c*10**(e+q)/(log(10)*10**q),\n    # rounding down\n    shift = e+q\n    if shift >= 0:\n        cshift = c*10**shift\n    else:\n        cshift = c//10**-shift\n    quot, rem = divmod(cshift, _log10_digits(q))\n\n    # reduce remainder back to original precision\n    rem = _div_nearest(rem, 10**extra)\n\n    # error in result of _iexp < 120;  error after division < 0.62\n    return _div_nearest(_iexp(rem, 10**p), 1000), quot - p + 3\n\ndef _dpower(xc, xe, yc, ye, p):\n    \"\"\"Given integers xc, xe, yc and ye representing Decimals x = xc*10**xe and\n    y = yc*10**ye, compute x**y.  Returns a pair of integers (c, e) such that:\n\n      10**(p-1) <= c <= 10**p, and\n      (c-1)*10**e < x**y < (c+1)*10**e\n\n    in other words, c*10**e is an approximation to x**y with p digits\n    of precision, and with an error in c of at most 1.  (This is\n    almost, but not quite, the same as the error being < 1ulp: when c\n    == 10**(p-1) we can only guarantee error < 10ulp.)\n\n    We assume that: x is positive and not equal to 1, and y is nonzero.\n    \"\"\"\n\n    # Find b such that 10**(b-1) <= |y| <= 10**b\n    b = len(str(abs(yc))) + ye\n\n    # log(x) = lxc*10**(-p-b-1), to p+b+1 places after the decimal point\n    lxc = _dlog(xc, xe, p+b+1)\n\n    # compute product y*log(x) = yc*lxc*10**(-p-b-1+ye) = pc*10**(-p-1)\n    shift = ye-b\n    if shift >= 0:\n        pc = lxc*yc*10**shift\n    else:\n        pc = _div_nearest(lxc*yc, 10**-shift)\n\n    if pc == 0:\n        # we prefer a result that isn't exactly 1; this makes it\n        # easier to compute a correctly rounded result in __pow__\n        if ((len(str(xc)) + xe >= 1) == (yc > 0)): # if x**y > 1:\n            coeff, exp = 10**(p-1)+1, 1-p\n        else:\n            coeff, exp = 10**p-1, -p\n    else:\n        coeff, exp = _dexp(pc, -(p+1), p+1)\n        coeff = _div_nearest(coeff, 10)\n        exp += 1\n\n    return coeff, exp\n\ndef _log10_lb(c, correction = {\n        '1': 100, '2': 70, '3': 53, '4': 40, '5': 31,\n        '6': 23, '7': 16, '8': 10, '9': 5}):\n    \"\"\"Compute a lower bound for 100*log10(c) for a positive integer c.\"\"\"\n    if c <= 0:\n        raise ValueError(\"The argument to _log10_lb should be nonnegative.\")\n    str_c = str(c)\n    return 100*len(str_c) - correction[str_c[0]]\n\n##### Helper Functions ####################################################\n\ndef _convert_other(other, raiseit=False, allow_float=False):\n    \"\"\"Convert other to Decimal.\n\n    Verifies that it's ok to use in an implicit construction.\n    If allow_float is true, allow conversion from float;  this\n    is used in the comparison methods (__eq__ and friends).\n\n    \"\"\"\n    if isinstance(other, Decimal):\n        return other\n    if isinstance(other, int):\n        return Decimal(other)\n    if allow_float and isinstance(other, float):\n        return Decimal.from_float(other)\n\n    if raiseit:\n        raise TypeError(\"Unable to convert %s to Decimal\" % other)\n    return NotImplemented\n\ndef _convert_for_comparison(self, other, equality_op=False):\n    \"\"\"Given a Decimal instance self and a Python object other, return\n    a pair (s, o) of Decimal instances such that \"s op o\" is\n    equivalent to \"self op other\" for any of the 6 comparison\n    operators \"op\".\n\n    \"\"\"\n    if isinstance(other, Decimal):\n        return self, other\n\n    # Comparison with a Rational instance (also includes integers):\n    # self op n/d <=> self*d op n (for n and d integers, d positive).\n    # A NaN or infinity can be left unchanged without affecting the\n    # comparison result.\n    if isinstance(other, _numbers.Rational):\n        if not self._is_special:\n            self = _dec_from_triple(self._sign,\n                                    str(int(self._int) * other.denominator),\n                                    self._exp)\n        return self, Decimal(other.numerator)\n\n    # Comparisons with float and complex types.  == and != comparisons\n    # with complex numbers should succeed, returning either True or False\n    # as appropriate.  Other comparisons return NotImplemented.\n    if equality_op and isinstance(other, _numbers.Complex) and other.imag == 0:\n        other = other.real\n    if isinstance(other, float):\n        context = getcontext()\n        if equality_op:\n            context.flags[FloatOperation] = 1\n        else:\n            context._raise_error(FloatOperation,\n                \"strict semantics for mixing floats and Decimals are enabled\")\n        return self, Decimal.from_float(other)\n    return NotImplemented, NotImplemented\n\n\n##### Setup Specific Contexts ############################################\n\n# The default context prototype used by Context()\n# Is mutable, so that new contexts can have different default values\n\nDefaultContext = Context(\n        prec=17, rounding=ROUND_HALF_EVEN,\n        traps=[DivisionByZero, Overflow, InvalidOperation],\n        flags=[],\n        Emax=308,\n        Emin=-324,\n        capitals=1,\n        clamp=0\n)\n\n# Pre-made alternate contexts offered by the specification\n# Don't change these; the user should be able to select these\n# contexts and be able to reproduce results from other implementations\n# of the spec.\n\nBasicContext = Context(\n        prec=9, rounding=ROUND_HALF_UP,\n        traps=[DivisionByZero, Overflow, InvalidOperation, Clamped, Underflow],\n        flags=[],\n)\n\nExtendedContext = Context(\n        prec=9, rounding=ROUND_HALF_EVEN,\n        traps=[],\n        flags=[],\n)\n\n\n##### crud for parsing strings #############################################\n#\n# Regular expression used for parsing numeric strings.  Additional\n# comments:\n#\n# 1. Uncomment the two '\\s*' lines to allow leading and/or trailing\n# whitespace.  But note that the specification disallows whitespace in\n# a numeric string.\n#\n# 2. For finite numbers (not infinities and NaNs) the body of the\n# number between the optional sign and the optional exponent must have\n# at least one decimal digit, possibly after the decimal point.  The\n# lookahead expression '(?=\\d|\\.\\d)' checks this.\n\nimport re\n_parser = re.compile(r\"\"\"        # A numeric string consists of:\n#    \\s*\n    (?P<sign>[-+])?              # an optional sign, followed by either...\n    (\n        (?=\\d|\\.\\d)              # ...a number (with at least one digit)\n        (?P<int>\\d*)             # having a (possibly empty) integer part\n        (\\.(?P<frac>\\d*))?       # followed by an optional fractional part\n        (E(?P<exp>[-+]?\\d+))?    # followed by an optional exponent, or...\n    |\n        Inf(inity)?              # ...an infinity, or...\n    |\n        (?P<signal>s)?           # ...an (optionally signaling)\n        NaN                      # NaN\n        (?P<diag>\\d*)            # with (possibly empty) diagnostic info.\n    )\n#    \\s*\n    \\Z\n\"\"\", re.VERBOSE | re.IGNORECASE).match\n\n_all_zeros = re.compile('0*$').match\n_exact_half = re.compile('50*$').match\n\n##### PEP3101 support functions ##############################################\n# The functions in this section have little to do with the Decimal\n# class, and could potentially be reused or adapted for other pure\n# Python numeric classes that want to implement __format__\n#\n# A format specifier for Decimal looks like:\n#\n#   [[fill]align][sign][#][0][minimumwidth][,][.precision][type]\n\n_parse_format_specifier_regex = re.compile(r\"\"\"\\A\n(?:\n   (?P<fill>.)?\n   (?P<align>[<>=^])\n)?\n(?P<sign>[-+ ])?\n(?P<alt>\\#)?\n(?P<zeropad>0)?\n(?P<minimumwidth>(?!0)\\d+)?\n(?P<thousands_sep>,)?\n(?:\\.(?P<precision>0|(?!0)\\d+))?\n(?P<type>[eEfFgGn%])?\n\\Z\n\"\"\", re.VERBOSE|re.DOTALL)\n\ndel re\n\n# The locale module is only needed for the 'n' format specifier.  The\n# rest of the PEP 3101 code functions quite happily without it, so we\n# don't care too much if locale isn't present.\ntry:\n    import locale as _locale\nexcept ImportError:\n    pass\n\ndef _parse_format_specifier(format_spec, _localeconv=None):\n    \"\"\"Parse and validate a format specifier.\n\n    Turns a standard numeric format specifier into a dict, with the\n    following entries:\n\n      fill: fill character to pad field to minimum width\n      align: alignment type, either '<', '>', '=' or '^'\n      sign: either '+', '-' or ' '\n      minimumwidth: nonnegative integer giving minimum width\n      zeropad: boolean, indicating whether to pad with zeros\n      thousands_sep: string to use as thousands separator, or ''\n      grouping: grouping for thousands separators, in format\n        used by localeconv\n      decimal_point: string to use for decimal point\n      precision: nonnegative integer giving precision, or None\n      type: one of the characters 'eEfFgG%', or None\n\n    \"\"\"\n    m = _parse_format_specifier_regex.match(format_spec)\n    if m is None:\n        raise ValueError(\"Invalid format specifier: \" + format_spec)\n\n    # get the dictionary\n    format_dict = m.groupdict()\n\n    # zeropad; defaults for fill and alignment.  If zero padding\n    # is requested, the fill and align fields should be absent.\n    fill = format_dict['fill']\n    align = format_dict['align']\n    format_dict['zeropad'] = (format_dict['zeropad'] is not None)\n    if format_dict['zeropad']:\n        if fill is not None:\n            raise ValueError(\"Fill character conflicts with '0'\"\n                             \" in format specifier: \" + format_spec)\n        if align is not None:\n            raise ValueError(\"Alignment conflicts with '0' in \"\n                             \"format specifier: \" + format_spec)\n    format_dict['fill'] = fill or ' '\n    # PEP 3101 originally specified that the default alignment should\n    # be left;  it was later agreed that right-aligned makes more sense\n    # for numeric types.  See http://bugs.python.org/issue6857.\n    format_dict['align'] = align or '>'\n\n    # default sign handling: '-' for negative, '' for positive\n    if format_dict['sign'] is None:\n        format_dict['sign'] = '-'\n\n    # minimumwidth defaults to 0; precision remains None if not given\n    format_dict['minimumwidth'] = int(format_dict['minimumwidth'] or '0')\n    if format_dict['precision'] is not None:\n        format_dict['precision'] = int(format_dict['precision'])\n\n    # if format type is 'g' or 'G' then a precision of 0 makes little\n    # sense; convert it to 1.  Same if format type is unspecified.\n    if format_dict['precision'] == 0:\n        if format_dict['type'] is None or format_dict['type'] in 'gGn':\n            format_dict['precision'] = 1\n\n    # determine thousands separator, grouping, and decimal separator, and\n    # add appropriate entries to format_dict\n    if format_dict['type'] == 'n':\n        # apart from separators, 'n' behaves just like 'g'\n        format_dict['type'] = 'g'\n        if _localeconv is None:\n            _localeconv = _locale.localeconv()\n        if format_dict['thousands_sep'] is not None:\n            raise ValueError(\"Explicit thousands separator conflicts with \"\n                             \"'n' type in format specifier: \" + format_spec)\n        format_dict['thousands_sep'] = _localeconv['thousands_sep']\n        format_dict['grouping'] = _localeconv['grouping']\n        format_dict['decimal_point'] = _localeconv['decimal_point']\n    else:\n        if format_dict['thousands_sep'] is None:\n            format_dict['thousands_sep'] = ''\n        format_dict['grouping'] = [3, 0]\n        format_dict['decimal_point'] = '.'\n\n    return format_dict\n\ndef _format_align(sign, body, spec):\n    \"\"\"Given an unpadded, non-aligned numeric string 'body' and sign\n    string 'sign', add padding and alignment conforming to the given\n    format specifier dictionary 'spec' (as produced by\n    parse_format_specifier).\n\n    \"\"\"\n    # how much extra space do we have to play with?\n    minimumwidth = spec['minimumwidth']\n    fill = spec['fill']\n    padding = fill*(minimumwidth - len(sign) - len(body))\n\n    align = spec['align']\n    if align == '<':\n        result = sign + body + padding\n    elif align == '>':\n        result = padding + sign + body\n    elif align == '=':\n        result = sign + padding + body\n    elif align == '^':\n        half = len(padding)//2\n        result = padding[:half] + sign + body + padding[half:]\n    else:\n        raise ValueError('Unrecognised alignment field')\n\n    return result\n\ndef _group_lengths(grouping):\n    \"\"\"Convert a localeconv-style grouping into a (possibly infinite)\n    iterable of integers representing group lengths.\n\n    \"\"\"\n    # The result from localeconv()['grouping'], and the input to this\n    # function, should be a list of integers in one of the\n    # following three forms:\n    #\n    #   (1) an empty list, or\n    #   (2) nonempty list of positive integers + [0]\n    #   (3) list of positive integers + [locale.CHAR_MAX], or\n\n    from itertools import chain, repeat\n    if not grouping:\n        return []\n    elif grouping[-1] == 0 and len(grouping) >= 2:\n        return chain(grouping[:-1], repeat(grouping[-2]))\n    elif grouping[-1] == _locale.CHAR_MAX:\n        return grouping[:-1]\n    else:\n        raise ValueError('unrecognised format for grouping')\n\ndef _insert_thousands_sep(digits, spec, min_width=1):\n    \"\"\"Insert thousands separators into a digit string.\n\n    spec is a dictionary whose keys should include 'thousands_sep' and\n    'grouping'; typically it's the result of parsing the format\n    specifier using _parse_format_specifier.\n\n    The min_width keyword argument gives the minimum length of the\n    result, which will be padded on the left with zeros if necessary.\n\n    If necessary, the zero padding adds an extra '0' on the left to\n    avoid a leading thousands separator.  For example, inserting\n    commas every three digits in '123456', with min_width=8, gives\n    '0,123,456', even though that has length 9.\n\n    \"\"\"\n\n    sep = spec['thousands_sep']\n    grouping = spec['grouping']\n\n    groups = []\n    for l in _group_lengths(grouping):\n        if l <= 0:\n            raise ValueError(\"group length should be positive\")\n        # max(..., 1) forces at least 1 digit to the left of a separator\n        l = min(max(len(digits), min_width, 1), l)\n        groups.append('0'*(l - len(digits)) + digits[-l:])\n        digits = digits[:-l]\n        min_width -= l\n        if not digits and min_width <= 0:\n            break\n        min_width -= len(sep)\n    else:\n        l = max(len(digits), min_width, 1)\n        groups.append('0'*(l - len(digits)) + digits[-l:])\n    return sep.join(reversed(groups))\n\ndef _format_sign(is_negative, spec):\n    \"\"\"Determine sign character.\"\"\"\n\n    if is_negative:\n        return '-'\n    elif spec['sign'] in ' +':\n        return spec['sign']\n    else:\n        return ''\n\ndef _format_number(is_negative, intpart, fracpart, exp, spec):\n    \"\"\"Format a number, given the following data:\n\n    is_negative: true if the number is negative, else false\n    intpart: string of digits that must appear before the decimal point\n    fracpart: string of digits that must come after the point\n    exp: exponent, as an integer\n    spec: dictionary resulting from parsing the format specifier\n\n    This function uses the information in spec to:\n      insert separators (decimal separator and thousands separators)\n      format the sign\n      format the exponent\n      add trailing '%' for the '%' type\n      zero-pad if necessary\n      fill and align if necessary\n    \"\"\"\n\n    sign = _format_sign(is_negative, spec)\n\n    if fracpart or spec['alt']:\n        fracpart = spec['decimal_point'] + fracpart\n\n    if exp != 0 or spec['type'] in 'eE':\n        echar = {'E': 'E', 'e': 'e', 'G': 'E', 'g': 'e'}[spec['type']]\n        fracpart += \"{0}{1:+}\".format(echar, exp)\n    if spec['type'] == '%':\n        fracpart += '%'\n\n    if spec['zeropad']:\n        min_width = spec['minimumwidth'] - len(fracpart) - len(sign)\n    else:\n        min_width = 0\n    intpart = _insert_thousands_sep(intpart, spec, min_width)\n\n    return _format_align(sign, intpart+fracpart, spec)\n\n\n##### Useful Constants (internal use only) ################################\n\n# Reusable defaults\n_Infinity = Decimal('Inf')\n_NegativeInfinity = Decimal('-Inf')\n_NaN = Decimal('NaN')\n_Zero = Decimal(0)\n_One = Decimal(1)\n_NegativeOne = Decimal(-1)\n\n# _SignedInfinity[sign] is infinity w/ that sign\n_SignedInfinity = (_Infinity, _NegativeInfinity)\n\n# Constants related to the hash implementation;  hash(x) is based\n# on the reduction of x modulo _PyHASH_MODULUS\n_PyHASH_MODULUS = sys.hash_info.modulus\n# hash values to use for positive and negative infinities, and nans\n_PyHASH_INF = sys.hash_info.inf\n_PyHASH_NAN = sys.hash_info.nan\n\n# _PyHASH_10INV is the inverse of 10 modulo the prime _PyHASH_MODULUS\n_PyHASH_10INV = pow(10, _PyHASH_MODULUS - 2, _PyHASH_MODULUS)\ndel sys\n\ntry:\n    import _decimal\nexcept ImportError:\n    pass\nelse:\n    s1 = set(dir())\n    s2 = set(dir(_decimal))\n    for name in s1 - s2:\n        del globals()[name]\n    del s1, s2, name\n    from _decimal import *\n\nif __name__ == '__main__':\n    import doctest, decimal\n    doctest.testmod(decimal)\n"], "dis": [".js", "var $module=(function($B){\n\nvar mod = {\n    dis:function(src){\n        return __BRYTHON__.py2js(src,'__main__','__main__','__builtins__').to_js()\n    }\n}\nreturn mod\n\n})(__BRYTHON__)"], "xml.etree.cElementTree": [".py", "# Deprecated alias for xml.etree.ElementTree\n\nfrom xml.etree.ElementTree import *\n"], "locale": [".py", "def getdefaultlocale():\n    return __BRYTHON__.language,None\n\ndef localeconv():\n        \"\"\" localeconv() -> dict.\n            Returns numeric and monetary locale-specific parameters.\n        \"\"\"\n        # 'C' locale default values\n        return {'grouping': [127],\n                'currency_symbol': '',\n                'n_sign_posn': 127,\n                'p_cs_precedes': 127,\n                'n_cs_precedes': 127,\n                'mon_grouping': [],\n                'n_sep_by_space': 127,\n                'decimal_point': '.',\n                'negative_sign': '',\n                'positive_sign': '',\n                'p_sep_by_space': 127,\n                'decimal_point': '.',\n                'negative_sign': '',\n                'positive_sign': '',\n                'p_sep_by_space': 127,\n                'int_curr_symbol': '',\n                'p_sign_posn': 127,\n                'thousands_sep': '',\n                'mon_thousands_sep': '',\n                'frac_digits': 127,\n                'mon_decimal_point': '',\n                'int_frac_digits': 127}\n\ndef setlocale(category, value=None):\n        \"\"\" setlocale(integer,string=None) -> string.\n            Activates/queries locale processing.\n        \"\"\"\n        if value not in (None, '', 'C'):\n            raise Error('_locale emulation only supports \"C\" locale')\n        return 'C'\n\nCHAR_MAX = 127\nLC_ALL = 6\nLC_COLLATE = 3\nLC_CTYPE = 0\nLC_MESSAGES = 5\nLC_MONETARY = 4\nLC_NUMERIC = 1\nLC_TIME = 2\nError = ValueError\n\n\ndef getlocale(category=LC_CTYPE):\n\n    \"\"\" Returns the current setting for the given locale category as\n        tuple (language code, encoding).\n\n        category may be one of the LC_* value except LC_ALL. It\n        defaults to LC_CTYPE.\n\n        Except for the code 'C', the language code corresponds to RFC\n        1766.  code and encoding can be None in case the values cannot\n        be determined.\n\n    \"\"\"\n    return None, None\n"], "multiprocessing.process": [".py", "#\n# Module providing the `Process` class which emulates `threading.Thread`\n#\n# multiprocessing/process.py\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# Licensed to PSF under a Contributor Agreement.\n#\n\n__all__ = ['Process', 'current_process', 'active_children']\n\n#\n# Imports\n#\n\nimport os\nimport sys\nimport signal\nimport itertools\nfrom _weakrefset import WeakSet\n\n#for brython\nfrom _multiprocessing import Process\n#\n#\n#\n\ntry:\n    ORIGINAL_DIR = os.path.abspath(os.getcwd())\nexcept OSError:\n    ORIGINAL_DIR = None\n\n#\n# Public functions\n#\n\ndef current_process():\n    '''\n    Return process object representing the current process\n    '''\n    return _current_process\n\ndef active_children():\n    '''\n    Return list of process objects corresponding to live child processes\n    '''\n    _cleanup()\n    return list(_current_process._children)\n\n#\n#\n#\n\ndef _cleanup():\n    # check for processes which have finished\n    for p in list(_current_process._children):\n        if p._popen.poll() is not None:\n            _current_process._children.discard(p)\n\n#\n# The `Process` class\n#\n\n# brython note: class Process is defined in /usr/libs/_multiprocessing.js\n\n\n#\n# We subclass bytes to avoid accidental transmission of auth keys over network\n#\n\nclass AuthenticationString(bytes):\n    def __reduce__(self):\n        from .forking import Popen\n        if not Popen.thread_is_spawning():\n            raise TypeError(\n                'Pickling an AuthenticationString object is '\n                'disallowed for security reasons'\n                )\n        return AuthenticationString, (bytes(self),)\n\n#\n# Create object representing the main process\n#\n\nclass _MainProcess(Process):\n\n    def __init__(self):\n        self._identity = ()\n        self._daemonic = False\n        self._name = 'MainProcess'\n        self._parent_pid = None\n        self._popen = None\n        self._counter = itertools.count(1)\n        self._children = set()\n        self._authkey = AuthenticationString(os.urandom(32))\n        self._tempdir = None\n\n_current_process = _MainProcess()\ndel _MainProcess\n\n#\n# Give names to some return codes\n#\n\n_exitcode_to_name = {}\n\nfor name, signum in list(signal.__dict__.items()):\n    if name[:3]=='SIG' and '_' not in name:\n        _exitcode_to_name[-signum] = name\n\n# For debug and leak testing\n_dangling = WeakSet()\n"], "atexit": [".py", "\"\"\"allow programmer to define multiple exit functions to be executedupon normal program termination.\n\nTwo public functions, register and unregister, are defined.\n\"\"\"\n\n\nclass __loader__(object):\n    pass\n\ndef _clear(*args,**kw):\n    \"\"\"_clear() -> None    \n    Clear the list of previously registered exit functions.\"\"\"\n    pass\n\ndef _run_exitfuncs(*args,**kw):\n    \"\"\"_run_exitfuncs() -> None    \n    Run all registered exit functions.\"\"\"\n    pass\n\ndef register(*args,**kw):\n    \"\"\"register(func, *args, **kwargs) -> func    \n    Register a function to be executed upon normal program termination\n    \n        func - function to be called at exit\n        args - optional arguments to pass to func\n        kwargs - optional keyword arguments to pass to func\n    \n        func is returned to facilitate usage as a decorator.\"\"\"\n    pass\n\ndef unregister(*args,**kw):\n    \"\"\"unregister(func) -> None    \n    Unregister a exit function which was previously registered using\n    atexit.register\n    \n        func - function to be unregistered\"\"\"\n    pass\n"], "pydoc_data": [".py", "", 1], "unittest.test.testmock.support": [".py", "import sys\n\ndef is_instance(obj, klass):\n    \"\"\"Version of is_instance that doesn't access __class__\"\"\"\n    return issubclass(type(obj), klass)\n\n\nclass SomeClass(object):\n    class_attribute = None\n\n    def wibble(self):\n        pass\n\n\nclass X(object):\n    pass\n\n\ndef examine_warnings(func):\n    def wrapper():\n        with catch_warnings(record=True) as ws:\n            func(ws)\n    return wrapper\n"], "encodings": [".py", "\"\"\" Standard \"encodings\" Package\n\n    Standard Python encoding modules are stored in this package\n    directory.\n\n    Codec modules must have names corresponding to normalized encoding\n    names as defined in the normalize_encoding() function below, e.g.\n    'utf-8' must be implemented by the module 'utf_8.py'.\n\n    Each codec module must export the following interface:\n\n    * getregentry() -> codecs.CodecInfo object\n    The getregentry() API must return a CodecInfo object with encoder, decoder,\n    incrementalencoder, incrementaldecoder, streamwriter and streamreader\n    atttributes which adhere to the Python Codec Interface Standard.\n\n    In addition, a module may optionally also define the following\n    APIs which are then used by the package's codec search function:\n\n    * getaliases() -> sequence of encoding name strings to use as aliases\n\n    Alias names returned by getaliases() must be normalized encoding\n    names as defined by normalize_encoding().\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"#\"\n\nimport codecs\nfrom . import aliases\n\n_cache = {}\n_unknown = '--unknown--'\n_import_tail = ['*']\n_aliases = aliases.aliases\n\nclass CodecRegistryError(LookupError, SystemError):\n    pass\n\ndef normalize_encoding(encoding):\n\n    \"\"\" Normalize an encoding name.\n\n        Normalization works as follows: all non-alphanumeric\n        characters except the dot used for Python package names are\n        collapsed and replaced with a single underscore, e.g. '  -;#'\n        becomes '_'. Leading and trailing underscores are removed.\n\n        Note that encoding names should be ASCII only; if they do use\n        non-ASCII characters, these must be Latin-1 compatible.\n\n    \"\"\"\n    if isinstance(encoding, bytes):\n        encoding = str(encoding, \"ascii\")\n    chars = []\n    punct = False\n    for c in encoding:\n        if c.isalnum() or c == '.':\n            if punct and chars:\n                chars.append('_')\n            chars.append(c)\n            punct = False\n        else:\n            punct = True\n    return ''.join(chars)\n\ndef search_function(encoding):\n\n    # Cache lookup\n    entry = _cache.get(encoding, _unknown)\n    if entry is not _unknown:\n        return entry\n\n    # Import the module:\n    #\n    # First try to find an alias for the normalized encoding\n    # name and lookup the module using the aliased name, then try to\n    # lookup the module using the standard import scheme, i.e. first\n    # try in the encodings package, then at top-level.\n    #\n    norm_encoding = normalize_encoding(encoding)\n    aliased_encoding = _aliases.get(norm_encoding) or \\\n                       _aliases.get(norm_encoding.replace('.', '_'))\n    if aliased_encoding is not None:\n        modnames = [aliased_encoding,\n                    norm_encoding]\n    else:\n        modnames = [norm_encoding]\n    for modname in modnames:\n        if not modname or '.' in modname:\n            continue\n        try:\n            # Import is absolute to prevent the possibly malicious import of a\n            # module with side-effects that is not in the 'encodings' package.\n            mod = __import__('encodings.' + modname, fromlist=_import_tail,\n                             level=0)\n        except ImportError:\n            pass\n        else:\n            break\n    else:\n        mod = None\n\n    try:\n        getregentry = mod.getregentry\n    except AttributeError:\n        # Not a codec module\n        mod = None\n\n    if mod is None:\n        # Cache misses\n        _cache[encoding] = None\n        return None\n\n    # Now ask the module for the registry entry\n    entry = getregentry()\n    if not isinstance(entry, codecs.CodecInfo):\n        if not 4 <= len(entry) <= 7:\n            raise CodecRegistryError('module \"%s\" (%s) failed to register'\n                                     % (mod.__name__, mod.__file__))\n        if not callable(entry[0]) or not callable(entry[1]) or \\\n           (entry[2] is not None and not callable(entry[2])) or \\\n           (entry[3] is not None and not callable(entry[3])) or \\\n           (len(entry) > 4 and entry[4] is not None and not callable(entry[4])) or \\\n           (len(entry) > 5 and entry[5] is not None and not callable(entry[5])):\n            raise CodecRegistryError('incompatible codecs in module \"%s\" (%s)'\n                                     % (mod.__name__, mod.__file__))\n        if len(entry)<7 or entry[6] is None:\n            entry += (None,)*(6-len(entry)) + (mod.__name__.split(\".\", 1)[1],)\n        entry = codecs.CodecInfo(*entry)\n\n    # Cache the codec registry entry\n    _cache[encoding] = entry\n\n    # Register its aliases (without overwriting previously registered\n    # aliases)\n    try:\n        codecaliases = mod.getaliases()\n    except AttributeError:\n        pass\n    else:\n        for alias in codecaliases:\n            if alias not in _aliases:\n                _aliases[alias] = modname\n\n    # Return the registry entry\n    return entry\n\n# Register the search_function in the Python codec registry\ncodecs.register(search_function)\n", 1], "calendar": [".py", "\"\"\"Calendar printing functions\n\nNote when comparing these calendars to the ones printed by cal(1): By\ndefault, these calendars have Monday as the first day of the week, and\nSunday as the last (the European convention). Use setfirstweekday() to\nset the first day of the week (0=Monday, 6=Sunday).\"\"\"\n\nimport sys\nimport datetime\nimport locale as _locale\n\n__all__ = [\"IllegalMonthError\", \"IllegalWeekdayError\", \"setfirstweekday\",\n           \"firstweekday\", \"isleap\", \"leapdays\", \"weekday\", \"monthrange\",\n           \"monthcalendar\", \"prmonth\", \"month\", \"prcal\", \"calendar\",\n           \"timegm\", \"month_name\", \"month_abbr\", \"day_name\", \"day_abbr\"]\n\n# Exception raised for bad input (with string parameter for details)\nerror = ValueError\n\n# Exceptions raised for bad input\nclass IllegalMonthError(ValueError):\n    def __init__(self, month):\n        self.month = month\n    def __str__(self):\n        return \"bad month number %r; must be 1-12\" % self.month\n\n\nclass IllegalWeekdayError(ValueError):\n    def __init__(self, weekday):\n        self.weekday = weekday\n    def __str__(self):\n        return \"bad weekday number %r; must be 0 (Monday) to 6 (Sunday)\" % self.weekday\n\n\n# Constants for months referenced later\nJanuary = 1\nFebruary = 2\n\n# Number of days per month (except for February in leap years)\nmdays = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n\n# This module used to have hard-coded lists of day and month names, as\n# English strings.  The classes following emulate a read-only version of\n# that, but supply localized names.  Note that the values are computed\n# fresh on each call, in case the user changes locale between calls.\n\nclass _localized_month:\n\n    _months = [datetime.date(2001, i+1, 1).strftime for i in range(12)]\n    _months.insert(0, lambda x: \"\")\n\n    def __init__(self, format):\n        self.format = format\n\n    def __getitem__(self, i):\n        funcs = self._months[i]\n        if isinstance(i, slice):\n            return [f(self.format) for f in funcs]\n        else:\n            return funcs(self.format)\n\n    def __len__(self):\n        return 13\n\n\nclass _localized_day:\n\n    # January 1, 2001, was a Monday.\n    _days = [datetime.date(2001, 1, i+1).strftime for i in range(7)]\n\n    def __init__(self, format):\n        self.format = format\n\n    def __getitem__(self, i):\n        funcs = self._days[i]\n        if isinstance(i, slice):\n            return [f(self.format) for f in funcs]\n        else:\n            return funcs(self.format)\n\n    def __len__(self):\n        return 7\n\n\n# Full and abbreviated names of weekdays\nday_name = _localized_day('%A')\nday_abbr = _localized_day('%a')\n\n# Full and abbreviated names of months (1-based arrays!!!)\nmonth_name = _localized_month('%B')\nmonth_abbr = _localized_month('%b')\n\n# Constants for weekdays\n(MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY) = range(7)\n\n\ndef isleap(year):\n    \"\"\"Return True for leap years, False for non-leap years.\"\"\"\n    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n\n\ndef leapdays(y1, y2):\n    \"\"\"Return number of leap years in range [y1, y2).\n       Assume y1 <= y2.\"\"\"\n    y1 -= 1\n    y2 -= 1\n    return (y2//4 - y1//4) - (y2//100 - y1//100) + (y2//400 - y1//400)\n\n\ndef weekday(year, month, day):\n    \"\"\"Return weekday (0-6 ~ Mon-Sun) for year (1970-...), month (1-12),\n       day (1-31).\"\"\"\n    return datetime.date(year, month, day).weekday()\n\n\ndef monthrange(year, month):\n    \"\"\"Return weekday (0-6 ~ Mon-Sun) and number of days (28-31) for\n       year, month.\"\"\"\n    if not 1 <= month <= 12:\n        raise IllegalMonthError(month)\n    day1 = weekday(year, month, 1)\n    ndays = mdays[month] + (month == February and isleap(year))\n    return day1, ndays\n\n\nclass Calendar(object):\n    \"\"\"\n    Base calendar class. This class doesn't do any formatting. It simply\n    provides data to subclasses.\n    \"\"\"\n\n    def __init__(self, firstweekday=0):\n        self.firstweekday = firstweekday # 0 = Monday, 6 = Sunday\n\n    def getfirstweekday(self):\n        return self._firstweekday % 7\n\n    def setfirstweekday(self, firstweekday):\n        self._firstweekday = firstweekday\n\n    firstweekday = property(getfirstweekday, setfirstweekday)\n\n    def iterweekdays(self):\n        \"\"\"\n        Return a iterator for one week of weekday numbers starting with the\n        configured first one.\n        \"\"\"\n        for i in range(self.firstweekday, self.firstweekday + 7):\n            yield i%7\n\n    def itermonthdates(self, year, month):\n        \"\"\"\n        Return an iterator for one month. The iterator will yield datetime.date\n        values and will always iterate through complete weeks, so it will yield\n        dates outside the specified month.\n        \"\"\"\n        date = datetime.date(year, month, 1)\n        # Go back to the beginning of the week\n        days = (date.weekday() - self.firstweekday) % 7\n        date -= datetime.timedelta(days=days)\n        oneday = datetime.timedelta(days=1)\n        while True:\n            yield date\n            try:\n                date += oneday\n            except OverflowError:\n                # Adding one day could fail after datetime.MAXYEAR\n                break\n            if date.month != month and date.weekday() == self.firstweekday:\n                break\n\n    def itermonthdays2(self, year, month):\n        \"\"\"\n        Like itermonthdates(), but will yield (day number, weekday number)\n        tuples. For days outside the specified month the day number is 0.\n        \"\"\"\n        for date in self.itermonthdates(year, month):\n            if date.month != month:\n                yield (0, date.weekday())\n            else:\n                yield (date.day, date.weekday())\n\n    def itermonthdays(self, year, month):\n        \"\"\"\n        Like itermonthdates(), but will yield day numbers. For days outside\n        the specified month the day number is 0.\n        \"\"\"\n        for date in self.itermonthdates(year, month):\n            if date.month != month:\n                yield 0\n            else:\n                yield date.day\n\n    def monthdatescalendar(self, year, month):\n        \"\"\"\n        Return a matrix (list of lists) representing a month's calendar.\n        Each row represents a week; week entries are datetime.date values.\n        \"\"\"\n        dates = list(self.itermonthdates(year, month))\n        return [ dates[i:i+7] for i in range(0, len(dates), 7) ]\n\n    def monthdays2calendar(self, year, month):\n        \"\"\"\n        Return a matrix representing a month's calendar.\n        Each row represents a week; week entries are\n        (day number, weekday number) tuples. Day numbers outside this month\n        are zero.\n        \"\"\"\n        days = list(self.itermonthdays2(year, month))\n        return [ days[i:i+7] for i in range(0, len(days), 7) ]\n\n    def monthdayscalendar(self, year, month):\n        \"\"\"\n        Return a matrix representing a month's calendar.\n        Each row represents a week; days outside this month are zero.\n        \"\"\"\n        days = list(self.itermonthdays(year, month))\n        return [ days[i:i+7] for i in range(0, len(days), 7) ]\n\n    def yeardatescalendar(self, year, width=3):\n        \"\"\"\n        Return the data for the specified year ready for formatting. The return\n        value is a list of month rows. Each month row contains up to width months.\n        Each month contains between 4 and 6 weeks and each week contains 1-7\n        days. Days are datetime.date objects.\n        \"\"\"\n        months = [\n            self.monthdatescalendar(year, i)\n            for i in range(January, January+12)\n        ]\n        return [months[i:i+width] for i in range(0, len(months), width) ]\n\n    def yeardays2calendar(self, year, width=3):\n        \"\"\"\n        Return the data for the specified year ready for formatting (similar to\n        yeardatescalendar()). Entries in the week lists are\n        (day number, weekday number) tuples. Day numbers outside this month are\n        zero.\n        \"\"\"\n        months = [\n            self.monthdays2calendar(year, i)\n            for i in range(January, January+12)\n        ]\n        return [months[i:i+width] for i in range(0, len(months), width) ]\n\n    def yeardayscalendar(self, year, width=3):\n        \"\"\"\n        Return the data for the specified year ready for formatting (similar to\n        yeardatescalendar()). Entries in the week lists are day numbers.\n        Day numbers outside this month are zero.\n        \"\"\"\n        months = [\n            self.monthdayscalendar(year, i)\n            for i in range(January, January+12)\n        ]\n        return [months[i:i+width] for i in range(0, len(months), width) ]\n\n\nclass TextCalendar(Calendar):\n    \"\"\"\n    Subclass of Calendar that outputs a calendar as a simple plain text\n    similar to the UNIX program cal.\n    \"\"\"\n\n    def prweek(self, theweek, width):\n        \"\"\"\n        Print a single week (no newline).\n        \"\"\"\n        print(self.formatweek(theweek, width), end=' ')\n\n    def formatday(self, day, weekday, width):\n        \"\"\"\n        Returns a formatted day.\n        \"\"\"\n        if day == 0:\n            s = ''\n        else:\n            s = '%2i' % day             # right-align single-digit days\n        return s.center(width)\n\n    def formatweek(self, theweek, width):\n        \"\"\"\n        Returns a single week in a string (no newline).\n        \"\"\"\n        return ' '.join(self.formatday(d, wd, width) for (d, wd) in theweek)\n\n    def formatweekday(self, day, width):\n        \"\"\"\n        Returns a formatted week day name.\n        \"\"\"\n        if width >= 9:\n            names = day_name\n        else:\n            names = day_abbr\n        return names[day][:width].center(width)\n\n    def formatweekheader(self, width):\n        \"\"\"\n        Return a header for a week.\n        \"\"\"\n        return ' '.join(self.formatweekday(i, width) for i in self.iterweekdays())\n\n    def formatmonthname(self, theyear, themonth, width, withyear=True):\n        \"\"\"\n        Return a formatted month name.\n        \"\"\"\n        s = month_name[themonth]\n        if withyear:\n            s = \"%s %r\" % (s, theyear)\n        return s.center(width)\n\n    def prmonth(self, theyear, themonth, w=0, l=0):\n        \"\"\"\n        Print a month's calendar.\n        \"\"\"\n        print(self.formatmonth(theyear, themonth, w, l), end=' ')\n\n    def formatmonth(self, theyear, themonth, w=0, l=0):\n        \"\"\"\n        Return a month's calendar string (multi-line).\n        \"\"\"\n        w = max(2, w)\n        l = max(1, l)\n        s = self.formatmonthname(theyear, themonth, 7 * (w + 1) - 1)\n        s = s.rstrip()\n        s += '\\n' * l\n        s += self.formatweekheader(w).rstrip()\n        s += '\\n' * l\n        for week in self.monthdays2calendar(theyear, themonth):\n            s += self.formatweek(week, w).rstrip()\n            s += '\\n' * l\n        return s\n\n    def formatyear(self, theyear, w=2, l=1, c=6, m=3):\n        \"\"\"\n        Returns a year's calendar as a multi-line string.\n        \"\"\"\n        w = max(2, w)\n        l = max(1, l)\n        c = max(2, c)\n        colwidth = (w + 1) * 7 - 1\n        v = []\n        a = v.append\n        a(repr(theyear).center(colwidth*m+c*(m-1)).rstrip())\n        a('\\n'*l)\n        header = self.formatweekheader(w)\n        for (i, row) in enumerate(self.yeardays2calendar(theyear, m)):\n            # months in this row\n            months = range(m*i+1, min(m*(i+1)+1, 13))\n            a('\\n'*l)\n            names = (self.formatmonthname(theyear, k, colwidth, False)\n                     for k in months)\n            a(formatstring(names, colwidth, c).rstrip())\n            a('\\n'*l)\n            headers = (header for k in months)\n            a(formatstring(headers, colwidth, c).rstrip())\n            a('\\n'*l)\n            # max number of weeks for this row\n            height = max(len(cal) for cal in row)\n            for j in range(height):\n                weeks = []\n                for cal in row:\n                    if j >= len(cal):\n                        weeks.append('')\n                    else:\n                        weeks.append(self.formatweek(cal[j], w))\n                a(formatstring(weeks, colwidth, c).rstrip())\n                a('\\n' * l)\n        return ''.join(v)\n\n    def pryear(self, theyear, w=0, l=0, c=6, m=3):\n        \"\"\"Print a year's calendar.\"\"\"\n        print(self.formatyear(theyear, w, l, c, m))\n\n\nclass HTMLCalendar(Calendar):\n    \"\"\"\n    This calendar returns complete HTML pages.\n    \"\"\"\n\n    # CSS classes for the day <td>s\n    cssclasses = [\"mon\", \"tue\", \"wed\", \"thu\", \"fri\", \"sat\", \"sun\"]\n\n    def formatday(self, day, weekday):\n        \"\"\"\n        Return a day as a table cell.\n        \"\"\"\n        if day == 0:\n            return '<td class=\"noday\">&nbsp;</td>' # day outside month\n        else:\n            return '<td class=\"%s\">%d</td>' % (self.cssclasses[weekday], day)\n\n    def formatweek(self, theweek):\n        \"\"\"\n        Return a complete week as a table row.\n        \"\"\"\n        s = ''.join(self.formatday(d, wd) for (d, wd) in theweek)\n        return '<tr>%s</tr>' % s\n\n    def formatweekday(self, day):\n        \"\"\"\n        Return a weekday name as a table header.\n        \"\"\"\n        return '<th class=\"%s\">%s</th>' % (self.cssclasses[day], day_abbr[day])\n\n    def formatweekheader(self):\n        \"\"\"\n        Return a header for a week as a table row.\n        \"\"\"\n        s = ''.join(self.formatweekday(i) for i in self.iterweekdays())\n        return '<tr>%s</tr>' % s\n\n    def formatmonthname(self, theyear, themonth, withyear=True):\n        \"\"\"\n        Return a month name as a table row.\n        \"\"\"\n        if withyear:\n            s = '%s %s' % (month_name[themonth], theyear)\n        else:\n            s = '%s' % month_name[themonth]\n        return '<tr><th colspan=\"7\" class=\"month\">%s</th></tr>' % s\n\n    def formatmonth(self, theyear, themonth, withyear=True):\n        \"\"\"\n        Return a formatted month as a table.\n        \"\"\"\n        v = []\n        a = v.append\n        a('<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"month\">')\n        a('\\n')\n        a(self.formatmonthname(theyear, themonth, withyear=withyear))\n        a('\\n')\n        a(self.formatweekheader())\n        a('\\n')\n        for week in self.monthdays2calendar(theyear, themonth):\n            a(self.formatweek(week))\n            a('\\n')\n        a('</table>')\n        a('\\n')\n        return ''.join(v)\n\n    def formatyear(self, theyear, width=3):\n        \"\"\"\n        Return a formatted year as a table of tables.\n        \"\"\"\n        v = []\n        a = v.append\n        width = max(width, 1)\n        a('<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"year\">')\n        a('\\n')\n        a('<tr><th colspan=\"%d\" class=\"year\">%s</th></tr>' % (width, theyear))\n        for i in range(January, January+12, width):\n            # months in this row\n            months = range(i, min(i+width, 13))\n            a('<tr>')\n            for m in months:\n                a('<td>')\n                a(self.formatmonth(theyear, m, withyear=False))\n                a('</td>')\n            a('</tr>')\n        a('</table>')\n        return ''.join(v)\n\n    def formatyearpage(self, theyear, width=3, css='calendar.css', encoding=None):\n        \"\"\"\n        Return a formatted year as a complete HTML page.\n        \"\"\"\n        if encoding is None:\n            encoding = sys.getdefaultencoding()\n        v = []\n        a = v.append\n        a('<?xml version=\"1.0\" encoding=\"%s\"?>\\n' % encoding)\n        a('<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\\n')\n        a('<html>\\n')\n        a('<head>\\n')\n        a('<meta http-equiv=\"Content-Type\" content=\"text/html; charset=%s\" />\\n' % encoding)\n        if css is not None:\n            a('<link rel=\"stylesheet\" type=\"text/css\" href=\"%s\" />\\n' % css)\n        a('<title>Calendar for %d</title>\\n' % theyear)\n        a('</head>\\n')\n        a('<body>\\n')\n        a(self.formatyear(theyear, width))\n        a('</body>\\n')\n        a('</html>\\n')\n        return ''.join(v).encode(encoding, \"xmlcharrefreplace\")\n\n\nclass different_locale:\n    def __init__(self, locale):\n        self.locale = locale\n\n    def __enter__(self):\n        self.oldlocale = _locale.getlocale(_locale.LC_TIME)\n        _locale.setlocale(_locale.LC_TIME, self.locale)\n\n    def __exit__(self, *args):\n        _locale.setlocale(_locale.LC_TIME, self.oldlocale)\n\n\nclass LocaleTextCalendar(TextCalendar):\n    \"\"\"\n    This class can be passed a locale name in the constructor and will return\n    month and weekday names in the specified locale. If this locale includes\n    an encoding all strings containing month and weekday names will be returned\n    as unicode.\n    \"\"\"\n\n    def __init__(self, firstweekday=0, locale=None):\n        TextCalendar.__init__(self, firstweekday)\n        if locale is None:\n            locale = _locale.getdefaultlocale()\n        self.locale = locale\n\n    def formatweekday(self, day, width):\n        with different_locale(self.locale):\n            if width >= 9:\n                names = day_name\n            else:\n                names = day_abbr\n            name = names[day]\n            return name[:width].center(width)\n\n    def formatmonthname(self, theyear, themonth, width, withyear=True):\n        with different_locale(self.locale):\n            s = month_name[themonth]\n            if withyear:\n                s = \"%s %r\" % (s, theyear)\n            return s.center(width)\n\n\nclass LocaleHTMLCalendar(HTMLCalendar):\n    \"\"\"\n    This class can be passed a locale name in the constructor and will return\n    month and weekday names in the specified locale. If this locale includes\n    an encoding all strings containing month and weekday names will be returned\n    as unicode.\n    \"\"\"\n    def __init__(self, firstweekday=0, locale=None):\n        HTMLCalendar.__init__(self, firstweekday)\n        if locale is None:\n            locale = _locale.getdefaultlocale()\n        self.locale = locale\n\n    def formatweekday(self, day):\n        with different_locale(self.locale):\n            s = day_abbr[day]\n            return '<th class=\"%s\">%s</th>' % (self.cssclasses[day], s)\n\n    def formatmonthname(self, theyear, themonth, withyear=True):\n        with different_locale(self.locale):\n            s = month_name[themonth]\n            if withyear:\n                s = '%s %s' % (s, theyear)\n            return '<tr><th colspan=\"7\" class=\"month\">%s</th></tr>' % s\n\n\n# Support for old module level interface\nc = TextCalendar()\n\nfirstweekday = c.getfirstweekday\n\ndef setfirstweekday(firstweekday):\n    if not MONDAY <= firstweekday <= SUNDAY:\n        raise IllegalWeekdayError(firstweekday)\n    c.firstweekday = firstweekday\n\nmonthcalendar = c.monthdayscalendar\nprweek = c.prweek\nweek = c.formatweek\nweekheader = c.formatweekheader\nprmonth = c.prmonth\nmonth = c.formatmonth\ncalendar = c.formatyear\nprcal = c.pryear\n\n\n# Spacing of month columns for multi-column year calendar\n_colwidth = 7*3 - 1         # Amount printed by prweek()\n_spacing = 6                # Number of spaces between columns\n\n\ndef format(cols, colwidth=_colwidth, spacing=_spacing):\n    \"\"\"Prints multi-column formatting for year calendars\"\"\"\n    print(formatstring(cols, colwidth, spacing))\n\n\ndef formatstring(cols, colwidth=_colwidth, spacing=_spacing):\n    \"\"\"Returns a string formatted from n strings, centered within n columns.\"\"\"\n    spacing *= ' '\n    return spacing.join(c.center(colwidth) for c in cols)\n\n\nEPOCH = 1970\n_EPOCH_ORD = datetime.date(EPOCH, 1, 1).toordinal()\n\n\ndef timegm(tuple):\n    \"\"\"Unrelated but handy function to calculate Unix timestamp from GMT.\"\"\"\n    year, month, day, hour, minute, second = tuple[:6]\n    days = datetime.date(year, month, 1).toordinal() - _EPOCH_ORD + day - 1\n    hours = days*24 + hour\n    minutes = hours*60 + minute\n    seconds = minutes*60 + second\n    return seconds\n\n\ndef main(args):\n    import optparse\n    parser = optparse.OptionParser(usage=\"usage: %prog [options] [year [month]]\")\n    parser.add_option(\n        \"-w\", \"--width\",\n        dest=\"width\", type=\"int\", default=2,\n        help=\"width of date column (default 2, text only)\"\n    )\n    parser.add_option(\n        \"-l\", \"--lines\",\n        dest=\"lines\", type=\"int\", default=1,\n        help=\"number of lines for each week (default 1, text only)\"\n    )\n    parser.add_option(\n        \"-s\", \"--spacing\",\n        dest=\"spacing\", type=\"int\", default=6,\n        help=\"spacing between months (default 6, text only)\"\n    )\n    parser.add_option(\n        \"-m\", \"--months\",\n        dest=\"months\", type=\"int\", default=3,\n        help=\"months per row (default 3, text only)\"\n    )\n    parser.add_option(\n        \"-c\", \"--css\",\n        dest=\"css\", default=\"calendar.css\",\n        help=\"CSS to use for page (html only)\"\n    )\n    parser.add_option(\n        \"-L\", \"--locale\",\n        dest=\"locale\", default=None,\n        help=\"locale to be used from month and weekday names\"\n    )\n    parser.add_option(\n        \"-e\", \"--encoding\",\n        dest=\"encoding\", default=None,\n        help=\"Encoding to use for output.\"\n    )\n    parser.add_option(\n        \"-t\", \"--type\",\n        dest=\"type\", default=\"text\",\n        choices=(\"text\", \"html\"),\n        help=\"output type (text or html)\"\n    )\n\n    (options, args) = parser.parse_args(args)\n\n    if options.locale and not options.encoding:\n        parser.error(\"if --locale is specified --encoding is required\")\n        sys.exit(1)\n\n    locale = options.locale, options.encoding\n\n    if options.type == \"html\":\n        if options.locale:\n            cal = LocaleHTMLCalendar(locale=locale)\n        else:\n            cal = HTMLCalendar()\n        encoding = options.encoding\n        if encoding is None:\n            encoding = sys.getdefaultencoding()\n        optdict = dict(encoding=encoding, css=options.css)\n        write = sys.stdout.buffer.write\n        if len(args) == 1:\n            write(cal.formatyearpage(datetime.date.today().year, **optdict))\n        elif len(args) == 2:\n            write(cal.formatyearpage(int(args[1]), **optdict))\n        else:\n            parser.error(\"incorrect number of arguments\")\n            sys.exit(1)\n    else:\n        if options.locale:\n            cal = LocaleTextCalendar(locale=locale)\n        else:\n            cal = TextCalendar()\n        optdict = dict(w=options.width, l=options.lines)\n        if len(args) != 3:\n            optdict[\"c\"] = options.spacing\n            optdict[\"m\"] = options.months\n        if len(args) == 1:\n            result = cal.formatyear(datetime.date.today().year, **optdict)\n        elif len(args) == 2:\n            result = cal.formatyear(int(args[1]), **optdict)\n        elif len(args) == 3:\n            result = cal.formatmonth(int(args[1]), int(args[2]), **optdict)\n        else:\n            parser.error(\"incorrect number of arguments\")\n            sys.exit(1)\n        write = sys.stdout.write\n        if options.encoding:\n            result = result.encode(options.encoding)\n            write = sys.stdout.buffer.write\n        write(result)\n\n\nif __name__ == \"__main__\":\n    main(sys.argv)\n"], "logging.handlers": [".py", "# Copyright 2001-2013 by Vinay Sajip. All Rights Reserved.\n#\n# Permission to use, copy, modify, and distribute this software and its\n# documentation for any purpose and without fee is hereby granted,\n# provided that the above copyright notice appear in all copies and that\n# both that copyright notice and this permission notice appear in\n# supporting documentation, and that the name of Vinay Sajip\n# not be used in advertising or publicity pertaining to distribution\n# of the software without specific, written prior permission.\n# VINAY SAJIP DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING\n# ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\n# VINAY SAJIP BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR\n# ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER\n# IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\n# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n\"\"\"\nAdditional handlers for the logging package for Python. The core package is\nbased on PEP 282 and comments thereto in comp.lang.python.\n\nCopyright (C) 2001-2013 Vinay Sajip. All Rights Reserved.\n\nTo use, simply 'import logging.handlers' and log away!\n\"\"\"\n\nimport errno, logging, socket, os, pickle, struct, time, re\nfrom codecs import BOM_UTF8\nfrom stat import ST_DEV, ST_INO, ST_MTIME\nimport queue\ntry:\n    import threading\nexcept ImportError: #pragma: no cover\n    threading = None\n\n#\n# Some constants...\n#\n\nDEFAULT_TCP_LOGGING_PORT    = 9020\nDEFAULT_UDP_LOGGING_PORT    = 9021\nDEFAULT_HTTP_LOGGING_PORT   = 9022\nDEFAULT_SOAP_LOGGING_PORT   = 9023\nSYSLOG_UDP_PORT             = 514\nSYSLOG_TCP_PORT             = 514\n\n_MIDNIGHT = 24 * 60 * 60  # number of seconds in a day\n\nclass BaseRotatingHandler(logging.FileHandler):\n    \"\"\"\n    Base class for handlers that rotate log files at a certain point.\n    Not meant to be instantiated directly.  Instead, use RotatingFileHandler\n    or TimedRotatingFileHandler.\n    \"\"\"\n    def __init__(self, filename, mode, encoding=None, delay=False):\n        \"\"\"\n        Use the specified filename for streamed logging\n        \"\"\"\n        logging.FileHandler.__init__(self, filename, mode, encoding, delay)\n        self.mode = mode\n        self.encoding = encoding\n        self.namer = None\n        self.rotator = None\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        Output the record to the file, catering for rollover as described\n        in doRollover().\n        \"\"\"\n        try:\n            if self.shouldRollover(record):\n                self.doRollover()\n            logging.FileHandler.emit(self, record)\n        except (KeyboardInterrupt, SystemExit): #pragma: no cover\n            raise\n        except:\n            self.handleError(record)\n\n    def rotation_filename(self, default_name):\n        \"\"\"\n        Modify the filename of a log file when rotating.\n\n        This is provided so that a custom filename can be provided.\n\n        The default implementation calls the 'namer' attribute of the\n        handler, if it's callable, passing the default name to\n        it. If the attribute isn't callable (the default is None), the name\n        is returned unchanged.\n\n        :param default_name: The default name for the log file.\n        \"\"\"\n        if not callable(self.namer):\n            result = default_name\n        else:\n            result = self.namer(default_name)\n        return result\n\n    def rotate(self, source, dest):\n        \"\"\"\n        When rotating, rotate the current log.\n\n        The default implementation calls the 'rotator' attribute of the\n        handler, if it's callable, passing the source and dest arguments to\n        it. If the attribute isn't callable (the default is None), the source\n        is simply renamed to the destination.\n\n        :param source: The source filename. This is normally the base\n                       filename, e.g. 'test.log'\n        :param dest:   The destination filename. This is normally\n                       what the source is rotated to, e.g. 'test.log.1'.\n        \"\"\"\n        if not callable(self.rotator):\n            # Issue 18940: A file may not have been created if delay is True.\n            if os.path.exists(source):\n                os.rename(source, dest)\n        else:\n            self.rotator(source, dest)\n\nclass RotatingFileHandler(BaseRotatingHandler):\n    \"\"\"\n    Handler for logging to a set of files, which switches from one file\n    to the next when the current file reaches a certain size.\n    \"\"\"\n    def __init__(self, filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=False):\n        \"\"\"\n        Open the specified file and use it as the stream for logging.\n\n        By default, the file grows indefinitely. You can specify particular\n        values of maxBytes and backupCount to allow the file to rollover at\n        a predetermined size.\n\n        Rollover occurs whenever the current log file is nearly maxBytes in\n        length. If backupCount is >= 1, the system will successively create\n        new files with the same pathname as the base file, but with extensions\n        \".1\", \".2\" etc. appended to it. For example, with a backupCount of 5\n        and a base file name of \"app.log\", you would get \"app.log\",\n        \"app.log.1\", \"app.log.2\", ... through to \"app.log.5\". The file being\n        written to is always \"app.log\" - when it gets filled up, it is closed\n        and renamed to \"app.log.1\", and if files \"app.log.1\", \"app.log.2\" etc.\n        exist, then they are renamed to \"app.log.2\", \"app.log.3\" etc.\n        respectively.\n\n        If maxBytes is zero, rollover never occurs.\n        \"\"\"\n        # If rotation/rollover is wanted, it doesn't make sense to use another\n        # mode. If for example 'w' were specified, then if there were multiple\n        # runs of the calling application, the logs from previous runs would be\n        # lost if the 'w' is respected, because the log file would be truncated\n        # on each run.\n        if maxBytes > 0:\n            mode = 'a'\n        BaseRotatingHandler.__init__(self, filename, mode, encoding, delay)\n        self.maxBytes = maxBytes\n        self.backupCount = backupCount\n\n    def doRollover(self):\n        \"\"\"\n        Do a rollover, as described in __init__().\n        \"\"\"\n        if self.stream:\n            self.stream.close()\n            self.stream = None\n        if self.backupCount > 0:\n            for i in range(self.backupCount - 1, 0, -1):\n                sfn = self.rotation_filename(\"%s.%d\" % (self.baseFilename, i))\n                dfn = self.rotation_filename(\"%s.%d\" % (self.baseFilename,\n                                                        i + 1))\n                if os.path.exists(sfn):\n                    if os.path.exists(dfn):\n                        os.remove(dfn)\n                    os.rename(sfn, dfn)\n            dfn = self.rotation_filename(self.baseFilename + \".1\")\n            if os.path.exists(dfn):\n                os.remove(dfn)\n            self.rotate(self.baseFilename, dfn)\n        if not self.delay:\n            self.stream = self._open()\n\n    def shouldRollover(self, record):\n        \"\"\"\n        Determine if rollover should occur.\n\n        Basically, see if the supplied record would cause the file to exceed\n        the size limit we have.\n        \"\"\"\n        if self.stream is None:                 # delay was set...\n            self.stream = self._open()\n        if self.maxBytes > 0:                   # are we rolling over?\n            msg = \"%s\\n\" % self.format(record)\n            self.stream.seek(0, 2)  #due to non-posix-compliant Windows feature\n            if self.stream.tell() + len(msg) >= self.maxBytes:\n                return 1\n        return 0\n\nclass TimedRotatingFileHandler(BaseRotatingHandler):\n    \"\"\"\n    Handler for logging to a file, rotating the log file at certain timed\n    intervals.\n\n    If backupCount is > 0, when rollover is done, no more than backupCount\n    files are kept - the oldest ones are deleted.\n    \"\"\"\n    def __init__(self, filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False):\n        BaseRotatingHandler.__init__(self, filename, 'a', encoding, delay)\n        self.when = when.upper()\n        self.backupCount = backupCount\n        self.utc = utc\n        # Calculate the real rollover interval, which is just the number of\n        # seconds between rollovers.  Also set the filename suffix used when\n        # a rollover occurs.  Current 'when' events supported:\n        # S - Seconds\n        # M - Minutes\n        # H - Hours\n        # D - Days\n        # midnight - roll over at midnight\n        # W{0-6} - roll over on a certain day; 0 - Monday\n        #\n        # Case of the 'when' specifier is not important; lower or upper case\n        # will work.\n        if self.when == 'S':\n            self.interval = 1 # one second\n            self.suffix = \"%Y-%m-%d_%H-%M-%S\"\n            self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}(\\.\\w+)?$\"\n        elif self.when == 'M':\n            self.interval = 60 # one minute\n            self.suffix = \"%Y-%m-%d_%H-%M\"\n            self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}(\\.\\w+)?$\"\n        elif self.when == 'H':\n            self.interval = 60 * 60 # one hour\n            self.suffix = \"%Y-%m-%d_%H\"\n            self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}_\\d{2}(\\.\\w+)?$\"\n        elif self.when == 'D' or self.when == 'MIDNIGHT':\n            self.interval = 60 * 60 * 24 # one day\n            self.suffix = \"%Y-%m-%d\"\n            self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}(\\.\\w+)?$\"\n        elif self.when.startswith('W'):\n            self.interval = 60 * 60 * 24 * 7 # one week\n            if len(self.when) != 2:\n                raise ValueError(\"You must specify a day for weekly rollover from 0 to 6 (0 is Monday): %s\" % self.when)\n            if self.when[1] < '0' or self.when[1] > '6':\n                raise ValueError(\"Invalid day specified for weekly rollover: %s\" % self.when)\n            self.dayOfWeek = int(self.when[1])\n            self.suffix = \"%Y-%m-%d\"\n            self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}(\\.\\w+)?$\"\n        else:\n            raise ValueError(\"Invalid rollover interval specified: %s\" % self.when)\n\n        self.extMatch = re.compile(self.extMatch, re.ASCII)\n        self.interval = self.interval * interval # multiply by units requested\n        if os.path.exists(filename):\n            t = os.stat(filename)[ST_MTIME]\n        else:\n            t = int(time.time())\n        self.rolloverAt = self.computeRollover(t)\n\n    def computeRollover(self, currentTime):\n        \"\"\"\n        Work out the rollover time based on the specified time.\n        \"\"\"\n        result = currentTime + self.interval\n        # If we are rolling over at midnight or weekly, then the interval is already known.\n        # What we need to figure out is WHEN the next interval is.  In other words,\n        # if you are rolling over at midnight, then your base interval is 1 day,\n        # but you want to start that one day clock at midnight, not now.  So, we\n        # have to fudge the rolloverAt value in order to trigger the first rollover\n        # at the right time.  After that, the regular interval will take care of\n        # the rest.  Note that this code doesn't care about leap seconds. :)\n        if self.when == 'MIDNIGHT' or self.when.startswith('W'):\n            # This could be done with less code, but I wanted it to be clear\n            if self.utc:\n                t = time.gmtime(currentTime)\n            else:\n                t = time.localtime(currentTime)\n            currentHour = t[3]\n            currentMinute = t[4]\n            currentSecond = t[5]\n            # r is the number of seconds left between now and midnight\n            r = _MIDNIGHT - ((currentHour * 60 + currentMinute) * 60 +\n                    currentSecond)\n            result = currentTime + r\n            # If we are rolling over on a certain day, add in the number of days until\n            # the next rollover, but offset by 1 since we just calculated the time\n            # until the next day starts.  There are three cases:\n            # Case 1) The day to rollover is today; in this case, do nothing\n            # Case 2) The day to rollover is further in the interval (i.e., today is\n            #         day 2 (Wednesday) and rollover is on day 6 (Sunday).  Days to\n            #         next rollover is simply 6 - 2 - 1, or 3.\n            # Case 3) The day to rollover is behind us in the interval (i.e., today\n            #         is day 5 (Saturday) and rollover is on day 3 (Thursday).\n            #         Days to rollover is 6 - 5 + 3, or 4.  In this case, it's the\n            #         number of days left in the current week (1) plus the number\n            #         of days in the next week until the rollover day (3).\n            # The calculations described in 2) and 3) above need to have a day added.\n            # This is because the above time calculation takes us to midnight on this\n            # day, i.e. the start of the next day.\n            if self.when.startswith('W'):\n                day = t[6] # 0 is Monday\n                if day != self.dayOfWeek:\n                    if day < self.dayOfWeek:\n                        daysToWait = self.dayOfWeek - day\n                    else:\n                        daysToWait = 6 - day + self.dayOfWeek + 1\n                    newRolloverAt = result + (daysToWait * (60 * 60 * 24))\n                    if not self.utc:\n                        dstNow = t[-1]\n                        dstAtRollover = time.localtime(newRolloverAt)[-1]\n                        if dstNow != dstAtRollover:\n                            if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour\n                                addend = -3600\n                            else:           # DST bows out before next rollover, so we need to add an hour\n                                addend = 3600\n                            newRolloverAt += addend\n                    result = newRolloverAt\n        return result\n\n    def shouldRollover(self, record):\n        \"\"\"\n        Determine if rollover should occur.\n\n        record is not used, as we are just comparing times, but it is needed so\n        the method signatures are the same\n        \"\"\"\n        t = int(time.time())\n        if t >= self.rolloverAt:\n            return 1\n        return 0\n\n    def getFilesToDelete(self):\n        \"\"\"\n        Determine the files to delete when rolling over.\n\n        More specific than the earlier method, which just used glob.glob().\n        \"\"\"\n        dirName, baseName = os.path.split(self.baseFilename)\n        fileNames = os.listdir(dirName)\n        result = []\n        prefix = baseName + \".\"\n        plen = len(prefix)\n        for fileName in fileNames:\n            if fileName[:plen] == prefix:\n                suffix = fileName[plen:]\n                if self.extMatch.match(suffix):\n                    result.append(os.path.join(dirName, fileName))\n        result.sort()\n        if len(result) < self.backupCount:\n            result = []\n        else:\n            result = result[:len(result) - self.backupCount]\n        return result\n\n    def doRollover(self):\n        \"\"\"\n        do a rollover; in this case, a date/time stamp is appended to the filename\n        when the rollover happens.  However, you want the file to be named for the\n        start of the interval, not the current time.  If there is a backup count,\n        then we have to get a list of matching filenames, sort them and remove\n        the one with the oldest suffix.\n        \"\"\"\n        if self.stream:\n            self.stream.close()\n            self.stream = None\n        # get the time that this sequence started at and make it a TimeTuple\n        currentTime = int(time.time())\n        dstNow = time.localtime(currentTime)[-1]\n        t = self.rolloverAt - self.interval\n        if self.utc:\n            timeTuple = time.gmtime(t)\n        else:\n            timeTuple = time.localtime(t)\n            dstThen = timeTuple[-1]\n            if dstNow != dstThen:\n                if dstNow:\n                    addend = 3600\n                else:\n                    addend = -3600\n                timeTuple = time.localtime(t + addend)\n        dfn = self.rotation_filename(self.baseFilename + \".\" +\n                                     time.strftime(self.suffix, timeTuple))\n        if os.path.exists(dfn):\n            os.remove(dfn)\n        self.rotate(self.baseFilename, dfn)\n        if self.backupCount > 0:\n            for s in self.getFilesToDelete():\n                os.remove(s)\n        if not self.delay:\n            self.stream = self._open()\n        newRolloverAt = self.computeRollover(currentTime)\n        while newRolloverAt <= currentTime:\n            newRolloverAt = newRolloverAt + self.interval\n        #If DST changes and midnight or weekly rollover, adjust for this.\n        if (self.when == 'MIDNIGHT' or self.when.startswith('W')) and not self.utc:\n            dstAtRollover = time.localtime(newRolloverAt)[-1]\n            if dstNow != dstAtRollover:\n                if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour\n                    addend = -3600\n                else:           # DST bows out before next rollover, so we need to add an hour\n                    addend = 3600\n                newRolloverAt += addend\n        self.rolloverAt = newRolloverAt\n\nclass WatchedFileHandler(logging.FileHandler):\n    \"\"\"\n    A handler for logging to a file, which watches the file\n    to see if it has changed while in use. This can happen because of\n    usage of programs such as newsyslog and logrotate which perform\n    log file rotation. This handler, intended for use under Unix,\n    watches the file to see if it has changed since the last emit.\n    (A file has changed if its device or inode have changed.)\n    If it has changed, the old file stream is closed, and the file\n    opened to get a new stream.\n\n    This handler is not appropriate for use under Windows, because\n    under Windows open files cannot be moved or renamed - logging\n    opens the files with exclusive locks - and so there is no need\n    for such a handler. Furthermore, ST_INO is not supported under\n    Windows; stat always returns zero for this value.\n\n    This handler is based on a suggestion and patch by Chad J.\n    Schroeder.\n    \"\"\"\n    def __init__(self, filename, mode='a', encoding=None, delay=False):\n        logging.FileHandler.__init__(self, filename, mode, encoding, delay)\n        self.dev, self.ino = -1, -1\n        self._statstream()\n\n    def _statstream(self):\n        if self.stream:\n            sres = os.fstat(self.stream.fileno())\n            self.dev, self.ino = sres[ST_DEV], sres[ST_INO]\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        First check if the underlying file has changed, and if it\n        has, close the old stream and reopen the file to get the\n        current stream.\n        \"\"\"\n        # Reduce the chance of race conditions by stat'ing by path only\n        # once and then fstat'ing our new fd if we opened a new log stream.\n        # See issue #14632: Thanks to John Mulligan for the problem report\n        # and patch.\n        try:\n            # stat the file by path, checking for existence\n            sres = os.stat(self.baseFilename)\n        except OSError as err:\n            if err.errno == errno.ENOENT:\n                sres = None\n            else:\n                raise\n        # compare file system stat with that of our stream file handle\n        if not sres or sres[ST_DEV] != self.dev or sres[ST_INO] != self.ino:\n            if self.stream is not None:\n                # we have an open file handle, clean it up\n                self.stream.flush()\n                self.stream.close()\n                # open a new file handle and get new stat info from that fd\n                self.stream = self._open()\n                self._statstream()\n        logging.FileHandler.emit(self, record)\n\n\nclass SocketHandler(logging.Handler):\n    \"\"\"\n    A handler class which writes logging records, in pickle format, to\n    a streaming socket. The socket is kept open across logging calls.\n    If the peer resets it, an attempt is made to reconnect on the next call.\n    The pickle which is sent is that of the LogRecord's attribute dictionary\n    (__dict__), so that the receiver does not need to have the logging module\n    installed in order to process the logging event.\n\n    To unpickle the record at the receiving end into a LogRecord, use the\n    makeLogRecord function.\n    \"\"\"\n\n    def __init__(self, host, port):\n        \"\"\"\n        Initializes the handler with a specific host address and port.\n\n        When the attribute *closeOnError* is set to True - if a socket error\n        occurs, the socket is silently closed and then reopened on the next\n        logging call.\n        \"\"\"\n        logging.Handler.__init__(self)\n        self.host = host\n        self.port = port\n        self.sock = None\n        self.closeOnError = False\n        self.retryTime = None\n        #\n        # Exponential backoff parameters.\n        #\n        self.retryStart = 1.0\n        self.retryMax = 30.0\n        self.retryFactor = 2.0\n\n    def makeSocket(self, timeout=1):\n        \"\"\"\n        A factory method which allows subclasses to define the precise\n        type of socket they want.\n        \"\"\"\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        if hasattr(s, 'settimeout'):\n            s.settimeout(timeout)\n        try:\n            s.connect((self.host, self.port))\n            return s\n        except socket.error:\n            s.close()\n            raise\n\n    def createSocket(self):\n        \"\"\"\n        Try to create a socket, using an exponential backoff with\n        a max retry time. Thanks to Robert Olson for the original patch\n        (SF #815911) which has been slightly refactored.\n        \"\"\"\n        now = time.time()\n        # Either retryTime is None, in which case this\n        # is the first time back after a disconnect, or\n        # we've waited long enough.\n        if self.retryTime is None:\n            attempt = True\n        else:\n            attempt = (now >= self.retryTime)\n        if attempt:\n            try:\n                self.sock = self.makeSocket()\n                self.retryTime = None # next time, no delay before trying\n            except socket.error:\n                #Creation failed, so set the retry time and return.\n                if self.retryTime is None:\n                    self.retryPeriod = self.retryStart\n                else:\n                    self.retryPeriod = self.retryPeriod * self.retryFactor\n                    if self.retryPeriod > self.retryMax:\n                        self.retryPeriod = self.retryMax\n                self.retryTime = now + self.retryPeriod\n\n    def send(self, s):\n        \"\"\"\n        Send a pickled string to the socket.\n\n        This function allows for partial sends which can happen when the\n        network is busy.\n        \"\"\"\n        if self.sock is None:\n            self.createSocket()\n        #self.sock can be None either because we haven't reached the retry\n        #time yet, or because we have reached the retry time and retried,\n        #but are still unable to connect.\n        if self.sock:\n            try:\n                if hasattr(self.sock, \"sendall\"):\n                    self.sock.sendall(s)\n                else: #pragma: no cover\n                    sentsofar = 0\n                    left = len(s)\n                    while left > 0:\n                        sent = self.sock.send(s[sentsofar:])\n                        sentsofar = sentsofar + sent\n                        left = left - sent\n            except socket.error: #pragma: no cover\n                self.sock.close()\n                self.sock = None  # so we can call createSocket next time\n\n    def makePickle(self, record):\n        \"\"\"\n        Pickles the record in binary format with a length prefix, and\n        returns it ready for transmission across the socket.\n        \"\"\"\n        ei = record.exc_info\n        if ei:\n            # just to get traceback text into record.exc_text ...\n            dummy = self.format(record)\n        # See issue #14436: If msg or args are objects, they may not be\n        # available on the receiving end. So we convert the msg % args\n        # to a string, save it as msg and zap the args.\n        d = dict(record.__dict__)\n        d['msg'] = record.getMessage()\n        d['args'] = None\n        d['exc_info'] = None\n        s = pickle.dumps(d, 1)\n        slen = struct.pack(\">L\", len(s))\n        return slen + s\n\n    def handleError(self, record):\n        \"\"\"\n        Handle an error during logging.\n\n        An error has occurred during logging. Most likely cause -\n        connection lost. Close the socket so that we can retry on the\n        next event.\n        \"\"\"\n        if self.closeOnError and self.sock:\n            self.sock.close()\n            self.sock = None        #try to reconnect next time\n        else:\n            logging.Handler.handleError(self, record)\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        Pickles the record and writes it to the socket in binary format.\n        If there is an error with the socket, silently drop the packet.\n        If there was a problem with the socket, re-establishes the\n        socket.\n        \"\"\"\n        try:\n            s = self.makePickle(record)\n            self.send(s)\n        except (KeyboardInterrupt, SystemExit): #pragma: no cover\n            raise\n        except:\n            self.handleError(record)\n\n    def close(self):\n        \"\"\"\n        Closes the socket.\n        \"\"\"\n        self.acquire()\n        try:\n            if self.sock:\n                self.sock.close()\n                self.sock = None\n            logging.Handler.close(self)\n        finally:\n            self.release()\n\nclass DatagramHandler(SocketHandler):\n    \"\"\"\n    A handler class which writes logging records, in pickle format, to\n    a datagram socket.  The pickle which is sent is that of the LogRecord's\n    attribute dictionary (__dict__), so that the receiver does not need to\n    have the logging module installed in order to process the logging event.\n\n    To unpickle the record at the receiving end into a LogRecord, use the\n    makeLogRecord function.\n\n    \"\"\"\n    def __init__(self, host, port):\n        \"\"\"\n        Initializes the handler with a specific host address and port.\n        \"\"\"\n        SocketHandler.__init__(self, host, port)\n        self.closeOnError = False\n\n    def makeSocket(self):\n        \"\"\"\n        The factory method of SocketHandler is here overridden to create\n        a UDP socket (SOCK_DGRAM).\n        \"\"\"\n        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        return s\n\n    def send(self, s):\n        \"\"\"\n        Send a pickled string to a socket.\n\n        This function no longer allows for partial sends which can happen\n        when the network is busy - UDP does not guarantee delivery and\n        can deliver packets out of sequence.\n        \"\"\"\n        if self.sock is None:\n            self.createSocket()\n        self.sock.sendto(s, (self.host, self.port))\n\nclass SysLogHandler(logging.Handler):\n    \"\"\"\n    A handler class which sends formatted logging records to a syslog\n    server. Based on Sam Rushing's syslog module:\n    http://www.nightmare.com/squirl/python-ext/misc/syslog.py\n    Contributed by Nicolas Untz (after which minor refactoring changes\n    have been made).\n    \"\"\"\n\n    # from <linux/sys/syslog.h>:\n    # ======================================================================\n    # priorities/facilities are encoded into a single 32-bit quantity, where\n    # the bottom 3 bits are the priority (0-7) and the top 28 bits are the\n    # facility (0-big number). Both the priorities and the facilities map\n    # roughly one-to-one to strings in the syslogd(8) source code.  This\n    # mapping is included in this file.\n    #\n    # priorities (these are ordered)\n\n    LOG_EMERG     = 0       #  system is unusable\n    LOG_ALERT     = 1       #  action must be taken immediately\n    LOG_CRIT      = 2       #  critical conditions\n    LOG_ERR       = 3       #  error conditions\n    LOG_WARNING   = 4       #  warning conditions\n    LOG_NOTICE    = 5       #  normal but significant condition\n    LOG_INFO      = 6       #  informational\n    LOG_DEBUG     = 7       #  debug-level messages\n\n    #  facility codes\n    LOG_KERN      = 0       #  kernel messages\n    LOG_USER      = 1       #  random user-level messages\n    LOG_MAIL      = 2       #  mail system\n    LOG_DAEMON    = 3       #  system daemons\n    LOG_AUTH      = 4       #  security/authorization messages\n    LOG_SYSLOG    = 5       #  messages generated internally by syslogd\n    LOG_LPR       = 6       #  line printer subsystem\n    LOG_NEWS      = 7       #  network news subsystem\n    LOG_UUCP      = 8       #  UUCP subsystem\n    LOG_CRON      = 9       #  clock daemon\n    LOG_AUTHPRIV  = 10      #  security/authorization messages (private)\n    LOG_FTP       = 11      #  FTP daemon\n\n    #  other codes through 15 reserved for system use\n    LOG_LOCAL0    = 16      #  reserved for local use\n    LOG_LOCAL1    = 17      #  reserved for local use\n    LOG_LOCAL2    = 18      #  reserved for local use\n    LOG_LOCAL3    = 19      #  reserved for local use\n    LOG_LOCAL4    = 20      #  reserved for local use\n    LOG_LOCAL5    = 21      #  reserved for local use\n    LOG_LOCAL6    = 22      #  reserved for local use\n    LOG_LOCAL7    = 23      #  reserved for local use\n\n    priority_names = {\n        \"alert\":    LOG_ALERT,\n        \"crit\":     LOG_CRIT,\n        \"critical\": LOG_CRIT,\n        \"debug\":    LOG_DEBUG,\n        \"emerg\":    LOG_EMERG,\n        \"err\":      LOG_ERR,\n        \"error\":    LOG_ERR,        #  DEPRECATED\n        \"info\":     LOG_INFO,\n        \"notice\":   LOG_NOTICE,\n        \"panic\":    LOG_EMERG,      #  DEPRECATED\n        \"warn\":     LOG_WARNING,    #  DEPRECATED\n        \"warning\":  LOG_WARNING,\n        }\n\n    facility_names = {\n        \"auth\":     LOG_AUTH,\n        \"authpriv\": LOG_AUTHPRIV,\n        \"cron\":     LOG_CRON,\n        \"daemon\":   LOG_DAEMON,\n        \"ftp\":      LOG_FTP,\n        \"kern\":     LOG_KERN,\n        \"lpr\":      LOG_LPR,\n        \"mail\":     LOG_MAIL,\n        \"news\":     LOG_NEWS,\n        \"security\": LOG_AUTH,       #  DEPRECATED\n        \"syslog\":   LOG_SYSLOG,\n        \"user\":     LOG_USER,\n        \"uucp\":     LOG_UUCP,\n        \"local0\":   LOG_LOCAL0,\n        \"local1\":   LOG_LOCAL1,\n        \"local2\":   LOG_LOCAL2,\n        \"local3\":   LOG_LOCAL3,\n        \"local4\":   LOG_LOCAL4,\n        \"local5\":   LOG_LOCAL5,\n        \"local6\":   LOG_LOCAL6,\n        \"local7\":   LOG_LOCAL7,\n        }\n\n    #The map below appears to be trivially lowercasing the key. However,\n    #there's more to it than meets the eye - in some locales, lowercasing\n    #gives unexpected results. See SF #1524081: in the Turkish locale,\n    #\"INFO\".lower() != \"info\"\n    priority_map = {\n        \"DEBUG\" : \"debug\",\n        \"INFO\" : \"info\",\n        \"WARNING\" : \"warning\",\n        \"ERROR\" : \"error\",\n        \"CRITICAL\" : \"critical\"\n    }\n\n    def __init__(self, address=('localhost', SYSLOG_UDP_PORT),\n                 facility=LOG_USER, socktype=None):\n        \"\"\"\n        Initialize a handler.\n\n        If address is specified as a string, a UNIX socket is used. To log to a\n        local syslogd, \"SysLogHandler(address=\"/dev/log\")\" can be used.\n        If facility is not specified, LOG_USER is used.\n        \"\"\"\n        logging.Handler.__init__(self)\n\n        self.address = address\n        self.facility = facility\n        self.socktype = socktype\n\n        if isinstance(address, str):\n            self.unixsocket = True\n            self._connect_unixsocket(address)\n        else:\n            self.unixsocket = False\n            if socktype is None:\n                socktype = socket.SOCK_DGRAM\n            self.socket = socket.socket(socket.AF_INET, socktype)\n            if socktype == socket.SOCK_STREAM:\n                self.socket.connect(address)\n            self.socktype = socktype\n        self.formatter = None\n\n    def _connect_unixsocket(self, address):\n        use_socktype = self.socktype\n        if use_socktype is None:\n            use_socktype = socket.SOCK_DGRAM\n        self.socket = socket.socket(socket.AF_UNIX, use_socktype)\n        try:\n            self.socket.connect(address)\n            # it worked, so set self.socktype to the used type\n            self.socktype = use_socktype\n        except socket.error:\n            self.socket.close()\n            if self.socktype is not None:\n                # user didn't specify falling back, so fail\n                raise\n            use_socktype = socket.SOCK_STREAM\n            self.socket = socket.socket(socket.AF_UNIX, use_socktype)\n            try:\n                self.socket.connect(address)\n                # it worked, so set self.socktype to the used type\n                self.socktype = use_socktype\n            except socket.error:\n                self.socket.close()\n                raise\n\n    def encodePriority(self, facility, priority):\n        \"\"\"\n        Encode the facility and priority. You can pass in strings or\n        integers - if strings are passed, the facility_names and\n        priority_names mapping dictionaries are used to convert them to\n        integers.\n        \"\"\"\n        if isinstance(facility, str):\n            facility = self.facility_names[facility]\n        if isinstance(priority, str):\n            priority = self.priority_names[priority]\n        return (facility << 3) | priority\n\n    def close (self):\n        \"\"\"\n        Closes the socket.\n        \"\"\"\n        self.acquire()\n        try:\n            self.socket.close()\n            logging.Handler.close(self)\n        finally:\n            self.release()\n\n    def mapPriority(self, levelName):\n        \"\"\"\n        Map a logging level name to a key in the priority_names map.\n        This is useful in two scenarios: when custom levels are being\n        used, and in the case where you can't do a straightforward\n        mapping by lowercasing the logging level name because of locale-\n        specific issues (see SF #1524081).\n        \"\"\"\n        return self.priority_map.get(levelName, \"warning\")\n\n    ident = ''          # prepended to all messages\n    append_nul = True   # some old syslog daemons expect a NUL terminator\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        The record is formatted, and then sent to the syslog server. If\n        exception information is present, it is NOT sent to the server.\n        \"\"\"\n        msg = self.format(record)\n        if self.ident:\n            msg = self.ident + msg\n        if self.append_nul:\n            msg += '\\000'\n        \"\"\"\n        We need to convert record level to lowercase, maybe this will\n        change in the future.\n        \"\"\"\n        prio = '<%d>' % self.encodePriority(self.facility,\n                                            self.mapPriority(record.levelname))\n        prio = prio.encode('utf-8')\n        # Message is a string. Convert to bytes as required by RFC 5424\n        msg = msg.encode('utf-8')\n        msg = prio + msg\n        try:\n            if self.unixsocket:\n                try:\n                    self.socket.send(msg)\n                except socket.error:\n                    self.socket.close()\n                    self._connect_unixsocket(self.address)\n                    self.socket.send(msg)\n            elif self.socktype == socket.SOCK_DGRAM:\n                self.socket.sendto(msg, self.address)\n            else:\n                self.socket.sendall(msg)\n        except (KeyboardInterrupt, SystemExit): #pragma: no cover\n            raise\n        except:\n            self.handleError(record)\n\nclass SMTPHandler(logging.Handler):\n    \"\"\"\n    A handler class which sends an SMTP email for each logging event.\n    \"\"\"\n    def __init__(self, mailhost, fromaddr, toaddrs, subject,\n                 credentials=None, secure=None, timeout=5.0):\n        \"\"\"\n        Initialize the handler.\n\n        Initialize the instance with the from and to addresses and subject\n        line of the email. To specify a non-standard SMTP port, use the\n        (host, port) tuple format for the mailhost argument. To specify\n        authentication credentials, supply a (username, password) tuple\n        for the credentials argument. To specify the use of a secure\n        protocol (TLS), pass in a tuple for the secure argument. This will\n        only be used when authentication credentials are supplied. The tuple\n        will be either an empty tuple, or a single-value tuple with the name\n        of a keyfile, or a 2-value tuple with the names of the keyfile and\n        certificate file. (This tuple is passed to the `starttls` method).\n        A timeout in seconds can be specified for the SMTP connection (the\n        default is one second).\n        \"\"\"\n        logging.Handler.__init__(self)\n        if isinstance(mailhost, tuple):\n            self.mailhost, self.mailport = mailhost\n        else:\n            self.mailhost, self.mailport = mailhost, None\n        if isinstance(credentials, tuple):\n            self.username, self.password = credentials\n        else:\n            self.username = None\n        self.fromaddr = fromaddr\n        if isinstance(toaddrs, str):\n            toaddrs = [toaddrs]\n        self.toaddrs = toaddrs\n        self.subject = subject\n        self.secure = secure\n        self.timeout = timeout\n\n    def getSubject(self, record):\n        \"\"\"\n        Determine the subject for the email.\n\n        If you want to specify a subject line which is record-dependent,\n        override this method.\n        \"\"\"\n        return self.subject\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        Format the record and send it to the specified addressees.\n        \"\"\"\n        try:\n            import smtplib\n            from email.utils import formatdate\n            port = self.mailport\n            if not port:\n                port = smtplib.SMTP_PORT\n            smtp = smtplib.SMTP(self.mailhost, port, timeout=self.timeout)\n            msg = self.format(record)\n            msg = \"From: %s\\r\\nTo: %s\\r\\nSubject: %s\\r\\nDate: %s\\r\\n\\r\\n%s\" % (\n                            self.fromaddr,\n                            \",\".join(self.toaddrs),\n                            self.getSubject(record),\n                            formatdate(), msg)\n            if self.username:\n                if self.secure is not None:\n                    smtp.ehlo()\n                    smtp.starttls(*self.secure)\n                    smtp.ehlo()\n                smtp.login(self.username, self.password)\n            smtp.sendmail(self.fromaddr, self.toaddrs, msg)\n            smtp.quit()\n        except (KeyboardInterrupt, SystemExit): #pragma: no cover\n            raise\n        except:\n            self.handleError(record)\n\nclass NTEventLogHandler(logging.Handler):\n    \"\"\"\n    A handler class which sends events to the NT Event Log. Adds a\n    registry entry for the specified application name. If no dllname is\n    provided, win32service.pyd (which contains some basic message\n    placeholders) is used. Note that use of these placeholders will make\n    your event logs big, as the entire message source is held in the log.\n    If you want slimmer logs, you have to pass in the name of your own DLL\n    which contains the message definitions you want to use in the event log.\n    \"\"\"\n    def __init__(self, appname, dllname=None, logtype=\"Application\"):\n        logging.Handler.__init__(self)\n        try:\n            import win32evtlogutil, win32evtlog\n            self.appname = appname\n            self._welu = win32evtlogutil\n            if not dllname:\n                dllname = os.path.split(self._welu.__file__)\n                dllname = os.path.split(dllname[0])\n                dllname = os.path.join(dllname[0], r'win32service.pyd')\n            self.dllname = dllname\n            self.logtype = logtype\n            self._welu.AddSourceToRegistry(appname, dllname, logtype)\n            self.deftype = win32evtlog.EVENTLOG_ERROR_TYPE\n            self.typemap = {\n                logging.DEBUG   : win32evtlog.EVENTLOG_INFORMATION_TYPE,\n                logging.INFO    : win32evtlog.EVENTLOG_INFORMATION_TYPE,\n                logging.WARNING : win32evtlog.EVENTLOG_WARNING_TYPE,\n                logging.ERROR   : win32evtlog.EVENTLOG_ERROR_TYPE,\n                logging.CRITICAL: win32evtlog.EVENTLOG_ERROR_TYPE,\n         }\n        except ImportError:\n            print(\"The Python Win32 extensions for NT (service, event \"\\\n                        \"logging) appear not to be available.\")\n            self._welu = None\n\n    def getMessageID(self, record):\n        \"\"\"\n        Return the message ID for the event record. If you are using your\n        own messages, you could do this by having the msg passed to the\n        logger being an ID rather than a formatting string. Then, in here,\n        you could use a dictionary lookup to get the message ID. This\n        version returns 1, which is the base message ID in win32service.pyd.\n        \"\"\"\n        return 1\n\n    def getEventCategory(self, record):\n        \"\"\"\n        Return the event category for the record.\n\n        Override this if you want to specify your own categories. This version\n        returns 0.\n        \"\"\"\n        return 0\n\n    def getEventType(self, record):\n        \"\"\"\n        Return the event type for the record.\n\n        Override this if you want to specify your own types. This version does\n        a mapping using the handler's typemap attribute, which is set up in\n        __init__() to a dictionary which contains mappings for DEBUG, INFO,\n        WARNING, ERROR and CRITICAL. If you are using your own levels you will\n        either need to override this method or place a suitable dictionary in\n        the handler's typemap attribute.\n        \"\"\"\n        return self.typemap.get(record.levelno, self.deftype)\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        Determine the message ID, event category and event type. Then\n        log the message in the NT event log.\n        \"\"\"\n        if self._welu:\n            try:\n                id = self.getMessageID(record)\n                cat = self.getEventCategory(record)\n                type = self.getEventType(record)\n                msg = self.format(record)\n                self._welu.ReportEvent(self.appname, id, cat, type, [msg])\n            except (KeyboardInterrupt, SystemExit): #pragma: no cover\n                raise\n            except:\n                self.handleError(record)\n\n    def close(self):\n        \"\"\"\n        Clean up this handler.\n\n        You can remove the application name from the registry as a\n        source of event log entries. However, if you do this, you will\n        not be able to see the events as you intended in the Event Log\n        Viewer - it needs to be able to access the registry to get the\n        DLL name.\n        \"\"\"\n        #self._welu.RemoveSourceFromRegistry(self.appname, self.logtype)\n        logging.Handler.close(self)\n\nclass HTTPHandler(logging.Handler):\n    \"\"\"\n    A class which sends records to a Web server, using either GET or\n    POST semantics.\n    \"\"\"\n    def __init__(self, host, url, method=\"GET\", secure=False, credentials=None):\n        \"\"\"\n        Initialize the instance with the host, the request URL, and the method\n        (\"GET\" or \"POST\")\n        \"\"\"\n        logging.Handler.__init__(self)\n        method = method.upper()\n        if method not in [\"GET\", \"POST\"]:\n            raise ValueError(\"method must be GET or POST\")\n        self.host = host\n        self.url = url\n        self.method = method\n        self.secure = secure\n        self.credentials = credentials\n\n    def mapLogRecord(self, record):\n        \"\"\"\n        Default implementation of mapping the log record into a dict\n        that is sent as the CGI data. Overwrite in your class.\n        Contributed by Franz Glasner.\n        \"\"\"\n        return record.__dict__\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        Send the record to the Web server as a percent-encoded dictionary\n        \"\"\"\n        try:\n            import http.client, urllib.parse\n            host = self.host\n            if self.secure:\n                h = http.client.HTTPSConnection(host)\n            else:\n                h = http.client.HTTPConnection(host)\n            url = self.url\n            data = urllib.parse.urlencode(self.mapLogRecord(record))\n            if self.method == \"GET\":\n                if (url.find('?') >= 0):\n                    sep = '&'\n                else:\n                    sep = '?'\n                url = url + \"%c%s\" % (sep, data)\n            h.putrequest(self.method, url)\n            # support multiple hosts on one IP address...\n            # need to strip optional :port from host, if present\n            i = host.find(\":\")\n            if i >= 0:\n                host = host[:i]\n            h.putheader(\"Host\", host)\n            if self.method == \"POST\":\n                h.putheader(\"Content-type\",\n                            \"application/x-www-form-urlencoded\")\n                h.putheader(\"Content-length\", str(len(data)))\n            if self.credentials:\n                import base64\n                s = ('u%s:%s' % self.credentials).encode('utf-8')\n                s = 'Basic ' + base64.b64encode(s).strip()\n                h.putheader('Authorization', s)\n            h.endheaders()\n            if self.method == \"POST\":\n                h.send(data.encode('utf-8'))\n            h.getresponse()    #can't do anything with the result\n        except (KeyboardInterrupt, SystemExit): #pragma: no cover\n            raise\n        except:\n            self.handleError(record)\n\nclass BufferingHandler(logging.Handler):\n    \"\"\"\n  A handler class which buffers logging records in memory. Whenever each\n  record is added to the buffer, a check is made to see if the buffer should\n  be flushed. If it should, then flush() is expected to do what's needed.\n    \"\"\"\n    def __init__(self, capacity):\n        \"\"\"\n        Initialize the handler with the buffer size.\n        \"\"\"\n        logging.Handler.__init__(self)\n        self.capacity = capacity\n        self.buffer = []\n\n    def shouldFlush(self, record):\n        \"\"\"\n        Should the handler flush its buffer?\n\n        Returns true if the buffer is up to capacity. This method can be\n        overridden to implement custom flushing strategies.\n        \"\"\"\n        return (len(self.buffer) >= self.capacity)\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        Append the record. If shouldFlush() tells us to, call flush() to process\n        the buffer.\n        \"\"\"\n        self.buffer.append(record)\n        if self.shouldFlush(record):\n            self.flush()\n\n    def flush(self):\n        \"\"\"\n        Override to implement custom flushing behaviour.\n\n        This version just zaps the buffer to empty.\n        \"\"\"\n        self.acquire()\n        try:\n            self.buffer = []\n        finally:\n            self.release()\n\n    def close(self):\n        \"\"\"\n        Close the handler.\n\n        This version just flushes and chains to the parent class' close().\n        \"\"\"\n        self.flush()\n        logging.Handler.close(self)\n\nclass MemoryHandler(BufferingHandler):\n    \"\"\"\n    A handler class which buffers logging records in memory, periodically\n    flushing them to a target handler. Flushing occurs whenever the buffer\n    is full, or when an event of a certain severity or greater is seen.\n    \"\"\"\n    def __init__(self, capacity, flushLevel=logging.ERROR, target=None):\n        \"\"\"\n        Initialize the handler with the buffer size, the level at which\n        flushing should occur and an optional target.\n\n        Note that without a target being set either here or via setTarget(),\n        a MemoryHandler is no use to anyone!\n        \"\"\"\n        BufferingHandler.__init__(self, capacity)\n        self.flushLevel = flushLevel\n        self.target = target\n\n    def shouldFlush(self, record):\n        \"\"\"\n        Check for buffer full or a record at the flushLevel or higher.\n        \"\"\"\n        return (len(self.buffer) >= self.capacity) or \\\n                (record.levelno >= self.flushLevel)\n\n    def setTarget(self, target):\n        \"\"\"\n        Set the target handler for this handler.\n        \"\"\"\n        self.target = target\n\n    def flush(self):\n        \"\"\"\n        For a MemoryHandler, flushing means just sending the buffered\n        records to the target, if there is one. Override if you want\n        different behaviour.\n\n        The record buffer is also cleared by this operation.\n        \"\"\"\n        self.acquire()\n        try:\n            if self.target:\n                for record in self.buffer:\n                    self.target.handle(record)\n                self.buffer = []\n        finally:\n            self.release()\n\n    def close(self):\n        \"\"\"\n        Flush, set the target to None and lose the buffer.\n        \"\"\"\n        self.flush()\n        self.acquire()\n        try:\n            self.target = None\n            BufferingHandler.close(self)\n        finally:\n            self.release()\n\n\nclass QueueHandler(logging.Handler):\n    \"\"\"\n    This handler sends events to a queue. Typically, it would be used together\n    with a multiprocessing Queue to centralise logging to file in one process\n    (in a multi-process application), so as to avoid file write contention\n    between processes.\n\n    This code is new in Python 3.2, but this class can be copy pasted into\n    user code for use with earlier Python versions.\n    \"\"\"\n\n    def __init__(self, queue):\n        \"\"\"\n        Initialise an instance, using the passed queue.\n        \"\"\"\n        logging.Handler.__init__(self)\n        self.queue = queue\n\n    def enqueue(self, record):\n        \"\"\"\n        Enqueue a record.\n\n        The base implementation uses put_nowait. You may want to override\n        this method if you want to use blocking, timeouts or custom queue\n        implementations.\n        \"\"\"\n        self.queue.put_nowait(record)\n\n    def prepare(self, record):\n        \"\"\"\n        Prepares a record for queuing. The object returned by this method is\n        enqueued.\n\n        The base implementation formats the record to merge the message\n        and arguments, and removes unpickleable items from the record\n        in-place.\n\n        You might want to override this method if you want to convert\n        the record to a dict or JSON string, or send a modified copy\n        of the record while leaving the original intact.\n        \"\"\"\n        # The format operation gets traceback text into record.exc_text\n        # (if there's exception data), and also puts the message into\n        # record.message. We can then use this to replace the original\n        # msg + args, as these might be unpickleable. We also zap the\n        # exc_info attribute, as it's no longer needed and, if not None,\n        # will typically not be pickleable.\n        self.format(record)\n        record.msg = record.message\n        record.args = None\n        record.exc_info = None\n        return record\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        Writes the LogRecord to the queue, preparing it for pickling first.\n        \"\"\"\n        try:\n            self.enqueue(self.prepare(record))\n        except (KeyboardInterrupt, SystemExit): #pragma: no cover\n            raise\n        except:\n            self.handleError(record)\n\nif threading:\n    class QueueListener(object):\n        \"\"\"\n        This class implements an internal threaded listener which watches for\n        LogRecords being added to a queue, removes them and passes them to a\n        list of handlers for processing.\n        \"\"\"\n        _sentinel = None\n\n        def __init__(self, queue, *handlers):\n            \"\"\"\n            Initialise an instance with the specified queue and\n            handlers.\n            \"\"\"\n            self.queue = queue\n            self.handlers = handlers\n            self._stop = threading.Event()\n            self._thread = None\n\n        def dequeue(self, block):\n            \"\"\"\n            Dequeue a record and return it, optionally blocking.\n\n            The base implementation uses get. You may want to override this method\n            if you want to use timeouts or work with custom queue implementations.\n            \"\"\"\n            return self.queue.get(block)\n\n        def start(self):\n            \"\"\"\n            Start the listener.\n\n            This starts up a background thread to monitor the queue for\n            LogRecords to process.\n            \"\"\"\n            self._thread = t = threading.Thread(target=self._monitor)\n            t.setDaemon(True)\n            t.start()\n\n        def prepare(self , record):\n            \"\"\"\n            Prepare a record for handling.\n\n            This method just returns the passed-in record. You may want to\n            override this method if you need to do any custom marshalling or\n            manipulation of the record before passing it to the handlers.\n            \"\"\"\n            return record\n\n        def handle(self, record):\n            \"\"\"\n            Handle a record.\n\n            This just loops through the handlers offering them the record\n            to handle.\n            \"\"\"\n            record = self.prepare(record)\n            for handler in self.handlers:\n                handler.handle(record)\n\n        def _monitor(self):\n            \"\"\"\n            Monitor the queue for records, and ask the handler\n            to deal with them.\n\n            This method runs on a separate, internal thread.\n            The thread will terminate if it sees a sentinel object in the queue.\n            \"\"\"\n            q = self.queue\n            has_task_done = hasattr(q, 'task_done')\n            while not self._stop.isSet():\n                try:\n                    record = self.dequeue(True)\n                    if record is self._sentinel:\n                        break\n                    self.handle(record)\n                    if has_task_done:\n                        q.task_done()\n                except queue.Empty:\n                    pass\n            # There might still be records in the queue.\n            while True:\n                try:\n                    record = self.dequeue(False)\n                    if record is self._sentinel:\n                        break\n                    self.handle(record)\n                    if has_task_done:\n                        q.task_done()\n                except queue.Empty:\n                    break\n\n        def enqueue_sentinel(self):\n            \"\"\"\n            This is used to enqueue the sentinel record.\n\n            The base implementation uses put_nowait. You may want to override this\n            method if you want to use timeouts or work with custom queue\n            implementations.\n            \"\"\"\n            self.queue.put_nowait(self._sentinel)\n\n        def stop(self):\n            \"\"\"\n            Stop the listener.\n\n            This asks the thread to terminate, and then waits for it to do so.\n            Note that if you don't call this before your application exits, there\n            may be some records still left on the queue, which won't be processed.\n            \"\"\"\n            self._stop.set()\n            self.enqueue_sentinel()\n            self._thread.join()\n            self._thread = None\n"], "_websocket": [".js", "// websocket\nvar $module = (function($B){\n\n    var $WebSocketDict = {\n        __class__ :$B.$type,\n        __name__:'WebSocket'\n    }\n    \n    $WebSocketDict.bind = function(self,event,callback){\n        self.$ws['on'+event] = callback\n    }\n    \n    $WebSocketDict.send = function(self,data){\n        self.$ws.send(data)\n    }\n        \n    $WebSocketDict.close = function(self){\n        self.$ws.close()\n    }\n    \n    $WebSocketDict.__mro__ = [$WebSocketDict,$B.builtins.object.$dict]\n    \n    function websocket(host){\n        var $socket = new WebSocket(host);\n        var res = {\n            __class__:$WebSocketDict,\n            $ws : $socket\n        }\n        res.$websocket = $socket\n        return res\n    }\n    websocket.__class__ = $B.$factory\n    websocket.$dict = $WebSocketDict\n    \n    return {websocket:websocket}\n\n})(__BRYTHON__)\n"], "abc": [".py", "# Copyright 2007 Google, Inc. All Rights Reserved.\n# Licensed to PSF under a Contributor Agreement.\n\n\"\"\"Abstract Base Classes (ABCs) according to PEP 3119.\"\"\"\n\nfrom _weakrefset import WeakSet\n\ndef abstractmethod(funcobj):\n    \"\"\"A decorator indicating abstract methods.\n\n    Requires that the metaclass is ABCMeta or derived from it.  A\n    class that has a metaclass derived from ABCMeta cannot be\n    instantiated unless all of its abstract methods are overridden.\n    The abstract methods can be called using any of the normal\n    'super' call mechanisms.\n\n    Usage:\n\n        class C(metaclass=ABCMeta):\n            @abstractmethod\n            def my_abstract_method(self, ...):\n                ...\n    \"\"\"\n    funcobj.__isabstractmethod__ = True\n    return funcobj\n\n\nclass abstractclassmethod(classmethod):\n    \"\"\"\n    A decorator indicating abstract classmethods.\n\n    Similar to abstractmethod.\n\n    Usage:\n\n        class C(metaclass=ABCMeta):\n            @abstractclassmethod\n            def my_abstract_classmethod(cls, ...):\n                ...\n\n    'abstractclassmethod' is deprecated. Use 'classmethod' with\n    'abstractmethod' instead.\n    \"\"\"\n\n    __isabstractmethod__ = True\n\n    def __init__(self, callable):\n        callable.__isabstractmethod__ = True\n        super().__init__(callable)\n\n\nclass abstractstaticmethod(staticmethod):\n    \"\"\"\n    A decorator indicating abstract staticmethods.\n\n    Similar to abstractmethod.\n\n    Usage:\n\n        class C(metaclass=ABCMeta):\n            @abstractstaticmethod\n            def my_abstract_staticmethod(...):\n                ...\n\n    'abstractstaticmethod' is deprecated. Use 'staticmethod' with\n    'abstractmethod' instead.\n    \"\"\"\n\n    __isabstractmethod__ = True\n\n    def __init__(self, callable):\n        callable.__isabstractmethod__ = True\n        super().__init__(callable)\n\n\nclass abstractproperty(property):\n    \"\"\"\n    A decorator indicating abstract properties.\n\n    Requires that the metaclass is ABCMeta or derived from it.  A\n    class that has a metaclass derived from ABCMeta cannot be\n    instantiated unless all of its abstract properties are overridden.\n    The abstract properties can be called using any of the normal\n    'super' call mechanisms.\n\n    Usage:\n\n        class C(metaclass=ABCMeta):\n            @abstractproperty\n            def my_abstract_property(self):\n                ...\n\n    This defines a read-only property; you can also define a read-write\n    abstract property using the 'long' form of property declaration:\n\n        class C(metaclass=ABCMeta):\n            def getx(self): ...\n            def setx(self, value): ...\n            x = abstractproperty(getx, setx)\n\n    'abstractproperty' is deprecated. Use 'property' with 'abstractmethod'\n    instead.\n    \"\"\"\n\n    __isabstractmethod__ = True\n\n\nclass ABCMeta(type):\n\n    \"\"\"Metaclass for defining Abstract Base Classes (ABCs).\n\n    Use this metaclass to create an ABC.  An ABC can be subclassed\n    directly, and then acts as a mix-in class.  You can also register\n    unrelated concrete classes (even built-in classes) and unrelated\n    ABCs as 'virtual subclasses' -- these and their descendants will\n    be considered subclasses of the registering ABC by the built-in\n    issubclass() function, but the registering ABC won't show up in\n    their MRO (Method Resolution Order) nor will method\n    implementations defined by the registering ABC be callable (not\n    even via super()).\n\n    \"\"\"\n\n    # A global counter that is incremented each time a class is\n    # registered as a virtual subclass of anything.  It forces the\n    # negative cache to be cleared before its next use.\n    _abc_invalidation_counter = 0\n\n    def __new__(mcls, name, bases, namespace):\n        cls = super().__new__(mcls, name, bases, namespace)\n        # Compute set of abstract method names\n        abstracts = {name\n                     for name, value in namespace.items()\n                     if getattr(value, \"__isabstractmethod__\", False)}\n        for base in bases:\n            for name in getattr(base, \"__abstractmethods__\", set()):\n                value = getattr(cls, name, None)\n                if getattr(value, \"__isabstractmethod__\", False):\n                    abstracts.add(name)\n        cls.__abstractmethods__ = frozenset(abstracts)\n        # Set up inheritance registry\n        cls._abc_registry = WeakSet()\n        cls._abc_cache = WeakSet()\n        cls._abc_negative_cache = WeakSet()\n        cls._abc_negative_cache_version = ABCMeta._abc_invalidation_counter\n        return cls\n\n    def register(cls, subclass):\n        \"\"\"Register a virtual subclass of an ABC.\n\n        Returns the subclass, to allow usage as a class decorator.\n        \"\"\"\n        if not isinstance(subclass, type):\n            raise TypeError(\"Can only register classes\")\n        if issubclass(subclass, cls):\n            return subclass  # Already a subclass\n        # Subtle: test for cycles *after* testing for \"already a subclass\";\n        # this means we allow X.register(X) and interpret it as a no-op.\n        if issubclass(cls, subclass):\n            # This would create a cycle, which is bad for the algorithm below\n            raise RuntimeError(\"Refusing to create an inheritance cycle\")\n        cls._abc_registry.add(subclass)\n        ABCMeta._abc_invalidation_counter += 1  # Invalidate negative cache\n        return subclass\n\n    def _dump_registry(cls, file=None):\n        \"\"\"Debug helper to print the ABC registry.\"\"\"\n        print(\"Class: %s.%s\" % (cls.__module__, cls.__name__), file=file)\n        print(\"Inv.counter: %s\" % ABCMeta._abc_invalidation_counter, file=file)\n        for name in sorted(cls.__dict__.keys()):\n            if name.startswith(\"_abc_\"):\n                value = getattr(cls, name)\n                print(\"%s: %r\" % (name, value), file=file)\n\n    def __instancecheck__(cls, instance):\n        \"\"\"Override for isinstance(instance, cls).\"\"\"\n        # Inline the cache checking\n        subclass = instance.__class__\n        if subclass in cls._abc_cache:\n            return True\n        subtype = type(instance)\n        if subtype is subclass:\n            if (cls._abc_negative_cache_version ==\n                ABCMeta._abc_invalidation_counter and\n                subclass in cls._abc_negative_cache):\n                return False\n            # Fall back to the subclass check.\n            return cls.__subclasscheck__(subclass)\n        return any(cls.__subclasscheck__(c) for c in {subclass, subtype})\n\n    def __subclasscheck__(cls, subclass):\n        \"\"\"Override for issubclass(subclass, cls).\"\"\"\n        # Check cache\n        if subclass in cls._abc_cache:\n            return True\n        # Check negative cache; may have to invalidate\n        if cls._abc_negative_cache_version < ABCMeta._abc_invalidation_counter:\n            # Invalidate the negative cache\n            cls._abc_negative_cache = WeakSet()\n            cls._abc_negative_cache_version = ABCMeta._abc_invalidation_counter\n        elif subclass in cls._abc_negative_cache:\n            return False\n        # Check the subclass hook\n        ok = cls.__subclasshook__(subclass)\n        if ok is not NotImplemented:\n            assert isinstance(ok, bool)\n            if ok:\n                cls._abc_cache.add(subclass)\n            else:\n                cls._abc_negative_cache.add(subclass)\n            return ok\n        # Check if it's a direct subclass\n        if cls in getattr(subclass, '__mro__', ()):\n            cls._abc_cache.add(subclass)\n            return True\n        # Check if it's a subclass of a registered class (recursive)\n        for rcls in cls._abc_registry:\n            if issubclass(subclass, rcls):\n                cls._abc_cache.add(subclass)\n                return True\n        # Check if it's a subclass of a subclass (recursive)\n        for scls in cls.__subclasses__():\n            if issubclass(subclass, scls):\n                cls._abc_cache.add(subclass)\n                return True\n        # No dice; update negative cache\n        cls._abc_negative_cache.add(subclass)\n        return False\n"], "_thread": [".py", "\"\"\"Drop-in replacement for the thread module.\n\nMeant to be used as a brain-dead substitute so that threaded code does\nnot need to be rewritten for when the thread module is not present.\n\nSuggested usage is::\n\n    try:\n        import _thread\n    except ImportError:\n        import _dummy_thread as _thread\n\n\"\"\"\n# Exports only things specified by thread documentation;\n# skipping obsolete synonyms allocate(), start_new(), exit_thread().\n__all__ = ['error', 'start_new_thread', 'exit', 'get_ident', 'allocate_lock',\n           'interrupt_main', 'LockType']\n\n# A dummy value\nTIMEOUT_MAX = 2**31\n\n# NOTE: this module can be imported early in the extension building process,\n# and so top level imports of other modules should be avoided.  Instead, all\n# imports are done when needed on a function-by-function basis.  Since threads\n# are disabled, the import lock should not be an issue anyway (??).\n\nerror = RuntimeError\n\ndef start_new_thread(function, args, kwargs={}):\n    \"\"\"Dummy implementation of _thread.start_new_thread().\n\n    Compatibility is maintained by making sure that ``args`` is a\n    tuple and ``kwargs`` is a dictionary.  If an exception is raised\n    and it is SystemExit (which can be done by _thread.exit()) it is\n    caught and nothing is done; all other exceptions are printed out\n    by using traceback.print_exc().\n\n    If the executed function calls interrupt_main the KeyboardInterrupt will be\n    raised when the function returns.\n\n    \"\"\"\n    if type(args) != type(tuple()):\n        raise TypeError(\"2nd arg must be a tuple\")\n    if type(kwargs) != type(dict()):\n        raise TypeError(\"3rd arg must be a dict\")\n    global _main\n    _main = False\n    try:\n        function(*args, **kwargs)\n    except SystemExit:\n        pass\n    except:\n        import traceback\n        traceback.print_exc()\n    _main = True\n    global _interrupt\n    if _interrupt:\n        _interrupt = False\n        raise KeyboardInterrupt\n\ndef exit():\n    \"\"\"Dummy implementation of _thread.exit().\"\"\"\n    raise SystemExit\n\ndef get_ident():\n    \"\"\"Dummy implementation of _thread.get_ident().\n\n    Since this module should only be used when _threadmodule is not\n    available, it is safe to assume that the current process is the\n    only thread.  Thus a constant can be safely returned.\n    \"\"\"\n    return -1\n\ndef allocate_lock():\n    \"\"\"Dummy implementation of _thread.allocate_lock().\"\"\"\n    return LockType()\n\ndef stack_size(size=None):\n    \"\"\"Dummy implementation of _thread.stack_size().\"\"\"\n    if size is not None:\n        raise error(\"setting thread stack size not supported\")\n    return 0\n\nclass LockType(object):\n    \"\"\"Class implementing dummy implementation of _thread.LockType.\n\n    Compatibility is maintained by maintaining self.locked_status\n    which is a boolean that stores the state of the lock.  Pickling of\n    the lock, though, should not be done since if the _thread module is\n    then used with an unpickled ``lock()`` from here problems could\n    occur from this class not having atomic methods.\n\n    \"\"\"\n\n    def __init__(self):\n        self.locked_status = False\n\n    def acquire(self, waitflag=None, timeout=-1):\n        \"\"\"Dummy implementation of acquire().\n\n        For blocking calls, self.locked_status is automatically set to\n        True and returned appropriately based on value of\n        ``waitflag``.  If it is non-blocking, then the value is\n        actually checked and not set if it is already acquired.  This\n        is all done so that threading.Condition's assert statements\n        aren't triggered and throw a little fit.\n\n        \"\"\"\n        if waitflag is None or waitflag:\n            self.locked_status = True\n            return True\n        else:\n            if not self.locked_status:\n                self.locked_status = True\n                return True\n            else:\n                if timeout > 0:\n                    import time\n                    time.sleep(timeout)\n                return False\n\n    __enter__ = acquire\n\n    def __exit__(self, typ, val, tb):\n        self.release()\n\n    def release(self):\n        \"\"\"Release the dummy lock.\"\"\"\n        # XXX Perhaps shouldn't actually bother to test?  Could lead\n        #     to problems for complex, threaded code.\n        if not self.locked_status:\n            raise error\n        self.locked_status = False\n        return True\n\n    def locked(self):\n        return self.locked_status\n\n# Used to signal that interrupt_main was called in a \"thread\"\n_interrupt = False\n# True when not executing in a \"thread\"\n_main = True\n\ndef interrupt_main():\n    \"\"\"Set _interrupt flag to True to have start_new_thread raise\n    KeyboardInterrupt upon exiting.\"\"\"\n    if _main:\n        raise KeyboardInterrupt\n    else:\n        global _interrupt\n        _interrupt = True\n\n# Brython-specific to avoid circular references between threading and _threading_local\nclass _local:\n    pass"], "html.parser": [".py", "\"\"\"A parser for HTML and XHTML.\"\"\"\n\n# This file is based on sgmllib.py, but the API is slightly different.\n\n# XXX There should be a way to distinguish between PCDATA (parsed\n# character data -- the normal case), RCDATA (replaceable character\n# data -- only char and entity references and end tags are special)\n# and CDATA (character data -- only end tags are special).\n\n\nimport _markupbase\nimport re\nimport warnings\n\n# Regular expressions used for parsing\n\ninteresting_normal = re.compile('[&<]')\nincomplete = re.compile('&[a-zA-Z#]')\n\nentityref = re.compile('&([a-zA-Z][-.a-zA-Z0-9]*)[^a-zA-Z0-9]')\ncharref = re.compile('&#(?:[0-9]+|[xX][0-9a-fA-F]+)[^0-9a-fA-F]')\n\nstarttagopen = re.compile('<[a-zA-Z]')\npiclose = re.compile('>')\ncommentclose = re.compile(r'--\\s*>')\ntagfind = re.compile('([a-zA-Z][-.a-zA-Z0-9:_]*)(?:\\s|/(?!>))*')\n# see http://www.w3.org/TR/html5/tokenization.html#tag-open-state\n# and http://www.w3.org/TR/html5/tokenization.html#tag-name-state\ntagfind_tolerant = re.compile('[a-zA-Z][^\\t\\n\\r\\f />\\x00]*')\n# Note:\n#  1) the strict attrfind isn't really strict, but we can't make it\n#     correctly strict without breaking backward compatibility;\n#  2) if you change attrfind remember to update locatestarttagend too;\n#  3) if you change attrfind and/or locatestarttagend the parser will\n#     explode, so don't do it.\nattrfind = re.compile(\n    r'\\s*([a-zA-Z_][-.:a-zA-Z_0-9]*)(\\s*=\\s*'\n    r'(\\'[^\\']*\\'|\"[^\"]*\"|[^\\s\"\\'=<>`]*))?')\nattrfind_tolerant = re.compile(\n    r'((?<=[\\'\"\\s/])[^\\s/>][^\\s/=>]*)(\\s*=+\\s*'\n    r'(\\'[^\\']*\\'|\"[^\"]*\"|(?![\\'\"])[^>\\s]*))?(?:\\s|/(?!>))*')\nlocatestarttagend = re.compile(r\"\"\"\n  <[a-zA-Z][-.a-zA-Z0-9:_]*          # tag name\n  (?:\\s+                             # whitespace before attribute name\n    (?:[a-zA-Z_][-.:a-zA-Z0-9_]*     # attribute name\n      (?:\\s*=\\s*                     # value indicator\n        (?:'[^']*'                   # LITA-enclosed value\n          |\\\"[^\\\"]*\\\"                # LIT-enclosed value\n          |[^'\\\">\\s]+                # bare value\n         )\n       )?\n     )\n   )*\n  \\s*                                # trailing whitespace\n\"\"\", re.VERBOSE)\nlocatestarttagend_tolerant = re.compile(r\"\"\"\n  <[a-zA-Z][-.a-zA-Z0-9:_]*          # tag name\n  (?:[\\s/]*                          # optional whitespace before attribute name\n    (?:(?<=['\"\\s/])[^\\s/>][^\\s/=>]*  # attribute name\n      (?:\\s*=+\\s*                    # value indicator\n        (?:'[^']*'                   # LITA-enclosed value\n          |\"[^\"]*\"                   # LIT-enclosed value\n          |(?!['\"])[^>\\s]*           # bare value\n         )\n         (?:\\s*,)*                   # possibly followed by a comma\n       )?(?:\\s|/(?!>))*\n     )*\n   )?\n  \\s*                                # trailing whitespace\n\"\"\", re.VERBOSE)\nendendtag = re.compile('>')\n# the HTML 5 spec, section 8.1.2.2, doesn't allow spaces between\n# </ and the tag name, so maybe this should be fixed\nendtagfind = re.compile('</\\s*([a-zA-Z][-.a-zA-Z0-9:_]*)\\s*>')\n\n\nclass HTMLParseError(Exception):\n    \"\"\"Exception raised for all parse errors.\"\"\"\n\n    def __init__(self, msg, position=(None, None)):\n        assert msg\n        self.msg = msg\n        self.lineno = position[0]\n        self.offset = position[1]\n\n    def __str__(self):\n        result = self.msg\n        if self.lineno is not None:\n            result = result + \", at line %d\" % self.lineno\n        if self.offset is not None:\n            result = result + \", column %d\" % (self.offset + 1)\n        return result\n\n\nclass HTMLParser(_markupbase.ParserBase):\n    \"\"\"Find tags and other markup and call handler functions.\n\n    Usage:\n        p = HTMLParser()\n        p.feed(data)\n        ...\n        p.close()\n\n    Start tags are handled by calling self.handle_starttag() or\n    self.handle_startendtag(); end tags by self.handle_endtag().  The\n    data between tags is passed from the parser to the derived class\n    by calling self.handle_data() with the data as argument (the data\n    may be split up in arbitrary chunks).  Entity references are\n    passed by calling self.handle_entityref() with the entity\n    reference as the argument.  Numeric character references are\n    passed to self.handle_charref() with the string containing the\n    reference as the argument.\n    \"\"\"\n\n    CDATA_CONTENT_ELEMENTS = (\"script\", \"style\")\n\n    def __init__(self, strict=False):\n        \"\"\"Initialize and reset this instance.\n\n        If strict is set to False (the default) the parser will parse invalid\n        markup, otherwise it will raise an error.  Note that the strict mode\n        is deprecated.\n        \"\"\"\n        if strict:\n            warnings.warn(\"The strict mode is deprecated.\",\n                          DeprecationWarning, stacklevel=2)\n        self.strict = strict\n        self.reset()\n\n    def reset(self):\n        \"\"\"Reset this instance.  Loses all unprocessed data.\"\"\"\n        self.rawdata = ''\n        self.lasttag = '???'\n        self.interesting = interesting_normal\n        self.cdata_elem = None\n        _markupbase.ParserBase.reset(self)\n\n    def feed(self, data):\n        r\"\"\"Feed data to the parser.\n\n        Call this as often as you want, with as little or as much text\n        as you want (may include '\\n').\n        \"\"\"\n        self.rawdata = self.rawdata + data\n        self.goahead(0)\n\n    def close(self):\n        \"\"\"Handle any buffered data.\"\"\"\n        self.goahead(1)\n\n    def error(self, message):\n        raise HTMLParseError(message, self.getpos())\n\n    __starttag_text = None\n\n    def get_starttag_text(self):\n        \"\"\"Return full source of start tag: '<...>'.\"\"\"\n        return self.__starttag_text\n\n    def set_cdata_mode(self, elem):\n        self.cdata_elem = elem.lower()\n        self.interesting = re.compile(r'</\\s*%s\\s*>' % self.cdata_elem, re.I)\n\n    def clear_cdata_mode(self):\n        self.interesting = interesting_normal\n        self.cdata_elem = None\n\n    # Internal -- handle data as far as reasonable.  May leave state\n    # and data to be processed by a subsequent call.  If 'end' is\n    # true, force handling all data as if followed by EOF marker.\n    def goahead(self, end):\n        rawdata = self.rawdata\n        i = 0\n        n = len(rawdata)\n        while i < n:\n            match = self.interesting.search(rawdata, i) # < or &\n            if match:\n                j = match.start()\n            else:\n                if self.cdata_elem:\n                    break\n                j = n\n            if i < j: self.handle_data(rawdata[i:j])\n            i = self.updatepos(i, j)\n            if i == n: break\n            startswith = rawdata.startswith\n            if startswith('<', i):\n                if starttagopen.match(rawdata, i): # < + letter\n                    k = self.parse_starttag(i)\n                elif startswith(\"</\", i):\n                    k = self.parse_endtag(i)\n                elif startswith(\"<!--\", i):\n                    k = self.parse_comment(i)\n                elif startswith(\"<?\", i):\n                    k = self.parse_pi(i)\n                elif startswith(\"<!\", i):\n                    if self.strict:\n                        k = self.parse_declaration(i)\n                    else:\n                        k = self.parse_html_declaration(i)\n                elif (i + 1) < n:\n                    self.handle_data(\"<\")\n                    k = i + 1\n                else:\n                    break\n                if k < 0:\n                    if not end:\n                        break\n                    if self.strict:\n                        self.error(\"EOF in middle of construct\")\n                    k = rawdata.find('>', i + 1)\n                    if k < 0:\n                        k = rawdata.find('<', i + 1)\n                        if k < 0:\n                            k = i + 1\n                    else:\n                        k += 1\n                    self.handle_data(rawdata[i:k])\n                i = self.updatepos(i, k)\n            elif startswith(\"&#\", i):\n                match = charref.match(rawdata, i)\n                if match:\n                    name = match.group()[2:-1]\n                    self.handle_charref(name)\n                    k = match.end()\n                    if not startswith(';', k-1):\n                        k = k - 1\n                    i = self.updatepos(i, k)\n                    continue\n                else:\n                    if \";\" in rawdata[i:]: #bail by consuming &#\n                        self.handle_data(rawdata[0:2])\n                        i = self.updatepos(i, 2)\n                    break\n            elif startswith('&', i):\n                match = entityref.match(rawdata, i)\n                if match:\n                    name = match.group(1)\n                    self.handle_entityref(name)\n                    k = match.end()\n                    if not startswith(';', k-1):\n                        k = k - 1\n                    i = self.updatepos(i, k)\n                    continue\n                match = incomplete.match(rawdata, i)\n                if match:\n                    # match.group() will contain at least 2 chars\n                    if end and match.group() == rawdata[i:]:\n                        if self.strict:\n                            self.error(\"EOF in middle of entity or char ref\")\n                        else:\n                            k = match.end()\n                            if k <= i:\n                                k = n\n                            i = self.updatepos(i, i + 1)\n                    # incomplete\n                    break\n                elif (i + 1) < n:\n                    # not the end of the buffer, and can't be confused\n                    # with some other construct\n                    self.handle_data(\"&\")\n                    i = self.updatepos(i, i + 1)\n                else:\n                    break\n            else:\n                assert 0, \"interesting.search() lied\"\n        # end while\n        if end and i < n and not self.cdata_elem:\n            self.handle_data(rawdata[i:n])\n            i = self.updatepos(i, n)\n        self.rawdata = rawdata[i:]\n\n    # Internal -- parse html declarations, return length or -1 if not terminated\n    # See w3.org/TR/html5/tokenization.html#markup-declaration-open-state\n    # See also parse_declaration in _markupbase\n    def parse_html_declaration(self, i):\n        rawdata = self.rawdata\n        assert rawdata[i:i+2] == '<!', ('unexpected call to '\n                                        'parse_html_declaration()')\n        if rawdata[i:i+4] == '<!--':\n            # this case is actually already handled in goahead()\n            return self.parse_comment(i)\n        elif rawdata[i:i+3] == '<![':\n            return self.parse_marked_section(i)\n        elif rawdata[i:i+9].lower() == '<!doctype':\n            # find the closing >\n            gtpos = rawdata.find('>', i+9)\n            if gtpos == -1:\n                return -1\n            self.handle_decl(rawdata[i+2:gtpos])\n            return gtpos+1\n        else:\n            return self.parse_bogus_comment(i)\n\n    # Internal -- parse bogus comment, return length or -1 if not terminated\n    # see http://www.w3.org/TR/html5/tokenization.html#bogus-comment-state\n    def parse_bogus_comment(self, i, report=1):\n        rawdata = self.rawdata\n        assert rawdata[i:i+2] in ('<!', '</'), ('unexpected call to '\n                                                'parse_comment()')\n        pos = rawdata.find('>', i+2)\n        if pos == -1:\n            return -1\n        if report:\n            self.handle_comment(rawdata[i+2:pos])\n        return pos + 1\n\n    # Internal -- parse processing instr, return end or -1 if not terminated\n    def parse_pi(self, i):\n        rawdata = self.rawdata\n        assert rawdata[i:i+2] == '<?', 'unexpected call to parse_pi()'\n        match = piclose.search(rawdata, i+2) # >\n        if not match:\n            return -1\n        j = match.start()\n        self.handle_pi(rawdata[i+2: j])\n        j = match.end()\n        return j\n\n    # Internal -- handle starttag, return end or -1 if not terminated\n    def parse_starttag(self, i):\n        self.__starttag_text = None\n        endpos = self.check_for_whole_start_tag(i)\n        if endpos < 0:\n            return endpos\n        rawdata = self.rawdata\n        self.__starttag_text = rawdata[i:endpos]\n\n        # Now parse the data between i+1 and j into a tag and attrs\n        attrs = []\n        match = tagfind.match(rawdata, i+1)\n        assert match, 'unexpected call to parse_starttag()'\n        k = match.end()\n        self.lasttag = tag = match.group(1).lower()\n        while k < endpos:\n            if self.strict:\n                m = attrfind.match(rawdata, k)\n            else:\n                m = attrfind_tolerant.match(rawdata, k)\n            if not m:\n                break\n            attrname, rest, attrvalue = m.group(1, 2, 3)\n            if not rest:\n                attrvalue = None\n            elif attrvalue[:1] == '\\'' == attrvalue[-1:] or \\\n                 attrvalue[:1] == '\"' == attrvalue[-1:]:\n                attrvalue = attrvalue[1:-1]\n            if attrvalue:\n                attrvalue = self.unescape(attrvalue)\n            attrs.append((attrname.lower(), attrvalue))\n            k = m.end()\n\n        end = rawdata[k:endpos].strip()\n        if end not in (\">\", \"/>\"):\n            lineno, offset = self.getpos()\n            if \"\\n\" in self.__starttag_text:\n                lineno = lineno + self.__starttag_text.count(\"\\n\")\n                offset = len(self.__starttag_text) \\\n                         - self.__starttag_text.rfind(\"\\n\")\n            else:\n                offset = offset + len(self.__starttag_text)\n            if self.strict:\n                self.error(\"junk characters in start tag: %r\"\n                           % (rawdata[k:endpos][:20],))\n            self.handle_data(rawdata[i:endpos])\n            return endpos\n        if end.endswith('/>'):\n            # XHTML-style empty tag: <span attr=\"value\" />\n            self.handle_startendtag(tag, attrs)\n        else:\n            self.handle_starttag(tag, attrs)\n            if tag in self.CDATA_CONTENT_ELEMENTS:\n                self.set_cdata_mode(tag)\n        return endpos\n\n    # Internal -- check to see if we have a complete starttag; return end\n    # or -1 if incomplete.\n    def check_for_whole_start_tag(self, i):\n        rawdata = self.rawdata\n        if self.strict:\n            m = locatestarttagend.match(rawdata, i)\n        else:\n            m = locatestarttagend_tolerant.match(rawdata, i)\n        if m:\n            j = m.end()\n            next = rawdata[j:j+1]\n            if next == \">\":\n                return j + 1\n            if next == \"/\":\n                if rawdata.startswith(\"/>\", j):\n                    return j + 2\n                if rawdata.startswith(\"/\", j):\n                    # buffer boundary\n                    return -1\n                # else bogus input\n                if self.strict:\n                    self.updatepos(i, j + 1)\n                    self.error(\"malformed empty start tag\")\n                if j > i:\n                    return j\n                else:\n                    return i + 1\n            if next == \"\":\n                # end of input\n                return -1\n            if next in (\"abcdefghijklmnopqrstuvwxyz=/\"\n                        \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"):\n                # end of input in or before attribute value, or we have the\n                # '/' from a '/>' ending\n                return -1\n            if self.strict:\n                self.updatepos(i, j)\n                self.error(\"malformed start tag\")\n            if j > i:\n                return j\n            else:\n                return i + 1\n        raise AssertionError(\"we should not get here!\")\n\n    # Internal -- parse endtag, return end or -1 if incomplete\n    def parse_endtag(self, i):\n        rawdata = self.rawdata\n        assert rawdata[i:i+2] == \"</\", \"unexpected call to parse_endtag\"\n        match = endendtag.search(rawdata, i+1) # >\n        if not match:\n            return -1\n        gtpos = match.end()\n        match = endtagfind.match(rawdata, i) # </ + tag + >\n        if not match:\n            if self.cdata_elem is not None:\n                self.handle_data(rawdata[i:gtpos])\n                return gtpos\n            if self.strict:\n                self.error(\"bad end tag: %r\" % (rawdata[i:gtpos],))\n            # find the name: w3.org/TR/html5/tokenization.html#tag-name-state\n            namematch = tagfind_tolerant.match(rawdata, i+2)\n            if not namematch:\n                # w3.org/TR/html5/tokenization.html#end-tag-open-state\n                if rawdata[i:i+3] == '</>':\n                    return i+3\n                else:\n                    return self.parse_bogus_comment(i)\n            tagname = namematch.group().lower()\n            # consume and ignore other stuff between the name and the >\n            # Note: this is not 100% correct, since we might have things like\n            # </tag attr=\">\">, but looking for > after tha name should cover\n            # most of the cases and is much simpler\n            gtpos = rawdata.find('>', namematch.end())\n            self.handle_endtag(tagname)\n            return gtpos+1\n\n        elem = match.group(1).lower() # script or style\n        if self.cdata_elem is not None:\n            if elem != self.cdata_elem:\n                self.handle_data(rawdata[i:gtpos])\n                return gtpos\n\n        self.handle_endtag(elem.lower())\n        self.clear_cdata_mode()\n        return gtpos\n\n    # Overridable -- finish processing of start+end tag: <tag.../>\n    def handle_startendtag(self, tag, attrs):\n        self.handle_starttag(tag, attrs)\n        self.handle_endtag(tag)\n\n    # Overridable -- handle start tag\n    def handle_starttag(self, tag, attrs):\n        pass\n\n    # Overridable -- handle end tag\n    def handle_endtag(self, tag):\n        pass\n\n    # Overridable -- handle character reference\n    def handle_charref(self, name):\n        pass\n\n    # Overridable -- handle entity reference\n    def handle_entityref(self, name):\n        pass\n\n    # Overridable -- handle data\n    def handle_data(self, data):\n        pass\n\n    # Overridable -- handle comment\n    def handle_comment(self, data):\n        pass\n\n    # Overridable -- handle declaration\n    def handle_decl(self, decl):\n        pass\n\n    # Overridable -- handle processing instruction\n    def handle_pi(self, data):\n        pass\n\n    def unknown_decl(self, data):\n        if self.strict:\n            self.error(\"unknown declaration: %r\" % (data,))\n\n    # Internal -- helper to remove special character quoting\n    def unescape(self, s):\n        if '&' not in s:\n            return s\n        def replaceEntities(s):\n            s = s.groups()[0]\n            try:\n                if s[0] == \"#\":\n                    s = s[1:]\n                    if s[0] in ['x','X']:\n                        c = int(s[1:].rstrip(';'), 16)\n                    else:\n                        c = int(s.rstrip(';'))\n                    return chr(c)\n            except ValueError:\n                return '&#' + s\n            else:\n                from html.entities import html5\n                if s in html5:\n                    return html5[s]\n                elif s.endswith(';'):\n                    return '&' + s\n                for x in range(2, len(s)):\n                    if s[:x] in html5:\n                        return html5[s[:x]] + s[x:]\n                else:\n                    return '&' + s\n\n        return re.sub(r\"&(#?[xX]?(?:[0-9a-fA-F]+;|\\w{1,32};?))\",\n                      replaceEntities, s, flags=re.ASCII)\n"], "unittest.test": [".py", "import os\nimport sys\nimport unittest\n\n\nhere = os.path.dirname(__file__)\nloader = unittest.defaultTestLoader\n\ndef suite():\n    suite = unittest.TestSuite()\n    for fn in os.listdir(here):\n        if fn.startswith(\"test\") and fn.endswith(\".py\"):\n            modname = \"unittest.test.\" + fn[:-3]\n            __import__(modname)\n            module = sys.modules[modname]\n            suite.addTest(loader.loadTestsFromModule(module))\n    suite.addTest(loader.loadTestsFromName('unittest.test.testmock'))\n    return suite\n\n\nif __name__ == \"__main__\":\n    unittest.main(defaultTest=\"suite\")\n", 1], "_multiprocessing": [".js", "// multiprocessing\nvar $module = (function($B){\n\nvar _b_ = $B.builtins\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\n//for(var $py_builtin in _b_){eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")}\n\nvar $ProcessDict = {__class__:$B.$type,__name__:'Process'}\n\nvar $convert_args=function(args) {\n    var _list=[]\n    for(var i=0; i < args.length; i++) {\n      var _a=args[i]\n      if(isinstance(_a, str)){_list.push(\"'\"+_a+\"'\")} else {_list.push(_a)} \n    }\n\n    return _list.join(',')\n}\n\n$ProcessDict.__mro__ = [$ProcessDict, _b_.object.$dict]\n\n$ProcessDict.__str__=$ProcessDict.toString=$ProcessDict.__repr__=function(self){\n   return '<object Process>'\n}\n\n$ProcessDict.is_alive = function(self){return self.$alive}\n\n$ProcessDict.join = function(self, timeout){\n   // need to block until process is complete\n   // could probably use a addEventListener to execute all existing code\n   // after this join statement\n\n   self.$worker.addEventListener('message', function (e) {\n        var data=e.data\n        if (data.stdout != '') { // output stdout from process\n           $B.stdout.write(data.stdout)\n        }\n   }, false);\n}\n\n$ProcessDict.run = function(self){\n   //fix me\n}\n\n$ProcessDict.start = function(self){\n   //var _args=[]\n   //for(var i=0; i < self.$args.length; i++) {\n   //   var _a=self.$args[i]\n   //   if(isinstance(_a, str)){_args.push(\"'\"+_a+\"'\")} else {_args.push(_a)} \n   //}\n\n   self.$worker.postMessage({target: self.$target, \n                             args: $convert_args(self.$args),\n                          //   kwargs: self.$kwargs\n                           })\n   self.$worker.addEventListener('error', function(e) { throw e})\n   self.$alive=true\n}\n\n$ProcessDict.terminate = function(self){\n   self.$worker.terminate()\n   self.$alive=false\n}\n\n// variables\n//name\n//daemon\n//pid\n//exitcode\n\nfunction Process(){\n    //arguments group=None, target=None, name=None, args=(), kwargs=()\n\n    var $ns=$B.$MakeArgs('Process',arguments,[],[],null,'kw')\n    var kw=$ns['kw']\n\n    var target=_b_.dict.$dict.get($ns['kw'],'target',None)\n    var args=_b_.dict.$dict.get($ns['kw'],'args',tuple())\n\n    var worker = new Worker('/src/web_workers/multiprocessing.js')\n\n    var res = {\n        __class__:$ProcessDict,\n        $worker: worker,\n        name: $ns['name'] || None,\n        $target: target+'',\n        $args: args,\n        //$kwargs: $ns['kw'],\n        $alive: false\n    }\n    return res\n}\n\nProcess.__class__ = $B.$factory\nProcess.$dict = $ProcessDict\n\n\nvar $PoolDict = {__class__:$B.$type,__name__:'Pool'}\n\n$PoolDict.__mro__ = [$PoolDict, _b_.object.$dict]\n\n$PoolDict.__enter__ = function(self){}\n$PoolDict.__exit__ = function(self){}\n\n$PoolDict.__str__ = $PoolDict.toString = $PoolDict.__repr__=function(self){\n   return '<object Pool>'\n}\n\n$PoolDict.map = function(self){\n   var args = []\n   for(var i=1;i<arguments.length;i++) args.push(arguments[i])\n\n   var $ns=$B.$MakeArgs('Pool.map',args,['func', 'fargs'],[],'args','kw')\n   var func=$ns['func']\n   var fargs=$ns['fargs']\n\n   var _results=[]\n\n   fargs=iter(fargs)\n\n   var _pos=0\n   console.log(self.$processes)\n   _workers=[]\n   for(var i=0; i < self.$processes; i++) {\n       _workers[i] = new Worker('/src/web_workers/multiprocessing.js')\n       var arg\n\n       try{ \n          arg=getattr(fargs, '__next__')()\n       } catch(err) {\n          if (err.__name__ == 'StopIteration') {\n             __BRYTHON__.$pop_exc()\n          } else {\n             throw err\n          }\n       }\n       console.log(arg)\n       _workers[i].finished=false\n       _workers[i].postMessage({target: func+'', pos: _pos,\n                             args: $convert_args([arg])})\n       _pos++\n\n       _workers[i].addEventListener('message', function(e) {\n           _results[e.data.pos]=e.data.result\n           if (_results.length == args.length) return _results\n\n           try {\n               arg=getattr(fargs, '__next__')()\n               e.currentTarget.postMessage({target: func+'', pos: _pos,\n                                            args: $convert_args([arg])})\n               _pos++\n           } catch(err) {\n               if (err.__name__ != 'StopIteration') throw err\n               this.finished=true\n           }\n       }, false);\n   }\n}\n\n$PoolDict.apply_async = function(self){\n   var args = []\n   for(var i=1;i<arguments.length;i++){args.push(arguments[i])}\n\n   var $ns=$B.$MakeArgs('apply_async',args,['func', 'fargs'],[],'args','kw')\n   var func=$ns['func']\n   var fargs=$ns['fargs']\n\n   fargs=iter(fargs)\n\n   async_result = {}\n   async_result.get=function(timeout){\n                      console.log(results)\n                      console.log(fargs)\n                      return this.results}\n   async_result.results=[]\n\n   var _pos=0\n\n   _workers=[]\n   for(var i=0; i < self.$processes; i++) {\n       _workers[i] = new Worker('/src/web_workers/multiprocessing.js')\n       var arg\n\n       try{ \n          arg=getattr(fargs, '__next__')()\n       } catch(err) {\n          if (err.__name__ == 'StopIteration') {\n             $B.$pop_exc()\n          } else {\n             throw err\n          }\n       }\n       //console.log(arg)\n       //_workers[i].finished=false\n       _workers[i].postMessage({target: func+'', pos: _pos,\n                             args: $convert_args([arg])})\n       _pos++\n\n       _workers[i].addEventListener('message', function(e) {\n           async_result.results[e.data.pos]=e.data.result\n           //if (_results.length == args.length) return _results\n\n           try {\n               arg=getattr(fargs, '__next__')()\n               e.currentTarget.postMessage({target: func+'', pos: _pos,\n                                            args: $convert_args([arg])})\n               _pos++\n           } catch(err) {\n               if (err.__name__ != 'StopIteration') throw err\n               this.finished=true\n           }\n       }, false);\n   }\n\n   console.log(\"return\", async_result)\n   return async_result\n}\n\nfunction Pool(){\n    console.log(\"pool\")\n    console.log(arguments)\n    var $ns=$B.$MakeArgs('Pool',arguments,[],['processes'],'args','kw')\n    //var kw=$ns['kw']\n\n    var processes=$ns['processes']\n\n    if (processes == None) {\n       // look to see if we have stored cpu_count in local storage\n       // maybe we should create a brython config file with settings,etc..??\n\n       // if not there use a tool such as Core Estimator to calculate number of cpu's\n       // http://eligrey.com/blog/post/cpu-core-estimation-with-javascript\n    }\n\n    console.log(processes)\n    var res = {\n        __class__:$PoolDict,\n        $processes:processes\n    }\n    return res\n}\n\nPool.__class__ = $B.$factory\nPool.$dict = $PoolDict\n\nreturn {Process:Process, Pool:Pool}\n\n})(__BRYTHON__)\n"], "tarfile": [".py", "#!/usr/bin/env python3\n#-------------------------------------------------------------------\n# tarfile.py\n#-------------------------------------------------------------------\n# Copyright (C) 2002 Lars Gustaebel <lars@gustaebel.de>\n# All rights reserved.\n#\n# Permission  is  hereby granted,  free  of charge,  to  any person\n# obtaining a  copy of  this software  and associated documentation\n# files  (the  \"Software\"),  to   deal  in  the  Software   without\n# restriction,  including  without limitation  the  rights to  use,\n# copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies  of  the  Software,  and to  permit  persons  to  whom the\n# Software  is  furnished  to  do  so,  subject  to  the  following\n# conditions:\n#\n# The above copyright  notice and this  permission notice shall  be\n# included in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS  IS\", WITHOUT WARRANTY OF ANY  KIND,\n# EXPRESS OR IMPLIED, INCLUDING  BUT NOT LIMITED TO  THE WARRANTIES\n# OF  MERCHANTABILITY,  FITNESS   FOR  A  PARTICULAR   PURPOSE  AND\n# NONINFRINGEMENT.  IN  NO  EVENT SHALL  THE  AUTHORS  OR COPYRIGHT\n# HOLDERS  BE LIABLE  FOR ANY  CLAIM, DAMAGES  OR OTHER  LIABILITY,\n# WHETHER  IN AN  ACTION OF  CONTRACT, TORT  OR OTHERWISE,  ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n# OTHER DEALINGS IN THE SOFTWARE.\n#\n\"\"\"Read from and write to tar format archives.\n\"\"\"\n\nversion     = \"0.9.0\"\n__author__  = \"Lars Gust\\u00e4bel (lars@gustaebel.de)\"\n__date__    = \"$Date: 2011-02-25 17:42:01 +0200 (Fri, 25 Feb 2011) $\"\n__cvsid__   = \"$Id: tarfile.py 88586 2011-02-25 15:42:01Z marc-andre.lemburg $\"\n__credits__ = \"Gustavo Niemeyer, Niels Gust\\u00e4bel, Richard Townsend.\"\n\n#---------\n# Imports\n#---------\nimport sys\nimport os\nimport io\nimport shutil\nimport stat\nimport time\nimport struct\nimport copy\nimport re\n\ntry:\n    import grp, pwd\nexcept ImportError:\n    grp = pwd = None\n\n# os.symlink on Windows prior to 6.0 raises NotImplementedError\nsymlink_exception = (AttributeError, NotImplementedError)\ntry:\n    # WindowsError (1314) will be raised if the caller does not hold the\n    # SeCreateSymbolicLinkPrivilege privilege\n    symlink_exception += (WindowsError,)\nexcept NameError:\n    pass\n\n# from tarfile import *\n__all__ = [\"TarFile\", \"TarInfo\", \"is_tarfile\", \"TarError\"]\n\nfrom builtins import open as _open # Since 'open' is TarFile.open\n\n#---------------------------------------------------------\n# tar constants\n#---------------------------------------------------------\nNUL = b\"\\0\"                     # the null character\nBLOCKSIZE = 512                 # length of processing blocks\nRECORDSIZE = BLOCKSIZE * 20     # length of records\nGNU_MAGIC = b\"ustar  \\0\"        # magic gnu tar string\nPOSIX_MAGIC = b\"ustar\\x0000\"    # magic posix tar string\n\nLENGTH_NAME = 100               # maximum length of a filename\nLENGTH_LINK = 100               # maximum length of a linkname\nLENGTH_PREFIX = 155             # maximum length of the prefix field\n\nREGTYPE = b\"0\"                  # regular file\nAREGTYPE = b\"\\0\"                # regular file\nLNKTYPE = b\"1\"                  # link (inside tarfile)\nSYMTYPE = b\"2\"                  # symbolic link\nCHRTYPE = b\"3\"                  # character special device\nBLKTYPE = b\"4\"                  # block special device\nDIRTYPE = b\"5\"                  # directory\nFIFOTYPE = b\"6\"                 # fifo special device\nCONTTYPE = b\"7\"                 # contiguous file\n\nGNUTYPE_LONGNAME = b\"L\"         # GNU tar longname\nGNUTYPE_LONGLINK = b\"K\"         # GNU tar longlink\nGNUTYPE_SPARSE = b\"S\"           # GNU tar sparse file\n\nXHDTYPE = b\"x\"                  # POSIX.1-2001 extended header\nXGLTYPE = b\"g\"                  # POSIX.1-2001 global header\nSOLARIS_XHDTYPE = b\"X\"          # Solaris extended header\n\nUSTAR_FORMAT = 0                # POSIX.1-1988 (ustar) format\nGNU_FORMAT = 1                  # GNU tar format\nPAX_FORMAT = 2                  # POSIX.1-2001 (pax) format\nDEFAULT_FORMAT = GNU_FORMAT\n\n#---------------------------------------------------------\n# tarfile constants\n#---------------------------------------------------------\n# File types that tarfile supports:\nSUPPORTED_TYPES = (REGTYPE, AREGTYPE, LNKTYPE,\n                   SYMTYPE, DIRTYPE, FIFOTYPE,\n                   CONTTYPE, CHRTYPE, BLKTYPE,\n                   GNUTYPE_LONGNAME, GNUTYPE_LONGLINK,\n                   GNUTYPE_SPARSE)\n\n# File types that will be treated as a regular file.\nREGULAR_TYPES = (REGTYPE, AREGTYPE,\n                 CONTTYPE, GNUTYPE_SPARSE)\n\n# File types that are part of the GNU tar format.\nGNU_TYPES = (GNUTYPE_LONGNAME, GNUTYPE_LONGLINK,\n             GNUTYPE_SPARSE)\n\n# Fields from a pax header that override a TarInfo attribute.\nPAX_FIELDS = (\"path\", \"linkpath\", \"size\", \"mtime\",\n              \"uid\", \"gid\", \"uname\", \"gname\")\n\n# Fields from a pax header that are affected by hdrcharset.\nPAX_NAME_FIELDS = {\"path\", \"linkpath\", \"uname\", \"gname\"}\n\n# Fields in a pax header that are numbers, all other fields\n# are treated as strings.\nPAX_NUMBER_FIELDS = {\n    \"atime\": float,\n    \"ctime\": float,\n    \"mtime\": float,\n    \"uid\": int,\n    \"gid\": int,\n    \"size\": int\n}\n\n#---------------------------------------------------------\n# Bits used in the mode field, values in octal.\n#---------------------------------------------------------\nS_IFLNK = 0o120000        # symbolic link\nS_IFREG = 0o100000        # regular file\nS_IFBLK = 0o060000        # block device\nS_IFDIR = 0o040000        # directory\nS_IFCHR = 0o020000        # character device\nS_IFIFO = 0o010000        # fifo\n\nTSUID   = 0o4000          # set UID on execution\nTSGID   = 0o2000          # set GID on execution\nTSVTX   = 0o1000          # reserved\n\nTUREAD  = 0o400           # read by owner\nTUWRITE = 0o200           # write by owner\nTUEXEC  = 0o100           # execute/search by owner\nTGREAD  = 0o040           # read by group\nTGWRITE = 0o020           # write by group\nTGEXEC  = 0o010           # execute/search by group\nTOREAD  = 0o004           # read by other\nTOWRITE = 0o002           # write by other\nTOEXEC  = 0o001           # execute/search by other\n\n#---------------------------------------------------------\n# initialization\n#---------------------------------------------------------\nif os.name in (\"nt\", \"ce\"):\n    ENCODING = \"utf-8\"\nelse:\n    ENCODING = sys.getfilesystemencoding()\n\n#---------------------------------------------------------\n# Some useful functions\n#---------------------------------------------------------\n\ndef stn(s, length, encoding, errors):\n    \"\"\"Convert a string to a null-terminated bytes object.\n    \"\"\"\n    s = s.encode(encoding, errors)\n    return s[:length] + (length - len(s)) * NUL\n\ndef nts(s, encoding, errors):\n    \"\"\"Convert a null-terminated bytes object to a string.\n    \"\"\"\n    p = s.find(b\"\\0\")\n    if p != -1:\n        s = s[:p]\n    return s.decode(encoding, errors)\n\ndef nti(s):\n    \"\"\"Convert a number field to a python number.\n    \"\"\"\n    # There are two possible encodings for a number field, see\n    # itn() below.\n    if s[0] in (0o200, 0o377):\n        n = 0\n        for i in range(len(s) - 1):\n            n <<= 8\n            n += s[i + 1]\n        if s[0] == 0o377:\n            n = -(256 ** (len(s) - 1) - n)\n    else:\n        try:\n            n = int(nts(s, \"ascii\", \"strict\") or \"0\", 8)\n        except ValueError:\n            raise InvalidHeaderError(\"invalid header\")\n    return n\n\ndef itn(n, digits=8, format=DEFAULT_FORMAT):\n    \"\"\"Convert a python number to a number field.\n    \"\"\"\n    # POSIX 1003.1-1988 requires numbers to be encoded as a string of\n    # octal digits followed by a null-byte, this allows values up to\n    # (8**(digits-1))-1. GNU tar allows storing numbers greater than\n    # that if necessary. A leading 0o200 or 0o377 byte indicate this\n    # particular encoding, the following digits-1 bytes are a big-endian\n    # base-256 representation. This allows values up to (256**(digits-1))-1.\n    # A 0o200 byte indicates a positive number, a 0o377 byte a negative\n    # number.\n    if 0 <= n < 8 ** (digits - 1):\n        s = bytes(\"%0*o\" % (digits - 1, n), \"ascii\") + NUL\n    elif format == GNU_FORMAT and -256 ** (digits - 1) <= n < 256 ** (digits - 1):\n        if n >= 0:\n            s = bytearray([0o200])\n        else:\n            s = bytearray([0o377])\n            n = 256 ** digits + n\n\n        for i in range(digits - 1):\n            s.insert(1, n & 0o377)\n            n >>= 8\n    else:\n        raise ValueError(\"overflow in number field\")\n\n    return s\n\ndef calc_chksums(buf):\n    \"\"\"Calculate the checksum for a member's header by summing up all\n       characters except for the chksum field which is treated as if\n       it was filled with spaces. According to the GNU tar sources,\n       some tars (Sun and NeXT) calculate chksum with signed char,\n       which will be different if there are chars in the buffer with\n       the high bit set. So we calculate two checksums, unsigned and\n       signed.\n    \"\"\"\n    unsigned_chksum = 256 + sum(struct.unpack_from(\"148B8x356B\", buf))\n    signed_chksum = 256 + sum(struct.unpack_from(\"148b8x356b\", buf))\n    return unsigned_chksum, signed_chksum\n\ndef copyfileobj(src, dst, length=None):\n    \"\"\"Copy length bytes from fileobj src to fileobj dst.\n       If length is None, copy the entire content.\n    \"\"\"\n    if length == 0:\n        return\n    if length is None:\n        shutil.copyfileobj(src, dst)\n        return\n\n    BUFSIZE = 16 * 1024\n    blocks, remainder = divmod(length, BUFSIZE)\n    for b in range(blocks):\n        buf = src.read(BUFSIZE)\n        if len(buf) < BUFSIZE:\n            raise IOError(\"end of file reached\")\n        dst.write(buf)\n\n    if remainder != 0:\n        buf = src.read(remainder)\n        if len(buf) < remainder:\n            raise IOError(\"end of file reached\")\n        dst.write(buf)\n    return\n\ndef filemode(mode):\n    \"\"\"Deprecated in this location; use stat.filemode.\"\"\"\n    import warnings\n    warnings.warn(\"deprecated in favor of stat.filemode\",\n                  DeprecationWarning, 2)\n    return stat.filemode(mode)\n\n\nclass TarError(Exception):\n    \"\"\"Base exception.\"\"\"\n    pass\nclass ExtractError(TarError):\n    \"\"\"General exception for extract errors.\"\"\"\n    pass\nclass ReadError(TarError):\n    \"\"\"Exception for unreadable tar archives.\"\"\"\n    pass\nclass CompressionError(TarError):\n    \"\"\"Exception for unavailable compression methods.\"\"\"\n    pass\nclass StreamError(TarError):\n    \"\"\"Exception for unsupported operations on stream-like TarFiles.\"\"\"\n    pass\nclass HeaderError(TarError):\n    \"\"\"Base exception for header errors.\"\"\"\n    pass\nclass EmptyHeaderError(HeaderError):\n    \"\"\"Exception for empty headers.\"\"\"\n    pass\nclass TruncatedHeaderError(HeaderError):\n    \"\"\"Exception for truncated headers.\"\"\"\n    pass\nclass EOFHeaderError(HeaderError):\n    \"\"\"Exception for end of file headers.\"\"\"\n    pass\nclass InvalidHeaderError(HeaderError):\n    \"\"\"Exception for invalid headers.\"\"\"\n    pass\nclass SubsequentHeaderError(HeaderError):\n    \"\"\"Exception for missing and invalid extended headers.\"\"\"\n    pass\n\n#---------------------------\n# internal stream interface\n#---------------------------\nclass _LowLevelFile:\n    \"\"\"Low-level file object. Supports reading and writing.\n       It is used instead of a regular file object for streaming\n       access.\n    \"\"\"\n\n    def __init__(self, name, mode):\n        mode = {\n            \"r\": os.O_RDONLY,\n            \"w\": os.O_WRONLY | os.O_CREAT | os.O_TRUNC,\n        }[mode]\n        if hasattr(os, \"O_BINARY\"):\n            mode |= os.O_BINARY\n        self.fd = os.open(name, mode, 0o666)\n\n    def close(self):\n        os.close(self.fd)\n\n    def read(self, size):\n        return os.read(self.fd, size)\n\n    def write(self, s):\n        os.write(self.fd, s)\n\nclass _Stream:\n    \"\"\"Class that serves as an adapter between TarFile and\n       a stream-like object.  The stream-like object only\n       needs to have a read() or write() method and is accessed\n       blockwise.  Use of gzip or bzip2 compression is possible.\n       A stream-like object could be for example: sys.stdin,\n       sys.stdout, a socket, a tape device etc.\n\n       _Stream is intended to be used only internally.\n    \"\"\"\n\n    def __init__(self, name, mode, comptype, fileobj, bufsize):\n        \"\"\"Construct a _Stream object.\n        \"\"\"\n        self._extfileobj = True\n        if fileobj is None:\n            fileobj = _LowLevelFile(name, mode)\n            self._extfileobj = False\n\n        if comptype == '*':\n            # Enable transparent compression detection for the\n            # stream interface\n            fileobj = _StreamProxy(fileobj)\n            comptype = fileobj.getcomptype()\n\n        self.name     = name or \"\"\n        self.mode     = mode\n        self.comptype = comptype\n        self.fileobj  = fileobj\n        self.bufsize  = bufsize\n        self.buf      = b\"\"\n        self.pos      = 0\n        self.closed   = False\n\n        try:\n            if comptype == \"gz\":\n                try:\n                    import zlib\n                except ImportError:\n                    raise CompressionError(\"zlib module is not available\")\n                self.zlib = zlib\n                self.crc = zlib.crc32(b\"\")\n                if mode == \"r\":\n                    self._init_read_gz()\n                    self.exception = zlib.error\n                else:\n                    self._init_write_gz()\n\n            elif comptype == \"bz2\":\n                try:\n                    import bz2\n                except ImportError:\n                    raise CompressionError(\"bz2 module is not available\")\n                if mode == \"r\":\n                    self.dbuf = b\"\"\n                    self.cmp = bz2.BZ2Decompressor()\n                    self.exception = IOError\n                else:\n                    self.cmp = bz2.BZ2Compressor()\n\n            elif comptype == \"xz\":\n                try:\n                    import lzma\n                except ImportError:\n                    raise CompressionError(\"lzma module is not available\")\n                if mode == \"r\":\n                    self.dbuf = b\"\"\n                    self.cmp = lzma.LZMADecompressor()\n                    self.exception = lzma.LZMAError\n                else:\n                    self.cmp = lzma.LZMACompressor()\n\n            elif comptype != \"tar\":\n                raise CompressionError(\"unknown compression type %r\" % comptype)\n\n        except:\n            if not self._extfileobj:\n                self.fileobj.close()\n            self.closed = True\n            raise\n\n    def __del__(self):\n        if hasattr(self, \"closed\") and not self.closed:\n            self.close()\n\n    def _init_write_gz(self):\n        \"\"\"Initialize for writing with gzip compression.\n        \"\"\"\n        self.cmp = self.zlib.compressobj(9, self.zlib.DEFLATED,\n                                            -self.zlib.MAX_WBITS,\n                                            self.zlib.DEF_MEM_LEVEL,\n                                            0)\n        timestamp = struct.pack(\"<L\", int(time.time()))\n        self.__write(b\"\\037\\213\\010\\010\" + timestamp + b\"\\002\\377\")\n        if self.name.endswith(\".gz\"):\n            self.name = self.name[:-3]\n        # RFC1952 says we must use ISO-8859-1 for the FNAME field.\n        self.__write(self.name.encode(\"iso-8859-1\", \"replace\") + NUL)\n\n    def write(self, s):\n        \"\"\"Write string s to the stream.\n        \"\"\"\n        if self.comptype == \"gz\":\n            self.crc = self.zlib.crc32(s, self.crc)\n        self.pos += len(s)\n        if self.comptype != \"tar\":\n            s = self.cmp.compress(s)\n        self.__write(s)\n\n    def __write(self, s):\n        \"\"\"Write string s to the stream if a whole new block\n           is ready to be written.\n        \"\"\"\n        self.buf += s\n        while len(self.buf) > self.bufsize:\n            self.fileobj.write(self.buf[:self.bufsize])\n            self.buf = self.buf[self.bufsize:]\n\n    def close(self):\n        \"\"\"Close the _Stream object. No operation should be\n           done on it afterwards.\n        \"\"\"\n        if self.closed:\n            return\n\n        if self.mode == \"w\" and self.comptype != \"tar\":\n            self.buf += self.cmp.flush()\n\n        if self.mode == \"w\" and self.buf:\n            self.fileobj.write(self.buf)\n            self.buf = b\"\"\n            if self.comptype == \"gz\":\n                # The native zlib crc is an unsigned 32-bit integer, but\n                # the Python wrapper implicitly casts that to a signed C\n                # long.  So, on a 32-bit box self.crc may \"look negative\",\n                # while the same crc on a 64-bit box may \"look positive\".\n                # To avoid irksome warnings from the `struct` module, force\n                # it to look positive on all boxes.\n                self.fileobj.write(struct.pack(\"<L\", self.crc & 0xffffffff))\n                self.fileobj.write(struct.pack(\"<L\", self.pos & 0xffffFFFF))\n\n        if not self._extfileobj:\n            self.fileobj.close()\n\n        self.closed = True\n\n    def _init_read_gz(self):\n        \"\"\"Initialize for reading a gzip compressed fileobj.\n        \"\"\"\n        self.cmp = self.zlib.decompressobj(-self.zlib.MAX_WBITS)\n        self.dbuf = b\"\"\n\n        # taken from gzip.GzipFile with some alterations\n        if self.__read(2) != b\"\\037\\213\":\n            raise ReadError(\"not a gzip file\")\n        if self.__read(1) != b\"\\010\":\n            raise CompressionError(\"unsupported compression method\")\n\n        flag = ord(self.__read(1))\n        self.__read(6)\n\n        if flag & 4:\n            xlen = ord(self.__read(1)) + 256 * ord(self.__read(1))\n            self.read(xlen)\n        if flag & 8:\n            while True:\n                s = self.__read(1)\n                if not s or s == NUL:\n                    break\n        if flag & 16:\n            while True:\n                s = self.__read(1)\n                if not s or s == NUL:\n                    break\n        if flag & 2:\n            self.__read(2)\n\n    def tell(self):\n        \"\"\"Return the stream's file pointer position.\n        \"\"\"\n        return self.pos\n\n    def seek(self, pos=0):\n        \"\"\"Set the stream's file pointer to pos. Negative seeking\n           is forbidden.\n        \"\"\"\n        if pos - self.pos >= 0:\n            blocks, remainder = divmod(pos - self.pos, self.bufsize)\n            for i in range(blocks):\n                self.read(self.bufsize)\n            self.read(remainder)\n        else:\n            raise StreamError(\"seeking backwards is not allowed\")\n        return self.pos\n\n    def read(self, size=None):\n        \"\"\"Return the next size number of bytes from the stream.\n           If size is not defined, return all bytes of the stream\n           up to EOF.\n        \"\"\"\n        if size is None:\n            t = []\n            while True:\n                buf = self._read(self.bufsize)\n                if not buf:\n                    break\n                t.append(buf)\n            buf = \"\".join(t)\n        else:\n            buf = self._read(size)\n        self.pos += len(buf)\n        return buf\n\n    def _read(self, size):\n        \"\"\"Return size bytes from the stream.\n        \"\"\"\n        if self.comptype == \"tar\":\n            return self.__read(size)\n\n        c = len(self.dbuf)\n        while c < size:\n            buf = self.__read(self.bufsize)\n            if not buf:\n                break\n            try:\n                buf = self.cmp.decompress(buf)\n            except self.exception:\n                raise ReadError(\"invalid compressed data\")\n            self.dbuf += buf\n            c += len(buf)\n        buf = self.dbuf[:size]\n        self.dbuf = self.dbuf[size:]\n        return buf\n\n    def __read(self, size):\n        \"\"\"Return size bytes from stream. If internal buffer is empty,\n           read another block from the stream.\n        \"\"\"\n        c = len(self.buf)\n        while c < size:\n            buf = self.fileobj.read(self.bufsize)\n            if not buf:\n                break\n            self.buf += buf\n            c += len(buf)\n        buf = self.buf[:size]\n        self.buf = self.buf[size:]\n        return buf\n# class _Stream\n\nclass _StreamProxy(object):\n    \"\"\"Small proxy class that enables transparent compression\n       detection for the Stream interface (mode 'r|*').\n    \"\"\"\n\n    def __init__(self, fileobj):\n        self.fileobj = fileobj\n        self.buf = self.fileobj.read(BLOCKSIZE)\n\n    def read(self, size):\n        self.read = self.fileobj.read\n        return self.buf\n\n    def getcomptype(self):\n        if self.buf.startswith(b\"\\x1f\\x8b\\x08\"):\n            return \"gz\"\n        elif self.buf[0:3] == b\"BZh\" and self.buf[4:10] == b\"1AY&SY\":\n            return \"bz2\"\n        elif self.buf.startswith((b\"\\x5d\\x00\\x00\\x80\", b\"\\xfd7zXZ\")):\n            return \"xz\"\n        else:\n            return \"tar\"\n\n    def close(self):\n        self.fileobj.close()\n# class StreamProxy\n\n#------------------------\n# Extraction file object\n#------------------------\nclass _FileInFile(object):\n    \"\"\"A thin wrapper around an existing file object that\n       provides a part of its data as an individual file\n       object.\n    \"\"\"\n\n    def __init__(self, fileobj, offset, size, blockinfo=None):\n        self.fileobj = fileobj\n        self.offset = offset\n        self.size = size\n        self.position = 0\n        self.name = getattr(fileobj, \"name\", None)\n        self.closed = False\n\n        if blockinfo is None:\n            blockinfo = [(0, size)]\n\n        # Construct a map with data and zero blocks.\n        self.map_index = 0\n        self.map = []\n        lastpos = 0\n        realpos = self.offset\n        for offset, size in blockinfo:\n            if offset > lastpos:\n                self.map.append((False, lastpos, offset, None))\n            self.map.append((True, offset, offset + size, realpos))\n            realpos += size\n            lastpos = offset + size\n        if lastpos < self.size:\n            self.map.append((False, lastpos, self.size, None))\n\n    def flush(self):\n        pass\n\n    def readable(self):\n        return True\n\n    def writable(self):\n        return False\n\n    def seekable(self):\n        return self.fileobj.seekable()\n\n    def tell(self):\n        \"\"\"Return the current file position.\n        \"\"\"\n        return self.position\n\n    def seek(self, position, whence=io.SEEK_SET):\n        \"\"\"Seek to a position in the file.\n        \"\"\"\n        if whence == io.SEEK_SET:\n            self.position = min(max(position, 0), self.size)\n        elif whence == io.SEEK_CUR:\n            if position < 0:\n                self.position = max(self.position + position, 0)\n            else:\n                self.position = min(self.position + position, self.size)\n        elif whence == io.SEEK_END:\n            self.position = max(min(self.size + position, self.size), 0)\n        else:\n            raise ValueError(\"Invalid argument\")\n        return self.position\n\n    def read(self, size=None):\n        \"\"\"Read data from the file.\n        \"\"\"\n        if size is None:\n            size = self.size - self.position\n        else:\n            size = min(size, self.size - self.position)\n\n        buf = b\"\"\n        while size > 0:\n            while True:\n                data, start, stop, offset = self.map[self.map_index]\n                if start <= self.position < stop:\n                    break\n                else:\n                    self.map_index += 1\n                    if self.map_index == len(self.map):\n                        self.map_index = 0\n            length = min(size, stop - self.position)\n            if data:\n                self.fileobj.seek(offset + (self.position - start))\n                buf += self.fileobj.read(length)\n            else:\n                buf += NUL * length\n            size -= length\n            self.position += length\n        return buf\n\n    def readinto(self, b):\n        buf = self.read(len(b))\n        b[:len(buf)] = buf\n        return len(buf)\n\n    def close(self):\n        self.closed = True\n#class _FileInFile\n\nclass ExFileObject(io.BufferedReader):\n\n    def __init__(self, tarfile, tarinfo):\n        fileobj = _FileInFile(tarfile.fileobj, tarinfo.offset_data,\n                tarinfo.size, tarinfo.sparse)\n        super().__init__(fileobj)\n#class ExFileObject\n\n#------------------\n# Exported Classes\n#------------------\nclass TarInfo(object):\n    \"\"\"Informational class which holds the details about an\n       archive member given by a tar header block.\n       TarInfo objects are returned by TarFile.getmember(),\n       TarFile.getmembers() and TarFile.gettarinfo() and are\n       usually created internally.\n    \"\"\"\n\n    __slots__ = (\"name\", \"mode\", \"uid\", \"gid\", \"size\", \"mtime\",\n                 \"chksum\", \"type\", \"linkname\", \"uname\", \"gname\",\n                 \"devmajor\", \"devminor\",\n                 \"offset\", \"offset_data\", \"pax_headers\", \"sparse\",\n                 \"tarfile\", \"_sparse_structs\", \"_link_target\")\n\n    def __init__(self, name=\"\"):\n        \"\"\"Construct a TarInfo object. name is the optional name\n           of the member.\n        \"\"\"\n        self.name = name        # member name\n        self.mode = 0o644       # file permissions\n        self.uid = 0            # user id\n        self.gid = 0            # group id\n        self.size = 0           # file size\n        self.mtime = 0          # modification time\n        self.chksum = 0         # header checksum\n        self.type = REGTYPE     # member type\n        self.linkname = \"\"      # link name\n        self.uname = \"\"         # user name\n        self.gname = \"\"         # group name\n        self.devmajor = 0       # device major number\n        self.devminor = 0       # device minor number\n\n        self.offset = 0         # the tar header starts here\n        self.offset_data = 0    # the file's data starts here\n\n        self.sparse = None      # sparse member information\n        self.pax_headers = {}   # pax header information\n\n    # In pax headers the \"name\" and \"linkname\" field are called\n    # \"path\" and \"linkpath\".\n    def _getpath(self):\n        return self.name\n    def _setpath(self, name):\n        self.name = name\n    path = property(_getpath, _setpath)\n\n    def _getlinkpath(self):\n        return self.linkname\n    def _setlinkpath(self, linkname):\n        self.linkname = linkname\n    linkpath = property(_getlinkpath, _setlinkpath)\n\n    def __repr__(self):\n        return \"<%s %r at %#x>\" % (self.__class__.__name__,self.name,id(self))\n\n    def get_info(self):\n        \"\"\"Return the TarInfo's attributes as a dictionary.\n        \"\"\"\n        info = {\n            \"name\":     self.name,\n            \"mode\":     self.mode & 0o7777,\n            \"uid\":      self.uid,\n            \"gid\":      self.gid,\n            \"size\":     self.size,\n            \"mtime\":    self.mtime,\n            \"chksum\":   self.chksum,\n            \"type\":     self.type,\n            \"linkname\": self.linkname,\n            \"uname\":    self.uname,\n            \"gname\":    self.gname,\n            \"devmajor\": self.devmajor,\n            \"devminor\": self.devminor\n        }\n\n        if info[\"type\"] == DIRTYPE and not info[\"name\"].endswith(\"/\"):\n            info[\"name\"] += \"/\"\n\n        return info\n\n    def tobuf(self, format=DEFAULT_FORMAT, encoding=ENCODING, errors=\"surrogateescape\"):\n        \"\"\"Return a tar header as a string of 512 byte blocks.\n        \"\"\"\n        info = self.get_info()\n\n        if format == USTAR_FORMAT:\n            return self.create_ustar_header(info, encoding, errors)\n        elif format == GNU_FORMAT:\n            return self.create_gnu_header(info, encoding, errors)\n        elif format == PAX_FORMAT:\n            return self.create_pax_header(info, encoding)\n        else:\n            raise ValueError(\"invalid format\")\n\n    def create_ustar_header(self, info, encoding, errors):\n        \"\"\"Return the object as a ustar header block.\n        \"\"\"\n        info[\"magic\"] = POSIX_MAGIC\n\n        if len(info[\"linkname\"]) > LENGTH_LINK:\n            raise ValueError(\"linkname is too long\")\n\n        if len(info[\"name\"]) > LENGTH_NAME:\n            info[\"prefix\"], info[\"name\"] = self._posix_split_name(info[\"name\"])\n\n        return self._create_header(info, USTAR_FORMAT, encoding, errors)\n\n    def create_gnu_header(self, info, encoding, errors):\n        \"\"\"Return the object as a GNU header block sequence.\n        \"\"\"\n        info[\"magic\"] = GNU_MAGIC\n\n        buf = b\"\"\n        if len(info[\"linkname\"]) > LENGTH_LINK:\n            buf += self._create_gnu_long_header(info[\"linkname\"], GNUTYPE_LONGLINK, encoding, errors)\n\n        if len(info[\"name\"]) > LENGTH_NAME:\n            buf += self._create_gnu_long_header(info[\"name\"], GNUTYPE_LONGNAME, encoding, errors)\n\n        return buf + self._create_header(info, GNU_FORMAT, encoding, errors)\n\n    def create_pax_header(self, info, encoding):\n        \"\"\"Return the object as a ustar header block. If it cannot be\n           represented this way, prepend a pax extended header sequence\n           with supplement information.\n        \"\"\"\n        info[\"magic\"] = POSIX_MAGIC\n        pax_headers = self.pax_headers.copy()\n\n        # Test string fields for values that exceed the field length or cannot\n        # be represented in ASCII encoding.\n        for name, hname, length in (\n                (\"name\", \"path\", LENGTH_NAME), (\"linkname\", \"linkpath\", LENGTH_LINK),\n                (\"uname\", \"uname\", 32), (\"gname\", \"gname\", 32)):\n\n            if hname in pax_headers:\n                # The pax header has priority.\n                continue\n\n            # Try to encode the string as ASCII.\n            try:\n                info[name].encode(\"ascii\", \"strict\")\n            except UnicodeEncodeError:\n                pax_headers[hname] = info[name]\n                continue\n\n            if len(info[name]) > length:\n                pax_headers[hname] = info[name]\n\n        # Test number fields for values that exceed the field limit or values\n        # that like to be stored as float.\n        for name, digits in ((\"uid\", 8), (\"gid\", 8), (\"size\", 12), (\"mtime\", 12)):\n            if name in pax_headers:\n                # The pax header has priority. Avoid overflow.\n                info[name] = 0\n                continue\n\n            val = info[name]\n            if not 0 <= val < 8 ** (digits - 1) or isinstance(val, float):\n                pax_headers[name] = str(val)\n                info[name] = 0\n\n        # Create a pax extended header if necessary.\n        if pax_headers:\n            buf = self._create_pax_generic_header(pax_headers, XHDTYPE, encoding)\n        else:\n            buf = b\"\"\n\n        return buf + self._create_header(info, USTAR_FORMAT, \"ascii\", \"replace\")\n\n    @classmethod\n    def create_pax_global_header(cls, pax_headers):\n        \"\"\"Return the object as a pax global header block sequence.\n        \"\"\"\n        return cls._create_pax_generic_header(pax_headers, XGLTYPE, \"utf-8\")\n\n    def _posix_split_name(self, name):\n        \"\"\"Split a name longer than 100 chars into a prefix\n           and a name part.\n        \"\"\"\n        prefix = name[:LENGTH_PREFIX + 1]\n        while prefix and prefix[-1] != \"/\":\n            prefix = prefix[:-1]\n\n        name = name[len(prefix):]\n        prefix = prefix[:-1]\n\n        if not prefix or len(name) > LENGTH_NAME:\n            raise ValueError(\"name is too long\")\n        return prefix, name\n\n    @staticmethod\n    def _create_header(info, format, encoding, errors):\n        \"\"\"Return a header block. info is a dictionary with file\n           information, format must be one of the *_FORMAT constants.\n        \"\"\"\n        parts = [\n            stn(info.get(\"name\", \"\"), 100, encoding, errors),\n            itn(info.get(\"mode\", 0) & 0o7777, 8, format),\n            itn(info.get(\"uid\", 0), 8, format),\n            itn(info.get(\"gid\", 0), 8, format),\n            itn(info.get(\"size\", 0), 12, format),\n            itn(info.get(\"mtime\", 0), 12, format),\n            b\"        \", # checksum field\n            info.get(\"type\", REGTYPE),\n            stn(info.get(\"linkname\", \"\"), 100, encoding, errors),\n            info.get(\"magic\", POSIX_MAGIC),\n            stn(info.get(\"uname\", \"\"), 32, encoding, errors),\n            stn(info.get(\"gname\", \"\"), 32, encoding, errors),\n            itn(info.get(\"devmajor\", 0), 8, format),\n            itn(info.get(\"devminor\", 0), 8, format),\n            stn(info.get(\"prefix\", \"\"), 155, encoding, errors)\n        ]\n\n        buf = struct.pack(\"%ds\" % BLOCKSIZE, b\"\".join(parts))\n        chksum = calc_chksums(buf[-BLOCKSIZE:])[0]\n        buf = buf[:-364] + bytes(\"%06o\\0\" % chksum, \"ascii\") + buf[-357:]\n        return buf\n\n    @staticmethod\n    def _create_payload(payload):\n        \"\"\"Return the string payload filled with zero bytes\n           up to the next 512 byte border.\n        \"\"\"\n        blocks, remainder = divmod(len(payload), BLOCKSIZE)\n        if remainder > 0:\n            payload += (BLOCKSIZE - remainder) * NUL\n        return payload\n\n    @classmethod\n    def _create_gnu_long_header(cls, name, type, encoding, errors):\n        \"\"\"Return a GNUTYPE_LONGNAME or GNUTYPE_LONGLINK sequence\n           for name.\n        \"\"\"\n        name = name.encode(encoding, errors) + NUL\n\n        info = {}\n        info[\"name\"] = \"././@LongLink\"\n        info[\"type\"] = type\n        info[\"size\"] = len(name)\n        info[\"magic\"] = GNU_MAGIC\n\n        # create extended header + name blocks.\n        return cls._create_header(info, USTAR_FORMAT, encoding, errors) + \\\n                cls._create_payload(name)\n\n    @classmethod\n    def _create_pax_generic_header(cls, pax_headers, type, encoding):\n        \"\"\"Return a POSIX.1-2008 extended or global header sequence\n           that contains a list of keyword, value pairs. The values\n           must be strings.\n        \"\"\"\n        # Check if one of the fields contains surrogate characters and thereby\n        # forces hdrcharset=BINARY, see _proc_pax() for more information.\n        binary = False\n        for keyword, value in pax_headers.items():\n            try:\n                value.encode(\"utf-8\", \"strict\")\n            except UnicodeEncodeError:\n                binary = True\n                break\n\n        records = b\"\"\n        if binary:\n            # Put the hdrcharset field at the beginning of the header.\n            records += b\"21 hdrcharset=BINARY\\n\"\n\n        for keyword, value in pax_headers.items():\n            keyword = keyword.encode(\"utf-8\")\n            if binary:\n                # Try to restore the original byte representation of `value'.\n                # Needless to say, that the encoding must match the string.\n                value = value.encode(encoding, \"surrogateescape\")\n            else:\n                value = value.encode(\"utf-8\")\n\n            l = len(keyword) + len(value) + 3   # ' ' + '=' + '\\n'\n            n = p = 0\n            while True:\n                n = l + len(str(p))\n                if n == p:\n                    break\n                p = n\n            records += bytes(str(p), \"ascii\") + b\" \" + keyword + b\"=\" + value + b\"\\n\"\n\n        # We use a hardcoded \"././@PaxHeader\" name like star does\n        # instead of the one that POSIX recommends.\n        info = {}\n        info[\"name\"] = \"././@PaxHeader\"\n        info[\"type\"] = type\n        info[\"size\"] = len(records)\n        info[\"magic\"] = POSIX_MAGIC\n\n        # Create pax header + record blocks.\n        return cls._create_header(info, USTAR_FORMAT, \"ascii\", \"replace\") + \\\n                cls._create_payload(records)\n\n    @classmethod\n    def frombuf(cls, buf, encoding, errors):\n        \"\"\"Construct a TarInfo object from a 512 byte bytes object.\n        \"\"\"\n        if len(buf) == 0:\n            raise EmptyHeaderError(\"empty header\")\n        if len(buf) != BLOCKSIZE:\n            raise TruncatedHeaderError(\"truncated header\")\n        if buf.count(NUL) == BLOCKSIZE:\n            raise EOFHeaderError(\"end of file header\")\n\n        chksum = nti(buf[148:156])\n        if chksum not in calc_chksums(buf):\n            raise InvalidHeaderError(\"bad checksum\")\n\n        obj = cls()\n        obj.name = nts(buf[0:100], encoding, errors)\n        obj.mode = nti(buf[100:108])\n        obj.uid = nti(buf[108:116])\n        obj.gid = nti(buf[116:124])\n        obj.size = nti(buf[124:136])\n        obj.mtime = nti(buf[136:148])\n        obj.chksum = chksum\n        obj.type = buf[156:157]\n        obj.linkname = nts(buf[157:257], encoding, errors)\n        obj.uname = nts(buf[265:297], encoding, errors)\n        obj.gname = nts(buf[297:329], encoding, errors)\n        obj.devmajor = nti(buf[329:337])\n        obj.devminor = nti(buf[337:345])\n        prefix = nts(buf[345:500], encoding, errors)\n\n        # Old V7 tar format represents a directory as a regular\n        # file with a trailing slash.\n        if obj.type == AREGTYPE and obj.name.endswith(\"/\"):\n            obj.type = DIRTYPE\n\n        # The old GNU sparse format occupies some of the unused\n        # space in the buffer for up to 4 sparse structures.\n        # Save the them for later processing in _proc_sparse().\n        if obj.type == GNUTYPE_SPARSE:\n            pos = 386\n            structs = []\n            for i in range(4):\n                try:\n                    offset = nti(buf[pos:pos + 12])\n                    numbytes = nti(buf[pos + 12:pos + 24])\n                except ValueError:\n                    break\n                structs.append((offset, numbytes))\n                pos += 24\n            isextended = bool(buf[482])\n            origsize = nti(buf[483:495])\n            obj._sparse_structs = (structs, isextended, origsize)\n\n        # Remove redundant slashes from directories.\n        if obj.isdir():\n            obj.name = obj.name.rstrip(\"/\")\n\n        # Reconstruct a ustar longname.\n        if prefix and obj.type not in GNU_TYPES:\n            obj.name = prefix + \"/\" + obj.name\n        return obj\n\n    @classmethod\n    def fromtarfile(cls, tarfile):\n        \"\"\"Return the next TarInfo object from TarFile object\n           tarfile.\n        \"\"\"\n        buf = tarfile.fileobj.read(BLOCKSIZE)\n        obj = cls.frombuf(buf, tarfile.encoding, tarfile.errors)\n        obj.offset = tarfile.fileobj.tell() - BLOCKSIZE\n        return obj._proc_member(tarfile)\n\n    #--------------------------------------------------------------------------\n    # The following are methods that are called depending on the type of a\n    # member. The entry point is _proc_member() which can be overridden in a\n    # subclass to add custom _proc_*() methods. A _proc_*() method MUST\n    # implement the following\n    # operations:\n    # 1. Set self.offset_data to the position where the data blocks begin,\n    #    if there is data that follows.\n    # 2. Set tarfile.offset to the position where the next member's header will\n    #    begin.\n    # 3. Return self or another valid TarInfo object.\n    def _proc_member(self, tarfile):\n        \"\"\"Choose the right processing method depending on\n           the type and call it.\n        \"\"\"\n        if self.type in (GNUTYPE_LONGNAME, GNUTYPE_LONGLINK):\n            return self._proc_gnulong(tarfile)\n        elif self.type == GNUTYPE_SPARSE:\n            return self._proc_sparse(tarfile)\n        elif self.type in (XHDTYPE, XGLTYPE, SOLARIS_XHDTYPE):\n            return self._proc_pax(tarfile)\n        else:\n            return self._proc_builtin(tarfile)\n\n    def _proc_builtin(self, tarfile):\n        \"\"\"Process a builtin type or an unknown type which\n           will be treated as a regular file.\n        \"\"\"\n        self.offset_data = tarfile.fileobj.tell()\n        offset = self.offset_data\n        if self.isreg() or self.type not in SUPPORTED_TYPES:\n            # Skip the following data blocks.\n            offset += self._block(self.size)\n        tarfile.offset = offset\n\n        # Patch the TarInfo object with saved global\n        # header information.\n        self._apply_pax_info(tarfile.pax_headers, tarfile.encoding, tarfile.errors)\n\n        return self\n\n    def _proc_gnulong(self, tarfile):\n        \"\"\"Process the blocks that hold a GNU longname\n           or longlink member.\n        \"\"\"\n        buf = tarfile.fileobj.read(self._block(self.size))\n\n        # Fetch the next header and process it.\n        try:\n            next = self.fromtarfile(tarfile)\n        except HeaderError:\n            raise SubsequentHeaderError(\"missing or bad subsequent header\")\n\n        # Patch the TarInfo object from the next header with\n        # the longname information.\n        next.offset = self.offset\n        if self.type == GNUTYPE_LONGNAME:\n            next.name = nts(buf, tarfile.encoding, tarfile.errors)\n        elif self.type == GNUTYPE_LONGLINK:\n            next.linkname = nts(buf, tarfile.encoding, tarfile.errors)\n\n        return next\n\n    def _proc_sparse(self, tarfile):\n        \"\"\"Process a GNU sparse header plus extra headers.\n        \"\"\"\n        # We already collected some sparse structures in frombuf().\n        structs, isextended, origsize = self._sparse_structs\n        del self._sparse_structs\n\n        # Collect sparse structures from extended header blocks.\n        while isextended:\n            buf = tarfile.fileobj.read(BLOCKSIZE)\n            pos = 0\n            for i in range(21):\n                try:\n                    offset = nti(buf[pos:pos + 12])\n                    numbytes = nti(buf[pos + 12:pos + 24])\n                except ValueError:\n                    break\n                if offset and numbytes:\n                    structs.append((offset, numbytes))\n                pos += 24\n            isextended = bool(buf[504])\n        self.sparse = structs\n\n        self.offset_data = tarfile.fileobj.tell()\n        tarfile.offset = self.offset_data + self._block(self.size)\n        self.size = origsize\n        return self\n\n    def _proc_pax(self, tarfile):\n        \"\"\"Process an extended or global header as described in\n           POSIX.1-2008.\n        \"\"\"\n        # Read the header information.\n        buf = tarfile.fileobj.read(self._block(self.size))\n\n        # A pax header stores supplemental information for either\n        # the following file (extended) or all following files\n        # (global).\n        if self.type == XGLTYPE:\n            pax_headers = tarfile.pax_headers\n        else:\n            pax_headers = tarfile.pax_headers.copy()\n\n        # Check if the pax header contains a hdrcharset field. This tells us\n        # the encoding of the path, linkpath, uname and gname fields. Normally,\n        # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n        # implementations are allowed to store them as raw binary strings if\n        # the translation to UTF-8 fails.\n        match = re.search(br\"\\d+ hdrcharset=([^\\n]+)\\n\", buf)\n        if match is not None:\n            pax_headers[\"hdrcharset\"] = match.group(1).decode(\"utf-8\")\n\n        # For the time being, we don't care about anything other than \"BINARY\".\n        # The only other value that is currently allowed by the standard is\n        # \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n        hdrcharset = pax_headers.get(\"hdrcharset\")\n        if hdrcharset == \"BINARY\":\n            encoding = tarfile.encoding\n        else:\n            encoding = \"utf-8\"\n\n        # Parse pax header information. A record looks like that:\n        # \"%d %s=%s\\n\" % (length, keyword, value). length is the size\n        # of the complete record including the length field itself and\n        # the newline. keyword and value are both UTF-8 encoded strings.\n        regex = re.compile(br\"(\\d+) ([^=]+)=\")\n        pos = 0\n        while True:\n            match = regex.match(buf, pos)\n            if not match:\n                break\n\n            length, keyword = match.groups()\n            length = int(length)\n            value = buf[match.end(2) + 1:match.start(1) + length - 1]\n\n            # Normally, we could just use \"utf-8\" as the encoding and \"strict\"\n            # as the error handler, but we better not take the risk. For\n            # example, GNU tar <= 1.23 is known to store filenames it cannot\n            # translate to UTF-8 as raw strings (unfortunately without a\n            # hdrcharset=BINARY header).\n            # We first try the strict standard encoding, and if that fails we\n            # fall back on the user's encoding and error handler.\n            keyword = self._decode_pax_field(keyword, \"utf-8\", \"utf-8\",\n                    tarfile.errors)\n            if keyword in PAX_NAME_FIELDS:\n                value = self._decode_pax_field(value, encoding, tarfile.encoding,\n                        tarfile.errors)\n            else:\n                value = self._decode_pax_field(value, \"utf-8\", \"utf-8\",\n                        tarfile.errors)\n\n            pax_headers[keyword] = value\n            pos += length\n\n        # Fetch the next header.\n        try:\n            next = self.fromtarfile(tarfile)\n        except HeaderError:\n            raise SubsequentHeaderError(\"missing or bad subsequent header\")\n\n        # Process GNU sparse information.\n        if \"GNU.sparse.map\" in pax_headers:\n            # GNU extended sparse format version 0.1.\n            self._proc_gnusparse_01(next, pax_headers)\n\n        elif \"GNU.sparse.size\" in pax_headers:\n            # GNU extended sparse format version 0.0.\n            self._proc_gnusparse_00(next, pax_headers, buf)\n\n        elif pax_headers.get(\"GNU.sparse.major\") == \"1\" and pax_headers.get(\"GNU.sparse.minor\") == \"0\":\n            # GNU extended sparse format version 1.0.\n            self._proc_gnusparse_10(next, pax_headers, tarfile)\n\n        if self.type in (XHDTYPE, SOLARIS_XHDTYPE):\n            # Patch the TarInfo object with the extended header info.\n            next._apply_pax_info(pax_headers, tarfile.encoding, tarfile.errors)\n            next.offset = self.offset\n\n            if \"size\" in pax_headers:\n                # If the extended header replaces the size field,\n                # we need to recalculate the offset where the next\n                # header starts.\n                offset = next.offset_data\n                if next.isreg() or next.type not in SUPPORTED_TYPES:\n                    offset += next._block(next.size)\n                tarfile.offset = offset\n\n        return next\n\n    def _proc_gnusparse_00(self, next, pax_headers, buf):\n        \"\"\"Process a GNU tar extended sparse header, version 0.0.\n        \"\"\"\n        offsets = []\n        for match in re.finditer(br\"\\d+ GNU.sparse.offset=(\\d+)\\n\", buf):\n            offsets.append(int(match.group(1)))\n        numbytes = []\n        for match in re.finditer(br\"\\d+ GNU.sparse.numbytes=(\\d+)\\n\", buf):\n            numbytes.append(int(match.group(1)))\n        next.sparse = list(zip(offsets, numbytes))\n\n    def _proc_gnusparse_01(self, next, pax_headers):\n        \"\"\"Process a GNU tar extended sparse header, version 0.1.\n        \"\"\"\n        sparse = [int(x) for x in pax_headers[\"GNU.sparse.map\"].split(\",\")]\n        next.sparse = list(zip(sparse[::2], sparse[1::2]))\n\n    def _proc_gnusparse_10(self, next, pax_headers, tarfile):\n        \"\"\"Process a GNU tar extended sparse header, version 1.0.\n        \"\"\"\n        fields = None\n        sparse = []\n        buf = tarfile.fileobj.read(BLOCKSIZE)\n        fields, buf = buf.split(b\"\\n\", 1)\n        fields = int(fields)\n        while len(sparse) < fields * 2:\n            if b\"\\n\" not in buf:\n                buf += tarfile.fileobj.read(BLOCKSIZE)\n            number, buf = buf.split(b\"\\n\", 1)\n            sparse.append(int(number))\n        next.offset_data = tarfile.fileobj.tell()\n        next.sparse = list(zip(sparse[::2], sparse[1::2]))\n\n    def _apply_pax_info(self, pax_headers, encoding, errors):\n        \"\"\"Replace fields with supplemental information from a previous\n           pax extended or global header.\n        \"\"\"\n        for keyword, value in pax_headers.items():\n            if keyword == \"GNU.sparse.name\":\n                setattr(self, \"path\", value)\n            elif keyword == \"GNU.sparse.size\":\n                setattr(self, \"size\", int(value))\n            elif keyword == \"GNU.sparse.realsize\":\n                setattr(self, \"size\", int(value))\n            elif keyword in PAX_FIELDS:\n                if keyword in PAX_NUMBER_FIELDS:\n                    try:\n                        value = PAX_NUMBER_FIELDS[keyword](value)\n                    except ValueError:\n                        value = 0\n                if keyword == \"path\":\n                    value = value.rstrip(\"/\")\n                setattr(self, keyword, value)\n\n        self.pax_headers = pax_headers.copy()\n\n    def _decode_pax_field(self, value, encoding, fallback_encoding, fallback_errors):\n        \"\"\"Decode a single field from a pax record.\n        \"\"\"\n        try:\n            return value.decode(encoding, \"strict\")\n        except UnicodeDecodeError:\n            return value.decode(fallback_encoding, fallback_errors)\n\n    def _block(self, count):\n        \"\"\"Round up a byte count by BLOCKSIZE and return it,\n           e.g. _block(834) => 1024.\n        \"\"\"\n        blocks, remainder = divmod(count, BLOCKSIZE)\n        if remainder:\n            blocks += 1\n        return blocks * BLOCKSIZE\n\n    def isreg(self):\n        return self.type in REGULAR_TYPES\n    def isfile(self):\n        return self.isreg()\n    def isdir(self):\n        return self.type == DIRTYPE\n    def issym(self):\n        return self.type == SYMTYPE\n    def islnk(self):\n        return self.type == LNKTYPE\n    def ischr(self):\n        return self.type == CHRTYPE\n    def isblk(self):\n        return self.type == BLKTYPE\n    def isfifo(self):\n        return self.type == FIFOTYPE\n    def issparse(self):\n        return self.sparse is not None\n    def isdev(self):\n        return self.type in (CHRTYPE, BLKTYPE, FIFOTYPE)\n# class TarInfo\n\nclass TarFile(object):\n    \"\"\"The TarFile Class provides an interface to tar archives.\n    \"\"\"\n\n    debug = 0                   # May be set from 0 (no msgs) to 3 (all msgs)\n\n    dereference = False         # If true, add content of linked file to the\n                                # tar file, else the link.\n\n    ignore_zeros = False        # If true, skips empty or invalid blocks and\n                                # continues processing.\n\n    errorlevel = 1              # If 0, fatal errors only appear in debug\n                                # messages (if debug >= 0). If > 0, errors\n                                # are passed to the caller as exceptions.\n\n    format = DEFAULT_FORMAT     # The format to use when creating an archive.\n\n    encoding = ENCODING         # Encoding for 8-bit character strings.\n\n    errors = None               # Error handler for unicode conversion.\n\n    tarinfo = TarInfo           # The default TarInfo class to use.\n\n    fileobject = ExFileObject   # The file-object for extractfile().\n\n    def __init__(self, name=None, mode=\"r\", fileobj=None, format=None,\n            tarinfo=None, dereference=None, ignore_zeros=None, encoding=None,\n            errors=\"surrogateescape\", pax_headers=None, debug=None, errorlevel=None):\n        \"\"\"Open an (uncompressed) tar archive `name'. `mode' is either 'r' to\n           read from an existing archive, 'a' to append data to an existing\n           file or 'w' to create a new file overwriting an existing one. `mode'\n           defaults to 'r'.\n           If `fileobj' is given, it is used for reading or writing data. If it\n           can be determined, `mode' is overridden by `fileobj's mode.\n           `fileobj' is not closed, when TarFile is closed.\n        \"\"\"\n        if len(mode) > 1 or mode not in \"raw\":\n            raise ValueError(\"mode must be 'r', 'a' or 'w'\")\n        self.mode = mode\n        self._mode = {\"r\": \"rb\", \"a\": \"r+b\", \"w\": \"wb\"}[mode]\n\n        if not fileobj:\n            if self.mode == \"a\" and not os.path.exists(name):\n                # Create nonexistent files in append mode.\n                self.mode = \"w\"\n                self._mode = \"wb\"\n            fileobj = bltn_open(name, self._mode)\n            self._extfileobj = False\n        else:\n            if name is None and hasattr(fileobj, \"name\"):\n                name = fileobj.name\n            if hasattr(fileobj, \"mode\"):\n                self._mode = fileobj.mode\n            self._extfileobj = True\n        self.name = os.path.abspath(name) if name else None\n        self.fileobj = fileobj\n\n        # Init attributes.\n        if format is not None:\n            self.format = format\n        if tarinfo is not None:\n            self.tarinfo = tarinfo\n        if dereference is not None:\n            self.dereference = dereference\n        if ignore_zeros is not None:\n            self.ignore_zeros = ignore_zeros\n        if encoding is not None:\n            self.encoding = encoding\n        self.errors = errors\n\n        if pax_headers is not None and self.format == PAX_FORMAT:\n            self.pax_headers = pax_headers\n        else:\n            self.pax_headers = {}\n\n        if debug is not None:\n            self.debug = debug\n        if errorlevel is not None:\n            self.errorlevel = errorlevel\n\n        # Init datastructures.\n        self.closed = False\n        self.members = []       # list of members as TarInfo objects\n        self._loaded = False    # flag if all members have been read\n        self.offset = self.fileobj.tell()\n                                # current position in the archive file\n        self.inodes = {}        # dictionary caching the inodes of\n                                # archive members already added\n\n        try:\n            if self.mode == \"r\":\n                self.firstmember = None\n                self.firstmember = self.next()\n\n            if self.mode == \"a\":\n                # Move to the end of the archive,\n                # before the first empty block.\n                while True:\n                    self.fileobj.seek(self.offset)\n                    try:\n                        tarinfo = self.tarinfo.fromtarfile(self)\n                        self.members.append(tarinfo)\n                    except EOFHeaderError:\n                        self.fileobj.seek(self.offset)\n                        break\n                    except HeaderError as e:\n                        raise ReadError(str(e))\n\n            if self.mode in \"aw\":\n                self._loaded = True\n\n                if self.pax_headers:\n                    buf = self.tarinfo.create_pax_global_header(self.pax_headers.copy())\n                    self.fileobj.write(buf)\n                    self.offset += len(buf)\n        except:\n            if not self._extfileobj:\n                self.fileobj.close()\n            self.closed = True\n            raise\n\n    #--------------------------------------------------------------------------\n    # Below are the classmethods which act as alternate constructors to the\n    # TarFile class. The open() method is the only one that is needed for\n    # public use; it is the \"super\"-constructor and is able to select an\n    # adequate \"sub\"-constructor for a particular compression using the mapping\n    # from OPEN_METH.\n    #\n    # This concept allows one to subclass TarFile without losing the comfort of\n    # the super-constructor. A sub-constructor is registered and made available\n    # by adding it to the mapping in OPEN_METH.\n\n    @classmethod\n    def open(cls, name=None, mode=\"r\", fileobj=None, bufsize=RECORDSIZE, **kwargs):\n        \"\"\"Open a tar archive for reading, writing or appending. Return\n           an appropriate TarFile class.\n\n           mode:\n           'r' or 'r:*' open for reading with transparent compression\n           'r:'         open for reading exclusively uncompressed\n           'r:gz'       open for reading with gzip compression\n           'r:bz2'      open for reading with bzip2 compression\n           'r:xz'       open for reading with lzma compression\n           'a' or 'a:'  open for appending, creating the file if necessary\n           'w' or 'w:'  open for writing without compression\n           'w:gz'       open for writing with gzip compression\n           'w:bz2'      open for writing with bzip2 compression\n           'w:xz'       open for writing with lzma compression\n\n           'r|*'        open a stream of tar blocks with transparent compression\n           'r|'         open an uncompressed stream of tar blocks for reading\n           'r|gz'       open a gzip compressed stream of tar blocks\n           'r|bz2'      open a bzip2 compressed stream of tar blocks\n           'r|xz'       open an lzma compressed stream of tar blocks\n           'w|'         open an uncompressed stream for writing\n           'w|gz'       open a gzip compressed stream for writing\n           'w|bz2'      open a bzip2 compressed stream for writing\n           'w|xz'       open an lzma compressed stream for writing\n        \"\"\"\n\n        if not name and not fileobj:\n            raise ValueError(\"nothing to open\")\n\n        if mode in (\"r\", \"r:*\"):\n            # Find out which *open() is appropriate for opening the file.\n            for comptype in cls.OPEN_METH:\n                func = getattr(cls, cls.OPEN_METH[comptype])\n                if fileobj is not None:\n                    saved_pos = fileobj.tell()\n                try:\n                    return func(name, \"r\", fileobj, **kwargs)\n                except (ReadError, CompressionError) as e:\n                    if fileobj is not None:\n                        fileobj.seek(saved_pos)\n                    continue\n            raise ReadError(\"file could not be opened successfully\")\n\n        elif \":\" in mode:\n            filemode, comptype = mode.split(\":\", 1)\n            filemode = filemode or \"r\"\n            comptype = comptype or \"tar\"\n\n            # Select the *open() function according to\n            # given compression.\n            if comptype in cls.OPEN_METH:\n                func = getattr(cls, cls.OPEN_METH[comptype])\n            else:\n                raise CompressionError(\"unknown compression type %r\" % comptype)\n            return func(name, filemode, fileobj, **kwargs)\n\n        elif \"|\" in mode:\n            filemode, comptype = mode.split(\"|\", 1)\n            filemode = filemode or \"r\"\n            comptype = comptype or \"tar\"\n\n            if filemode not in \"rw\":\n                raise ValueError(\"mode must be 'r' or 'w'\")\n\n            stream = _Stream(name, filemode, comptype, fileobj, bufsize)\n            try:\n                t = cls(name, filemode, stream, **kwargs)\n            except:\n                stream.close()\n                raise\n            t._extfileobj = False\n            return t\n\n        elif mode in \"aw\":\n            return cls.taropen(name, mode, fileobj, **kwargs)\n\n        raise ValueError(\"undiscernible mode\")\n\n    @classmethod\n    def taropen(cls, name, mode=\"r\", fileobj=None, **kwargs):\n        \"\"\"Open uncompressed tar archive name for reading or writing.\n        \"\"\"\n        if len(mode) > 1 or mode not in \"raw\":\n            raise ValueError(\"mode must be 'r', 'a' or 'w'\")\n        return cls(name, mode, fileobj, **kwargs)\n\n    @classmethod\n    def gzopen(cls, name, mode=\"r\", fileobj=None, compresslevel=9, **kwargs):\n        \"\"\"Open gzip compressed tar archive name for reading or writing.\n           Appending is not allowed.\n        \"\"\"\n        if len(mode) > 1 or mode not in \"rw\":\n            raise ValueError(\"mode must be 'r' or 'w'\")\n\n        try:\n            import gzip\n            gzip.GzipFile\n        except (ImportError, AttributeError):\n            raise CompressionError(\"gzip module is not available\")\n\n        extfileobj = fileobj is not None\n        try:\n            fileobj = gzip.GzipFile(name, mode + \"b\", compresslevel, fileobj)\n            t = cls.taropen(name, mode, fileobj, **kwargs)\n        except IOError:\n            if not extfileobj and fileobj is not None:\n                fileobj.close()\n            if fileobj is None:\n                raise\n            raise ReadError(\"not a gzip file\")\n        except:\n            if not extfileobj and fileobj is not None:\n                fileobj.close()\n            raise\n        t._extfileobj = extfileobj\n        return t\n\n    @classmethod\n    def bz2open(cls, name, mode=\"r\", fileobj=None, compresslevel=9, **kwargs):\n        \"\"\"Open bzip2 compressed tar archive name for reading or writing.\n           Appending is not allowed.\n        \"\"\"\n        if len(mode) > 1 or mode not in \"rw\":\n            raise ValueError(\"mode must be 'r' or 'w'.\")\n\n        try:\n            import bz2\n        except ImportError:\n            raise CompressionError(\"bz2 module is not available\")\n\n        fileobj = bz2.BZ2File(fileobj or name, mode,\n                              compresslevel=compresslevel)\n\n        try:\n            t = cls.taropen(name, mode, fileobj, **kwargs)\n        except (IOError, EOFError):\n            fileobj.close()\n            raise ReadError(\"not a bzip2 file\")\n        t._extfileobj = False\n        return t\n\n    @classmethod\n    def xzopen(cls, name, mode=\"r\", fileobj=None, preset=None, **kwargs):\n        \"\"\"Open lzma compressed tar archive name for reading or writing.\n           Appending is not allowed.\n        \"\"\"\n        if mode not in (\"r\", \"w\"):\n            raise ValueError(\"mode must be 'r' or 'w'\")\n\n        try:\n            import lzma\n        except ImportError:\n            raise CompressionError(\"lzma module is not available\")\n\n        fileobj = lzma.LZMAFile(fileobj or name, mode, preset=preset)\n\n        try:\n            t = cls.taropen(name, mode, fileobj, **kwargs)\n        except (lzma.LZMAError, EOFError):\n            fileobj.close()\n            raise ReadError(\"not an lzma file\")\n        t._extfileobj = False\n        return t\n\n    # All *open() methods are registered here.\n    OPEN_METH = {\n        \"tar\": \"taropen\",   # uncompressed tar\n        \"gz\":  \"gzopen\",    # gzip compressed tar\n        \"bz2\": \"bz2open\",   # bzip2 compressed tar\n        \"xz\":  \"xzopen\"     # lzma compressed tar\n    }\n\n    #--------------------------------------------------------------------------\n    # The public methods which TarFile provides:\n\n    def close(self):\n        \"\"\"Close the TarFile. In write-mode, two finishing zero blocks are\n           appended to the archive.\n        \"\"\"\n        if self.closed:\n            return\n\n        if self.mode in \"aw\":\n            self.fileobj.write(NUL * (BLOCKSIZE * 2))\n            self.offset += (BLOCKSIZE * 2)\n            # fill up the end with zero-blocks\n            # (like option -b20 for tar does)\n            blocks, remainder = divmod(self.offset, RECORDSIZE)\n            if remainder > 0:\n                self.fileobj.write(NUL * (RECORDSIZE - remainder))\n\n        if not self._extfileobj:\n            self.fileobj.close()\n        self.closed = True\n\n    def getmember(self, name):\n        \"\"\"Return a TarInfo object for member `name'. If `name' can not be\n           found in the archive, KeyError is raised. If a member occurs more\n           than once in the archive, its last occurrence is assumed to be the\n           most up-to-date version.\n        \"\"\"\n        tarinfo = self._getmember(name)\n        if tarinfo is None:\n            raise KeyError(\"filename %r not found\" % name)\n        return tarinfo\n\n    def getmembers(self):\n        \"\"\"Return the members of the archive as a list of TarInfo objects. The\n           list has the same order as the members in the archive.\n        \"\"\"\n        self._check()\n        if not self._loaded:    # if we want to obtain a list of\n            self._load()        # all members, we first have to\n                                # scan the whole archive.\n        return self.members\n\n    def getnames(self):\n        \"\"\"Return the members of the archive as a list of their names. It has\n           the same order as the list returned by getmembers().\n        \"\"\"\n        return [tarinfo.name for tarinfo in self.getmembers()]\n\n    def gettarinfo(self, name=None, arcname=None, fileobj=None):\n        \"\"\"Create a TarInfo object for either the file `name' or the file\n           object `fileobj' (using os.fstat on its file descriptor). You can\n           modify some of the TarInfo's attributes before you add it using\n           addfile(). If given, `arcname' specifies an alternative name for the\n           file in the archive.\n        \"\"\"\n        self._check(\"aw\")\n\n        # When fileobj is given, replace name by\n        # fileobj's real name.\n        if fileobj is not None:\n            name = fileobj.name\n\n        # Building the name of the member in the archive.\n        # Backward slashes are converted to forward slashes,\n        # Absolute paths are turned to relative paths.\n        if arcname is None:\n            arcname = name\n        drv, arcname = os.path.splitdrive(arcname)\n        arcname = arcname.replace(os.sep, \"/\")\n        arcname = arcname.lstrip(\"/\")\n\n        # Now, fill the TarInfo object with\n        # information specific for the file.\n        tarinfo = self.tarinfo()\n        tarinfo.tarfile = self\n\n        # Use os.stat or os.lstat, depending on platform\n        # and if symlinks shall be resolved.\n        if fileobj is None:\n            if hasattr(os, \"lstat\") and not self.dereference:\n                statres = os.lstat(name)\n            else:\n                statres = os.stat(name)\n        else:\n            statres = os.fstat(fileobj.fileno())\n        linkname = \"\"\n\n        stmd = statres.st_mode\n        if stat.S_ISREG(stmd):\n            inode = (statres.st_ino, statres.st_dev)\n            if not self.dereference and statres.st_nlink > 1 and \\\n                    inode in self.inodes and arcname != self.inodes[inode]:\n                # Is it a hardlink to an already\n                # archived file?\n                type = LNKTYPE\n                linkname = self.inodes[inode]\n            else:\n                # The inode is added only if its valid.\n                # For win32 it is always 0.\n                type = REGTYPE\n                if inode[0]:\n                    self.inodes[inode] = arcname\n        elif stat.S_ISDIR(stmd):\n            type = DIRTYPE\n        elif stat.S_ISFIFO(stmd):\n            type = FIFOTYPE\n        elif stat.S_ISLNK(stmd):\n            type = SYMTYPE\n            linkname = os.readlink(name)\n        elif stat.S_ISCHR(stmd):\n            type = CHRTYPE\n        elif stat.S_ISBLK(stmd):\n            type = BLKTYPE\n        else:\n            return None\n\n        # Fill the TarInfo object with all\n        # information we can get.\n        tarinfo.name = arcname\n        tarinfo.mode = stmd\n        tarinfo.uid = statres.st_uid\n        tarinfo.gid = statres.st_gid\n        if type == REGTYPE:\n            tarinfo.size = statres.st_size\n        else:\n            tarinfo.size = 0\n        tarinfo.mtime = statres.st_mtime\n        tarinfo.type = type\n        tarinfo.linkname = linkname\n        if pwd:\n            try:\n                tarinfo.uname = pwd.getpwuid(tarinfo.uid)[0]\n            except KeyError:\n                pass\n        if grp:\n            try:\n                tarinfo.gname = grp.getgrgid(tarinfo.gid)[0]\n            except KeyError:\n                pass\n\n        if type in (CHRTYPE, BLKTYPE):\n            if hasattr(os, \"major\") and hasattr(os, \"minor\"):\n                tarinfo.devmajor = os.major(statres.st_rdev)\n                tarinfo.devminor = os.minor(statres.st_rdev)\n        return tarinfo\n\n    def list(self, verbose=True):\n        \"\"\"Print a table of contents to sys.stdout. If `verbose' is False, only\n           the names of the members are printed. If it is True, an `ls -l'-like\n           output is produced.\n        \"\"\"\n        self._check()\n\n        for tarinfo in self:\n            if verbose:\n                print(stat.filemode(tarinfo.mode), end=' ')\n                print(\"%s/%s\" % (tarinfo.uname or tarinfo.uid,\n                                 tarinfo.gname or tarinfo.gid), end=' ')\n                if tarinfo.ischr() or tarinfo.isblk():\n                    print(\"%10s\" % (\"%d,%d\" \\\n                                    % (tarinfo.devmajor, tarinfo.devminor)), end=' ')\n                else:\n                    print(\"%10d\" % tarinfo.size, end=' ')\n                print(\"%d-%02d-%02d %02d:%02d:%02d\" \\\n                      % time.localtime(tarinfo.mtime)[:6], end=' ')\n\n            print(tarinfo.name + (\"/\" if tarinfo.isdir() else \"\"), end=' ')\n\n            if verbose:\n                if tarinfo.issym():\n                    print(\"->\", tarinfo.linkname, end=' ')\n                if tarinfo.islnk():\n                    print(\"link to\", tarinfo.linkname, end=' ')\n            print()\n\n    def add(self, name, arcname=None, recursive=True, exclude=None, *, filter=None):\n        \"\"\"Add the file `name' to the archive. `name' may be any type of file\n           (directory, fifo, symbolic link, etc.). If given, `arcname'\n           specifies an alternative name for the file in the archive.\n           Directories are added recursively by default. This can be avoided by\n           setting `recursive' to False. `exclude' is a function that should\n           return True for each filename to be excluded. `filter' is a function\n           that expects a TarInfo object argument and returns the changed\n           TarInfo object, if it returns None the TarInfo object will be\n           excluded from the archive.\n        \"\"\"\n        self._check(\"aw\")\n\n        if arcname is None:\n            arcname = name\n\n        # Exclude pathnames.\n        if exclude is not None:\n            import warnings\n            warnings.warn(\"use the filter argument instead\",\n                    DeprecationWarning, 2)\n            if exclude(name):\n                self._dbg(2, \"tarfile: Excluded %r\" % name)\n                return\n\n        # Skip if somebody tries to archive the archive...\n        if self.name is not None and os.path.abspath(name) == self.name:\n            self._dbg(2, \"tarfile: Skipped %r\" % name)\n            return\n\n        self._dbg(1, name)\n\n        # Create a TarInfo object from the file.\n        tarinfo = self.gettarinfo(name, arcname)\n\n        if tarinfo is None:\n            self._dbg(1, \"tarfile: Unsupported type %r\" % name)\n            return\n\n        # Change or exclude the TarInfo object.\n        if filter is not None:\n            tarinfo = filter(tarinfo)\n            if tarinfo is None:\n                self._dbg(2, \"tarfile: Excluded %r\" % name)\n                return\n\n        # Append the tar header and data to the archive.\n        if tarinfo.isreg():\n            with bltn_open(name, \"rb\") as f:\n                self.addfile(tarinfo, f)\n\n        elif tarinfo.isdir():\n            self.addfile(tarinfo)\n            if recursive:\n                for f in os.listdir(name):\n                    self.add(os.path.join(name, f), os.path.join(arcname, f),\n                            recursive, exclude, filter=filter)\n\n        else:\n            self.addfile(tarinfo)\n\n    def addfile(self, tarinfo, fileobj=None):\n        \"\"\"Add the TarInfo object `tarinfo' to the archive. If `fileobj' is\n           given, tarinfo.size bytes are read from it and added to the archive.\n           You can create TarInfo objects using gettarinfo().\n           On Windows platforms, `fileobj' should always be opened with mode\n           'rb' to avoid irritation about the file size.\n        \"\"\"\n        self._check(\"aw\")\n\n        tarinfo = copy.copy(tarinfo)\n\n        buf = tarinfo.tobuf(self.format, self.encoding, self.errors)\n        self.fileobj.write(buf)\n        self.offset += len(buf)\n\n        # If there's data to follow, append it.\n        if fileobj is not None:\n            copyfileobj(fileobj, self.fileobj, tarinfo.size)\n            blocks, remainder = divmod(tarinfo.size, BLOCKSIZE)\n            if remainder > 0:\n                self.fileobj.write(NUL * (BLOCKSIZE - remainder))\n                blocks += 1\n            self.offset += blocks * BLOCKSIZE\n\n        self.members.append(tarinfo)\n\n    def extractall(self, path=\".\", members=None):\n        \"\"\"Extract all members from the archive to the current working\n           directory and set owner, modification time and permissions on\n           directories afterwards. `path' specifies a different directory\n           to extract to. `members' is optional and must be a subset of the\n           list returned by getmembers().\n        \"\"\"\n        directories = []\n\n        if members is None:\n            members = self\n\n        for tarinfo in members:\n            if tarinfo.isdir():\n                # Extract directories with a safe mode.\n                directories.append(tarinfo)\n                tarinfo = copy.copy(tarinfo)\n                tarinfo.mode = 0o700\n            # Do not set_attrs directories, as we will do that further down\n            self.extract(tarinfo, path, set_attrs=not tarinfo.isdir())\n\n        # Reverse sort directories.\n        directories.sort(key=lambda a: a.name)\n        directories.reverse()\n\n        # Set correct owner, mtime and filemode on directories.\n        for tarinfo in directories:\n            dirpath = os.path.join(path, tarinfo.name)\n            try:\n                self.chown(tarinfo, dirpath)\n                self.utime(tarinfo, dirpath)\n                self.chmod(tarinfo, dirpath)\n            except ExtractError as e:\n                if self.errorlevel > 1:\n                    raise\n                else:\n                    self._dbg(1, \"tarfile: %s\" % e)\n\n    def extract(self, member, path=\"\", set_attrs=True):\n        \"\"\"Extract a member from the archive to the current working directory,\n           using its full name. Its file information is extracted as accurately\n           as possible. `member' may be a filename or a TarInfo object. You can\n           specify a different directory using `path'. File attributes (owner,\n           mtime, mode) are set unless `set_attrs' is False.\n        \"\"\"\n        self._check(\"r\")\n\n        if isinstance(member, str):\n            tarinfo = self.getmember(member)\n        else:\n            tarinfo = member\n\n        # Prepare the link target for makelink().\n        if tarinfo.islnk():\n            tarinfo._link_target = os.path.join(path, tarinfo.linkname)\n\n        try:\n            self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n                                 set_attrs=set_attrs)\n        except EnvironmentError as e:\n            if self.errorlevel > 0:\n                raise\n            else:\n                if e.filename is None:\n                    self._dbg(1, \"tarfile: %s\" % e.strerror)\n                else:\n                    self._dbg(1, \"tarfile: %s %r\" % (e.strerror, e.filename))\n        except ExtractError as e:\n            if self.errorlevel > 1:\n                raise\n            else:\n                self._dbg(1, \"tarfile: %s\" % e)\n\n    def extractfile(self, member):\n        \"\"\"Extract a member from the archive as a file object. `member' may be\n           a filename or a TarInfo object. If `member' is a regular file or a\n           link, an io.BufferedReader object is returned. Otherwise, None is\n           returned.\n        \"\"\"\n        self._check(\"r\")\n\n        if isinstance(member, str):\n            tarinfo = self.getmember(member)\n        else:\n            tarinfo = member\n\n        if tarinfo.isreg() or tarinfo.type not in SUPPORTED_TYPES:\n            # Members with unknown types are treated as regular files.\n            return self.fileobject(self, tarinfo)\n\n        elif tarinfo.islnk() or tarinfo.issym():\n            if isinstance(self.fileobj, _Stream):\n                # A small but ugly workaround for the case that someone tries\n                # to extract a (sym)link as a file-object from a non-seekable\n                # stream of tar blocks.\n                raise StreamError(\"cannot extract (sym)link as file object\")\n            else:\n                # A (sym)link's file object is its target's file object.\n                return self.extractfile(self._find_link_target(tarinfo))\n        else:\n            # If there's no data associated with the member (directory, chrdev,\n            # blkdev, etc.), return None instead of a file object.\n            return None\n\n    def _extract_member(self, tarinfo, targetpath, set_attrs=True):\n        \"\"\"Extract the TarInfo object tarinfo to a physical\n           file called targetpath.\n        \"\"\"\n        # Fetch the TarInfo object for the given name\n        # and build the destination pathname, replacing\n        # forward slashes to platform specific separators.\n        targetpath = targetpath.rstrip(\"/\")\n        targetpath = targetpath.replace(\"/\", os.sep)\n\n        # Create all upper directories.\n        upperdirs = os.path.dirname(targetpath)\n        if upperdirs and not os.path.exists(upperdirs):\n            # Create directories that are not part of the archive with\n            # default permissions.\n            os.makedirs(upperdirs)\n\n        if tarinfo.islnk() or tarinfo.issym():\n            self._dbg(1, \"%s -> %s\" % (tarinfo.name, tarinfo.linkname))\n        else:\n            self._dbg(1, tarinfo.name)\n\n        if tarinfo.isreg():\n            self.makefile(tarinfo, targetpath)\n        elif tarinfo.isdir():\n            self.makedir(tarinfo, targetpath)\n        elif tarinfo.isfifo():\n            self.makefifo(tarinfo, targetpath)\n        elif tarinfo.ischr() or tarinfo.isblk():\n            self.makedev(tarinfo, targetpath)\n        elif tarinfo.islnk() or tarinfo.issym():\n            self.makelink(tarinfo, targetpath)\n        elif tarinfo.type not in SUPPORTED_TYPES:\n            self.makeunknown(tarinfo, targetpath)\n        else:\n            self.makefile(tarinfo, targetpath)\n\n        if set_attrs:\n            self.chown(tarinfo, targetpath)\n            if not tarinfo.issym():\n                self.chmod(tarinfo, targetpath)\n                self.utime(tarinfo, targetpath)\n\n    #--------------------------------------------------------------------------\n    # Below are the different file methods. They are called via\n    # _extract_member() when extract() is called. They can be replaced in a\n    # subclass to implement other functionality.\n\n    def makedir(self, tarinfo, targetpath):\n        \"\"\"Make a directory called targetpath.\n        \"\"\"\n        try:\n            # Use a safe mode for the directory, the real mode is set\n            # later in _extract_member().\n            os.mkdir(targetpath, 0o700)\n        except FileExistsError:\n            pass\n\n    def makefile(self, tarinfo, targetpath):\n        \"\"\"Make a file called targetpath.\n        \"\"\"\n        source = self.fileobj\n        source.seek(tarinfo.offset_data)\n        with bltn_open(targetpath, \"wb\") as target:\n            if tarinfo.sparse is not None:\n                for offset, size in tarinfo.sparse:\n                    target.seek(offset)\n                    copyfileobj(source, target, size)\n            else:\n                copyfileobj(source, target, tarinfo.size)\n            target.seek(tarinfo.size)\n            target.truncate()\n\n    def makeunknown(self, tarinfo, targetpath):\n        \"\"\"Make a file from a TarInfo object with an unknown type\n           at targetpath.\n        \"\"\"\n        self.makefile(tarinfo, targetpath)\n        self._dbg(1, \"tarfile: Unknown file type %r, \" \\\n                     \"extracted as regular file.\" % tarinfo.type)\n\n    def makefifo(self, tarinfo, targetpath):\n        \"\"\"Make a fifo called targetpath.\n        \"\"\"\n        if hasattr(os, \"mkfifo\"):\n            os.mkfifo(targetpath)\n        else:\n            raise ExtractError(\"fifo not supported by system\")\n\n    def makedev(self, tarinfo, targetpath):\n        \"\"\"Make a character or block device called targetpath.\n        \"\"\"\n        if not hasattr(os, \"mknod\") or not hasattr(os, \"makedev\"):\n            raise ExtractError(\"special devices not supported by system\")\n\n        mode = tarinfo.mode\n        if tarinfo.isblk():\n            mode |= stat.S_IFBLK\n        else:\n            mode |= stat.S_IFCHR\n\n        os.mknod(targetpath, mode,\n                 os.makedev(tarinfo.devmajor, tarinfo.devminor))\n\n    def makelink(self, tarinfo, targetpath):\n        \"\"\"Make a (symbolic) link called targetpath. If it cannot be created\n          (platform limitation), we try to make a copy of the referenced file\n          instead of a link.\n        \"\"\"\n        try:\n            # For systems that support symbolic and hard links.\n            if tarinfo.issym():\n                os.symlink(tarinfo.linkname, targetpath)\n            else:\n                # See extract().\n                if os.path.exists(tarinfo._link_target):\n                    os.link(tarinfo._link_target, targetpath)\n                else:\n                    self._extract_member(self._find_link_target(tarinfo),\n                                         targetpath)\n        except symlink_exception:\n            try:\n                self._extract_member(self._find_link_target(tarinfo),\n                                     targetpath)\n            except KeyError:\n                raise ExtractError(\"unable to resolve link inside archive\")\n\n    def chown(self, tarinfo, targetpath):\n        \"\"\"Set owner of targetpath according to tarinfo.\n        \"\"\"\n        if pwd and hasattr(os, \"geteuid\") and os.geteuid() == 0:\n            # We have to be root to do so.\n            try:\n                g = grp.getgrnam(tarinfo.gname)[2]\n            except KeyError:\n                g = tarinfo.gid\n            try:\n                u = pwd.getpwnam(tarinfo.uname)[2]\n            except KeyError:\n                u = tarinfo.uid\n            try:\n                if tarinfo.issym() and hasattr(os, \"lchown\"):\n                    os.lchown(targetpath, u, g)\n                else:\n                    if sys.platform != \"os2emx\":\n                        os.chown(targetpath, u, g)\n            except EnvironmentError as e:\n                raise ExtractError(\"could not change owner\")\n\n    def chmod(self, tarinfo, targetpath):\n        \"\"\"Set file permissions of targetpath according to tarinfo.\n        \"\"\"\n        if hasattr(os, 'chmod'):\n            try:\n                os.chmod(targetpath, tarinfo.mode)\n            except EnvironmentError as e:\n                raise ExtractError(\"could not change mode\")\n\n    def utime(self, tarinfo, targetpath):\n        \"\"\"Set modification time of targetpath according to tarinfo.\n        \"\"\"\n        if not hasattr(os, 'utime'):\n            return\n        try:\n            os.utime(targetpath, (tarinfo.mtime, tarinfo.mtime))\n        except EnvironmentError as e:\n            raise ExtractError(\"could not change modification time\")\n\n    #--------------------------------------------------------------------------\n    def next(self):\n        \"\"\"Return the next member of the archive as a TarInfo object, when\n           TarFile is opened for reading. Return None if there is no more\n           available.\n        \"\"\"\n        self._check(\"ra\")\n        if self.firstmember is not None:\n            m = self.firstmember\n            self.firstmember = None\n            return m\n\n        # Read the next block.\n        self.fileobj.seek(self.offset)\n        tarinfo = None\n        while True:\n            try:\n                tarinfo = self.tarinfo.fromtarfile(self)\n            except EOFHeaderError as e:\n                if self.ignore_zeros:\n                    self._dbg(2, \"0x%X: %s\" % (self.offset, e))\n                    self.offset += BLOCKSIZE\n                    continue\n            except InvalidHeaderError as e:\n                if self.ignore_zeros:\n                    self._dbg(2, \"0x%X: %s\" % (self.offset, e))\n                    self.offset += BLOCKSIZE\n                    continue\n                elif self.offset == 0:\n                    raise ReadError(str(e))\n            except EmptyHeaderError:\n                if self.offset == 0:\n                    raise ReadError(\"empty file\")\n            except TruncatedHeaderError as e:\n                if self.offset == 0:\n                    raise ReadError(str(e))\n            except SubsequentHeaderError as e:\n                raise ReadError(str(e))\n            break\n\n        if tarinfo is not None:\n            self.members.append(tarinfo)\n        else:\n            self._loaded = True\n\n        return tarinfo\n\n    #--------------------------------------------------------------------------\n    # Little helper methods:\n\n    def _getmember(self, name, tarinfo=None, normalize=False):\n        \"\"\"Find an archive member by name from bottom to top.\n           If tarinfo is given, it is used as the starting point.\n        \"\"\"\n        # Ensure that all members have been loaded.\n        members = self.getmembers()\n\n        # Limit the member search list up to tarinfo.\n        if tarinfo is not None:\n            members = members[:members.index(tarinfo)]\n\n        if normalize:\n            name = os.path.normpath(name)\n\n        for member in reversed(members):\n            if normalize:\n                member_name = os.path.normpath(member.name)\n            else:\n                member_name = member.name\n\n            if name == member_name:\n                return member\n\n    def _load(self):\n        \"\"\"Read through the entire archive file and look for readable\n           members.\n        \"\"\"\n        while True:\n            tarinfo = self.next()\n            if tarinfo is None:\n                break\n        self._loaded = True\n\n    def _check(self, mode=None):\n        \"\"\"Check if TarFile is still open, and if the operation's mode\n           corresponds to TarFile's mode.\n        \"\"\"\n        if self.closed:\n            raise IOError(\"%s is closed\" % self.__class__.__name__)\n        if mode is not None and self.mode not in mode:\n            raise IOError(\"bad operation for mode %r\" % self.mode)\n\n    def _find_link_target(self, tarinfo):\n        \"\"\"Find the target member of a symlink or hardlink member in the\n           archive.\n        \"\"\"\n        if tarinfo.issym():\n            # Always search the entire archive.\n            linkname = \"/\".join(filter(None, (os.path.dirname(tarinfo.name), tarinfo.linkname)))\n            limit = None\n        else:\n            # Search the archive before the link, because a hard link is\n            # just a reference to an already archived file.\n            linkname = tarinfo.linkname\n            limit = tarinfo\n\n        member = self._getmember(linkname, tarinfo=limit, normalize=True)\n        if member is None:\n            raise KeyError(\"linkname %r not found\" % linkname)\n        return member\n\n    def __iter__(self):\n        \"\"\"Provide an iterator object.\n        \"\"\"\n        if self._loaded:\n            return iter(self.members)\n        else:\n            return TarIter(self)\n\n    def _dbg(self, level, msg):\n        \"\"\"Write debugging output to sys.stderr.\n        \"\"\"\n        if level <= self.debug:\n            print(msg, file=sys.stderr)\n\n    def __enter__(self):\n        self._check()\n        return self\n\n    def __exit__(self, type, value, traceback):\n        if type is None:\n            self.close()\n        else:\n            # An exception occurred. We must not call close() because\n            # it would try to write end-of-archive blocks and padding.\n            if not self._extfileobj:\n                self.fileobj.close()\n            self.closed = True\n# class TarFile\n\nclass TarIter:\n    \"\"\"Iterator Class.\n\n       for tarinfo in TarFile(...):\n           suite...\n    \"\"\"\n\n    def __init__(self, tarfile):\n        \"\"\"Construct a TarIter object.\n        \"\"\"\n        self.tarfile = tarfile\n        self.index = 0\n    def __iter__(self):\n        \"\"\"Return iterator object.\n        \"\"\"\n        return self\n    def __next__(self):\n        \"\"\"Return the next item using TarFile's next() method.\n           When all members have been read, set TarFile as _loaded.\n        \"\"\"\n        # Fix for SF #1100429: Under rare circumstances it can\n        # happen that getmembers() is called during iteration,\n        # which will cause TarIter to stop prematurely.\n\n        if self.index == 0 and self.tarfile.firstmember is not None:\n            tarinfo = self.tarfile.next()\n        elif self.index < len(self.tarfile.members):\n            tarinfo = self.tarfile.members[self.index]\n        elif not self.tarfile._loaded:\n            tarinfo = self.tarfile.next()\n            if not tarinfo:\n                self.tarfile._loaded = True\n                raise StopIteration\n        else:\n            raise StopIteration\n        self.index += 1\n        return tarinfo\n\n#--------------------\n# exported functions\n#--------------------\ndef is_tarfile(name):\n    \"\"\"Return True if name points to a tar archive that we\n       are able to handle, else return False.\n    \"\"\"\n    try:\n        t = open(name)\n        t.close()\n        return True\n    except TarError:\n        return False\n\nbltn_open = open\nopen = TarFile.open\n"], "urllib": [".py", "", 1], "crypto_js.rollups.sha224": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(g,l){var f={},k=f.lib={},h=function(){},m=k.Base={extend:function(a){h.prototype=this;var c=new h;a&&c.mixIn(a);c.hasOwnProperty(\"init\")||(c.init=function(){c.$super.init.apply(this,arguments)});c.init.prototype=c;c.$super=this;return c},create:function(){var a=this.extend();a.init.apply(a,arguments);return a},init:function(){},mixIn:function(a){for(var c in a)a.hasOwnProperty(c)&&(this[c]=a[c]);a.hasOwnProperty(\"toString\")&&(this.toString=a.toString)},clone:function(){return this.init.prototype.extend(this)}},\nq=k.WordArray=m.extend({init:function(a,c){a=this.words=a||[];this.sigBytes=c!=l?c:4*a.length},toString:function(a){return(a||s).stringify(this)},concat:function(a){var c=this.words,d=a.words,b=this.sigBytes;a=a.sigBytes;this.clamp();if(b%4)for(var e=0;e<a;e++)c[b+e>>>2]|=(d[e>>>2]>>>24-8*(e%4)&255)<<24-8*((b+e)%4);else if(65535<d.length)for(e=0;e<a;e+=4)c[b+e>>>2]=d[e>>>2];else c.push.apply(c,d);this.sigBytes+=a;return this},clamp:function(){var a=this.words,c=this.sigBytes;a[c>>>2]&=4294967295<<\n32-8*(c%4);a.length=g.ceil(c/4)},clone:function(){var a=m.clone.call(this);a.words=this.words.slice(0);return a},random:function(a){for(var c=[],d=0;d<a;d+=4)c.push(4294967296*g.random()|0);return new q.init(c,a)}}),t=f.enc={},s=t.Hex={stringify:function(a){var c=a.words;a=a.sigBytes;for(var d=[],b=0;b<a;b++){var e=c[b>>>2]>>>24-8*(b%4)&255;d.push((e>>>4).toString(16));d.push((e&15).toString(16))}return d.join(\"\")},parse:function(a){for(var c=a.length,d=[],b=0;b<c;b+=2)d[b>>>3]|=parseInt(a.substr(b,\n2),16)<<24-4*(b%8);return new q.init(d,c/2)}},n=t.Latin1={stringify:function(a){var c=a.words;a=a.sigBytes;for(var d=[],b=0;b<a;b++)d.push(String.fromCharCode(c[b>>>2]>>>24-8*(b%4)&255));return d.join(\"\")},parse:function(a){for(var c=a.length,d=[],b=0;b<c;b++)d[b>>>2]|=(a.charCodeAt(b)&255)<<24-8*(b%4);return new q.init(d,c)}},j=t.Utf8={stringify:function(a){try{return decodeURIComponent(escape(n.stringify(a)))}catch(c){throw Error(\"Malformed UTF-8 data\");}},parse:function(a){return n.parse(unescape(encodeURIComponent(a)))}},\nw=k.BufferedBlockAlgorithm=m.extend({reset:function(){this._data=new q.init;this._nDataBytes=0},_append:function(a){\"string\"==typeof a&&(a=j.parse(a));this._data.concat(a);this._nDataBytes+=a.sigBytes},_process:function(a){var c=this._data,d=c.words,b=c.sigBytes,e=this.blockSize,f=b/(4*e),f=a?g.ceil(f):g.max((f|0)-this._minBufferSize,0);a=f*e;b=g.min(4*a,b);if(a){for(var u=0;u<a;u+=e)this._doProcessBlock(d,u);u=d.splice(0,a);c.sigBytes-=b}return new q.init(u,b)},clone:function(){var a=m.clone.call(this);\na._data=this._data.clone();return a},_minBufferSize:0});k.Hasher=w.extend({cfg:m.extend(),init:function(a){this.cfg=this.cfg.extend(a);this.reset()},reset:function(){w.reset.call(this);this._doReset()},update:function(a){this._append(a);this._process();return this},finalize:function(a){a&&this._append(a);return this._doFinalize()},blockSize:16,_createHelper:function(a){return function(c,d){return(new a.init(d)).finalize(c)}},_createHmacHelper:function(a){return function(c,d){return(new v.HMAC.init(a,\nd)).finalize(c)}}});var v=f.algo={};return f}(Math);\n(function(g){for(var l=CryptoJS,f=l.lib,k=f.WordArray,h=f.Hasher,f=l.algo,m=[],q=[],t=function(a){return 4294967296*(a-(a|0))|0},s=2,n=0;64>n;){var j;a:{j=s;for(var w=g.sqrt(j),v=2;v<=w;v++)if(!(j%v)){j=!1;break a}j=!0}j&&(8>n&&(m[n]=t(g.pow(s,0.5))),q[n]=t(g.pow(s,1/3)),n++);s++}var a=[],f=f.SHA256=h.extend({_doReset:function(){this._hash=new k.init(m.slice(0))},_doProcessBlock:function(c,d){for(var b=this._hash.words,e=b[0],f=b[1],g=b[2],k=b[3],h=b[4],l=b[5],m=b[6],n=b[7],p=0;64>p;p++){if(16>p)a[p]=\nc[d+p]|0;else{var j=a[p-15],r=a[p-2];a[p]=((j<<25|j>>>7)^(j<<14|j>>>18)^j>>>3)+a[p-7]+((r<<15|r>>>17)^(r<<13|r>>>19)^r>>>10)+a[p-16]}j=n+((h<<26|h>>>6)^(h<<21|h>>>11)^(h<<7|h>>>25))+(h&l^~h&m)+q[p]+a[p];r=((e<<30|e>>>2)^(e<<19|e>>>13)^(e<<10|e>>>22))+(e&f^e&g^f&g);n=m;m=l;l=h;h=k+j|0;k=g;g=f;f=e;e=j+r|0}b[0]=b[0]+e|0;b[1]=b[1]+f|0;b[2]=b[2]+g|0;b[3]=b[3]+k|0;b[4]=b[4]+h|0;b[5]=b[5]+l|0;b[6]=b[6]+m|0;b[7]=b[7]+n|0},_doFinalize:function(){var a=this._data,d=a.words,b=8*this._nDataBytes,e=8*a.sigBytes;\nd[e>>>5]|=128<<24-e%32;d[(e+64>>>9<<4)+14]=g.floor(b/4294967296);d[(e+64>>>9<<4)+15]=b;a.sigBytes=4*d.length;this._process();return this._hash},clone:function(){var a=h.clone.call(this);a._hash=this._hash.clone();return a}});l.SHA256=h._createHelper(f);l.HmacSHA256=h._createHmacHelper(f)})(Math);\n(function(){var g=CryptoJS,l=g.lib.WordArray,f=g.algo,k=f.SHA256,f=f.SHA224=k.extend({_doReset:function(){this._hash=new l.init([3238371032,914150663,812702999,4144912697,4290775857,1750603025,1694076839,3204075428])},_doFinalize:function(){var f=k._doFinalize.call(this);f.sigBytes-=4;return f}});g.SHA224=k._createHelper(f);g.HmacSHA224=k._createHmacHelper(f)})();\n"], "VFS_import": [".py", "import os\nfrom browser import doc\n\n#_scripts=doc.createElement('script')\n#_scripts.src=\"/src/py_VFS.js\"\n#_scripts.type=\"text/javascript\"\n#doc.get(tag='head')[0].appendChild(_scripts)\n\nVFS=dict(JSObject(__BRYTHON__.py_VFS))\nclass VFSModuleFinder:\n    def __init__(self, path_entry):\n        print(\"in VFSModuleFinder\")\n        if path_entry.startswith('/libs') or path_entry.startswith('/Lib'):\n           self.path_entry=path_entry\n        else:\n            raise ImportError()\n        \n    def __str__(self):\n        return '<%s for \"%s\">' % (self.__class__.__name__, self.path_entry)\n        \n    def find_module(self, fullname, path=None):\n        path = path or self.path_entry\n        #print('looking for \"%s\" in %s ...' % (fullname, path))\n        for _ext in ['js', 'pyj', 'py']:\n            _filepath=os.path.join(self.path_entry, '%s.%s' % (fullname, _ext))\n            if _filepath in VFS:\n               print(\"module found at %s:%s\" % (_filepath, fullname))\n               return VFSModuleLoader(_filepath, fullname)\n\n        print('module %s not found' % fullname)\n        raise ImportError()\n        return None\n\nclass VFSModuleLoader:\n    \"\"\"Load source for modules\"\"\"\n    \n    def __init__(self, filepath, name):\n        self._filepath=filepath\n        self._name=name\n        \n    def get_source(self):\n        if self._filepath in VFS:\n           return JSObject(readFromVFS(self._filepath))\n\n        raise ImportError('could not find source for %s' % fullname)\n\n    def is_package(self):\n        return '.' in self._name\n            \n    def load_module(self):\n        if self._name in sys.modules:\n           #print('reusing existing module from previous import of \"%s\"' % fullname)\n           mod = sys.modules[self._name]\n           return mod\n        \n        _src=self.get_source()\n        if self._filepath.endswith('.js'):\n           mod=JSObject(import_js_module(_src, self._filepath, self._name))\n        elif self._filepath.endswith('.py'):\n           mod=JSObject(import_py_module(_src, self._filepath, self._name))\n        elif self._filepath.endswith('.pyj'):\n           mod=JSObject(import_pyj_module(_src, self._filepath, self._name))\n        else:\n           raise ImportError('Invalid Module: %s' % self._filepath)\n\n        # Set a few properties required by PEP 302\n        mod.__file__ = self._filepath\n        mod.__name__ = self._name\n        mod.__path__ = os.path.abspath(self._filepath)\n        mod.__loader__ = self\n        mod.__package__ = '.'.join(self._name.split('.')[:-1])\n        \n        if self.is_package():\n           print('adding path for package')\n           # Set __path__ for packages\n           # so we can find the sub-modules.\n           mod.__path__ = [ self.path_entry ]\n        else:\n            print('imported as regular module')\n        \n        print('creating a new module object for \"%s\"' % self._name)\n        sys.modules.setdefault(self._name, mod)\n        JSObject(__BRYTHON__.imported)[self._name]=mod\n\n        return mod\n\nJSObject(__BRYTHON__.path_hooks.insert(0, VFSModuleFinder))\n"], "unittest.test.test_discovery": [".py", "import os\nimport re\nimport sys\n\nimport unittest\n\n\nclass TestableTestProgram(unittest.TestProgram):\n    module = '__main__'\n    exit = True\n    defaultTest = failfast = catchbreak = buffer = None\n    verbosity = 1\n    progName = ''\n    testRunner = testLoader = None\n\n    def __init__(self):\n        pass\n\n\nclass TestDiscovery(unittest.TestCase):\n\n    # Heavily mocked tests so I can avoid hitting the filesystem\n    def test_get_name_from_path(self):\n        loader = unittest.TestLoader()\n        loader._top_level_dir = '/foo'\n        name = loader._get_name_from_path('/foo/bar/baz.py')\n        self.assertEqual(name, 'bar.baz')\n\n        if not __debug__:\n            # asserts are off\n            return\n\n        with self.assertRaises(AssertionError):\n            loader._get_name_from_path('/bar/baz.py')\n\n    def test_find_tests(self):\n        loader = unittest.TestLoader()\n\n        original_listdir = os.listdir\n        def restore_listdir():\n            os.listdir = original_listdir\n        original_isfile = os.path.isfile\n        def restore_isfile():\n            os.path.isfile = original_isfile\n        original_isdir = os.path.isdir\n        def restore_isdir():\n            os.path.isdir = original_isdir\n\n        path_lists = [['test1.py', 'test2.py', 'not_a_test.py', 'test_dir',\n                       'test.foo', 'test-not-a-module.py', 'another_dir'],\n                      ['test3.py', 'test4.py', ]]\n        os.listdir = lambda path: path_lists.pop(0)\n        self.addCleanup(restore_listdir)\n\n        def isdir(path):\n            return path.endswith('dir')\n        os.path.isdir = isdir\n        self.addCleanup(restore_isdir)\n\n        def isfile(path):\n            # another_dir is not a package and so shouldn't be recursed into\n            return not path.endswith('dir') and not 'another_dir' in path\n        os.path.isfile = isfile\n        self.addCleanup(restore_isfile)\n\n        loader._get_module_from_name = lambda path: path + ' module'\n        loader.loadTestsFromModule = lambda module: module + ' tests'\n\n        top_level = os.path.abspath('/foo')\n        loader._top_level_dir = top_level\n        suite = list(loader._find_tests(top_level, 'test*.py'))\n\n        expected = [name + ' module tests' for name in\n                    ('test1', 'test2')]\n        expected.extend([('test_dir.%s' % name) + ' module tests' for name in\n                    ('test3', 'test4')])\n        self.assertEqual(suite, expected)\n\n    def test_find_tests_with_package(self):\n        loader = unittest.TestLoader()\n\n        original_listdir = os.listdir\n        def restore_listdir():\n            os.listdir = original_listdir\n        original_isfile = os.path.isfile\n        def restore_isfile():\n            os.path.isfile = original_isfile\n        original_isdir = os.path.isdir\n        def restore_isdir():\n            os.path.isdir = original_isdir\n\n        directories = ['a_directory', 'test_directory', 'test_directory2']\n        path_lists = [directories, [], [], []]\n        os.listdir = lambda path: path_lists.pop(0)\n        self.addCleanup(restore_listdir)\n\n        os.path.isdir = lambda path: True\n        self.addCleanup(restore_isdir)\n\n        os.path.isfile = lambda path: os.path.basename(path) not in directories\n        self.addCleanup(restore_isfile)\n\n        class Module(object):\n            paths = []\n            load_tests_args = []\n\n            def __init__(self, path):\n                self.path = path\n                self.paths.append(path)\n                if os.path.basename(path) == 'test_directory':\n                    def load_tests(loader, tests, pattern):\n                        self.load_tests_args.append((loader, tests, pattern))\n                        return 'load_tests'\n                    self.load_tests = load_tests\n\n            def __eq__(self, other):\n                return self.path == other.path\n\n        loader._get_module_from_name = lambda name: Module(name)\n        def loadTestsFromModule(module, use_load_tests):\n            if use_load_tests:\n                raise self.failureException('use_load_tests should be False for packages')\n            return module.path + ' module tests'\n        loader.loadTestsFromModule = loadTestsFromModule\n\n        loader._top_level_dir = '/foo'\n        # this time no '.py' on the pattern so that it can match\n        # a test package\n        suite = list(loader._find_tests('/foo', 'test*'))\n\n        # We should have loaded tests from the test_directory package by calling load_tests\n        # and directly from the test_directory2 package\n        self.assertEqual(suite,\n                         ['load_tests', 'test_directory2' + ' module tests'])\n        self.assertEqual(Module.paths, ['test_directory', 'test_directory2'])\n\n        # load_tests should have been called once with loader, tests and pattern\n        self.assertEqual(Module.load_tests_args,\n                         [(loader, 'test_directory' + ' module tests', 'test*')])\n\n    def test_discover(self):\n        loader = unittest.TestLoader()\n\n        original_isfile = os.path.isfile\n        original_isdir = os.path.isdir\n        def restore_isfile():\n            os.path.isfile = original_isfile\n\n        os.path.isfile = lambda path: False\n        self.addCleanup(restore_isfile)\n\n        orig_sys_path = sys.path[:]\n        def restore_path():\n            sys.path[:] = orig_sys_path\n        self.addCleanup(restore_path)\n\n        full_path = os.path.abspath(os.path.normpath('/foo'))\n        with self.assertRaises(ImportError):\n            loader.discover('/foo/bar', top_level_dir='/foo')\n\n        self.assertEqual(loader._top_level_dir, full_path)\n        self.assertIn(full_path, sys.path)\n\n        os.path.isfile = lambda path: True\n        os.path.isdir = lambda path: True\n\n        def restore_isdir():\n            os.path.isdir = original_isdir\n        self.addCleanup(restore_isdir)\n\n        _find_tests_args = []\n        def _find_tests(start_dir, pattern):\n            _find_tests_args.append((start_dir, pattern))\n            return ['tests']\n        loader._find_tests = _find_tests\n        loader.suiteClass = str\n\n        suite = loader.discover('/foo/bar/baz', 'pattern', '/foo/bar')\n\n        top_level_dir = os.path.abspath('/foo/bar')\n        start_dir = os.path.abspath('/foo/bar/baz')\n        self.assertEqual(suite, \"['tests']\")\n        self.assertEqual(loader._top_level_dir, top_level_dir)\n        self.assertEqual(_find_tests_args, [(start_dir, 'pattern')])\n        self.assertIn(top_level_dir, sys.path)\n\n    def test_discover_with_modules_that_fail_to_import(self):\n        loader = unittest.TestLoader()\n\n        listdir = os.listdir\n        os.listdir = lambda _: ['test_this_does_not_exist.py']\n        isfile = os.path.isfile\n        os.path.isfile = lambda _: True\n        orig_sys_path = sys.path[:]\n        def restore():\n            os.path.isfile = isfile\n            os.listdir = listdir\n            sys.path[:] = orig_sys_path\n        self.addCleanup(restore)\n\n        suite = loader.discover('.')\n        self.assertIn(os.getcwd(), sys.path)\n        self.assertEqual(suite.countTestCases(), 1)\n        test = list(list(suite)[0])[0] # extract test from suite\n\n        with self.assertRaises(ImportError):\n            test.test_this_does_not_exist()\n\n    def test_command_line_handling_parseArgs(self):\n        program = TestableTestProgram()\n\n        args = []\n        def do_discovery(argv):\n            args.extend(argv)\n        program._do_discovery = do_discovery\n        program.parseArgs(['something', 'discover'])\n        self.assertEqual(args, [])\n\n        program.parseArgs(['something', 'discover', 'foo', 'bar'])\n        self.assertEqual(args, ['foo', 'bar'])\n\n    def test_command_line_handling_discover_by_default(self):\n        program = TestableTestProgram()\n        program.module = None\n\n        self.called = False\n        def do_discovery(argv):\n            self.called = True\n            self.assertEqual(argv, [])\n        program._do_discovery = do_discovery\n        program.parseArgs(['something'])\n        self.assertTrue(self.called)\n\n    def test_command_line_handling_discover_by_default_with_options(self):\n        program = TestableTestProgram()\n        program.module = None\n\n        args = ['something', '-v', '-b', '-v', '-c', '-f']\n        self.called = False\n        def do_discovery(argv):\n            self.called = True\n            self.assertEqual(argv, args[1:])\n        program._do_discovery = do_discovery\n        program.parseArgs(args)\n        self.assertTrue(self.called)\n\n\n    def test_command_line_handling_do_discovery_too_many_arguments(self):\n        class Stop(Exception):\n            pass\n        def usageExit():\n            raise Stop\n\n        program = TestableTestProgram()\n        program.usageExit = usageExit\n\n        with self.assertRaises(Stop):\n            # too many args\n            program._do_discovery(['one', 'two', 'three', 'four'])\n\n\n    def test_command_line_handling_do_discovery_calls_loader(self):\n        program = TestableTestProgram()\n\n        class Loader(object):\n            args = []\n            def discover(self, start_dir, pattern, top_level_dir):\n                self.args.append((start_dir, pattern, top_level_dir))\n                return 'tests'\n\n        program._do_discovery(['-v'], Loader=Loader)\n        self.assertEqual(program.verbosity, 2)\n        self.assertEqual(program.test, 'tests')\n        self.assertEqual(Loader.args, [('.', 'test*.py', None)])\n\n        Loader.args = []\n        program = TestableTestProgram()\n        program._do_discovery(['--verbose'], Loader=Loader)\n        self.assertEqual(program.test, 'tests')\n        self.assertEqual(Loader.args, [('.', 'test*.py', None)])\n\n        Loader.args = []\n        program = TestableTestProgram()\n        program._do_discovery([], Loader=Loader)\n        self.assertEqual(program.test, 'tests')\n        self.assertEqual(Loader.args, [('.', 'test*.py', None)])\n\n        Loader.args = []\n        program = TestableTestProgram()\n        program._do_discovery(['fish'], Loader=Loader)\n        self.assertEqual(program.test, 'tests')\n        self.assertEqual(Loader.args, [('fish', 'test*.py', None)])\n\n        Loader.args = []\n        program = TestableTestProgram()\n        program._do_discovery(['fish', 'eggs'], Loader=Loader)\n        self.assertEqual(program.test, 'tests')\n        self.assertEqual(Loader.args, [('fish', 'eggs', None)])\n\n        Loader.args = []\n        program = TestableTestProgram()\n        program._do_discovery(['fish', 'eggs', 'ham'], Loader=Loader)\n        self.assertEqual(program.test, 'tests')\n        self.assertEqual(Loader.args, [('fish', 'eggs', 'ham')])\n\n        Loader.args = []\n        program = TestableTestProgram()\n        program._do_discovery(['-s', 'fish'], Loader=Loader)\n        self.assertEqual(program.test, 'tests')\n        self.assertEqual(Loader.args, [('fish', 'test*.py', None)])\n\n        Loader.args = []\n        program = TestableTestProgram()\n        program._do_discovery(['-t', 'fish'], Loader=Loader)\n        self.assertEqual(program.test, 'tests')\n        self.assertEqual(Loader.args, [('.', 'test*.py', 'fish')])\n\n        Loader.args = []\n        program = TestableTestProgram()\n        program._do_discovery(['-p', 'fish'], Loader=Loader)\n        self.assertEqual(program.test, 'tests')\n        self.assertEqual(Loader.args, [('.', 'fish', None)])\n        self.assertFalse(program.failfast)\n        self.assertFalse(program.catchbreak)\n\n        Loader.args = []\n        program = TestableTestProgram()\n        program._do_discovery(['-p', 'eggs', '-s', 'fish', '-v', '-f', '-c'],\n                              Loader=Loader)\n        self.assertEqual(program.test, 'tests')\n        self.assertEqual(Loader.args, [('fish', 'eggs', None)])\n        self.assertEqual(program.verbosity, 2)\n        self.assertTrue(program.failfast)\n        self.assertTrue(program.catchbreak)\n\n    def test_detect_module_clash(self):\n        class Module(object):\n            __file__ = 'bar/foo.py'\n        sys.modules['foo'] = Module\n        full_path = os.path.abspath('foo')\n        original_listdir = os.listdir\n        original_isfile = os.path.isfile\n        original_isdir = os.path.isdir\n\n        def cleanup():\n            os.listdir = original_listdir\n            os.path.isfile = original_isfile\n            os.path.isdir = original_isdir\n            del sys.modules['foo']\n            if full_path in sys.path:\n                sys.path.remove(full_path)\n        self.addCleanup(cleanup)\n\n        def listdir(_):\n            return ['foo.py']\n        def isfile(_):\n            return True\n        def isdir(_):\n            return True\n        os.listdir = listdir\n        os.path.isfile = isfile\n        os.path.isdir = isdir\n\n        loader = unittest.TestLoader()\n\n        mod_dir = os.path.abspath('bar')\n        expected_dir = os.path.abspath('foo')\n        msg = re.escape(r\"'foo' module incorrectly imported from %r. Expected %r. \"\n                \"Is this module globally installed?\" % (mod_dir, expected_dir))\n        self.assertRaisesRegex(\n            ImportError, '^%s$' % msg, loader.discover,\n            start_dir='foo', pattern='foo.py'\n        )\n        self.assertEqual(sys.path[0], full_path)\n\n\n    def test_discovery_from_dotted_path(self):\n        loader = unittest.TestLoader()\n\n        tests = [self]\n        expectedPath = os.path.abspath(os.path.dirname(unittest.test.__file__))\n\n        self.wasRun = False\n        def _find_tests(start_dir, pattern):\n            self.wasRun = True\n            self.assertEqual(start_dir, expectedPath)\n            return tests\n        loader._find_tests = _find_tests\n        suite = loader.discover('unittest.test')\n        self.assertTrue(self.wasRun)\n        self.assertEqual(suite._tests, tests)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"], "colorsys": [".py", "\"\"\"Conversion functions between RGB and other color systems.\n\nThis modules provides two functions for each color system ABC:\n\n  rgb_to_abc(r, g, b) --> a, b, c\n  abc_to_rgb(a, b, c) --> r, g, b\n\nAll inputs and outputs are triples of floats in the range [0.0...1.0]\n(with the exception of I and Q, which covers a slightly larger range).\nInputs outside the valid range may cause exceptions or invalid outputs.\n\nSupported color systems:\nRGB: Red, Green, Blue components\nYIQ: Luminance, Chrominance (used by composite video signals)\nHLS: Hue, Luminance, Saturation\nHSV: Hue, Saturation, Value\n\"\"\"\n\n# References:\n# http://en.wikipedia.org/wiki/YIQ\n# http://en.wikipedia.org/wiki/HLS_color_space\n# http://en.wikipedia.org/wiki/HSV_color_space\n\n__all__ = [\"rgb_to_yiq\",\"yiq_to_rgb\",\"rgb_to_hls\",\"hls_to_rgb\",\n           \"rgb_to_hsv\",\"hsv_to_rgb\"]\n\n# Some floating point constants\n\nONE_THIRD = 1.0/3.0\nONE_SIXTH = 1.0/6.0\nTWO_THIRD = 2.0/3.0\n\n# YIQ: used by composite video signals (linear combinations of RGB)\n# Y: perceived grey level (0.0 == black, 1.0 == white)\n# I, Q: color components\n\ndef rgb_to_yiq(r, g, b):\n    y = 0.30*r + 0.59*g + 0.11*b\n    i = 0.60*r - 0.28*g - 0.32*b\n    q = 0.21*r - 0.52*g + 0.31*b\n    return (y, i, q)\n\ndef yiq_to_rgb(y, i, q):\n    r = y + 0.948262*i + 0.624013*q\n    g = y - 0.276066*i - 0.639810*q\n    b = y - 1.105450*i + 1.729860*q\n    if r < 0.0:\n        r = 0.0\n    if g < 0.0:\n        g = 0.0\n    if b < 0.0:\n        b = 0.0\n    if r > 1.0:\n        r = 1.0\n    if g > 1.0:\n        g = 1.0\n    if b > 1.0:\n        b = 1.0\n    return (r, g, b)\n\n\n# HLS: Hue, Luminance, Saturation\n# H: position in the spectrum\n# L: color lightness\n# S: color saturation\n\ndef rgb_to_hls(r, g, b):\n    maxc = max(r, g, b)\n    minc = min(r, g, b)\n    # XXX Can optimize (maxc+minc) and (maxc-minc)\n    l = (minc+maxc)/2.0\n    if minc == maxc:\n        return 0.0, l, 0.0\n    if l <= 0.5:\n        s = (maxc-minc) / (maxc+minc)\n    else:\n        s = (maxc-minc) / (2.0-maxc-minc)\n    rc = (maxc-r) / (maxc-minc)\n    gc = (maxc-g) / (maxc-minc)\n    bc = (maxc-b) / (maxc-minc)\n    if r == maxc:\n        h = bc-gc\n    elif g == maxc:\n        h = 2.0+rc-bc\n    else:\n        h = 4.0+gc-rc\n    h = (h/6.0) % 1.0\n    return h, l, s\n\ndef hls_to_rgb(h, l, s):\n    if s == 0.0:\n        return l, l, l\n    if l <= 0.5:\n        m2 = l * (1.0+s)\n    else:\n        m2 = l+s-(l*s)\n    m1 = 2.0*l - m2\n    return (_v(m1, m2, h+ONE_THIRD), _v(m1, m2, h), _v(m1, m2, h-ONE_THIRD))\n\ndef _v(m1, m2, hue):\n    hue = hue % 1.0\n    if hue < ONE_SIXTH:\n        return m1 + (m2-m1)*hue*6.0\n    if hue < 0.5:\n        return m2\n    if hue < TWO_THIRD:\n        return m1 + (m2-m1)*(TWO_THIRD-hue)*6.0\n    return m1\n\n\n# HSV: Hue, Saturation, Value\n# H: position in the spectrum\n# S: color saturation (\"purity\")\n# V: color brightness\n\ndef rgb_to_hsv(r, g, b):\n    maxc = max(r, g, b)\n    minc = min(r, g, b)\n    v = maxc\n    if minc == maxc:\n        return 0.0, 0.0, v\n    s = (maxc-minc) / maxc\n    rc = (maxc-r) / (maxc-minc)\n    gc = (maxc-g) / (maxc-minc)\n    bc = (maxc-b) / (maxc-minc)\n    if r == maxc:\n        h = bc-gc\n    elif g == maxc:\n        h = 2.0+rc-bc\n    else:\n        h = 4.0+gc-rc\n    h = (h/6.0) % 1.0\n    return h, s, v\n\ndef hsv_to_rgb(h, s, v):\n    if s == 0.0:\n        return v, v, v\n    i = int(h*6.0) # XXX assume int() truncates!\n    f = (h*6.0) - i\n    p = v*(1.0 - s)\n    q = v*(1.0 - s*f)\n    t = v*(1.0 - s*(1.0-f))\n    i = i%6\n    if i == 0:\n        return v, t, p\n    if i == 1:\n        return q, v, p\n    if i == 2:\n        return p, v, t\n    if i == 3:\n        return p, q, v\n    if i == 4:\n        return t, p, v\n    if i == 5:\n        return v, p, q\n    # Cannot get here\n"], "formatter": [".py", "\"\"\"Generic output formatting.\n\nFormatter objects transform an abstract flow of formatting events into\nspecific output events on writer objects. Formatters manage several stack\nstructures to allow various properties of a writer object to be changed and\nrestored; writers need not be able to handle relative changes nor any sort\nof ``change back'' operation. Specific writer properties which may be\ncontrolled via formatter objects are horizontal alignment, font, and left\nmargin indentations. A mechanism is provided which supports providing\narbitrary, non-exclusive style settings to a writer as well. Additional\ninterfaces facilitate formatting events which are not reversible, such as\nparagraph separation.\n\nWriter objects encapsulate device interfaces. Abstract devices, such as\nfile formats, are supported as well as physical devices. The provided\nimplementations all work with abstract devices. The interface makes\navailable mechanisms for setting the properties which formatter objects\nmanage and inserting data into the output.\n\"\"\"\n\nimport sys\n\n\nAS_IS = None\n\n\nclass NullFormatter:\n    \"\"\"A formatter which does nothing.\n\n    If the writer parameter is omitted, a NullWriter instance is created.\n    No methods of the writer are called by NullFormatter instances.\n\n    Implementations should inherit from this class if implementing a writer\n    interface but don't need to inherit any implementation.\n\n    \"\"\"\n\n    def __init__(self, writer=None):\n        if writer is None:\n            writer = NullWriter()\n        self.writer = writer\n    def end_paragraph(self, blankline): pass\n    def add_line_break(self): pass\n    def add_hor_rule(self, *args, **kw): pass\n    def add_label_data(self, format, counter, blankline=None): pass\n    def add_flowing_data(self, data): pass\n    def add_literal_data(self, data): pass\n    def flush_softspace(self): pass\n    def push_alignment(self, align): pass\n    def pop_alignment(self): pass\n    def push_font(self, x): pass\n    def pop_font(self): pass\n    def push_margin(self, margin): pass\n    def pop_margin(self): pass\n    def set_spacing(self, spacing): pass\n    def push_style(self, *styles): pass\n    def pop_style(self, n=1): pass\n    def assert_line_data(self, flag=1): pass\n\n\nclass AbstractFormatter:\n    \"\"\"The standard formatter.\n\n    This implementation has demonstrated wide applicability to many writers,\n    and may be used directly in most circumstances.  It has been used to\n    implement a full-featured World Wide Web browser.\n\n    \"\"\"\n\n    #  Space handling policy:  blank spaces at the boundary between elements\n    #  are handled by the outermost context.  \"Literal\" data is not checked\n    #  to determine context, so spaces in literal data are handled directly\n    #  in all circumstances.\n\n    def __init__(self, writer):\n        self.writer = writer            # Output device\n        self.align = None               # Current alignment\n        self.align_stack = []           # Alignment stack\n        self.font_stack = []            # Font state\n        self.margin_stack = []          # Margin state\n        self.spacing = None             # Vertical spacing state\n        self.style_stack = []           # Other state, e.g. color\n        self.nospace = 1                # Should leading space be suppressed\n        self.softspace = 0              # Should a space be inserted\n        self.para_end = 1               # Just ended a paragraph\n        self.parskip = 0                # Skipped space between paragraphs?\n        self.hard_break = 1             # Have a hard break\n        self.have_label = 0\n\n    def end_paragraph(self, blankline):\n        if not self.hard_break:\n            self.writer.send_line_break()\n            self.have_label = 0\n        if self.parskip < blankline and not self.have_label:\n            self.writer.send_paragraph(blankline - self.parskip)\n            self.parskip = blankline\n            self.have_label = 0\n        self.hard_break = self.nospace = self.para_end = 1\n        self.softspace = 0\n\n    def add_line_break(self):\n        if not (self.hard_break or self.para_end):\n            self.writer.send_line_break()\n            self.have_label = self.parskip = 0\n        self.hard_break = self.nospace = 1\n        self.softspace = 0\n\n    def add_hor_rule(self, *args, **kw):\n        if not self.hard_break:\n            self.writer.send_line_break()\n        self.writer.send_hor_rule(*args, **kw)\n        self.hard_break = self.nospace = 1\n        self.have_label = self.para_end = self.softspace = self.parskip = 0\n\n    def add_label_data(self, format, counter, blankline = None):\n        if self.have_label or not self.hard_break:\n            self.writer.send_line_break()\n        if not self.para_end:\n            self.writer.send_paragraph((blankline and 1) or 0)\n        if isinstance(format, str):\n            self.writer.send_label_data(self.format_counter(format, counter))\n        else:\n            self.writer.send_label_data(format)\n        self.nospace = self.have_label = self.hard_break = self.para_end = 1\n        self.softspace = self.parskip = 0\n\n    def format_counter(self, format, counter):\n        label = ''\n        for c in format:\n            if c == '1':\n                label = label + ('%d' % counter)\n            elif c in 'aA':\n                if counter > 0:\n                    label = label + self.format_letter(c, counter)\n            elif c in 'iI':\n                if counter > 0:\n                    label = label + self.format_roman(c, counter)\n            else:\n                label = label + c\n        return label\n\n    def format_letter(self, case, counter):\n        label = ''\n        while counter > 0:\n            counter, x = divmod(counter-1, 26)\n            # This makes a strong assumption that lowercase letters\n            # and uppercase letters form two contiguous blocks, with\n            # letters in order!\n            s = chr(ord(case) + x)\n            label = s + label\n        return label\n\n    def format_roman(self, case, counter):\n        ones = ['i', 'x', 'c', 'm']\n        fives = ['v', 'l', 'd']\n        label, index = '', 0\n        # This will die of IndexError when counter is too big\n        while counter > 0:\n            counter, x = divmod(counter, 10)\n            if x == 9:\n                label = ones[index] + ones[index+1] + label\n            elif x == 4:\n                label = ones[index] + fives[index] + label\n            else:\n                if x >= 5:\n                    s = fives[index]\n                    x = x-5\n                else:\n                    s = ''\n                s = s + ones[index]*x\n                label = s + label\n            index = index + 1\n        if case == 'I':\n            return label.upper()\n        return label\n\n    def add_flowing_data(self, data):\n        if not data: return\n        prespace = data[:1].isspace()\n        postspace = data[-1:].isspace()\n        data = \" \".join(data.split())\n        if self.nospace and not data:\n            return\n        elif prespace or self.softspace:\n            if not data:\n                if not self.nospace:\n                    self.softspace = 1\n                    self.parskip = 0\n                return\n            if not self.nospace:\n                data = ' ' + data\n        self.hard_break = self.nospace = self.para_end = \\\n                          self.parskip = self.have_label = 0\n        self.softspace = postspace\n        self.writer.send_flowing_data(data)\n\n    def add_literal_data(self, data):\n        if not data: return\n        if self.softspace:\n            self.writer.send_flowing_data(\" \")\n        self.hard_break = data[-1:] == '\\n'\n        self.nospace = self.para_end = self.softspace = \\\n                       self.parskip = self.have_label = 0\n        self.writer.send_literal_data(data)\n\n    def flush_softspace(self):\n        if self.softspace:\n            self.hard_break = self.para_end = self.parskip = \\\n                              self.have_label = self.softspace = 0\n            self.nospace = 1\n            self.writer.send_flowing_data(' ')\n\n    def push_alignment(self, align):\n        if align and align != self.align:\n            self.writer.new_alignment(align)\n            self.align = align\n            self.align_stack.append(align)\n        else:\n            self.align_stack.append(self.align)\n\n    def pop_alignment(self):\n        if self.align_stack:\n            del self.align_stack[-1]\n        if self.align_stack:\n            self.align = align = self.align_stack[-1]\n            self.writer.new_alignment(align)\n        else:\n            self.align = None\n            self.writer.new_alignment(None)\n\n    def push_font(self, font):\n        size, i, b, tt = font\n        if self.softspace:\n            self.hard_break = self.para_end = self.softspace = 0\n            self.nospace = 1\n            self.writer.send_flowing_data(' ')\n        if self.font_stack:\n            csize, ci, cb, ctt = self.font_stack[-1]\n            if size is AS_IS: size = csize\n            if i is AS_IS: i = ci\n            if b is AS_IS: b = cb\n            if tt is AS_IS: tt = ctt\n        font = (size, i, b, tt)\n        self.font_stack.append(font)\n        self.writer.new_font(font)\n\n    def pop_font(self):\n        if self.font_stack:\n            del self.font_stack[-1]\n        if self.font_stack:\n            font = self.font_stack[-1]\n        else:\n            font = None\n        self.writer.new_font(font)\n\n    def push_margin(self, margin):\n        self.margin_stack.append(margin)\n        fstack = [m for m in self.margin_stack if m]\n        if not margin and fstack:\n            margin = fstack[-1]\n        self.writer.new_margin(margin, len(fstack))\n\n    def pop_margin(self):\n        if self.margin_stack:\n            del self.margin_stack[-1]\n        fstack = [m for m in self.margin_stack if m]\n        if fstack:\n            margin = fstack[-1]\n        else:\n            margin = None\n        self.writer.new_margin(margin, len(fstack))\n\n    def set_spacing(self, spacing):\n        self.spacing = spacing\n        self.writer.new_spacing(spacing)\n\n    def push_style(self, *styles):\n        if self.softspace:\n            self.hard_break = self.para_end = self.softspace = 0\n            self.nospace = 1\n            self.writer.send_flowing_data(' ')\n        for style in styles:\n            self.style_stack.append(style)\n        self.writer.new_styles(tuple(self.style_stack))\n\n    def pop_style(self, n=1):\n        del self.style_stack[-n:]\n        self.writer.new_styles(tuple(self.style_stack))\n\n    def assert_line_data(self, flag=1):\n        self.nospace = self.hard_break = not flag\n        self.para_end = self.parskip = self.have_label = 0\n\n\nclass NullWriter:\n    \"\"\"Minimal writer interface to use in testing & inheritance.\n\n    A writer which only provides the interface definition; no actions are\n    taken on any methods.  This should be the base class for all writers\n    which do not need to inherit any implementation methods.\n\n    \"\"\"\n    def __init__(self): pass\n    def flush(self): pass\n    def new_alignment(self, align): pass\n    def new_font(self, font): pass\n    def new_margin(self, margin, level): pass\n    def new_spacing(self, spacing): pass\n    def new_styles(self, styles): pass\n    def send_paragraph(self, blankline): pass\n    def send_line_break(self): pass\n    def send_hor_rule(self, *args, **kw): pass\n    def send_label_data(self, data): pass\n    def send_flowing_data(self, data): pass\n    def send_literal_data(self, data): pass\n\n\nclass AbstractWriter(NullWriter):\n    \"\"\"A writer which can be used in debugging formatters, but not much else.\n\n    Each method simply announces itself by printing its name and\n    arguments on standard output.\n\n    \"\"\"\n\n    def new_alignment(self, align):\n        print(\"new_alignment(%r)\" % (align,))\n\n    def new_font(self, font):\n        print(\"new_font(%r)\" % (font,))\n\n    def new_margin(self, margin, level):\n        print(\"new_margin(%r, %d)\" % (margin, level))\n\n    def new_spacing(self, spacing):\n        print(\"new_spacing(%r)\" % (spacing,))\n\n    def new_styles(self, styles):\n        print(\"new_styles(%r)\" % (styles,))\n\n    def send_paragraph(self, blankline):\n        print(\"send_paragraph(%r)\" % (blankline,))\n\n    def send_line_break(self):\n        print(\"send_line_break()\")\n\n    def send_hor_rule(self, *args, **kw):\n        print(\"send_hor_rule()\")\n\n    def send_label_data(self, data):\n        print(\"send_label_data(%r)\" % (data,))\n\n    def send_flowing_data(self, data):\n        print(\"send_flowing_data(%r)\" % (data,))\n\n    def send_literal_data(self, data):\n        print(\"send_literal_data(%r)\" % (data,))\n\n\nclass DumbWriter(NullWriter):\n    \"\"\"Simple writer class which writes output on the file object passed in\n    as the file parameter or, if file is omitted, on standard output.  The\n    output is simply word-wrapped to the number of columns specified by\n    the maxcol parameter.  This class is suitable for reflowing a sequence\n    of paragraphs.\n\n    \"\"\"\n\n    def __init__(self, file=None, maxcol=72):\n        self.file = file or sys.stdout\n        self.maxcol = maxcol\n        NullWriter.__init__(self)\n        self.reset()\n\n    def reset(self):\n        self.col = 0\n        self.atbreak = 0\n\n    def send_paragraph(self, blankline):\n        self.file.write('\\n'*blankline)\n        self.col = 0\n        self.atbreak = 0\n\n    def send_line_break(self):\n        self.file.write('\\n')\n        self.col = 0\n        self.atbreak = 0\n\n    def send_hor_rule(self, *args, **kw):\n        self.file.write('\\n')\n        self.file.write('-'*self.maxcol)\n        self.file.write('\\n')\n        self.col = 0\n        self.atbreak = 0\n\n    def send_literal_data(self, data):\n        self.file.write(data)\n        i = data.rfind('\\n')\n        if i >= 0:\n            self.col = 0\n            data = data[i+1:]\n        data = data.expandtabs()\n        self.col = self.col + len(data)\n        self.atbreak = 0\n\n    def send_flowing_data(self, data):\n        if not data: return\n        atbreak = self.atbreak or data[0].isspace()\n        col = self.col\n        maxcol = self.maxcol\n        write = self.file.write\n        for word in data.split():\n            if atbreak:\n                if col + len(word) >= maxcol:\n                    write('\\n')\n                    col = 0\n                else:\n                    write(' ')\n                    col = col + 1\n            write(word)\n            col = col + len(word)\n            atbreak = 1\n        self.col = col\n        self.atbreak = data[-1].isspace()\n\n\ndef test(file = None):\n    w = DumbWriter()\n    f = AbstractFormatter(w)\n    if file is not None:\n        fp = open(file)\n    elif sys.argv[1:]:\n        fp = open(sys.argv[1])\n    else:\n        fp = sys.stdin\n    for line in fp:\n        if line == '\\n':\n            f.end_paragraph(1)\n        else:\n            f.add_flowing_data(line)\n    f.end_paragraph(0)\n\n\nif __name__ == '__main__':\n    test()\n"], "unittest.test.testmock.testcallable": [".py", "# Copyright (C) 2007-2012 Michael Foord & the mock team\n# E-mail: fuzzyman AT voidspace DOT org DOT uk\n# http://www.voidspace.org.uk/python/mock/\n\nimport unittest\nfrom unittest.test.testmock.support import is_instance, X, SomeClass\n\nfrom unittest.mock import (\n    Mock, MagicMock, NonCallableMagicMock,\n    NonCallableMock, patch, create_autospec,\n    CallableMixin\n)\n\n\n\nclass TestCallable(unittest.TestCase):\n\n    def assertNotCallable(self, mock):\n        self.assertTrue(is_instance(mock, NonCallableMagicMock))\n        self.assertFalse(is_instance(mock, CallableMixin))\n\n\n    def test_non_callable(self):\n        for mock in NonCallableMagicMock(), NonCallableMock():\n            self.assertRaises(TypeError, mock)\n            self.assertFalse(hasattr(mock, '__call__'))\n            self.assertIn(mock.__class__.__name__, repr(mock))\n\n\n    def test_heirarchy(self):\n        self.assertTrue(issubclass(MagicMock, Mock))\n        self.assertTrue(issubclass(NonCallableMagicMock, NonCallableMock))\n\n\n    def test_attributes(self):\n        one = NonCallableMock()\n        self.assertTrue(issubclass(type(one.one), Mock))\n\n        two = NonCallableMagicMock()\n        self.assertTrue(issubclass(type(two.two), MagicMock))\n\n\n    def test_subclasses(self):\n        class MockSub(Mock):\n            pass\n\n        one = MockSub()\n        self.assertTrue(issubclass(type(one.one), MockSub))\n\n        class MagicSub(MagicMock):\n            pass\n\n        two = MagicSub()\n        self.assertTrue(issubclass(type(two.two), MagicSub))\n\n\n    def test_patch_spec(self):\n        patcher = patch('%s.X' % __name__, spec=True)\n        mock = patcher.start()\n        self.addCleanup(patcher.stop)\n\n        instance = mock()\n        mock.assert_called_once_with()\n\n        self.assertNotCallable(instance)\n        self.assertRaises(TypeError, instance)\n\n\n    def test_patch_spec_set(self):\n        patcher = patch('%s.X' % __name__, spec_set=True)\n        mock = patcher.start()\n        self.addCleanup(patcher.stop)\n\n        instance = mock()\n        mock.assert_called_once_with()\n\n        self.assertNotCallable(instance)\n        self.assertRaises(TypeError, instance)\n\n\n    def test_patch_spec_instance(self):\n        patcher = patch('%s.X' % __name__, spec=X())\n        mock = patcher.start()\n        self.addCleanup(patcher.stop)\n\n        self.assertNotCallable(mock)\n        self.assertRaises(TypeError, mock)\n\n\n    def test_patch_spec_set_instance(self):\n        patcher = patch('%s.X' % __name__, spec_set=X())\n        mock = patcher.start()\n        self.addCleanup(patcher.stop)\n\n        self.assertNotCallable(mock)\n        self.assertRaises(TypeError, mock)\n\n\n    def test_patch_spec_callable_class(self):\n        class CallableX(X):\n            def __call__(self):\n                pass\n\n        class Sub(CallableX):\n            pass\n\n        class Multi(SomeClass, Sub):\n            pass\n\n        for arg in 'spec', 'spec_set':\n            for Klass in CallableX, Sub, Multi:\n                with patch('%s.X' % __name__, **{arg: Klass}) as mock:\n                    instance = mock()\n                    mock.assert_called_once_with()\n\n                    self.assertTrue(is_instance(instance, MagicMock))\n                    # inherited spec\n                    self.assertRaises(AttributeError, getattr, instance,\n                                      'foobarbaz')\n\n                    result = instance()\n                    # instance is callable, result has no spec\n                    instance.assert_called_once_with()\n\n                    result(3, 2, 1)\n                    result.assert_called_once_with(3, 2, 1)\n                    result.foo(3, 2, 1)\n                    result.foo.assert_called_once_with(3, 2, 1)\n\n\n    def test_create_autopsec(self):\n        mock = create_autospec(X)\n        instance = mock()\n        self.assertRaises(TypeError, instance)\n\n        mock = create_autospec(X())\n        self.assertRaises(TypeError, mock)\n\n\n    def test_create_autospec_instance(self):\n        mock = create_autospec(SomeClass, instance=True)\n\n        self.assertRaises(TypeError, mock)\n        mock.wibble()\n        mock.wibble.assert_called_once_with()\n\n        self.assertRaises(TypeError, mock.wibble, 'some',  'args')\n"], "math": [".js", "var $module=(function($B){\n\nvar _b_ = $B.builtins\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\n//for(var $py_builtin in _b_){eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")}\n\nvar float_check=function(x) {\n    if (x.value !== undefined && isinstance(x, float)) return x.value\n    return x\n}\n\nvar isWholeNumber=function(x){return (x*10) % 10 == 0}\n\nvar isOdd=function(x) {return isWholeNumber(x) && 2*Math.floor(x/2) != x}\n\nvar isLargeNumber=function(x) {return x > Math.pow(2,32)}\n\n// Big number Library from jsfromhell.com\n// This library helps with producing \"correct\" results from \n// mathematic operations\n\n//+ Jonas Raoni Soares Silva\n//@ http://jsfromhell.com/classes/bignumber [rev. #4]\n\n\nvar BigNumber = function(n, p, r){\n\tvar o = this, i;\n\tif(n instanceof BigNumber){\n\t\tfor(i in {precision: 0, roundType: 0, _s: 0, _f: 0}) o[i] = n[i];\n\t\to._d = n._d.slice();\n\t\treturn;\n\t}\n\to.precision = isNaN(p = Math.abs(p)) ? BigNumber.defaultPrecision : p;\n\to.roundType = isNaN(r = Math.abs(r)) ? BigNumber.defaultRoundType : r;\n\to._s = (n += \"\").charAt(0) == \"-\";\n\to._f = ((n = n.replace(/[^\\d.]/g, \"\").split(\".\", 2))[0] = n[0].replace(/^0+/, \"\") || \"0\").length;\n\tfor(i = (n = o._d = (n.join(\"\") || \"0\").split(\"\")).length; i; n[--i] = +n[i]);\n\to.round();\n};\nwith({$: BigNumber, o: BigNumber.prototype}){\n\t$.ROUND_HALF_EVEN = ($.ROUND_HALF_DOWN = ($.ROUND_HALF_UP = ($.ROUND_FLOOR = ($.ROUND_CEIL = ($.ROUND_DOWN = ($.ROUND_UP = 0) + 1) + 1) + 1) + 1) + 1) + 1;\n\t$.defaultPrecision = 40;\n\t$.defaultRoundType = $.ROUND_HALF_UP;\n\to.add = function(n){\n\t\tif(this._s != (n = new BigNumber(n))._s)\n\t\t\treturn n._s ^= 1, this.subtract(n);\n\t\tvar o = new BigNumber(this), a = o._d, b = n._d, la = o._f,\n\t\tlb = n._f, n = Math.max(la, lb), i, r;\n\t\tla != lb && ((lb = la - lb) > 0 ? o._zeroes(b, lb, 1) : o._zeroes(a, -lb, 1));\n\t\ti = (la = a.length) == (lb = b.length) ? a.length : ((lb = la - lb) > 0 ? o._zeroes(b, lb) : o._zeroes(a, -lb)).length;\n\t\tfor(r = 0; i; r = (a[--i] = a[i] + b[i] + r) / 10 >>> 0, a[i] %= 10);\n\t\treturn r && ++n && a.unshift(r), o._f = n, o.round();\n\t};\n\to.subtract = function(n){\n\t\tif(this._s != (n = new BigNumber(n))._s)\n\t\t\treturn n._s ^= 1, this.add(n);\n\t\tvar o = new BigNumber(this), c = o.abs().compare(n.abs()) + 1, a = c ? o : n, b = c ? n : o, la = a._f, lb = b._f, d = la, i, j;\n\t\ta = a._d, b = b._d, la != lb && ((lb = la - lb) > 0 ? o._zeroes(b, lb, 1) : o._zeroes(a, -lb, 1));\n\t\tfor(i = (la = a.length) == (lb = b.length) ? a.length : ((lb = la - lb) > 0 ? o._zeroes(b, lb) : o._zeroes(a, -lb)).length; i;){\n\t\t\tif(a[--i] < b[i]){\n\t\t\t\tfor(j = i; j && !a[--j]; a[j] = 9);\n\t\t\t\t--a[j], a[i] += 10;\n\t\t\t}\n\t\t\tb[i] = a[i] - b[i];\n\t\t}\n\t\treturn c || (o._s ^= 1), o._f = d, o._d = b, o.round();\n\t};\n\to.multiply = function(n){\n\t\tvar o = new BigNumber(this), r = o._d.length >= (n = new BigNumber(n))._d.length, a = (r ? o : n)._d,\n\t\tb = (r ? n : o)._d, la = a.length, lb = b.length, x = new BigNumber, i, j, s;\n\t\tfor(i = lb; i; r && s.unshift(r), x.set(x.add(new BigNumber(s.join(\"\")))))\n\t\t\tfor(s = (new Array(lb - --i)).join(\"0\").split(\"\"), r = 0, j = la; j; r += a[--j] * b[i], s.unshift(r % 10), r = (r / 10) >>> 0);\n\t\treturn o._s = o._s != n._s, o._f = ((r = la + lb - o._f - n._f) >= (j = (o._d = x._d).length) ? this._zeroes(o._d, r - j + 1, 1).length : j) - r, o.round();\n\t};\n\to.divide = function(n){\n\t\tif((n = new BigNumber(n)) == \"0\")\n\t\t\tthrow new Error(\"Division by 0\");\n\t\telse if(this == \"0\")\n\t\t\treturn new BigNumber;\n\t\tvar o = new BigNumber(this), a = o._d, b = n._d, la = a.length - o._f,\n\t\tlb = b.length - n._f, r = new BigNumber, i = 0, j, s, l, f = 1, c = 0, e = 0;\n\t\tr._s = o._s != n._s, r.precision = Math.max(o.precision, n.precision),\n\t\tr._f = +r._d.pop(), la != lb && o._zeroes(la > lb ? b : a, Math.abs(la - lb));\n\t\tn._f = b.length, b = n, b._s = false, b = b.round();\n\t\tfor(n = new BigNumber; a[0] == \"0\"; a.shift());\n\t\tout:\n\t\tdo{\n\t\t\tfor(l = c = 0, n == \"0\" && (n._d = [], n._f = 0); i < a.length && n.compare(b) == -1; ++i){\n\t\t\t\t(l = i + 1 == a.length, (!f && ++c > 1 || (e = l && n == \"0\" && a[i] == \"0\")))\n\t\t\t\t&& (r._f == r._d.length && ++r._f, r._d.push(0));\n\t\t\t\t(a[i] == \"0\" && n == \"0\") || (n._d.push(a[i]), ++n._f);\n\t\t\t\tif(e)\n\t\t\t\t\tbreak out;\n\t\t\t\tif((l && n.compare(b) == -1 && (r._f == r._d.length && ++r._f, 1)) || (l = 0))\n\t\t\t\t\twhile(r._d.push(0), n._d.push(0), ++n._f, n.compare(b) == -1);\n\t\t\t}\n\t\t\tif(f = 0, n.compare(b) == -1 && !(l = 0))\n\t\t\t\twhile(l ? r._d.push(0) : l = 1, n._d.push(0), ++n._f, n.compare(b) == -1);\n\t\t\tfor(s = new BigNumber, j = 0; n.compare(y = s.add(b)) + 1 && ++j; s.set(y));\n\t\t\tn.set(n.subtract(s)), !l && r._f == r._d.length && ++r._f, r._d.push(j);\n\t\t}\n\t\twhile((i < a.length || n != \"0\") && (r._d.length - r._f) <= r.precision);\n\t\treturn r.round();\n\t};\n\to.mod = function(n){\n\t\treturn this.subtract(this.divide(n).intPart().multiply(n));\n\t};\n\to.pow = function(n){\n\t\tvar o = new BigNumber(this), i;\n\t\tif((n = (new BigNumber(n)).intPart()) == 0) return o.set(1);\n\t\tfor(i = Math.abs(n); --i; o.set(o.multiply(this)));\n\t\treturn n < 0 ? o.set((new BigNumber(1)).divide(o)) : o;\n\t};\n\to.set = function(n){\n\t\treturn this.constructor(n), this;\n\t};\n\to.compare = function(n){\n\t\tvar a = this, la = this._f, b = new BigNumber(n), lb = b._f, r = [-1, 1], i, l;\n\t\tif(a._s != b._s)\n\t\t\treturn a._s ? -1 : 1;\n\t\tif(la != lb)\n\t\t\treturn r[(la > lb) ^ a._s];\n\t\tfor(la = (a = a._d).length, lb = (b = b._d).length, i = -1, l = Math.min(la, lb); ++i < l;)\n\t\t\tif(a[i] != b[i])\n\t\t\t\treturn r[(a[i] > b[i]) ^ a._s];\n\t\treturn la != lb ? r[(la > lb) ^ a._s] : 0;\n\t};\n\to.negate = function(){\n\t\tvar n = new BigNumber(this); return n._s ^= 1, n;\n\t};\n\to.abs = function(){\n\t\tvar n = new BigNumber(this); return n._s = 0, n;\n\t};\n\to.intPart = function(){\n\t\treturn new BigNumber((this._s ? \"-\" : \"\") + (this._d.slice(0, this._f).join(\"\") || \"0\"));\n\t};\n\to.valueOf = o.toString = function(){\n\t\tvar o = this;\n\t\treturn (o._s ? \"-\" : \"\") + (o._d.slice(0, o._f).join(\"\") || \"0\") + (o._f != o._d.length ? \".\" + o._d.slice(o._f).join(\"\") : \"\");\n\t};\n\to._zeroes = function(n, l, t){\n\t\tvar s = [\"push\", \"unshift\"][t || 0];\n\t\tfor(++l; --l;  n[s](0));\n\t\treturn n;\n\t};\n\to.round = function(){\n\t\tif(\"_rounding\" in this) return this;\n\t\tvar $ = BigNumber, r = this.roundType, b = this._d, d, p, n, x;\n\t\tfor(this._rounding = true; this._f > 1 && !b[0]; --this._f, b.shift());\n\t\tfor(d = this._f, p = this.precision + d, n = b[p]; b.length > d && !b[b.length -1]; b.pop());\n\t\tx = (this._s ? \"-\" : \"\") + (p - d ? \"0.\" + this._zeroes([], p - d - 1).join(\"\") : \"\") + 1;\n\t\tif(b.length > p){\n\t\t\tn && (r == $.DOWN ? false : r == $.UP ? true : r == $.CEIL ? !this._s\n\t\t\t: r == $.FLOOR ? this._s : r == $.HALF_UP ? n >= 5 : r == $.HALF_DOWN ? n > 5\n\t\t\t: r == $.HALF_EVEN ? n >= 5 && b[p - 1] & 1 : false) && this.add(x);\n\t\t\tb.splice(p, b.length - p);\n\t\t}\n\t\treturn delete this._rounding, this;\n\t};\n}\n\nvar isNegZero=function(x) {return x===0 && Math.atan2(x,x) < 0}\n\nvar _mod = {\n    __getattr__ : function(attr){\n        var res = this[attr]\n        if(res===undefined){$raise('AttributeError','module math has no attribute '+attr)}\n        return res\n    },\n    acos: function(x) {return float(Math.acos(float_check(x)))},\n    acosh: function(x) { \n        if (_b_.$isinf(x)) return float('inf');\n        var y = float_check(x);\n        return float(Math.log(y + Math.sqrt(y*y-1)));\n    },\n    asin: function(x) {return float(Math.asin(float_check(x)))},\n    asinh: function(x) {\n        if (_b_.$isninf(x)) return float('-inf');\n        if (_b_.$isinf(x)) return float('inf');\n        var y = float_check(x);\n        return float(Math.log(y + Math.sqrt(y*y+1)))\n    },\n    atan: function(x) {\n        if (_b_.$isninf(x)) return float(-Math.PI/2);\n        if (_b_.$isinf(x)) return float(Math.PI/2);\n        return float(Math.atan(float_check(x)))},\n    atan2: function(y,x) {\n        return float(Math.atan2(float_check(y),float_check(x)))\n    },\n    atanh: function(x) { \n       var y=float_check(x);\n       if (y==0) return 0;\n       return float(0.5 * Math.log((1/y+1)/(1/y-1)));\n    },\n    ceil: function(x) {\n       try{return getattr(x,'__ceil__')()}catch(err){$B.$pop_exc()}\n\n       if (_b_.$isninf(x)) return float('-inf')\n       if (_b_.$isinf(x)) return float('inf')\n       if (isNaN(x)) return float('nan')\n\n       var y=float_check(x);\n       if (!isNaN(parseFloat(y)) && isFinite(y)) return int(Math.ceil(y));\n       \n       $raise('ValueError', 'object is not a number and does not contain __ceil__')\n    },\n    copysign: function(x,y) {\n        var x1=Math.abs(float_check(x))\n        var y1=float_check(y)\n        var sign=y1?y1<0?-1:1:1\n        if (isNegZero(y1)) sign=-1   // probably need to work on adding a check for -0\n        return float(x1 * sign)\n    },\n    cos : function(x){return float(Math.cos(float_check(x)))},\n    cosh: function(x){\n        if (_b_.$isinf(x)) return float('inf')\n        var y = float_check(x)\n        if (Math.cosh !== undefined) return float(Math.cosh(y))\n        return float((Math.pow(Math.E,y) + Math.pow(Math.E,-y))/2)\n    },\n    degrees: function(x){return float(float_check(x) * 180/Math.PI)},\n    e: float(Math.E),\n    erf: function(x) {\n        // inspired from \n        // http://stackoverflow.com/questions/457408/is-there-an-easily-available-implementation-of-erf-for-python\n        var y =float_check(x);\n        var t = 1.0 / (1.0 + 0.5 * Math.abs(y))\n        var ans = 1 - t * Math.exp( -y*y - 1.26551223 +\n                     t * ( 1.00002368 +\n                     t * ( 0.37409196 + \n                     t * ( 0.09678418 + \n                     t * (-0.18628806 + \n                     t * ( 0.27886807 + \n                     t * (-1.13520398 + \n                     t * ( 1.48851587 + \n                     t * (-0.82215223 + \n                     t * 0.17087277)))))))))\n        if (y >= 0.0) return ans\n\n        return -ans\n    },\n\n    erfc: function(x) {\n        // inspired from \n        // http://stackoverflow.com/questions/457408/is-there-an-easily-available-implementation-of-erf-for-python\n        var y = float_check(x);\n        var t = 1.0 / (1.0 + 0.5 * Math.abs(y))\n        var ans = 1 - t * Math.exp( -y*y - 1.26551223 +\n                     t * ( 1.00002368 +\n                     t * ( 0.37409196 + \n                     t * ( 0.09678418 + \n                     t * (-0.18628806 + \n                     t * ( 0.27886807 + \n                     t * (-1.13520398 + \n                     t * ( 1.48851587 + \n                     t * (-0.82215223 + \n                     t * 0.17087277)))))))))\n        if (y >= 0.0) return 1-ans\n        return 1+ans\n    },\n    exp: function(x){\n         if (_b_.$isninf(x)) {return float(0)}\n         if (_b_.$isinf(x)) {return float('inf')}\n         var _r=Math.exp(float_check(x))\n         if (_b_.$isinf(_r)) {throw OverflowError(\"math range error\")}\n         return float(_r)\n    },\n    expm1: function(x){return float(Math.exp(float_check(x))-1)},\n    //fabs: function(x){ return x>0?float(x):float(-x)},\n    fabs: function(x){return _b_.$fabs(x)}, //located in py_float.js\n    factorial: function(x) {\n         //using code from http://stackoverflow.com/questions/3959211/fast-factorial-function-in-javascript\n         var y=float_check(x);\n         var r=1\n         for (var i=2; i<=y; i++){r*=i}\n         return r\n    },\n    floor:function(x){return Math.floor(float_check(x))},\n    fmod:function(x,y){return float(float_check(x)%float_check(y))},\n    frexp: function(x){return _b_.tuple(_b_.$frexp(x))}, // located in py_float.js\n    //fsum:function(x){},\n    gamma: function(x){\n         //using code from http://stackoverflow.com/questions/3959211/fast-factorial-function-in-javascript\n         // Lanczos Approximation of the Gamma Function\n         // As described in Numerical Recipes in C (2nd ed. Cambridge University Press, 1992)\n         var y=float_check(x);\n         var z = y + 1;\n         var d1 = Math.sqrt(2 * Math.PI) / z;\n\n         var d2 = 1.000000000190015;\n         d2 +=  76.18009172947146 / (z+1);\n         d2 += -86.50532032941677 / (z+2);\n         d2 +=  24.01409824083091 / (z+3); \n         d2 += -1.231739572450155 / (z+4); \n         d2 +=  1.208650973866179E-3 / (z+5);\n         d2 += -5.395239384953E-6 / (z+6);\n\n         return d1 * d2 * Math.pow(z+5.5,z+0.5) * Math.exp(-(z+5.5));\n    },\n    hypot: function(x,y){\n       if (_b_.$isinf(x) || _b_.$isinf(y)) return float('inf')\n       var x1=float_check(x);\n       var y1=float_check(y);\n       return float(Math.sqrt(x1*x1 + y1*y1))},\n    isfinite:function(x) {return isFinite(float_check(x))},\n    isinf:function(x) {return _b_.$isinf(float_check(x))},\n    isnan:function(x) {return isNaN(float_check(x))},\n    ldexp:function(x,i) {return _b_.$ldexp(x,i)},   //located in py_float.js\n    lgamma:function(x) {\n         // see gamma function for sources\n         var y=float_check(x);\n         var z = y + 1;\n         var d1 = Math.sqrt(2 * Math.PI) / z;\n\n         var d2 = 1.000000000190015;\n         d2 +=  76.18009172947146 / (z+1);\n         d2 += -86.50532032941677 / (z+2);\n         d2 +=  24.01409824083091 / (z+3); \n         d2 += -1.231739572450155 / (z+4); \n         d2 +=  1.208650973866179E-3 / (z+5);\n         d2 += -5.395239384953E-6 / (z+6);\n\n         return float(Math.log(Math.abs(d1 * d2 * Math.pow(z+5.5,z+0.5) * Math.exp(-(z+5.5)))));\n    },\n    log: function(x, base) {\n         var x1=float_check(x);\n         if (base === undefined) return float(Math.log(x1));\n         return float(Math.log(x1)/Math.log(float_check(base)));\n    },\n    log1p: function(x) {return float(Math.log(1.0 + float_check(x)))},\n    log2: function(x) {\n        if (isNaN(x)) return float('nan')\n        if (_b_.$isninf(x)) throw ValueError('')\n        var x1=float_check(x)\n        if (x1 < 0.0) throw ValueError('')\n        //if (isLargeNumber(x1)) x1=new BigNumber(x1)         \n        return float(Math.log(x1)/Math.LN2)\n    },\n    log10: function(x) {return float(Math.log(float_check(x))/Math.LN10)},\n    modf:function(x) {\n       if (_b_.$isninf(x)) return _b_.tuple([0.0, float('-inf')])\n       if (_b_.$isinf(x)) return _b_.tuple([0.0, float('inf')])\n       if (isNaN(x)) return _b_.tuple([float('nan'), float('nan')])\n\n       var x1=float_check(x);\n       if (x1 > 0) {\n          var i=float(x1-Math.floor(x1))\n          return _b_.tuple([i, float(x1-i)])\n       }\n\n       var x2=Math.ceil(x1)\n       var i=float(x1-x2)\n       return _b_.tuple([i, float(x2)])\n    },\n    pi : float(Math.PI),\n    pow: function(x,y) {\n        var x1=float_check(x)\n        var y1=float_check(y)\n        if (y1 == 0) return float(1)        \n        if (x1 == 0 && y1 < 0) throw _b_.ValueError('')\n\n        if(isNaN(y1)) {if(x1==1) return float(1) \n                       return float('nan')\n        }\n        if (x1 == 0) return float(0)\n\n        if(_b_.$isninf(y)) {if(x1==1||x1==-1) {return float(1)}\n                       if(x1 < 1 && x1 > -1) return float('inf') \n                       return float(0)\n        }\n        if(_b_.$isinf(y)) {if(x1==1||x1==-1) {return float(1)} \n                      if(x1 < 1 && x1 > -1) return float(0) \n                      return float('inf')}\n\n        if(isNaN(x1)) return float('nan')\n        if(_b_.$isninf(x)) {\n            if (y1 > 0 && isOdd(y1)) return float('-inf')\n            if (y1 > 0) return float('inf')  // this is even or a float\n            if (y1 < 0) return float(0)\n            return float(1)\n        }\n\n        if(_b_.$isinf(x)) { \n            if (y1 > 0) return float('inf')\n            if (y1 < 0) return float(0)\n            return float(1)\n        }\n\n        var r\n        if (isLargeNumber(x1) || isLargeNumber(y1)) {\n           var x=new BigNumber(x1)\n           var y=new BigNumber(y1)\n           r=x.pow(y)\n        } else {\n           r=Math.pow(x1,y1)\n        }\n\n        if (isNaN(r)) return float('nan')\n        if (_b_.$isninf(r)) return float('-inf')\n        if (_b_.$isinf(r)) return float('inf')\n\n        return r\n    },\n    radians: function(x){return float(float_check(x) * Math.PI/180)},\n    sin : function(x){return float(Math.sin(float_check(x)))},\n    sinh: function(x) { \n        //if (_b_.$isinf(x)) return float('inf');\n        var y = float_check(x)\n        if (Math.sinh !== undefined) { return float(Math.sinh(y))}\n        return float((Math.pow(Math.E,y) - Math.pow(Math.E,-y))/2)\n    },\n    sqrt : function(x){\n      var y = float_check(x)\n      if (y < 0) { throw ValueError(\"math range error\")}\n      if (_b_.$isinf(y)) return float('inf')\n      var _r=Math.sqrt(y)\n      if (_b_.$isinf(_r)) {throw OverflowError(\"math range error\")}\n      return float(_r)\n    },\n    tan: function(x) {\n        var y = float_check(x)\n        return float(Math.tan(y))\n    },\n    tanh: function(x) {\n        var y = float_check(x)\n        if (Math.tanh !== undefined) return float(Math.tanh(y))\n        return float((Math.pow(Math.E,y) - Math.pow(Math.E,-y))/\n                     (Math.pow(Math.E,y) + Math.pow(Math.E,-y)))       \n    },\n    trunc: function(x) {\n       try{return getattr(x,'__trunc__')()}catch(err){$B.$pop_exc()}\n       var x1=float_check(x);\n       if (!isNaN(parseFloat(x1)) && isFinite(x1)) {\n          if (Math.trunc !== undefined) { return int(Math.trunc(x1))}\n          if (x1 > 0) {return int(Math.floor(x1))}\n          return int(Math.ceil(x1))  // x1 < 0\n       }\n       $raise('ValueError', 'object is not a number and does not contain __trunc__')\n    }\n}\n\nfor(var $attr in _mod){\n    if(typeof _mod[$attr]==='function'){\n        _mod[$attr].__repr__=(function(func){\n            return function(){return '<built-in function '+func+'>'}})($attr)\n        _mod[$attr].__str__=(function(func){\n            return function(){return '<built-in function '+func+'>'}})($attr)\n    }\n}\n\nreturn _mod\n\n})(__BRYTHON__)\n"], "unittest.loader": [".py", "\"\"\"Loading unittests.\"\"\"\n\nimport os\nimport re\nimport sys\nimport traceback\nimport types\nimport functools\n\nfrom fnmatch import fnmatch\n\nfrom . import case, suite, util\n\n__unittest = True\n\n# what about .pyc or .pyo (etc)\n# we would need to avoid loading the same tests multiple times\n# from '.py', '.pyc' *and* '.pyo'\nVALID_MODULE_NAME = re.compile(r'[_a-z]\\w*\\.py$', re.IGNORECASE)\n\n\ndef _make_failed_import_test(name, suiteClass):\n    message = 'Failed to import test module: %s\\n%s' % (name, traceback.format_exc())\n    return _make_failed_test('ModuleImportFailure', name, ImportError(message),\n                             suiteClass)\n\ndef _make_failed_load_tests(name, exception, suiteClass):\n    return _make_failed_test('LoadTestsFailure', name, exception, suiteClass)\n\ndef _make_failed_test(classname, methodname, exception, suiteClass):\n    def testFailure(self):\n        raise exception\n    attrs = {methodname: testFailure}\n    TestClass = type(classname, (case.TestCase,), attrs)\n    return suiteClass((TestClass(methodname),))\n\ndef _jython_aware_splitext(path):\n    if path.lower().endswith('$py.class'):\n        return path[:-9]\n    return os.path.splitext(path)[0]\n\n\nclass TestLoader(object):\n    \"\"\"\n    This class is responsible for loading tests according to various criteria\n    and returning them wrapped in a TestSuite\n    \"\"\"\n    testMethodPrefix = 'test'\n    sortTestMethodsUsing = staticmethod(util.three_way_cmp)\n    suiteClass = suite.TestSuite\n    _top_level_dir = None\n\n    def loadTestsFromTestCase(self, testCaseClass):\n        \"\"\"Return a suite of all tests cases contained in testCaseClass\"\"\"\n        if issubclass(testCaseClass, suite.TestSuite):\n            raise TypeError(\"Test cases should not be derived from TestSuite.\" \\\n                                \" Maybe you meant to derive from TestCase?\")\n        testCaseNames = self.getTestCaseNames(testCaseClass)\n        if not testCaseNames and hasattr(testCaseClass, 'runTest'):\n            testCaseNames = ['runTest']\n        loaded_suite = self.suiteClass(map(testCaseClass, testCaseNames))\n        return loaded_suite\n\n    def loadTestsFromModule(self, module, use_load_tests=True):\n        \"\"\"Return a suite of all tests cases contained in the given module\"\"\"\n        tests = []\n        for name in dir(module):\n            obj = getattr(module, name)\n            if isinstance(obj, type) and issubclass(obj, case.TestCase):\n                tests.append(self.loadTestsFromTestCase(obj))\n\n        load_tests = getattr(module, 'load_tests', None)\n        tests = self.suiteClass(tests)\n        if use_load_tests and load_tests is not None:\n            try:\n                return load_tests(self, tests, None)\n            except Exception as e:\n                return _make_failed_load_tests(module.__name__, e,\n                                               self.suiteClass)\n        return tests\n\n    def loadTestsFromName(self, name, module=None):\n        \"\"\"Return a suite of all tests cases given a string specifier.\n\n        The name may resolve either to a module, a test case class, a\n        test method within a test case class, or a callable object which\n        returns a TestCase or TestSuite instance.\n\n        The method optionally resolves the names relative to a given module.\n        \"\"\"\n        parts = name.split('.')\n        if module is None:\n            parts_copy = parts[:]\n            while parts_copy:\n                try:\n                    module = __import__('.'.join(parts_copy))\n                    break\n                except ImportError:\n                    del parts_copy[-1]\n                    if not parts_copy:\n                        raise\n            parts = parts[1:]\n        obj = module\n        for part in parts:\n            parent, obj = obj, getattr(obj, part)\n\n        if isinstance(obj, types.ModuleType):\n            return self.loadTestsFromModule(obj)\n        elif isinstance(obj, type) and issubclass(obj, case.TestCase):\n            return self.loadTestsFromTestCase(obj)\n        elif (isinstance(obj, types.FunctionType) and\n              isinstance(parent, type) and\n              issubclass(parent, case.TestCase)):\n            name = parts[-1]\n            inst = parent(name)\n            # static methods follow a different path\n            if not isinstance(getattr(inst, name), types.FunctionType):\n                return self.suiteClass([inst])\n        elif isinstance(obj, suite.TestSuite):\n            return obj\n        if callable(obj):\n            test = obj()\n            if isinstance(test, suite.TestSuite):\n                return test\n            elif isinstance(test, case.TestCase):\n                return self.suiteClass([test])\n            else:\n                raise TypeError(\"calling %s returned %s, not a test\" %\n                                (obj, test))\n        else:\n            raise TypeError(\"don't know how to make test from: %s\" % obj)\n\n    def loadTestsFromNames(self, names, module=None):\n        \"\"\"Return a suite of all tests cases found using the given sequence\n        of string specifiers. See 'loadTestsFromName()'.\n        \"\"\"\n        suites = [self.loadTestsFromName(name, module) for name in names]\n        return self.suiteClass(suites)\n\n    def getTestCaseNames(self, testCaseClass):\n        \"\"\"Return a sorted sequence of method names found within testCaseClass\n        \"\"\"\n        def isTestMethod(attrname, testCaseClass=testCaseClass,\n                         prefix=self.testMethodPrefix):\n            return attrname.startswith(prefix) and \\\n                callable(getattr(testCaseClass, attrname))\n        testFnNames = list(filter(isTestMethod, dir(testCaseClass)))\n        if self.sortTestMethodsUsing:\n            testFnNames.sort(key=functools.cmp_to_key(self.sortTestMethodsUsing))\n        return testFnNames\n\n    def discover(self, start_dir, pattern='test*.py', top_level_dir=None):\n        \"\"\"Find and return all test modules from the specified start\n        directory, recursing into subdirectories to find them and return all\n        tests found within them. Only test files that match the pattern will\n        be loaded. (Using shell style pattern matching.)\n\n        All test modules must be importable from the top level of the project.\n        If the start directory is not the top level directory then the top\n        level directory must be specified separately.\n\n        If a test package name (directory with '__init__.py') matches the\n        pattern then the package will be checked for a 'load_tests' function. If\n        this exists then it will be called with loader, tests, pattern.\n\n        If load_tests exists then discovery does  *not* recurse into the package,\n        load_tests is responsible for loading all tests in the package.\n\n        The pattern is deliberately not stored as a loader attribute so that\n        packages can continue discovery themselves. top_level_dir is stored so\n        load_tests does not need to pass this argument in to loader.discover().\n        \"\"\"\n        set_implicit_top = False\n        if top_level_dir is None and self._top_level_dir is not None:\n            # make top_level_dir optional if called from load_tests in a package\n            top_level_dir = self._top_level_dir\n        elif top_level_dir is None:\n            set_implicit_top = True\n            top_level_dir = start_dir\n\n        top_level_dir = os.path.abspath(top_level_dir)\n\n        if not top_level_dir in sys.path:\n            # all test modules must be importable from the top level directory\n            # should we *unconditionally* put the start directory in first\n            # in sys.path to minimise likelihood of conflicts between installed\n            # modules and development versions?\n            sys.path.insert(0, top_level_dir)\n        self._top_level_dir = top_level_dir\n\n        is_not_importable = False\n        if os.path.isdir(os.path.abspath(start_dir)):\n            start_dir = os.path.abspath(start_dir)\n            if start_dir != top_level_dir:\n                is_not_importable = not os.path.isfile(os.path.join(start_dir, '__init__.py'))\n        else:\n            # support for discovery from dotted module names\n            try:\n                __import__(start_dir)\n            except ImportError:\n                is_not_importable = True\n            else:\n                the_module = sys.modules[start_dir]\n                top_part = start_dir.split('.')[0]\n                start_dir = os.path.abspath(os.path.dirname((the_module.__file__)))\n                if set_implicit_top:\n                    self._top_level_dir = self._get_directory_containing_module(top_part)\n                    sys.path.remove(top_level_dir)\n\n        if is_not_importable:\n            raise ImportError('Start directory is not importable: %r' % start_dir)\n\n        tests = list(self._find_tests(start_dir, pattern))\n        return self.suiteClass(tests)\n\n    def _get_directory_containing_module(self, module_name):\n        module = sys.modules[module_name]\n        full_path = os.path.abspath(module.__file__)\n\n        if os.path.basename(full_path).lower().startswith('__init__.py'):\n            return os.path.dirname(os.path.dirname(full_path))\n        else:\n            # here we have been given a module rather than a package - so\n            # all we can do is search the *same* directory the module is in\n            # should an exception be raised instead\n            return os.path.dirname(full_path)\n\n    def _get_name_from_path(self, path):\n        path = _jython_aware_splitext(os.path.normpath(path))\n\n        _relpath = os.path.relpath(path, self._top_level_dir)\n        assert not os.path.isabs(_relpath), \"Path must be within the project\"\n        assert not _relpath.startswith('..'), \"Path must be within the project\"\n\n        name = _relpath.replace(os.path.sep, '.')\n        return name\n\n    def _get_module_from_name(self, name):\n        __import__(name)\n        return sys.modules[name]\n\n    def _match_path(self, path, full_path, pattern):\n        # override this method to use alternative matching strategy\n        return fnmatch(path, pattern)\n\n    def _find_tests(self, start_dir, pattern):\n        \"\"\"Used by discovery. Yields test suites it loads.\"\"\"\n        paths = os.listdir(start_dir)\n\n        for path in paths:\n            full_path = os.path.join(start_dir, path)\n            if os.path.isfile(full_path):\n                if not VALID_MODULE_NAME.match(path):\n                    # valid Python identifiers only\n                    continue\n                if not self._match_path(path, full_path, pattern):\n                    continue\n                # if the test file matches, load it\n                name = self._get_name_from_path(full_path)\n                try:\n                    module = self._get_module_from_name(name)\n                except:\n                    yield _make_failed_import_test(name, self.suiteClass)\n                else:\n                    mod_file = os.path.abspath(getattr(module, '__file__', full_path))\n                    realpath = _jython_aware_splitext(os.path.realpath(mod_file))\n                    fullpath_noext = _jython_aware_splitext(os.path.realpath(full_path))\n                    if realpath.lower() != fullpath_noext.lower():\n                        module_dir = os.path.dirname(realpath)\n                        mod_name = _jython_aware_splitext(os.path.basename(full_path))\n                        expected_dir = os.path.dirname(full_path)\n                        msg = (\"%r module incorrectly imported from %r. Expected %r. \"\n                               \"Is this module globally installed?\")\n                        raise ImportError(msg % (mod_name, module_dir, expected_dir))\n                    yield self.loadTestsFromModule(module)\n            elif os.path.isdir(full_path):\n                if not os.path.isfile(os.path.join(full_path, '__init__.py')):\n                    continue\n\n                load_tests = None\n                tests = None\n                if fnmatch(path, pattern):\n                    # only check load_tests if the package directory itself matches the filter\n                    name = self._get_name_from_path(full_path)\n                    package = self._get_module_from_name(name)\n                    load_tests = getattr(package, 'load_tests', None)\n                    tests = self.loadTestsFromModule(package, use_load_tests=False)\n\n                if load_tests is None:\n                    if tests is not None:\n                        # tests loaded from package file\n                        yield tests\n                    # recurse into the package\n                    for test in self._find_tests(full_path, pattern):\n                        yield test\n                else:\n                    try:\n                        yield load_tests(self, tests, pattern)\n                    except Exception as e:\n                        yield _make_failed_load_tests(package.__name__, e,\n                                                      self.suiteClass)\n\ndefaultTestLoader = TestLoader()\n\n\ndef _makeLoader(prefix, sortUsing, suiteClass=None):\n    loader = TestLoader()\n    loader.sortTestMethodsUsing = sortUsing\n    loader.testMethodPrefix = prefix\n    if suiteClass:\n        loader.suiteClass = suiteClass\n    return loader\n\ndef getTestCaseNames(testCaseClass, prefix, sortUsing=util.three_way_cmp):\n    return _makeLoader(prefix, sortUsing).getTestCaseNames(testCaseClass)\n\ndef makeSuite(testCaseClass, prefix='test', sortUsing=util.three_way_cmp,\n              suiteClass=suite.TestSuite):\n    return _makeLoader(prefix, sortUsing, suiteClass).loadTestsFromTestCase(\n        testCaseClass)\n\ndef findTestCases(module, prefix='test', sortUsing=util.three_way_cmp,\n                  suiteClass=suite.TestSuite):\n    return _makeLoader(prefix, sortUsing, suiteClass).loadTestsFromModule(\\\n        module)\n"], "unittest.case": [".py", "\"\"\"Test case implementation\"\"\"\n\nimport sys\nimport functools\nimport difflib\nimport pprint\nimport re\nimport warnings\nimport collections\n\nfrom . import result\nfrom .util import (strclass, safe_repr, _count_diff_all_purpose,\n                   _count_diff_hashable)\n\n__unittest = True\n\n\nDIFF_OMITTED = ('\\nDiff is %s characters long. '\n                 'Set self.maxDiff to None to see it.')\n\nclass SkipTest(Exception):\n    \"\"\"\n    Raise this exception in a test to skip it.\n\n    Usually you can use TestCase.skipTest() or one of the skipping decorators\n    instead of raising this directly.\n    \"\"\"\n\nclass _ExpectedFailure(Exception):\n    \"\"\"\n    Raise this when a test is expected to fail.\n\n    This is an implementation detail.\n    \"\"\"\n\n    def __init__(self, exc_info):\n        super(_ExpectedFailure, self).__init__()\n        self.exc_info = exc_info\n\nclass _UnexpectedSuccess(Exception):\n    \"\"\"\n    The test was supposed to fail, but it didn't!\n    \"\"\"\n\n\nclass _Outcome(object):\n    def __init__(self):\n        self.success = True\n        self.skipped = None\n        self.unexpectedSuccess = None\n        self.expectedFailure = None\n        self.errors = []\n        self.failures = []\n\n\ndef _id(obj):\n    return obj\n\ndef skip(reason):\n    \"\"\"\n    Unconditionally skip a test.\n    \"\"\"\n    def decorator(test_item):\n        if not isinstance(test_item, type):\n            @functools.wraps(test_item)\n            def skip_wrapper(*args, **kwargs):\n                raise SkipTest(reason)\n            test_item = skip_wrapper\n\n        test_item.__unittest_skip__ = True\n        test_item.__unittest_skip_why__ = reason\n        return test_item\n    return decorator\n\ndef skipIf(condition, reason):\n    \"\"\"\n    Skip a test if the condition is true.\n    \"\"\"\n    if condition:\n        return skip(reason)\n    return _id\n\ndef skipUnless(condition, reason):\n    \"\"\"\n    Skip a test unless the condition is true.\n    \"\"\"\n    if not condition:\n        return skip(reason)\n    return _id\n\n\ndef expectedFailure(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        try:\n            func(*args, **kwargs)\n        except Exception:\n            raise _ExpectedFailure(sys.exc_info())\n        raise _UnexpectedSuccess\n    return wrapper\n\n\nclass _AssertRaisesBaseContext(object):\n\n    def __init__(self, expected, test_case, callable_obj=None,\n                 expected_regex=None):\n        self.expected = expected\n        self.test_case = test_case\n        if callable_obj is not None:\n            try:\n                self.obj_name = callable_obj.__name__\n            except AttributeError:\n                self.obj_name = str(callable_obj)\n        else:\n            self.obj_name = None\n        if isinstance(expected_regex, (bytes, str)):\n            expected_regex = re.compile(expected_regex)\n        self.expected_regex = expected_regex\n        self.msg = None\n\n    def _raiseFailure(self, standardMsg):\n        msg = self.test_case._formatMessage(self.msg, standardMsg)\n        raise self.test_case.failureException(msg)\n\n    def handle(self, name, callable_obj, args, kwargs):\n        \"\"\"\n        If callable_obj is None, assertRaises/Warns is being used as a\n        context manager, so check for a 'msg' kwarg and return self.\n        If callable_obj is not None, call it passing args and kwargs.\n        \"\"\"\n        if callable_obj is None:\n            self.msg = kwargs.pop('msg', None)\n            return self\n        with self:\n            callable_obj(*args, **kwargs)\n\n\n\nclass _AssertRaisesContext(_AssertRaisesBaseContext):\n    \"\"\"A context manager used to implement TestCase.assertRaises* methods.\"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb):\n        if exc_type is None:\n            try:\n                exc_name = self.expected.__name__\n            except AttributeError:\n                exc_name = str(self.expected)\n            if self.obj_name:\n                self._raiseFailure(\"{} not raised by {}\".format(exc_name,\n                                                                self.obj_name))\n            else:\n                self._raiseFailure(\"{} not raised\".format(exc_name))\n        if not issubclass(exc_type, self.expected):\n            # let unexpected exceptions pass through\n            return False\n        # store exception, without traceback, for later retrieval\n        self.exception = exc_value.with_traceback(None)\n        if self.expected_regex is None:\n            return True\n\n        expected_regex = self.expected_regex\n        if not expected_regex.search(str(exc_value)):\n            self._raiseFailure('\"{}\" does not match \"{}\"'.format(\n                     expected_regex.pattern, str(exc_value)))\n        return True\n\n\nclass _AssertWarnsContext(_AssertRaisesBaseContext):\n    \"\"\"A context manager used to implement TestCase.assertWarns* methods.\"\"\"\n\n    def __enter__(self):\n        # The __warningregistry__'s need to be in a pristine state for tests\n        # to work properly.\n        for v in sys.modules.values():\n            if getattr(v, '__warningregistry__', None):\n                v.__warningregistry__ = {}\n        self.warnings_manager = warnings.catch_warnings(record=True)\n        self.warnings = self.warnings_manager.__enter__()\n        warnings.simplefilter(\"always\", self.expected)\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb):\n        self.warnings_manager.__exit__(exc_type, exc_value, tb)\n        if exc_type is not None:\n            # let unexpected exceptions pass through\n            return\n        try:\n            exc_name = self.expected.__name__\n        except AttributeError:\n            exc_name = str(self.expected)\n        first_matching = None\n        for m in self.warnings:\n            w = m.message\n            if not isinstance(w, self.expected):\n                continue\n            if first_matching is None:\n                first_matching = w\n            if (self.expected_regex is not None and\n                not self.expected_regex.search(str(w))):\n                continue\n            # store warning for later retrieval\n            self.warning = w\n            self.filename = m.filename\n            self.lineno = m.lineno\n            return\n        # Now we simply try to choose a helpful failure message\n        if first_matching is not None:\n            self._raiseFailure('\"{}\" does not match \"{}\"'.format(\n                     self.expected_regex.pattern, str(first_matching)))\n        if self.obj_name:\n            self._raiseFailure(\"{} not triggered by {}\".format(exc_name,\n                                                               self.obj_name))\n        else:\n            self._raiseFailure(\"{} not triggered\".format(exc_name))\n\n\nclass TestCase(object):\n    \"\"\"A class whose instances are single test cases.\n\n    By default, the test code itself should be placed in a method named\n    'runTest'.\n\n    If the fixture may be used for many test cases, create as\n    many test methods as are needed. When instantiating such a TestCase\n    subclass, specify in the constructor arguments the name of the test method\n    that the instance is to execute.\n\n    Test authors should subclass TestCase for their own tests. Construction\n    and deconstruction of the test's environment ('fixture') can be\n    implemented by overriding the 'setUp' and 'tearDown' methods respectively.\n\n    If it is necessary to override the __init__ method, the base class\n    __init__ method must always be called. It is important that subclasses\n    should not change the signature of their __init__ method, since instances\n    of the classes are instantiated automatically by parts of the framework\n    in order to be run.\n\n    When subclassing TestCase, you can set these attributes:\n    * failureException: determines which exception will be raised when\n        the instance's assertion methods fail; test methods raising this\n        exception will be deemed to have 'failed' rather than 'errored'.\n    * longMessage: determines whether long messages (including repr of\n        objects used in assert methods) will be printed on failure in *addition*\n        to any explicit message passed.\n    * maxDiff: sets the maximum length of a diff in failure messages\n        by assert methods using difflib. It is looked up as an instance\n        attribute so can be configured by individual tests if required.\n    \"\"\"\n\n    failureException = AssertionError\n\n    longMessage = True\n\n    maxDiff = 80*8\n\n    # If a string is longer than _diffThreshold, use normal comparison instead\n    # of difflib.  See #11763.\n    _diffThreshold = 2**16\n\n    # Attribute used by TestSuite for classSetUp\n\n    _classSetupFailed = False\n\n    def __init__(self, methodName='runTest'):\n        \"\"\"Create an instance of the class that will use the named test\n           method when executed. Raises a ValueError if the instance does\n           not have a method with the specified name.\n        \"\"\"\n        self._testMethodName = methodName\n        self._outcomeForDoCleanups = None\n        self._testMethodDoc = 'No test'\n        try:\n            testMethod = getattr(self, methodName)\n        except AttributeError:\n            if methodName != 'runTest':\n                # we allow instantiation with no explicit method name\n                # but not an *incorrect* or missing method name\n                raise ValueError(\"no such test method in %s: %s\" %\n                      (self.__class__, methodName))\n        else:\n            self._testMethodDoc = testMethod.__doc__\n        self._cleanups = []\n\n        # Map types to custom assertEqual functions that will compare\n        # instances of said type in more detail to generate a more useful\n        # error message.\n        self._type_equality_funcs = {}\n        self.addTypeEqualityFunc(dict, 'assertDictEqual')\n        self.addTypeEqualityFunc(list, 'assertListEqual')\n        self.addTypeEqualityFunc(tuple, 'assertTupleEqual')\n        self.addTypeEqualityFunc(set, 'assertSetEqual')\n        self.addTypeEqualityFunc(frozenset, 'assertSetEqual')\n        self.addTypeEqualityFunc(str, 'assertMultiLineEqual')\n\n    def addTypeEqualityFunc(self, typeobj, function):\n        \"\"\"Add a type specific assertEqual style function to compare a type.\n\n        This method is for use by TestCase subclasses that need to register\n        their own type equality functions to provide nicer error messages.\n\n        Args:\n            typeobj: The data type to call this function on when both values\n                    are of the same type in assertEqual().\n            function: The callable taking two arguments and an optional\n                    msg= argument that raises self.failureException with a\n                    useful error message when the two arguments are not equal.\n        \"\"\"\n        self._type_equality_funcs[typeobj] = function\n\n    def addCleanup(self, function, *args, **kwargs):\n        \"\"\"Add a function, with arguments, to be called when the test is\n        completed. Functions added are called on a LIFO basis and are\n        called after tearDown on test failure or success.\n\n        Cleanup items are called even if setUp fails (unlike tearDown).\"\"\"\n        self._cleanups.append((function, args, kwargs))\n\n    def setUp(self):\n        \"Hook method for setting up the test fixture before exercising it.\"\n        pass\n\n    def tearDown(self):\n        \"Hook method for deconstructing the test fixture after testing it.\"\n        pass\n\n    @classmethod\n    def setUpClass(cls):\n        \"Hook method for setting up class fixture before running tests in the class.\"\n\n    @classmethod\n    def tearDownClass(cls):\n        \"Hook method for deconstructing the class fixture after running all tests in the class.\"\n\n    def countTestCases(self):\n        return 1\n\n    def defaultTestResult(self):\n        return result.TestResult()\n\n    def shortDescription(self):\n        \"\"\"Returns a one-line description of the test, or None if no\n        description has been provided.\n\n        The default implementation of this method returns the first line of\n        the specified test method's docstring.\n        \"\"\"\n        doc = self._testMethodDoc\n        return doc and doc.split(\"\\n\")[0].strip() or None\n\n\n    def id(self):\n        return \"%s.%s\" % (strclass(self.__class__), self._testMethodName)\n\n    def __eq__(self, other):\n        if type(self) is not type(other):\n            return NotImplemented\n\n        return self._testMethodName == other._testMethodName\n\n    def __hash__(self):\n        return hash((type(self), self._testMethodName))\n\n    def __str__(self):\n        return \"%s (%s)\" % (self._testMethodName, strclass(self.__class__))\n\n    def __repr__(self):\n        return \"<%s testMethod=%s>\" % \\\n               (strclass(self.__class__), self._testMethodName)\n\n    def _addSkip(self, result, reason):\n        addSkip = getattr(result, 'addSkip', None)\n        if addSkip is not None:\n            addSkip(self, reason)\n        else:\n            warnings.warn(\"TestResult has no addSkip method, skips not reported\",\n                          RuntimeWarning, 2)\n            result.addSuccess(self)\n\n    def _executeTestPart(self, function, outcome, isTest=False):\n        try:\n            function()\n        except KeyboardInterrupt:\n            raise\n        except SkipTest as e:\n            outcome.success = False\n            outcome.skipped = str(e)\n        except _UnexpectedSuccess:\n            exc_info = sys.exc_info()\n            outcome.success = False\n            if isTest:\n                outcome.unexpectedSuccess = exc_info\n            else:\n                outcome.errors.append(exc_info)\n        except _ExpectedFailure:\n            outcome.success = False\n            exc_info = sys.exc_info()\n            if isTest:\n                outcome.expectedFailure = exc_info\n            else:\n                outcome.errors.append(exc_info)\n        except self.failureException:\n            outcome.success = False\n            outcome.failures.append(sys.exc_info())\n            exc_info = sys.exc_info()\n        except:\n            outcome.success = False\n            outcome.errors.append(sys.exc_info())\n\n    def run(self, result=None):\n        orig_result = result\n        if result is None:\n            result = self.defaultTestResult()\n            startTestRun = getattr(result, 'startTestRun', None)\n            if startTestRun is not None:\n                startTestRun()\n\n        result.startTest(self)\n\n        testMethod = getattr(self, self._testMethodName)\n        if (getattr(self.__class__, \"__unittest_skip__\", False) or\n            getattr(testMethod, \"__unittest_skip__\", False)):\n            # If the class or method was skipped.\n            try:\n                skip_why = (getattr(self.__class__, '__unittest_skip_why__', '')\n                            or getattr(testMethod, '__unittest_skip_why__', ''))\n                self._addSkip(result, skip_why)\n            finally:\n                result.stopTest(self)\n            return\n        try:\n            outcome = _Outcome()\n            self._outcomeForDoCleanups = outcome\n\n            self._executeTestPart(self.setUp, outcome)\n            if outcome.success:\n                self._executeTestPart(testMethod, outcome, isTest=True)\n                self._executeTestPart(self.tearDown, outcome)\n\n            self.doCleanups()\n            if outcome.success:\n                result.addSuccess(self)\n            else:\n                if outcome.skipped is not None:\n                    self._addSkip(result, outcome.skipped)\n                for exc_info in outcome.errors:\n                    result.addError(self, exc_info)\n                for exc_info in outcome.failures:\n                    result.addFailure(self, exc_info)\n                if outcome.unexpectedSuccess is not None:\n                    addUnexpectedSuccess = getattr(result, 'addUnexpectedSuccess', None)\n                    if addUnexpectedSuccess is not None:\n                        addUnexpectedSuccess(self)\n                    else:\n                        warnings.warn(\"TestResult has no addUnexpectedSuccess method, reporting as failures\",\n                                      RuntimeWarning)\n                        result.addFailure(self, outcome.unexpectedSuccess)\n\n                if outcome.expectedFailure is not None:\n                    addExpectedFailure = getattr(result, 'addExpectedFailure', None)\n                    if addExpectedFailure is not None:\n                        addExpectedFailure(self, outcome.expectedFailure)\n                    else:\n                        warnings.warn(\"TestResult has no addExpectedFailure method, reporting as passes\",\n                                      RuntimeWarning)\n                        result.addSuccess(self)\n            return result\n        finally:\n            result.stopTest(self)\n            if orig_result is None:\n                stopTestRun = getattr(result, 'stopTestRun', None)\n                if stopTestRun is not None:\n                    stopTestRun()\n\n    def doCleanups(self):\n        \"\"\"Execute all cleanup functions. Normally called for you after\n        tearDown.\"\"\"\n        outcome = self._outcomeForDoCleanups or _Outcome()\n        while self._cleanups:\n            function, args, kwargs = self._cleanups.pop()\n            part = lambda: function(*args, **kwargs)\n            self._executeTestPart(part, outcome)\n\n        # return this for backwards compatibility\n        # even though we no longer us it internally\n        return outcome.success\n\n    def __call__(self, *args, **kwds):\n        return self.run(*args, **kwds)\n\n    def debug(self):\n        \"\"\"Run the test without collecting errors in a TestResult\"\"\"\n        self.setUp()\n        getattr(self, self._testMethodName)()\n        self.tearDown()\n        while self._cleanups:\n            function, args, kwargs = self._cleanups.pop(-1)\n            function(*args, **kwargs)\n\n    def skipTest(self, reason):\n        \"\"\"Skip this test.\"\"\"\n        raise SkipTest(reason)\n\n    def fail(self, msg=None):\n        \"\"\"Fail immediately, with the given message.\"\"\"\n        raise self.failureException(msg)\n\n    def assertFalse(self, expr, msg=None):\n        \"\"\"Check that the expression is false.\"\"\"\n        if expr:\n            msg = self._formatMessage(msg, \"%s is not false\" % safe_repr(expr))\n            raise self.failureException(msg)\n\n    def assertTrue(self, expr, msg=None):\n        \"\"\"Check that the expression is true.\"\"\"\n        if not expr:\n            msg = self._formatMessage(msg, \"%s is not true\" % safe_repr(expr))\n            raise self.failureException(msg)\n\n    def _formatMessage(self, msg, standardMsg):\n        \"\"\"Honour the longMessage attribute when generating failure messages.\n        If longMessage is False this means:\n        * Use only an explicit message if it is provided\n        * Otherwise use the standard message for the assert\n\n        If longMessage is True:\n        * Use the standard message\n        * If an explicit message is provided, plus ' : ' and the explicit message\n        \"\"\"\n        if not self.longMessage:\n            return msg or standardMsg\n        if msg is None:\n            return standardMsg\n        try:\n            # don't switch to '{}' formatting in Python 2.X\n            # it changes the way unicode input is handled\n            return '%s : %s' % (standardMsg, msg)\n        except UnicodeDecodeError:\n            return  '%s : %s' % (safe_repr(standardMsg), safe_repr(msg))\n\n    def assertRaises(self, excClass, callableObj=None, *args, **kwargs):\n        \"\"\"Fail unless an exception of class excClass is raised\n           by callableObj when invoked with arguments args and keyword\n           arguments kwargs. If a different type of exception is\n           raised, it will not be caught, and the test case will be\n           deemed to have suffered an error, exactly as for an\n           unexpected exception.\n\n           If called with callableObj omitted or None, will return a\n           context object used like this::\n\n                with self.assertRaises(SomeException):\n                    do_something()\n\n           An optional keyword argument 'msg' can be provided when assertRaises\n           is used as a context object.\n\n           The context manager keeps a reference to the exception as\n           the 'exception' attribute. This allows you to inspect the\n           exception after the assertion::\n\n               with self.assertRaises(SomeException) as cm:\n                   do_something()\n               the_exception = cm.exception\n               self.assertEqual(the_exception.error_code, 3)\n        \"\"\"\n        context = _AssertRaisesContext(excClass, self, callableObj)\n        return context.handle('assertRaises', callableObj, args, kwargs)\n\n    def assertWarns(self, expected_warning, callable_obj=None, *args, **kwargs):\n        \"\"\"Fail unless a warning of class warnClass is triggered\n           by callable_obj when invoked with arguments args and keyword\n           arguments kwargs.  If a different type of warning is\n           triggered, it will not be handled: depending on the other\n           warning filtering rules in effect, it might be silenced, printed\n           out, or raised as an exception.\n\n           If called with callable_obj omitted or None, will return a\n           context object used like this::\n\n                with self.assertWarns(SomeWarning):\n                    do_something()\n\n           An optional keyword argument 'msg' can be provided when assertWarns\n           is used as a context object.\n\n           The context manager keeps a reference to the first matching\n           warning as the 'warning' attribute; similarly, the 'filename'\n           and 'lineno' attributes give you information about the line\n           of Python code from which the warning was triggered.\n           This allows you to inspect the warning after the assertion::\n\n               with self.assertWarns(SomeWarning) as cm:\n                   do_something()\n               the_warning = cm.warning\n               self.assertEqual(the_warning.some_attribute, 147)\n        \"\"\"\n        context = _AssertWarnsContext(expected_warning, self, callable_obj)\n        return context.handle('assertWarns', callable_obj, args, kwargs)\n\n    def _getAssertEqualityFunc(self, first, second):\n        \"\"\"Get a detailed comparison function for the types of the two args.\n\n        Returns: A callable accepting (first, second, msg=None) that will\n        raise a failure exception if first != second with a useful human\n        readable error message for those types.\n        \"\"\"\n        #\n        # NOTE(gregory.p.smith): I considered isinstance(first, type(second))\n        # and vice versa.  I opted for the conservative approach in case\n        # subclasses are not intended to be compared in detail to their super\n        # class instances using a type equality func.  This means testing\n        # subtypes won't automagically use the detailed comparison.  Callers\n        # should use their type specific assertSpamEqual method to compare\n        # subclasses if the detailed comparison is desired and appropriate.\n        # See the discussion in http://bugs.python.org/issue2578.\n        #\n        if type(first) is type(second):\n            asserter = self._type_equality_funcs.get(type(first))\n            if asserter is not None:\n                if isinstance(asserter, str):\n                    asserter = getattr(self, asserter)\n                return asserter\n\n        return self._baseAssertEqual\n\n    def _baseAssertEqual(self, first, second, msg=None):\n        \"\"\"The default assertEqual implementation, not type specific.\"\"\"\n        if not first == second:\n            standardMsg = '%s != %s' % (safe_repr(first), safe_repr(second))\n            msg = self._formatMessage(msg, standardMsg)\n            raise self.failureException(msg)\n\n    def assertEqual(self, first, second, msg=None):\n        \"\"\"Fail if the two objects are unequal as determined by the '=='\n           operator.\n        \"\"\"\n        assertion_func = self._getAssertEqualityFunc(first, second)\n        assertion_func(first, second, msg=msg)\n\n    def assertNotEqual(self, first, second, msg=None):\n        \"\"\"Fail if the two objects are equal as determined by the '!='\n           operator.\n        \"\"\"\n        if not first != second:\n            msg = self._formatMessage(msg, '%s == %s' % (safe_repr(first),\n                                                          safe_repr(second)))\n            raise self.failureException(msg)\n\n    def assertAlmostEqual(self, first, second, places=None, msg=None,\n                          delta=None):\n        \"\"\"Fail if the two objects are unequal as determined by their\n           difference rounded to the given number of decimal places\n           (default 7) and comparing to zero, or by comparing that the\n           between the two objects is more than the given delta.\n\n           Note that decimal places (from zero) are usually not the same\n           as significant digits (measured from the most signficant digit).\n\n           If the two objects compare equal then they will automatically\n           compare almost equal.\n        \"\"\"\n        if first == second:\n            # shortcut\n            return\n        if delta is not None and places is not None:\n            raise TypeError(\"specify delta or places not both\")\n\n        if delta is not None:\n            if abs(first - second) <= delta:\n                return\n\n            standardMsg = '%s != %s within %s delta' % (safe_repr(first),\n                                                        safe_repr(second),\n                                                        safe_repr(delta))\n        else:\n            if places is None:\n                places = 7\n\n            if round(abs(second-first), places) == 0:\n                return\n\n            standardMsg = '%s != %s within %r places' % (safe_repr(first),\n                                                          safe_repr(second),\n                                                          places)\n        msg = self._formatMessage(msg, standardMsg)\n        raise self.failureException(msg)\n\n    def assertNotAlmostEqual(self, first, second, places=None, msg=None,\n                             delta=None):\n        \"\"\"Fail if the two objects are equal as determined by their\n           difference rounded to the given number of decimal places\n           (default 7) and comparing to zero, or by comparing that the\n           between the two objects is less than the given delta.\n\n           Note that decimal places (from zero) are usually not the same\n           as significant digits (measured from the most signficant digit).\n\n           Objects that are equal automatically fail.\n        \"\"\"\n        if delta is not None and places is not None:\n            raise TypeError(\"specify delta or places not both\")\n        if delta is not None:\n            if not (first == second) and abs(first - second) > delta:\n                return\n            standardMsg = '%s == %s within %s delta' % (safe_repr(first),\n                                                        safe_repr(second),\n                                                        safe_repr(delta))\n        else:\n            if places is None:\n                places = 7\n            if not (first == second) and round(abs(second-first), places) != 0:\n                return\n            standardMsg = '%s == %s within %r places' % (safe_repr(first),\n                                                         safe_repr(second),\n                                                         places)\n\n        msg = self._formatMessage(msg, standardMsg)\n        raise self.failureException(msg)\n\n\n    def assertSequenceEqual(self, seq1, seq2, msg=None, seq_type=None):\n        \"\"\"An equality assertion for ordered sequences (like lists and tuples).\n\n        For the purposes of this function, a valid ordered sequence type is one\n        which can be indexed, has a length, and has an equality operator.\n\n        Args:\n            seq1: The first sequence to compare.\n            seq2: The second sequence to compare.\n            seq_type: The expected datatype of the sequences, or None if no\n                    datatype should be enforced.\n            msg: Optional message to use on failure instead of a list of\n                    differences.\n        \"\"\"\n        if seq_type is not None:\n            seq_type_name = seq_type.__name__\n            if not isinstance(seq1, seq_type):\n                raise self.failureException('First sequence is not a %s: %s'\n                                        % (seq_type_name, safe_repr(seq1)))\n            if not isinstance(seq2, seq_type):\n                raise self.failureException('Second sequence is not a %s: %s'\n                                        % (seq_type_name, safe_repr(seq2)))\n        else:\n            seq_type_name = \"sequence\"\n\n        differing = None\n        try:\n            len1 = len(seq1)\n        except (TypeError, NotImplementedError):\n            differing = 'First %s has no length.    Non-sequence?' % (\n                    seq_type_name)\n\n        if differing is None:\n            try:\n                len2 = len(seq2)\n            except (TypeError, NotImplementedError):\n                differing = 'Second %s has no length.    Non-sequence?' % (\n                        seq_type_name)\n\n        if differing is None:\n            if seq1 == seq2:\n                return\n\n            seq1_repr = safe_repr(seq1)\n            seq2_repr = safe_repr(seq2)\n            if len(seq1_repr) > 30:\n                seq1_repr = seq1_repr[:30] + '...'\n            if len(seq2_repr) > 30:\n                seq2_repr = seq2_repr[:30] + '...'\n            elements = (seq_type_name.capitalize(), seq1_repr, seq2_repr)\n            differing = '%ss differ: %s != %s\\n' % elements\n\n            for i in range(min(len1, len2)):\n                try:\n                    item1 = seq1[i]\n                except (TypeError, IndexError, NotImplementedError):\n                    differing += ('\\nUnable to index element %d of first %s\\n' %\n                                 (i, seq_type_name))\n                    break\n\n                try:\n                    item2 = seq2[i]\n                except (TypeError, IndexError, NotImplementedError):\n                    differing += ('\\nUnable to index element %d of second %s\\n' %\n                                 (i, seq_type_name))\n                    break\n\n                if item1 != item2:\n                    differing += ('\\nFirst differing element %d:\\n%s\\n%s\\n' %\n                                 (i, item1, item2))\n                    break\n            else:\n                if (len1 == len2 and seq_type is None and\n                    type(seq1) != type(seq2)):\n                    # The sequences are the same, but have differing types.\n                    return\n\n            if len1 > len2:\n                differing += ('\\nFirst %s contains %d additional '\n                             'elements.\\n' % (seq_type_name, len1 - len2))\n                try:\n                    differing += ('First extra element %d:\\n%s\\n' %\n                                  (len2, seq1[len2]))\n                except (TypeError, IndexError, NotImplementedError):\n                    differing += ('Unable to index element %d '\n                                  'of first %s\\n' % (len2, seq_type_name))\n            elif len1 < len2:\n                differing += ('\\nSecond %s contains %d additional '\n                             'elements.\\n' % (seq_type_name, len2 - len1))\n                try:\n                    differing += ('First extra element %d:\\n%s\\n' %\n                                  (len1, seq2[len1]))\n                except (TypeError, IndexError, NotImplementedError):\n                    differing += ('Unable to index element %d '\n                                  'of second %s\\n' % (len1, seq_type_name))\n        standardMsg = differing\n        diffMsg = '\\n' + '\\n'.join(\n            difflib.ndiff(pprint.pformat(seq1).splitlines(),\n                          pprint.pformat(seq2).splitlines()))\n\n        standardMsg = self._truncateMessage(standardMsg, diffMsg)\n        msg = self._formatMessage(msg, standardMsg)\n        self.fail(msg)\n\n    def _truncateMessage(self, message, diff):\n        max_diff = self.maxDiff\n        if max_diff is None or len(diff) <= max_diff:\n            return message + diff\n        return message + (DIFF_OMITTED % len(diff))\n\n    def assertListEqual(self, list1, list2, msg=None):\n        \"\"\"A list-specific equality assertion.\n\n        Args:\n            list1: The first list to compare.\n            list2: The second list to compare.\n            msg: Optional message to use on failure instead of a list of\n                    differences.\n\n        \"\"\"\n        self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n\n    def assertTupleEqual(self, tuple1, tuple2, msg=None):\n        \"\"\"A tuple-specific equality assertion.\n\n        Args:\n            tuple1: The first tuple to compare.\n            tuple2: The second tuple to compare.\n            msg: Optional message to use on failure instead of a list of\n                    differences.\n        \"\"\"\n        self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n\n    def assertSetEqual(self, set1, set2, msg=None):\n        \"\"\"A set-specific equality assertion.\n\n        Args:\n            set1: The first set to compare.\n            set2: The second set to compare.\n            msg: Optional message to use on failure instead of a list of\n                    differences.\n\n        assertSetEqual uses ducktyping to support different types of sets, and\n        is optimized for sets specifically (parameters must support a\n        difference method).\n        \"\"\"\n        try:\n            difference1 = set1.difference(set2)\n        except TypeError as e:\n            self.fail('invalid type when attempting set difference: %s' % e)\n        except AttributeError as e:\n            self.fail('first argument does not support set difference: %s' % e)\n\n        try:\n            difference2 = set2.difference(set1)\n        except TypeError as e:\n            self.fail('invalid type when attempting set difference: %s' % e)\n        except AttributeError as e:\n            self.fail('second argument does not support set difference: %s' % e)\n\n        if not (difference1 or difference2):\n            return\n\n        lines = []\n        if difference1:\n            lines.append('Items in the first set but not the second:')\n            for item in difference1:\n                lines.append(repr(item))\n        if difference2:\n            lines.append('Items in the second set but not the first:')\n            for item in difference2:\n                lines.append(repr(item))\n\n        standardMsg = '\\n'.join(lines)\n        self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertIn(self, member, container, msg=None):\n        \"\"\"Just like self.assertTrue(a in b), but with a nicer default message.\"\"\"\n        if member not in container:\n            standardMsg = '%s not found in %s' % (safe_repr(member),\n                                                  safe_repr(container))\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertNotIn(self, member, container, msg=None):\n        \"\"\"Just like self.assertTrue(a not in b), but with a nicer default message.\"\"\"\n        if member in container:\n            standardMsg = '%s unexpectedly found in %s' % (safe_repr(member),\n                                                        safe_repr(container))\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertIs(self, expr1, expr2, msg=None):\n        \"\"\"Just like self.assertTrue(a is b), but with a nicer default message.\"\"\"\n        if expr1 is not expr2:\n            standardMsg = '%s is not %s' % (safe_repr(expr1),\n                                             safe_repr(expr2))\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertIsNot(self, expr1, expr2, msg=None):\n        \"\"\"Just like self.assertTrue(a is not b), but with a nicer default message.\"\"\"\n        if expr1 is expr2:\n            standardMsg = 'unexpectedly identical: %s' % (safe_repr(expr1),)\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertDictEqual(self, d1, d2, msg=None):\n        self.assertIsInstance(d1, dict, 'First argument is not a dictionary')\n        self.assertIsInstance(d2, dict, 'Second argument is not a dictionary')\n\n        if d1 != d2:\n            standardMsg = '%s != %s' % (safe_repr(d1, True), safe_repr(d2, True))\n            diff = ('\\n' + '\\n'.join(difflib.ndiff(\n                           pprint.pformat(d1).splitlines(),\n                           pprint.pformat(d2).splitlines())))\n            standardMsg = self._truncateMessage(standardMsg, diff)\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertDictContainsSubset(self, subset, dictionary, msg=None):\n        \"\"\"Checks whether dictionary is a superset of subset.\"\"\"\n        warnings.warn('assertDictContainsSubset is deprecated',\n                      DeprecationWarning)\n        missing = []\n        mismatched = []\n        for key, value in subset.items():\n            if key not in dictionary:\n                missing.append(key)\n            elif value != dictionary[key]:\n                mismatched.append('%s, expected: %s, actual: %s' %\n                                  (safe_repr(key), safe_repr(value),\n                                   safe_repr(dictionary[key])))\n\n        if not (missing or mismatched):\n            return\n\n        standardMsg = ''\n        if missing:\n            standardMsg = 'Missing: %s' % ','.join(safe_repr(m) for m in\n                                                    missing)\n        if mismatched:\n            if standardMsg:\n                standardMsg += '; '\n            standardMsg += 'Mismatched values: %s' % ','.join(mismatched)\n\n        self.fail(self._formatMessage(msg, standardMsg))\n\n\n    def assertCountEqual(self, first, second, msg=None):\n        \"\"\"An unordered sequence comparison asserting that the same elements,\n        regardless of order.  If the same element occurs more than once,\n        it verifies that the elements occur the same number of times.\n\n            self.assertEqual(Counter(list(first)),\n                             Counter(list(second)))\n\n         Example:\n            - [0, 1, 1] and [1, 0, 1] compare equal.\n            - [0, 0, 1] and [0, 1] compare unequal.\n\n        \"\"\"\n        first_seq, second_seq = list(first), list(second)\n        try:\n            first = collections.Counter(first_seq)\n            second = collections.Counter(second_seq)\n        except TypeError:\n            # Handle case with unhashable elements\n            differences = _count_diff_all_purpose(first_seq, second_seq)\n        else:\n            if first == second:\n                return\n            differences = _count_diff_hashable(first_seq, second_seq)\n\n        if differences:\n            standardMsg = 'Element counts were not equal:\\n'\n            lines = ['First has %d, Second has %d:  %r' % diff for diff in differences]\n            diffMsg = '\\n'.join(lines)\n            standardMsg = self._truncateMessage(standardMsg, diffMsg)\n            msg = self._formatMessage(msg, standardMsg)\n            self.fail(msg)\n\n    def assertMultiLineEqual(self, first, second, msg=None):\n        \"\"\"Assert that two multi-line strings are equal.\"\"\"\n        self.assertIsInstance(first, str, 'First argument is not a string')\n        self.assertIsInstance(second, str, 'Second argument is not a string')\n\n        if first != second:\n            # don't use difflib if the strings are too long\n            if (len(first) > self._diffThreshold or\n                len(second) > self._diffThreshold):\n                self._baseAssertEqual(first, second, msg)\n            firstlines = first.splitlines(keepends=True)\n            secondlines = second.splitlines(keepends=True)\n            if len(firstlines) == 1 and first.strip('\\r\\n') == first:\n                firstlines = [first + '\\n']\n                secondlines = [second + '\\n']\n            standardMsg = '%s != %s' % (safe_repr(first, True),\n                                        safe_repr(second, True))\n            diff = '\\n' + ''.join(difflib.ndiff(firstlines, secondlines))\n            standardMsg = self._truncateMessage(standardMsg, diff)\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertLess(self, a, b, msg=None):\n        \"\"\"Just like self.assertTrue(a < b), but with a nicer default message.\"\"\"\n        if not a < b:\n            standardMsg = '%s not less than %s' % (safe_repr(a), safe_repr(b))\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertLessEqual(self, a, b, msg=None):\n        \"\"\"Just like self.assertTrue(a <= b), but with a nicer default message.\"\"\"\n        if not a <= b:\n            standardMsg = '%s not less than or equal to %s' % (safe_repr(a), safe_repr(b))\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertGreater(self, a, b, msg=None):\n        \"\"\"Just like self.assertTrue(a > b), but with a nicer default message.\"\"\"\n        if not a > b:\n            standardMsg = '%s not greater than %s' % (safe_repr(a), safe_repr(b))\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertGreaterEqual(self, a, b, msg=None):\n        \"\"\"Just like self.assertTrue(a >= b), but with a nicer default message.\"\"\"\n        if not a >= b:\n            standardMsg = '%s not greater than or equal to %s' % (safe_repr(a), safe_repr(b))\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertIsNone(self, obj, msg=None):\n        \"\"\"Same as self.assertTrue(obj is None), with a nicer default message.\"\"\"\n        if obj is not None:\n            standardMsg = '%s is not None' % (safe_repr(obj),)\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertIsNotNone(self, obj, msg=None):\n        \"\"\"Included for symmetry with assertIsNone.\"\"\"\n        if obj is None:\n            standardMsg = 'unexpectedly None'\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertIsInstance(self, obj, cls, msg=None):\n        \"\"\"Same as self.assertTrue(isinstance(obj, cls)), with a nicer\n        default message.\"\"\"\n        if not isinstance(obj, cls):\n            standardMsg = '%s is not an instance of %r' % (safe_repr(obj), cls)\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertNotIsInstance(self, obj, cls, msg=None):\n        \"\"\"Included for symmetry with assertIsInstance.\"\"\"\n        if isinstance(obj, cls):\n            standardMsg = '%s is an instance of %r' % (safe_repr(obj), cls)\n            self.fail(self._formatMessage(msg, standardMsg))\n\n    def assertRaisesRegex(self, expected_exception, expected_regex,\n                          callable_obj=None, *args, **kwargs):\n        \"\"\"Asserts that the message in a raised exception matches a regex.\n\n        Args:\n            expected_exception: Exception class expected to be raised.\n            expected_regex: Regex (re pattern object or string) expected\n                    to be found in error message.\n            callable_obj: Function to be called.\n            msg: Optional message used in case of failure. Can only be used\n                    when assertRaisesRegex is used as a context manager.\n            args: Extra args.\n            kwargs: Extra kwargs.\n        \"\"\"\n        context = _AssertRaisesContext(expected_exception, self, callable_obj,\n                                       expected_regex)\n\n        return context.handle('assertRaisesRegex', callable_obj, args, kwargs)\n\n    def assertWarnsRegex(self, expected_warning, expected_regex,\n                         callable_obj=None, *args, **kwargs):\n        \"\"\"Asserts that the message in a triggered warning matches a regexp.\n        Basic functioning is similar to assertWarns() with the addition\n        that only warnings whose messages also match the regular expression\n        are considered successful matches.\n\n        Args:\n            expected_warning: Warning class expected to be triggered.\n            expected_regex: Regex (re pattern object or string) expected\n                    to be found in error message.\n            callable_obj: Function to be called.\n            msg: Optional message used in case of failure. Can only be used\n                    when assertWarnsRegex is used as a context manager.\n            args: Extra args.\n            kwargs: Extra kwargs.\n        \"\"\"\n        context = _AssertWarnsContext(expected_warning, self, callable_obj,\n                                      expected_regex)\n        return context.handle('assertWarnsRegex', callable_obj, args, kwargs)\n\n    def assertRegex(self, text, expected_regex, msg=None):\n        \"\"\"Fail the test unless the text matches the regular expression.\"\"\"\n        if isinstance(expected_regex, (str, bytes)):\n            assert expected_regex, \"expected_regex must not be empty.\"\n            expected_regex = re.compile(expected_regex)\n        if not expected_regex.search(text):\n            msg = msg or \"Regex didn't match\"\n            msg = '%s: %r not found in %r' % (msg, expected_regex.pattern, text)\n            raise self.failureException(msg)\n\n    def assertNotRegex(self, text, unexpected_regex, msg=None):\n        \"\"\"Fail the test if the text matches the regular expression.\"\"\"\n        if isinstance(unexpected_regex, (str, bytes)):\n            unexpected_regex = re.compile(unexpected_regex)\n        match = unexpected_regex.search(text)\n        if match:\n            msg = msg or \"Regex matched\"\n            msg = '%s: %r matches %r in %r' % (msg,\n                                               text[match.start():match.end()],\n                                               unexpected_regex.pattern,\n                                               text)\n            raise self.failureException(msg)\n\n\n    def _deprecate(original_func):\n        def deprecated_func(*args, **kwargs):\n            warnings.warn(\n                'Please use {0} instead.'.format(original_func.__name__),\n                DeprecationWarning, 2)\n            return original_func(*args, **kwargs)\n        return deprecated_func\n\n    # see #9424\n    failUnlessEqual = assertEquals = _deprecate(assertEqual)\n    failIfEqual = assertNotEquals = _deprecate(assertNotEqual)\n    failUnlessAlmostEqual = assertAlmostEquals = _deprecate(assertAlmostEqual)\n    failIfAlmostEqual = assertNotAlmostEquals = _deprecate(assertNotAlmostEqual)\n    failUnless = assert_ = _deprecate(assertTrue)\n    failUnlessRaises = _deprecate(assertRaises)\n    failIf = _deprecate(assertFalse)\n    assertRaisesRegexp = _deprecate(assertRaisesRegex)\n    assertRegexpMatches = _deprecate(assertRegex)\n\n\n\nclass FunctionTestCase(TestCase):\n    \"\"\"A test case that wraps a test function.\n\n    This is useful for slipping pre-existing test functions into the\n    unittest framework. Optionally, set-up and tidy-up functions can be\n    supplied. As with TestCase, the tidy-up ('tearDown') function will\n    always be called if the set-up ('setUp') function ran successfully.\n    \"\"\"\n\n    def __init__(self, testFunc, setUp=None, tearDown=None, description=None):\n        super(FunctionTestCase, self).__init__()\n        self._setUpFunc = setUp\n        self._tearDownFunc = tearDown\n        self._testFunc = testFunc\n        self._description = description\n\n    def setUp(self):\n        if self._setUpFunc is not None:\n            self._setUpFunc()\n\n    def tearDown(self):\n        if self._tearDownFunc is not None:\n            self._tearDownFunc()\n\n    def runTest(self):\n        self._testFunc()\n\n    def id(self):\n        return self._testFunc.__name__\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n\n        return self._setUpFunc == other._setUpFunc and \\\n               self._tearDownFunc == other._tearDownFunc and \\\n               self._testFunc == other._testFunc and \\\n               self._description == other._description\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __hash__(self):\n        return hash((type(self), self._setUpFunc, self._tearDownFunc,\n                     self._testFunc, self._description))\n\n    def __str__(self):\n        return \"%s (%s)\" % (strclass(self.__class__),\n                            self._testFunc.__name__)\n\n    def __repr__(self):\n        return \"<%s tec=%s>\" % (strclass(self.__class__),\n                                     self._testFunc)\n\n    def shortDescription(self):\n        if self._description is not None:\n            return self._description\n        doc = self._testFunc.__doc__\n        return doc and doc.split(\"\\n\")[0].strip() or None\n"], "javascript": [".js", "var $module=(function($B) {\n  return {\n    JSObject: $B.JSObject,\n    JSConstructor: $B.JSConstructor,\n    console: $B.JSObject(window.console),\n    py2js: function(src){return $B.py2js(src).to_js()},\n    pyobj2jsobj:function(obj){ return $B.pyobj2jsobj(obj)},\n    jsobj2pyobj:function(obj){ return $B.jsobj2pyobj(obj)}\n  }\n})(__BRYTHON__)\n"], "unittest.test.test_suite": [".py", "import unittest\n\nimport sys\nfrom .support import LoggingResult, TestEquality\n\n\n### Support code for Test_TestSuite\n################################################################\n\nclass Test(object):\n    class Foo(unittest.TestCase):\n        def test_1(self): pass\n        def test_2(self): pass\n        def test_3(self): pass\n        def runTest(self): pass\n\ndef _mk_TestSuite(*names):\n    return unittest.TestSuite(Test.Foo(n) for n in names)\n\n################################################################\n\n\nclass Test_TestSuite(unittest.TestCase, TestEquality):\n\n    ### Set up attributes needed by inherited tests\n    ################################################################\n\n    # Used by TestEquality.test_eq\n    eq_pairs = [(unittest.TestSuite(), unittest.TestSuite())\n               ,(unittest.TestSuite(), unittest.TestSuite([]))\n               ,(_mk_TestSuite('test_1'), _mk_TestSuite('test_1'))]\n\n    # Used by TestEquality.test_ne\n    ne_pairs = [(unittest.TestSuite(), _mk_TestSuite('test_1'))\n               ,(unittest.TestSuite([]), _mk_TestSuite('test_1'))\n               ,(_mk_TestSuite('test_1', 'test_2'), _mk_TestSuite('test_1', 'test_3'))\n               ,(_mk_TestSuite('test_1'), _mk_TestSuite('test_2'))]\n\n    ################################################################\n    ### /Set up attributes needed by inherited tests\n\n    ### Tests for TestSuite.__init__\n    ################################################################\n\n    # \"class TestSuite([tests])\"\n    #\n    # The tests iterable should be optional\n    def test_init__tests_optional(self):\n        suite = unittest.TestSuite()\n\n        self.assertEqual(suite.countTestCases(), 0)\n\n    # \"class TestSuite([tests])\"\n    # ...\n    # \"If tests is given, it must be an iterable of individual test cases\n    # or other test suites that will be used to build the suite initially\"\n    #\n    # TestSuite should deal with empty tests iterables by allowing the\n    # creation of an empty suite\n    def test_init__empty_tests(self):\n        suite = unittest.TestSuite([])\n\n        self.assertEqual(suite.countTestCases(), 0)\n\n    # \"class TestSuite([tests])\"\n    # ...\n    # \"If tests is given, it must be an iterable of individual test cases\n    # or other test suites that will be used to build the suite initially\"\n    #\n    # TestSuite should allow any iterable to provide tests\n    def test_init__tests_from_any_iterable(self):\n        def tests():\n            yield unittest.FunctionTestCase(lambda: None)\n            yield unittest.FunctionTestCase(lambda: None)\n\n        suite_1 = unittest.TestSuite(tests())\n        self.assertEqual(suite_1.countTestCases(), 2)\n\n        suite_2 = unittest.TestSuite(suite_1)\n        self.assertEqual(suite_2.countTestCases(), 2)\n\n        suite_3 = unittest.TestSuite(set(suite_1))\n        self.assertEqual(suite_3.countTestCases(), 2)\n\n    # \"class TestSuite([tests])\"\n    # ...\n    # \"If tests is given, it must be an iterable of individual test cases\n    # or other test suites that will be used to build the suite initially\"\n    #\n    # Does TestSuite() also allow other TestSuite() instances to be present\n    # in the tests iterable?\n    def test_init__TestSuite_instances_in_tests(self):\n        def tests():\n            ftc = unittest.FunctionTestCase(lambda: None)\n            yield unittest.TestSuite([ftc])\n            yield unittest.FunctionTestCase(lambda: None)\n\n        suite = unittest.TestSuite(tests())\n        self.assertEqual(suite.countTestCases(), 2)\n\n    ################################################################\n    ### /Tests for TestSuite.__init__\n\n    # Container types should support the iter protocol\n    def test_iter(self):\n        test1 = unittest.FunctionTestCase(lambda: None)\n        test2 = unittest.FunctionTestCase(lambda: None)\n        suite = unittest.TestSuite((test1, test2))\n\n        self.assertEqual(list(suite), [test1, test2])\n\n    # \"Return the number of tests represented by the this test object.\n    # ...this method is also implemented by the TestSuite class, which can\n    # return larger [greater than 1] values\"\n    #\n    # Presumably an empty TestSuite returns 0?\n    def test_countTestCases_zero_simple(self):\n        suite = unittest.TestSuite()\n\n        self.assertEqual(suite.countTestCases(), 0)\n\n    # \"Return the number of tests represented by the this test object.\n    # ...this method is also implemented by the TestSuite class, which can\n    # return larger [greater than 1] values\"\n    #\n    # Presumably an empty TestSuite (even if it contains other empty\n    # TestSuite instances) returns 0?\n    def test_countTestCases_zero_nested(self):\n        class Test1(unittest.TestCase):\n            def test(self):\n                pass\n\n        suite = unittest.TestSuite([unittest.TestSuite()])\n\n        self.assertEqual(suite.countTestCases(), 0)\n\n    # \"Return the number of tests represented by the this test object.\n    # ...this method is also implemented by the TestSuite class, which can\n    # return larger [greater than 1] values\"\n    def test_countTestCases_simple(self):\n        test1 = unittest.FunctionTestCase(lambda: None)\n        test2 = unittest.FunctionTestCase(lambda: None)\n        suite = unittest.TestSuite((test1, test2))\n\n        self.assertEqual(suite.countTestCases(), 2)\n\n    # \"Return the number of tests represented by the this test object.\n    # ...this method is also implemented by the TestSuite class, which can\n    # return larger [greater than 1] values\"\n    #\n    # Make sure this holds for nested TestSuite instances, too\n    def test_countTestCases_nested(self):\n        class Test1(unittest.TestCase):\n            def test1(self): pass\n            def test2(self): pass\n\n        test2 = unittest.FunctionTestCase(lambda: None)\n        test3 = unittest.FunctionTestCase(lambda: None)\n        child = unittest.TestSuite((Test1('test2'), test2))\n        parent = unittest.TestSuite((test3, child, Test1('test1')))\n\n        self.assertEqual(parent.countTestCases(), 4)\n\n    # \"Run the tests associated with this suite, collecting the result into\n    # the test result object passed as result.\"\n    #\n    # And if there are no tests? What then?\n    def test_run__empty_suite(self):\n        events = []\n        result = LoggingResult(events)\n\n        suite = unittest.TestSuite()\n\n        suite.run(result)\n\n        self.assertEqual(events, [])\n\n    # \"Note that unlike TestCase.run(), TestSuite.run() requires the\n    # \"result object to be passed in.\"\n    def test_run__requires_result(self):\n        suite = unittest.TestSuite()\n\n        try:\n            suite.run()\n        except TypeError:\n            pass\n        else:\n            self.fail(\"Failed to raise TypeError\")\n\n    # \"Run the tests associated with this suite, collecting the result into\n    # the test result object passed as result.\"\n    def test_run(self):\n        events = []\n        result = LoggingResult(events)\n\n        class LoggingCase(unittest.TestCase):\n            def run(self, result):\n                events.append('run %s' % self._testMethodName)\n\n            def test1(self): pass\n            def test2(self): pass\n\n        tests = [LoggingCase('test1'), LoggingCase('test2')]\n\n        unittest.TestSuite(tests).run(result)\n\n        self.assertEqual(events, ['run test1', 'run test2'])\n\n    # \"Add a TestCase ... to the suite\"\n    def test_addTest__TestCase(self):\n        class Foo(unittest.TestCase):\n            def test(self): pass\n\n        test = Foo('test')\n        suite = unittest.TestSuite()\n\n        suite.addTest(test)\n\n        self.assertEqual(suite.countTestCases(), 1)\n        self.assertEqual(list(suite), [test])\n\n    # \"Add a ... TestSuite to the suite\"\n    def test_addTest__TestSuite(self):\n        class Foo(unittest.TestCase):\n            def test(self): pass\n\n        suite_2 = unittest.TestSuite([Foo('test')])\n\n        suite = unittest.TestSuite()\n        suite.addTest(suite_2)\n\n        self.assertEqual(suite.countTestCases(), 1)\n        self.assertEqual(list(suite), [suite_2])\n\n    # \"Add all the tests from an iterable of TestCase and TestSuite\n    # instances to this test suite.\"\n    #\n    # \"This is equivalent to iterating over tests, calling addTest() for\n    # each element\"\n    def test_addTests(self):\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n\n        test_1 = Foo('test_1')\n        test_2 = Foo('test_2')\n        inner_suite = unittest.TestSuite([test_2])\n\n        def gen():\n            yield test_1\n            yield test_2\n            yield inner_suite\n\n        suite_1 = unittest.TestSuite()\n        suite_1.addTests(gen())\n\n        self.assertEqual(list(suite_1), list(gen()))\n\n        # \"This is equivalent to iterating over tests, calling addTest() for\n        # each element\"\n        suite_2 = unittest.TestSuite()\n        for t in gen():\n            suite_2.addTest(t)\n\n        self.assertEqual(suite_1, suite_2)\n\n    # \"Add all the tests from an iterable of TestCase and TestSuite\n    # instances to this test suite.\"\n    #\n    # What happens if it doesn't get an iterable?\n    def test_addTest__noniterable(self):\n        suite = unittest.TestSuite()\n\n        try:\n            suite.addTests(5)\n        except TypeError:\n            pass\n        else:\n            self.fail(\"Failed to raise TypeError\")\n\n    def test_addTest__noncallable(self):\n        suite = unittest.TestSuite()\n        self.assertRaises(TypeError, suite.addTest, 5)\n\n    def test_addTest__casesuiteclass(self):\n        suite = unittest.TestSuite()\n        self.assertRaises(TypeError, suite.addTest, Test_TestSuite)\n        self.assertRaises(TypeError, suite.addTest, unittest.TestSuite)\n\n    def test_addTests__string(self):\n        suite = unittest.TestSuite()\n        self.assertRaises(TypeError, suite.addTests, \"foo\")\n\n    def test_function_in_suite(self):\n        def f(_):\n            pass\n        suite = unittest.TestSuite()\n        suite.addTest(f)\n\n        # when the bug is fixed this line will not crash\n        suite.run(unittest.TestResult())\n\n\n\n    def test_basetestsuite(self):\n        class Test(unittest.TestCase):\n            wasSetUp = False\n            wasTornDown = False\n            @classmethod\n            def setUpClass(cls):\n                cls.wasSetUp = True\n            @classmethod\n            def tearDownClass(cls):\n                cls.wasTornDown = True\n            def testPass(self):\n                pass\n            def testFail(self):\n                fail\n        class Module(object):\n            wasSetUp = False\n            wasTornDown = False\n            @staticmethod\n            def setUpModule():\n                Module.wasSetUp = True\n            @staticmethod\n            def tearDownModule():\n                Module.wasTornDown = True\n\n        Test.__module__ = 'Module'\n        sys.modules['Module'] = Module\n        self.addCleanup(sys.modules.pop, 'Module')\n\n        suite = unittest.BaseTestSuite()\n        suite.addTests([Test('testPass'), Test('testFail')])\n        self.assertEqual(suite.countTestCases(), 2)\n\n        result = unittest.TestResult()\n        suite.run(result)\n        self.assertFalse(Module.wasSetUp)\n        self.assertFalse(Module.wasTornDown)\n        self.assertFalse(Test.wasSetUp)\n        self.assertFalse(Test.wasTornDown)\n        self.assertEqual(len(result.errors), 1)\n        self.assertEqual(len(result.failures), 0)\n        self.assertEqual(result.testsRun, 2)\n\n\n    def test_overriding_call(self):\n        class MySuite(unittest.TestSuite):\n            called = False\n            def __call__(self, *args, **kw):\n                self.called = True\n                unittest.TestSuite.__call__(self, *args, **kw)\n\n        suite = MySuite()\n        result = unittest.TestResult()\n        wrapper = unittest.TestSuite()\n        wrapper.addTest(suite)\n        wrapper(result)\n        self.assertTrue(suite.called)\n\n        # reusing results should be permitted even if abominable\n        self.assertFalse(result._testRunEntered)\n\n\n\nif __name__ == '__main__':\n    unittest.main()\n"], "ui.widget": [".py", "import __random as random\nfrom browser import doc\n\ndef getMousePosition(e):\n    if e is None:\n       e=win.event\n\n    if e.pageX or e.pageY:\n       return {'x': e.pageX, 'y': e.pageY}\n\n    if e.clientX or e.clientY:\n       _posx=e.clientX + doc.body.scrollLeft + doc.documentElement.scrollLeft;\n       _posy=e.clientY + doc.body.scrollTop + doc.documentElement.scrollTop;\n       return {'x': _posx, 'y': _posy}\n      \n    return {'x': 0, 'y': 0}\n\nclass Widget:\n  def __init__(self, element, type, id=None):\n      self._element=element\n\n      if id is None:\n         self._element.id='%s_%s' % (type, int(100000*random.random()))\n      else:\n         self._element.id=id\n\n  def get_id(self):\n      return self._element.id\n\n  def attach(self, element_id):\n      \"\"\" append this DOM component to DOM element element_id\"\"\"\n      #document[element_id] <= self._element   #this doesn't work :(\n      #doc is actually the global 'doc' not the one we imported from browser :(\n      doc[element_id] <= self._element\n\n  def show(self):\n      self._element.display='block'\n\n  def hide(self):\n      self._element.display='none'\n\nclass DraggableWidget(Widget):\n  def __init__(self, element, type, id=None):\n      Widget.__init__(self, element, type, id)\n\n      def drag(e):\n          self._element.style.top='%spx' % (e.clientY - self._deltaY)\n          self._element.style.left='%spx' % (e.clientX - self._deltaX)\n\n      def mouseDown(e):\n          self._element.style.position='absolute'\n          self._deltaX=e.clientX - self._element.offsetLeft\n          self._deltaY=e.clientY - self._element.offsetTop\n          doc.bind('mousemove', drag)\n\n      def mouseUp(e):\n          doc.unbind('mousemove')\n\n      self._element.bind('mousedown', mouseDown)\n      self._element.bind('mouseup', mouseUp)\n"], "crypto_js.rollups.sha512": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(a,m){var r={},f=r.lib={},g=function(){},l=f.Base={extend:function(a){g.prototype=this;var b=new g;a&&b.mixIn(a);b.hasOwnProperty(\"init\")||(b.init=function(){b.$super.init.apply(this,arguments)});b.init.prototype=b;b.$super=this;return b},create:function(){var a=this.extend();a.init.apply(a,arguments);return a},init:function(){},mixIn:function(a){for(var b in a)a.hasOwnProperty(b)&&(this[b]=a[b]);a.hasOwnProperty(\"toString\")&&(this.toString=a.toString)},clone:function(){return this.init.prototype.extend(this)}},\np=f.WordArray=l.extend({init:function(a,b){a=this.words=a||[];this.sigBytes=b!=m?b:4*a.length},toString:function(a){return(a||q).stringify(this)},concat:function(a){var b=this.words,d=a.words,c=this.sigBytes;a=a.sigBytes;this.clamp();if(c%4)for(var j=0;j<a;j++)b[c+j>>>2]|=(d[j>>>2]>>>24-8*(j%4)&255)<<24-8*((c+j)%4);else if(65535<d.length)for(j=0;j<a;j+=4)b[c+j>>>2]=d[j>>>2];else b.push.apply(b,d);this.sigBytes+=a;return this},clamp:function(){var n=this.words,b=this.sigBytes;n[b>>>2]&=4294967295<<\n32-8*(b%4);n.length=a.ceil(b/4)},clone:function(){var a=l.clone.call(this);a.words=this.words.slice(0);return a},random:function(n){for(var b=[],d=0;d<n;d+=4)b.push(4294967296*a.random()|0);return new p.init(b,n)}}),y=r.enc={},q=y.Hex={stringify:function(a){var b=a.words;a=a.sigBytes;for(var d=[],c=0;c<a;c++){var j=b[c>>>2]>>>24-8*(c%4)&255;d.push((j>>>4).toString(16));d.push((j&15).toString(16))}return d.join(\"\")},parse:function(a){for(var b=a.length,d=[],c=0;c<b;c+=2)d[c>>>3]|=parseInt(a.substr(c,\n2),16)<<24-4*(c%8);return new p.init(d,b/2)}},G=y.Latin1={stringify:function(a){var b=a.words;a=a.sigBytes;for(var d=[],c=0;c<a;c++)d.push(String.fromCharCode(b[c>>>2]>>>24-8*(c%4)&255));return d.join(\"\")},parse:function(a){for(var b=a.length,d=[],c=0;c<b;c++)d[c>>>2]|=(a.charCodeAt(c)&255)<<24-8*(c%4);return new p.init(d,b)}},fa=y.Utf8={stringify:function(a){try{return decodeURIComponent(escape(G.stringify(a)))}catch(b){throw Error(\"Malformed UTF-8 data\");}},parse:function(a){return G.parse(unescape(encodeURIComponent(a)))}},\nh=f.BufferedBlockAlgorithm=l.extend({reset:function(){this._data=new p.init;this._nDataBytes=0},_append:function(a){\"string\"==typeof a&&(a=fa.parse(a));this._data.concat(a);this._nDataBytes+=a.sigBytes},_process:function(n){var b=this._data,d=b.words,c=b.sigBytes,j=this.blockSize,l=c/(4*j),l=n?a.ceil(l):a.max((l|0)-this._minBufferSize,0);n=l*j;c=a.min(4*n,c);if(n){for(var h=0;h<n;h+=j)this._doProcessBlock(d,h);h=d.splice(0,n);b.sigBytes-=c}return new p.init(h,c)},clone:function(){var a=l.clone.call(this);\na._data=this._data.clone();return a},_minBufferSize:0});f.Hasher=h.extend({cfg:l.extend(),init:function(a){this.cfg=this.cfg.extend(a);this.reset()},reset:function(){h.reset.call(this);this._doReset()},update:function(a){this._append(a);this._process();return this},finalize:function(a){a&&this._append(a);return this._doFinalize()},blockSize:16,_createHelper:function(a){return function(b,d){return(new a.init(d)).finalize(b)}},_createHmacHelper:function(a){return function(b,d){return(new ga.HMAC.init(a,\nd)).finalize(b)}}});var ga=r.algo={};return r}(Math);\n(function(a){var m=CryptoJS,r=m.lib,f=r.Base,g=r.WordArray,m=m.x64={};m.Word=f.extend({init:function(a,p){this.high=a;this.low=p}});m.WordArray=f.extend({init:function(l,p){l=this.words=l||[];this.sigBytes=p!=a?p:8*l.length},toX32:function(){for(var a=this.words,p=a.length,f=[],q=0;q<p;q++){var G=a[q];f.push(G.high);f.push(G.low)}return g.create(f,this.sigBytes)},clone:function(){for(var a=f.clone.call(this),p=a.words=this.words.slice(0),g=p.length,q=0;q<g;q++)p[q]=p[q].clone();return a}})})();\n(function(){function a(){return g.create.apply(g,arguments)}for(var m=CryptoJS,r=m.lib.Hasher,f=m.x64,g=f.Word,l=f.WordArray,f=m.algo,p=[a(1116352408,3609767458),a(1899447441,602891725),a(3049323471,3964484399),a(3921009573,2173295548),a(961987163,4081628472),a(1508970993,3053834265),a(2453635748,2937671579),a(2870763221,3664609560),a(3624381080,2734883394),a(310598401,1164996542),a(607225278,1323610764),a(1426881987,3590304994),a(1925078388,4068182383),a(2162078206,991336113),a(2614888103,633803317),\na(3248222580,3479774868),a(3835390401,2666613458),a(4022224774,944711139),a(264347078,2341262773),a(604807628,2007800933),a(770255983,1495990901),a(1249150122,1856431235),a(1555081692,3175218132),a(1996064986,2198950837),a(2554220882,3999719339),a(2821834349,766784016),a(2952996808,2566594879),a(3210313671,3203337956),a(3336571891,1034457026),a(3584528711,2466948901),a(113926993,3758326383),a(338241895,168717936),a(666307205,1188179964),a(773529912,1546045734),a(1294757372,1522805485),a(1396182291,\n2643833823),a(1695183700,2343527390),a(1986661051,1014477480),a(2177026350,1206759142),a(2456956037,344077627),a(2730485921,1290863460),a(2820302411,3158454273),a(3259730800,3505952657),a(3345764771,106217008),a(3516065817,3606008344),a(3600352804,1432725776),a(4094571909,1467031594),a(275423344,851169720),a(430227734,3100823752),a(506948616,1363258195),a(659060556,3750685593),a(883997877,3785050280),a(958139571,3318307427),a(1322822218,3812723403),a(1537002063,2003034995),a(1747873779,3602036899),\na(1955562222,1575990012),a(2024104815,1125592928),a(2227730452,2716904306),a(2361852424,442776044),a(2428436474,593698344),a(2756734187,3733110249),a(3204031479,2999351573),a(3329325298,3815920427),a(3391569614,3928383900),a(3515267271,566280711),a(3940187606,3454069534),a(4118630271,4000239992),a(116418474,1914138554),a(174292421,2731055270),a(289380356,3203993006),a(460393269,320620315),a(685471733,587496836),a(852142971,1086792851),a(1017036298,365543100),a(1126000580,2618297676),a(1288033470,\n3409855158),a(1501505948,4234509866),a(1607167915,987167468),a(1816402316,1246189591)],y=[],q=0;80>q;q++)y[q]=a();f=f.SHA512=r.extend({_doReset:function(){this._hash=new l.init([new g.init(1779033703,4089235720),new g.init(3144134277,2227873595),new g.init(1013904242,4271175723),new g.init(2773480762,1595750129),new g.init(1359893119,2917565137),new g.init(2600822924,725511199),new g.init(528734635,4215389547),new g.init(1541459225,327033209)])},_doProcessBlock:function(a,f){for(var h=this._hash.words,\ng=h[0],n=h[1],b=h[2],d=h[3],c=h[4],j=h[5],l=h[6],h=h[7],q=g.high,m=g.low,r=n.high,N=n.low,Z=b.high,O=b.low,$=d.high,P=d.low,aa=c.high,Q=c.low,ba=j.high,R=j.low,ca=l.high,S=l.low,da=h.high,T=h.low,v=q,s=m,H=r,E=N,I=Z,F=O,W=$,J=P,w=aa,t=Q,U=ba,K=R,V=ca,L=S,X=da,M=T,x=0;80>x;x++){var B=y[x];if(16>x)var u=B.high=a[f+2*x]|0,e=B.low=a[f+2*x+1]|0;else{var u=y[x-15],e=u.high,z=u.low,u=(e>>>1|z<<31)^(e>>>8|z<<24)^e>>>7,z=(z>>>1|e<<31)^(z>>>8|e<<24)^(z>>>7|e<<25),D=y[x-2],e=D.high,k=D.low,D=(e>>>19|k<<13)^\n(e<<3|k>>>29)^e>>>6,k=(k>>>19|e<<13)^(k<<3|e>>>29)^(k>>>6|e<<26),e=y[x-7],Y=e.high,C=y[x-16],A=C.high,C=C.low,e=z+e.low,u=u+Y+(e>>>0<z>>>0?1:0),e=e+k,u=u+D+(e>>>0<k>>>0?1:0),e=e+C,u=u+A+(e>>>0<C>>>0?1:0);B.high=u;B.low=e}var Y=w&U^~w&V,C=t&K^~t&L,B=v&H^v&I^H&I,ha=s&E^s&F^E&F,z=(v>>>28|s<<4)^(v<<30|s>>>2)^(v<<25|s>>>7),D=(s>>>28|v<<4)^(s<<30|v>>>2)^(s<<25|v>>>7),k=p[x],ia=k.high,ea=k.low,k=M+((t>>>14|w<<18)^(t>>>18|w<<14)^(t<<23|w>>>9)),A=X+((w>>>14|t<<18)^(w>>>18|t<<14)^(w<<23|t>>>9))+(k>>>0<M>>>\n0?1:0),k=k+C,A=A+Y+(k>>>0<C>>>0?1:0),k=k+ea,A=A+ia+(k>>>0<ea>>>0?1:0),k=k+e,A=A+u+(k>>>0<e>>>0?1:0),e=D+ha,B=z+B+(e>>>0<D>>>0?1:0),X=V,M=L,V=U,L=K,U=w,K=t,t=J+k|0,w=W+A+(t>>>0<J>>>0?1:0)|0,W=I,J=F,I=H,F=E,H=v,E=s,s=k+e|0,v=A+B+(s>>>0<k>>>0?1:0)|0}m=g.low=m+s;g.high=q+v+(m>>>0<s>>>0?1:0);N=n.low=N+E;n.high=r+H+(N>>>0<E>>>0?1:0);O=b.low=O+F;b.high=Z+I+(O>>>0<F>>>0?1:0);P=d.low=P+J;d.high=$+W+(P>>>0<J>>>0?1:0);Q=c.low=Q+t;c.high=aa+w+(Q>>>0<t>>>0?1:0);R=j.low=R+K;j.high=ba+U+(R>>>0<K>>>0?1:0);S=l.low=\nS+L;l.high=ca+V+(S>>>0<L>>>0?1:0);T=h.low=T+M;h.high=da+X+(T>>>0<M>>>0?1:0)},_doFinalize:function(){var a=this._data,f=a.words,h=8*this._nDataBytes,g=8*a.sigBytes;f[g>>>5]|=128<<24-g%32;f[(g+128>>>10<<5)+30]=Math.floor(h/4294967296);f[(g+128>>>10<<5)+31]=h;a.sigBytes=4*f.length;this._process();return this._hash.toX32()},clone:function(){var a=r.clone.call(this);a._hash=this._hash.clone();return a},blockSize:32});m.SHA512=r._createHelper(f);m.HmacSHA512=r._createHmacHelper(f)})();\n"], "unittest.suite": [".py", "\"\"\"TestSuite\"\"\"\n\nimport sys\n\nfrom . import case\nfrom . import util\n\n__unittest = True\n\n\ndef _call_if_exists(parent, attr):\n    func = getattr(parent, attr, lambda: None)\n    func()\n\n\nclass BaseTestSuite(object):\n    \"\"\"A simple test suite that doesn't provide class or module shared fixtures.\n    \"\"\"\n    def __init__(self, tests=()):\n        self._tests = []\n        self.addTests(tests)\n\n    def __repr__(self):\n        return \"<%s tests=%s>\" % (util.strclass(self.__class__), list(self))\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return list(self) == list(other)\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __iter__(self):\n        return iter(self._tests)\n\n    def countTestCases(self):\n        cases = 0\n        for test in self:\n            cases += test.countTestCases()\n        return cases\n\n    def addTest(self, test):\n        # sanity checks\n        if not callable(test):\n            raise TypeError(\"{} is not callable\".format(repr(test)))\n        if isinstance(test, type) and issubclass(test,\n                                                 (case.TestCase, TestSuite)):\n            raise TypeError(\"TestCases and TestSuites must be instantiated \"\n                            \"before passing them to addTest()\")\n        self._tests.append(test)\n\n    def addTests(self, tests):\n        if isinstance(tests, str):\n            raise TypeError(\"tests must be an iterable of tests, not a string\")\n        for test in tests:\n            self.addTest(test)\n\n    def run(self, result):\n        for test in self:\n            if result.shouldStop:\n                break\n            test(result)\n        return result\n\n    def __call__(self, *args, **kwds):\n        return self.run(*args, **kwds)\n\n    def debug(self):\n        \"\"\"Run the tests without collecting errors in a TestResult\"\"\"\n        for test in self:\n            test.debug()\n\n\nclass TestSuite(BaseTestSuite):\n    \"\"\"A test suite is a composite test consisting of a number of TestCases.\n\n    For use, create an instance of TestSuite, then add test case instances.\n    When all tests have been added, the suite can be passed to a test\n    runner, such as TextTestRunner. It will run the individual test cases\n    in the order in which they were added, aggregating the results. When\n    subclassing, do not forget to call the base class constructor.\n    \"\"\"\n\n    def run(self, result, debug=False):\n        topLevel = False\n        if getattr(result, '_testRunEntered', False) is False:\n            result._testRunEntered = topLevel = True\n\n        for test in self:\n            if result.shouldStop:\n                break\n\n            if _isnotsuite(test):\n                self._tearDownPreviousClass(test, result)\n                self._handleModuleFixture(test, result)\n                self._handleClassSetUp(test, result)\n                result._previousTestClass = test.__class__\n\n                if (getattr(test.__class__, '_classSetupFailed', False) or\n                    getattr(result, '_moduleSetUpFailed', False)):\n                    continue\n\n            if not debug:\n                test(result)\n            else:\n                test.debug()\n\n        if topLevel:\n            self._tearDownPreviousClass(None, result)\n            self._handleModuleTearDown(result)\n            result._testRunEntered = False\n        return result\n\n    def debug(self):\n        \"\"\"Run the tests without collecting errors in a TestResult\"\"\"\n        debug = _DebugResult()\n        self.run(debug, True)\n\n    ################################\n\n    def _handleClassSetUp(self, test, result):\n        previousClass = getattr(result, '_previousTestClass', None)\n        currentClass = test.__class__\n        if currentClass == previousClass:\n            return\n        if result._moduleSetUpFailed:\n            return\n        if getattr(currentClass, \"__unittest_skip__\", False):\n            return\n\n        try:\n            currentClass._classSetupFailed = False\n        except TypeError:\n            # test may actually be a function\n            # so its class will be a builtin-type\n            pass\n\n        setUpClass = getattr(currentClass, 'setUpClass', None)\n        if setUpClass is not None:\n            _call_if_exists(result, '_setupStdout')\n            try:\n                setUpClass()\n            except Exception as e:\n                if isinstance(result, _DebugResult):\n                    raise\n                currentClass._classSetupFailed = True\n                className = util.strclass(currentClass)\n                errorName = 'setUpClass (%s)' % className\n                self._addClassOrModuleLevelException(result, e, errorName)\n            finally:\n                _call_if_exists(result, '_restoreStdout')\n\n    def _get_previous_module(self, result):\n        previousModule = None\n        previousClass = getattr(result, '_previousTestClass', None)\n        if previousClass is not None:\n            previousModule = previousClass.__module__\n        return previousModule\n\n\n    def _handleModuleFixture(self, test, result):\n        previousModule = self._get_previous_module(result)\n        currentModule = test.__class__.__module__\n        if currentModule == previousModule:\n            return\n\n        self._handleModuleTearDown(result)\n\n\n        result._moduleSetUpFailed = False\n        try:\n            module = sys.modules[currentModule]\n        except KeyError:\n            return\n        setUpModule = getattr(module, 'setUpModule', None)\n        if setUpModule is not None:\n            _call_if_exists(result, '_setupStdout')\n            try:\n                setUpModule()\n            except Exception as e:\n                if isinstance(result, _DebugResult):\n                    raise\n                result._moduleSetUpFailed = True\n                errorName = 'setUpModule (%s)' % currentModule\n                self._addClassOrModuleLevelException(result, e, errorName)\n            finally:\n                _call_if_exists(result, '_restoreStdout')\n\n    def _addClassOrModuleLevelException(self, result, exception, errorName):\n        error = _ErrorHolder(errorName)\n        addSkip = getattr(result, 'addSkip', None)\n        if addSkip is not None and isinstance(exception, case.SkipTest):\n            addSkip(error, str(exception))\n        else:\n            result.addError(error, sys.exc_info())\n\n    def _handleModuleTearDown(self, result):\n        previousModule = self._get_previous_module(result)\n        if previousModule is None:\n            return\n        if result._moduleSetUpFailed:\n            return\n\n        try:\n            module = sys.modules[previousModule]\n        except KeyError:\n            return\n\n        tearDownModule = getattr(module, 'tearDownModule', None)\n        if tearDownModule is not None:\n            _call_if_exists(result, '_setupStdout')\n            try:\n                tearDownModule()\n            except Exception as e:\n                if isinstance(result, _DebugResult):\n                    raise\n                errorName = 'tearDownModule (%s)' % previousModule\n                self._addClassOrModuleLevelException(result, e, errorName)\n            finally:\n                _call_if_exists(result, '_restoreStdout')\n\n    def _tearDownPreviousClass(self, test, result):\n        previousClass = getattr(result, '_previousTestClass', None)\n        currentClass = test.__class__\n        if currentClass == previousClass:\n            return\n        if getattr(previousClass, '_classSetupFailed', False):\n            return\n        if getattr(result, '_moduleSetUpFailed', False):\n            return\n        if getattr(previousClass, \"__unittest_skip__\", False):\n            return\n\n        tearDownClass = getattr(previousClass, 'tearDownClass', None)\n        if tearDownClass is not None:\n            _call_if_exists(result, '_setupStdout')\n            try:\n                tearDownClass()\n            except Exception as e:\n                if isinstance(result, _DebugResult):\n                    raise\n                className = util.strclass(previousClass)\n                errorName = 'tearDownClass (%s)' % className\n                self._addClassOrModuleLevelException(result, e, errorName)\n            finally:\n                _call_if_exists(result, '_restoreStdout')\n\n\nclass _ErrorHolder(object):\n    \"\"\"\n    Placeholder for a TestCase inside a result. As far as a TestResult\n    is concerned, this looks exactly like a unit test. Used to insert\n    arbitrary errors into a test suite run.\n    \"\"\"\n    # Inspired by the ErrorHolder from Twisted:\n    # http://twistedmatrix.com/trac/browser/trunk/twisted/trial/runner.py\n\n    # attribute used by TestResult._exc_info_to_string\n    failureException = None\n\n    def __init__(self, description):\n        self.description = description\n\n    def id(self):\n        return self.description\n\n    def shortDescription(self):\n        return None\n\n    def __repr__(self):\n        return \"<ErrorHolder description=%r>\" % (self.description,)\n\n    def __str__(self):\n        return self.id()\n\n    def run(self, result):\n        # could call result.addError(...) - but this test-like object\n        # shouldn't be run anyway\n        pass\n\n    def __call__(self, result):\n        return self.run(result)\n\n    def countTestCases(self):\n        return 0\n\ndef _isnotsuite(test):\n    \"A crude way to tell apart testcases and suites with duck-typing\"\n    try:\n        iter(test)\n    except TypeError:\n        return True\n    return False\n\n\nclass _DebugResult(object):\n    \"Used by the TestSuite to hold previous class when running in debug.\"\n    _previousTestClass = None\n    _moduleSetUpFailed = False\n    shouldStop = False\n"], "inspect": [".py", "\"\"\"Get useful information from live Python objects.\n\nThis module encapsulates the interface provided by the internal special\nattributes (co_*, im_*, tb_*, etc.) in a friendlier fashion.\nIt also provides some help for examining source code and class layout.\n\nHere are some of the useful functions provided by this module:\n\n    ismodule(), isclass(), ismethod(), isfunction(), isgeneratorfunction(),\n        isgenerator(), istraceback(), isframe(), iscode(), isbuiltin(),\n        isroutine() - check object types\n    getmembers() - get members of an object that satisfy a given condition\n\n    getfile(), getsourcefile(), getsource() - find an object's source code\n    getdoc(), getcomments() - get documentation on an object\n    getmodule() - determine the module that an object came from\n    getclasstree() - arrange classes so as to represent their hierarchy\n\n    getargspec(), getargvalues(), getcallargs() - get info about function arguments\n    getfullargspec() - same, with support for Python-3000 features\n    formatargspec(), formatargvalues() - format an argument spec\n    getouterframes(), getinnerframes() - get info about frames\n    currentframe() - get the current stack frame\n    stack(), trace() - get info about frames on the stack or in a traceback\n\n    signature() - get a Signature object for the callable\n\"\"\"\n\n# This module is in the public domain.  No warranties.\n\n__author__ = ('Ka-Ping Yee <ping@lfw.org>',\n              'Yury Selivanov <yselivanov@sprymix.com>')\n\nimport imp\nimport importlib.machinery\nimport itertools\nimport linecache\nimport os\nimport re\nimport sys\nimport tokenize\nimport types\nimport warnings\nimport functools\nimport builtins\nfrom operator import attrgetter\nfrom collections import namedtuple, OrderedDict\n\n# Create constants for the compiler flags in Include/code.h\n# We try to get them from dis to avoid duplication, but fall\n# back to hardcoding so the dependency is optional\ntry:\n    from dis import COMPILER_FLAG_NAMES as _flag_names\nexcept ImportError:\n    CO_OPTIMIZED, CO_NEWLOCALS = 0x1, 0x2\n    CO_VARARGS, CO_VARKEYWORDS = 0x4, 0x8\n    CO_NESTED, CO_GENERATOR, CO_NOFREE = 0x10, 0x20, 0x40\nelse:\n    mod_dict = globals()\n    for k, v in _flag_names.items():\n        mod_dict[\"CO_\" + v] = k\n\n# See Include/object.h\nTPFLAGS_IS_ABSTRACT = 1 << 20\n\n# ----------------------------------------------------------- type-checking\ndef ismodule(object):\n    \"\"\"Return true if the object is a module.\n\n    Module objects provide these attributes:\n        __cached__      pathname to byte compiled file\n        __doc__         documentation string\n        __file__        filename (missing for built-in modules)\"\"\"\n    return isinstance(object, types.ModuleType)\n\ndef isclass(object):\n    \"\"\"Return true if the object is a class.\n\n    Class objects provide these attributes:\n        __doc__         documentation string\n        __module__      name of module in which this class was defined\"\"\"\n    return isinstance(object, type)\n\ndef ismethod(object):\n    \"\"\"Return true if the object is an instance method.\n\n    Instance method objects provide these attributes:\n        __doc__         documentation string\n        __name__        name with which this method was defined\n        __func__        function object containing implementation of method\n        __self__        instance to which this method is bound\"\"\"\n    return isinstance(object, types.MethodType)\n\ndef ismethoddescriptor(object):\n    \"\"\"Return true if the object is a method descriptor.\n\n    But not if ismethod() or isclass() or isfunction() are true.\n\n    This is new in Python 2.2, and, for example, is true of int.__add__.\n    An object passing this test has a __get__ attribute but not a __set__\n    attribute, but beyond that the set of attributes varies.  __name__ is\n    usually sensible, and __doc__ often is.\n\n    Methods implemented via descriptors that also pass one of the other\n    tests return false from the ismethoddescriptor() test, simply because\n    the other tests promise more -- you can, e.g., count on having the\n    __func__ attribute (etc) when an object passes ismethod().\"\"\"\n    if isclass(object) or ismethod(object) or isfunction(object):\n        # mutual exclusion\n        return False\n    tp = type(object)\n    return hasattr(tp, \"__get__\") and not hasattr(tp, \"__set__\")\n\ndef isdatadescriptor(object):\n    \"\"\"Return true if the object is a data descriptor.\n\n    Data descriptors have both a __get__ and a __set__ attribute.  Examples are\n    properties (defined in Python) and getsets and members (defined in C).\n    Typically, data descriptors will also have __name__ and __doc__ attributes\n    (properties, getsets, and members have both of these attributes), but this\n    is not guaranteed.\"\"\"\n    if isclass(object) or ismethod(object) or isfunction(object):\n        # mutual exclusion\n        return False\n    tp = type(object)\n    return hasattr(tp, \"__set__\") and hasattr(tp, \"__get__\")\n\nif hasattr(types, 'MemberDescriptorType'):\n    # CPython and equivalent\n    def ismemberdescriptor(object):\n        \"\"\"Return true if the object is a member descriptor.\n\n        Member descriptors are specialized descriptors defined in extension\n        modules.\"\"\"\n        return isinstance(object, types.MemberDescriptorType)\nelse:\n    # Other implementations\n    def ismemberdescriptor(object):\n        \"\"\"Return true if the object is a member descriptor.\n\n        Member descriptors are specialized descriptors defined in extension\n        modules.\"\"\"\n        return False\n\nif hasattr(types, 'GetSetDescriptorType'):\n    # CPython and equivalent\n    def isgetsetdescriptor(object):\n        \"\"\"Return true if the object is a getset descriptor.\n\n        getset descriptors are specialized descriptors defined in extension\n        modules.\"\"\"\n        return isinstance(object, types.GetSetDescriptorType)\nelse:\n    # Other implementations\n    def isgetsetdescriptor(object):\n        \"\"\"Return true if the object is a getset descriptor.\n\n        getset descriptors are specialized descriptors defined in extension\n        modules.\"\"\"\n        return False\n\ndef isfunction(object):\n    \"\"\"Return true if the object is a user-defined function.\n\n    Function objects provide these attributes:\n        __doc__         documentation string\n        __name__        name with which this function was defined\n        __code__        code object containing compiled function bytecode\n        __defaults__    tuple of any default values for arguments\n        __globals__     global namespace in which this function was defined\n        __annotations__ dict of parameter annotations\n        __kwdefaults__  dict of keyword only parameters with defaults\"\"\"\n    return isinstance(object, types.FunctionType)\n\ndef isgeneratorfunction(object):\n    \"\"\"Return true if the object is a user-defined generator function.\n\n    Generator function objects provides same attributes as functions.\n\n    See help(isfunction) for attributes listing.\"\"\"\n    return bool((isfunction(object) or ismethod(object)) and\n                object.__code__.co_flags & CO_GENERATOR)\n\ndef isgenerator(object):\n    \"\"\"Return true if the object is a generator.\n\n    Generator objects provide these attributes:\n        __iter__        defined to support iteration over container\n        close           raises a new GeneratorExit exception inside the\n                        generator to terminate the iteration\n        gi_code         code object\n        gi_frame        frame object or possibly None once the generator has\n                        been exhausted\n        gi_running      set to 1 when generator is executing, 0 otherwise\n        next            return the next item from the container\n        send            resumes the generator and \"sends\" a value that becomes\n                        the result of the current yield-expression\n        throw           used to raise an exception inside the generator\"\"\"\n    return isinstance(object, types.GeneratorType)\n\ndef istraceback(object):\n    \"\"\"Return true if the object is a traceback.\n\n    Traceback objects provide these attributes:\n        tb_frame        frame object at this level\n        tb_lasti        index of last attempted instruction in bytecode\n        tb_lineno       current line number in Python source code\n        tb_next         next inner traceback object (called by this level)\"\"\"\n    return isinstance(object, types.TracebackType)\n\ndef isframe(object):\n    \"\"\"Return true if the object is a frame object.\n\n    Frame objects provide these attributes:\n        f_back          next outer frame object (this frame's caller)\n        f_builtins      built-in namespace seen by this frame\n        f_code          code object being executed in this frame\n        f_globals       global namespace seen by this frame\n        f_lasti         index of last attempted instruction in bytecode\n        f_lineno        current line number in Python source code\n        f_locals        local namespace seen by this frame\n        f_trace         tracing function for this frame, or None\"\"\"\n    return isinstance(object, types.FrameType)\n\ndef iscode(object):\n    \"\"\"Return true if the object is a code object.\n\n    Code objects provide these attributes:\n        co_argcount     number of arguments (not including * or ** args)\n        co_code         string of raw compiled bytecode\n        co_consts       tuple of constants used in the bytecode\n        co_filename     name of file in which this code object was created\n        co_firstlineno  number of first line in Python source code\n        co_flags        bitmap: 1=optimized | 2=newlocals | 4=*arg | 8=**arg\n        co_lnotab       encoded mapping of line numbers to bytecode indices\n        co_name         name with which this code object was defined\n        co_names        tuple of names of local variables\n        co_nlocals      number of local variables\n        co_stacksize    virtual machine stack space required\n        co_varnames     tuple of names of arguments and local variables\"\"\"\n    return isinstance(object, types.CodeType)\n\ndef isbuiltin(object):\n    \"\"\"Return true if the object is a built-in function or method.\n\n    Built-in functions and methods provide these attributes:\n        __doc__         documentation string\n        __name__        original name of this function or method\n        __self__        instance to which a method is bound, or None\"\"\"\n    return isinstance(object, types.BuiltinFunctionType)\n\ndef isroutine(object):\n    \"\"\"Return true if the object is any kind of function or method.\"\"\"\n    return (isbuiltin(object)\n            or isfunction(object)\n            or ismethod(object)\n            or ismethoddescriptor(object))\n\ndef isabstract(object):\n    \"\"\"Return true if the object is an abstract base class (ABC).\"\"\"\n    return bool(isinstance(object, type) and object.__flags__ & TPFLAGS_IS_ABSTRACT)\n\ndef getmembers(object, predicate=None):\n    \"\"\"Return all members of an object as (name, value) pairs sorted by name.\n    Optionally, only return members that satisfy a given predicate.\"\"\"\n    if isclass(object):\n        mro = (object,) + getmro(object)\n    else:\n        mro = ()\n    results = []\n    for key in dir(object):\n        # First try to get the value via __dict__. Some descriptors don't\n        # like calling their __get__ (see bug #1785).\n        for base in mro:\n            if key in base.__dict__:\n                value = base.__dict__[key]\n                break\n        else:\n            try:\n                value = getattr(object, key)\n            except AttributeError:\n                continue\n        if not predicate or predicate(value):\n            results.append((key, value))\n    results.sort()\n    return results\n\nAttribute = namedtuple('Attribute', 'name kind defining_class object')\n\ndef classify_class_attrs(cls):\n    \"\"\"Return list of attribute-descriptor tuples.\n\n    For each name in dir(cls), the return list contains a 4-tuple\n    with these elements:\n\n        0. The name (a string).\n\n        1. The kind of attribute this is, one of these strings:\n               'class method'    created via classmethod()\n               'static method'   created via staticmethod()\n               'property'        created via property()\n               'method'          any other flavor of method\n               'data'            not a method\n\n        2. The class which defined this attribute (a class).\n\n        3. The object as obtained directly from the defining class's\n           __dict__, not via getattr.  This is especially important for\n           data attributes:  C.data is just a data object, but\n           C.__dict__['data'] may be a data descriptor with additional\n           info, like a __doc__ string.\n    \"\"\"\n\n    mro = getmro(cls)\n    names = dir(cls)\n    result = []\n    for name in names:\n        # Get the object associated with the name, and where it was defined.\n        # Getting an obj from the __dict__ sometimes reveals more than\n        # using getattr.  Static and class methods are dramatic examples.\n        # Furthermore, some objects may raise an Exception when fetched with\n        # getattr(). This is the case with some descriptors (bug #1785).\n        # Thus, we only use getattr() as a last resort.\n        homecls = None\n        for base in (cls,) + mro:\n            if name in base.__dict__:\n                obj = base.__dict__[name]\n                homecls = base\n                break\n        else:\n            obj = getattr(cls, name)\n            homecls = getattr(obj, \"__objclass__\", homecls)\n\n        # Classify the object.\n        if isinstance(obj, staticmethod):\n            kind = \"static method\"\n        elif isinstance(obj, classmethod):\n            kind = \"class method\"\n        elif isinstance(obj, property):\n            kind = \"property\"\n        elif ismethoddescriptor(obj):\n            kind = \"method\"\n        elif isdatadescriptor(obj):\n            kind = \"data\"\n        else:\n            obj_via_getattr = getattr(cls, name)\n            if (isfunction(obj_via_getattr) or\n                ismethoddescriptor(obj_via_getattr)):\n                kind = \"method\"\n            else:\n                kind = \"data\"\n            obj = obj_via_getattr\n\n        result.append(Attribute(name, kind, homecls, obj))\n\n    return result\n\n# ----------------------------------------------------------- class helpers\n\ndef getmro(cls):\n    \"Return tuple of base classes (including cls) in method resolution order.\"\n    return cls.__mro__\n\n# -------------------------------------------------- source code extraction\ndef indentsize(line):\n    \"\"\"Return the indent size, in spaces, at the start of a line of text.\"\"\"\n    expline = line.expandtabs()\n    return len(expline) - len(expline.lstrip())\n\ndef getdoc(object):\n    \"\"\"Get the documentation string for an object.\n\n    All tabs are expanded to spaces.  To clean up docstrings that are\n    indented to line up with blocks of code, any whitespace than can be\n    uniformly removed from the second line onwards is removed.\"\"\"\n    try:\n        doc = object.__doc__\n    except AttributeError:\n        return None\n    if not isinstance(doc, str):\n        return None\n    return cleandoc(doc)\n\ndef cleandoc(doc):\n    \"\"\"Clean up indentation from docstrings.\n\n    Any whitespace that can be uniformly removed from the second line\n    onwards is removed.\"\"\"\n    try:\n        lines = doc.expandtabs().split('\\n')\n    except UnicodeError:\n        return None\n    else:\n        # Find minimum indentation of any non-blank lines after first line.\n        margin = sys.maxsize\n        for line in lines[1:]:\n            content = len(line.lstrip())\n            if content:\n                indent = len(line) - content\n                margin = min(margin, indent)\n        # Remove indentation.\n        if lines:\n            lines[0] = lines[0].lstrip()\n        if margin < sys.maxsize:\n            for i in range(1, len(lines)): lines[i] = lines[i][margin:]\n        # Remove any trailing or leading blank lines.\n        while lines and not lines[-1]:\n            lines.pop()\n        while lines and not lines[0]:\n            lines.pop(0)\n        return '\\n'.join(lines)\n\ndef getfile(object):\n    \"\"\"Work out which source or compiled file an object was defined in.\"\"\"\n    if ismodule(object):\n        if hasattr(object, '__file__'):\n            return object.__file__\n        raise TypeError('{!r} is a built-in module'.format(object))\n    if isclass(object):\n        object = sys.modules.get(object.__module__)\n        if hasattr(object, '__file__'):\n            return object.__file__\n        raise TypeError('{!r} is a built-in class'.format(object))\n    if ismethod(object):\n        object = object.__func__\n    if isfunction(object):\n        object = object.__code__\n    if istraceback(object):\n        object = object.tb_frame\n    if isframe(object):\n        object = object.f_code\n    if iscode(object):\n        return object.co_filename\n    raise TypeError('{!r} is not a module, class, method, '\n                    'function, traceback, frame, or code object'.format(object))\n\nModuleInfo = namedtuple('ModuleInfo', 'name suffix mode module_type')\n\ndef getmoduleinfo(path):\n    \"\"\"Get the module name, suffix, mode, and module type for a given file.\"\"\"\n    warnings.warn('inspect.getmoduleinfo() is deprecated', DeprecationWarning,\n                  2)\n    filename = os.path.basename(path)\n    suffixes = [(-len(suffix), suffix, mode, mtype)\n                    for suffix, mode, mtype in imp.get_suffixes()]\n    suffixes.sort() # try longest suffixes first, in case they overlap\n    for neglen, suffix, mode, mtype in suffixes:\n        if filename[neglen:] == suffix:\n            return ModuleInfo(filename[:neglen], suffix, mode, mtype)\n\ndef getmodulename(path):\n    \"\"\"Return the module name for a given file, or None.\"\"\"\n    fname = os.path.basename(path)\n    # Check for paths that look like an actual module file\n    suffixes = [(-len(suffix), suffix)\n                    for suffix in importlib.machinery.all_suffixes()]\n    suffixes.sort() # try longest suffixes first, in case they overlap\n    for neglen, suffix in suffixes:\n        if fname.endswith(suffix):\n            return fname[:neglen]\n    return None\n\ndef getsourcefile(object):\n    \"\"\"Return the filename that can be used to locate an object's source.\n    Return None if no way can be identified to get the source.\n    \"\"\"\n    filename = getfile(object)\n    all_bytecode_suffixes = importlib.machinery.DEBUG_BYTECODE_SUFFIXES[:]\n    all_bytecode_suffixes += importlib.machinery.OPTIMIZED_BYTECODE_SUFFIXES[:]\n    if any(filename.endswith(s) for s in all_bytecode_suffixes):\n        filename = (os.path.splitext(filename)[0] +\n                    importlib.machinery.SOURCE_SUFFIXES[0])\n    elif any(filename.endswith(s) for s in\n                 importlib.machinery.EXTENSION_SUFFIXES):\n        return None\n    if os.path.exists(filename):\n        return filename\n    # only return a non-existent filename if the module has a PEP 302 loader\n    if hasattr(getmodule(object, filename), '__loader__'):\n        return filename\n    # or it is in the linecache\n    if filename in linecache.cache:\n        return filename\n\ndef getabsfile(object, _filename=None):\n    \"\"\"Return an absolute path to the source or compiled file for an object.\n\n    The idea is for each object to have a unique origin, so this routine\n    normalizes the result as much as possible.\"\"\"\n    if _filename is None:\n        _filename = getsourcefile(object) or getfile(object)\n    return os.path.normcase(os.path.abspath(_filename))\n\nmodulesbyfile = {}\n_filesbymodname = {}\n\ndef getmodule(object, _filename=None):\n    \"\"\"Return the module an object was defined in, or None if not found.\"\"\"\n    if ismodule(object):\n        return object\n    if hasattr(object, '__module__'):\n        return sys.modules.get(object.__module__)\n    # Try the filename to modulename cache\n    if _filename is not None and _filename in modulesbyfile:\n        return sys.modules.get(modulesbyfile[_filename])\n    # Try the cache again with the absolute file name\n    try:\n        file = getabsfile(object, _filename)\n    except TypeError:\n        return None\n    if file in modulesbyfile:\n        return sys.modules.get(modulesbyfile[file])\n    # Update the filename to module name cache and check yet again\n    # Copy sys.modules in order to cope with changes while iterating\n    for modname, module in list(sys.modules.items()):\n        if ismodule(module) and hasattr(module, '__file__'):\n            f = module.__file__\n            if f == _filesbymodname.get(modname, None):\n                # Have already mapped this module, so skip it\n                continue\n            _filesbymodname[modname] = f\n            f = getabsfile(module)\n            # Always map to the name the module knows itself by\n            modulesbyfile[f] = modulesbyfile[\n                os.path.realpath(f)] = module.__name__\n    if file in modulesbyfile:\n        return sys.modules.get(modulesbyfile[file])\n    # Check the main module\n    main = sys.modules['__main__']\n    if not hasattr(object, '__name__'):\n        return None\n    if hasattr(main, object.__name__):\n        mainobject = getattr(main, object.__name__)\n        if mainobject is object:\n            return main\n    # Check builtins\n    builtin = sys.modules['builtins']\n    if hasattr(builtin, object.__name__):\n        builtinobject = getattr(builtin, object.__name__)\n        if builtinobject is object:\n            return builtin\n\ndef findsource(object):\n    \"\"\"Return the entire source file and starting line number for an object.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a list of all the lines\n    in the file and the line number indexes a line in that list.  An IOError\n    is raised if the source code cannot be retrieved.\"\"\"\n\n    file = getfile(object)\n    sourcefile = getsourcefile(object)\n    if not sourcefile and file[:1] + file[-1:] != '<>':\n        raise IOError('source code not available')\n    file = sourcefile if sourcefile else file\n\n    module = getmodule(object, file)\n    if module:\n        lines = linecache.getlines(file, module.__dict__)\n    else:\n        lines = linecache.getlines(file)\n    if not lines:\n        raise IOError('could not get source code')\n\n    if ismodule(object):\n        return lines, 0\n\n    if isclass(object):\n        name = object.__name__\n        pat = re.compile(r'^(\\s*)class\\s*' + name + r'\\b')\n        # make some effort to find the best matching class definition:\n        # use the one with the least indentation, which is the one\n        # that's most probably not inside a function definition.\n        candidates = []\n        for i in range(len(lines)):\n            match = pat.match(lines[i])\n            if match:\n                # if it's at toplevel, it's already the best one\n                if lines[i][0] == 'c':\n                    return lines, i\n                # else add whitespace to candidate list\n                candidates.append((match.group(1), i))\n        if candidates:\n            # this will sort by whitespace, and by line number,\n            # less whitespace first\n            candidates.sort()\n            return lines, candidates[0][1]\n        else:\n            raise IOError('could not find class definition')\n\n    if ismethod(object):\n        object = object.__func__\n    if isfunction(object):\n        object = object.__code__\n    if istraceback(object):\n        object = object.tb_frame\n    if isframe(object):\n        object = object.f_code\n    if iscode(object):\n        if not hasattr(object, 'co_firstlineno'):\n            raise IOError('could not find function definition')\n        lnum = object.co_firstlineno - 1\n        pat = re.compile(r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)')\n        while lnum > 0:\n            if pat.match(lines[lnum]): break\n            lnum = lnum - 1\n        return lines, lnum\n    raise IOError('could not find code object')\n\ndef getcomments(object):\n    \"\"\"Get lines of comments immediately preceding an object's source code.\n\n    Returns None when source can't be found.\n    \"\"\"\n    try:\n        lines, lnum = findsource(object)\n    except (IOError, TypeError):\n        return None\n\n    if ismodule(object):\n        # Look for a comment block at the top of the file.\n        start = 0\n        if lines and lines[0][:2] == '#!': start = 1\n        while start < len(lines) and lines[start].strip() in ('', '#'):\n            start = start + 1\n        if start < len(lines) and lines[start][:1] == '#':\n            comments = []\n            end = start\n            while end < len(lines) and lines[end][:1] == '#':\n                comments.append(lines[end].expandtabs())\n                end = end + 1\n            return ''.join(comments)\n\n    # Look for a preceding block of comments at the same indentation.\n    elif lnum > 0:\n        indent = indentsize(lines[lnum])\n        end = lnum - 1\n        if end >= 0 and lines[end].lstrip()[:1] == '#' and \\\n            indentsize(lines[end]) == indent:\n            comments = [lines[end].expandtabs().lstrip()]\n            if end > 0:\n                end = end - 1\n                comment = lines[end].expandtabs().lstrip()\n                while comment[:1] == '#' and indentsize(lines[end]) == indent:\n                    comments[:0] = [comment]\n                    end = end - 1\n                    if end < 0: break\n                    comment = lines[end].expandtabs().lstrip()\n            while comments and comments[0].strip() == '#':\n                comments[:1] = []\n            while comments and comments[-1].strip() == '#':\n                comments[-1:] = []\n            return ''.join(comments)\n\nclass EndOfBlock(Exception): pass\n\nclass BlockFinder:\n    \"\"\"Provide a tokeneater() method to detect the end of a code block.\"\"\"\n    def __init__(self):\n        self.indent = 0\n        self.islambda = False\n        self.started = False\n        self.passline = False\n        self.last = 1\n\n    def tokeneater(self, type, token, srowcol, erowcol, line):\n        if not self.started:\n            # look for the first \"def\", \"class\" or \"lambda\"\n            if token in (\"def\", \"class\", \"lambda\"):\n                if token == \"lambda\":\n                    self.islambda = True\n                self.started = True\n            self.passline = True    # skip to the end of the line\n        elif type == tokenize.NEWLINE:\n            self.passline = False   # stop skipping when a NEWLINE is seen\n            self.last = srowcol[0]\n            if self.islambda:       # lambdas always end at the first NEWLINE\n                raise EndOfBlock\n        elif self.passline:\n            pass\n        elif type == tokenize.INDENT:\n            self.indent = self.indent + 1\n            self.passline = True\n        elif type == tokenize.DEDENT:\n            self.indent = self.indent - 1\n            # the end of matching indent/dedent pairs end a block\n            # (note that this only works for \"def\"/\"class\" blocks,\n            #  not e.g. for \"if: else:\" or \"try: finally:\" blocks)\n            if self.indent <= 0:\n                raise EndOfBlock\n        elif self.indent == 0 and type not in (tokenize.COMMENT, tokenize.NL):\n            # any other token on the same indentation level end the previous\n            # block as well, except the pseudo-tokens COMMENT and NL.\n            raise EndOfBlock\n\ndef getblock(lines):\n    \"\"\"Extract the block of code at the top of the given list of lines.\"\"\"\n    blockfinder = BlockFinder()\n    try:\n        tokens = tokenize.generate_tokens(iter(lines).__next__)\n        for _token in tokens:\n            blockfinder.tokeneater(*_token)\n    except (EndOfBlock, IndentationError):\n        pass\n    return lines[:blockfinder.last]\n\ndef getsourcelines(object):\n    \"\"\"Return a list of source lines and starting line number for an object.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a list of the lines\n    corresponding to the object and the line number indicates where in the\n    original source file the first line of code was found.  An IOError is\n    raised if the source code cannot be retrieved.\"\"\"\n    lines, lnum = findsource(object)\n\n    if ismodule(object): return lines, 0\n    else: return getblock(lines[lnum:]), lnum + 1\n\ndef getsource(object):\n    \"\"\"Return the text of the source code for an object.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a single string.  An\n    IOError is raised if the source code cannot be retrieved.\"\"\"\n    lines, lnum = getsourcelines(object)\n    return ''.join(lines)\n\n# --------------------------------------------------- class tree extraction\ndef walktree(classes, children, parent):\n    \"\"\"Recursive helper function for getclasstree().\"\"\"\n    results = []\n    classes.sort(key=attrgetter('__module__', '__name__'))\n    for c in classes:\n        results.append((c, c.__bases__))\n        if c in children:\n            results.append(walktree(children[c], children, c))\n    return results\n\ndef getclasstree(classes, unique=False):\n    \"\"\"Arrange the given list of classes into a hierarchy of nested lists.\n\n    Where a nested list appears, it contains classes derived from the class\n    whose entry immediately precedes the list.  Each entry is a 2-tuple\n    containing a class and a tuple of its base classes.  If the 'unique'\n    argument is true, exactly one entry appears in the returned structure\n    for each class in the given list.  Otherwise, classes using multiple\n    inheritance and their descendants will appear multiple times.\"\"\"\n    children = {}\n    roots = []\n    for c in classes:\n        if c.__bases__:\n            for parent in c.__bases__:\n                if not parent in children:\n                    children[parent] = []\n                if c not in children[parent]:\n                    children[parent].append(c)\n                if unique and parent in classes: break\n        elif c not in roots:\n            roots.append(c)\n    for parent in children:\n        if parent not in classes:\n            roots.append(parent)\n    return walktree(roots, children, None)\n\n# ------------------------------------------------ argument list extraction\nArguments = namedtuple('Arguments', 'args, varargs, varkw')\n\ndef getargs(co):\n    \"\"\"Get information about the arguments accepted by a code object.\n\n    Three things are returned: (args, varargs, varkw), where\n    'args' is the list of argument names. Keyword-only arguments are\n    appended. 'varargs' and 'varkw' are the names of the * and **\n    arguments or None.\"\"\"\n    args, varargs, kwonlyargs, varkw = _getfullargs(co)\n    return Arguments(args + kwonlyargs, varargs, varkw)\n\ndef _getfullargs(co):\n    \"\"\"Get information about the arguments accepted by a code object.\n\n    Four things are returned: (args, varargs, kwonlyargs, varkw), where\n    'args' and 'kwonlyargs' are lists of argument names, and 'varargs'\n    and 'varkw' are the names of the * and ** arguments or None.\"\"\"\n\n    if not iscode(co):\n        raise TypeError('{!r} is not a code object'.format(co))\n\n    nargs = co.co_argcount\n    names = co.co_varnames\n    nkwargs = co.co_kwonlyargcount\n    args = list(names[:nargs])\n    kwonlyargs = list(names[nargs:nargs+nkwargs])\n    step = 0\n\n    nargs += nkwargs\n    varargs = None\n    if co.co_flags & CO_VARARGS:\n        varargs = co.co_varnames[nargs]\n        nargs = nargs + 1\n    varkw = None\n    if co.co_flags & CO_VARKEYWORDS:\n        varkw = co.co_varnames[nargs]\n    return args, varargs, kwonlyargs, varkw\n\n\nArgSpec = namedtuple('ArgSpec', 'args varargs keywords defaults')\n\ndef getargspec(func):\n    \"\"\"Get the names and default values of a function's arguments.\n\n    A tuple of four things is returned: (args, varargs, varkw, defaults).\n    'args' is a list of the argument names.\n    'args' will include keyword-only argument names.\n    'varargs' and 'varkw' are the names of the * and ** arguments or None.\n    'defaults' is an n-tuple of the default values of the last n arguments.\n\n    Use the getfullargspec() API for Python-3000 code, as annotations\n    and keyword arguments are supported. getargspec() will raise ValueError\n    if the func has either annotations or keyword arguments.\n    \"\"\"\n\n    args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, ann = \\\n        getfullargspec(func)\n    if kwonlyargs or ann:\n        raise ValueError(\"Function has keyword-only arguments or annotations\"\n                         \", use getfullargspec() API which can support them\")\n    return ArgSpec(args, varargs, varkw, defaults)\n\nFullArgSpec = namedtuple('FullArgSpec',\n    'args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations')\n\ndef getfullargspec(func):\n    \"\"\"Get the names and default values of a function's arguments.\n\n    A tuple of seven things is returned:\n    (args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults annotations).\n    'args' is a list of the argument names.\n    'varargs' and 'varkw' are the names of the * and ** arguments or None.\n    'defaults' is an n-tuple of the default values of the last n arguments.\n    'kwonlyargs' is a list of keyword-only argument names.\n    'kwonlydefaults' is a dictionary mapping names from kwonlyargs to defaults.\n    'annotations' is a dictionary mapping argument names to annotations.\n\n    The first four items in the tuple correspond to getargspec().\n    \"\"\"\n\n    if ismethod(func):\n        func = func.__func__\n    if not isfunction(func):\n        raise TypeError('{!r} is not a Python function'.format(func))\n    args, varargs, kwonlyargs, varkw = _getfullargs(func.__code__)\n    return FullArgSpec(args, varargs, varkw, func.__defaults__,\n            kwonlyargs, func.__kwdefaults__, func.__annotations__)\n\nArgInfo = namedtuple('ArgInfo', 'args varargs keywords locals')\n\ndef getargvalues(frame):\n    \"\"\"Get information about arguments passed into a particular frame.\n\n    A tuple of four things is returned: (args, varargs, varkw, locals).\n    'args' is a list of the argument names.\n    'varargs' and 'varkw' are the names of the * and ** arguments or None.\n    'locals' is the locals dictionary of the given frame.\"\"\"\n    args, varargs, varkw = getargs(frame.f_code)\n    return ArgInfo(args, varargs, varkw, frame.f_locals)\n\ndef formatannotation(annotation, base_module=None):\n    if isinstance(annotation, type):\n        if annotation.__module__ in ('builtins', base_module):\n            return annotation.__name__\n        return annotation.__module__+'.'+annotation.__name__\n    return repr(annotation)\n\ndef formatannotationrelativeto(object):\n    module = getattr(object, '__module__', None)\n    def _formatannotation(annotation):\n        return formatannotation(annotation, module)\n    return _formatannotation\n\n#brython fix me\ndef formatargspec(args, varargs=None, varkw=None, defaults=None,\n                  kwonlyargs=(), kwonlydefaults={}, annotations={},\n                  formatarg=str,\n                  formatvarargs=lambda name: '*' + name,\n                  formatvarkw=lambda name: '**' + name,\n                  formatvalue=lambda value: '=' + repr(value),\n                  formatreturns=lambda text: ' -> ' + text,\n                  formatannotation=formatannotation):\n    \"\"\"Format an argument spec from the values returned by getargspec\n    or getfullargspec.\n\n    The first seven arguments are (args, varargs, varkw, defaults,\n    kwonlyargs, kwonlydefaults, annotations).  The other five arguments\n    are the corresponding optional formatting functions that are called to\n    turn names and values into strings.  The last argument is an optional\n    function to format the sequence of arguments.\"\"\"\n    def formatargandannotation(arg):\n        result = formatarg(arg)\n        if arg in annotations:\n            result += ': ' + formatannotation(annotations[arg])\n        return result\n    specs = []\n    if defaults:\n        firstdefault = len(args) - len(defaults)\n    for i, arg in enumerate(args):\n        spec = formatargandannotation(arg)\n        if defaults and i >= firstdefault:\n            spec = spec + formatvalue(defaults[i - firstdefault])\n        specs.append(spec)\n    if varargs is not None:\n        specs.append(formatvarargs(formatargandannotation(varargs)))\n    else:\n        if kwonlyargs:\n            specs.append('*')\n    if kwonlyargs:\n        for kwonlyarg in kwonlyargs:\n            spec = formatargandannotation(kwonlyarg)\n            if kwonlydefaults and kwonlyarg in kwonlydefaults:\n                spec += formatvalue(kwonlydefaults[kwonlyarg])\n            specs.append(spec)\n    if varkw is not None:\n        specs.append(formatvarkw(formatargandannotation(varkw)))\n    result = '(' + ', '.join(specs) + ')'\n    if 'return' in annotations:\n        result += formatreturns(formatannotation(annotations['return']))\n    return result\n\n#brython fix me\n#def formatargvalues(args, varargs, varkw, locals,\n#                    formatarg=str,\n#                    formatvarargs=lambda name: '*' + name,\n#                    formatvarkw=lambda name: '**' + name,\n#                    formatvalue=lambda value: '=' + repr(value)):\n#    \"\"\"Format an argument spec from the 4 values returned by getargvalues.\n\n#    The first four arguments are (args, varargs, varkw, locals).  The\n#    next four arguments are the corresponding optional formatting functions\n#    that are called to turn names and values into strings.  The ninth\n#    argument is an optional function to format the sequence of arguments.\"\"\"\n#    def convert(name, locals=locals,\n#                formatarg=formatarg, formatvalue=formatvalue):\n#        return formatarg(name) + formatvalue(locals[name])\n#    specs = []\n#    for i in range(len(args)):\n#        specs.append(convert(args[i]))\n#    if varargs:\n#        specs.append(formatvarargs(varargs) + formatvalue(locals[varargs]))\n#    if varkw:\n#        specs.append(formatvarkw(varkw) + formatvalue(locals[varkw]))\n#    return '(' + ', '.join(specs) + ')'\n\ndef _missing_arguments(f_name, argnames, pos, values):\n    names = [repr(name) for name in argnames if name not in values]\n    missing = len(names)\n    if missing == 1:\n        s = names[0]\n    elif missing == 2:\n        s = \"{} and {}\".format(*names)\n    else:\n        tail = \", {} and {}\".format(names[-2:])\n        del names[-2:]\n        s = \", \".join(names) + tail\n    raise TypeError(\"%s() missing %i required %s argument%s: %s\" %\n                    (f_name, missing,\n                      \"positional\" if pos else \"keyword-only\",\n                      \"\" if missing == 1 else \"s\", s))\n\ndef _too_many(f_name, args, kwonly, varargs, defcount, given, values):\n    atleast = len(args) - defcount\n    kwonly_given = len([arg for arg in kwonly if arg in values])\n    if varargs:\n        plural = atleast != 1\n        sig = \"at least %d\" % (atleast,)\n    elif defcount:\n        plural = True\n        sig = \"from %d to %d\" % (atleast, len(args))\n    else:\n        plural = len(args) != 1\n        sig = str(len(args))\n    kwonly_sig = \"\"\n    if kwonly_given:\n        msg = \" positional argument%s (and %d keyword-only argument%s)\"\n        kwonly_sig = (msg % (\"s\" if given != 1 else \"\", kwonly_given,\n                             \"s\" if kwonly_given != 1 else \"\"))\n    raise TypeError(\"%s() takes %s positional argument%s but %d%s %s given\" %\n            (f_name, sig, \"s\" if plural else \"\", given, kwonly_sig,\n             \"was\" if given == 1 and not kwonly_given else \"were\"))\n\ndef getcallargs(func, *positional, **named):\n    \"\"\"Get the mapping of arguments to values.\n\n    A dict is returned, with keys the function argument names (including the\n    names of the * and ** arguments, if any), and values the respective bound\n    values from 'positional' and 'named'.\"\"\"\n    spec = getfullargspec(func)\n    args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, ann = spec\n    f_name = func.__name__\n    arg2value = {}\n\n\n    if ismethod(func) and func.__self__ is not None:\n        # implicit 'self' (or 'cls' for classmethods) argument\n        positional = (func.__self__,) + positional\n    num_pos = len(positional)\n    num_args = len(args)\n    num_defaults = len(defaults) if defaults else 0\n\n    n = min(num_pos, num_args)\n    for i in range(n):\n        arg2value[args[i]] = positional[i]\n    if varargs:\n        arg2value[varargs] = tuple(positional[n:])\n    possible_kwargs = set(args + kwonlyargs)\n    if varkw:\n        arg2value[varkw] = {}\n    for kw, value in named.items():\n        if kw not in possible_kwargs:\n            if not varkw:\n                raise TypeError(\"%s() got an unexpected keyword argument %r\" %\n                                (f_name, kw))\n            arg2value[varkw][kw] = value\n            continue\n        if kw in arg2value:\n            raise TypeError(\"%s() got multiple values for argument %r\" %\n                            (f_name, kw))\n        arg2value[kw] = value\n    if num_pos > num_args and not varargs:\n        _too_many(f_name, args, kwonlyargs, varargs, num_defaults,\n                   num_pos, arg2value)\n    if num_pos < num_args:\n        req = args[:num_args - num_defaults]\n        for arg in req:\n            if arg not in arg2value:\n                _missing_arguments(f_name, req, True, arg2value)\n        for i, arg in enumerate(args[num_args - num_defaults:]):\n            if arg not in arg2value:\n                arg2value[arg] = defaults[i]\n    missing = 0\n    for kwarg in kwonlyargs:\n        if kwarg not in arg2value:\n            if kwarg in kwonlydefaults:\n                arg2value[kwarg] = kwonlydefaults[kwarg]\n            else:\n                missing += 1\n    if missing:\n        _missing_arguments(f_name, kwonlyargs, False, arg2value)\n    return arg2value\n\nClosureVars = namedtuple('ClosureVars', 'nonlocals globals builtins unbound')\n\ndef getclosurevars(func):\n    \"\"\"\n    Get the mapping of free variables to their current values.\n\n    Returns a named tuple of dicts mapping the current nonlocal, global\n    and builtin references as seen by the body of the function. A final\n    set of unbound names that could not be resolved is also provided.\n    \"\"\"\n\n    if ismethod(func):\n        func = func.__func__\n\n    if not isfunction(func):\n        raise TypeError(\"'{!r}' is not a Python function\".format(func))\n\n    code = func.__code__\n    # Nonlocal references are named in co_freevars and resolved\n    # by looking them up in __closure__ by positional index\n    if func.__closure__ is None:\n        nonlocal_vars = {}\n    else:\n        nonlocal_vars = {\n            var : cell.cell_contents\n            for var, cell in zip(code.co_freevars, func.__closure__)\n       }\n\n    # Global and builtin references are named in co_names and resolved\n    # by looking them up in __globals__ or __builtins__\n    global_ns = func.__globals__\n    builtin_ns = global_ns.get(\"__builtins__\", builtins.__dict__)\n    if ismodule(builtin_ns):\n        builtin_ns = builtin_ns.__dict__\n    global_vars = {}\n    builtin_vars = {}\n    unbound_names = set()\n    for name in code.co_names:\n        if name in (\"None\", \"True\", \"False\"):\n            # Because these used to be builtins instead of keywords, they\n            # may still show up as name references. We ignore them.\n            continue\n        try:\n            global_vars[name] = global_ns[name]\n        except KeyError:\n            try:\n                builtin_vars[name] = builtin_ns[name]\n            except KeyError:\n                unbound_names.add(name)\n\n    return ClosureVars(nonlocal_vars, global_vars,\n                       builtin_vars, unbound_names)\n\n# -------------------------------------------------- stack frame extraction\n\nTraceback = namedtuple('Traceback', 'filename lineno function code_context index')\n\ndef getframeinfo(frame, context=1):\n    \"\"\"Get information about a frame or traceback object.\n\n    A tuple of five things is returned: the filename, the line number of\n    the current line, the function name, a list of lines of context from\n    the source code, and the index of the current line within that list.\n    The optional second argument specifies the number of lines of context\n    to return, which are centered around the current line.\"\"\"\n    if istraceback(frame):\n        lineno = frame.tb_lineno\n        frame = frame.tb_frame\n    else:\n        lineno = frame.f_lineno\n    if not isframe(frame):\n        raise TypeError('{!r} is not a frame or traceback object'.format(frame))\n\n    filename = getsourcefile(frame) or getfile(frame)\n    if context > 0:\n        start = lineno - 1 - context//2\n        try:\n            lines, lnum = findsource(frame)\n        except IOError:\n            lines = index = None\n        else:\n            start = max(start, 1)\n            start = max(0, min(start, len(lines) - context))\n            lines = lines[start:start+context]\n            index = lineno - 1 - start\n    else:\n        lines = index = None\n\n    return Traceback(filename, lineno, frame.f_code.co_name, lines, index)\n\ndef getlineno(frame):\n    \"\"\"Get the line number from a frame object, allowing for optimization.\"\"\"\n    # FrameType.f_lineno is now a descriptor that grovels co_lnotab\n    return frame.f_lineno\n\ndef getouterframes(frame, context=1):\n    \"\"\"Get a list of records for a frame and all higher (calling) frames.\n\n    Each record contains a frame object, filename, line number, function\n    name, a list of lines of context, and index within the context.\"\"\"\n    framelist = []\n    while frame:\n        framelist.append((frame,) + getframeinfo(frame, context))\n        frame = frame.f_back\n    return framelist\n\ndef getinnerframes(tb, context=1):\n    \"\"\"Get a list of records for a traceback's frame and all lower frames.\n\n    Each record contains a frame object, filename, line number, function\n    name, a list of lines of context, and index within the context.\"\"\"\n    framelist = []\n    while tb:\n        framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n        tb = tb.tb_next\n    return framelist\n\ndef currentframe():\n    \"\"\"Return the frame of the caller or None if this is not possible.\"\"\"\n    return sys._getframe(1) if hasattr(sys, \"_getframe\") else None\n\ndef stack(context=1):\n    \"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\n    return getouterframes(sys._getframe(1), context)\n\ndef trace(context=1):\n    \"\"\"Return a list of records for the stack below the current exception.\"\"\"\n    return getinnerframes(sys.exc_info()[2], context)\n\n\n# ------------------------------------------------ static version of getattr\n\n_sentinel = object()\n\ndef _static_getmro(klass):\n    return type.__dict__['__mro__'].__get__(klass)\n\ndef _check_instance(obj, attr):\n    instance_dict = {}\n    try:\n        instance_dict = object.__getattribute__(obj, \"__dict__\")\n    except AttributeError:\n        pass\n    return dict.get(instance_dict, attr, _sentinel)\n\n\ndef _check_class(klass, attr):\n    for entry in _static_getmro(klass):\n        if _shadowed_dict(type(entry)) is _sentinel:\n            try:\n                return entry.__dict__[attr]\n            except KeyError:\n                pass\n    return _sentinel\n\ndef _is_type(obj):\n    try:\n        _static_getmro(obj)\n    except TypeError:\n        return False\n    return True\n\ndef _shadowed_dict(klass):\n    dict_attr = type.__dict__[\"__dict__\"]\n    for entry in _static_getmro(klass):\n        try:\n            class_dict = dict_attr.__get__(entry)[\"__dict__\"]\n        except KeyError:\n            pass\n        else:\n            if not (type(class_dict) is types.GetSetDescriptorType and\n                    class_dict.__name__ == \"__dict__\" and\n                    class_dict.__objclass__ is entry):\n                return class_dict\n    return _sentinel\n\ndef getattr_static(obj, attr, default=_sentinel):\n    \"\"\"Retrieve attributes without triggering dynamic lookup via the\n       descriptor protocol,  __getattr__ or __getattribute__.\n\n       Note: this function may not be able to retrieve all attributes\n       that getattr can fetch (like dynamically created attributes)\n       and may find attributes that getattr can't (like descriptors\n       that raise AttributeError). It can also return descriptor objects\n       instead of instance members in some cases. See the\n       documentation for details.\n    \"\"\"\n    instance_result = _sentinel\n    if not _is_type(obj):\n        klass = type(obj)\n        dict_attr = _shadowed_dict(klass)\n        if (dict_attr is _sentinel or\n            type(dict_attr) is types.MemberDescriptorType):\n            instance_result = _check_instance(obj, attr)\n    else:\n        klass = obj\n\n    klass_result = _check_class(klass, attr)\n\n    if instance_result is not _sentinel and klass_result is not _sentinel:\n        if (_check_class(type(klass_result), '__get__') is not _sentinel and\n            _check_class(type(klass_result), '__set__') is not _sentinel):\n            return klass_result\n\n    if instance_result is not _sentinel:\n        return instance_result\n    if klass_result is not _sentinel:\n        return klass_result\n\n    if obj is klass:\n        # for types we check the metaclass too\n        for entry in _static_getmro(type(klass)):\n            if _shadowed_dict(type(entry)) is _sentinel:\n                try:\n                    return entry.__dict__[attr]\n                except KeyError:\n                    pass\n    if default is not _sentinel:\n        return default\n    raise AttributeError(attr)\n\n\n# ------------------------------------------------ generator introspection\n\nGEN_CREATED = 'GEN_CREATED'\nGEN_RUNNING = 'GEN_RUNNING'\nGEN_SUSPENDED = 'GEN_SUSPENDED'\nGEN_CLOSED = 'GEN_CLOSED'\n\ndef getgeneratorstate(generator):\n    \"\"\"Get current state of a generator-iterator.\n\n    Possible states are:\n      GEN_CREATED: Waiting to start execution.\n      GEN_RUNNING: Currently being executed by the interpreter.\n      GEN_SUSPENDED: Currently suspended at a yield expression.\n      GEN_CLOSED: Execution has completed.\n    \"\"\"\n    if generator.gi_running:\n        return GEN_RUNNING\n    if generator.gi_frame is None:\n        return GEN_CLOSED\n    if generator.gi_frame.f_lasti == -1:\n        return GEN_CREATED\n    return GEN_SUSPENDED\n\n\ndef getgeneratorlocals(generator):\n    \"\"\"\n    Get the mapping of generator local variables to their current values.\n\n    A dict is returned, with the keys the local variable names and values the\n    bound values.\"\"\"\n\n    if not isgenerator(generator):\n        raise TypeError(\"'{!r}' is not a Python generator\".format(generator))\n\n    frame = getattr(generator, \"gi_frame\", None)\n    if frame is not None:\n        return generator.gi_frame.f_locals\n    else:\n        return {}\n\n###############################################################################\n### Function Signature Object (PEP 362)\n###############################################################################\n\n\n_WrapperDescriptor = type(type.__call__)\n_MethodWrapper = type(all.__call__)\n\n_NonUserDefinedCallables = (_WrapperDescriptor,\n                            _MethodWrapper,\n                            types.BuiltinFunctionType)\n\n\ndef _get_user_defined_method(cls, method_name):\n    try:\n        meth = getattr(cls, method_name)\n    except AttributeError:\n        return\n    else:\n        if not isinstance(meth, _NonUserDefinedCallables):\n            # Once '__signature__' will be added to 'C'-level\n            # callables, this check won't be necessary\n            return meth\n\n\ndef signature(obj):\n    '''Get a signature object for the passed callable.'''\n\n    if not callable(obj):\n        raise TypeError('{!r} is not a callable object'.format(obj))\n\n    if isinstance(obj, types.MethodType):\n        # In this case we skip the first parameter of the underlying\n        # function (usually `self` or `cls`).\n        sig = signature(obj.__func__)\n        return sig.replace(parameters=tuple(sig.parameters.values())[1:])\n\n    try:\n        sig = obj.__signature__\n    except AttributeError:\n        pass\n    else:\n        if sig is not None:\n            return sig\n\n    try:\n        # Was this function wrapped by a decorator?\n        wrapped = obj.__wrapped__\n    except AttributeError:\n        pass\n    else:\n        return signature(wrapped)\n\n    if isinstance(obj, types.FunctionType):\n        return Signature.from_function(obj)\n\n    if isinstance(obj, functools.partial):\n        sig = signature(obj.func)\n\n        new_params = OrderedDict(sig.parameters.items())\n\n        partial_args = obj.args or ()\n        partial_keywords = obj.keywords or {}\n        try:\n            ba = sig.bind_partial(*partial_args, **partial_keywords)\n        except TypeError as ex:\n            msg = 'partial object {!r} has incorrect arguments'.format(obj)\n            raise ValueError(msg) from ex\n\n        for arg_name, arg_value in ba.arguments.items():\n            param = new_params[arg_name]\n            if arg_name in partial_keywords:\n                # We set a new default value, because the following code\n                # is correct:\n                #\n                #   >>> def foo(a): print(a)\n                #   >>> print(partial(partial(foo, a=10), a=20)())\n                #   20\n                #   >>> print(partial(partial(foo, a=10), a=20)(a=30))\n                #   30\n                #\n                # So, with 'partial' objects, passing a keyword argument is\n                # like setting a new default value for the corresponding\n                # parameter\n                #\n                # We also mark this parameter with '_partial_kwarg'\n                # flag.  Later, in '_bind', the 'default' value of this\n                # parameter will be added to 'kwargs', to simulate\n                # the 'functools.partial' real call.\n                new_params[arg_name] = param.replace(default=arg_value,\n                                                     _partial_kwarg=True)\n\n            elif (param.kind not in (_VAR_KEYWORD, _VAR_POSITIONAL) and\n                            not param._partial_kwarg):\n                new_params.pop(arg_name)\n\n        return sig.replace(parameters=new_params.values())\n\n    sig = None\n    if isinstance(obj, type):\n        # obj is a class or a metaclass\n\n        # First, let's see if it has an overloaded __call__ defined\n        # in its metaclass\n        call = _get_user_defined_method(type(obj), '__call__')\n        if call is not None:\n            sig = signature(call)\n        else:\n            # Now we check if the 'obj' class has a '__new__' method\n            new = _get_user_defined_method(obj, '__new__')\n            if new is not None:\n                sig = signature(new)\n            else:\n                # Finally, we should have at least __init__ implemented\n                init = _get_user_defined_method(obj, '__init__')\n                if init is not None:\n                    sig = signature(init)\n    elif not isinstance(obj, _NonUserDefinedCallables):\n        # An object with __call__\n        # We also check that the 'obj' is not an instance of\n        # _WrapperDescriptor or _MethodWrapper to avoid\n        # infinite recursion (and even potential segfault)\n        call = _get_user_defined_method(type(obj), '__call__')\n        if call is not None:\n            sig = signature(call)\n\n    if sig is not None:\n        # For classes and objects we skip the first parameter of their\n        # __call__, __new__, or __init__ methods\n        return sig.replace(parameters=tuple(sig.parameters.values())[1:])\n\n    if isinstance(obj, types.BuiltinFunctionType):\n        # Raise a nicer error message for builtins\n        msg = 'no signature found for builtin function {!r}'.format(obj)\n        raise ValueError(msg)\n\n    raise ValueError('callable {!r} is not supported by signature'.format(obj))\n\n\nclass _void:\n    '''A private marker - used in Parameter & Signature'''\n\n\nclass _empty:\n    pass\n\n\nclass _ParameterKind(int):\n    def __new__(self, *args, name):\n        obj = int.__new__(self, *args)\n        obj._name = name\n        return obj\n\n    def __str__(self):\n        return self._name\n\n    def __repr__(self):\n        return '<_ParameterKind: {!r}>'.format(self._name)\n\n\n_POSITIONAL_ONLY        = _ParameterKind(0, name='POSITIONAL_ONLY')\n_POSITIONAL_OR_KEYWORD  = _ParameterKind(1, name='POSITIONAL_OR_KEYWORD')\n_VAR_POSITIONAL         = _ParameterKind(2, name='VAR_POSITIONAL')\n_KEYWORD_ONLY           = _ParameterKind(3, name='KEYWORD_ONLY')\n_VAR_KEYWORD            = _ParameterKind(4, name='VAR_KEYWORD')\n\n\nclass Parameter:\n    '''Represents a parameter in a function signature.\n\n    Has the following public attributes:\n\n    * name : str\n        The name of the parameter as a string.\n    * default : object\n        The default value for the parameter if specified.  If the\n        parameter has no default value, this attribute is not set.\n    * annotation\n        The annotation for the parameter if specified.  If the\n        parameter has no annotation, this attribute is not set.\n    * kind : str\n        Describes how argument values are bound to the parameter.\n        Possible values: `Parameter.POSITIONAL_ONLY`,\n        `Parameter.POSITIONAL_OR_KEYWORD`, `Parameter.VAR_POSITIONAL`,\n        `Parameter.KEYWORD_ONLY`, `Parameter.VAR_KEYWORD`.\n    '''\n\n    __slots__ = ('_name', '_kind', '_default', '_annotation', '_partial_kwarg')\n\n    POSITIONAL_ONLY         = _POSITIONAL_ONLY\n    POSITIONAL_OR_KEYWORD   = _POSITIONAL_OR_KEYWORD\n    VAR_POSITIONAL          = _VAR_POSITIONAL\n    KEYWORD_ONLY            = _KEYWORD_ONLY\n    VAR_KEYWORD             = _VAR_KEYWORD\n\n    empty = _empty\n\n    def __init__(self, name, kind, *, default=_empty, annotation=_empty,\n                 _partial_kwarg=False):\n\n        if kind not in (_POSITIONAL_ONLY, _POSITIONAL_OR_KEYWORD,\n                        _VAR_POSITIONAL, _KEYWORD_ONLY, _VAR_KEYWORD):\n            raise ValueError(\"invalid value for 'Parameter.kind' attribute\")\n        self._kind = kind\n\n        if default is not _empty:\n            if kind in (_VAR_POSITIONAL, _VAR_KEYWORD):\n                msg = '{} parameters cannot have default values'.format(kind)\n                raise ValueError(msg)\n        self._default = default\n        self._annotation = annotation\n\n        if name is None:\n            if kind != _POSITIONAL_ONLY:\n                raise ValueError(\"None is not a valid name for a \"\n                                 \"non-positional-only parameter\")\n            self._name = name\n        else:\n            name = str(name)\n            if kind != _POSITIONAL_ONLY and not name.isidentifier():\n                msg = '{!r} is not a valid parameter name'.format(name)\n                raise ValueError(msg)\n            self._name = name\n\n        self._partial_kwarg = _partial_kwarg\n\n    @property\n    def name(self):\n        return self._name\n\n    @property\n    def default(self):\n        return self._default\n\n    @property\n    def annotation(self):\n        return self._annotation\n\n    @property\n    def kind(self):\n        return self._kind\n\n    def replace(self, *, name=_void, kind=_void, annotation=_void,\n                default=_void, _partial_kwarg=_void):\n        '''Creates a customized copy of the Parameter.'''\n\n        if name is _void:\n            name = self._name\n\n        if kind is _void:\n            kind = self._kind\n\n        if annotation is _void:\n            annotation = self._annotation\n\n        if default is _void:\n            default = self._default\n\n        if _partial_kwarg is _void:\n            _partial_kwarg = self._partial_kwarg\n\n        return type(self)(name, kind, default=default, annotation=annotation,\n                          _partial_kwarg=_partial_kwarg)\n\n    def __str__(self):\n        kind = self.kind\n\n        formatted = self._name\n        if kind == _POSITIONAL_ONLY:\n            if formatted is None:\n                formatted = ''\n            formatted = '<{}>'.format(formatted)\n\n        # Add annotation and default value\n        if self._annotation is not _empty:\n            formatted = '{}:{}'.format(formatted,\n                                       formatannotation(self._annotation))\n\n        if self._default is not _empty:\n            formatted = '{}={}'.format(formatted, repr(self._default))\n\n        if kind == _VAR_POSITIONAL:\n            formatted = '*' + formatted\n        elif kind == _VAR_KEYWORD:\n            formatted = '**' + formatted\n\n        return formatted\n\n    def __repr__(self):\n        return '<{} at {:#x} {!r}>'.format(self.__class__.__name__,\n                                           id(self), self.name)\n\n    def __eq__(self, other):\n        return (issubclass(other.__class__, Parameter) and\n                self._name == other._name and\n                self._kind == other._kind and\n                self._default == other._default and\n                self._annotation == other._annotation)\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n\nclass BoundArguments:\n    '''Result of `Signature.bind` call.  Holds the mapping of arguments\n    to the function's parameters.\n\n    Has the following public attributes:\n\n    * arguments : OrderedDict\n        An ordered mutable mapping of parameters' names to arguments' values.\n        Does not contain arguments' default values.\n    * signature : Signature\n        The Signature object that created this instance.\n    * args : tuple\n        Tuple of positional arguments values.\n    * kwargs : dict\n        Dict of keyword arguments values.\n    '''\n\n    def __init__(self, signature, arguments):\n        self.arguments = arguments\n        self._signature = signature\n\n    @property\n    def signature(self):\n        return self._signature\n\n    @property\n    def args(self):\n        args = []\n        for param_name, param in self._signature.parameters.items():\n            if (param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY) or\n                                                    param._partial_kwarg):\n                # Keyword arguments mapped by 'functools.partial'\n                # (Parameter._partial_kwarg is True) are mapped\n                # in 'BoundArguments.kwargs', along with VAR_KEYWORD &\n                # KEYWORD_ONLY\n                break\n\n            try:\n                arg = self.arguments[param_name]\n            except KeyError:\n                # We're done here. Other arguments\n                # will be mapped in 'BoundArguments.kwargs'\n                break\n            else:\n                if param.kind == _VAR_POSITIONAL:\n                    # *args\n                    args.extend(arg)\n                else:\n                    # plain argument\n                    args.append(arg)\n\n        return tuple(args)\n\n    @property\n    def kwargs(self):\n        kwargs = {}\n        kwargs_started = False\n        for param_name, param in self._signature.parameters.items():\n            if not kwargs_started:\n                if (param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY) or\n                                                param._partial_kwarg):\n                    kwargs_started = True\n                else:\n                    if param_name not in self.arguments:\n                        kwargs_started = True\n                        continue\n\n            if not kwargs_started:\n                continue\n\n            try:\n                arg = self.arguments[param_name]\n            except KeyError:\n                pass\n            else:\n                if param.kind == _VAR_KEYWORD:\n                    # **kwargs\n                    kwargs.update(arg)\n                else:\n                    # plain keyword argument\n                    kwargs[param_name] = arg\n\n        return kwargs\n\n    def __eq__(self, other):\n        return (issubclass(other.__class__, BoundArguments) and\n                self.signature == other.signature and\n                self.arguments == other.arguments)\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n\nclass Signature:\n    '''A Signature object represents the overall signature of a function.\n    It stores a Parameter object for each parameter accepted by the\n    function, as well as information specific to the function itself.\n\n    A Signature object has the following public attributes and methods:\n\n    * parameters : OrderedDict\n        An ordered mapping of parameters' names to the corresponding\n        Parameter objects (keyword-only arguments are in the same order\n        as listed in `code.co_varnames`).\n    * return_annotation : object\n        The annotation for the return type of the function if specified.\n        If the function has no annotation for its return type, this\n        attribute is not set.\n    * bind(*args, **kwargs) -> BoundArguments\n        Creates a mapping from positional and keyword arguments to\n        parameters.\n    * bind_partial(*args, **kwargs) -> BoundArguments\n        Creates a partial mapping from positional and keyword arguments\n        to parameters (simulating 'functools.partial' behavior.)\n    '''\n\n    __slots__ = ('_return_annotation', '_parameters')\n\n    _parameter_cls = Parameter\n    _bound_arguments_cls = BoundArguments\n\n    empty = _empty\n\n    def __init__(self, parameters=None, *, return_annotation=_empty,\n                 __validate_parameters__=True):\n        '''Constructs Signature from the given list of Parameter\n        objects and 'return_annotation'.  All arguments are optional.\n        '''\n\n        if parameters is None:\n            params = OrderedDict()\n        else:\n            if __validate_parameters__:\n                params = OrderedDict()\n                top_kind = _POSITIONAL_ONLY\n\n                for idx, param in enumerate(parameters):\n                    kind = param.kind\n                    if kind < top_kind:\n                        msg = 'wrong parameter order: {} before {}'\n                        msg = msg.format(top_kind, param.kind)\n                        raise ValueError(msg)\n                    else:\n                        top_kind = kind\n\n                    name = param.name\n                    if name is None:\n                        name = str(idx)\n                        param = param.replace(name=name)\n\n                    if name in params:\n                        msg = 'duplicate parameter name: {!r}'.format(name)\n                        raise ValueError(msg)\n                    params[name] = param\n            else:\n                params = OrderedDict(((param.name, param)\n                                                for param in parameters))\n\n        self._parameters = types.MappingProxyType(params)\n        self._return_annotation = return_annotation\n\n    @classmethod\n    def from_function(cls, func):\n        '''Constructs Signature for the given python function'''\n\n        if not isinstance(func, types.FunctionType):\n            raise TypeError('{!r} is not a Python function'.format(func))\n\n        Parameter = cls._parameter_cls\n\n        # Parameter information.\n        func_code = func.__code__\n        pos_count = func_code.co_argcount\n        arg_names = func_code.co_varnames\n        positional = tuple(arg_names[:pos_count])\n        keyword_only_count = func_code.co_kwonlyargcount\n        keyword_only = arg_names[pos_count:(pos_count + keyword_only_count)]\n        annotations = func.__annotations__\n        defaults = func.__defaults__\n        kwdefaults = func.__kwdefaults__\n\n        if defaults:\n            pos_default_count = len(defaults)\n        else:\n            pos_default_count = 0\n\n        parameters = []\n\n        # Non-keyword-only parameters w/o defaults.\n        non_default_count = pos_count - pos_default_count\n        for name in positional[:non_default_count]:\n            annotation = annotations.get(name, _empty)\n            parameters.append(Parameter(name, annotation=annotation,\n                                        kind=_POSITIONAL_OR_KEYWORD))\n\n        # ... w/ defaults.\n        for offset, name in enumerate(positional[non_default_count:]):\n            annotation = annotations.get(name, _empty)\n            parameters.append(Parameter(name, annotation=annotation,\n                                        kind=_POSITIONAL_OR_KEYWORD,\n                                        default=defaults[offset]))\n\n        # *args\n        if func_code.co_flags & 0x04:\n            name = arg_names[pos_count + keyword_only_count]\n            annotation = annotations.get(name, _empty)\n            parameters.append(Parameter(name, annotation=annotation,\n                                        kind=_VAR_POSITIONAL))\n\n        # Keyword-only parameters.\n        for name in keyword_only:\n            default = _empty\n            if kwdefaults is not None:\n                default = kwdefaults.get(name, _empty)\n\n            annotation = annotations.get(name, _empty)\n            parameters.append(Parameter(name, annotation=annotation,\n                                        kind=_KEYWORD_ONLY,\n                                        default=default))\n        # **kwargs\n        if func_code.co_flags & 0x08:\n            index = pos_count + keyword_only_count\n            if func_code.co_flags & 0x04:\n                index += 1\n\n            name = arg_names[index]\n            annotation = annotations.get(name, _empty)\n            parameters.append(Parameter(name, annotation=annotation,\n                                        kind=_VAR_KEYWORD))\n\n        return cls(parameters,\n                   return_annotation=annotations.get('return', _empty),\n                   __validate_parameters__=False)\n\n    @property\n    def parameters(self):\n        return self._parameters\n\n    @property\n    def return_annotation(self):\n        return self._return_annotation\n\n    def replace(self, *, parameters=_void, return_annotation=_void):\n        '''Creates a customized copy of the Signature.\n        Pass 'parameters' and/or 'return_annotation' arguments\n        to override them in the new copy.\n        '''\n\n        if parameters is _void:\n            parameters = self.parameters.values()\n\n        if return_annotation is _void:\n            return_annotation = self._return_annotation\n\n        return type(self)(parameters,\n                          return_annotation=return_annotation)\n\n    def __eq__(self, other):\n        if (not issubclass(type(other), Signature) or\n                    self.return_annotation != other.return_annotation or\n                    len(self.parameters) != len(other.parameters)):\n            return False\n\n        other_positions = {param: idx\n                           for idx, param in enumerate(other.parameters.keys())}\n\n        for idx, (param_name, param) in enumerate(self.parameters.items()):\n            if param.kind == _KEYWORD_ONLY:\n                try:\n                    other_param = other.parameters[param_name]\n                except KeyError:\n                    return False\n                else:\n                    if param != other_param:\n                        return False\n            else:\n                try:\n                    other_idx = other_positions[param_name]\n                except KeyError:\n                    return False\n                else:\n                    if (idx != other_idx or\n                                    param != other.parameters[param_name]):\n                        return False\n\n        return True\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n    def _bind(self, args, kwargs, *, partial=False):\n        '''Private method.  Don't use directly.'''\n\n        arguments = OrderedDict()\n\n        parameters = iter(self.parameters.values())\n        parameters_ex = ()\n        arg_vals = iter(args)\n\n        if partial:\n            # Support for binding arguments to 'functools.partial' objects.\n            # See 'functools.partial' case in 'signature()' implementation\n            # for details.\n            for param_name, param in self.parameters.items():\n                if (param._partial_kwarg and param_name not in kwargs):\n                    # Simulating 'functools.partial' behavior\n                    kwargs[param_name] = param.default\n\n        while True:\n            # Let's iterate through the positional arguments and corresponding\n            # parameters\n            try:\n                arg_val = next(arg_vals)\n            except StopIteration:\n                # No more positional arguments\n                try:\n                    param = next(parameters)\n                except StopIteration:\n                    # No more parameters. That's it. Just need to check that\n                    # we have no `kwargs` after this while loop\n                    break\n                else:\n                    if param.kind == _VAR_POSITIONAL:\n                        # That's OK, just empty *args.  Let's start parsing\n                        # kwargs\n                        break\n                    elif param.name in kwargs:\n                        if param.kind == _POSITIONAL_ONLY:\n                            msg = '{arg!r} parameter is positional only, ' \\\n                                  'but was passed as a keyword'\n                            msg = msg.format(arg=param.name)\n                            raise TypeError(msg) from None\n                        parameters_ex = (param,)\n                        break\n                    elif (param.kind == _VAR_KEYWORD or\n                                                param.default is not _empty):\n                        # That's fine too - we have a default value for this\n                        # parameter.  So, lets start parsing `kwargs`, starting\n                        # with the current parameter\n                        parameters_ex = (param,)\n                        break\n                    else:\n                        if partial:\n                            parameters_ex = (param,)\n                            break\n                        else:\n                            msg = '{arg!r} parameter lacking default value'\n                            msg = msg.format(arg=param.name)\n                            raise TypeError(msg) from None\n            else:\n                # We have a positional argument to process\n                try:\n                    param = next(parameters)\n                except StopIteration:\n                    raise TypeError('too many positional arguments') from None\n                else:\n                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):\n                        # Looks like we have no parameter for this positional\n                        # argument\n                        raise TypeError('too many positional arguments')\n\n                    if param.kind == _VAR_POSITIONAL:\n                        # We have an '*args'-like argument, let's fill it with\n                        # all positional arguments we have left and move on to\n                        # the next phase\n                        values = [arg_val]\n                        values.extend(arg_vals)\n                        arguments[param.name] = tuple(values)\n                        break\n\n                    if param.name in kwargs:\n                        raise TypeError('multiple values for argument '\n                                        '{arg!r}'.format(arg=param.name))\n\n                    arguments[param.name] = arg_val\n\n        # Now, we iterate through the remaining parameters to process\n        # keyword arguments\n        kwargs_param = None\n        for param in itertools.chain(parameters_ex, parameters):\n            if param.kind == _POSITIONAL_ONLY:\n                # This should never happen in case of a properly built\n                # Signature object (but let's have this check here\n                # to ensure correct behaviour just in case)\n                raise TypeError('{arg!r} parameter is positional only, '\n                                'but was passed as a keyword'. \\\n                                format(arg=param.name))\n\n            if param.kind == _VAR_KEYWORD:\n                # Memorize that we have a '**kwargs'-like parameter\n                kwargs_param = param\n                continue\n\n            param_name = param.name\n            try:\n                arg_val = kwargs.pop(param_name)\n            except KeyError:\n                # We have no value for this parameter.  It's fine though,\n                # if it has a default value, or it is an '*args'-like\n                # parameter, left alone by the processing of positional\n                # arguments.\n                if (not partial and param.kind != _VAR_POSITIONAL and\n                                                    param.default is _empty):\n                    raise TypeError('{arg!r} parameter lacking default value'. \\\n                                    format(arg=param_name)) from None\n\n            else:\n                arguments[param_name] = arg_val\n\n        if kwargs:\n            if kwargs_param is not None:\n                # Process our '**kwargs'-like parameter\n                arguments[kwargs_param.name] = kwargs\n            else:\n                raise TypeError('too many keyword arguments')\n\n        return self._bound_arguments_cls(self, arguments)\n\n    def bind(__bind_self, *args, **kwargs):\n        '''Get a BoundArguments object, that maps the passed `args`\n        and `kwargs` to the function's signature.  Raises `TypeError`\n        if the passed arguments can not be bound.\n        '''\n        return __bind_self._bind(args, kwargs)\n\n    def bind_partial(__bind_self, *args, **kwargs):\n        '''Get a BoundArguments object, that partially maps the\n        passed `args` and `kwargs` to the function's signature.\n        Raises `TypeError` if the passed arguments can not be bound.\n        '''\n        return __bind_self._bind(args, kwargs, partial=True)\n\n    def __str__(self):\n        result = []\n        render_kw_only_separator = True\n        for idx, param in enumerate(self.parameters.values()):\n            formatted = str(param)\n\n            kind = param.kind\n            if kind == _VAR_POSITIONAL:\n                # OK, we have an '*args'-like parameter, so we won't need\n                # a '*' to separate keyword-only arguments\n                render_kw_only_separator = False\n            elif kind == _KEYWORD_ONLY and render_kw_only_separator:\n                # We have a keyword-only parameter to render and we haven't\n                # rendered an '*args'-like parameter before, so add a '*'\n                # separator to the parameters list (\"foo(arg1, *, arg2)\" case)\n                result.append('*')\n                # This condition should be only triggered once, so\n                # reset the flag\n                render_kw_only_separator = False\n\n            result.append(formatted)\n\n        rendered = '({})'.format(', '.join(result))\n\n        if self.return_annotation is not _empty:\n            anno = formatannotation(self.return_annotation)\n            rendered += ' -> {}'.format(anno)\n\n        return rendered\n"], "browser.markdown": [".py", "import browser.html\nimport _jsre as re\nimport __random as random\n\nletters = 'abcdefghijklmnopqrstuvwxyz'\nletters += letters.upper()+'0123456789'\n\nclass URL:\n    def __init__(self,src):\n        elts = src.split(maxsplit=1)\n        self.href = elts[0]\n        self.alt = ''\n        if len(elts)==2:\n            alt = elts[1]\n            if alt[0]=='\"' and alt[-1]=='\"':self.alt=alt[1:-1]\n            elif alt[0]==\"'\" and alt[-1]==\"'\":self.alt=alt[1:-1]\n            elif alt[0]==\"(\" and alt[-1]==\")\":self.alt=alt[1:-1]\n        \nclass CodeBlock:\n    def __init__(self,line):\n        self.lines = [line]\n    \n    def to_html(self):\n        if self.lines[0].startswith(\"`\"):\n            self.lines.pop(0)\n        res = escape('\\n'.join(self.lines))\n        res = unmark(res)\n        res = '<pre class=\"marked\">%s</pre>\\n' %res\n        return res,[]\n\nclass HtmlBlock:\n\n    def __init__(self, src):\n        self.src = src\n    \n    def to_html(self):\n        return self.src\n        \nclass Marked:\n    def __init__(self, line=''):\n        self.line = line\n        self.children = []\n\n    def to_html(self):\n        return apply_markdown(self.line)\n        \n# get references\nrefs = {}\nref_pattern = r\"^\\[(.*)\\]:\\s+(.*)\"\n\ndef mark(src):\n\n    global refs\n    refs = {}\n    # split source in sections\n    # sections can be :\n    # - a block-level HTML element (markdown syntax will not be processed)\n    # - a script\n    # - a span-level HTML tag (markdown syntax will be processed)\n    # - a code block\n    \n    # normalise line feeds\n    src = src.replace('\\r\\n','\\n')\n    \n    # lines followed by dashes\n    src = re.sub(r'(.*?)\\n=+\\n', '\\n# \\\\1\\n', src)\n    src = re.sub(r'(.*?)\\n-+\\n', '\\n## \\\\1\\n', src) \n\n    lines = src.split('\\n')+['']\n    \n    i = bq = 0\n    ul = ol = 0\n    \n    while i<len(lines):\n\n        # enclose lines starting by > in a blockquote\n        if lines[i].startswith('>'):\n            nb = 1\n            while nb<len(lines[i]) and lines[i][nb]=='>':\n                nb += 1\n            lines[i] = lines[i][nb:]\n            if nb>bq:\n                lines.insert(i,'<blockquote>'*(nb-bq))\n                i += 1\n                bq = nb\n            elif nb<bq:\n                lines.insert(i,'</blockquote>'*(bq-nb))\n                i += 1\n                bq = nb\n        elif bq>0:\n            lines.insert(i,'</blockquote>'*bq)\n            i += 1\n            bq = 0\n\n        # unordered lists\n        if lines[i].strip() and lines[i].lstrip()[0] in '-+*' \\\n            and len(lines[i].lstrip())>1 \\\n            and lines[i].lstrip()[1]==' ' \\\n            and (i==0 or ul or not lines[i-1].strip()):\n            # line indentation indicates nesting level\n            nb = 1+len(lines[i])-len(lines[i].lstrip())\n            lines[i] = '<li>'+lines[i][nb:]\n            if nb>ul:\n                lines.insert(i,'<ul>'*(nb-ul))\n                i += 1\n            elif nb<ul:\n                lines.insert(i,'</ul>'*(ul-nb))\n                i += 1\n            ul = nb\n        elif ul and not lines[i].strip():\n            if i<len(lines)-1 and lines[i+1].strip() \\\n                and not lines[i+1].startswith(' '):\n                    nline = lines[i+1].lstrip()\n                    if nline[0] in '-+*' and len(nline)>1 and nline[1]==' ':\n                        pass\n                    else:\n                        lines.insert(i,'</ul>'*ul)\n                        i += 1\n                        ul = 0\n\n        # ordered lists\n        mo = re.search(r'^(\\d+\\.)',lines[i])\n        if mo:\n            if not ol:\n                lines.insert(i,'<ol>')\n                i += 1\n            lines[i] = '<li>'+lines[i][len(mo.groups()[0]):]\n            ol = 1\n        elif ol and not lines[i].strip() and i<len(lines)-1 \\\n            and not lines[i+1].startswith(' ') \\\n            and not re.search(r'^(\\d+\\.)',lines[i+1]):\n            lines.insert(i,'</ol>')\n            i += 1\n            ol = 0\n        \n        i += 1\n    \n    if ul:\n        lines.append('</ul>'*ul)\n    if ol:\n        lines.append('</ol>'*ol)\n    if bq:\n        lines.append('</blockquote>'*bq)\n    \n    sections = []\n    scripts = []\n    section = Marked()\n\n    i = 0\n    while i<len(lines):\n        line = lines[i]\n        if line.strip() and line.startswith('    '):\n            if isinstance(section,Marked) and section.line:\n                sections.append(section)\n            section = CodeBlock(line[4:])\n            j = i+1\n            while j<len(lines) and lines[j].startswith('    '):\n                    section.lines.append(lines[j][4:])\n                    j += 1\n            sections.append(section)\n            section = Marked()\n            i = j   \n            continue\n\n        elif line.lower().startswith('<script'):\n            if isinstance(section,Marked) and section.line:\n                sections.append(section)\n                section = Marked()\n            j = i+1\n            while j<len(lines):\n                if lines[j].lower().startswith('</script>'):\n                    scripts.append('\\n'.join(lines[i+1:j]))\n                    for k in range(i,j+1):\n                        lines[k] = ''\n                    break\n                j += 1\n            i = j\n            continue\n\n        # atext header\n        elif line.startswith('#'):\n            level = 1\n            line = lines[i]\n            while level<len(line) and line[level]=='#' and level<=6:\n                level += 1\n            if not line[level+1:].strip():\n                if level==1:\n                    i += 1\n                    continue\n                else:\n                    lines[i] = '<H%s>%s</H%s>\\n' %(level-1,'#',level-1)\n            else:\n                lines[i] = '<H%s>%s</H%s>\\n' %(level,line[level+1:],level)\n\n        else:\n            mo = re.search(ref_pattern,line)\n            if mo is not None:\n                if isinstance(section,Marked) and section.line:\n                    sections.append(section)\n                    section = Marked()\n                key = mo.groups()[0]\n                value = URL(mo.groups()[1])\n                refs[key.lower()] = value\n            else:\n                if not line.strip():\n                    line = '<p></p>'\n                if section.line:\n                    section.line += ' '\n                section.line += line\n                    \n            i += 1\n\n    if isinstance(section,Marked) and section.line:\n        sections.append(section)\n\n    res = ''\n    for section in sections:\n        mk,_scripts = section.to_html()\n        res += mk\n        scripts += _scripts\n    return res,scripts\n\ndef escape(czone):\n    czone = czone.replace('&','&amp;')\n    czone = czone.replace('<','&lt;')\n    czone = czone.replace('>','&gt;')\n    czone = czone.replace('_','&#95;')\n    czone = czone.replace('*','&#42;')\n    return czone\n\ndef s_escape(mo):\n    # used in re.sub\n    czone = mo.string[mo.start():mo.end()]\n    return escape(czone)\n\ndef unmark(code_zone):\n    # convert _ to &#95; inside inline code\n    code_zone = code_zone.replace('_','&#95;')\n    return code_zone\n\ndef s_unmark(mo):\n    # convert _ to &#95; inside inline code\n    code_zone = mo.string[mo.start():mo.end()]\n    code_zone = code_zone.replace('_','&#95;')\n    return code_zone\n\ndef apply_markdown(src):\n\n    scripts = []\n    key = None\n\n    i = 0\n    while i<len(src):\n        if src[i]=='[':\n            start_a = i+1\n            while True:\n                end_a = src.find(']',i)\n                if end_a == -1:\n                    break\n                if src[end_a-1]=='\\\\':\n                    i = end_a+1\n                else:\n                    break\n            if end_a>-1 and src[start_a:end_a].find('\\n')==-1:\n                link = src[start_a:end_a]\n                rest = src[end_a+1:].lstrip()\n                if rest and rest[0]=='(':\n                    j = 0\n                    while True:\n                        end_href = rest.find(')',j)\n                        if end_href == -1:\n                            break\n                        if rest[end_href-1]=='\\\\':\n                            j = end_href+1\n                        else:\n                            break\n                    if end_href>-1 and rest[:end_href].find('\\n')==-1:\n                        tag = '<a href=\"'+rest[1:end_href]+'\">'+link+'</a>'\n                        src = src[:start_a-1]+tag+rest[end_href+1:]\n                        i = start_a+len(tag)\n                elif rest and rest[0]=='[':\n                    j = 0\n                    while True:\n                        end_key = rest.find(']',j)\n                        if end_key == -1:\n                            break\n                        if rest[end_key-1]=='\\\\':\n                            j = end_key+1\n                        else:\n                            break\n                    if end_key>-1 and rest[:end_key].find('\\n')==-1:\n                        if not key:\n                            key = link\n                        if key.lower() not in refs:\n                            raise KeyError('unknown reference %s' %key)\n                        url = refs[key.lower()]\n                        tag = '<a href=\"'+url+'\">'+link+'</a>'\n                        src = src[:start_a-1]+tag+rest[end_key+1:]\n                        i = start_a+len(tag)\n        \n        i += 1\n\n    # before apply the markup with _ and *, isolate HTML tags because they can\n    # contain these characters\n\n    # We replace them temporarily by a random string\n    rstr = ''.join(random.choice(letters) for i in range(16))\n    \n    i = 0\n    state = None\n    start = -1\n    data = ''\n    tags = []\n    while i<len(src):\n        if src[i]=='<':\n            j = i+1\n            while j<len(src):\n                if src[j]=='\"' or src[j]==\"'\":\n                    if state==src[j] and src[j-1]!='\\\\':\n                        state = None\n                        #src = src[:start+1]+data+src[j:]\n                        j = start+len(data)+1\n                        data = ''\n                    elif state==None:\n                        state = src[j]\n                        start = j\n                    else:\n                        data += src[j]\n                elif src[j]=='>' and state is None:\n                    tags.append(src[i:j+1])\n                    src = src[:i]+rstr+src[j+1:]\n                    i += len(rstr)\n                    break\n                elif state=='\"' or state==\"'\":\n                    data += src[j]\n                elif src[j]=='\\n':\n                    # if a sign < is not followed by > in the same ligne, it\n                    # is the sign \"lesser than\"\n                    src = src[:i]+'&lt;'+src[i+1:]\n                    j=i+4\n                    break\n                j += 1\n            #i = j\n        elif src[i]=='`' and i>0 and src[i-1]!='\\\\':\n            # ignore the content of inline code\n            j = i+1\n            while j<len(src):\n                if src[j]=='`' and src[j-1]!='\\\\':\n                    break\n                j += 1\n            i = j\n        i += 1                    \n\n    # escape \"<\", \">\", \"&\" and \"_\" in inline code\n    code_pattern = r'\\`(.*?)\\`'\n    src = re.sub(code_pattern,s_escape,src)\n\n    # replace escaped ` _ * by HTML characters\n    src = src.replace(r'\\\\\\`','&#96;')\n    src = src.replace(r'\\\\_','&#95;')\n    src = src.replace(r'\\\\*','&#42;')\n\n    # emphasis\n    strong_patterns = [('STRONG',r'\\*\\*(.*?)\\*\\*'),('B',r'__(.*?)__')]\n    for tag,strong_pattern in strong_patterns:\n        src = re.sub(strong_pattern,r'<%s>\\1</%s>' %(tag,tag),src)\n\n    em_patterns = [('EM',r'\\*(.*?)\\*'),('I',r'\\_(.*?)\\_')]\n    for tag,em_pattern in em_patterns:\n        src = re.sub(em_pattern,r'<%s>\\1</%s>' %(tag,tag),src)\n\n    # inline code\n    code_pattern = r'\\`(.*?)\\`'\n    src = re.sub(code_pattern,r'<code>\\1</code>',src)\n    \n    # restore tags\n    while True:\n        pos = src.rfind(rstr)\n        if pos==-1:\n            break\n        repl = tags.pop()\n        src = src[:pos]+repl+src[pos+len(rstr):]\n\n    src = '<p>'+src+'</p>'\n\n    return src,scripts\n"], "test.pystone": [".py", "#! /usr/bin/python3.3\n\n\"\"\"\n\"PYSTONE\" Benchmark Program\n\nVersion:        Python/1.1 (corresponds to C/1.1 plus 2 Pystone fixes)\n\nAuthor:         Reinhold P. Weicker,  CACM Vol 27, No 10, 10/84 pg. 1013.\n\n                Translated from ADA to C by Rick Richardson.\n                Every method to preserve ADA-likeness has been used,\n                at the expense of C-ness.\n\n                Translated from C to Python by Guido van Rossum.\n\nVersion History:\n\n                Version 1.1 corrects two bugs in version 1.0:\n\n                First, it leaked memory: in Proc1(), NextRecord ends\n                up having a pointer to itself.  I have corrected this\n                by zapping NextRecord.PtrComp at the end of Proc1().\n\n                Second, Proc3() used the operator != to compare a\n                record to None.  This is rather inefficient and not\n                true to the intention of the original benchmark (where\n                a pointer comparison to None is intended; the !=\n                operator attempts to find a method __cmp__ to do value\n                comparison of the record).  Version 1.1 runs 5-10\n                percent faster than version 1.0, so benchmark figures\n                of different versions can't be compared directly.\n\n\"\"\"\n\nLOOPS = 50000\n\nfrom time import clock\n\n__version__ = \"1.1\"\n\n[Ident1, Ident2, Ident3, Ident4, Ident5] = range(1, 6)\n\nclass Record:\n\n    def __init__(self, PtrComp = None, Discr = 0, EnumComp = 0,\n                       IntComp = 0, StringComp = 0):\n        self.PtrComp = PtrComp\n        self.Discr = Discr\n        self.EnumComp = EnumComp\n        self.IntComp = IntComp\n        self.StringComp = StringComp\n\n    def copy(self):\n        return Record(self.PtrComp, self.Discr, self.EnumComp,\n                      self.IntComp, self.StringComp)\n\nTRUE = 1\nFALSE = 0\n\ndef main(loops=LOOPS):\n    benchtime, stones = pystones(loops)\n    print(\"Pystone(%s) time for %d passes = %g\" % \\\n          (__version__, loops, benchtime))\n    print(\"This machine benchmarks at %g pystones/second\" % stones)\n\n\ndef pystones(loops=LOOPS):\n    return Proc0(loops)\n\nIntGlob = 0\nBoolGlob = FALSE\nChar1Glob = '\\0'\nChar2Glob = '\\0'\nArray1Glob = [0]*51\nArray2Glob = [x[:] for x in [Array1Glob]*51]\nPtrGlb = None\nPtrGlbNext = None\n\ndef Proc0(loops=LOOPS):\n    global IntGlob\n    global BoolGlob\n    global Char1Glob\n    global Char2Glob\n    global Array1Glob\n    global Array2Glob\n    global PtrGlb\n    global PtrGlbNext\n\n    starttime = clock()\n    for i in range(loops):\n        pass\n    nulltime = clock() - starttime\n\n    PtrGlbNext = Record()\n    PtrGlb = Record()\n    PtrGlb.PtrComp = PtrGlbNext\n    PtrGlb.Discr = Ident1\n    PtrGlb.EnumComp = Ident3\n    PtrGlb.IntComp = 40\n    PtrGlb.StringComp = \"DHRYSTONE PROGRAM, SOME STRING\"\n    String1Loc = \"DHRYSTONE PROGRAM, 1'ST STRING\"\n    Array2Glob[8][7] = 10\n\n    starttime = clock()\n\n    for i in range(loops):\n        Proc5()\n        Proc4()\n        IntLoc1 = 2\n        IntLoc2 = 3\n        String2Loc = \"DHRYSTONE PROGRAM, 2'ND STRING\"\n        EnumLoc = Ident2\n        BoolGlob = not Func2(String1Loc, String2Loc)\n        while IntLoc1 < IntLoc2:\n            IntLoc3 = 5 * IntLoc1 - IntLoc2\n            IntLoc3 = Proc7(IntLoc1, IntLoc2)\n            IntLoc1 = IntLoc1 + 1\n        Proc8(Array1Glob, Array2Glob, IntLoc1, IntLoc3)\n        PtrGlb = Proc1(PtrGlb)\n        CharIndex = 'A'\n        while CharIndex <= Char2Glob:\n            if EnumLoc == Func1(CharIndex, 'C'):\n                EnumLoc = Proc6(Ident1)\n            CharIndex = chr(ord(CharIndex)+1)\n        IntLoc3 = IntLoc2 * IntLoc1\n        IntLoc2 = IntLoc3 / IntLoc1\n        IntLoc2 = 7 * (IntLoc3 - IntLoc2) - IntLoc1\n        IntLoc1 = Proc2(IntLoc1)\n\n    benchtime = clock() - starttime - nulltime\n    if benchtime == 0.0:\n        loopsPerBenchtime = 0.0\n    else:\n        loopsPerBenchtime = (loops / benchtime)\n    return benchtime, loopsPerBenchtime\n\ndef Proc1(PtrParIn):\n    PtrParIn.PtrComp = NextRecord = PtrGlb.copy()\n    PtrParIn.IntComp = 5\n    NextRecord.IntComp = PtrParIn.IntComp\n    NextRecord.PtrComp = PtrParIn.PtrComp\n    NextRecord.PtrComp = Proc3(NextRecord.PtrComp)\n    if NextRecord.Discr == Ident1:\n        NextRecord.IntComp = 6\n        NextRecord.EnumComp = Proc6(PtrParIn.EnumComp)\n        NextRecord.PtrComp = PtrGlb.PtrComp\n        NextRecord.IntComp = Proc7(NextRecord.IntComp, 10)\n    else:\n        PtrParIn = NextRecord.copy()\n    NextRecord.PtrComp = None\n    return PtrParIn\n\ndef Proc2(IntParIO):\n    IntLoc = IntParIO + 10\n    while 1:\n        if Char1Glob == 'A':\n            IntLoc = IntLoc - 1\n            IntParIO = IntLoc - IntGlob\n            EnumLoc = Ident1\n        if EnumLoc == Ident1:\n            break\n    return IntParIO\n\ndef Proc3(PtrParOut):\n    global IntGlob\n\n    if PtrGlb is not None:\n        PtrParOut = PtrGlb.PtrComp\n    else:\n        IntGlob = 100\n    PtrGlb.IntComp = Proc7(10, IntGlob)\n    return PtrParOut\n\ndef Proc4():\n    global Char2Glob\n\n    BoolLoc = Char1Glob == 'A'\n    BoolLoc = BoolLoc or BoolGlob\n    Char2Glob = 'B'\n\ndef Proc5():\n    global Char1Glob\n    global BoolGlob\n\n    Char1Glob = 'A'\n    BoolGlob = FALSE\n\ndef Proc6(EnumParIn):\n    EnumParOut = EnumParIn\n    if not Func3(EnumParIn):\n        EnumParOut = Ident4\n    if EnumParIn == Ident1:\n        EnumParOut = Ident1\n    elif EnumParIn == Ident2:\n        if IntGlob > 100:\n            EnumParOut = Ident1\n        else:\n            EnumParOut = Ident4\n    elif EnumParIn == Ident3:\n        EnumParOut = Ident2\n    elif EnumParIn == Ident4:\n        pass\n    elif EnumParIn == Ident5:\n        EnumParOut = Ident3\n    return EnumParOut\n\ndef Proc7(IntParI1, IntParI2):\n    IntLoc = IntParI1 + 2\n    IntParOut = IntParI2 + IntLoc\n    return IntParOut\n\ndef Proc8(Array1Par, Array2Par, IntParI1, IntParI2):\n    global IntGlob\n\n    IntLoc = IntParI1 + 5\n    Array1Par[IntLoc] = IntParI2\n    Array1Par[IntLoc+1] = Array1Par[IntLoc]\n    Array1Par[IntLoc+30] = IntLoc\n    for IntIndex in range(IntLoc, IntLoc+2):\n        Array2Par[IntLoc][IntIndex] = IntLoc\n    Array2Par[IntLoc][IntLoc-1] = Array2Par[IntLoc][IntLoc-1] + 1\n    Array2Par[IntLoc+20][IntLoc] = Array1Par[IntLoc]\n    IntGlob = 5\n\ndef Func1(CharPar1, CharPar2):\n    CharLoc1 = CharPar1\n    CharLoc2 = CharLoc1\n    if CharLoc2 != CharPar2:\n        return Ident1\n    else:\n        return Ident2\n\ndef Func2(StrParI1, StrParI2):\n    IntLoc = 1\n    while IntLoc <= 1:\n        if Func1(StrParI1[IntLoc], StrParI2[IntLoc+1]) == Ident1:\n            CharLoc = 'A'\n            IntLoc = IntLoc + 1\n    if CharLoc >= 'W' and CharLoc <= 'Z':\n        IntLoc = 7\n    if CharLoc == 'X':\n        return TRUE\n    else:\n        if StrParI1 > StrParI2:\n            IntLoc = IntLoc + 7\n            return TRUE\n        else:\n            return FALSE\n\ndef Func3(EnumParIn):\n    EnumLoc = EnumParIn\n    if EnumLoc == Ident3: return TRUE\n    return FALSE\n\nif __name__ == '__main__':\n    import sys\n    def error(msg):\n        print(msg, end=' ', file=sys.stderr)\n        print(\"usage: %s [number_of_loops]\" % sys.argv[0], file=sys.stderr)\n        sys.exit(100)\n    nargs = len(sys.argv) - 1\n    if nargs > 1:\n        error(\"%d arguments are too many;\" % nargs)\n    elif nargs == 1:\n        try: loops = int(sys.argv[1])\n        except ValueError:\n            error(\"Invalid argument %r;\" % sys.argv[1])\n    else:\n        loops = LOOPS\n    main(loops)\n"], "xml": [".py", "\"\"\"Core XML support for Python.\n\nThis package contains four sub-packages:\n\ndom -- The W3C Document Object Model.  This supports DOM Level 1 +\n       Namespaces.\n\nparsers -- Python wrappers for XML parsers (currently only supports Expat).\n\nsax -- The Simple API for XML, developed by XML-Dev, led by David\n       Megginson and ported to Python by Lars Marius Garshol.  This\n       supports the SAX 2 API.\n\netree -- The ElementTree XML library.  This is a subset of the full\n       ElementTree XML release.\n\n\"\"\"\n\n\n__all__ = [\"dom\", \"parsers\", \"sax\", \"etree\"]\n", 1], "_testcapi": [".py", "\nCHAR_MAX = 127\n\nCHAR_MIN = -128\n\nDBL_MAX = 1.7976931348623157e+308\n\nDBL_MIN = 2.2250738585072014e-308\n\nFLT_MAX = 3.4028234663852886e+38\n\nFLT_MIN = 1.1754943508222875e-38\n\nINT_MAX = 2147483647\n\nINT_MIN = -2147483648\n\nLLONG_MAX = 9223372036854775807\n\nLLONG_MIN = -9223372036854775808\n\nLONG_MAX = 2147483647\n\nLONG_MIN = -2147483648\n\nPY_SSIZE_T_MAX = 2147483647\n\nPY_SSIZE_T_MIN = -2147483648\n\nSHRT_MAX = 32767\n\nSHRT_MIN = -32768\n\nSIZEOF_PYGC_HEAD = 16\n\nUCHAR_MAX = 255\n\nUINT_MAX = 4294967295\n\nULLONG_MAX = 18446744073709551615\n\nULONG_MAX = 4294967295\n\nUSHRT_MAX = 65535\n\n__loader__ = \"<_frozen_importlib.ExtensionFileLoader object at 0x00C98DD0>\"\n\ndef _pending_threadfunc(*args,**kw):\n    pass\n\nclass _test_structmembersType(object):\n    pass\n\ndef _test_thread_state(*args,**kw):\n    pass\n\ndef argparsing(*args,**kw):\n    pass\n\ndef code_newempty(*args,**kw):\n    pass\n\ndef codec_incrementaldecoder(*args,**kw):\n    pass\n\ndef codec_incrementalencoder(*args,**kw):\n    pass\n\ndef crash_no_current_thread(*args,**kw):\n    pass\n\nclass error(Exception):\n    pass\n\ndef exception_print(*args,**kw):\n    pass\n\ndef getargs_B(*args,**kw):\n    pass\n\ndef getargs_H(*args,**kw):\n    pass\n\ndef getargs_I(*args,**kw):\n    pass\n\ndef getargs_K(*args,**kw):\n    pass\n\ndef getargs_L(*args,**kw):\n    pass\n\ndef getargs_Z(*args,**kw):\n    pass\n\ndef getargs_Z_hash(*args,**kw):\n    pass\n\ndef getargs_b(*args,**kw):\n    pass\n\ndef getargs_c(*args,**kw):\n    pass\n\ndef getargs_h(*args,**kw):\n    pass\n\ndef getargs_i(*args,**kw):\n    pass\n\ndef getargs_k(*args,**kw):\n    pass\n\ndef getargs_keyword_only(*args,**kw):\n    pass\n\ndef getargs_keywords(*args,**kw):\n    pass\n\ndef getargs_l(*args,**kw):\n    pass\n\ndef getargs_n(*args,**kw):\n    pass\n\ndef getargs_p(*args,**kw):\n    pass\n\ndef getargs_s(*args,**kw):\n    pass\n\ndef getargs_s_hash(*args,**kw):\n    pass\n\ndef getargs_s_star(*args,**kw):\n    pass\n\ndef getargs_tuple(*args,**kw):\n    pass\n\ndef getargs_u(*args,**kw):\n    pass\n\ndef getargs_u_hash(*args,**kw):\n    pass\n\ndef getargs_w_star(*args,**kw):\n    pass\n\ndef getargs_y(*args,**kw):\n    pass\n\ndef getargs_y_hash(*args,**kw):\n    pass\n\ndef getargs_y_star(*args,**kw):\n    pass\n\ndef getargs_z(*args,**kw):\n    pass\n\ndef getargs_z_hash(*args,**kw):\n    pass\n\ndef getargs_z_star(*args,**kw):\n    pass\n\nclass instancemethod(object):\n    pass\n\ndef make_exception_with_doc(*args,**kw):\n    pass\n\ndef make_memoryview_from_NULL_pointer(*args,**kw):\n    pass\n\ndef parse_tuple_and_keywords(*args,**kw):\n    pass\n\ndef pytime_object_to_time_t(*args,**kw):\n    pass\n\ndef pytime_object_to_timespec(*args,**kw):\n    pass\n\ndef pytime_object_to_timeval(*args,**kw):\n    pass\n\ndef raise_exception(*args,**kw):\n    pass\n\ndef raise_memoryerror(*args,**kw):\n    pass\n\ndef run_in_subinterp(*args,**kw):\n    pass\n\ndef set_exc_info(*args,**kw):\n    pass\n\ndef test_L_code(*args,**kw):\n    pass\n\ndef test_Z_code(*args,**kw):\n    pass\n\ndef test_capsule(*args,**kw):\n    pass\n\ndef test_config(*args,**kw):\n    pass\n\ndef test_datetime_capi(*args,**kw):\n    pass\n\ndef test_dict_iteration(*args,**kw):\n    pass\n\ndef test_empty_argparse(*args,**kw):\n    pass\n\ndef test_k_code(*args,**kw):\n    pass\n\ndef test_lazy_hash_inheritance(*args,**kw):\n    pass\n\ndef test_list_api(*args,**kw):\n    pass\n\ndef test_long_and_overflow(*args,**kw):\n    pass\n\ndef test_long_api(*args,**kw):\n    pass\n\ndef test_long_as_double(*args,**kw):\n    pass\n\ndef test_long_as_size_t(*args,**kw):\n    pass\n\ndef test_long_long_and_overflow(*args,**kw):\n    pass\n\ndef test_long_numbits(*args,**kw):\n    pass\n\ndef test_longlong_api(*args,**kw):\n    pass\n\ndef test_null_strings(*args,**kw):\n    pass\n\ndef test_s_code(*args,**kw):\n    pass\n\ndef test_string_from_format(*args,**kw):\n    pass\n\ndef test_string_to_double(*args,**kw):\n    pass\n\ndef test_u_code(*args,**kw):\n    pass\n\ndef test_unicode_compare_with_ascii(*args,**kw):\n    pass\n\ndef test_widechar(*args,**kw):\n    pass\n\ndef test_with_docstring(*args,**kw):\n    \"\"\"This is a pretty normal docstring.\"\"\"\n    pass\n\ndef traceback_print(*args,**kw):\n    pass\n\ndef unicode_aswidechar(*args,**kw):\n    pass\n\ndef unicode_aswidecharstring(*args,**kw):\n    pass\n\ndef unicode_encodedecimal(*args,**kw):\n    pass\n\ndef unicode_transformdecimaltoascii(*args,**kw):\n    pass\n"], "codecs": [".py", "\"\"\" codecs -- Python Codec Registry, API and helpers.\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"#\"\n\nimport builtins, sys\n\n### Registry and builtin stateless codec functions\n\ntry:\n    from _codecs import *\nexcept ImportError as why:\n    raise SystemError('Failed to load the builtin codecs: %s' % why)\n\n__all__ = [\"register\", \"lookup\", \"open\", \"EncodedFile\", \"BOM\", \"BOM_BE\",\n           \"BOM_LE\", \"BOM32_BE\", \"BOM32_LE\", \"BOM64_BE\", \"BOM64_LE\",\n           \"BOM_UTF8\", \"BOM_UTF16\", \"BOM_UTF16_LE\", \"BOM_UTF16_BE\",\n           \"BOM_UTF32\", \"BOM_UTF32_LE\", \"BOM_UTF32_BE\",\n           \"strict_errors\", \"ignore_errors\", \"replace_errors\",\n           \"xmlcharrefreplace_errors\",\n           \"register_error\", \"lookup_error\"]\n\n### Constants\n\n#\n# Byte Order Mark (BOM = ZERO WIDTH NO-BREAK SPACE = U+FEFF)\n# and its possible byte string values\n# for UTF8/UTF16/UTF32 output and little/big endian machines\n#\n\n# UTF-8\nBOM_UTF8 = b'\\xef\\xbb\\xbf'\n\n# UTF-16, little endian\nBOM_LE = BOM_UTF16_LE = b'\\xff\\xfe'\n\n# UTF-16, big endian\nBOM_BE = BOM_UTF16_BE = b'\\xfe\\xff'\n\n# UTF-32, little endian\nBOM_UTF32_LE = b'\\xff\\xfe\\x00\\x00'\n\n# UTF-32, big endian\nBOM_UTF32_BE = b'\\x00\\x00\\xfe\\xff'\n\nif sys.byteorder == 'little':\n\n    # UTF-16, native endianness\n    BOM = BOM_UTF16 = BOM_UTF16_LE\n\n    # UTF-32, native endianness\n    BOM_UTF32 = BOM_UTF32_LE\n\nelse:\n\n    # UTF-16, native endianness\n    BOM = BOM_UTF16 = BOM_UTF16_BE\n\n    # UTF-32, native endianness\n    BOM_UTF32 = BOM_UTF32_BE\n\n# Old broken names (don't use in new code)\nBOM32_LE = BOM_UTF16_LE\nBOM32_BE = BOM_UTF16_BE\nBOM64_LE = BOM_UTF32_LE\nBOM64_BE = BOM_UTF32_BE\n\n\n### Codec base classes (defining the API)\n\nclass CodecInfo(tuple):\n\n    def __new__(cls, encode, decode, streamreader=None, streamwriter=None,\n        incrementalencoder=None, incrementaldecoder=None, name=None):\n        self = tuple.__new__(cls, (encode, decode, streamreader, streamwriter))\n        self.name = name\n        self.encode = encode\n        self.decode = decode\n        self.incrementalencoder = incrementalencoder\n        self.incrementaldecoder = incrementaldecoder\n        self.streamwriter = streamwriter\n        self.streamreader = streamreader\n        return self\n\n    def __repr__(self):\n        return \"<%s.%s object for encoding %s at 0x%x>\" % \\\n                (self.__class__.__module__, self.__class__.__name__,\n                 self.name, id(self))\n\nclass Codec:\n\n    \"\"\" Defines the interface for stateless encoders/decoders.\n\n        The .encode()/.decode() methods may use different error\n        handling schemes by providing the errors argument. These\n        string values are predefined:\n\n         'strict' - raise a ValueError error (or a subclass)\n         'ignore' - ignore the character and continue with the next\n         'replace' - replace with a suitable replacement character;\n                    Python will use the official U+FFFD REPLACEMENT\n                    CHARACTER for the builtin Unicode codecs on\n                    decoding and '?' on encoding.\n         'surrogateescape' - replace with private codepoints U+DCnn.\n         'xmlcharrefreplace' - Replace with the appropriate XML\n                               character reference (only for encoding).\n         'backslashreplace'  - Replace with backslashed escape sequences\n                               (only for encoding).\n\n        The set of allowed values can be extended via register_error.\n\n    \"\"\"\n    def encode(self, input, errors='strict'):\n\n        \"\"\" Encodes the object input and returns a tuple (output\n            object, length consumed).\n\n            errors defines the error handling to apply. It defaults to\n            'strict' handling.\n\n            The method may not store state in the Codec instance. Use\n            StreamCodec for codecs which have to keep state in order to\n            make encoding/decoding efficient.\n\n            The encoder must be able to handle zero length input and\n            return an empty object of the output object type in this\n            situation.\n\n        \"\"\"\n        raise NotImplementedError\n\n    def decode(self, input, errors='strict'):\n\n        \"\"\" Decodes the object input and returns a tuple (output\n            object, length consumed).\n\n            input must be an object which provides the bf_getreadbuf\n            buffer slot. Python strings, buffer objects and memory\n            mapped files are examples of objects providing this slot.\n\n            errors defines the error handling to apply. It defaults to\n            'strict' handling.\n\n            The method may not store state in the Codec instance. Use\n            StreamCodec for codecs which have to keep state in order to\n            make encoding/decoding efficient.\n\n            The decoder must be able to handle zero length input and\n            return an empty object of the output object type in this\n            situation.\n\n        \"\"\"\n        raise NotImplementedError\n\nclass IncrementalEncoder(object):\n    \"\"\"\n    An IncrementalEncoder encodes an input in multiple steps. The input can\n    be passed piece by piece to the encode() method. The IncrementalEncoder\n    remembers the state of the encoding process between calls to encode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        \"\"\"\n        Creates an IncrementalEncoder instance.\n\n        The IncrementalEncoder may use different error handling schemes by\n        providing the errors keyword argument. See the module docstring\n        for a list of possible values.\n        \"\"\"\n        self.errors = errors\n        self.buffer = \"\"\n\n    def encode(self, input, final=False):\n        \"\"\"\n        Encodes input and returns the resulting object.\n        \"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"\n        Resets the encoder to the initial state.\n        \"\"\"\n\n    def getstate(self):\n        \"\"\"\n        Return the current state of the encoder.\n        \"\"\"\n        return 0\n\n    def setstate(self, state):\n        \"\"\"\n        Set the current state of the encoder. state must have been\n        returned by getstate().\n        \"\"\"\n\nclass BufferedIncrementalEncoder(IncrementalEncoder):\n    \"\"\"\n    This subclass of IncrementalEncoder can be used as the baseclass for an\n    incremental encoder if the encoder must keep some of the output in a\n    buffer between calls to encode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        IncrementalEncoder.__init__(self, errors)\n        # unencoded input that is kept between calls to encode()\n        self.buffer = \"\"\n\n    def _buffer_encode(self, input, errors, final):\n        # Overwrite this method in subclasses: It must encode input\n        # and return an (output, length consumed) tuple\n        raise NotImplementedError\n\n    def encode(self, input, final=False):\n        # encode input (taking the buffer into account)\n        data = self.buffer + input\n        (result, consumed) = self._buffer_encode(data, self.errors, final)\n        # keep unencoded input until the next call\n        self.buffer = data[consumed:]\n        return result\n\n    def reset(self):\n        IncrementalEncoder.reset(self)\n        self.buffer = \"\"\n\n    def getstate(self):\n        return self.buffer or 0\n\n    def setstate(self, state):\n        self.buffer = state or \"\"\n\nclass IncrementalDecoder(object):\n    \"\"\"\n    An IncrementalDecoder decodes an input in multiple steps. The input can\n    be passed piece by piece to the decode() method. The IncrementalDecoder\n    remembers the state of the decoding process between calls to decode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        \"\"\"\n        Create a IncrementalDecoder instance.\n\n        The IncrementalDecoder may use different error handling schemes by\n        providing the errors keyword argument. See the module docstring\n        for a list of possible values.\n        \"\"\"\n        self.errors = errors\n\n    def decode(self, input, final=False):\n        \"\"\"\n        Decode input and returns the resulting object.\n        \"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"\n        Reset the decoder to the initial state.\n        \"\"\"\n\n    def getstate(self):\n        \"\"\"\n        Return the current state of the decoder.\n\n        This must be a (buffered_input, additional_state_info) tuple.\n        buffered_input must be a bytes object containing bytes that\n        were passed to decode() that have not yet been converted.\n        additional_state_info must be a non-negative integer\n        representing the state of the decoder WITHOUT yet having\n        processed the contents of buffered_input.  In the initial state\n        and after reset(), getstate() must return (b\"\", 0).\n        \"\"\"\n        return (b\"\", 0)\n\n    def setstate(self, state):\n        \"\"\"\n        Set the current state of the decoder.\n\n        state must have been returned by getstate().  The effect of\n        setstate((b\"\", 0)) must be equivalent to reset().\n        \"\"\"\n\nclass BufferedIncrementalDecoder(IncrementalDecoder):\n    \"\"\"\n    This subclass of IncrementalDecoder can be used as the baseclass for an\n    incremental decoder if the decoder must be able to handle incomplete\n    byte sequences.\n    \"\"\"\n    def __init__(self, errors='strict'):\n        IncrementalDecoder.__init__(self, errors)\n        # undecoded input that is kept between calls to decode()\n        self.buffer = b\"\"\n\n    def _buffer_decode(self, input, errors, final):\n        # Overwrite this method in subclasses: It must decode input\n        # and return an (output, length consumed) tuple\n        raise NotImplementedError\n\n    def decode(self, input, final=False):\n        # decode input (taking the buffer into account)\n        data = self.buffer + input\n        (result, consumed) = self._buffer_decode(data, self.errors, final)\n        # keep undecoded input until the next call\n        self.buffer = data[consumed:]\n        return result\n\n    def reset(self):\n        IncrementalDecoder.reset(self)\n        self.buffer = b\"\"\n\n    def getstate(self):\n        # additional state info is always 0\n        return (self.buffer, 0)\n\n    def setstate(self, state):\n        # ignore additional state info\n        self.buffer = state[0]\n\n#\n# The StreamWriter and StreamReader class provide generic working\n# interfaces which can be used to implement new encoding submodules\n# very easily. See encodings/utf_8.py for an example on how this is\n# done.\n#\n\nclass StreamWriter(Codec):\n\n    def __init__(self, stream, errors='strict'):\n\n        \"\"\" Creates a StreamWriter instance.\n\n            stream must be a file-like object open for writing\n            (binary) data.\n\n            The StreamWriter may use different error handling\n            schemes by providing the errors keyword argument. These\n            parameters are predefined:\n\n             'strict' - raise a ValueError (or a subclass)\n             'ignore' - ignore the character and continue with the next\n             'replace'- replace with a suitable replacement character\n             'xmlcharrefreplace' - Replace with the appropriate XML\n                                   character reference.\n             'backslashreplace'  - Replace with backslashed escape\n                                   sequences (only for encoding).\n\n            The set of allowed parameter values can be extended via\n            register_error.\n        \"\"\"\n        self.stream = stream\n        self.errors = errors\n\n    def write(self, object):\n\n        \"\"\" Writes the object's contents encoded to self.stream.\n        \"\"\"\n        data, consumed = self.encode(object, self.errors)\n        self.stream.write(data)\n\n    def writelines(self, list):\n\n        \"\"\" Writes the concatenated list of strings to the stream\n            using .write().\n        \"\"\"\n        self.write(''.join(list))\n\n    def reset(self):\n\n        \"\"\" Flushes and resets the codec buffers used for keeping state.\n\n            Calling this method should ensure that the data on the\n            output is put into a clean state, that allows appending\n            of new fresh data without having to rescan the whole\n            stream to recover state.\n\n        \"\"\"\n        pass\n\n    def seek(self, offset, whence=0):\n        self.stream.seek(offset, whence)\n        if whence == 0 and offset == 0:\n            self.reset()\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamReader(Codec):\n\n    charbuffertype = str\n\n    def __init__(self, stream, errors='strict'):\n\n        \"\"\" Creates a StreamReader instance.\n\n            stream must be a file-like object open for reading\n            (binary) data.\n\n            The StreamReader may use different error handling\n            schemes by providing the errors keyword argument. These\n            parameters are predefined:\n\n             'strict' - raise a ValueError (or a subclass)\n             'ignore' - ignore the character and continue with the next\n             'replace'- replace with a suitable replacement character;\n\n            The set of allowed parameter values can be extended via\n            register_error.\n        \"\"\"\n        self.stream = stream\n        self.errors = errors\n        self.bytebuffer = b\"\"\n        self._empty_charbuffer = self.charbuffertype()\n        self.charbuffer = self._empty_charbuffer\n        self.linebuffer = None\n\n    def decode(self, input, errors='strict'):\n        raise NotImplementedError\n\n    def read(self, size=-1, chars=-1, firstline=False):\n\n        \"\"\" Decodes data from the stream self.stream and returns the\n            resulting object.\n\n            chars indicates the number of characters to read from the\n            stream. read() will never return more than chars\n            characters, but it might return less, if there are not enough\n            characters available.\n\n            size indicates the approximate maximum number of bytes to\n            read from the stream for decoding purposes. The decoder\n            can modify this setting as appropriate. The default value\n            -1 indicates to read and decode as much as possible.  size\n            is intended to prevent having to decode huge files in one\n            step.\n\n            If firstline is true, and a UnicodeDecodeError happens\n            after the first line terminator in the input only the first line\n            will be returned, the rest of the input will be kept until the\n            next call to read().\n\n            The method should use a greedy read strategy meaning that\n            it should read as much data as is allowed within the\n            definition of the encoding and the given size, e.g.  if\n            optional encoding endings or state markers are available\n            on the stream, these should be read too.\n        \"\"\"\n        # If we have lines cached, first merge them back into characters\n        if self.linebuffer:\n            self.charbuffer = self._empty_charbuffer.join(self.linebuffer)\n            self.linebuffer = None\n\n        # read until we get the required number of characters (if available)\n        while True:\n            # can the request be satisfied from the character buffer?\n            if chars < 0:\n                if size < 0:\n                    if self.charbuffer:\n                        break\n                elif len(self.charbuffer) >= size:\n                    break\n            else:\n                if len(self.charbuffer) >= chars:\n                    break\n            # we need more data\n            if size < 0:\n                newdata = self.stream.read()\n            else:\n                newdata = self.stream.read(size)\n            # decode bytes (those remaining from the last call included)\n            data = self.bytebuffer + newdata\n            try:\n                newchars, decodedbytes = self.decode(data, self.errors)\n            except UnicodeDecodeError as exc:\n                if firstline:\n                    newchars, decodedbytes = \\\n                        self.decode(data[:exc.start], self.errors)\n                    lines = newchars.splitlines(keepends=True)\n                    if len(lines)<=1:\n                        raise\n                else:\n                    raise\n            # keep undecoded bytes until the next call\n            self.bytebuffer = data[decodedbytes:]\n            # put new characters in the character buffer\n            self.charbuffer += newchars\n            # there was no data available\n            if not newdata:\n                break\n        if chars < 0:\n            # Return everything we've got\n            result = self.charbuffer\n            self.charbuffer = self._empty_charbuffer\n        else:\n            # Return the first chars characters\n            result = self.charbuffer[:chars]\n            self.charbuffer = self.charbuffer[chars:]\n        return result\n\n    def readline(self, size=None, keepends=True):\n\n        \"\"\" Read one line from the input stream and return the\n            decoded data.\n\n            size, if given, is passed as size argument to the\n            read() method.\n\n        \"\"\"\n        # If we have lines cached from an earlier read, return\n        # them unconditionally\n        if self.linebuffer:\n            line = self.linebuffer[0]\n            del self.linebuffer[0]\n            if len(self.linebuffer) == 1:\n                # revert to charbuffer mode; we might need more data\n                # next time\n                self.charbuffer = self.linebuffer[0]\n                self.linebuffer = None\n            if not keepends:\n                line = line.splitlines(keepends=False)[0]\n            return line\n\n        readsize = size or 72\n        line = self._empty_charbuffer\n        # If size is given, we call read() only once\n        while True:\n            data = self.read(readsize, firstline=True)\n            if data:\n                # If we're at a \"\\r\" read one extra character (which might\n                # be a \"\\n\") to get a proper line ending. If the stream is\n                # temporarily exhausted we return the wrong line ending.\n                if (isinstance(data, str) and data.endswith(\"\\r\")) or \\\n                   (isinstance(data, bytes) and data.endswith(b\"\\r\")):\n                    data += self.read(size=1, chars=1)\n\n            line += data\n            lines = line.splitlines(keepends=True)\n            if lines:\n                if len(lines) > 1:\n                    # More than one line result; the first line is a full line\n                    # to return\n                    line = lines[0]\n                    del lines[0]\n                    if len(lines) > 1:\n                        # cache the remaining lines\n                        lines[-1] += self.charbuffer\n                        self.linebuffer = lines\n                        self.charbuffer = None\n                    else:\n                        # only one remaining line, put it back into charbuffer\n                        self.charbuffer = lines[0] + self.charbuffer\n                    if not keepends:\n                        line = line.splitlines(keepends=False)[0]\n                    break\n                line0withend = lines[0]\n                line0withoutend = lines[0].splitlines(keepends=False)[0]\n                if line0withend != line0withoutend: # We really have a line end\n                    # Put the rest back together and keep it until the next call\n                    self.charbuffer = self._empty_charbuffer.join(lines[1:]) + \\\n                                      self.charbuffer\n                    if keepends:\n                        line = line0withend\n                    else:\n                        line = line0withoutend\n                    break\n            # we didn't get anything or this was our only try\n            if not data or size is not None:\n                if line and not keepends:\n                    line = line.splitlines(keepends=False)[0]\n                break\n            if readsize < 8000:\n                readsize *= 2\n        return line\n\n    def readlines(self, sizehint=None, keepends=True):\n\n        \"\"\" Read all lines available on the input stream\n            and return them as list of lines.\n\n            Line breaks are implemented using the codec's decoder\n            method and are included in the list entries.\n\n            sizehint, if given, is ignored since there is no efficient\n            way to finding the true end-of-line.\n\n        \"\"\"\n        data = self.read()\n        return data.splitlines(keepends)\n\n    def reset(self):\n\n        \"\"\" Resets the codec buffers used for keeping state.\n\n            Note that no stream repositioning should take place.\n            This method is primarily intended to be able to recover\n            from decoding errors.\n\n        \"\"\"\n        self.bytebuffer = b\"\"\n        self.charbuffer = self._empty_charbuffer\n        self.linebuffer = None\n\n    def seek(self, offset, whence=0):\n        \"\"\" Set the input stream's current position.\n\n            Resets the codec buffers used for keeping state.\n        \"\"\"\n        self.stream.seek(offset, whence)\n        self.reset()\n\n    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        line = self.readline()\n        if line:\n            return line\n        raise StopIteration\n\n    def __iter__(self):\n        return self\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamReaderWriter:\n\n    \"\"\" StreamReaderWriter instances allow wrapping streams which\n        work in both read and write modes.\n\n        The design is such that one can use the factory functions\n        returned by the codec.lookup() function to construct the\n        instance.\n\n    \"\"\"\n    # Optional attributes set by the file wrappers below\n    encoding = 'unknown'\n\n    def __init__(self, stream, Reader, Writer, errors='strict'):\n\n        \"\"\" Creates a StreamReaderWriter instance.\n\n            stream must be a Stream-like object.\n\n            Reader, Writer must be factory functions or classes\n            providing the StreamReader, StreamWriter interface resp.\n\n            Error handling is done in the same way as defined for the\n            StreamWriter/Readers.\n\n        \"\"\"\n        self.stream = stream\n        self.reader = Reader(stream, errors)\n        self.writer = Writer(stream, errors)\n        self.errors = errors\n\n    def read(self, size=-1):\n\n        return self.reader.read(size)\n\n    def readline(self, size=None):\n\n        return self.reader.readline(size)\n\n    def readlines(self, sizehint=None):\n\n        return self.reader.readlines(sizehint)\n\n    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        return next(self.reader)\n\n    def __iter__(self):\n        return self\n\n    def write(self, data):\n\n        return self.writer.write(data)\n\n    def writelines(self, list):\n\n        return self.writer.writelines(list)\n\n    def reset(self):\n\n        self.reader.reset()\n        self.writer.reset()\n\n    def seek(self, offset, whence=0):\n        self.stream.seek(offset, whence)\n        self.reader.reset()\n        if whence == 0 and offset == 0:\n            self.writer.reset()\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    # these are needed to make \"with codecs.open(...)\" work properly\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamRecoder:\n\n    \"\"\" StreamRecoder instances provide a frontend - backend\n        view of encoding data.\n\n        They use the complete set of APIs returned by the\n        codecs.lookup() function to implement their task.\n\n        Data written to the stream is first decoded into an\n        intermediate format (which is dependent on the given codec\n        combination) and then written to the stream using an instance\n        of the provided Writer class.\n\n        In the other direction, data is read from the stream using a\n        Reader instance and then return encoded data to the caller.\n\n    \"\"\"\n    # Optional attributes set by the file wrappers below\n    data_encoding = 'unknown'\n    file_encoding = 'unknown'\n\n    def __init__(self, stream, encode, decode, Reader, Writer,\n                 errors='strict'):\n\n        \"\"\" Creates a StreamRecoder instance which implements a two-way\n            conversion: encode and decode work on the frontend (the\n            input to .read() and output of .write()) while\n            Reader and Writer work on the backend (reading and\n            writing to the stream).\n\n            You can use these objects to do transparent direct\n            recodings from e.g. latin-1 to utf-8 and back.\n\n            stream must be a file-like object.\n\n            encode, decode must adhere to the Codec interface, Reader,\n            Writer must be factory functions or classes providing the\n            StreamReader, StreamWriter interface resp.\n\n            encode and decode are needed for the frontend translation,\n            Reader and Writer for the backend translation. Unicode is\n            used as intermediate encoding.\n\n            Error handling is done in the same way as defined for the\n            StreamWriter/Readers.\n\n        \"\"\"\n        self.stream = stream\n        self.encode = encode\n        self.decode = decode\n        self.reader = Reader(stream, errors)\n        self.writer = Writer(stream, errors)\n        self.errors = errors\n\n    def read(self, size=-1):\n\n        data = self.reader.read(size)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def readline(self, size=None):\n\n        if size is None:\n            data = self.reader.readline()\n        else:\n            data = self.reader.readline(size)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def readlines(self, sizehint=None):\n\n        data = self.reader.read()\n        data, bytesencoded = self.encode(data, self.errors)\n        return data.splitlines(keepends=True)\n\n    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        data = next(self.reader)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def __iter__(self):\n        return self\n\n    def write(self, data):\n\n        data, bytesdecoded = self.decode(data, self.errors)\n        return self.writer.write(data)\n\n    def writelines(self, list):\n\n        data = ''.join(list)\n        data, bytesdecoded = self.decode(data, self.errors)\n        return self.writer.write(data)\n\n    def reset(self):\n\n        self.reader.reset()\n        self.writer.reset()\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n### Shortcuts\n\ndef open(filename, mode='rb', encoding=None, errors='strict', buffering=1):\n\n    \"\"\" Open an encoded file using the given mode and return\n        a wrapped version providing transparent encoding/decoding.\n\n        Note: The wrapped version will only accept the object format\n        defined by the codecs, i.e. Unicode objects for most builtin\n        codecs. Output is also codec dependent and will usually be\n        Unicode as well.\n\n        Files are always opened in binary mode, even if no binary mode\n        was specified. This is done to avoid data loss due to encodings\n        using 8-bit values. The default file mode is 'rb' meaning to\n        open the file in binary read mode.\n\n        encoding specifies the encoding which is to be used for the\n        file.\n\n        errors may be given to define the error handling. It defaults\n        to 'strict' which causes ValueErrors to be raised in case an\n        encoding error occurs.\n\n        buffering has the same meaning as for the builtin open() API.\n        It defaults to line buffered.\n\n        The returned wrapped file object provides an extra attribute\n        .encoding which allows querying the used encoding. This\n        attribute is only available if an encoding was specified as\n        parameter.\n\n    \"\"\"\n    if encoding is not None and \\\n       'b' not in mode:\n        # Force opening of the file in binary mode\n        mode = mode + 'b'\n    file = builtins.open(filename, mode, buffering)\n    if encoding is None:\n        return file\n    info = lookup(encoding)\n    srw = StreamReaderWriter(file, info.streamreader, info.streamwriter, errors)\n    # Add attributes to simplify introspection\n    srw.encoding = encoding\n    return srw\n\ndef EncodedFile(file, data_encoding, file_encoding=None, errors='strict'):\n\n    \"\"\" Return a wrapped version of file which provides transparent\n        encoding translation.\n\n        Strings written to the wrapped file are interpreted according\n        to the given data_encoding and then written to the original\n        file as string using file_encoding. The intermediate encoding\n        will usually be Unicode but depends on the specified codecs.\n\n        Strings are read from the file using file_encoding and then\n        passed back to the caller as string using data_encoding.\n\n        If file_encoding is not given, it defaults to data_encoding.\n\n        errors may be given to define the error handling. It defaults\n        to 'strict' which causes ValueErrors to be raised in case an\n        encoding error occurs.\n\n        The returned wrapped file object provides two extra attributes\n        .data_encoding and .file_encoding which reflect the given\n        parameters of the same name. The attributes can be used for\n        introspection by Python programs.\n\n    \"\"\"\n    if file_encoding is None:\n        file_encoding = data_encoding\n    data_info = lookup(data_encoding)\n    file_info = lookup(file_encoding)\n    sr = StreamRecoder(file, data_info.encode, data_info.decode,\n                       file_info.streamreader, file_info.streamwriter, errors)\n    # Add attributes to simplify introspection\n    sr.data_encoding = data_encoding\n    sr.file_encoding = file_encoding\n    return sr\n\n### Helpers for codec lookup\n\ndef getencoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its encoder function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).encode\n\ndef getdecoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its decoder function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).decode\n\ndef getincrementalencoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its IncrementalEncoder class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found\n        or the codecs doesn't provide an incremental encoder.\n\n    \"\"\"\n    encoder = lookup(encoding).incrementalencoder\n    if encoder is None:\n        raise LookupError(encoding)\n    return encoder\n\ndef getincrementaldecoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its IncrementalDecoder class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found\n        or the codecs doesn't provide an incremental decoder.\n\n    \"\"\"\n    decoder = lookup(encoding).incrementaldecoder\n    if decoder is None:\n        raise LookupError(encoding)\n    return decoder\n\ndef getreader(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its StreamReader class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).streamreader\n\ndef getwriter(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its StreamWriter class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).streamwriter\n\ndef iterencode(iterator, encoding, errors='strict', **kwargs):\n    \"\"\"\n    Encoding iterator.\n\n    Encodes the input strings from the iterator using a IncrementalEncoder.\n\n    errors and kwargs are passed through to the IncrementalEncoder\n    constructor.\n    \"\"\"\n    encoder = getincrementalencoder(encoding)(errors, **kwargs)\n    for input in iterator:\n        output = encoder.encode(input)\n        if output:\n            yield output\n    output = encoder.encode(\"\", True)\n    if output:\n        yield output\n\ndef iterdecode(iterator, encoding, errors='strict', **kwargs):\n    \"\"\"\n    Decoding iterator.\n\n    Decodes the input strings from the iterator using a IncrementalDecoder.\n\n    errors and kwargs are passed through to the IncrementalDecoder\n    constructor.\n    \"\"\"\n    decoder = getincrementaldecoder(encoding)(errors, **kwargs)\n    for input in iterator:\n        output = decoder.decode(input)\n        if output:\n            yield output\n    output = decoder.decode(b\"\", True)\n    if output:\n        yield output\n\n### Helpers for charmap-based codecs\n\ndef make_identity_dict(rng):\n\n    \"\"\" make_identity_dict(rng) -> dict\n\n        Return a dictionary where elements of the rng sequence are\n        mapped to themselves.\n\n    \"\"\"\n    return {i:i for i in rng}\n\ndef make_encoding_map(decoding_map):\n\n    \"\"\" Creates an encoding map from a decoding map.\n\n        If a target mapping in the decoding map occurs multiple\n        times, then that target is mapped to None (undefined mapping),\n        causing an exception when encountered by the charmap codec\n        during translation.\n\n        One example where this happens is cp875.py which decodes\n        multiple character to \\u001a.\n\n    \"\"\"\n    m = {}\n    for k,v in decoding_map.items():\n        if not v in m:\n            m[v] = k\n        else:\n            m[v] = None\n    return m\n\n### error handlers\n\ntry:\n    strict_errors = lookup_error(\"strict\")\n    ignore_errors = lookup_error(\"ignore\")\n    replace_errors = lookup_error(\"replace\")\n    xmlcharrefreplace_errors = lookup_error(\"xmlcharrefreplace\")\n    backslashreplace_errors = lookup_error(\"backslashreplace\")\nexcept LookupError:\n    # In --disable-unicode builds, these error handler are missing\n    strict_errors = None\n    ignore_errors = None\n    replace_errors = None\n    xmlcharrefreplace_errors = None\n    backslashreplace_errors = None\n\n# Tell modulefinder that using codecs probably needs the encodings\n# package\n_false = 0\nif _false:\n    import encodings\n\n### Tests\n\nif __name__ == '__main__':\n\n    # Make stdout translate Latin-1 output into UTF-8 output\n    sys.stdout = EncodedFile(sys.stdout, 'latin-1', 'utf-8')\n\n    # Have stdin translate Latin-1 input into UTF-8 input\n    sys.stdin = EncodedFile(sys.stdin, 'utf-8', 'latin-1')\n"], "unittest.runner": [".py", "\"\"\"Running tests\"\"\"\n\nimport sys\nimport time\nimport warnings\n\nfrom . import result\nfrom .signals import registerResult\n\n__unittest = True\n\n\nclass _WritelnDecorator(object):\n    \"\"\"Used to decorate file-like objects with a handy 'writeln' method\"\"\"\n    def __init__(self,stream):\n        self.stream = stream\n\n    def __getattr__(self, attr):\n        if attr in ('stream', '__getstate__'):\n            raise AttributeError(attr)\n        return getattr(self.stream,attr)\n\n    def writeln(self, arg=None):\n        if arg:\n            self.write(arg)\n        self.write('\\n') # text-mode streams translate to \\r\\n if needed\n\n\nclass TextTestResult(result.TestResult):\n    \"\"\"A test result class that can print formatted text results to a stream.\n\n    Used by TextTestRunner.\n    \"\"\"\n    separator1 = '=' * 70\n    separator2 = '-' * 70\n\n    def __init__(self, stream, descriptions, verbosity):\n        super(TextTestResult, self).__init__(stream, descriptions, verbosity)\n        self.stream = stream\n        self.showAll = verbosity > 1\n        self.dots = verbosity == 1\n        self.descriptions = descriptions\n\n    def getDescription(self, test):\n        doc_first_line = test.shortDescription()\n        if self.descriptions and doc_first_line:\n            return '\\n'.join((str(test), doc_first_line))\n        else:\n            return str(test)\n\n    def startTest(self, test):\n        super(TextTestResult, self).startTest(test)\n        if self.showAll:\n            self.stream.write(self.getDescription(test))\n            self.stream.write(\" ... \")\n            self.stream.flush()\n\n    def addSuccess(self, test):\n        super(TextTestResult, self).addSuccess(test)\n        if self.showAll:\n            self.stream.writeln(\"ok\")\n        elif self.dots:\n            self.stream.write('.')\n            self.stream.flush()\n\n    def addError(self, test, err):\n        super(TextTestResult, self).addError(test, err)\n        if self.showAll:\n            self.stream.writeln(\"ERROR\")\n        elif self.dots:\n            self.stream.write('E')\n            self.stream.flush()\n\n    def addFailure(self, test, err):\n        super(TextTestResult, self).addFailure(test, err)\n        if self.showAll:\n            self.stream.writeln(\"FAIL\")\n        elif self.dots:\n            self.stream.write('F')\n            self.stream.flush()\n\n    def addSkip(self, test, reason):\n        super(TextTestResult, self).addSkip(test, reason)\n        if self.showAll:\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\n        elif self.dots:\n            self.stream.write(\"s\")\n            self.stream.flush()\n\n    def addExpectedFailure(self, test, err):\n        super(TextTestResult, self).addExpectedFailure(test, err)\n        if self.showAll:\n            self.stream.writeln(\"expected failure\")\n        elif self.dots:\n            self.stream.write(\"x\")\n            self.stream.flush()\n\n    def addUnexpectedSuccess(self, test):\n        super(TextTestResult, self).addUnexpectedSuccess(test)\n        if self.showAll:\n            self.stream.writeln(\"unexpected success\")\n        elif self.dots:\n            self.stream.write(\"u\")\n            self.stream.flush()\n\n    def printErrors(self):\n        if self.dots or self.showAll:\n            self.stream.writeln()\n        self.printErrorList('ERROR', self.errors)\n        self.printErrorList('FAIL', self.failures)\n\n    def printErrorList(self, flavour, errors):\n        for test, err in errors:\n            self.stream.writeln(self.separator1)\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\n            self.stream.writeln(self.separator2)\n            self.stream.writeln(\"%s\" % err)\n\n\nclass TextTestRunner(object):\n    \"\"\"A test runner class that displays results in textual form.\n\n    It prints out the names of tests as they are run, errors as they\n    occur, and a summary of the results at the end of the test run.\n    \"\"\"\n    resultclass = TextTestResult\n\n    def __init__(self, stream=None, descriptions=True, verbosity=1,\n                 failfast=False, buffer=False, resultclass=None, warnings=None):\n        if stream is None:\n            stream = sys.stderr\n        self.stream = _WritelnDecorator(stream)\n        self.descriptions = descriptions\n        self.verbosity = verbosity\n        self.failfast = failfast\n        self.buffer = buffer\n        self.warnings = warnings\n        if resultclass is not None:\n            self.resultclass = resultclass\n\n    def _makeResult(self):\n        return self.resultclass(self.stream, self.descriptions, self.verbosity)\n\n    def run(self, test):\n        \"Run the given test case or test suite.\"\n        result = self._makeResult()\n        registerResult(result)\n        result.failfast = self.failfast\n        result.buffer = self.buffer\n        with warnings.catch_warnings():\n\n            if self.warnings:\n                # if self.warnings is set, use it to filter all the warnings\n                warnings.simplefilter(self.warnings)\n                # if the filter is 'default' or 'always', special-case the\n                # warnings from the deprecated unittest methods to show them\n                # no more than once per module, because they can be fairly\n                # noisy.  The -Wd and -Wa flags can be used to bypass this\n                # only when self.warnings is None.\n                if self.warnings in ['default', 'always']:\n                    warnings.filterwarnings('module',\n                            category=DeprecationWarning,\n                            message='Please use assert\\w+ instead.')\n            startTime = time.time()\n            startTestRun = getattr(result, 'startTestRun', None)\n            if startTestRun is not None:\n                startTestRun()\n            try:\n                test(result)\n            finally:\n                stopTestRun = getattr(result, 'stopTestRun', None)\n                if stopTestRun is not None:\n                    stopTestRun()\n            stopTime = time.time()\n        timeTaken = stopTime - startTime\n        result.printErrors()\n        if hasattr(result, 'separator2'):\n            self.stream.writeln(result.separator2)\n        run = result.testsRun\n        self.stream.writeln(\"Ran %d test%s in %.3fs\" %\n                            (run, run != 1 and \"s\" or \"\", timeTaken))\n        self.stream.writeln()\n\n        expectedFails = unexpectedSuccesses = skipped = 0\n        try:\n            results = map(len, (result.expectedFailures,\n                                result.unexpectedSuccesses,\n                                result.skipped))\n        except AttributeError:\n            pass\n        else:\n            expectedFails, unexpectedSuccesses, skipped = results\n\n        infos = []\n        if not result.wasSuccessful():\n            self.stream.write(\"FAILED\")\n            failed, errored = len(result.failures), len(result.errors)\n            if failed:\n                infos.append(\"failures=%d\" % failed)\n            if errored:\n                infos.append(\"errors=%d\" % errored)\n        else:\n            self.stream.write(\"OK\")\n        if skipped:\n            infos.append(\"skipped=%d\" % skipped)\n        if expectedFails:\n            infos.append(\"expected failures=%d\" % expectedFails)\n        if unexpectedSuccesses:\n            infos.append(\"unexpected successes=%d\" % unexpectedSuccesses)\n        if infos:\n            self.stream.writeln(\" (%s)\" % (\", \".join(infos),))\n        else:\n            self.stream.write(\"\\n\")\n        return result\n"], "unittest.signals": [".py", "import signal\nimport weakref\n\nfrom functools import wraps\n\n__unittest = True\n\n\nclass _InterruptHandler(object):\n    def __init__(self, default_handler):\n        self.called = False\n        self.original_handler = default_handler\n        if isinstance(default_handler, int):\n            if default_handler == signal.SIG_DFL:\n                # Pretend it's signal.default_int_handler instead.\n                default_handler = signal.default_int_handler\n            elif default_handler == signal.SIG_IGN:\n                # Not quite the same thing as SIG_IGN, but the closest we\n                # can make it: do nothing.\n                def default_handler(unused_signum, unused_frame):\n                    pass\n            else:\n                raise TypeError(\"expected SIGINT signal handler to be \"\n                                \"signal.SIG_IGN, signal.SIG_DFL, or a \"\n                                \"callable object\")\n        self.default_handler = default_handler\n\n    def __call__(self, signum, frame):\n        installed_handler = signal.getsignal(signal.SIGINT)\n        if installed_handler is not self:\n            # if we aren't the installed handler, then delegate immediately\n            # to the default handler\n            self.default_handler(signum, frame)\n\n        if self.called:\n            self.default_handler(signum, frame)\n        self.called = True\n        for result in _results.keys():\n            result.stop()\n\n_results = weakref.WeakKeyDictionary()\ndef registerResult(result):\n    _results[result] = 1\n\ndef removeResult(result):\n    return bool(_results.pop(result, None))\n\n_interrupt_handler = None\ndef installHandler():\n    global _interrupt_handler\n    if _interrupt_handler is None:\n        default_handler = signal.getsignal(signal.SIGINT)\n        _interrupt_handler = _InterruptHandler(default_handler)\n        signal.signal(signal.SIGINT, _interrupt_handler)\n\n\ndef removeHandler(method=None):\n    if method is not None:\n        @wraps(method)\n        def inner(*args, **kwargs):\n            initial = signal.getsignal(signal.SIGINT)\n            removeHandler()\n            try:\n                return method(*args, **kwargs)\n            finally:\n                signal.signal(signal.SIGINT, initial)\n        return inner\n\n    global _interrupt_handler\n    if _interrupt_handler is not None:\n        signal.signal(signal.SIGINT, _interrupt_handler.original_handler)\n"], "browser.ajax": [".py", "from _ajax import *"], "http.cookies": [".py", "#!/usr/bin/env python3\n#\n\n####\n# Copyright 2000 by Timothy O'Malley <timo@alum.mit.edu>\n#\n#                All Rights Reserved\n#\n# Permission to use, copy, modify, and distribute this software\n# and its documentation for any purpose and without fee is hereby\n# granted, provided that the above copyright notice appear in all\n# copies and that both that copyright notice and this permission\n# notice appear in supporting documentation, and that the name of\n# Timothy O'Malley  not be used in advertising or publicity\n# pertaining to distribution of the software without specific, written\n# prior permission.\n#\n# Timothy O'Malley DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS\n# SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\n# AND FITNESS, IN NO EVENT SHALL Timothy O'Malley BE LIABLE FOR\n# ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,\n# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\n# PERFORMANCE OF THIS SOFTWARE.\n#\n####\n#\n# Id: Cookie.py,v 2.29 2000/08/23 05:28:49 timo Exp\n#   by Timothy O'Malley <timo@alum.mit.edu>\n#\n#  Cookie.py is a Python module for the handling of HTTP\n#  cookies as a Python dictionary.  See RFC 2109 for more\n#  information on cookies.\n#\n#  The original idea to treat Cookies as a dictionary came from\n#  Dave Mitchell (davem@magnet.com) in 1995, when he released the\n#  first version of nscookie.py.\n#\n####\n\nr\"\"\"\nHere's a sample session to show how to use this module.\nAt the moment, this is the only documentation.\n\nThe Basics\n----------\n\nImporting is easy...\n\n   >>> from http import cookies\n\nMost of the time you start by creating a cookie.\n\n   >>> C = cookies.SimpleCookie()\n\nOnce you've created your Cookie, you can add values just as if it were\na dictionary.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C[\"fig\"] = \"newton\"\n   >>> C[\"sugar\"] = \"wafer\"\n   >>> C.output()\n   'Set-Cookie: fig=newton\\r\\nSet-Cookie: sugar=wafer'\n\nNotice that the printable representation of a Cookie is the\nappropriate format for a Set-Cookie: header.  This is the\ndefault behavior.  You can change the header and printed\nattributes by using the .output() function\n\n   >>> C = cookies.SimpleCookie()\n   >>> C[\"rocky\"] = \"road\"\n   >>> C[\"rocky\"][\"path\"] = \"/cookie\"\n   >>> print(C.output(header=\"Cookie:\"))\n   Cookie: rocky=road; Path=/cookie\n   >>> print(C.output(attrs=[], header=\"Cookie:\"))\n   Cookie: rocky=road\n\nThe load() method of a Cookie extracts cookies from a string.  In a\nCGI script, you would use this method to extract the cookies from the\nHTTP_COOKIE environment variable.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C.load(\"chips=ahoy; vienna=finger\")\n   >>> C.output()\n   'Set-Cookie: chips=ahoy\\r\\nSet-Cookie: vienna=finger'\n\nThe load() method is darn-tootin smart about identifying cookies\nwithin a string.  Escaped quotation marks, nested semicolons, and other\nsuch trickeries do not confuse it.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C.load('keebler=\"E=everybody; L=\\\\\"Loves\\\\\"; fudge=\\\\012;\";')\n   >>> print(C)\n   Set-Cookie: keebler=\"E=everybody; L=\\\"Loves\\\"; fudge=\\012;\"\n\nEach element of the Cookie also supports all of the RFC 2109\nCookie attributes.  Here's an example which sets the Path\nattribute.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C[\"oreo\"] = \"doublestuff\"\n   >>> C[\"oreo\"][\"path\"] = \"/\"\n   >>> print(C)\n   Set-Cookie: oreo=doublestuff; Path=/\n\nEach dictionary element has a 'value' attribute, which gives you\nback the value associated with the key.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C[\"twix\"] = \"none for you\"\n   >>> C[\"twix\"].value\n   'none for you'\n\nThe SimpleCookie expects that all values should be standard strings.\nJust to be sure, SimpleCookie invokes the str() builtin to convert\nthe value to a string, when the values are set dictionary-style.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C[\"number\"] = 7\n   >>> C[\"string\"] = \"seven\"\n   >>> C[\"number\"].value\n   '7'\n   >>> C[\"string\"].value\n   'seven'\n   >>> C.output()\n   'Set-Cookie: number=7\\r\\nSet-Cookie: string=seven'\n\nFinis.\n\"\"\"\n\n#\n# Import our required modules\n#\nimport re\nimport string\n\n__all__ = [\"CookieError\", \"BaseCookie\", \"SimpleCookie\"]\n\n_nulljoin = ''.join\n_semispacejoin = '; '.join\n_spacejoin = ' '.join\n\n#\n# Define an exception visible to External modules\n#\nclass CookieError(Exception):\n    pass\n\n\n# These quoting routines conform to the RFC2109 specification, which in\n# turn references the character definitions from RFC2068.  They provide\n# a two-way quoting algorithm.  Any non-text character is translated\n# into a 4 character sequence: a forward-slash followed by the\n# three-digit octal equivalent of the character.  Any '\\' or '\"' is\n# quoted with a preceeding '\\' slash.\n#\n# These are taken from RFC2068 and RFC2109.\n#       _LegalChars       is the list of chars which don't require \"'s\n#       _Translator       hash-table for fast quoting\n#\n_LegalChars       = string.ascii_letters + string.digits + \"!#$%&'*+-.^_`|~:\"\n_Translator       = {\n    '\\000' : '\\\\000',  '\\001' : '\\\\001',  '\\002' : '\\\\002',\n    '\\003' : '\\\\003',  '\\004' : '\\\\004',  '\\005' : '\\\\005',\n    '\\006' : '\\\\006',  '\\007' : '\\\\007',  '\\010' : '\\\\010',\n    '\\011' : '\\\\011',  '\\012' : '\\\\012',  '\\013' : '\\\\013',\n    '\\014' : '\\\\014',  '\\015' : '\\\\015',  '\\016' : '\\\\016',\n    '\\017' : '\\\\017',  '\\020' : '\\\\020',  '\\021' : '\\\\021',\n    '\\022' : '\\\\022',  '\\023' : '\\\\023',  '\\024' : '\\\\024',\n    '\\025' : '\\\\025',  '\\026' : '\\\\026',  '\\027' : '\\\\027',\n    '\\030' : '\\\\030',  '\\031' : '\\\\031',  '\\032' : '\\\\032',\n    '\\033' : '\\\\033',  '\\034' : '\\\\034',  '\\035' : '\\\\035',\n    '\\036' : '\\\\036',  '\\037' : '\\\\037',\n\n    # Because of the way browsers really handle cookies (as opposed\n    # to what the RFC says) we also encode , and ;\n\n    ',' : '\\\\054', ';' : '\\\\073',\n\n    '\"' : '\\\\\"',       '\\\\' : '\\\\\\\\',\n\n    '\\177' : '\\\\177',  '\\200' : '\\\\200',  '\\201' : '\\\\201',\n    '\\202' : '\\\\202',  '\\203' : '\\\\203',  '\\204' : '\\\\204',\n    '\\205' : '\\\\205',  '\\206' : '\\\\206',  '\\207' : '\\\\207',\n    '\\210' : '\\\\210',  '\\211' : '\\\\211',  '\\212' : '\\\\212',\n    '\\213' : '\\\\213',  '\\214' : '\\\\214',  '\\215' : '\\\\215',\n    '\\216' : '\\\\216',  '\\217' : '\\\\217',  '\\220' : '\\\\220',\n    '\\221' : '\\\\221',  '\\222' : '\\\\222',  '\\223' : '\\\\223',\n    '\\224' : '\\\\224',  '\\225' : '\\\\225',  '\\226' : '\\\\226',\n    '\\227' : '\\\\227',  '\\230' : '\\\\230',  '\\231' : '\\\\231',\n    '\\232' : '\\\\232',  '\\233' : '\\\\233',  '\\234' : '\\\\234',\n    '\\235' : '\\\\235',  '\\236' : '\\\\236',  '\\237' : '\\\\237',\n    '\\240' : '\\\\240',  '\\241' : '\\\\241',  '\\242' : '\\\\242',\n    '\\243' : '\\\\243',  '\\244' : '\\\\244',  '\\245' : '\\\\245',\n    '\\246' : '\\\\246',  '\\247' : '\\\\247',  '\\250' : '\\\\250',\n    '\\251' : '\\\\251',  '\\252' : '\\\\252',  '\\253' : '\\\\253',\n    '\\254' : '\\\\254',  '\\255' : '\\\\255',  '\\256' : '\\\\256',\n    '\\257' : '\\\\257',  '\\260' : '\\\\260',  '\\261' : '\\\\261',\n    '\\262' : '\\\\262',  '\\263' : '\\\\263',  '\\264' : '\\\\264',\n    '\\265' : '\\\\265',  '\\266' : '\\\\266',  '\\267' : '\\\\267',\n    '\\270' : '\\\\270',  '\\271' : '\\\\271',  '\\272' : '\\\\272',\n    '\\273' : '\\\\273',  '\\274' : '\\\\274',  '\\275' : '\\\\275',\n    '\\276' : '\\\\276',  '\\277' : '\\\\277',  '\\300' : '\\\\300',\n    '\\301' : '\\\\301',  '\\302' : '\\\\302',  '\\303' : '\\\\303',\n    '\\304' : '\\\\304',  '\\305' : '\\\\305',  '\\306' : '\\\\306',\n    '\\307' : '\\\\307',  '\\310' : '\\\\310',  '\\311' : '\\\\311',\n    '\\312' : '\\\\312',  '\\313' : '\\\\313',  '\\314' : '\\\\314',\n    '\\315' : '\\\\315',  '\\316' : '\\\\316',  '\\317' : '\\\\317',\n    '\\320' : '\\\\320',  '\\321' : '\\\\321',  '\\322' : '\\\\322',\n    '\\323' : '\\\\323',  '\\324' : '\\\\324',  '\\325' : '\\\\325',\n    '\\326' : '\\\\326',  '\\327' : '\\\\327',  '\\330' : '\\\\330',\n    '\\331' : '\\\\331',  '\\332' : '\\\\332',  '\\333' : '\\\\333',\n    '\\334' : '\\\\334',  '\\335' : '\\\\335',  '\\336' : '\\\\336',\n    '\\337' : '\\\\337',  '\\340' : '\\\\340',  '\\341' : '\\\\341',\n    '\\342' : '\\\\342',  '\\343' : '\\\\343',  '\\344' : '\\\\344',\n    '\\345' : '\\\\345',  '\\346' : '\\\\346',  '\\347' : '\\\\347',\n    '\\350' : '\\\\350',  '\\351' : '\\\\351',  '\\352' : '\\\\352',\n    '\\353' : '\\\\353',  '\\354' : '\\\\354',  '\\355' : '\\\\355',\n    '\\356' : '\\\\356',  '\\357' : '\\\\357',  '\\360' : '\\\\360',\n    '\\361' : '\\\\361',  '\\362' : '\\\\362',  '\\363' : '\\\\363',\n    '\\364' : '\\\\364',  '\\365' : '\\\\365',  '\\366' : '\\\\366',\n    '\\367' : '\\\\367',  '\\370' : '\\\\370',  '\\371' : '\\\\371',\n    '\\372' : '\\\\372',  '\\373' : '\\\\373',  '\\374' : '\\\\374',\n    '\\375' : '\\\\375',  '\\376' : '\\\\376',  '\\377' : '\\\\377'\n    }\n\ndef _quote(str, LegalChars=_LegalChars):\n    r\"\"\"Quote a string for use in a cookie header.\n\n    If the string does not need to be double-quoted, then just return the\n    string.  Otherwise, surround the string in doublequotes and quote\n    (with a \\) special characters.\n    \"\"\"\n    if all(c in LegalChars for c in str):\n        return str\n    else:\n        return '\"' + _nulljoin(_Translator.get(s, s) for s in str) + '\"'\n\n\n_OctalPatt = re.compile(r\"\\\\[0-3][0-7][0-7]\")\n_QuotePatt = re.compile(r\"[\\\\].\")\n\ndef _unquote(str):\n    # If there aren't any doublequotes,\n    # then there can't be any special characters.  See RFC 2109.\n    if len(str) < 2:\n        return str\n    if str[0] != '\"' or str[-1] != '\"':\n        return str\n\n    # We have to assume that we must decode this string.\n    # Down to work.\n\n    # Remove the \"s\n    str = str[1:-1]\n\n    # Check for special sequences.  Examples:\n    #    \\012 --> \\n\n    #    \\\"   --> \"\n    #\n    i = 0\n    n = len(str)\n    res = []\n    while 0 <= i < n:\n        o_match = _OctalPatt.search(str, i)\n        q_match = _QuotePatt.search(str, i)\n        if not o_match and not q_match:              # Neither matched\n            res.append(str[i:])\n            break\n        # else:\n        j = k = -1\n        if o_match:\n            j = o_match.start(0)\n        if q_match:\n            k = q_match.start(0)\n        if q_match and (not o_match or k < j):     # QuotePatt matched\n            res.append(str[i:k])\n            res.append(str[k+1])\n            i = k + 2\n        else:                                      # OctalPatt matched\n            res.append(str[i:j])\n            res.append(chr(int(str[j+1:j+4], 8)))\n            i = j + 4\n    return _nulljoin(res)\n\n# The _getdate() routine is used to set the expiration time in the cookie's HTTP\n# header.  By default, _getdate() returns the current time in the appropriate\n# \"expires\" format for a Set-Cookie header.  The one optional argument is an\n# offset from now, in seconds.  For example, an offset of -3600 means \"one hour\n# ago\".  The offset may be a floating point number.\n#\n\n_weekdayname = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n\n_monthname = [None,\n              'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n\ndef _getdate(future=0, weekdayname=_weekdayname, monthname=_monthname):\n    from time import gmtime, time\n    now = time()\n    year, month, day, hh, mm, ss, wd, y, z = gmtime(now + future)\n    return \"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % \\\n           (weekdayname[wd], day, monthname[month], year, hh, mm, ss)\n\n\nclass Morsel(dict):\n    \"\"\"A class to hold ONE (key, value) pair.\n\n    In a cookie, each such pair may have several attributes, so this class is\n    used to keep the attributes associated with the appropriate key,value pair.\n    This class also includes a coded_value attribute, which is used to hold\n    the network representation of the value.  This is most useful when Python\n    objects are pickled for network transit.\n    \"\"\"\n    # RFC 2109 lists these attributes as reserved:\n    #   path       comment         domain\n    #   max-age    secure      version\n    #\n    # For historical reasons, these attributes are also reserved:\n    #   expires\n    #\n    # This is an extension from Microsoft:\n    #   httponly\n    #\n    # This dictionary provides a mapping from the lowercase\n    # variant on the left to the appropriate traditional\n    # formatting on the right.\n    _reserved = {\n        \"expires\"  : \"expires\",\n        \"path\"     : \"Path\",\n        \"comment\"  : \"Comment\",\n        \"domain\"   : \"Domain\",\n        \"max-age\"  : \"Max-Age\",\n        \"secure\"   : \"secure\",\n        \"httponly\" : \"httponly\",\n        \"version\"  : \"Version\",\n    }\n\n    _flags = {'secure', 'httponly'}\n\n    def __init__(self):\n        # Set defaults\n        self.key = self.value = self.coded_value = None\n\n        # Set default attributes\n        for key in self._reserved:\n            dict.__setitem__(self, key, \"\")\n\n    def __setitem__(self, K, V):\n        K = K.lower()\n        if not K in self._reserved:\n            raise CookieError(\"Invalid Attribute %s\" % K)\n        dict.__setitem__(self, K, V)\n\n    def isReservedKey(self, K):\n        return K.lower() in self._reserved\n\n    def set(self, key, val, coded_val, LegalChars=_LegalChars):\n        # First we verify that the key isn't a reserved word\n        # Second we make sure it only contains legal characters\n        if key.lower() in self._reserved:\n            raise CookieError(\"Attempt to set a reserved key: %s\" % key)\n        if any(c not in LegalChars for c in key):\n            raise CookieError(\"Illegal key value: %s\" % key)\n\n        # It's a good key, so save it.\n        self.key = key\n        self.value = val\n        self.coded_value = coded_val\n\n    def output(self, attrs=None, header=\"Set-Cookie:\"):\n        return \"%s %s\" % (header, self.OutputString(attrs))\n\n    __str__ = output\n\n    def __repr__(self):\n        return '<%s: %s=%s>' % (self.__class__.__name__,\n                                self.key, repr(self.value))\n\n    def js_output(self, attrs=None):\n        # Print javascript\n        return \"\"\"\n        <script type=\"text/javascript\">\n        <!-- begin hiding\n        document.cookie = \\\"%s\\\";\n        // end hiding -->\n        </script>\n        \"\"\" % (self.OutputString(attrs).replace('\"', r'\\\"'))\n\n    def OutputString(self, attrs=None):\n        # Build up our result\n        #\n        result = []\n        append = result.append\n\n        # First, the key=value pair\n        append(\"%s=%s\" % (self.key, self.coded_value))\n\n        # Now add any defined attributes\n        if attrs is None:\n            attrs = self._reserved\n        items = sorted(self.items())\n        for key, value in items:\n            if value == \"\":\n                continue\n            if key not in attrs:\n                continue\n            if key == \"expires\" and isinstance(value, int):\n                append(\"%s=%s\" % (self._reserved[key], _getdate(value)))\n            elif key == \"max-age\" and isinstance(value, int):\n                append(\"%s=%d\" % (self._reserved[key], value))\n            elif key == \"secure\":\n                append(str(self._reserved[key]))\n            elif key == \"httponly\":\n                append(str(self._reserved[key]))\n            else:\n                append(\"%s=%s\" % (self._reserved[key], value))\n\n        # Return the result\n        return _semispacejoin(result)\n\n\n#\n# Pattern for finding cookie\n#\n# This used to be strict parsing based on the RFC2109 and RFC2068\n# specifications.  I have since discovered that MSIE 3.0x doesn't\n# follow the character rules outlined in those specs.  As a\n# result, the parsing rules here are less strict.\n#\n\n_LegalCharsPatt  = r\"[\\w\\d!#%&'~_`><@,:/\\$\\*\\+\\-\\.\\^\\|\\)\\(\\?\\}\\{\\=]\"\n_CookiePattern = re.compile(r\"\"\"\n    (?x)                           # This is a verbose pattern\n    (?P<key>                       # Start of group 'key'\n    \"\"\" + _LegalCharsPatt + r\"\"\"+?   # Any word of at least one letter\n    )                              # End of group 'key'\n    (                              # Optional group: there may not be a value.\n    \\s*=\\s*                          # Equal Sign\n    (?P<val>                         # Start of group 'val'\n    \"(?:[^\\\\\"]|\\\\.)*\"                  # Any doublequoted string\n    |                                  # or\n    \\w{3},\\s[\\w\\d\\s-]{9,11}\\s[\\d:]{8}\\sGMT  # Special case for \"expires\" attr\n    |                                  # or\n    \"\"\" + _LegalCharsPatt + r\"\"\"*      # Any word or empty string\n    )                                # End of group 'val'\n    )?                             # End of optional value group\n    \\s*                            # Any number of spaces.\n    (\\s+|;|$)                      # Ending either at space, semicolon, or EOS.\n    \"\"\", re.ASCII)                 # May be removed if safe.\n\n\n# At long last, here is the cookie class.  Using this class is almost just like\n# using a dictionary.  See this module's docstring for example usage.\n#\nclass BaseCookie(dict):\n    \"\"\"A container class for a set of Morsels.\"\"\"\n\n    def value_decode(self, val):\n        \"\"\"real_value, coded_value = value_decode(STRING)\n        Called prior to setting a cookie's value from the network\n        representation.  The VALUE is the value read from HTTP\n        header.\n        Override this function to modify the behavior of cookies.\n        \"\"\"\n        return val, val\n\n    def value_encode(self, val):\n        \"\"\"real_value, coded_value = value_encode(VALUE)\n        Called prior to setting a cookie's value from the dictionary\n        representation.  The VALUE is the value being assigned.\n        Override this function to modify the behavior of cookies.\n        \"\"\"\n        strval = str(val)\n        return strval, strval\n\n    def __init__(self, input=None):\n        if input:\n            self.load(input)\n\n    def __set(self, key, real_value, coded_value):\n        \"\"\"Private method for setting a cookie's value\"\"\"\n        M = self.get(key, Morsel())\n        M.set(key, real_value, coded_value)\n        dict.__setitem__(self, key, M)\n\n    def __setitem__(self, key, value):\n        \"\"\"Dictionary style assignment.\"\"\"\n        rval, cval = self.value_encode(value)\n        self.__set(key, rval, cval)\n\n    def output(self, attrs=None, header=\"Set-Cookie:\", sep=\"\\015\\012\"):\n        \"\"\"Return a string suitable for HTTP.\"\"\"\n        result = []\n        items = sorted(self.items())\n        for key, value in items:\n            result.append(value.output(attrs, header))\n        return sep.join(result)\n\n    __str__ = output\n\n    def __repr__(self):\n        l = []\n        items = sorted(self.items())\n        for key, value in items:\n            l.append('%s=%s' % (key, repr(value.value)))\n        return '<%s: %s>' % (self.__class__.__name__, _spacejoin(l))\n\n    def js_output(self, attrs=None):\n        \"\"\"Return a string suitable for JavaScript.\"\"\"\n        result = []\n        items = sorted(self.items())\n        for key, value in items:\n            result.append(value.js_output(attrs))\n        return _nulljoin(result)\n\n    def load(self, rawdata):\n        \"\"\"Load cookies from a string (presumably HTTP_COOKIE) or\n        from a dictionary.  Loading cookies from a dictionary 'd'\n        is equivalent to calling:\n            map(Cookie.__setitem__, d.keys(), d.values())\n        \"\"\"\n        if isinstance(rawdata, str):\n            self.__parse_string(rawdata)\n        else:\n            # self.update() wouldn't call our custom __setitem__\n            for key, value in rawdata.items():\n                self[key] = value\n        return\n\n    def __parse_string(self, str, patt=_CookiePattern):\n        i = 0            # Our starting point\n        n = len(str)     # Length of string\n        M = None         # current morsel\n\n        while 0 <= i < n:\n            # Start looking for a cookie\n            match = patt.search(str, i)\n            if not match:\n                # No more cookies\n                break\n\n            key, value = match.group(\"key\"), match.group(\"val\")\n            i = match.end(0)\n\n            # Parse the key, value in case it's metainfo\n            if key[0] == \"$\":\n                # We ignore attributes which pertain to the cookie\n                # mechanism as a whole.  See RFC 2109.\n                # (Does anyone care?)\n                if M:\n                    M[key[1:]] = value\n            elif key.lower() in Morsel._reserved:\n                if M:\n                    if value is None:\n                        if key.lower() in Morsel._flags:\n                            M[key] = True\n                    else:\n                        M[key] = _unquote(value)\n            elif value is not None:\n                rval, cval = self.value_decode(value)\n                self.__set(key, rval, cval)\n                M = self[key]\n\n\nclass SimpleCookie(BaseCookie):\n    \"\"\"\n    SimpleCookie supports strings as cookie values.  When setting\n    the value using the dictionary assignment notation, SimpleCookie\n    calls the builtin str() to convert the value to a string.  Values\n    received from HTTP are kept as strings.\n    \"\"\"\n    def value_decode(self, val):\n        return _unquote(val), val\n\n    def value_encode(self, val):\n        strval = str(val)\n        return strval, _quote(strval)\n"], "importlib": [".py", "\"\"\"A pure Python implementation of import.\"\"\"\n__all__ = ['__import__', 'import_module', 'invalidate_caches']\n\n# Bootstrap help #####################################################\n\n# Until bootstrapping is complete, DO NOT import any modules that attempt\n# to import importlib._bootstrap (directly or indirectly). Since this\n# partially initialised package would be present in sys.modules, those\n# modules would get an uninitialised copy of the source version, instead\n# of a fully initialised version (either the frozen one or the one\n# initialised below if the frozen one is not available).\nimport _imp  # Just the builtin component, NOT the full Python module\nimport sys\n\nfrom . import machinery   #fix me brython\n\ntry:\n    import _frozen_importlib as _bootstrap\nexcept ImportError:\n    from . import _bootstrap\n    _bootstrap._setup(sys, _imp)\nelse:\n    # importlib._bootstrap is the built-in import, ensure we don't create\n    # a second copy of the module.\n    _bootstrap.__name__ = 'importlib._bootstrap'\n    _bootstrap.__package__ = 'importlib'\n    _bootstrap.__file__ = __file__.replace('__init__.py', '_bootstrap.py')\n    sys.modules['importlib._bootstrap'] = _bootstrap\n\n# To simplify imports in test code\n_w_long = _bootstrap._w_long\n_r_long = _bootstrap._r_long\n\n# Fully bootstrapped at this point, import whatever you like, circular\n# dependencies and startup overhead minimisation permitting :)\n\n# Public API #########################################################\n\nfrom ._bootstrap import __import__\n\n\ndef invalidate_caches():\n    \"\"\"Call the invalidate_caches() method on all meta path finders stored in\n    sys.meta_path (where implemented).\"\"\"\n    for finder in sys.meta_path:\n        if hasattr(finder, 'invalidate_caches'):\n            finder.invalidate_caches()\n\n\ndef find_loader(name, path=None):\n    \"\"\"Find the loader for the specified module.\n\n    First, sys.modules is checked to see if the module was already imported. If\n    so, then sys.modules[name].__loader__ is returned. If that happens to be\n    set to None, then ValueError is raised. If the module is not in\n    sys.modules, then sys.meta_path is searched for a suitable loader with the\n    value of 'path' given to the finders. None is returned if no loader could\n    be found.\n\n    Dotted names do not have their parent packages implicitly imported. You will\n    most likely need to explicitly import all parent packages in the proper\n    order for a submodule to get the correct loader.\n\n    \"\"\"\n    try:\n        loader = sys.modules[name].__loader__\n        if loader is None:\n            raise ValueError('{}.__loader__ is None'.format(name))\n        else:\n            return loader\n    except KeyError:\n        pass\n    return _bootstrap._find_module(name, path)\n\n\ndef import_module(name, package=None):\n    \"\"\"Import a module.\n\n    The 'package' argument is required when performing a relative import. It\n    specifies the package to use as the anchor point from which to resolve the\n    relative import to an absolute import.\n\n    \"\"\"\n    level = 0\n    if name.startswith('.'):\n        if not package:\n            raise TypeError(\"relative imports require the 'package' argument\")\n        for character in name:\n            if character != '.':\n                break\n            level += 1\n    return _bootstrap._gcd_import(name[level:], package, level)\n", 1], "_functools": [".py", "def partial(func, *args, **keywords):\n    def newfunc(*fargs, **fkeywords):\n        newkeywords = keywords.copy()\n        newkeywords.update(fkeywords)\n        return func(*(args + fargs), **newkeywords)\n    newfunc.func = func\n    newfunc.args = args\n    newfunc.keywords = keywords\n    return newfunc\n\ndef reduce(func,iterable,initializer=None):\n    args = iter(iterable)\n    if initializer is not None:\n        res = initializer\n    else:\n        res = next(args)\n    while True:\n        try:\n            res = func(res,next(args))\n        except StopIteration:\n            return res\n"], "logging": [".py", "# Copyright 2001-2013 by Vinay Sajip. All Rights Reserved.\n#\n# Permission to use, copy, modify, and distribute this software and its\n# documentation for any purpose and without fee is hereby granted,\n# provided that the above copyright notice appear in all copies and that\n# both that copyright notice and this permission notice appear in\n# supporting documentation, and that the name of Vinay Sajip\n# not be used in advertising or publicity pertaining to distribution\n# of the software without specific, written prior permission.\n# VINAY SAJIP DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING\n# ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\n# VINAY SAJIP BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR\n# ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER\n# IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\n# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n\"\"\"\nLogging package for Python. Based on PEP 282 and comments thereto in\ncomp.lang.python.\n\nCopyright (C) 2001-2013 Vinay Sajip. All Rights Reserved.\n\nTo use, simply 'import logging' and log away!\n\"\"\"\n\nimport sys, os, time, io, traceback, warnings, weakref\nfrom string import Template\n\n__all__ = ['BASIC_FORMAT', 'BufferingFormatter', 'CRITICAL', 'DEBUG', 'ERROR',\n           'FATAL', 'FileHandler', 'Filter', 'Formatter', 'Handler', 'INFO',\n           'LogRecord', 'Logger', 'LoggerAdapter', 'NOTSET', 'NullHandler',\n           'StreamHandler', 'WARN', 'WARNING', 'addLevelName', 'basicConfig',\n           'captureWarnings', 'critical', 'debug', 'disable', 'error',\n           'exception', 'fatal', 'getLevelName', 'getLogger', 'getLoggerClass',\n           'info', 'log', 'makeLogRecord', 'setLoggerClass', 'warn', 'warning',\n           'getLogRecordFactory', 'setLogRecordFactory', 'lastResort']\n\ntry:\n    import threading\nexcept ImportError: #pragma: no cover\n    threading = None\n\n__author__  = \"Vinay Sajip <vinay_sajip@red-dove.com>\"\n__status__  = \"production\"\n__version__ = \"0.5.1.2\"\n__date__    = \"07 February 2010\"\n\n#---------------------------------------------------------------------------\n#   Miscellaneous module data\n#---------------------------------------------------------------------------\n\n#\n# _srcfile is used when walking the stack to check when we've got the first\n# caller stack frame.\n#\nif hasattr(sys, 'frozen'): #support for py2exe\n    _srcfile = \"logging%s__init__%s\" % (os.sep, __file__[-4:])\nelse:\n    _srcfile = __file__\n_srcfile = os.path.normcase(_srcfile)\n\n\nif hasattr(sys, '_getframe'):\n    currentframe = lambda: sys._getframe(3)\nelse: #pragma: no cover\n    def currentframe():\n        \"\"\"Return the frame object for the caller's stack frame.\"\"\"\n        try:\n            raise Exception\n        except:\n            return sys.exc_info()[2].tb_frame.f_back\n\n# _srcfile is only used in conjunction with sys._getframe().\n# To provide compatibility with older versions of Python, set _srcfile\n# to None if _getframe() is not available; this value will prevent\n# findCaller() from being called.\n#if not hasattr(sys, \"_getframe\"):\n#    _srcfile = None\n\n#\n#_startTime is used as the base when calculating the relative time of events\n#\n_startTime = time.time()\n\n#\n#raiseExceptions is used to see if exceptions during handling should be\n#propagated\n#\nraiseExceptions = True\n\n#\n# If you don't want threading information in the log, set this to zero\n#\nlogThreads = True\n\n#\n# If you don't want multiprocessing information in the log, set this to zero\n#\nlogMultiprocessing = True\n\n#\n# If you don't want process information in the log, set this to zero\n#\nlogProcesses = True\n\n#---------------------------------------------------------------------------\n#   Level related stuff\n#---------------------------------------------------------------------------\n#\n# Default levels and level names, these can be replaced with any positive set\n# of values having corresponding names. There is a pseudo-level, NOTSET, which\n# is only really there as a lower limit for user-defined levels. Handlers and\n# loggers are initialized with NOTSET so that they will log all messages, even\n# at user-defined levels.\n#\n\nCRITICAL = 50\nFATAL = CRITICAL\nERROR = 40\nWARNING = 30\nWARN = WARNING\nINFO = 20\nDEBUG = 10\nNOTSET = 0\n\n_levelNames = {\n    CRITICAL : 'CRITICAL',\n    ERROR : 'ERROR',\n    WARNING : 'WARNING',\n    INFO : 'INFO',\n    DEBUG : 'DEBUG',\n    NOTSET : 'NOTSET',\n    'CRITICAL' : CRITICAL,\n    'ERROR' : ERROR,\n    'WARN' : WARNING,\n    'WARNING' : WARNING,\n    'INFO' : INFO,\n    'DEBUG' : DEBUG,\n    'NOTSET' : NOTSET,\n}\n\ndef getLevelName(level):\n    \"\"\"\n    Return the textual representation of logging level 'level'.\n\n    If the level is one of the predefined levels (CRITICAL, ERROR, WARNING,\n    INFO, DEBUG) then you get the corresponding string. If you have\n    associated levels with names using addLevelName then the name you have\n    associated with 'level' is returned.\n\n    If a numeric value corresponding to one of the defined levels is passed\n    in, the corresponding string representation is returned.\n\n    Otherwise, the string \"Level %s\" % level is returned.\n    \"\"\"\n    return _levelNames.get(level, (\"Level %s\" % level))\n\ndef addLevelName(level, levelName):\n    \"\"\"\n    Associate 'levelName' with 'level'.\n\n    This is used when converting levels to text during message formatting.\n    \"\"\"\n    _acquireLock()\n    try:    #unlikely to cause an exception, but you never know...\n        _levelNames[level] = levelName\n        _levelNames[levelName] = level\n    finally:\n        _releaseLock()\n\ndef _checkLevel(level):\n    if isinstance(level, int):\n        rv = level\n    elif str(level) == level:\n        if level not in _levelNames:\n            raise ValueError(\"Unknown level: %r\" % level)\n        rv = _levelNames[level]\n    else:\n        raise TypeError(\"Level not an integer or a valid string: %r\" % level)\n    return rv\n\n#---------------------------------------------------------------------------\n#   Thread-related stuff\n#---------------------------------------------------------------------------\n\n#\n#_lock is used to serialize access to shared data structures in this module.\n#This needs to be an RLock because fileConfig() creates and configures\n#Handlers, and so might arbitrary user threads. Since Handler code updates the\n#shared dictionary _handlers, it needs to acquire the lock. But if configuring,\n#the lock would already have been acquired - so we need an RLock.\n#The same argument applies to Loggers and Manager.loggerDict.\n#\nif threading:\n    _lock = threading.RLock()\nelse: #pragma: no cover\n    _lock = None\n\n\ndef _acquireLock():\n    \"\"\"\n    Acquire the module-level lock for serializing access to shared data.\n\n    This should be released with _releaseLock().\n    \"\"\"\n    if _lock:\n        _lock.acquire()\n\ndef _releaseLock():\n    \"\"\"\n    Release the module-level lock acquired by calling _acquireLock().\n    \"\"\"\n    if _lock:\n        _lock.release()\n\n#---------------------------------------------------------------------------\n#   The logging record\n#---------------------------------------------------------------------------\n\nclass LogRecord(object):\n    \"\"\"\n    A LogRecord instance represents an event being logged.\n\n    LogRecord instances are created every time something is logged. They\n    contain all the information pertinent to the event being logged. The\n    main information passed in is in msg and args, which are combined\n    using str(msg) % args to create the message field of the record. The\n    record also includes information such as when the record was created,\n    the source line where the logging call was made, and any exception\n    information to be logged.\n    \"\"\"\n    def __init__(self, name, level, pathname, lineno,\n                 msg, args, exc_info, func=None, sinfo=None, **kwargs):\n        \"\"\"\n        Initialize a logging record with interesting information.\n        \"\"\"\n        ct = time.time()\n        self.name = name\n        self.msg = msg\n        #\n        # The following statement allows passing of a dictionary as a sole\n        # argument, so that you can do something like\n        #  logging.debug(\"a %(a)d b %(b)s\", {'a':1, 'b':2})\n        # Suggested by Stefan Behnel.\n        # Note that without the test for args[0], we get a problem because\n        # during formatting, we test to see if the arg is present using\n        # 'if self.args:'. If the event being logged is e.g. 'Value is %d'\n        # and if the passed arg fails 'if self.args:' then no formatting\n        # is done. For example, logger.warning('Value is %d', 0) would log\n        # 'Value is %d' instead of 'Value is 0'.\n        # For the use case of passing a dictionary, this should not be a\n        # problem.\n        if args and len(args) == 1 and isinstance(args[0], dict) and args[0]:\n            args = args[0]\n        self.args = args\n        self.levelname = getLevelName(level)\n        self.levelno = level\n        self.pathname = pathname\n        try:\n            self.filename = os.path.basename(pathname)\n            self.module = os.path.splitext(self.filename)[0]\n        except (TypeError, ValueError, AttributeError):\n            self.filename = pathname\n            self.module = \"Unknown module\"\n        self.exc_info = exc_info\n        self.exc_text = None      # used to cache the traceback text\n        self.stack_info = sinfo\n        self.lineno = lineno\n        self.funcName = func\n        self.created = ct\n        self.msecs = (ct - int(ct)) * 1000\n        self.relativeCreated = (self.created - _startTime) * 1000\n        if logThreads and threading:\n            self.thread = threading.get_ident()\n            self.threadName = threading.current_thread().name\n        else: # pragma: no cover\n            self.thread = None\n            self.threadName = None\n        if not logMultiprocessing: # pragma: no cover\n            self.processName = None\n        else:\n            self.processName = 'MainProcess'\n            mp = sys.modules.get('multiprocessing')\n            if mp is not None:\n                # Errors may occur if multiprocessing has not finished loading\n                # yet - e.g. if a custom import hook causes third-party code\n                # to run when multiprocessing calls import. See issue 8200\n                # for an example\n                try:\n                    self.processName = mp.current_process().name\n                except Exception: #pragma: no cover\n                    pass\n        if logProcesses and hasattr(os, 'getpid'):\n            self.process = os.getpid()\n        else:\n            self.process = None\n\n    def __str__(self):\n        return '<LogRecord: %s, %s, %s, %s, \"%s\">'%(self.name, self.levelno,\n            self.pathname, self.lineno, self.msg)\n\n    def getMessage(self):\n        \"\"\"\n        Return the message for this LogRecord.\n\n        Return the message for this LogRecord after merging any user-supplied\n        arguments with the message.\n        \"\"\"\n        msg = str(self.msg)\n        if self.args:\n            msg = msg % self.args\n        return msg\n\n#\n#   Determine which class to use when instantiating log records.\n#\n_logRecordFactory = LogRecord\n\ndef setLogRecordFactory(factory):\n    \"\"\"\n    Set the factory to be used when instantiating a log record.\n\n    :param factory: A callable which will be called to instantiate\n    a log record.\n    \"\"\"\n    global _logRecordFactory\n    _logRecordFactory = factory\n\ndef getLogRecordFactory():\n    \"\"\"\n    Return the factory to be used when instantiating a log record.\n    \"\"\"\n\n    return _logRecordFactory\n\ndef makeLogRecord(dict):\n    \"\"\"\n    Make a LogRecord whose attributes are defined by the specified dictionary,\n    This function is useful for converting a logging event received over\n    a socket connection (which is sent as a dictionary) into a LogRecord\n    instance.\n    \"\"\"\n    rv = _logRecordFactory(None, None, \"\", 0, \"\", (), None, None)\n    rv.__dict__.update(dict)\n    return rv\n\n#---------------------------------------------------------------------------\n#   Formatter classes and functions\n#---------------------------------------------------------------------------\n\nclass PercentStyle(object):\n\n    default_format = '%(message)s'\n    asctime_format = '%(asctime)s'\n    asctime_search = '%(asctime)'\n\n    def __init__(self, fmt):\n        self._fmt = fmt or self.default_format\n\n    def usesTime(self):\n        return self._fmt.find(self.asctime_search) >= 0\n\n    def format(self, record):\n        return self._fmt % record.__dict__\n\nclass StrFormatStyle(PercentStyle):\n    default_format = '{message}'\n    asctime_format = '{asctime}'\n    asctime_search = '{asctime'\n\n    def format(self, record):\n        return self._fmt.format(**record.__dict__)\n\n\nclass StringTemplateStyle(PercentStyle):\n    default_format = '${message}'\n    asctime_format = '${asctime}'\n    asctime_search = '${asctime}'\n\n    def __init__(self, fmt):\n        self._fmt = fmt or self.default_format\n        self._tpl = Template(self._fmt)\n\n    def usesTime(self):\n        fmt = self._fmt\n        return fmt.find('$asctime') >= 0 or fmt.find(self.asctime_format) >= 0\n\n    def format(self, record):\n        return self._tpl.substitute(**record.__dict__)\n\n_STYLES = {\n    '%': PercentStyle,\n    '{': StrFormatStyle,\n    '$': StringTemplateStyle\n}\n\nclass Formatter(object):\n    \"\"\"\n    Formatter instances are used to convert a LogRecord to text.\n\n    Formatters need to know how a LogRecord is constructed. They are\n    responsible for converting a LogRecord to (usually) a string which can\n    be interpreted by either a human or an external system. The base Formatter\n    allows a formatting string to be specified. If none is supplied, the\n    default value of \"%s(message)\" is used.\n\n    The Formatter can be initialized with a format string which makes use of\n    knowledge of the LogRecord attributes - e.g. the default value mentioned\n    above makes use of the fact that the user's message and arguments are pre-\n    formatted into a LogRecord's message attribute. Currently, the useful\n    attributes in a LogRecord are described by:\n\n    %(name)s            Name of the logger (logging channel)\n    %(levelno)s         Numeric logging level for the message (DEBUG, INFO,\n                        WARNING, ERROR, CRITICAL)\n    %(levelname)s       Text logging level for the message (\"DEBUG\", \"INFO\",\n                        \"WARNING\", \"ERROR\", \"CRITICAL\")\n    %(pathname)s        Full pathname of the source file where the logging\n                        call was issued (if available)\n    %(filename)s        Filename portion of pathname\n    %(module)s          Module (name portion of filename)\n    %(lineno)d          Source line number where the logging call was issued\n                        (if available)\n    %(funcName)s        Function name\n    %(created)f         Time when the LogRecord was created (time.time()\n                        return value)\n    %(asctime)s         Textual time when the LogRecord was created\n    %(msecs)d           Millisecond portion of the creation time\n    %(relativeCreated)d Time in milliseconds when the LogRecord was created,\n                        relative to the time the logging module was loaded\n                        (typically at application startup time)\n    %(thread)d          Thread ID (if available)\n    %(threadName)s      Thread name (if available)\n    %(process)d         Process ID (if available)\n    %(message)s         The result of record.getMessage(), computed just as\n                        the record is emitted\n    \"\"\"\n\n    converter = time.localtime\n\n    def __init__(self, fmt=None, datefmt=None, style='%'):\n        \"\"\"\n        Initialize the formatter with specified format strings.\n\n        Initialize the formatter either with the specified format string, or a\n        default as described above. Allow for specialized date formatting with\n        the optional datefmt argument (if omitted, you get the ISO8601 format).\n\n        Use a style parameter of '%', '{' or '$' to specify that you want to\n        use one of %-formatting, :meth:`str.format` (``{}``) formatting or\n        :class:`string.Template` formatting in your format string.\n\n        .. versionchanged: 3.2\n           Added the ``style`` parameter.\n        \"\"\"\n        if style not in _STYLES:\n            raise ValueError('Style must be one of: %s' % ','.join(\n                             _STYLES.keys()))\n        self._style = _STYLES[style](fmt)\n        self._fmt = self._style._fmt\n        self.datefmt = datefmt\n\n    default_time_format = '%Y-%m-%d %H:%M:%S'\n    default_msec_format = '%s,%03d'\n\n    def formatTime(self, record, datefmt=None):\n        \"\"\"\n        Return the creation time of the specified LogRecord as formatted text.\n\n        This method should be called from format() by a formatter which\n        wants to make use of a formatted time. This method can be overridden\n        in formatters to provide for any specific requirement, but the\n        basic behaviour is as follows: if datefmt (a string) is specified,\n        it is used with time.strftime() to format the creation time of the\n        record. Otherwise, the ISO8601 format is used. The resulting\n        string is returned. This function uses a user-configurable function\n        to convert the creation time to a tuple. By default, time.localtime()\n        is used; to change this for a particular formatter instance, set the\n        'converter' attribute to a function with the same signature as\n        time.localtime() or time.gmtime(). To change it for all formatters,\n        for example if you want all logging times to be shown in GMT,\n        set the 'converter' attribute in the Formatter class.\n        \"\"\"\n        ct = self.converter(record.created)\n        if datefmt:\n            s = time.strftime(datefmt, ct)\n        else:\n            t = time.strftime(self.default_time_format, ct)\n            s = self.default_msec_format % (t, record.msecs)\n        return s\n\n    def formatException(self, ei):\n        \"\"\"\n        Format and return the specified exception information as a string.\n\n        This default implementation just uses\n        traceback.print_exception()\n        \"\"\"\n        sio = io.StringIO()\n        tb = ei[2]\n        # See issues #9427, #1553375. Commented out for now.\n        #if getattr(self, 'fullstack', False):\n        #    traceback.print_stack(tb.tb_frame.f_back, file=sio)\n        traceback.print_exception(ei[0], ei[1], tb, None, sio)\n        s = sio.getvalue()\n        sio.close()\n        if s[-1:] == \"\\n\":\n            s = s[:-1]\n        return s\n\n    def usesTime(self):\n        \"\"\"\n        Check if the format uses the creation time of the record.\n        \"\"\"\n        return self._style.usesTime()\n\n    def formatMessage(self, record):\n        return self._style.format(record)\n\n    def formatStack(self, stack_info):\n        \"\"\"\n        This method is provided as an extension point for specialized\n        formatting of stack information.\n\n        The input data is a string as returned from a call to\n        :func:`traceback.print_stack`, but with the last trailing newline\n        removed.\n\n        The base implementation just returns the value passed in.\n        \"\"\"\n        return stack_info\n\n    def format(self, record):\n        \"\"\"\n        Format the specified record as text.\n\n        The record's attribute dictionary is used as the operand to a\n        string formatting operation which yields the returned string.\n        Before formatting the dictionary, a couple of preparatory steps\n        are carried out. The message attribute of the record is computed\n        using LogRecord.getMessage(). If the formatting string uses the\n        time (as determined by a call to usesTime(), formatTime() is\n        called to format the event time. If there is exception information,\n        it is formatted using formatException() and appended to the message.\n        \"\"\"\n        record.message = record.getMessage()\n        if self.usesTime():\n            record.asctime = self.formatTime(record, self.datefmt)\n        s = self.formatMessage(record)\n        if record.exc_info:\n            # Cache the traceback text to avoid converting it multiple times\n            # (it's constant anyway)\n            if not record.exc_text:\n                record.exc_text = self.formatException(record.exc_info)\n        if record.exc_text:\n            if s[-1:] != \"\\n\":\n                s = s + \"\\n\"\n            s = s + record.exc_text\n        if record.stack_info:\n            if s[-1:] != \"\\n\":\n                s = s + \"\\n\"\n            s = s + self.formatStack(record.stack_info)\n        return s\n\n#\n#   The default formatter to use when no other is specified\n#\n_defaultFormatter = Formatter()\n\nclass BufferingFormatter(object):\n    \"\"\"\n    A formatter suitable for formatting a number of records.\n    \"\"\"\n    def __init__(self, linefmt=None):\n        \"\"\"\n        Optionally specify a formatter which will be used to format each\n        individual record.\n        \"\"\"\n        if linefmt:\n            self.linefmt = linefmt\n        else:\n            self.linefmt = _defaultFormatter\n\n    def formatHeader(self, records):\n        \"\"\"\n        Return the header string for the specified records.\n        \"\"\"\n        return \"\"\n\n    def formatFooter(self, records):\n        \"\"\"\n        Return the footer string for the specified records.\n        \"\"\"\n        return \"\"\n\n    def format(self, records):\n        \"\"\"\n        Format the specified records and return the result as a string.\n        \"\"\"\n        rv = \"\"\n        if len(records) > 0:\n            rv = rv + self.formatHeader(records)\n            for record in records:\n                rv = rv + self.linefmt.format(record)\n            rv = rv + self.formatFooter(records)\n        return rv\n\n#---------------------------------------------------------------------------\n#   Filter classes and functions\n#---------------------------------------------------------------------------\n\nclass Filter(object):\n    \"\"\"\n    Filter instances are used to perform arbitrary filtering of LogRecords.\n\n    Loggers and Handlers can optionally use Filter instances to filter\n    records as desired. The base filter class only allows events which are\n    below a certain point in the logger hierarchy. For example, a filter\n    initialized with \"A.B\" will allow events logged by loggers \"A.B\",\n    \"A.B.C\", \"A.B.C.D\", \"A.B.D\" etc. but not \"A.BB\", \"B.A.B\" etc. If\n    initialized with the empty string, all events are passed.\n    \"\"\"\n    def __init__(self, name=''):\n        \"\"\"\n        Initialize a filter.\n\n        Initialize with the name of the logger which, together with its\n        children, will have its events allowed through the filter. If no\n        name is specified, allow every event.\n        \"\"\"\n        self.name = name\n        self.nlen = len(name)\n\n    def filter(self, record):\n        \"\"\"\n        Determine if the specified record is to be logged.\n\n        Is the specified record to be logged? Returns 0 for no, nonzero for\n        yes. If deemed appropriate, the record may be modified in-place.\n        \"\"\"\n        if self.nlen == 0:\n            return True\n        elif self.name == record.name:\n            return True\n        elif record.name.find(self.name, 0, self.nlen) != 0:\n            return False\n        return (record.name[self.nlen] == \".\")\n\nclass Filterer(object):\n    \"\"\"\n    A base class for loggers and handlers which allows them to share\n    common code.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initialize the list of filters to be an empty list.\n        \"\"\"\n        self.filters = []\n\n    def addFilter(self, filter):\n        \"\"\"\n        Add the specified filter to this handler.\n        \"\"\"\n        if not (filter in self.filters):\n            self.filters.append(filter)\n\n    def removeFilter(self, filter):\n        \"\"\"\n        Remove the specified filter from this handler.\n        \"\"\"\n        if filter in self.filters:\n            self.filters.remove(filter)\n\n    def filter(self, record):\n        \"\"\"\n        Determine if a record is loggable by consulting all the filters.\n\n        The default is to allow the record to be logged; any filter can veto\n        this and the record is then dropped. Returns a zero value if a record\n        is to be dropped, else non-zero.\n\n        .. versionchanged: 3.2\n\n           Allow filters to be just callables.\n        \"\"\"\n        rv = True\n        for f in self.filters:\n            if hasattr(f, 'filter'):\n                result = f.filter(record)\n            else:\n                result = f(record) # assume callable - will raise if not\n            if not result:\n                rv = False\n                break\n        return rv\n\n#---------------------------------------------------------------------------\n#   Handler classes and functions\n#---------------------------------------------------------------------------\n\n_handlers = weakref.WeakValueDictionary()  #map of handler names to handlers\n_handlerList = [] # added to allow handlers to be removed in reverse of order initialized\n\ndef _removeHandlerRef(wr):\n    \"\"\"\n    Remove a handler reference from the internal cleanup list.\n    \"\"\"\n    # This function can be called during module teardown, when globals are\n    # set to None. If _acquireLock is None, assume this is the case and do\n    # nothing.\n    if (_acquireLock is not None and _handlerList is not None and\n        _releaseLock is not None):\n        _acquireLock()\n        try:\n            if wr in _handlerList:\n                _handlerList.remove(wr)\n        finally:\n            _releaseLock()\n\ndef _addHandlerRef(handler):\n    \"\"\"\n    Add a handler to the internal cleanup list using a weak reference.\n    \"\"\"\n    _acquireLock()\n    try:\n        _handlerList.append(weakref.ref(handler, _removeHandlerRef))\n    finally:\n        _releaseLock()\n\nclass Handler(Filterer):\n    \"\"\"\n    Handler instances dispatch logging events to specific destinations.\n\n    The base handler class. Acts as a placeholder which defines the Handler\n    interface. Handlers can optionally use Formatter instances to format\n    records as desired. By default, no formatter is specified; in this case,\n    the 'raw' message as determined by record.message is logged.\n    \"\"\"\n    def __init__(self, level=NOTSET):\n        \"\"\"\n        Initializes the instance - basically setting the formatter to None\n        and the filter list to empty.\n        \"\"\"\n        Filterer.__init__(self)\n        self._name = None\n        self.level = _checkLevel(level)\n        self.formatter = None\n        # Add the handler to the global _handlerList (for cleanup on shutdown)\n        _addHandlerRef(self)\n        self.createLock()\n\n    def get_name(self):\n        return self._name\n\n    def set_name(self, name):\n        _acquireLock()\n        try:\n            if self._name in _handlers:\n                del _handlers[self._name]\n            self._name = name\n            if name:\n                _handlers[name] = self\n        finally:\n            _releaseLock()\n\n    name = property(get_name, set_name)\n\n    def createLock(self):\n        \"\"\"\n        Acquire a thread lock for serializing access to the underlying I/O.\n        \"\"\"\n        if threading:\n            self.lock = threading.RLock()\n        else: #pragma: no cover\n            self.lock = None\n\n    def acquire(self):\n        \"\"\"\n        Acquire the I/O thread lock.\n        \"\"\"\n        if self.lock:\n            self.lock.acquire()\n\n    def release(self):\n        \"\"\"\n        Release the I/O thread lock.\n        \"\"\"\n        if self.lock:\n            self.lock.release()\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the logging level of this handler.  level must be an int or a str.\n        \"\"\"\n        self.level = _checkLevel(level)\n\n    def format(self, record):\n        \"\"\"\n        Format the specified record.\n\n        If a formatter is set, use it. Otherwise, use the default formatter\n        for the module.\n        \"\"\"\n        if self.formatter:\n            fmt = self.formatter\n        else:\n            fmt = _defaultFormatter\n        return fmt.format(record)\n\n    def emit(self, record):\n        \"\"\"\n        Do whatever it takes to actually log the specified logging record.\n\n        This version is intended to be implemented by subclasses and so\n        raises a NotImplementedError.\n        \"\"\"\n        raise NotImplementedError('emit must be implemented '\n                                  'by Handler subclasses')\n\n    def handle(self, record):\n        \"\"\"\n        Conditionally emit the specified logging record.\n\n        Emission depends on filters which may have been added to the handler.\n        Wrap the actual emission of the record with acquisition/release of\n        the I/O thread lock. Returns whether the filter passed the record for\n        emission.\n        \"\"\"\n        rv = self.filter(record)\n        if rv:\n            self.acquire()\n            try:\n                self.emit(record)\n            finally:\n                self.release()\n        return rv\n\n    def setFormatter(self, fmt):\n        \"\"\"\n        Set the formatter for this handler.\n        \"\"\"\n        self.formatter = fmt\n\n    def flush(self):\n        \"\"\"\n        Ensure all logging output has been flushed.\n\n        This version does nothing and is intended to be implemented by\n        subclasses.\n        \"\"\"\n        pass\n\n    def close(self):\n        \"\"\"\n        Tidy up any resources used by the handler.\n\n        This version removes the handler from an internal map of handlers,\n        _handlers, which is used for handler lookup by name. Subclasses\n        should ensure that this gets called from overridden close()\n        methods.\n        \"\"\"\n        #get the module data lock, as we're updating a shared structure.\n        _acquireLock()\n        try:    #unlikely to raise an exception, but you never know...\n            if self._name and self._name in _handlers:\n                del _handlers[self._name]\n        finally:\n            _releaseLock()\n\n    def handleError(self, record):\n        \"\"\"\n        Handle errors which occur during an emit() call.\n\n        This method should be called from handlers when an exception is\n        encountered during an emit() call. If raiseExceptions is false,\n        exceptions get silently ignored. This is what is mostly wanted\n        for a logging system - most users will not care about errors in\n        the logging system, they are more interested in application errors.\n        You could, however, replace this with a custom handler if you wish.\n        The record which was being processed is passed in to this method.\n        \"\"\"\n        if raiseExceptions and sys.stderr:  # see issue 13807\n            ei = sys.exc_info()\n            try:\n                traceback.print_exception(ei[0], ei[1], ei[2],\n                                          None, sys.stderr)\n                sys.stderr.write('Logged from file %s, line %s\\n' % (\n                                 record.filename, record.lineno))\n            except IOError: #pragma: no cover\n                pass    # see issue 5971\n            finally:\n                del ei\n\nclass StreamHandler(Handler):\n    \"\"\"\n    A handler class which writes logging records, appropriately formatted,\n    to a stream. Note that this class does not close the stream, as\n    sys.stdout or sys.stderr may be used.\n    \"\"\"\n\n    terminator = '\\n'\n\n    def __init__(self, stream=None):\n        \"\"\"\n        Initialize the handler.\n\n        If stream is not specified, sys.stderr is used.\n        \"\"\"\n        Handler.__init__(self)\n        if stream is None:\n            stream = sys.stderr\n        self.stream = stream\n\n    def flush(self):\n        \"\"\"\n        Flushes the stream.\n        \"\"\"\n        self.acquire()\n        try:\n            if self.stream and hasattr(self.stream, \"flush\"):\n                self.stream.flush()\n        finally:\n            self.release()\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        If a formatter is specified, it is used to format the record.\n        The record is then written to the stream with a trailing newline.  If\n        exception information is present, it is formatted using\n        traceback.print_exception and appended to the stream.  If the stream\n        has an 'encoding' attribute, it is used to determine how to do the\n        output to the stream.\n        \"\"\"\n        try:\n            msg = self.format(record)\n            stream = self.stream\n            stream.write(msg)\n            stream.write(self.terminator)\n            self.flush()\n        except (KeyboardInterrupt, SystemExit): #pragma: no cover\n            raise\n        except:\n            self.handleError(record)\n\nclass FileHandler(StreamHandler):\n    \"\"\"\n    A handler class which writes formatted logging records to disk files.\n    \"\"\"\n    def __init__(self, filename, mode='a', encoding=None, delay=False):\n        \"\"\"\n        Open the specified file and use it as the stream for logging.\n        \"\"\"\n        #keep the absolute path, otherwise derived classes which use this\n        #may come a cropper when the current directory changes\n        self.baseFilename = os.path.abspath(filename)\n        self.mode = mode\n        self.encoding = encoding\n        self.delay = delay\n        if delay:\n            #We don't open the stream, but we still need to call the\n            #Handler constructor to set level, formatter, lock etc.\n            Handler.__init__(self)\n            self.stream = None\n        else:\n            StreamHandler.__init__(self, self._open())\n\n    def close(self):\n        \"\"\"\n        Closes the stream.\n        \"\"\"\n        self.acquire()\n        try:\n            if self.stream:\n                self.flush()\n                if hasattr(self.stream, \"close\"):\n                    self.stream.close()\n                StreamHandler.close(self)\n                self.stream = None\n        finally:\n            self.release()\n\n    def _open(self):\n        \"\"\"\n        Open the current base file with the (original) mode and encoding.\n        Return the resulting stream.\n        \"\"\"\n        return open(self.baseFilename, self.mode, encoding=self.encoding)\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        If the stream was not opened because 'delay' was specified in the\n        constructor, open it before calling the superclass's emit.\n        \"\"\"\n        if self.stream is None:\n            self.stream = self._open()\n        StreamHandler.emit(self, record)\n\nclass _StderrHandler(StreamHandler):\n    \"\"\"\n    This class is like a StreamHandler using sys.stderr, but always uses\n    whatever sys.stderr is currently set to rather than the value of\n    sys.stderr at handler construction time.\n    \"\"\"\n    def __init__(self, level=NOTSET):\n        \"\"\"\n        Initialize the handler.\n        \"\"\"\n        Handler.__init__(self, level)\n\n    @property\n    def stream(self):\n        return sys.stderr\n\n\n_defaultLastResort = _StderrHandler(WARNING)\nlastResort = _defaultLastResort\n\n#---------------------------------------------------------------------------\n#   Manager classes and functions\n#---------------------------------------------------------------------------\n\nclass PlaceHolder(object):\n    \"\"\"\n    PlaceHolder instances are used in the Manager logger hierarchy to take\n    the place of nodes for which no loggers have been defined. This class is\n    intended for internal use only and not as part of the public API.\n    \"\"\"\n    def __init__(self, alogger):\n        \"\"\"\n        Initialize with the specified logger being a child of this placeholder.\n        \"\"\"\n        self.loggerMap = { alogger : None }\n\n    def append(self, alogger):\n        \"\"\"\n        Add the specified logger as a child of this placeholder.\n        \"\"\"\n        if alogger not in self.loggerMap:\n            self.loggerMap[alogger] = None\n\n#\n#   Determine which class to use when instantiating loggers.\n#\n_loggerClass = None\n\ndef setLoggerClass(klass):\n    \"\"\"\n    Set the class to be used when instantiating a logger. The class should\n    define __init__() such that only a name argument is required, and the\n    __init__() should call Logger.__init__()\n    \"\"\"\n    if klass != Logger:\n        if not issubclass(klass, Logger):\n            raise TypeError(\"logger not derived from logging.Logger: \"\n                            + klass.__name__)\n    global _loggerClass\n    _loggerClass = klass\n\ndef getLoggerClass():\n    \"\"\"\n    Return the class to be used when instantiating a logger.\n    \"\"\"\n\n    return _loggerClass\n\nclass Manager(object):\n    \"\"\"\n    There is [under normal circumstances] just one Manager instance, which\n    holds the hierarchy of loggers.\n    \"\"\"\n    def __init__(self, rootnode):\n        \"\"\"\n        Initialize the manager with the root node of the logger hierarchy.\n        \"\"\"\n        self.root = rootnode\n        self.disable = 0\n        self.emittedNoHandlerWarning = False\n        self.loggerDict = {}\n        self.loggerClass = None\n        self.logRecordFactory = None\n\n    def getLogger(self, name):\n        \"\"\"\n        Get a logger with the specified name (channel name), creating it\n        if it doesn't yet exist. This name is a dot-separated hierarchical\n        name, such as \"a\", \"a.b\", \"a.b.c\" or similar.\n\n        If a PlaceHolder existed for the specified name [i.e. the logger\n        didn't exist but a child of it did], replace it with the created\n        logger and fix up the parent/child references which pointed to the\n        placeholder to now point to the logger.\n        \"\"\"\n        rv = None\n        if not isinstance(name, str):\n            raise TypeError('A logger name must be a string')\n        _acquireLock()\n        try:\n            if name in self.loggerDict:\n                rv = self.loggerDict[name]\n                if isinstance(rv, PlaceHolder):\n                    ph = rv\n                    rv = (self.loggerClass or _loggerClass)(name)\n                    rv.manager = self\n                    self.loggerDict[name] = rv\n                    self._fixupChildren(ph, rv)\n                    self._fixupParents(rv)\n            else:\n                rv = (self.loggerClass or _loggerClass)(name)\n                rv.manager = self\n                self.loggerDict[name] = rv\n                self._fixupParents(rv)\n        finally:\n            _releaseLock()\n        return rv\n\n    def setLoggerClass(self, klass):\n        \"\"\"\n        Set the class to be used when instantiating a logger with this Manager.\n        \"\"\"\n        if klass != Logger:\n            if not issubclass(klass, Logger):\n                raise TypeError(\"logger not derived from logging.Logger: \"\n                                + klass.__name__)\n        self.loggerClass = klass\n\n    def setLogRecordFactory(self, factory):\n        \"\"\"\n        Set the factory to be used when instantiating a log record with this\n        Manager.\n        \"\"\"\n        self.logRecordFactory = factory\n\n    def _fixupParents(self, alogger):\n        \"\"\"\n        Ensure that there are either loggers or placeholders all the way\n        from the specified logger to the root of the logger hierarchy.\n        \"\"\"\n        name = alogger.name\n        i = name.rfind(\".\")\n        rv = None\n        while (i > 0) and not rv:\n            substr = name[:i]\n            if substr not in self.loggerDict:\n                self.loggerDict[substr] = PlaceHolder(alogger)\n            else:\n                obj = self.loggerDict[substr]\n                if isinstance(obj, Logger):\n                    rv = obj\n                else:\n                    assert isinstance(obj, PlaceHolder)\n                    obj.append(alogger)\n            i = name.rfind(\".\", 0, i - 1)\n        if not rv:\n            rv = self.root\n        alogger.parent = rv\n\n    def _fixupChildren(self, ph, alogger):\n        \"\"\"\n        Ensure that children of the placeholder ph are connected to the\n        specified logger.\n        \"\"\"\n        name = alogger.name\n        namelen = len(name)\n        for c in ph.loggerMap.keys():\n            #The if means ... if not c.parent.name.startswith(nm)\n            if c.parent.name[:namelen] != name:\n                alogger.parent = c.parent\n                c.parent = alogger\n\n#---------------------------------------------------------------------------\n#   Logger classes and functions\n#---------------------------------------------------------------------------\n\nclass Logger(Filterer):\n    \"\"\"\n    Instances of the Logger class represent a single logging channel. A\n    \"logging channel\" indicates an area of an application. Exactly how an\n    \"area\" is defined is up to the application developer. Since an\n    application can have any number of areas, logging channels are identified\n    by a unique string. Application areas can be nested (e.g. an area\n    of \"input processing\" might include sub-areas \"read CSV files\", \"read\n    XLS files\" and \"read Gnumeric files\"). To cater for this natural nesting,\n    channel names are organized into a namespace hierarchy where levels are\n    separated by periods, much like the Java or Python package namespace. So\n    in the instance given above, channel names might be \"input\" for the upper\n    level, and \"input.csv\", \"input.xls\" and \"input.gnu\" for the sub-levels.\n    There is no arbitrary limit to the depth of nesting.\n    \"\"\"\n    def __init__(self, name, level=NOTSET):\n        \"\"\"\n        Initialize the logger with a name and an optional level.\n        \"\"\"\n        Filterer.__init__(self)\n        self.name = name\n        self.level = _checkLevel(level)\n        self.parent = None\n        self.propagate = True\n        self.handlers = []\n        self.disabled = False\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the logging level of this logger.  level must be an int or a str.\n        \"\"\"\n        self.level = _checkLevel(level)\n\n    def debug(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'DEBUG'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.debug(\"Houston, we have a %s\", \"thorny problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(DEBUG):\n            self._log(DEBUG, msg, args, **kwargs)\n\n    def info(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'INFO'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(INFO):\n            self._log(INFO, msg, args, **kwargs)\n\n    def warning(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'WARNING'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.warning(\"Houston, we have a %s\", \"bit of a problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(WARNING):\n            self._log(WARNING, msg, args, **kwargs)\n\n    def warn(self, msg, *args, **kwargs):\n        warnings.warn(\"The 'warn' method is deprecated, \"\n            \"use 'warning' instead\", DeprecationWarning, 2)\n        self.warning(msg, *args, **kwargs)\n\n    def error(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'ERROR'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.error(\"Houston, we have a %s\", \"major problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(ERROR):\n            self._log(ERROR, msg, args, **kwargs)\n\n    def exception(self, msg, *args, **kwargs):\n        \"\"\"\n        Convenience method for logging an ERROR with exception information.\n        \"\"\"\n        kwargs['exc_info'] = True\n        self.error(msg, *args, **kwargs)\n\n    def critical(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'CRITICAL'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.critical(\"Houston, we have a %s\", \"major disaster\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(CRITICAL):\n            self._log(CRITICAL, msg, args, **kwargs)\n\n    fatal = critical\n\n    def log(self, level, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with the integer severity 'level'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)\n        \"\"\"\n        if not isinstance(level, int):\n            if raiseExceptions:\n                raise TypeError(\"level must be an integer\")\n            else:\n                return\n        if self.isEnabledFor(level):\n            self._log(level, msg, args, **kwargs)\n\n    def findCaller(self, stack_info=False):\n        \"\"\"\n        Find the stack frame of the caller so that we can note the source\n        file name, line number and function name.\n        \"\"\"\n        f = currentframe()\n        #On some versions of IronPython, currentframe() returns None if\n        #IronPython isn't run with -X:Frames.\n        if f is not None:\n            f = f.f_back\n        rv = \"(unknown file)\", 0, \"(unknown function)\", None\n        while hasattr(f, \"f_code\"):\n            co = f.f_code\n            filename = os.path.normcase(co.co_filename)\n            if filename == _srcfile:\n                f = f.f_back\n                continue\n            sinfo = None\n            if stack_info:\n                sio = io.StringIO()\n                sio.write('Stack (most recent call last):\\n')\n                traceback.print_stack(f, file=sio)\n                sinfo = sio.getvalue()\n                if sinfo[-1] == '\\n':\n                    sinfo = sinfo[:-1]\n                sio.close()\n            rv = (co.co_filename, f.f_lineno, co.co_name, sinfo)\n            break\n        return rv\n\n    def makeRecord(self, name, level, fn, lno, msg, args, exc_info,\n                   func=None, extra=None, sinfo=None):\n        \"\"\"\n        A factory method which can be overridden in subclasses to create\n        specialized LogRecords.\n        \"\"\"\n        rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n                             sinfo)\n        if extra is not None:\n            for key in extra:\n                if (key in [\"message\", \"asctime\"]) or (key in rv.__dict__):\n                    raise KeyError(\"Attempt to overwrite %r in LogRecord\" % key)\n                rv.__dict__[key] = extra[key]\n        return rv\n\n    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False):\n        \"\"\"\n        Low-level logging routine which creates a LogRecord and then calls\n        all the handlers of this logger to handle the record.\n        \"\"\"\n        sinfo = None\n        if _srcfile:\n            #IronPython doesn't track Python frames, so findCaller raises an\n            #exception on some versions of IronPython. We trap it here so that\n            #IronPython can use logging.\n            try:\n                fn, lno, func, sinfo = self.findCaller(stack_info)\n            except ValueError: # pragma: no cover\n                fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        else: # pragma: no cover\n            fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        if exc_info:\n            if not isinstance(exc_info, tuple):\n                exc_info = sys.exc_info()\n        record = self.makeRecord(self.name, level, fn, lno, msg, args,\n                                 exc_info, func, extra, sinfo)\n        self.handle(record)\n\n    def handle(self, record):\n        \"\"\"\n        Call the handlers for the specified record.\n\n        This method is used for unpickled records received from a socket, as\n        well as those created locally. Logger-level filtering is applied.\n        \"\"\"\n        if (not self.disabled) and self.filter(record):\n            self.callHandlers(record)\n\n    def addHandler(self, hdlr):\n        \"\"\"\n        Add the specified handler to this logger.\n        \"\"\"\n        _acquireLock()\n        try:\n            if not (hdlr in self.handlers):\n                self.handlers.append(hdlr)\n        finally:\n            _releaseLock()\n\n    def removeHandler(self, hdlr):\n        \"\"\"\n        Remove the specified handler from this logger.\n        \"\"\"\n        _acquireLock()\n        try:\n            if hdlr in self.handlers:\n                self.handlers.remove(hdlr)\n        finally:\n            _releaseLock()\n\n    def hasHandlers(self):\n        \"\"\"\n        See if this logger has any handlers configured.\n\n        Loop through all handlers for this logger and its parents in the\n        logger hierarchy. Return True if a handler was found, else False.\n        Stop searching up the hierarchy whenever a logger with the \"propagate\"\n        attribute set to zero is found - that will be the last logger which\n        is checked for the existence of handlers.\n        \"\"\"\n        c = self\n        rv = False\n        while c:\n            if c.handlers:\n                rv = True\n                break\n            if not c.propagate:\n                break\n            else:\n                c = c.parent\n        return rv\n\n    def callHandlers(self, record):\n        \"\"\"\n        Pass a record to all relevant handlers.\n\n        Loop through all handlers for this logger and its parents in the\n        logger hierarchy. If no handler was found, output a one-off error\n        message to sys.stderr. Stop searching up the hierarchy whenever a\n        logger with the \"propagate\" attribute set to zero is found - that\n        will be the last logger whose handlers are called.\n        \"\"\"\n        c = self\n        found = 0\n        while c:\n            for hdlr in c.handlers:\n                found = found + 1\n                if record.levelno >= hdlr.level:\n                    hdlr.handle(record)\n            if not c.propagate:\n                c = None    #break out\n            else:\n                c = c.parent\n        if (found == 0):\n            if lastResort:\n                if record.levelno >= lastResort.level:\n                    lastResort.handle(record)\n            elif raiseExceptions and not self.manager.emittedNoHandlerWarning:\n                sys.stderr.write(\"No handlers could be found for logger\"\n                                 \" \\\"%s\\\"\\n\" % self.name)\n                self.manager.emittedNoHandlerWarning = True\n\n    def getEffectiveLevel(self):\n        \"\"\"\n        Get the effective level for this logger.\n\n        Loop through this logger and its parents in the logger hierarchy,\n        looking for a non-zero logging level. Return the first one found.\n        \"\"\"\n        logger = self\n        while logger:\n            if logger.level:\n                return logger.level\n            logger = logger.parent\n        return NOTSET\n\n    def isEnabledFor(self, level):\n        \"\"\"\n        Is this logger enabled for level 'level'?\n        \"\"\"\n        if self.manager.disable >= level:\n            return False\n        return level >= self.getEffectiveLevel()\n\n    def getChild(self, suffix):\n        \"\"\"\n        Get a logger which is a descendant to this one.\n\n        This is a convenience method, such that\n\n        logging.getLogger('abc').getChild('def.ghi')\n\n        is the same as\n\n        logging.getLogger('abc.def.ghi')\n\n        It's useful, for example, when the parent logger is named using\n        __name__ rather than a literal string.\n        \"\"\"\n        if self.root is not self:\n            suffix = '.'.join((self.name, suffix))\n        return self.manager.getLogger(suffix)\n\nclass RootLogger(Logger):\n    \"\"\"\n    A root logger is not that different to any other logger, except that\n    it must have a logging level and there is only one instance of it in\n    the hierarchy.\n    \"\"\"\n    def __init__(self, level):\n        \"\"\"\n        Initialize the logger with the name \"root\".\n        \"\"\"\n        Logger.__init__(self, \"root\", level)\n\n_loggerClass = Logger\n\nclass LoggerAdapter(object):\n    \"\"\"\n    An adapter for loggers which makes it easier to specify contextual\n    information in logging output.\n    \"\"\"\n\n    def __init__(self, logger, extra):\n        \"\"\"\n        Initialize the adapter with a logger and a dict-like object which\n        provides contextual information. This constructor signature allows\n        easy stacking of LoggerAdapters, if so desired.\n\n        You can effectively pass keyword arguments as shown in the\n        following example:\n\n        adapter = LoggerAdapter(someLogger, dict(p1=v1, p2=\"v2\"))\n        \"\"\"\n        self.logger = logger\n        self.extra = extra\n\n    def process(self, msg, kwargs):\n        \"\"\"\n        Process the logging message and keyword arguments passed in to\n        a logging call to insert contextual information. You can either\n        manipulate the message itself, the keyword args or both. Return\n        the message and kwargs modified (or not) to suit your needs.\n\n        Normally, you'll only need to override this one method in a\n        LoggerAdapter subclass for your specific needs.\n        \"\"\"\n        kwargs[\"extra\"] = self.extra\n        return msg, kwargs\n\n    #\n    # Boilerplate convenience methods\n    #\n    def debug(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a debug call to the underlying logger.\n        \"\"\"\n        self.log(DEBUG, msg, *args, **kwargs)\n\n    def info(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an info call to the underlying logger.\n        \"\"\"\n        self.log(INFO, msg, *args, **kwargs)\n\n    def warning(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a warning call to the underlying logger.\n        \"\"\"\n        self.log(WARNING, msg, *args, **kwargs)\n\n    def warn(self, msg, *args, **kwargs):\n        warnings.warn(\"The 'warn' method is deprecated, \"\n            \"use 'warning' instead\", DeprecationWarning, 2)\n        self.warning(msg, *args, **kwargs)\n\n    def error(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an error call to the underlying logger.\n        \"\"\"\n        self.log(ERROR, msg, *args, **kwargs)\n\n    def exception(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an exception call to the underlying logger.\n        \"\"\"\n        kwargs[\"exc_info\"] = True\n        self.log(ERROR, msg, *args, **kwargs)\n\n    def critical(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a critical call to the underlying logger.\n        \"\"\"\n        self.log(CRITICAL, msg, *args, **kwargs)\n\n    def log(self, level, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a log call to the underlying logger, after adding\n        contextual information from this adapter instance.\n        \"\"\"\n        if self.isEnabledFor(level):\n            msg, kwargs = self.process(msg, kwargs)\n            self.logger._log(level, msg, args, **kwargs)\n\n    def isEnabledFor(self, level):\n        \"\"\"\n        Is this logger enabled for level 'level'?\n        \"\"\"\n        if self.logger.manager.disable >= level:\n            return False\n        return level >= self.getEffectiveLevel()\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the specified level on the underlying logger.\n        \"\"\"\n        self.logger.setLevel(level)\n\n    def getEffectiveLevel(self):\n        \"\"\"\n        Get the effective level for the underlying logger.\n        \"\"\"\n        return self.logger.getEffectiveLevel()\n\n    def hasHandlers(self):\n        \"\"\"\n        See if the underlying logger has any handlers.\n        \"\"\"\n        return self.logger.hasHandlers()\n\nroot = RootLogger(WARNING)\nLogger.root = root\nLogger.manager = Manager(Logger.root)\n\n#---------------------------------------------------------------------------\n# Configuration classes and functions\n#---------------------------------------------------------------------------\n\nBASIC_FORMAT = \"%(levelname)s:%(name)s:%(message)s\"\n\ndef basicConfig(**kwargs):\n    \"\"\"\n    Do basic configuration for the logging system.\n\n    This function does nothing if the root logger already has handlers\n    configured. It is a convenience method intended for use by simple scripts\n    to do one-shot configuration of the logging package.\n\n    The default behaviour is to create a StreamHandler which writes to\n    sys.stderr, set a formatter using the BASIC_FORMAT format string, and\n    add the handler to the root logger.\n\n    A number of optional keyword arguments may be specified, which can alter\n    the default behaviour.\n\n    filename  Specifies that a FileHandler be created, using the specified\n              filename, rather than a StreamHandler.\n    filemode  Specifies the mode to open the file, if filename is specified\n              (if filemode is unspecified, it defaults to 'a').\n    format    Use the specified format string for the handler.\n    datefmt   Use the specified date/time format.\n    style     If a format string is specified, use this to specify the\n              type of format string (possible values '%', '{', '$', for\n              %-formatting, :meth:`str.format` and :class:`string.Template`\n              - defaults to '%').\n    level     Set the root logger level to the specified level.\n    stream    Use the specified stream to initialize the StreamHandler. Note\n              that this argument is incompatible with 'filename' - if both\n              are present, 'stream' is ignored.\n    handlers  If specified, this should be an iterable of already created\n              handlers, which will be added to the root handler. Any handler\n              in the list which does not have a formatter assigned will be\n              assigned the formatter created in this function.\n\n    Note that you could specify a stream created using open(filename, mode)\n    rather than passing the filename and mode in. However, it should be\n    remembered that StreamHandler does not close its stream (since it may be\n    using sys.stdout or sys.stderr), whereas FileHandler closes its stream\n    when the handler is closed.\n\n    .. versionchanged:: 3.2\n       Added the ``style`` parameter.\n\n    .. versionchanged:: 3.3\n       Added the ``handlers`` parameter. A ``ValueError`` is now thrown for\n       incompatible arguments (e.g. ``handlers`` specified together with\n       ``filename``/``filemode``, or ``filename``/``filemode`` specified\n       together with ``stream``, or ``handlers`` specified together with\n       ``stream``.\n    \"\"\"\n    # Add thread safety in case someone mistakenly calls\n    # basicConfig() from multiple threads\n    _acquireLock()\n    try:\n        if len(root.handlers) == 0:\n            handlers = kwargs.get(\"handlers\")\n            if handlers is None:\n                if \"stream\" in kwargs and \"filename\" in kwargs:\n                    raise ValueError(\"'stream' and 'filename' should not be \"\n                                     \"specified together\")\n            else:\n                if \"stream\" in kwargs or \"filename\" in kwargs:\n                    raise ValueError(\"'stream' or 'filename' should not be \"\n                                     \"specified together with 'handlers'\")\n            if handlers is None:\n                filename = kwargs.get(\"filename\")\n                if filename:\n                    mode = kwargs.get(\"filemode\", 'a')\n                    h = FileHandler(filename, mode)\n                else:\n                    stream = kwargs.get(\"stream\")\n                    h = StreamHandler(stream)\n                handlers = [h]\n            fs = kwargs.get(\"format\", BASIC_FORMAT)\n            dfs = kwargs.get(\"datefmt\", None)\n            style = kwargs.get(\"style\", '%')\n            fmt = Formatter(fs, dfs, style)\n            for h in handlers:\n                if h.formatter is None:\n                    h.setFormatter(fmt)\n                root.addHandler(h)\n            level = kwargs.get(\"level\")\n            if level is not None:\n                root.setLevel(level)\n    finally:\n        _releaseLock()\n\n#---------------------------------------------------------------------------\n# Utility functions at module level.\n# Basically delegate everything to the root logger.\n#---------------------------------------------------------------------------\n\ndef getLogger(name=None):\n    \"\"\"\n    Return a logger with the specified name, creating it if necessary.\n\n    If no name is specified, return the root logger.\n    \"\"\"\n    if name:\n        return Logger.manager.getLogger(name)\n    else:\n        return root\n\ndef critical(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'CRITICAL' on the root logger. If the logger\n    has no handlers, call basicConfig() to add a console handler with a\n    pre-defined format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.critical(msg, *args, **kwargs)\n\nfatal = critical\n\ndef error(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'ERROR' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.error(msg, *args, **kwargs)\n\ndef exception(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'ERROR' on the root logger, with exception\n    information. If the logger has no handlers, basicConfig() is called to add\n    a console handler with a pre-defined format.\n    \"\"\"\n    kwargs['exc_info'] = True\n    error(msg, *args, **kwargs)\n\ndef warning(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'WARNING' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.warning(msg, *args, **kwargs)\n\ndef warn(msg, *args, **kwargs):\n    warnings.warn(\"The 'warn' function is deprecated, \"\n        \"use 'warning' instead\", DeprecationWarning, 2)\n    warning(msg, *args, **kwargs)\n\ndef info(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'INFO' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.info(msg, *args, **kwargs)\n\ndef debug(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'DEBUG' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.debug(msg, *args, **kwargs)\n\ndef log(level, msg, *args, **kwargs):\n    \"\"\"\n    Log 'msg % args' with the integer severity 'level' on the root logger. If\n    the logger has no handlers, call basicConfig() to add a console handler\n    with a pre-defined format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.log(level, msg, *args, **kwargs)\n\ndef disable(level):\n    \"\"\"\n    Disable all logging calls of severity 'level' and below.\n    \"\"\"\n    root.manager.disable = level\n\ndef shutdown(handlerList=_handlerList):\n    \"\"\"\n    Perform any cleanup actions in the logging system (e.g. flushing\n    buffers).\n\n    Should be called at application exit.\n    \"\"\"\n    for wr in reversed(handlerList[:]):\n        #errors might occur, for example, if files are locked\n        #we just ignore them if raiseExceptions is not set\n        try:\n            h = wr()\n            if h:\n                try:\n                    h.acquire()\n                    h.flush()\n                    h.close()\n                except (IOError, ValueError):\n                    # Ignore errors which might be caused\n                    # because handlers have been closed but\n                    # references to them are still around at\n                    # application exit.\n                    pass\n                finally:\n                    h.release()\n        except:\n            if raiseExceptions:\n                raise\n            #else, swallow\n\n#Let's try and shutdown automatically on application exit...\nimport atexit\natexit.register(shutdown)\n\n# Null handler\n\nclass NullHandler(Handler):\n    \"\"\"\n    This handler does nothing. It's intended to be used to avoid the\n    \"No handlers could be found for logger XXX\" one-off warning. This is\n    important for library code, which may contain code to log events. If a user\n    of the library does not configure logging, the one-off warning might be\n    produced; to avoid this, the library developer simply needs to instantiate\n    a NullHandler and add it to the top-level logger of the library module or\n    package.\n    \"\"\"\n    def handle(self, record):\n        \"\"\"Stub.\"\"\"\n\n    def emit(self, record):\n        \"\"\"Stub.\"\"\"\n\n    def createLock(self):\n        self.lock = None\n\n# Warnings integration\n\n_warnings_showwarning = None\n\ndef _showwarning(message, category, filename, lineno, file=None, line=None):\n    \"\"\"\n    Implementation of showwarnings which redirects to logging, which will first\n    check to see if the file parameter is None. If a file is specified, it will\n    delegate to the original warnings implementation of showwarning. Otherwise,\n    it will call warnings.formatwarning and will log the resulting string to a\n    warnings logger named \"py.warnings\" with level logging.WARNING.\n    \"\"\"\n    if file is not None:\n        if _warnings_showwarning is not None:\n            _warnings_showwarning(message, category, filename, lineno, file, line)\n    else:\n        s = warnings.formatwarning(message, category, filename, lineno, line)\n        logger = getLogger(\"py.warnings\")\n        if not logger.handlers:\n            logger.addHandler(NullHandler())\n        logger.warning(\"%s\", s)\n\ndef captureWarnings(capture):\n    \"\"\"\n    If capture is true, redirect all warnings to the logging package.\n    If capture is False, ensure that warnings are not redirected to logging\n    but to their original destinations.\n    \"\"\"\n    global _warnings_showwarning\n    if capture:\n        if _warnings_showwarning is None:\n            _warnings_showwarning = warnings.showwarning\n            warnings.showwarning = _showwarning\n    else:\n        if _warnings_showwarning is not None:\n            warnings.showwarning = _warnings_showwarning\n            _warnings_showwarning = None\n", 1], "socket": [".py", "# Wrapper module for _socket, providing some additional facilities\n# implemented in Python.\n\n\"\"\"\\\nThis module provides socket operations and some related functions.\nOn Unix, it supports IP (Internet Protocol) and Unix domain sockets.\nOn other systems, it only supports IP. Functions specific for a\nsocket are available as methods of the socket object.\n\nFunctions:\n\nsocket() -- create a new socket object\nsocketpair() -- create a pair of new socket objects [*]\nfromfd() -- create a socket object from an open file descriptor [*]\nfromshare() -- create a socket object from data received from socket.share() [*]\ngethostname() -- return the current hostname\ngethostbyname() -- map a hostname to its IP number\ngethostbyaddr() -- map an IP number or hostname to DNS info\ngetservbyname() -- map a service name and a protocol name to a port number\ngetprotobyname() -- map a protocol name (e.g. 'tcp') to a number\nntohs(), ntohl() -- convert 16, 32 bit int from network to host byte order\nhtons(), htonl() -- convert 16, 32 bit int from host to network byte order\ninet_aton() -- convert IP addr string (123.45.67.89) to 32-bit packed format\ninet_ntoa() -- convert 32-bit packed format IP to string (123.45.67.89)\nsocket.getdefaulttimeout() -- get the default timeout value\nsocket.setdefaulttimeout() -- set the default timeout value\ncreate_connection() -- connects to an address, with an optional timeout and\n                       optional source address.\n\n [*] not available on all platforms!\n\nSpecial objects:\n\nSocketType -- type object for socket objects\nerror -- exception raised for I/O errors\nhas_ipv6 -- boolean value indicating if IPv6 is supported\n\nInteger constants:\n\nAF_INET, AF_UNIX -- socket domains (first argument to socket() call)\nSOCK_STREAM, SOCK_DGRAM, SOCK_RAW -- socket types (second argument)\n\nMany other constants may be defined; these may be used in calls to\nthe setsockopt() and getsockopt() methods.\n\"\"\"\n\nimport _socket\nfrom _socket import *\n\nimport os, sys, io\n\ntry:\n    import errno\nexcept ImportError:\n    errno = None\nEBADF = getattr(errno, 'EBADF', 9)\nEAGAIN = getattr(errno, 'EAGAIN', 11)\nEWOULDBLOCK = getattr(errno, 'EWOULDBLOCK', 11)\n\n__all__ = [\"getfqdn\", \"create_connection\"]\n__all__.extend(os._get_exports_list(_socket))\n\n\n_realsocket = socket\n\n# WSA error codes\nif sys.platform.lower().startswith(\"win\"):\n    errorTab = {}\n    errorTab[10004] = \"The operation was interrupted.\"\n    errorTab[10009] = \"A bad file handle was passed.\"\n    errorTab[10013] = \"Permission denied.\"\n    errorTab[10014] = \"A fault occurred on the network??\" # WSAEFAULT\n    errorTab[10022] = \"An invalid operation was attempted.\"\n    errorTab[10035] = \"The socket operation would block\"\n    errorTab[10036] = \"A blocking operation is already in progress.\"\n    errorTab[10048] = \"The network address is in use.\"\n    errorTab[10054] = \"The connection has been reset.\"\n    errorTab[10058] = \"The network has been shut down.\"\n    errorTab[10060] = \"The operation timed out.\"\n    errorTab[10061] = \"Connection refused.\"\n    errorTab[10063] = \"The name is too long.\"\n    errorTab[10064] = \"The host is down.\"\n    errorTab[10065] = \"The host is unreachable.\"\n    __all__.append(\"errorTab\")\n\n\nclass socket(_socket.socket):\n\n    \"\"\"A subclass of _socket.socket adding the makefile() method.\"\"\"\n\n    __slots__ = [\"__weakref__\", \"_io_refs\", \"_closed\"]\n\n    def __init__(self, family=AF_INET, type=SOCK_STREAM, proto=0, fileno=None):\n        _socket.socket.__init__(self, family, type, proto, fileno)\n        self._io_refs = 0\n        self._closed = False\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        if not self._closed:\n            self.close()\n\n    def __repr__(self):\n        \"\"\"Wrap __repr__() to reveal the real class name.\"\"\"\n        s = _socket.socket.__repr__(self)\n        if s.startswith(\"<socket object\"):\n            s = \"<%s.%s%s%s\" % (self.__class__.__module__,\n                                self.__class__.__name__,\n                                getattr(self, '_closed', False) and \" [closed] \" or \"\",\n                                s[7:])\n        return s\n\n    def __getstate__(self):\n        raise TypeError(\"Cannot serialize socket object\")\n\n    def dup(self):\n        \"\"\"dup() -> socket object\n\n        Return a new socket object connected to the same system resource.\n        \"\"\"\n        fd = dup(self.fileno())\n        sock = self.__class__(self.family, self.type, self.proto, fileno=fd)\n        sock.settimeout(self.gettimeout())\n        return sock\n\n    def accept(self):\n        \"\"\"accept() -> (socket object, address info)\n\n        Wait for an incoming connection.  Return a new socket\n        representing the connection, and the address of the client.\n        For IP sockets, the address info is a pair (hostaddr, port).\n        \"\"\"\n        fd, addr = self._accept()\n        sock = socket(self.family, self.type, self.proto, fileno=fd)\n        # Issue #7995: if no default timeout is set and the listening\n        # socket had a (non-zero) timeout, force the new socket in blocking\n        # mode to override platform-specific socket flags inheritance.\n        if getdefaulttimeout() is None and self.gettimeout():\n            sock.setblocking(True)\n        return sock, addr\n\n    def makefile(self, mode=\"r\", buffering=None, *,\n                 encoding=None, errors=None, newline=None):\n        \"\"\"makefile(...) -> an I/O stream connected to the socket\n\n        The arguments are as for io.open() after the filename,\n        except the only mode characters supported are 'r', 'w' and 'b'.\n        The semantics are similar too.  (XXX refactor to share code?)\n        \"\"\"\n        for c in mode:\n            if c not in {\"r\", \"w\", \"b\"}:\n                raise ValueError(\"invalid mode %r (only r, w, b allowed)\")\n        writing = \"w\" in mode\n        reading = \"r\" in mode or not writing\n        assert reading or writing\n        binary = \"b\" in mode\n        rawmode = \"\"\n        if reading:\n            rawmode += \"r\"\n        if writing:\n            rawmode += \"w\"\n        raw = SocketIO(self, rawmode)\n        self._io_refs += 1\n        if buffering is None:\n            buffering = -1\n        if buffering < 0:\n            buffering = io.DEFAULT_BUFFER_SIZE\n        if buffering == 0:\n            if not binary:\n                raise ValueError(\"unbuffered streams must be binary\")\n            return raw\n        if reading and writing:\n            buffer = io.BufferedRWPair(raw, raw, buffering)\n        elif reading:\n            buffer = io.BufferedReader(raw, buffering)\n        else:\n            assert writing\n            buffer = io.BufferedWriter(raw, buffering)\n        if binary:\n            return buffer\n        text = io.TextIOWrapper(buffer, encoding, errors, newline)\n        text.mode = mode\n        return text\n\n    def _decref_socketios(self):\n        if self._io_refs > 0:\n            self._io_refs -= 1\n        if self._closed:\n            self.close()\n\n    def _real_close(self, _ss=_socket.socket):\n        # This function should not reference any globals. See issue #808164.\n        _ss.close(self)\n\n    def close(self):\n        # This function should not reference any globals. See issue #808164.\n        self._closed = True\n        if self._io_refs <= 0:\n            self._real_close()\n\n    def detach(self):\n        \"\"\"detach() -> file descriptor\n\n        Close the socket object without closing the underlying file descriptor.\n        The object cannot be used after this call, but the file descriptor\n        can be reused for other purposes.  The file descriptor is returned.\n        \"\"\"\n        self._closed = True\n        return super().detach()\n\ndef fromfd(fd, family, type, proto=0):\n    \"\"\" fromfd(fd, family, type[, proto]) -> socket object\n\n    Create a socket object from a duplicate of the given file\n    descriptor.  The remaining arguments are the same as for socket().\n    \"\"\"\n    nfd = dup(fd)\n    return socket(family, type, proto, nfd)\n\nif hasattr(_socket.socket, \"share\"):\n    def fromshare(info):\n        \"\"\" fromshare(info) -> socket object\n\n        Create a socket object from a the bytes object returned by\n        socket.share(pid).\n        \"\"\"\n        return socket(0, 0, 0, info)\n\nif hasattr(_socket, \"socketpair\"):\n\n    def socketpair(family=None, type=SOCK_STREAM, proto=0):\n        \"\"\"socketpair([family[, type[, proto]]]) -> (socket object, socket object)\n\n        Create a pair of socket objects from the sockets returned by the platform\n        socketpair() function.\n        The arguments are the same as for socket() except the default family is\n        AF_UNIX if defined on the platform; otherwise, the default is AF_INET.\n        \"\"\"\n        if family is None:\n            try:\n                family = AF_UNIX\n            except NameError:\n                family = AF_INET\n        a, b = _socket.socketpair(family, type, proto)\n        a = socket(family, type, proto, a.detach())\n        b = socket(family, type, proto, b.detach())\n        return a, b\n\n\n_blocking_errnos = { EAGAIN, EWOULDBLOCK }\n\nclass SocketIO(io.RawIOBase):\n\n    \"\"\"Raw I/O implementation for stream sockets.\n\n    This class supports the makefile() method on sockets.  It provides\n    the raw I/O interface on top of a socket object.\n    \"\"\"\n\n    # One might wonder why not let FileIO do the job instead.  There are two\n    # main reasons why FileIO is not adapted:\n    # - it wouldn't work under Windows (where you can't used read() and\n    #   write() on a socket handle)\n    # - it wouldn't work with socket timeouts (FileIO would ignore the\n    #   timeout and consider the socket non-blocking)\n\n    # XXX More docs\n\n    def __init__(self, sock, mode):\n        if mode not in (\"r\", \"w\", \"rw\", \"rb\", \"wb\", \"rwb\"):\n            raise ValueError(\"invalid mode: %r\" % mode)\n        io.RawIOBase.__init__(self)\n        self._sock = sock\n        if \"b\" not in mode:\n            mode += \"b\"\n        self._mode = mode\n        self._reading = \"r\" in mode\n        self._writing = \"w\" in mode\n        self._timeout_occurred = False\n\n    def readinto(self, b):\n        \"\"\"Read up to len(b) bytes into the writable buffer *b* and return\n        the number of bytes read.  If the socket is non-blocking and no bytes\n        are available, None is returned.\n\n        If *b* is non-empty, a 0 return value indicates that the connection\n        was shutdown at the other end.\n        \"\"\"\n        self._checkClosed()\n        self._checkReadable()\n        if self._timeout_occurred:\n            raise IOError(\"cannot read from timed out object\")\n        while True:\n            try:\n                return self._sock.recv_into(b)\n            except timeout:\n                self._timeout_occurred = True\n                raise\n            except InterruptedError:\n                continue\n            except error as e:\n                if e.args[0] in _blocking_errnos:\n                    return None\n                raise\n\n    def write(self, b):\n        \"\"\"Write the given bytes or bytearray object *b* to the socket\n        and return the number of bytes written.  This can be less than\n        len(b) if not all data could be written.  If the socket is\n        non-blocking and no bytes could be written None is returned.\n        \"\"\"\n        self._checkClosed()\n        self._checkWritable()\n        try:\n            return self._sock.send(b)\n        except error as e:\n            # XXX what about EINTR?\n            if e.args[0] in _blocking_errnos:\n                return None\n            raise\n\n    def readable(self):\n        \"\"\"True if the SocketIO is open for reading.\n        \"\"\"\n        if self.closed:\n            raise ValueError(\"I/O operation on closed socket.\")\n        return self._reading\n\n    def writable(self):\n        \"\"\"True if the SocketIO is open for writing.\n        \"\"\"\n        if self.closed:\n            raise ValueError(\"I/O operation on closed socket.\")\n        return self._writing\n\n    def seekable(self):\n        \"\"\"True if the SocketIO is open for seeking.\n        \"\"\"\n        if self.closed:\n            raise ValueError(\"I/O operation on closed socket.\")\n        return super().seekable()\n\n    def fileno(self):\n        \"\"\"Return the file descriptor of the underlying socket.\n        \"\"\"\n        self._checkClosed()\n        return self._sock.fileno()\n\n    @property\n    def name(self):\n        if not self.closed:\n            return self.fileno()\n        else:\n            return -1\n\n    @property\n    def mode(self):\n        return self._mode\n\n    def close(self):\n        \"\"\"Close the SocketIO object.  This doesn't close the underlying\n        socket, except if all references to it have disappeared.\n        \"\"\"\n        if self.closed:\n            return\n        io.RawIOBase.close(self)\n        self._sock._decref_socketios()\n        self._sock = None\n\n\ndef getfqdn(name=''):\n    \"\"\"Get fully qualified domain name from name.\n\n    An empty argument is interpreted as meaning the local host.\n\n    First the hostname returned by gethostbyaddr() is checked, then\n    possibly existing aliases. In case no FQDN is available, hostname\n    from gethostname() is returned.\n    \"\"\"\n    name = name.strip()\n    if not name or name == '0.0.0.0':\n        name = gethostname()\n    try:\n        hostname, aliases, ipaddrs = gethostbyaddr(name)\n    except error:\n        pass\n    else:\n        aliases.insert(0, hostname)\n        for name in aliases:\n            if '.' in name:\n                break\n        else:\n            name = hostname\n    return name\n\n\n_GLOBAL_DEFAULT_TIMEOUT = object()\n\ndef create_connection(address, timeout=_GLOBAL_DEFAULT_TIMEOUT,\n                      source_address=None):\n    \"\"\"Connect to *address* and return the socket object.\n\n    Convenience function.  Connect to *address* (a 2-tuple ``(host,\n    port)``) and return the socket object.  Passing the optional\n    *timeout* parameter will set the timeout on the socket instance\n    before attempting to connect.  If no *timeout* is supplied, the\n    global default timeout setting returned by :func:`getdefaulttimeout`\n    is used.  If *source_address* is set it must be a tuple of (host, port)\n    for the socket to bind as a source address before making the connection.\n    An host of '' or port 0 tells the OS to use the default.\n    \"\"\"\n\n    host, port = address\n    err = None\n    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n        af, socktype, proto, canonname, sa = res\n        sock = None\n        try:\n            sock = socket(af, socktype, proto)\n            if timeout is not _GLOBAL_DEFAULT_TIMEOUT:\n                sock.settimeout(timeout)\n            if source_address:\n                sock.bind(source_address)\n            sock.connect(sa)\n            return sock\n\n        except error as _:\n            err = _\n            if sock is not None:\n                sock.close()\n\n    if err is not None:\n        raise err\n    else:\n        raise error(\"getaddrinfo returns an empty list\")\n"], "xml.etree": [".py", "# $Id: __init__.py 3375 2008-02-13 08:05:08Z fredrik $\n# elementtree package\n\n# --------------------------------------------------------------------\n# The ElementTree toolkit is\n#\n# Copyright (c) 1999-2008 by Fredrik Lundh\n#\n# By obtaining, using, and/or copying this software and/or its\n# associated documentation, you agree that you have read, understood,\n# and will comply with the following terms and conditions:\n#\n# Permission to use, copy, modify, and distribute this software and\n# its associated documentation for any purpose and without fee is\n# hereby granted, provided that the above copyright notice appears in\n# all copies, and that both that copyright notice and this permission\n# notice appear in supporting documentation, and that the name of\n# Secret Labs AB or the author not be used in advertising or publicity\n# pertaining to distribution of the software without specific, written\n# prior permission.\n#\n# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD\n# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-\n# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR\n# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY\n# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,\n# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE\n# OF THIS SOFTWARE.\n# --------------------------------------------------------------------\n\n# Licensed to PSF under a Contributor Agreement.\n# See http://www.python.org/psf/license for licensing details.\n", 1], "traceback": [".py", "import sys\ndef print_exc(file=sys.stderr):\n    exc = __BRYTHON__.exception_stack[-1]\n    file.write(exc.info)\n    file.write('\\n'+exc.__name__)\n    if exc.message:\n        file.write(': '+exc.message)\n    file.write('\\n')\n\ndef format_exc(limit=None,chain=True):\n    exc = __BRYTHON__.exception_stack[-1]\n    res = exc.info+'\\n'+exc.__name__\n    if exc.message:\n        res += ': '+exc.message\n    return res+'\\n'\n\ndef format_exception(_type, value, tb, limit=None, chain=True):\n    return ['%s\\n' %_type,'%s\\n' %value]    \n"], "test.re_tests": [".py", "#!/usr/bin/env python3\n# -*- mode: python -*-\n\n# Re test suite and benchmark suite v1.5\n\n# The 3 possible outcomes for each pattern\n[SUCCEED, FAIL, SYNTAX_ERROR] = range(3)\n\n# Benchmark suite (needs expansion)\n#\n# The benchmark suite does not test correctness, just speed.  The\n# first element of each tuple is the regex pattern; the second is a\n# string to match it against.  The benchmarking code will embed the\n# second string inside several sizes of padding, to test how regex\n# matching performs on large strings.\n\nbenchmarks = [\n\n    # test common prefix\n    ('Python|Perl', 'Perl'),    # Alternation\n    ('(Python|Perl)', 'Perl'),  # Grouped alternation\n\n    ('Python|Perl|Tcl', 'Perl'),        # Alternation\n    ('(Python|Perl|Tcl)', 'Perl'),      # Grouped alternation\n\n    ('(Python)\\\\1', 'PythonPython'),    # Backreference\n    ('([0a-z][a-z0-9]*,)+', 'a5,b7,c9,'), # Disable the fastmap optimization\n    ('([a-z][a-z0-9]*,)+', 'a5,b7,c9,'), # A few sets\n\n    ('Python', 'Python'),               # Simple text literal\n    ('.*Python', 'Python'),             # Bad text literal\n    ('.*Python.*', 'Python'),           # Worse text literal\n    ('.*(Python)', 'Python'),           # Bad text literal with grouping\n\n]\n\n# Test suite (for verifying correctness)\n#\n# The test suite is a list of 5- or 3-tuples.  The 5 parts of a\n# complete tuple are:\n# element 0: a string containing the pattern\n#         1: the string to match against the pattern\n#         2: the expected result (SUCCEED, FAIL, SYNTAX_ERROR)\n#         3: a string that will be eval()'ed to produce a test string.\n#            This is an arbitrary Python expression; the available\n#            variables are \"found\" (the whole match), and \"g1\", \"g2\", ...\n#            up to \"g99\" contain the contents of each group, or the\n#            string 'None' if the group wasn't given a value, or the\n#            string 'Error' if the group index was out of range;\n#            also \"groups\", the return value of m.group() (a tuple).\n#         4: The expected result of evaluating the expression.\n#            If the two don't match, an error is reported.\n#\n# If the regex isn't expected to work, the latter two elements can be omitted.\n\ntests = [\n    # Test ?P< and ?P= extensions\n    ('(?P<foo_123', '', SYNTAX_ERROR),      # Unterminated group identifier\n    ('(?P<1>a)', '', SYNTAX_ERROR),         # Begins with a digit\n    ('(?P<!>a)', '', SYNTAX_ERROR),         # Begins with an illegal char\n    ('(?P<foo!>a)', '', SYNTAX_ERROR),      # Begins with an illegal char\n\n    # Same tests, for the ?P= form\n    ('(?P<foo_123>a)(?P=foo_123', 'aa', SYNTAX_ERROR),\n    ('(?P<foo_123>a)(?P=1)', 'aa', SYNTAX_ERROR),\n    ('(?P<foo_123>a)(?P=!)', 'aa', SYNTAX_ERROR),\n    ('(?P<foo_123>a)(?P=foo_124', 'aa', SYNTAX_ERROR),  # Backref to undefined group\n\n    ('(?P<foo_123>a)', 'a', SUCCEED, 'g1', 'a'),\n    ('(?P<foo_123>a)(?P=foo_123)', 'aa', SUCCEED, 'g1', 'a'),\n\n    # Test octal escapes\n    ('\\\\1', 'a', SYNTAX_ERROR),    # Backreference\n    ('[\\\\1]', '\\1', SUCCEED, 'found', '\\1'),  # Character\n    ('\\\\09', chr(0) + '9', SUCCEED, 'found', chr(0) + '9'),\n    ('\\\\141', 'a', SUCCEED, 'found', 'a'),\n    ('(a)(b)(c)(d)(e)(f)(g)(h)(i)(j)(k)(l)\\\\119', 'abcdefghijklk9', SUCCEED, 'found+\"-\"+g11', 'abcdefghijklk9-k'),\n\n    # Test \\0 is handled everywhere\n    (r'\\0', '\\0', SUCCEED, 'found', '\\0'),\n    (r'[\\0a]', '\\0', SUCCEED, 'found', '\\0'),\n    (r'[a\\0]', '\\0', SUCCEED, 'found', '\\0'),\n    (r'[^a\\0]', '\\0', FAIL),\n\n    # Test various letter escapes\n    (r'\\a[\\b]\\f\\n\\r\\t\\v', '\\a\\b\\f\\n\\r\\t\\v', SUCCEED, 'found', '\\a\\b\\f\\n\\r\\t\\v'),\n    (r'[\\a][\\b][\\f][\\n][\\r][\\t][\\v]', '\\a\\b\\f\\n\\r\\t\\v', SUCCEED, 'found', '\\a\\b\\f\\n\\r\\t\\v'),\n    # NOTE: not an error under PCRE/PRE:\n    # (r'\\u', '', SYNTAX_ERROR),    # A Perl escape\n    (r'\\c\\e\\g\\h\\i\\j\\k\\m\\o\\p\\q\\y\\z', 'ceghijkmopqyz', SUCCEED, 'found', 'ceghijkmopqyz'),\n    (r'\\xff', '\\377', SUCCEED, 'found', chr(255)),\n    # new \\x semantics\n    (r'\\x00ffffffffffffff', '\\377', FAIL, 'found', chr(255)),\n    (r'\\x00f', '\\017', FAIL, 'found', chr(15)),\n    (r'\\x00fe', '\\376', FAIL, 'found', chr(254)),\n    # (r'\\x00ffffffffffffff', '\\377', SUCCEED, 'found', chr(255)),\n    # (r'\\x00f', '\\017', SUCCEED, 'found', chr(15)),\n    # (r'\\x00fe', '\\376', SUCCEED, 'found', chr(254)),\n\n    (r\"^\\w+=(\\\\[\\000-\\277]|[^\\n\\\\])*\", \"SRC=eval.c g.c blah blah blah \\\\\\\\\\n\\tapes.c\",\n     SUCCEED, 'found', \"SRC=eval.c g.c blah blah blah \\\\\\\\\"),\n\n    # Test that . only matches \\n in DOTALL mode\n    ('a.b', 'acb', SUCCEED, 'found', 'acb'),\n    ('a.b', 'a\\nb', FAIL),\n    ('a.*b', 'acc\\nccb', FAIL),\n    ('a.{4,5}b', 'acc\\nccb', FAIL),\n    ('a.b', 'a\\rb', SUCCEED, 'found', 'a\\rb'),\n    ('a.b(?s)', 'a\\nb', SUCCEED, 'found', 'a\\nb'),\n    ('a.*(?s)b', 'acc\\nccb', SUCCEED, 'found', 'acc\\nccb'),\n    ('(?s)a.{4,5}b', 'acc\\nccb', SUCCEED, 'found', 'acc\\nccb'),\n    ('(?s)a.b', 'a\\nb', SUCCEED, 'found', 'a\\nb'),\n\n    (')', '', SYNTAX_ERROR),           # Unmatched right bracket\n    ('', '', SUCCEED, 'found', ''),    # Empty pattern\n    ('abc', 'abc', SUCCEED, 'found', 'abc'),\n    ('abc', 'xbc', FAIL),\n    ('abc', 'axc', FAIL),\n    ('abc', 'abx', FAIL),\n    ('abc', 'xabcy', SUCCEED, 'found', 'abc'),\n    ('abc', 'ababc', SUCCEED, 'found', 'abc'),\n    ('ab*c', 'abc', SUCCEED, 'found', 'abc'),\n    ('ab*bc', 'abc', SUCCEED, 'found', 'abc'),\n    ('ab*bc', 'abbc', SUCCEED, 'found', 'abbc'),\n    ('ab*bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n    ('ab+bc', 'abbc', SUCCEED, 'found', 'abbc'),\n    ('ab+bc', 'abc', FAIL),\n    ('ab+bc', 'abq', FAIL),\n    ('ab+bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n    ('ab?bc', 'abbc', SUCCEED, 'found', 'abbc'),\n    ('ab?bc', 'abc', SUCCEED, 'found', 'abc'),\n    ('ab?bc', 'abbbbc', FAIL),\n    ('ab?c', 'abc', SUCCEED, 'found', 'abc'),\n    ('^abc$', 'abc', SUCCEED, 'found', 'abc'),\n    ('^abc$', 'abcc', FAIL),\n    ('^abc', 'abcc', SUCCEED, 'found', 'abc'),\n    ('^abc$', 'aabc', FAIL),\n    ('abc$', 'aabc', SUCCEED, 'found', 'abc'),\n    ('^', 'abc', SUCCEED, 'found+\"-\"', '-'),\n    ('$', 'abc', SUCCEED, 'found+\"-\"', '-'),\n    ('a.c', 'abc', SUCCEED, 'found', 'abc'),\n    ('a.c', 'axc', SUCCEED, 'found', 'axc'),\n    ('a.*c', 'axyzc', SUCCEED, 'found', 'axyzc'),\n    ('a.*c', 'axyzd', FAIL),\n    ('a[bc]d', 'abc', FAIL),\n    ('a[bc]d', 'abd', SUCCEED, 'found', 'abd'),\n    ('a[b-d]e', 'abd', FAIL),\n    ('a[b-d]e', 'ace', SUCCEED, 'found', 'ace'),\n    ('a[b-d]', 'aac', SUCCEED, 'found', 'ac'),\n    ('a[-b]', 'a-', SUCCEED, 'found', 'a-'),\n    ('a[\\\\-b]', 'a-', SUCCEED, 'found', 'a-'),\n    # NOTE: not an error under PCRE/PRE:\n    # ('a[b-]', 'a-', SYNTAX_ERROR),\n    ('a[]b', '-', SYNTAX_ERROR),\n    ('a[', '-', SYNTAX_ERROR),\n    ('a\\\\', '-', SYNTAX_ERROR),\n    ('abc)', '-', SYNTAX_ERROR),\n    ('(abc', '-', SYNTAX_ERROR),\n    ('a]', 'a]', SUCCEED, 'found', 'a]'),\n    ('a[]]b', 'a]b', SUCCEED, 'found', 'a]b'),\n    ('a[\\]]b', 'a]b', SUCCEED, 'found', 'a]b'),\n    ('a[^bc]d', 'aed', SUCCEED, 'found', 'aed'),\n    ('a[^bc]d', 'abd', FAIL),\n    ('a[^-b]c', 'adc', SUCCEED, 'found', 'adc'),\n    ('a[^-b]c', 'a-c', FAIL),\n    ('a[^]b]c', 'a]c', FAIL),\n    ('a[^]b]c', 'adc', SUCCEED, 'found', 'adc'),\n    ('\\\\ba\\\\b', 'a-', SUCCEED, '\"-\"', '-'),\n    ('\\\\ba\\\\b', '-a', SUCCEED, '\"-\"', '-'),\n    ('\\\\ba\\\\b', '-a-', SUCCEED, '\"-\"', '-'),\n    ('\\\\by\\\\b', 'xy', FAIL),\n    ('\\\\by\\\\b', 'yz', FAIL),\n    ('\\\\by\\\\b', 'xyz', FAIL),\n    ('x\\\\b', 'xyz', FAIL),\n    ('x\\\\B', 'xyz', SUCCEED, '\"-\"', '-'),\n    ('\\\\Bz', 'xyz', SUCCEED, '\"-\"', '-'),\n    ('z\\\\B', 'xyz', FAIL),\n    ('\\\\Bx', 'xyz', FAIL),\n    ('\\\\Ba\\\\B', 'a-', FAIL, '\"-\"', '-'),\n    ('\\\\Ba\\\\B', '-a', FAIL, '\"-\"', '-'),\n    ('\\\\Ba\\\\B', '-a-', FAIL, '\"-\"', '-'),\n    ('\\\\By\\\\B', 'xy', FAIL),\n    ('\\\\By\\\\B', 'yz', FAIL),\n    ('\\\\By\\\\b', 'xy', SUCCEED, '\"-\"', '-'),\n    ('\\\\by\\\\B', 'yz', SUCCEED, '\"-\"', '-'),\n    ('\\\\By\\\\B', 'xyz', SUCCEED, '\"-\"', '-'),\n    ('ab|cd', 'abc', SUCCEED, 'found', 'ab'),\n    ('ab|cd', 'abcd', SUCCEED, 'found', 'ab'),\n    ('()ef', 'def', SUCCEED, 'found+\"-\"+g1', 'ef-'),\n    ('$b', 'b', FAIL),\n    ('a\\\\(b', 'a(b', SUCCEED, 'found+\"-\"+g1', 'a(b-Error'),\n    ('a\\\\(*b', 'ab', SUCCEED, 'found', 'ab'),\n    ('a\\\\(*b', 'a((b', SUCCEED, 'found', 'a((b'),\n    ('a\\\\\\\\b', 'a\\\\b', SUCCEED, 'found', 'a\\\\b'),\n    ('((a))', 'abc', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'a-a-a'),\n    ('(a)b(c)', 'abc', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abc-a-c'),\n    ('a+b+c', 'aabbabc', SUCCEED, 'found', 'abc'),\n    ('(a+|b)*', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n    ('(a+|b)+', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n    ('(a+|b)?', 'ab', SUCCEED, 'found+\"-\"+g1', 'a-a'),\n    (')(', '-', SYNTAX_ERROR),\n    ('[^ab]*', 'cde', SUCCEED, 'found', 'cde'),\n    ('abc', '', FAIL),\n    ('a*', '', SUCCEED, 'found', ''),\n    ('a|b|c|d|e', 'e', SUCCEED, 'found', 'e'),\n    ('(a|b|c|d|e)f', 'ef', SUCCEED, 'found+\"-\"+g1', 'ef-e'),\n    ('abcd*efg', 'abcdefg', SUCCEED, 'found', 'abcdefg'),\n    ('ab*', 'xabyabbbz', SUCCEED, 'found', 'ab'),\n    ('ab*', 'xayabbbz', SUCCEED, 'found', 'a'),\n    ('(ab|cd)e', 'abcde', SUCCEED, 'found+\"-\"+g1', 'cde-cd'),\n    ('[abhgefdc]ij', 'hij', SUCCEED, 'found', 'hij'),\n    ('^(ab|cd)e', 'abcde', FAIL, 'xg1y', 'xy'),\n    ('(abc|)ef', 'abcdef', SUCCEED, 'found+\"-\"+g1', 'ef-'),\n    ('(a|b)c*d', 'abcd', SUCCEED, 'found+\"-\"+g1', 'bcd-b'),\n    ('(ab|ab*)bc', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-a'),\n    ('a([bc]*)c*', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-bc'),\n    ('a([bc]*)(c*d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-bc-d'),\n    ('a([bc]+)(c*d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-bc-d'),\n    ('a([bc]*)(c+d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-b-cd'),\n    ('a[bcd]*dcdcde', 'adcdcde', SUCCEED, 'found', 'adcdcde'),\n    ('a[bcd]+dcdcde', 'adcdcde', FAIL),\n    ('(ab|a)b*c', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-ab'),\n    ('((a)(b)c)(d)', 'abcd', SUCCEED, 'g1+\"-\"+g2+\"-\"+g3+\"-\"+g4', 'abc-a-b-d'),\n    ('[a-zA-Z_][a-zA-Z0-9_]*', 'alpha', SUCCEED, 'found', 'alpha'),\n    ('^a(bc+|b[eh])g|.h$', 'abh', SUCCEED, 'found+\"-\"+g1', 'bh-None'),\n    ('(bc+d$|ef*g.|h?i(j|k))', 'effgz', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'effgz-effgz-None'),\n    ('(bc+d$|ef*g.|h?i(j|k))', 'ij', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ij-ij-j'),\n    ('(bc+d$|ef*g.|h?i(j|k))', 'effg', FAIL),\n    ('(bc+d$|ef*g.|h?i(j|k))', 'bcdd', FAIL),\n    ('(bc+d$|ef*g.|h?i(j|k))', 'reffgz', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'effgz-effgz-None'),\n    ('(((((((((a)))))))))', 'a', SUCCEED, 'found', 'a'),\n    ('multiple words of text', 'uh-uh', FAIL),\n    ('multiple words', 'multiple words, yeah', SUCCEED, 'found', 'multiple words'),\n    ('(.*)c(.*)', 'abcde', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcde-ab-de'),\n    ('\\\\((.*), (.*)\\\\)', '(a, b)', SUCCEED, 'g2+\"-\"+g1', 'b-a'),\n    ('[k]', 'ab', FAIL),\n    ('a[-]?c', 'ac', SUCCEED, 'found', 'ac'),\n    ('(abc)\\\\1', 'abcabc', SUCCEED, 'g1', 'abc'),\n    ('([a-c]*)\\\\1', 'abcabc', SUCCEED, 'g1', 'abc'),\n    ('^(.+)?B', 'AB', SUCCEED, 'g1', 'A'),\n    ('(a+).\\\\1$', 'aaaaa', SUCCEED, 'found+\"-\"+g1', 'aaaaa-aa'),\n    ('^(a+).\\\\1$', 'aaaa', FAIL),\n    ('(abc)\\\\1', 'abcabc', SUCCEED, 'found+\"-\"+g1', 'abcabc-abc'),\n    ('([a-c]+)\\\\1', 'abcabc', SUCCEED, 'found+\"-\"+g1', 'abcabc-abc'),\n    ('(a)\\\\1', 'aa', SUCCEED, 'found+\"-\"+g1', 'aa-a'),\n    ('(a+)\\\\1', 'aa', SUCCEED, 'found+\"-\"+g1', 'aa-a'),\n    ('(a+)+\\\\1', 'aa', SUCCEED, 'found+\"-\"+g1', 'aa-a'),\n    ('(a).+\\\\1', 'aba', SUCCEED, 'found+\"-\"+g1', 'aba-a'),\n    ('(a)ba*\\\\1', 'aba', SUCCEED, 'found+\"-\"+g1', 'aba-a'),\n    ('(aa|a)a\\\\1$', 'aaa', SUCCEED, 'found+\"-\"+g1', 'aaa-a'),\n    ('(a|aa)a\\\\1$', 'aaa', SUCCEED, 'found+\"-\"+g1', 'aaa-a'),\n    ('(a+)a\\\\1$', 'aaa', SUCCEED, 'found+\"-\"+g1', 'aaa-a'),\n    ('([abc]*)\\\\1', 'abcabc', SUCCEED, 'found+\"-\"+g1', 'abcabc-abc'),\n    ('(a)(b)c|ab', 'ab', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ab-None-None'),\n    ('(a)+x', 'aaax', SUCCEED, 'found+\"-\"+g1', 'aaax-a'),\n    ('([ac])+x', 'aacx', SUCCEED, 'found+\"-\"+g1', 'aacx-c'),\n    ('([^/]*/)*sub1/', 'd:msgs/tdir/sub1/trial/away.cpp', SUCCEED, 'found+\"-\"+g1', 'd:msgs/tdir/sub1/-tdir/'),\n    ('([^.]*)\\\\.([^:]*):[T ]+(.*)', 'track1.title:TBlah blah blah', SUCCEED, 'found+\"-\"+g1+\"-\"+g2+\"-\"+g3', 'track1.title:TBlah blah blah-track1-title-Blah blah blah'),\n    ('([^N]*N)+', 'abNNxyzN', SUCCEED, 'found+\"-\"+g1', 'abNNxyzN-xyzN'),\n    ('([^N]*N)+', 'abNNxyz', SUCCEED, 'found+\"-\"+g1', 'abNN-N'),\n    ('([abc]*)x', 'abcx', SUCCEED, 'found+\"-\"+g1', 'abcx-abc'),\n    ('([abc]*)x', 'abc', FAIL),\n    ('([xyz]*)x', 'abcx', SUCCEED, 'found+\"-\"+g1', 'x-'),\n    ('(a)+b|aac', 'aac', SUCCEED, 'found+\"-\"+g1', 'aac-None'),\n\n    # Test symbolic groups\n\n    ('(?P<i d>aaa)a', 'aaaa', SYNTAX_ERROR),\n    ('(?P<id>aaa)a', 'aaaa', SUCCEED, 'found+\"-\"+id', 'aaaa-aaa'),\n    ('(?P<id>aa)(?P=id)', 'aaaa', SUCCEED, 'found+\"-\"+id', 'aaaa-aa'),\n    ('(?P<id>aa)(?P=xd)', 'aaaa', SYNTAX_ERROR),\n\n    # Test octal escapes/memory references\n\n    ('\\\\1', 'a', SYNTAX_ERROR),\n    ('\\\\09', chr(0) + '9', SUCCEED, 'found', chr(0) + '9'),\n    ('\\\\141', 'a', SUCCEED, 'found', 'a'),\n    ('(a)(b)(c)(d)(e)(f)(g)(h)(i)(j)(k)(l)\\\\119', 'abcdefghijklk9', SUCCEED, 'found+\"-\"+g11', 'abcdefghijklk9-k'),\n\n    # All tests from Perl\n\n    ('abc', 'abc', SUCCEED, 'found', 'abc'),\n    ('abc', 'xbc', FAIL),\n    ('abc', 'axc', FAIL),\n    ('abc', 'abx', FAIL),\n    ('abc', 'xabcy', SUCCEED, 'found', 'abc'),\n    ('abc', 'ababc', SUCCEED, 'found', 'abc'),\n    ('ab*c', 'abc', SUCCEED, 'found', 'abc'),\n    ('ab*bc', 'abc', SUCCEED, 'found', 'abc'),\n    ('ab*bc', 'abbc', SUCCEED, 'found', 'abbc'),\n    ('ab*bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n    ('ab{0,}bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n    ('ab+bc', 'abbc', SUCCEED, 'found', 'abbc'),\n    ('ab+bc', 'abc', FAIL),\n    ('ab+bc', 'abq', FAIL),\n    ('ab{1,}bc', 'abq', FAIL),\n    ('ab+bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n    ('ab{1,}bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n    ('ab{1,3}bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n    ('ab{3,4}bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n    ('ab{4,5}bc', 'abbbbc', FAIL),\n    ('ab?bc', 'abbc', SUCCEED, 'found', 'abbc'),\n    ('ab?bc', 'abc', SUCCEED, 'found', 'abc'),\n    ('ab{0,1}bc', 'abc', SUCCEED, 'found', 'abc'),\n    ('ab?bc', 'abbbbc', FAIL),\n    ('ab?c', 'abc', SUCCEED, 'found', 'abc'),\n    ('ab{0,1}c', 'abc', SUCCEED, 'found', 'abc'),\n    ('^abc$', 'abc', SUCCEED, 'found', 'abc'),\n    ('^abc$', 'abcc', FAIL),\n    ('^abc', 'abcc', SUCCEED, 'found', 'abc'),\n    ('^abc$', 'aabc', FAIL),\n    ('abc$', 'aabc', SUCCEED, 'found', 'abc'),\n    ('^', 'abc', SUCCEED, 'found', ''),\n    ('$', 'abc', SUCCEED, 'found', ''),\n    ('a.c', 'abc', SUCCEED, 'found', 'abc'),\n    ('a.c', 'axc', SUCCEED, 'found', 'axc'),\n    ('a.*c', 'axyzc', SUCCEED, 'found', 'axyzc'),\n    ('a.*c', 'axyzd', FAIL),\n    ('a[bc]d', 'abc', FAIL),\n    ('a[bc]d', 'abd', SUCCEED, 'found', 'abd'),\n    ('a[b-d]e', 'abd', FAIL),\n    ('a[b-d]e', 'ace', SUCCEED, 'found', 'ace'),\n    ('a[b-d]', 'aac', SUCCEED, 'found', 'ac'),\n    ('a[-b]', 'a-', SUCCEED, 'found', 'a-'),\n    ('a[b-]', 'a-', SUCCEED, 'found', 'a-'),\n    ('a[b-a]', '-', SYNTAX_ERROR),\n    ('a[]b', '-', SYNTAX_ERROR),\n    ('a[', '-', SYNTAX_ERROR),\n    ('a]', 'a]', SUCCEED, 'found', 'a]'),\n    ('a[]]b', 'a]b', SUCCEED, 'found', 'a]b'),\n    ('a[^bc]d', 'aed', SUCCEED, 'found', 'aed'),\n    ('a[^bc]d', 'abd', FAIL),\n    ('a[^-b]c', 'adc', SUCCEED, 'found', 'adc'),\n    ('a[^-b]c', 'a-c', FAIL),\n    ('a[^]b]c', 'a]c', FAIL),\n    ('a[^]b]c', 'adc', SUCCEED, 'found', 'adc'),\n    ('ab|cd', 'abc', SUCCEED, 'found', 'ab'),\n    ('ab|cd', 'abcd', SUCCEED, 'found', 'ab'),\n    ('()ef', 'def', SUCCEED, 'found+\"-\"+g1', 'ef-'),\n    ('*a', '-', SYNTAX_ERROR),\n    ('(*)b', '-', SYNTAX_ERROR),\n    ('$b', 'b', FAIL),\n    ('a\\\\', '-', SYNTAX_ERROR),\n    ('a\\\\(b', 'a(b', SUCCEED, 'found+\"-\"+g1', 'a(b-Error'),\n    ('a\\\\(*b', 'ab', SUCCEED, 'found', 'ab'),\n    ('a\\\\(*b', 'a((b', SUCCEED, 'found', 'a((b'),\n    ('a\\\\\\\\b', 'a\\\\b', SUCCEED, 'found', 'a\\\\b'),\n    ('abc)', '-', SYNTAX_ERROR),\n    ('(abc', '-', SYNTAX_ERROR),\n    ('((a))', 'abc', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'a-a-a'),\n    ('(a)b(c)', 'abc', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abc-a-c'),\n    ('a+b+c', 'aabbabc', SUCCEED, 'found', 'abc'),\n    ('a{1,}b{1,}c', 'aabbabc', SUCCEED, 'found', 'abc'),\n    ('a**', '-', SYNTAX_ERROR),\n    ('a.+?c', 'abcabc', SUCCEED, 'found', 'abc'),\n    ('(a+|b)*', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n    ('(a+|b){0,}', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n    ('(a+|b)+', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n    ('(a+|b){1,}', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n    ('(a+|b)?', 'ab', SUCCEED, 'found+\"-\"+g1', 'a-a'),\n    ('(a+|b){0,1}', 'ab', SUCCEED, 'found+\"-\"+g1', 'a-a'),\n    (')(', '-', SYNTAX_ERROR),\n    ('[^ab]*', 'cde', SUCCEED, 'found', 'cde'),\n    ('abc', '', FAIL),\n    ('a*', '', SUCCEED, 'found', ''),\n    ('([abc])*d', 'abbbcd', SUCCEED, 'found+\"-\"+g1', 'abbbcd-c'),\n    ('([abc])*bcd', 'abcd', SUCCEED, 'found+\"-\"+g1', 'abcd-a'),\n    ('a|b|c|d|e', 'e', SUCCEED, 'found', 'e'),\n    ('(a|b|c|d|e)f', 'ef', SUCCEED, 'found+\"-\"+g1', 'ef-e'),\n    ('abcd*efg', 'abcdefg', SUCCEED, 'found', 'abcdefg'),\n    ('ab*', 'xabyabbbz', SUCCEED, 'found', 'ab'),\n    ('ab*', 'xayabbbz', SUCCEED, 'found', 'a'),\n    ('(ab|cd)e', 'abcde', SUCCEED, 'found+\"-\"+g1', 'cde-cd'),\n    ('[abhgefdc]ij', 'hij', SUCCEED, 'found', 'hij'),\n    ('^(ab|cd)e', 'abcde', FAIL),\n    ('(abc|)ef', 'abcdef', SUCCEED, 'found+\"-\"+g1', 'ef-'),\n    ('(a|b)c*d', 'abcd', SUCCEED, 'found+\"-\"+g1', 'bcd-b'),\n    ('(ab|ab*)bc', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-a'),\n    ('a([bc]*)c*', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-bc'),\n    ('a([bc]*)(c*d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-bc-d'),\n    ('a([bc]+)(c*d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-bc-d'),\n    ('a([bc]*)(c+d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-b-cd'),\n    ('a[bcd]*dcdcde', 'adcdcde', SUCCEED, 'found', 'adcdcde'),\n    ('a[bcd]+dcdcde', 'adcdcde', FAIL),\n    ('(ab|a)b*c', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-ab'),\n    ('((a)(b)c)(d)', 'abcd', SUCCEED, 'g1+\"-\"+g2+\"-\"+g3+\"-\"+g4', 'abc-a-b-d'),\n    ('[a-zA-Z_][a-zA-Z0-9_]*', 'alpha', SUCCEED, 'found', 'alpha'),\n    ('^a(bc+|b[eh])g|.h$', 'abh', SUCCEED, 'found+\"-\"+g1', 'bh-None'),\n    ('(bc+d$|ef*g.|h?i(j|k))', 'effgz', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'effgz-effgz-None'),\n    ('(bc+d$|ef*g.|h?i(j|k))', 'ij', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ij-ij-j'),\n    ('(bc+d$|ef*g.|h?i(j|k))', 'effg', FAIL),\n    ('(bc+d$|ef*g.|h?i(j|k))', 'bcdd', FAIL),\n    ('(bc+d$|ef*g.|h?i(j|k))', 'reffgz', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'effgz-effgz-None'),\n    ('((((((((((a))))))))))', 'a', SUCCEED, 'g10', 'a'),\n    ('((((((((((a))))))))))\\\\10', 'aa', SUCCEED, 'found', 'aa'),\n# Python does not have the same rules for \\\\41 so this is a syntax error\n#    ('((((((((((a))))))))))\\\\41', 'aa', FAIL),\n#    ('((((((((((a))))))))))\\\\41', 'a!', SUCCEED, 'found', 'a!'),\n    ('((((((((((a))))))))))\\\\41', '', SYNTAX_ERROR),\n    ('(?i)((((((((((a))))))))))\\\\41', '', SYNTAX_ERROR),\n    ('(((((((((a)))))))))', 'a', SUCCEED, 'found', 'a'),\n    ('multiple words of text', 'uh-uh', FAIL),\n    ('multiple words', 'multiple words, yeah', SUCCEED, 'found', 'multiple words'),\n    ('(.*)c(.*)', 'abcde', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcde-ab-de'),\n    ('\\\\((.*), (.*)\\\\)', '(a, b)', SUCCEED, 'g2+\"-\"+g1', 'b-a'),\n    ('[k]', 'ab', FAIL),\n    ('a[-]?c', 'ac', SUCCEED, 'found', 'ac'),\n    ('(abc)\\\\1', 'abcabc', SUCCEED, 'g1', 'abc'),\n    ('([a-c]*)\\\\1', 'abcabc', SUCCEED, 'g1', 'abc'),\n    ('(?i)abc', 'ABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)abc', 'XBC', FAIL),\n    ('(?i)abc', 'AXC', FAIL),\n    ('(?i)abc', 'ABX', FAIL),\n    ('(?i)abc', 'XABCY', SUCCEED, 'found', 'ABC'),\n    ('(?i)abc', 'ABABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)ab*c', 'ABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)ab*bc', 'ABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)ab*bc', 'ABBC', SUCCEED, 'found', 'ABBC'),\n    ('(?i)ab*?bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n    ('(?i)ab{0,}?bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n    ('(?i)ab+?bc', 'ABBC', SUCCEED, 'found', 'ABBC'),\n    ('(?i)ab+bc', 'ABC', FAIL),\n    ('(?i)ab+bc', 'ABQ', FAIL),\n    ('(?i)ab{1,}bc', 'ABQ', FAIL),\n    ('(?i)ab+bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n    ('(?i)ab{1,}?bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n    ('(?i)ab{1,3}?bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n    ('(?i)ab{3,4}?bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n    ('(?i)ab{4,5}?bc', 'ABBBBC', FAIL),\n    ('(?i)ab??bc', 'ABBC', SUCCEED, 'found', 'ABBC'),\n    ('(?i)ab??bc', 'ABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)ab{0,1}?bc', 'ABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)ab??bc', 'ABBBBC', FAIL),\n    ('(?i)ab??c', 'ABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)ab{0,1}?c', 'ABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)^abc$', 'ABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)^abc$', 'ABCC', FAIL),\n    ('(?i)^abc', 'ABCC', SUCCEED, 'found', 'ABC'),\n    ('(?i)^abc$', 'AABC', FAIL),\n    ('(?i)abc$', 'AABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)^', 'ABC', SUCCEED, 'found', ''),\n    ('(?i)$', 'ABC', SUCCEED, 'found', ''),\n    ('(?i)a.c', 'ABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)a.c', 'AXC', SUCCEED, 'found', 'AXC'),\n    ('(?i)a.*?c', 'AXYZC', SUCCEED, 'found', 'AXYZC'),\n    ('(?i)a.*c', 'AXYZD', FAIL),\n    ('(?i)a[bc]d', 'ABC', FAIL),\n    ('(?i)a[bc]d', 'ABD', SUCCEED, 'found', 'ABD'),\n    ('(?i)a[b-d]e', 'ABD', FAIL),\n    ('(?i)a[b-d]e', 'ACE', SUCCEED, 'found', 'ACE'),\n    ('(?i)a[b-d]', 'AAC', SUCCEED, 'found', 'AC'),\n    ('(?i)a[-b]', 'A-', SUCCEED, 'found', 'A-'),\n    ('(?i)a[b-]', 'A-', SUCCEED, 'found', 'A-'),\n    ('(?i)a[b-a]', '-', SYNTAX_ERROR),\n    ('(?i)a[]b', '-', SYNTAX_ERROR),\n    ('(?i)a[', '-', SYNTAX_ERROR),\n    ('(?i)a]', 'A]', SUCCEED, 'found', 'A]'),\n    ('(?i)a[]]b', 'A]B', SUCCEED, 'found', 'A]B'),\n    ('(?i)a[^bc]d', 'AED', SUCCEED, 'found', 'AED'),\n    ('(?i)a[^bc]d', 'ABD', FAIL),\n    ('(?i)a[^-b]c', 'ADC', SUCCEED, 'found', 'ADC'),\n    ('(?i)a[^-b]c', 'A-C', FAIL),\n    ('(?i)a[^]b]c', 'A]C', FAIL),\n    ('(?i)a[^]b]c', 'ADC', SUCCEED, 'found', 'ADC'),\n    ('(?i)ab|cd', 'ABC', SUCCEED, 'found', 'AB'),\n    ('(?i)ab|cd', 'ABCD', SUCCEED, 'found', 'AB'),\n    ('(?i)()ef', 'DEF', SUCCEED, 'found+\"-\"+g1', 'EF-'),\n    ('(?i)*a', '-', SYNTAX_ERROR),\n    ('(?i)(*)b', '-', SYNTAX_ERROR),\n    ('(?i)$b', 'B', FAIL),\n    ('(?i)a\\\\', '-', SYNTAX_ERROR),\n    ('(?i)a\\\\(b', 'A(B', SUCCEED, 'found+\"-\"+g1', 'A(B-Error'),\n    ('(?i)a\\\\(*b', 'AB', SUCCEED, 'found', 'AB'),\n    ('(?i)a\\\\(*b', 'A((B', SUCCEED, 'found', 'A((B'),\n    ('(?i)a\\\\\\\\b', 'A\\\\B', SUCCEED, 'found', 'A\\\\B'),\n    ('(?i)abc)', '-', SYNTAX_ERROR),\n    ('(?i)(abc', '-', SYNTAX_ERROR),\n    ('(?i)((a))', 'ABC', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'A-A-A'),\n    ('(?i)(a)b(c)', 'ABC', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ABC-A-C'),\n    ('(?i)a+b+c', 'AABBABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)a{1,}b{1,}c', 'AABBABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)a**', '-', SYNTAX_ERROR),\n    ('(?i)a.+?c', 'ABCABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)a.*?c', 'ABCABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)a.{0,5}?c', 'ABCABC', SUCCEED, 'found', 'ABC'),\n    ('(?i)(a+|b)*', 'AB', SUCCEED, 'found+\"-\"+g1', 'AB-B'),\n    ('(?i)(a+|b){0,}', 'AB', SUCCEED, 'found+\"-\"+g1', 'AB-B'),\n    ('(?i)(a+|b)+', 'AB', SUCCEED, 'found+\"-\"+g1', 'AB-B'),\n    ('(?i)(a+|b){1,}', 'AB', SUCCEED, 'found+\"-\"+g1', 'AB-B'),\n    ('(?i)(a+|b)?', 'AB', SUCCEED, 'found+\"-\"+g1', 'A-A'),\n    ('(?i)(a+|b){0,1}', 'AB', SUCCEED, 'found+\"-\"+g1', 'A-A'),\n    ('(?i)(a+|b){0,1}?', 'AB', SUCCEED, 'found+\"-\"+g1', '-None'),\n    ('(?i))(', '-', SYNTAX_ERROR),\n    ('(?i)[^ab]*', 'CDE', SUCCEED, 'found', 'CDE'),\n    ('(?i)abc', '', FAIL),\n    ('(?i)a*', '', SUCCEED, 'found', ''),\n    ('(?i)([abc])*d', 'ABBBCD', SUCCEED, 'found+\"-\"+g1', 'ABBBCD-C'),\n    ('(?i)([abc])*bcd', 'ABCD', SUCCEED, 'found+\"-\"+g1', 'ABCD-A'),\n    ('(?i)a|b|c|d|e', 'E', SUCCEED, 'found', 'E'),\n    ('(?i)(a|b|c|d|e)f', 'EF', SUCCEED, 'found+\"-\"+g1', 'EF-E'),\n    ('(?i)abcd*efg', 'ABCDEFG', SUCCEED, 'found', 'ABCDEFG'),\n    ('(?i)ab*', 'XABYABBBZ', SUCCEED, 'found', 'AB'),\n    ('(?i)ab*', 'XAYABBBZ', SUCCEED, 'found', 'A'),\n    ('(?i)(ab|cd)e', 'ABCDE', SUCCEED, 'found+\"-\"+g1', 'CDE-CD'),\n    ('(?i)[abhgefdc]ij', 'HIJ', SUCCEED, 'found', 'HIJ'),\n    ('(?i)^(ab|cd)e', 'ABCDE', FAIL),\n    ('(?i)(abc|)ef', 'ABCDEF', SUCCEED, 'found+\"-\"+g1', 'EF-'),\n    ('(?i)(a|b)c*d', 'ABCD', SUCCEED, 'found+\"-\"+g1', 'BCD-B'),\n    ('(?i)(ab|ab*)bc', 'ABC', SUCCEED, 'found+\"-\"+g1', 'ABC-A'),\n    ('(?i)a([bc]*)c*', 'ABC', SUCCEED, 'found+\"-\"+g1', 'ABC-BC'),\n    ('(?i)a([bc]*)(c*d)', 'ABCD', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ABCD-BC-D'),\n    ('(?i)a([bc]+)(c*d)', 'ABCD', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ABCD-BC-D'),\n    ('(?i)a([bc]*)(c+d)', 'ABCD', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ABCD-B-CD'),\n    ('(?i)a[bcd]*dcdcde', 'ADCDCDE', SUCCEED, 'found', 'ADCDCDE'),\n    ('(?i)a[bcd]+dcdcde', 'ADCDCDE', FAIL),\n    ('(?i)(ab|a)b*c', 'ABC', SUCCEED, 'found+\"-\"+g1', 'ABC-AB'),\n    ('(?i)((a)(b)c)(d)', 'ABCD', SUCCEED, 'g1+\"-\"+g2+\"-\"+g3+\"-\"+g4', 'ABC-A-B-D'),\n    ('(?i)[a-zA-Z_][a-zA-Z0-9_]*', 'ALPHA', SUCCEED, 'found', 'ALPHA'),\n    ('(?i)^a(bc+|b[eh])g|.h$', 'ABH', SUCCEED, 'found+\"-\"+g1', 'BH-None'),\n    ('(?i)(bc+d$|ef*g.|h?i(j|k))', 'EFFGZ', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'EFFGZ-EFFGZ-None'),\n    ('(?i)(bc+d$|ef*g.|h?i(j|k))', 'IJ', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'IJ-IJ-J'),\n    ('(?i)(bc+d$|ef*g.|h?i(j|k))', 'EFFG', FAIL),\n    ('(?i)(bc+d$|ef*g.|h?i(j|k))', 'BCDD', FAIL),\n    ('(?i)(bc+d$|ef*g.|h?i(j|k))', 'REFFGZ', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'EFFGZ-EFFGZ-None'),\n    ('(?i)((((((((((a))))))))))', 'A', SUCCEED, 'g10', 'A'),\n    ('(?i)((((((((((a))))))))))\\\\10', 'AA', SUCCEED, 'found', 'AA'),\n    #('(?i)((((((((((a))))))))))\\\\41', 'AA', FAIL),\n    #('(?i)((((((((((a))))))))))\\\\41', 'A!', SUCCEED, 'found', 'A!'),\n    ('(?i)(((((((((a)))))))))', 'A', SUCCEED, 'found', 'A'),\n    ('(?i)(?:(?:(?:(?:(?:(?:(?:(?:(?:(a))))))))))', 'A', SUCCEED, 'g1', 'A'),\n    ('(?i)(?:(?:(?:(?:(?:(?:(?:(?:(?:(a|b|c))))))))))', 'C', SUCCEED, 'g1', 'C'),\n    ('(?i)multiple words of text', 'UH-UH', FAIL),\n    ('(?i)multiple words', 'MULTIPLE WORDS, YEAH', SUCCEED, 'found', 'MULTIPLE WORDS'),\n    ('(?i)(.*)c(.*)', 'ABCDE', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ABCDE-AB-DE'),\n    ('(?i)\\\\((.*), (.*)\\\\)', '(A, B)', SUCCEED, 'g2+\"-\"+g1', 'B-A'),\n    ('(?i)[k]', 'AB', FAIL),\n#    ('(?i)abcd', 'ABCD', SUCCEED, 'found+\"-\"+\\\\found+\"-\"+\\\\\\\\found', 'ABCD-$&-\\\\ABCD'),\n#    ('(?i)a(bc)d', 'ABCD', SUCCEED, 'g1+\"-\"+\\\\g1+\"-\"+\\\\\\\\g1', 'BC-$1-\\\\BC'),\n    ('(?i)a[-]?c', 'AC', SUCCEED, 'found', 'AC'),\n    ('(?i)(abc)\\\\1', 'ABCABC', SUCCEED, 'g1', 'ABC'),\n    ('(?i)([a-c]*)\\\\1', 'ABCABC', SUCCEED, 'g1', 'ABC'),\n    ('a(?!b).', 'abad', SUCCEED, 'found', 'ad'),\n    ('a(?=d).', 'abad', SUCCEED, 'found', 'ad'),\n    ('a(?=c|d).', 'abad', SUCCEED, 'found', 'ad'),\n    ('a(?:b|c|d)(.)', 'ace', SUCCEED, 'g1', 'e'),\n    ('a(?:b|c|d)*(.)', 'ace', SUCCEED, 'g1', 'e'),\n    ('a(?:b|c|d)+?(.)', 'ace', SUCCEED, 'g1', 'e'),\n    ('a(?:b|(c|e){1,2}?|d)+?(.)', 'ace', SUCCEED, 'g1 + g2', 'ce'),\n    ('^(.+)?B', 'AB', SUCCEED, 'g1', 'A'),\n\n    # lookbehind: split by : but not if it is escaped by -.\n    ('(?<!-):(.*?)(?<!-):', 'a:bc-:de:f', SUCCEED, 'g1', 'bc-:de' ),\n    # escaping with \\ as we know it\n    ('(?<!\\\\\\):(.*?)(?<!\\\\\\):', 'a:bc\\\\:de:f', SUCCEED, 'g1', 'bc\\\\:de' ),\n    # terminating with ' and escaping with ? as in edifact\n    (\"(?<!\\\\?)'(.*?)(?<!\\\\?)'\", \"a'bc?'de'f\", SUCCEED, 'g1', \"bc?'de\" ),\n\n    # Comments using the (?#...) syntax\n\n    ('w(?# comment', 'w', SYNTAX_ERROR),\n    ('w(?# comment 1)xy(?# comment 2)z', 'wxyz', SUCCEED, 'found', 'wxyz'),\n\n    # Check odd placement of embedded pattern modifiers\n\n    # not an error under PCRE/PRE:\n    ('w(?i)', 'W', SUCCEED, 'found', 'W'),\n    # ('w(?i)', 'W', SYNTAX_ERROR),\n\n    # Comments using the x embedded pattern modifier\n\n    (\"\"\"(?x)w# comment 1\n        x y\n        # comment 2\n        z\"\"\", 'wxyz', SUCCEED, 'found', 'wxyz'),\n\n    # using the m embedded pattern modifier\n\n    ('^abc', \"\"\"jkl\nabc\nxyz\"\"\", FAIL),\n    ('(?m)^abc', \"\"\"jkl\nabc\nxyz\"\"\", SUCCEED, 'found', 'abc'),\n\n    ('(?m)abc$', \"\"\"jkl\nxyzabc\n123\"\"\", SUCCEED, 'found', 'abc'),\n\n    # using the s embedded pattern modifier\n\n    ('a.b', 'a\\nb', FAIL),\n    ('(?s)a.b', 'a\\nb', SUCCEED, 'found', 'a\\nb'),\n\n    # test \\w, etc. both inside and outside character classes\n\n    ('\\\\w+', '--ab_cd0123--', SUCCEED, 'found', 'ab_cd0123'),\n    ('[\\\\w]+', '--ab_cd0123--', SUCCEED, 'found', 'ab_cd0123'),\n    ('\\\\D+', '1234abc5678', SUCCEED, 'found', 'abc'),\n    ('[\\\\D]+', '1234abc5678', SUCCEED, 'found', 'abc'),\n    ('[\\\\da-fA-F]+', '123abc', SUCCEED, 'found', '123abc'),\n    # not an error under PCRE/PRE:\n    # ('[\\\\d-x]', '-', SYNTAX_ERROR),\n    (r'([\\s]*)([\\S]*)([\\s]*)', ' testing!1972', SUCCEED, 'g3+g2+g1', 'testing!1972 '),\n    (r'(\\s*)(\\S*)(\\s*)', ' testing!1972', SUCCEED, 'g3+g2+g1', 'testing!1972 '),\n\n    (r'\\xff', '\\377', SUCCEED, 'found', chr(255)),\n    # new \\x semantics\n    (r'\\x00ff', '\\377', FAIL),\n    # (r'\\x00ff', '\\377', SUCCEED, 'found', chr(255)),\n    (r'\\t\\n\\v\\r\\f\\a\\g', '\\t\\n\\v\\r\\f\\ag', SUCCEED, 'found', '\\t\\n\\v\\r\\f\\ag'),\n    ('\\t\\n\\v\\r\\f\\a\\g', '\\t\\n\\v\\r\\f\\ag', SUCCEED, 'found', '\\t\\n\\v\\r\\f\\ag'),\n    (r'\\t\\n\\v\\r\\f\\a', '\\t\\n\\v\\r\\f\\a', SUCCEED, 'found', chr(9)+chr(10)+chr(11)+chr(13)+chr(12)+chr(7)),\n    (r'[\\t][\\n][\\v][\\r][\\f][\\b]', '\\t\\n\\v\\r\\f\\b', SUCCEED, 'found', '\\t\\n\\v\\r\\f\\b'),\n\n    #\n    # post-1.5.2 additions\n\n    # xmllib problem\n    (r'(([a-z]+):)?([a-z]+)$', 'smil', SUCCEED, 'g1+\"-\"+g2+\"-\"+g3', 'None-None-smil'),\n    # bug 110866: reference to undefined group\n    (r'((.)\\1+)', '', SYNTAX_ERROR),\n    # bug 111869: search (PRE/PCRE fails on this one, SRE doesn't)\n    (r'.*d', 'abc\\nabd', SUCCEED, 'found', 'abd'),\n    # bug 112468: various expected syntax errors\n    (r'(', '', SYNTAX_ERROR),\n    (r'[\\41]', '!', SUCCEED, 'found', '!'),\n    # bug 114033: nothing to repeat\n    (r'(x?)?', 'x', SUCCEED, 'found', 'x'),\n    # bug 115040: rescan if flags are modified inside pattern\n    (r' (?x)foo ', 'foo', SUCCEED, 'found', 'foo'),\n    # bug 115618: negative lookahead\n    (r'(?<!abc)(d.f)', 'abcdefdof', SUCCEED, 'found', 'dof'),\n    # bug 116251: character class bug\n    (r'[\\w-]+', 'laser_beam', SUCCEED, 'found', 'laser_beam'),\n    # bug 123769+127259: non-greedy backtracking bug\n    (r'.*?\\S *:', 'xx:', SUCCEED, 'found', 'xx:'),\n    (r'a[ ]*?\\ (\\d+).*', 'a   10', SUCCEED, 'found', 'a   10'),\n    (r'a[ ]*?\\ (\\d+).*', 'a    10', SUCCEED, 'found', 'a    10'),\n    # bug 127259: \\Z shouldn't depend on multiline mode\n    (r'(?ms).*?x\\s*\\Z(.*)','xx\\nx\\n', SUCCEED, 'g1', ''),\n    # bug 128899: uppercase literals under the ignorecase flag\n    (r'(?i)M+', 'MMM', SUCCEED, 'found', 'MMM'),\n    (r'(?i)m+', 'MMM', SUCCEED, 'found', 'MMM'),\n    (r'(?i)[M]+', 'MMM', SUCCEED, 'found', 'MMM'),\n    (r'(?i)[m]+', 'MMM', SUCCEED, 'found', 'MMM'),\n    # bug 130748: ^* should be an error (nothing to repeat)\n    (r'^*', '', SYNTAX_ERROR),\n    # bug 133283: minimizing repeat problem\n    (r'\"(?:\\\\\"|[^\"])*?\"', r'\"\\\"\"', SUCCEED, 'found', r'\"\\\"\"'),\n    # bug 477728: minimizing repeat problem\n    (r'^.*?$', 'one\\ntwo\\nthree\\n', FAIL),\n    # bug 483789: minimizing repeat problem\n    (r'a[^>]*?b', 'a>b', FAIL),\n    # bug 490573: minimizing repeat problem\n    (r'^a*?$', 'foo', FAIL),\n    # bug 470582: nested groups problem\n    (r'^((a)c)?(ab)$', 'ab', SUCCEED, 'g1+\"-\"+g2+\"-\"+g3', 'None-None-ab'),\n    # another minimizing repeat problem (capturing groups in assertions)\n    ('^([ab]*?)(?=(b)?)c', 'abc', SUCCEED, 'g1+\"-\"+g2', 'ab-None'),\n    ('^([ab]*?)(?!(b))c', 'abc', SUCCEED, 'g1+\"-\"+g2', 'ab-None'),\n    ('^([ab]*?)(?<!(a))c', 'abc', SUCCEED, 'g1+\"-\"+g2', 'ab-None'),\n]\n\nu = '\\N{LATIN CAPITAL LETTER A WITH DIAERESIS}'\ntests.extend([\n    # bug 410271: \\b broken under locales\n    (r'\\b.\\b', 'a', SUCCEED, 'found', 'a'),\n    (r'(?u)\\b.\\b', u, SUCCEED, 'found', u),\n    (r'(?u)\\w', u, SUCCEED, 'found', u),\n])\n"], "multiprocessing": [".py", "#\n# Package analogous to 'threading.py' but using processes\n#\n# multiprocessing/__init__.py\n#\n# This package is intended to duplicate the functionality (and much of\n# the API) of threading.py but uses processes instead of threads.  A\n# subpackage 'multiprocessing.dummy' has the same API but is a simple\n# wrapper for 'threading'.\n#\n# Try calling `multiprocessing.doc.main()` to read the html\n# documentation in a webbrowser.\n#\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# Licensed to PSF under a Contributor Agreement.\n#\n\n__version__ = '0.70a1'\n\n__all__ = [\n    'Process', 'current_process', 'active_children', 'freeze_support',\n    'Manager', 'Pipe', 'cpu_count', 'log_to_stderr', 'get_logger',\n    'allow_connection_pickling', 'BufferTooShort', 'TimeoutError',\n    'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Condition',\n    'Event', 'Barrier', 'Queue', 'SimpleQueue', 'JoinableQueue', 'Pool',\n    'Value', 'Array', 'RawValue', 'RawArray', 'SUBDEBUG', 'SUBWARNING',\n    ]\n\n__author__ = 'R. Oudkerk (r.m.oudkerk@gmail.com)'\n\n#\n# Imports\n#\n\nimport os\nimport sys\n\nfrom multiprocessing.process import Process, current_process, active_children\nfrom multiprocessing.util import SUBDEBUG, SUBWARNING\n\n#\n# Exceptions\n#\n\nclass ProcessError(Exception):\n    pass\n\nclass BufferTooShort(ProcessError):\n    pass\n\nclass TimeoutError(ProcessError):\n    pass\n\nclass AuthenticationError(ProcessError):\n    pass\n\nimport _multiprocessing\n\n#\n# Definitions not depending on native semaphores\n#\n\ndef Manager():\n    '''\n    Returns a manager associated with a running server process\n\n    The managers methods such as `Lock()`, `Condition()` and `Queue()`\n    can be used to create shared objects.\n    '''\n    from multiprocessing.managers import SyncManager\n    m = SyncManager()\n    m.start()\n    return m\n\n#brython fix me\n#def Pipe(duplex=True):\n#    '''\n#    Returns two connection object connected by a pipe\n#    '''\n#    from multiprocessing.connection import Pipe\n#    return Pipe(duplex)\n\ndef cpu_count():\n    '''\n    Returns the number of CPUs in the system\n    '''\n    if sys.platform == 'win32':\n        try:\n            num = int(os.environ['NUMBER_OF_PROCESSORS'])\n        except (ValueError, KeyError):\n            num = 0\n    elif 'bsd' in sys.platform or sys.platform == 'darwin':\n        comm = '/sbin/sysctl -n hw.ncpu'\n        if sys.platform == 'darwin':\n            comm = '/usr' + comm\n        try:\n            with os.popen(comm) as p:\n                num = int(p.read())\n        except ValueError:\n            num = 0\n    else:\n        try:\n            num = os.sysconf('SC_NPROCESSORS_ONLN')\n        except (ValueError, OSError, AttributeError):\n            num = 0\n\n    if num >= 1:\n        return num\n    else:\n        raise NotImplementedError('cannot determine number of cpus')\n\ndef freeze_support():\n    '''\n    Check whether this is a fake forked process in a frozen executable.\n    If so then run code specified by commandline and exit.\n    '''\n    if sys.platform == 'win32' and getattr(sys, 'frozen', False):\n        from multiprocessing.forking import freeze_support\n        freeze_support()\n\ndef get_logger():\n    '''\n    Return package logger -- if it does not already exist then it is created\n    '''\n    from multiprocessing.util import get_logger\n    return get_logger()\n\ndef log_to_stderr(level=None):\n    '''\n    Turn on logging and add a handler which prints to stderr\n    '''\n    from multiprocessing.util import log_to_stderr\n    return log_to_stderr(level)\n\n#brython fix me\n#def allow_connection_pickling():\n#    '''\n#    Install support for sending connections and sockets between processes\n#    '''\n#    # This is undocumented.  In previous versions of multiprocessing\n#    # its only effect was to make socket objects inheritable on Windows.\n#    import multiprocessing.connection\n\n#\n# Definitions depending on native semaphores\n#\n\ndef Lock():\n    '''\n    Returns a non-recursive lock object\n    '''\n    from multiprocessing.synchronize import Lock\n    return Lock()\n\ndef RLock():\n    '''\n    Returns a recursive lock object\n    '''\n    from multiprocessing.synchronize import RLock\n    return RLock()\n\ndef Condition(lock=None):\n    '''\n    Returns a condition object\n    '''\n    from multiprocessing.synchronize import Condition\n    return Condition(lock)\n\ndef Semaphore(value=1):\n    '''\n    Returns a semaphore object\n    '''\n    from multiprocessing.synchronize import Semaphore\n    return Semaphore(value)\n\ndef BoundedSemaphore(value=1):\n    '''\n    Returns a bounded semaphore object\n    '''\n    from multiprocessing.synchronize import BoundedSemaphore\n    return BoundedSemaphore(value)\n\ndef Event():\n    '''\n    Returns an event object\n    '''\n    from multiprocessing.synchronize import Event\n    return Event()\n\ndef Barrier(parties, action=None, timeout=None):\n    '''\n    Returns a barrier object\n    '''\n    from multiprocessing.synchronize import Barrier\n    return Barrier(parties, action, timeout)\n\ndef Queue(maxsize=0):\n    '''\n    Returns a queue object\n    '''\n    from multiprocessing.queues import Queue\n    return Queue(maxsize)\n\ndef JoinableQueue(maxsize=0):\n    '''\n    Returns a queue object\n    '''\n    from multiprocessing.queues import JoinableQueue\n    return JoinableQueue(maxsize)\n\ndef SimpleQueue():\n    '''\n    Returns a queue object\n    '''\n    from multiprocessing.queues import SimpleQueue\n    return SimpleQueue()\n\ndef Pool(processes=None, initializer=None, initargs=(), maxtasksperchild=None):\n    '''\n    Returns a process pool object\n    '''\n    from multiprocessing.pool import Pool\n    return Pool(processes, initializer, initargs, maxtasksperchild)\n\ndef RawValue(typecode_or_type, *args):\n    '''\n    Returns a shared object\n    '''\n    from multiprocessing.sharedctypes import RawValue\n    return RawValue(typecode_or_type, *args)\n\ndef RawArray(typecode_or_type, size_or_initializer):\n    '''\n    Returns a shared array\n    '''\n    from multiprocessing.sharedctypes import RawArray\n    return RawArray(typecode_or_type, size_or_initializer)\n\ndef Value(typecode_or_type, *args, lock=True):\n    '''\n    Returns a synchronized shared object\n    '''\n    from multiprocessing.sharedctypes import Value\n    return Value(typecode_or_type, *args, lock=lock)\n\ndef Array(typecode_or_type, size_or_initializer, *, lock=True):\n    '''\n    Returns a synchronized shared array\n    '''\n    from multiprocessing.sharedctypes import Array\n    return Array(typecode_or_type, size_or_initializer, lock=lock)\n\n#\n#\n#\n\nif sys.platform == 'win32':\n\n    def set_executable(executable):\n        '''\n        Sets the path to a python.exe or pythonw.exe binary used to run\n        child processes on Windows instead of sys.executable.\n        Useful for people embedding Python.\n        '''\n        from multiprocessing.forking import set_executable\n        set_executable(executable)\n\n    __all__ += ['set_executable']\n", 1], "queue": [".py", "'''A multi-producer, multi-consumer queue.'''\n\ntry:\n    import threading\nexcept ImportError:\n    import dummy_threading as threading\nfrom collections import deque\nfrom heapq import heappush, heappop\ntry:\n    from time import monotonic as time\nexcept ImportError:\n    from time import time\n\n__all__ = ['Empty', 'Full', 'Queue', 'PriorityQueue', 'LifoQueue']\n\nclass Empty(Exception):\n    'Exception raised by Queue.get(block=0)/get_nowait().'\n    pass\n\nclass Full(Exception):\n    'Exception raised by Queue.put(block=0)/put_nowait().'\n    pass\n\nclass Queue:\n    '''Create a queue object with a given maximum size.\n\n    If maxsize is <= 0, the queue size is infinite.\n    '''\n\n    def __init__(self, maxsize=0):\n        self.maxsize = maxsize\n        self._init(maxsize)\n\n        # mutex must be held whenever the queue is mutating.  All methods\n        # that acquire mutex must release it before returning.  mutex\n        # is shared between the three conditions, so acquiring and\n        # releasing the conditions also acquires and releases mutex.\n        self.mutex = threading.Lock()\n\n        # Notify not_empty whenever an item is added to the queue; a\n        # thread waiting to get is notified then.\n        self.not_empty = threading.Condition(self.mutex)\n\n        # Notify not_full whenever an item is removed from the queue;\n        # a thread waiting to put is notified then.\n        self.not_full = threading.Condition(self.mutex)\n\n        # Notify all_tasks_done whenever the number of unfinished tasks\n        # drops to zero; thread waiting to join() is notified to resume\n        self.all_tasks_done = threading.Condition(self.mutex)\n        self.unfinished_tasks = 0\n\n    def task_done(self):\n        '''Indicate that a formerly enqueued task is complete.\n\n        Used by Queue consumer threads.  For each get() used to fetch a task,\n        a subsequent call to task_done() tells the queue that the processing\n        on the task is complete.\n\n        If a join() is currently blocking, it will resume when all items\n        have been processed (meaning that a task_done() call was received\n        for every item that had been put() into the queue).\n\n        Raises a ValueError if called more times than there were items\n        placed in the queue.\n        '''\n        with self.all_tasks_done:\n            unfinished = self.unfinished_tasks - 1\n            if unfinished <= 0:\n                if unfinished < 0:\n                    raise ValueError('task_done() called too many times')\n                self.all_tasks_done.notify_all()\n            self.unfinished_tasks = unfinished\n\n    def join(self):\n        '''Blocks until all items in the Queue have been gotten and processed.\n\n        The count of unfinished tasks goes up whenever an item is added to the\n        queue. The count goes down whenever a consumer thread calls task_done()\n        to indicate the item was retrieved and all work on it is complete.\n\n        When the count of unfinished tasks drops to zero, join() unblocks.\n        '''\n        with self.all_tasks_done:\n            while self.unfinished_tasks:\n                self.all_tasks_done.wait()\n\n    def qsize(self):\n        '''Return the approximate size of the queue (not reliable!).'''\n        with self.mutex:\n            return self._qsize()\n\n    def empty(self):\n        '''Return True if the queue is empty, False otherwise (not reliable!).\n\n        This method is likely to be removed at some point.  Use qsize() == 0\n        as a direct substitute, but be aware that either approach risks a race\n        condition where a queue can grow before the result of empty() or\n        qsize() can be used.\n\n        To create code that needs to wait for all queued tasks to be\n        completed, the preferred technique is to use the join() method.\n        '''\n        with self.mutex:\n            return not self._qsize()\n\n    def full(self):\n        '''Return True if the queue is full, False otherwise (not reliable!).\n\n        This method is likely to be removed at some point.  Use qsize() >= n\n        as a direct substitute, but be aware that either approach risks a race\n        condition where a queue can shrink before the result of full() or\n        qsize() can be used.\n        '''\n        with self.mutex:\n            return 0 < self.maxsize <= self._qsize()\n\n    def put(self, item, block=True, timeout=None):\n        '''Put an item into the queue.\n\n        If optional args 'block' is true and 'timeout' is None (the default),\n        block if necessary until a free slot is available. If 'timeout' is\n        a non-negative number, it blocks at most 'timeout' seconds and raises\n        the Full exception if no free slot was available within that time.\n        Otherwise ('block' is false), put an item on the queue if a free slot\n        is immediately available, else raise the Full exception ('timeout'\n        is ignored in that case).\n        '''\n        with self.not_full:\n            if self.maxsize > 0:\n                if not block:\n                    if self._qsize() >= self.maxsize:\n                        raise Full\n                elif timeout is None:\n                    while self._qsize() >= self.maxsize:\n                        self.not_full.wait()\n                elif timeout < 0:\n                    raise ValueError(\"'timeout' must be a non-negative number\")\n                else:\n                    endtime = time() + timeout\n                    while self._qsize() >= self.maxsize:\n                        remaining = endtime - time()\n                        if remaining <= 0.0:\n                            raise Full\n                        self.not_full.wait(remaining)\n            self._put(item)\n            self.unfinished_tasks += 1\n            self.not_empty.notify()\n\n    def get(self, block=True, timeout=None):\n        '''Remove and return an item from the queue.\n\n        If optional args 'block' is true and 'timeout' is None (the default),\n        block if necessary until an item is available. If 'timeout' is\n        a non-negative number, it blocks at most 'timeout' seconds and raises\n        the Empty exception if no item was available within that time.\n        Otherwise ('block' is false), return an item if one is immediately\n        available, else raise the Empty exception ('timeout' is ignored\n        in that case).\n        '''\n        with self.not_empty:\n            if not block:\n                if not self._qsize():\n                    raise Empty\n            elif timeout is None:\n                while not self._qsize():\n                    self.not_empty.wait()\n            elif timeout < 0:\n                raise ValueError(\"'timeout' must be a non-negative number\")\n            else:\n                endtime = time() + timeout\n                while not self._qsize():\n                    remaining = endtime - time()\n                    if remaining <= 0.0:\n                        raise Empty\n                    self.not_empty.wait(remaining)\n            item = self._get()\n            self.not_full.notify()\n            return item\n\n    def put_nowait(self, item):\n        '''Put an item into the queue without blocking.\n\n        Only enqueue the item if a free slot is immediately available.\n        Otherwise raise the Full exception.\n        '''\n        return self.put(item, block=False)\n\n    def get_nowait(self):\n        '''Remove and return an item from the queue without blocking.\n\n        Only get an item if one is immediately available. Otherwise\n        raise the Empty exception.\n        '''\n        return self.get(block=False)\n\n    # Override these methods to implement other queue organizations\n    # (e.g. stack or priority queue).\n    # These will only be called with appropriate locks held\n\n    # Initialize the queue representation\n    def _init(self, maxsize):\n        self.queue = deque()\n\n    def _qsize(self):\n        return len(self.queue)\n\n    # Put a new item in the queue\n    def _put(self, item):\n        self.queue.append(item)\n\n    # Get an item from the queue\n    def _get(self):\n        return self.queue.popleft()\n\n\nclass PriorityQueue(Queue):\n    '''Variant of Queue that retrieves open entries in priority order (lowest first).\n\n    Entries are typically tuples of the form:  (priority number, data).\n    '''\n\n    def _init(self, maxsize):\n        self.queue = []\n\n    def _qsize(self):\n        return len(self.queue)\n\n    def _put(self, item):\n        heappush(self.queue, item)\n\n    def _get(self):\n        return heappop(self.queue)\n\n\nclass LifoQueue(Queue):\n    '''Variant of Queue that retrieves most recently added entries first.'''\n\n    def _init(self, maxsize):\n        self.queue = []\n\n    def _qsize(self):\n        return len(self.queue)\n\n    def _put(self, item):\n        self.queue.append(item)\n\n    def _get(self):\n        return self.queue.pop()\n"], "itertools": [".py", "import operator\n\nclass accumulate:\n    def __init__(self, iterable, func = operator.add):\n        self.it = iter(iterable)\n        self._total = None\n        self.func = func\n        \n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if not self._total:\n            self._total = next(self.it)\n            return self._total\n        else:\n            element = next(self.it)\n            try:\n                self._total = self.func(self._total, element)\n            except:\n                raise TypeError(\"unsupported operand type\")\n            return self._total\n                \n## Adapted from:\n## https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-34\nclass chain:\n    def __init__(self, *iterables):\n        self._iterables_iter = iter(map(iter, iterables))\n        # little trick for the first chain.__next__() call\n        self._cur_iterable_iter = iter([])\n\n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        while True:\n            try:\n                return next(self._cur_iterable_iter)\n            except StopIteration:\n                self._cur_iterable_iter = next(self._iterables_iter)\n    \n    @classmethod\n    def from_iterable(cls, iterable):\n        for it in iterable:\n            for element in it:\n                yield element\n                \nclass combinations:\n    def __init__(self, iterable, r):\n        self.pool = tuple(iterable)\n        self.n = len(self.pool)\n        self.r = r\n        self.indices = list(range(self.r))\n        self.zero = False\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.r > self.n:\n            raise StopIteration\n        if not self.zero:\n            self.zero = True\n            return tuple(self.pool[i] for i in self.indices)\n        else:\n            try:\n                for i in reversed(range(self.r)):\n                    if self.indices[i] != i + self.n - self.r:\n                        break\n                self.indices[i] += 1\n                for j in range(i+1, self.r):\n                    self.indices[j] = self.indices[j-1] + 1\n                return tuple(self.pool[i] for i in self.indices)\n            except:\n                raise StopIteration\n                \nclass combinations_with_replacement:\n    def __init__(self, iterable, r):\n        self.pool = tuple(iterable)\n        self.n = len(self.pool)\n        self.r = r\n        self.indices = [0] * self.r\n        self.zero = False\n        \n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        if not self.n and self.r:\n            raise StopIteration\n        if not self.zero:\n            self.zero = True\n            return tuple(self.pool[i] for i in self.indices)\n        else:\n            try:\n                for i in reversed(range(self.r)):\n                    if self.indices[i] != self.n - 1:\n                        break\n                self.indices[i:] = [self.indices[i] + 1] * (self.r - i)\n                return tuple(self.pool[i] for i in self.indices)\n            except:\n                raise StopIteration\n                \n## Literally copied from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-63 \nclass compress:\n    def __init__(self, data, selectors):\n        self.data = iter(data)\n        self.selectors = iter(selectors)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        while True:\n            next_item = next(self.data)\n            next_selector = next(self.selectors)\n            if bool(next_selector):\n                return next_item\n                \n## Adapted from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-79\n## I mimicked the > python3.1 behavior\nclass count:\n    \"\"\"\n    Input is an int or a float. The original Python 3 implementation\n    includes also complex numbers... but it still is not implemented \n    in Brython as complex type is NotImplemented\n    \"\"\"\n    def __init__(self, start = 0, step = 1):\n        if not isinstance(start, (int, float)):\n            raise TypeError('a number is required')\n        self.times = start - step\n        self.step = step\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        self.times += self.step\n        return self.times\n\n    def __repr__(self):\n        return 'count(%d)' % (self.times + self.step)\n\n## Literally copied from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-112        \nclass cycle:\n    def __init__(self, iterable):\n        self._cur_iter = iter(iterable)\n        self._saved = []\n        self._must_save = True\n        \n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        try:\n            next_elt = next(self._cur_iter)\n            if self._must_save:\n                self._saved.append(next_elt)\n        except StopIteration:\n            self._cur_iter = iter(self._saved)\n            next_elt = next(self._cur_iter)\n            self._must_save = False\n        return next_elt\n        \n## Literally copied from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-149\nclass dropwhile:\n    def __init__(self, predicate, iterable):\n        self._predicate = predicate\n        self._iter = iter(iterable)\n        self._dropped = False\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        value = next(self._iter)\n        if self._dropped:\n            return value\n        while self._predicate(value):\n            value = next(self._iter)\n        self._dropped = True\n        return value\n        \n## Adapted from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-261\nclass filterfalse:\n    def __init__(self, predicate, iterable):\n        # Make sure iterable *IS* iterable\n        self._iter = iter(iterable)\n        if predicate is None:\n            self._predicate = bool\n        else:\n            self._predicate = predicate\n\n    def __iter__(self):\n        return self\n    def __next__(self):\n        next_elt = next(self._iter)\n        while True:\n            if not self._predicate(next_elt):\n                return next_elt\n            next_elt = next(self._iter)\n\nclass groupby:\n    # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B\n    # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D\n    def __init__(self, iterable, key=None):\n        if key is None:\n            key = lambda x: x\n        self.keyfunc = key\n        self.it = iter(iterable)\n        self.tgtkey = self.currkey = self.currvalue = object()\n    def __iter__(self):\n        return self\n    def __next__(self):\n        while self.currkey == self.tgtkey:\n            self.currvalue = next(self.it)    # Exit on StopIteration\n            self.currkey = self.keyfunc(self.currvalue)\n        self.tgtkey = self.currkey\n        return (self.currkey, self._grouper(self.tgtkey))\n    def _grouper(self, tgtkey):\n        while self.currkey == tgtkey:\n            yield self.currvalue\n            self.currvalue = next(self.it)    # Exit on StopIteration\n            self.currkey = self.keyfunc(self.currvalue)\n          \n## adapted from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-323\nclass islice:\n    def __init__(self, iterable, *args):\n        s = slice(*args)\n        self.start, self.stop, self.step = s.start or 0, s.stop, s.step\n        if not isinstance(self.start, int):\n           raise ValueError(\"Start argument must be an integer\")\n        if self.stop != None and not isinstance(self.stop, int):\n            raise ValueError(\"Stop argument must be an integer or None\")\n        if self.step is None:\n            self.step = 1\n        if self.start<0 or (self.stop != None and self.stop<0\n           ) or self.step<=0:\n            raise ValueError(\"indices for islice() must be positive\")\n        self.it = iter(iterable)\n        self.donext = None\n        self.cnt = 0\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        nextindex = self.start\n        if self.stop != None and nextindex >= self.stop:\n            raise StopIteration\n        while self.cnt <= nextindex:\n            nextitem = next(self.it)\n            self.cnt += 1\n        self.start += self.step \n        return nextitem\n        \nclass permutations:\n    def __init__(self, iterable, r = None):\n        self.pool = tuple(iterable)\n        self.n = len(self.pool)\n        self.r = self.n if r is None else r\n        self.indices = list(range(self.n))\n        self.cycles = list(range(self.n, self.n - self.r, -1))\n        self.zero = False\n        self.stop = False\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        indices = self.indices\n        if self.r > self.n:\n            raise StopIteration\n        if not self.zero:\n            self.zero = True\n            return tuple(self.pool[i] for i in indices[:self.r])\n        \n        i = self.r - 1\n        while i >= 0:\n            j = self.cycles[i] - 1\n            if j > 0:\n                self.cycles[i] = j\n                indices[i], indices[-j] = indices[-j], indices[i]\n                return tuple(self.pool[i] for i in indices[:self.r])\n            self.cycles[i] = len(indices) - i\n            n1 = len(indices) - 1\n            assert n1 >= 0\n            num = indices[i]\n            for k in range(i, n1):\n                indices[k] = indices[k+1]\n            indices[n1] = num\n            i -= 1\n        raise StopIteration\n\n# copied from Python documentation on itertools.product\ndef product(*args, repeat=1):\n    # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy\n    # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111\n    pools = [tuple(pool) for pool in args] * repeat\n    result = [[]]\n    for pool in pools:\n        result = [x+[y] for x in result for y in pool]\n    for prod in result:\n        yield tuple(prod)\n\n\n## adapted from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-392        \n\n## (Brython) \n## renamed to _product : the implementation fails for product('abc', [])\n## with CPython 3.x\nclass _product:\n    def __init__(self, *args, **kw):\n        if len(kw) > 1:\n            raise TypeError(\"product() takes at most 1 argument (%d given)\" %\n                             len(kw))\n        self.repeat = kw.get('repeat', 1)\n        if not isinstance(self.repeat, int):\n            raise TypeError(\"integer argument expected, got %s\" %\n                             type(self.repeat))\n        self.gears = [x for x in args] * self.repeat\n        self.num_gears = len(self.gears)\n        # initialization of indicies to loop over\n        self.indicies = [(0, len(self.gears[x]))\n                         for x in range(0, self.num_gears)]\n        self.cont = True\n        self.zero = False\n\n    def roll_gears(self):\n        # Starting from the end of the gear indicies work to the front\n        # incrementing the gear until the limit is reached. When the limit\n        # is reached carry operation to the next gear\n        should_carry = True\n        for n in range(0, self.num_gears):\n            nth_gear = self.num_gears - n - 1\n            if should_carry:\n                count, lim = self.indicies[nth_gear]\n                count += 1\n                if count == lim and nth_gear == 0:\n                    self.cont = False\n                if count == lim:\n                    should_carry = True\n                    count = 0\n                else:\n                    should_carry = False\n                self.indicies[nth_gear] = (count, lim)  \n            else:\n                break\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.zero:\n            raise StopIteration\n        if self.repeat > 0:\n            if not self.cont:\n                raise StopIteration\n            l = []\n            for x in range(0, self.num_gears):\n                index, limit = self.indicies[x]\n                print('itertools 353',self.gears,x,index)\n                l.append(self.gears[x][index])\n            self.roll_gears()\n            return tuple(l)\n        elif self.repeat == 0:\n            self.zero = True\n            return ()\n        else:\n            raise ValueError(\"repeat argument cannot be negative\")\n            \n## Literally copied from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-441\nclass repeat:\n    def __init__(self, obj, times=None):\n        self._obj = obj\n        if times is not None:\n            range(times) # Raise a TypeError\n            if times < 0:\n                times = 0\n        self._times = times\n        \n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        # __next__() *need* to decrement self._times when consumed\n        if self._times is not None:\n            if self._times <= 0: \n                raise StopIteration()\n            self._times -= 1\n        return self._obj\n\n    def __repr__(self):\n        if self._times is not None:\n            return 'repeat(%r, %r)' % (self._obj, self._times)\n        else:\n            return 'repeat(%r)' % (self._obj,)\n\n    def __len__(self):\n        if self._times == -1 or self._times is None:\n            raise TypeError(\"len() of uniszed object\")\n        return self._times\n\n## Adapted from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-489\nclass starmap(object):\n    def __init__(self, function, iterable):\n        self._func = function\n        self._iter = iter(iterable)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        t = next(self._iter)\n        return self._func(*t)\n        \n## Literally copied from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-520\nclass takewhile(object):\n    def __init__(self, predicate, iterable):\n        self._predicate = predicate\n        self._iter = iter(iterable)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        value = next(self._iter)\n        if not self._predicate(value):\n            raise StopIteration()\n        return value\n\n## Almost literal from\n##https://bitbucket.org/pypy/pypy/src/c1aa74c06e86/lib_pypy/itertools.py#cl-547\nclass TeeData(object):\n    def __init__(self, iterator):\n        self.data = []\n        self._iter = iterator\n\n    def __getitem__(self, i):\n        # iterates until 'i' if not done yet\n        while i>= len(self.data):\n            self.data.append(next(self._iter))\n        return self.data[i]\n\n\nclass TeeObject(object):\n    def __init__(self, iterable=None, tee_data=None):\n        if tee_data:\n            self.tee_data = tee_data\n            self.pos = 0\n        # <=> Copy constructor\n        elif isinstance(iterable, TeeObject):\n            self.tee_data = iterable.tee_data\n            self.pos = iterable.pos\n        else:\n            self.tee_data = TeeData(iter(iterable))\n            self.pos = 0\n            \n    def __next__(self):\n        data = self.tee_data[self.pos]\n        self.pos += 1\n        return data\n    \n    def __iter__(self):\n        return self\n\n\ndef tee(iterable, n=2):\n    if isinstance(iterable, TeeObject):\n        return tuple([iterable] +\n        [TeeObject(tee_data=iterable.tee_data) for i in range(n - 1)])\n    tee_data = TeeData(iter(iterable))\n    return tuple([TeeObject(tee_data=tee_data) for i in range(n)])\n\nclass zip_longest:\n    def __init__(self, *args, fillvalue = None):\n        self.args = args\n        self.fillvalue = fillvalue\n        self.max_length = max([len(arg) for arg in self.args])\n        self.units = len(args)\n        self.counter = 0\n    \n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        if self.counter == self.max_length:\n            raise StopIteration\n        else:\n            temp = []\n            for i in range(self.units):\n                try:\n                    temp.append(self.args[i][self.counter])\n                except:\n                    temp.append(self.fillvalue)\n            self.counter = self.counter + 1\n            return tuple(temp)\n"], "crypto_js.rollups.md5": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(s,p){var m={},l=m.lib={},n=function(){},r=l.Base={extend:function(b){n.prototype=this;var h=new n;b&&h.mixIn(b);h.hasOwnProperty(\"init\")||(h.init=function(){h.$super.init.apply(this,arguments)});h.init.prototype=h;h.$super=this;return h},create:function(){var b=this.extend();b.init.apply(b,arguments);return b},init:function(){},mixIn:function(b){for(var h in b)b.hasOwnProperty(h)&&(this[h]=b[h]);b.hasOwnProperty(\"toString\")&&(this.toString=b.toString)},clone:function(){return this.init.prototype.extend(this)}},\nq=l.WordArray=r.extend({init:function(b,h){b=this.words=b||[];this.sigBytes=h!=p?h:4*b.length},toString:function(b){return(b||t).stringify(this)},concat:function(b){var h=this.words,a=b.words,j=this.sigBytes;b=b.sigBytes;this.clamp();if(j%4)for(var g=0;g<b;g++)h[j+g>>>2]|=(a[g>>>2]>>>24-8*(g%4)&255)<<24-8*((j+g)%4);else if(65535<a.length)for(g=0;g<b;g+=4)h[j+g>>>2]=a[g>>>2];else h.push.apply(h,a);this.sigBytes+=b;return this},clamp:function(){var b=this.words,h=this.sigBytes;b[h>>>2]&=4294967295<<\n32-8*(h%4);b.length=s.ceil(h/4)},clone:function(){var b=r.clone.call(this);b.words=this.words.slice(0);return b},random:function(b){for(var h=[],a=0;a<b;a+=4)h.push(4294967296*s.random()|0);return new q.init(h,b)}}),v=m.enc={},t=v.Hex={stringify:function(b){var a=b.words;b=b.sigBytes;for(var g=[],j=0;j<b;j++){var k=a[j>>>2]>>>24-8*(j%4)&255;g.push((k>>>4).toString(16));g.push((k&15).toString(16))}return g.join(\"\")},parse:function(b){for(var a=b.length,g=[],j=0;j<a;j+=2)g[j>>>3]|=parseInt(b.substr(j,\n2),16)<<24-4*(j%8);return new q.init(g,a/2)}},a=v.Latin1={stringify:function(b){var a=b.words;b=b.sigBytes;for(var g=[],j=0;j<b;j++)g.push(String.fromCharCode(a[j>>>2]>>>24-8*(j%4)&255));return g.join(\"\")},parse:function(b){for(var a=b.length,g=[],j=0;j<a;j++)g[j>>>2]|=(b.charCodeAt(j)&255)<<24-8*(j%4);return new q.init(g,a)}},u=v.Utf8={stringify:function(b){try{return decodeURIComponent(escape(a.stringify(b)))}catch(g){throw Error(\"Malformed UTF-8 data\");}},parse:function(b){return a.parse(unescape(encodeURIComponent(b)))}},\ng=l.BufferedBlockAlgorithm=r.extend({reset:function(){this._data=new q.init;this._nDataBytes=0},_append:function(b){\"string\"==typeof b&&(b=u.parse(b));this._data.concat(b);this._nDataBytes+=b.sigBytes},_process:function(b){var a=this._data,g=a.words,j=a.sigBytes,k=this.blockSize,m=j/(4*k),m=b?s.ceil(m):s.max((m|0)-this._minBufferSize,0);b=m*k;j=s.min(4*b,j);if(b){for(var l=0;l<b;l+=k)this._doProcessBlock(g,l);l=g.splice(0,b);a.sigBytes-=j}return new q.init(l,j)},clone:function(){var b=r.clone.call(this);\nb._data=this._data.clone();return b},_minBufferSize:0});l.Hasher=g.extend({cfg:r.extend(),init:function(b){this.cfg=this.cfg.extend(b);this.reset()},reset:function(){g.reset.call(this);this._doReset()},update:function(b){this._append(b);this._process();return this},finalize:function(b){b&&this._append(b);return this._doFinalize()},blockSize:16,_createHelper:function(b){return function(a,g){return(new b.init(g)).finalize(a)}},_createHmacHelper:function(b){return function(a,g){return(new k.HMAC.init(b,\ng)).finalize(a)}}});var k=m.algo={};return m}(Math);\n(function(s){function p(a,k,b,h,l,j,m){a=a+(k&b|~k&h)+l+m;return(a<<j|a>>>32-j)+k}function m(a,k,b,h,l,j,m){a=a+(k&h|b&~h)+l+m;return(a<<j|a>>>32-j)+k}function l(a,k,b,h,l,j,m){a=a+(k^b^h)+l+m;return(a<<j|a>>>32-j)+k}function n(a,k,b,h,l,j,m){a=a+(b^(k|~h))+l+m;return(a<<j|a>>>32-j)+k}for(var r=CryptoJS,q=r.lib,v=q.WordArray,t=q.Hasher,q=r.algo,a=[],u=0;64>u;u++)a[u]=4294967296*s.abs(s.sin(u+1))|0;q=q.MD5=t.extend({_doReset:function(){this._hash=new v.init([1732584193,4023233417,2562383102,271733878])},\n_doProcessBlock:function(g,k){for(var b=0;16>b;b++){var h=k+b,w=g[h];g[h]=(w<<8|w>>>24)&16711935|(w<<24|w>>>8)&4278255360}var b=this._hash.words,h=g[k+0],w=g[k+1],j=g[k+2],q=g[k+3],r=g[k+4],s=g[k+5],t=g[k+6],u=g[k+7],v=g[k+8],x=g[k+9],y=g[k+10],z=g[k+11],A=g[k+12],B=g[k+13],C=g[k+14],D=g[k+15],c=b[0],d=b[1],e=b[2],f=b[3],c=p(c,d,e,f,h,7,a[0]),f=p(f,c,d,e,w,12,a[1]),e=p(e,f,c,d,j,17,a[2]),d=p(d,e,f,c,q,22,a[3]),c=p(c,d,e,f,r,7,a[4]),f=p(f,c,d,e,s,12,a[5]),e=p(e,f,c,d,t,17,a[6]),d=p(d,e,f,c,u,22,a[7]),\nc=p(c,d,e,f,v,7,a[8]),f=p(f,c,d,e,x,12,a[9]),e=p(e,f,c,d,y,17,a[10]),d=p(d,e,f,c,z,22,a[11]),c=p(c,d,e,f,A,7,a[12]),f=p(f,c,d,e,B,12,a[13]),e=p(e,f,c,d,C,17,a[14]),d=p(d,e,f,c,D,22,a[15]),c=m(c,d,e,f,w,5,a[16]),f=m(f,c,d,e,t,9,a[17]),e=m(e,f,c,d,z,14,a[18]),d=m(d,e,f,c,h,20,a[19]),c=m(c,d,e,f,s,5,a[20]),f=m(f,c,d,e,y,9,a[21]),e=m(e,f,c,d,D,14,a[22]),d=m(d,e,f,c,r,20,a[23]),c=m(c,d,e,f,x,5,a[24]),f=m(f,c,d,e,C,9,a[25]),e=m(e,f,c,d,q,14,a[26]),d=m(d,e,f,c,v,20,a[27]),c=m(c,d,e,f,B,5,a[28]),f=m(f,c,\nd,e,j,9,a[29]),e=m(e,f,c,d,u,14,a[30]),d=m(d,e,f,c,A,20,a[31]),c=l(c,d,e,f,s,4,a[32]),f=l(f,c,d,e,v,11,a[33]),e=l(e,f,c,d,z,16,a[34]),d=l(d,e,f,c,C,23,a[35]),c=l(c,d,e,f,w,4,a[36]),f=l(f,c,d,e,r,11,a[37]),e=l(e,f,c,d,u,16,a[38]),d=l(d,e,f,c,y,23,a[39]),c=l(c,d,e,f,B,4,a[40]),f=l(f,c,d,e,h,11,a[41]),e=l(e,f,c,d,q,16,a[42]),d=l(d,e,f,c,t,23,a[43]),c=l(c,d,e,f,x,4,a[44]),f=l(f,c,d,e,A,11,a[45]),e=l(e,f,c,d,D,16,a[46]),d=l(d,e,f,c,j,23,a[47]),c=n(c,d,e,f,h,6,a[48]),f=n(f,c,d,e,u,10,a[49]),e=n(e,f,c,d,\nC,15,a[50]),d=n(d,e,f,c,s,21,a[51]),c=n(c,d,e,f,A,6,a[52]),f=n(f,c,d,e,q,10,a[53]),e=n(e,f,c,d,y,15,a[54]),d=n(d,e,f,c,w,21,a[55]),c=n(c,d,e,f,v,6,a[56]),f=n(f,c,d,e,D,10,a[57]),e=n(e,f,c,d,t,15,a[58]),d=n(d,e,f,c,B,21,a[59]),c=n(c,d,e,f,r,6,a[60]),f=n(f,c,d,e,z,10,a[61]),e=n(e,f,c,d,j,15,a[62]),d=n(d,e,f,c,x,21,a[63]);b[0]=b[0]+c|0;b[1]=b[1]+d|0;b[2]=b[2]+e|0;b[3]=b[3]+f|0},_doFinalize:function(){var a=this._data,k=a.words,b=8*this._nDataBytes,h=8*a.sigBytes;k[h>>>5]|=128<<24-h%32;var l=s.floor(b/\n4294967296);k[(h+64>>>9<<4)+15]=(l<<8|l>>>24)&16711935|(l<<24|l>>>8)&4278255360;k[(h+64>>>9<<4)+14]=(b<<8|b>>>24)&16711935|(b<<24|b>>>8)&4278255360;a.sigBytes=4*(k.length+1);this._process();a=this._hash;k=a.words;for(b=0;4>b;b++)h=k[b],k[b]=(h<<8|h>>>24)&16711935|(h<<24|h>>>8)&4278255360;return a},clone:function(){var a=t.clone.call(this);a._hash=this._hash.clone();return a}});r.MD5=t._createHelper(q);r.HmacMD5=t._createHmacHelper(q)})(Math);\n"], "_posixsubprocess": [".js", "var $module=(function($B){\n\n    return {\n       cloexec_pipe: function() {}   // fixme\n    }\n})(__BRYTHON__)\n"], "multiprocessing.util": [".py", "#\n# Module providing various facilities to other parts of the package\n#\n# multiprocessing/util.py\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# Licensed to PSF under a Contributor Agreement.\n#\n\nimport sys\nimport functools\nimport os\nimport itertools\nimport weakref\nimport atexit\nimport threading        # we want threading to install it's\n                        # cleanup function before multiprocessing does\nfrom subprocess import _args_from_interpreter_flags\n\nfrom multiprocessing.process import current_process, active_children\n\n__all__ = [\n    'sub_debug', 'debug', 'info', 'sub_warning', 'get_logger',\n    'log_to_stderr', 'get_temp_dir', 'register_after_fork',\n    'is_exiting', 'Finalize', 'ForkAwareThreadLock', 'ForkAwareLocal',\n    'SUBDEBUG', 'SUBWARNING',\n    ]\n\n#\n# Logging\n#\n\nNOTSET = 0\nSUBDEBUG = 5\nDEBUG = 10\nINFO = 20\nSUBWARNING = 25\n\nLOGGER_NAME = 'multiprocessing'\nDEFAULT_LOGGING_FORMAT = '[%(levelname)s/%(processName)s] %(message)s'\n\n_logger = None\n_log_to_stderr = False\n\ndef sub_debug(msg, *args):\n    if _logger:\n        _logger.log(SUBDEBUG, msg, *args)\n\ndef debug(msg, *args):\n    if _logger:\n        _logger.log(DEBUG, msg, *args)\n\ndef info(msg, *args):\n    if _logger:\n        _logger.log(INFO, msg, *args)\n\ndef sub_warning(msg, *args):\n    if _logger:\n        _logger.log(SUBWARNING, msg, *args)\n\ndef get_logger():\n    '''\n    Returns logger used by multiprocessing\n    '''\n    global _logger\n    import logging\n\n    logging._acquireLock()\n    try:\n        if not _logger:\n\n            _logger = logging.getLogger(LOGGER_NAME)\n            _logger.propagate = 0\n            logging.addLevelName(SUBDEBUG, 'SUBDEBUG')\n            logging.addLevelName(SUBWARNING, 'SUBWARNING')\n\n            # XXX multiprocessing should cleanup before logging\n            if hasattr(atexit, 'unregister'):\n                atexit.unregister(_exit_function)\n                atexit.register(_exit_function)\n            else:\n                atexit._exithandlers.remove((_exit_function, (), {}))\n                atexit._exithandlers.append((_exit_function, (), {}))\n\n    finally:\n        logging._releaseLock()\n\n    return _logger\n\ndef log_to_stderr(level=None):\n    '''\n    Turn on logging and add a handler which prints to stderr\n    '''\n    global _log_to_stderr\n    import logging\n\n    logger = get_logger()\n    formatter = logging.Formatter(DEFAULT_LOGGING_FORMAT)\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n\n    if level:\n        logger.setLevel(level)\n    _log_to_stderr = True\n    return _logger\n\n#\n# Function returning a temp directory which will be removed on exit\n#\n\ndef get_temp_dir():\n    # get name of a temp directory which will be automatically cleaned up\n    if current_process()._tempdir is None:\n        import shutil, tempfile\n        tempdir = tempfile.mkdtemp(prefix='pymp-')\n        info('created temp directory %s', tempdir)\n        Finalize(None, shutil.rmtree, args=[tempdir], exitpriority=-100)\n        current_process()._tempdir = tempdir\n    return current_process()._tempdir\n\n#\n# Support for reinitialization of objects when bootstrapping a child process\n#\n\n_afterfork_registry = weakref.WeakValueDictionary()\n_afterfork_counter = itertools.count()\n\ndef _run_after_forkers():\n    items = list(_afterfork_registry.items())\n    items.sort()\n    for (index, ident, func), obj in items:\n        try:\n            func(obj)\n        except Exception as e:\n            info('after forker raised exception %s', e)\n\ndef register_after_fork(obj, func):\n    _afterfork_registry[(next(_afterfork_counter), id(obj), func)] = obj\n\n#\n# Finalization using weakrefs\n#\n\n_finalizer_registry = {}\n_finalizer_counter = itertools.count()\n\n\nclass Finalize(object):\n    '''\n    Class which supports object finalization using weakrefs\n    '''\n    def __init__(self, obj, callback, args=(), kwargs=None, exitpriority=None):\n        assert exitpriority is None or type(exitpriority) is int\n\n        if obj is not None:\n            self._weakref = weakref.ref(obj, self)\n        else:\n            assert exitpriority is not None\n\n        self._callback = callback\n        self._args = args\n        self._kwargs = kwargs or {}\n        self._key = (exitpriority, next(_finalizer_counter))\n        self._pid = os.getpid()\n\n        _finalizer_registry[self._key] = self\n\n    def __call__(self, wr=None,\n                 # Need to bind these locally because the globals can have\n                 # been cleared at shutdown\n                 _finalizer_registry=_finalizer_registry,\n                 sub_debug=sub_debug, getpid=os.getpid):\n        '''\n        Run the callback unless it has already been called or cancelled\n        '''\n        try:\n            del _finalizer_registry[self._key]\n        except KeyError:\n            sub_debug('finalizer no longer registered')\n        else:\n            if self._pid != getpid():\n                sub_debug('finalizer ignored because different process')\n                res = None\n            else:\n                sub_debug('finalizer calling %s with args %s and kwargs %s',\n                          self._callback, self._args, self._kwargs)\n                res = self._callback(*self._args, **self._kwargs)\n            self._weakref = self._callback = self._args = \\\n                            self._kwargs = self._key = None\n            return res\n\n    def cancel(self):\n        '''\n        Cancel finalization of the object\n        '''\n        try:\n            del _finalizer_registry[self._key]\n        except KeyError:\n            pass\n        else:\n            self._weakref = self._callback = self._args = \\\n                            self._kwargs = self._key = None\n\n    def still_active(self):\n        '''\n        Return whether this finalizer is still waiting to invoke callback\n        '''\n        return self._key in _finalizer_registry\n\n    def __repr__(self):\n        try:\n            obj = self._weakref()\n        except (AttributeError, TypeError):\n            obj = None\n\n        if obj is None:\n            return '<Finalize object, dead>'\n\n        x = '<Finalize object, callback=%s' % \\\n            getattr(self._callback, '__name__', self._callback)\n        if self._args:\n            x += ', args=' + str(self._args)\n        if self._kwargs:\n            x += ', kwargs=' + str(self._kwargs)\n        if self._key[0] is not None:\n            x += ', exitprority=' + str(self._key[0])\n        return x + '>'\n\n\ndef _run_finalizers(minpriority=None):\n    '''\n    Run all finalizers whose exit priority is not None and at least minpriority\n\n    Finalizers with highest priority are called first; finalizers with\n    the same priority will be called in reverse order of creation.\n    '''\n    if _finalizer_registry is None:\n        # This function may be called after this module's globals are\n        # destroyed.  See the _exit_function function in this module for more\n        # notes.\n        return\n\n    if minpriority is None:\n        f = lambda p : p[0][0] is not None\n    else:\n        f = lambda p : p[0][0] is not None and p[0][0] >= minpriority\n\n    items = [x for x in list(_finalizer_registry.items()) if f(x)]\n    items.sort(reverse=True)\n\n    for key, finalizer in items:\n        sub_debug('calling %s', finalizer)\n        try:\n            finalizer()\n        except Exception:\n            import traceback\n            traceback.print_exc()\n\n    if minpriority is None:\n        _finalizer_registry.clear()\n\n#\n# Clean up on exit\n#\n\ndef is_exiting():\n    '''\n    Returns true if the process is shutting down\n    '''\n    return _exiting or _exiting is None\n\n_exiting = False\n\ndef _exit_function(info=info, debug=debug, _run_finalizers=_run_finalizers,\n                   active_children=active_children,\n                   current_process=current_process):\n    # We hold on to references to functions in the arglist due to the\n    # situation described below, where this function is called after this\n    # module's globals are destroyed.\n\n    global _exiting\n\n    if not _exiting:\n        _exiting = True\n\n        info('process shutting down')\n        debug('running all \"atexit\" finalizers with priority >= 0')\n        _run_finalizers(0)\n\n        if current_process() is not None:\n            # We check if the current process is None here because if\n            # it's None, any call to ``active_children()`` will raise\n            # an AttributeError (active_children winds up trying to\n            # get attributes from util._current_process).  One\n            # situation where this can happen is if someone has\n            # manipulated sys.modules, causing this module to be\n            # garbage collected.  The destructor for the module type\n            # then replaces all values in the module dict with None.\n            # For instance, after setuptools runs a test it replaces\n            # sys.modules with a copy created earlier.  See issues\n            # #9775 and #15881.  Also related: #4106, #9205, and\n            # #9207.\n\n            for p in active_children():\n                if p._daemonic:\n                    info('calling terminate() for daemon %s', p.name)\n                    p._popen.terminate()\n\n            for p in active_children():\n                info('calling join() for process %s', p.name)\n                p.join()\n\n        debug('running the remaining \"atexit\" finalizers')\n        _run_finalizers()\n\natexit.register(_exit_function)\n\n#\n# Some fork aware types\n#\n\nclass ForkAwareThreadLock(object):\n    def __init__(self):\n        self._reset()\n        register_after_fork(self, ForkAwareThreadLock._reset)\n\n    def _reset(self):\n        self._lock = threading.Lock()\n        self.acquire = self._lock.acquire\n        self.release = self._lock.release\n\nclass ForkAwareLocal(threading.local):\n    def __init__(self):\n        register_after_fork(self, lambda obj : obj.__dict__.clear())\n    def __reduce__(self):\n        return type(self), ()\n"], "xml.dom.xmlbuilder": [".py", "\"\"\"Implementation of the DOM Level 3 'LS-Load' feature.\"\"\"\n\nimport copy\nimport xml.dom\n\nfrom xml.dom.NodeFilter import NodeFilter\n\n\n__all__ = [\"DOMBuilder\", \"DOMEntityResolver\", \"DOMInputSource\"]\n\n\nclass Options:\n    \"\"\"Features object that has variables set for each DOMBuilder feature.\n\n    The DOMBuilder class uses an instance of this class to pass settings to\n    the ExpatBuilder class.\n    \"\"\"\n\n    # Note that the DOMBuilder class in LoadSave constrains which of these\n    # values can be set using the DOM Level 3 LoadSave feature.\n\n    namespaces = 1\n    namespace_declarations = True\n    validation = False\n    external_parameter_entities = True\n    external_general_entities = True\n    external_dtd_subset = True\n    validate_if_schema = False\n    validate = False\n    datatype_normalization = False\n    create_entity_ref_nodes = True\n    entities = True\n    whitespace_in_element_content = True\n    cdata_sections = True\n    comments = True\n    charset_overrides_xml_encoding = True\n    infoset = False\n    supported_mediatypes_only = False\n\n    errorHandler = None\n    filter = None\n\n\nclass DOMBuilder:\n    entityResolver = None\n    errorHandler = None\n    filter = None\n\n    ACTION_REPLACE = 1\n    ACTION_APPEND_AS_CHILDREN = 2\n    ACTION_INSERT_AFTER = 3\n    ACTION_INSERT_BEFORE = 4\n\n    _legal_actions = (ACTION_REPLACE, ACTION_APPEND_AS_CHILDREN,\n                      ACTION_INSERT_AFTER, ACTION_INSERT_BEFORE)\n\n    def __init__(self):\n        self._options = Options()\n\n    def _get_entityResolver(self):\n        return self.entityResolver\n    def _set_entityResolver(self, entityResolver):\n        self.entityResolver = entityResolver\n\n    def _get_errorHandler(self):\n        return self.errorHandler\n    def _set_errorHandler(self, errorHandler):\n        self.errorHandler = errorHandler\n\n    def _get_filter(self):\n        return self.filter\n    def _set_filter(self, filter):\n        self.filter = filter\n\n    def setFeature(self, name, state):\n        if self.supportsFeature(name):\n            state = state and 1 or 0\n            try:\n                settings = self._settings[(_name_xform(name), state)]\n            except KeyError:\n                raise xml.dom.NotSupportedErr(\n                    \"unsupported feature: %r\" % (name,))\n            else:\n                for name, value in settings:\n                    setattr(self._options, name, value)\n        else:\n            raise xml.dom.NotFoundErr(\"unknown feature: \" + repr(name))\n\n    def supportsFeature(self, name):\n        return hasattr(self._options, _name_xform(name))\n\n    def canSetFeature(self, name, state):\n        key = (_name_xform(name), state and 1 or 0)\n        return key in self._settings\n\n    # This dictionary maps from (feature,value) to a list of\n    # (option,value) pairs that should be set on the Options object.\n    # If a (feature,value) setting is not in this dictionary, it is\n    # not supported by the DOMBuilder.\n    #\n    _settings = {\n        (\"namespace_declarations\", 0): [\n            (\"namespace_declarations\", 0)],\n        (\"namespace_declarations\", 1): [\n            (\"namespace_declarations\", 1)],\n        (\"validation\", 0): [\n            (\"validation\", 0)],\n        (\"external_general_entities\", 0): [\n            (\"external_general_entities\", 0)],\n        (\"external_general_entities\", 1): [\n            (\"external_general_entities\", 1)],\n        (\"external_parameter_entities\", 0): [\n            (\"external_parameter_entities\", 0)],\n        (\"external_parameter_entities\", 1): [\n            (\"external_parameter_entities\", 1)],\n        (\"validate_if_schema\", 0): [\n            (\"validate_if_schema\", 0)],\n        (\"create_entity_ref_nodes\", 0): [\n            (\"create_entity_ref_nodes\", 0)],\n        (\"create_entity_ref_nodes\", 1): [\n            (\"create_entity_ref_nodes\", 1)],\n        (\"entities\", 0): [\n            (\"create_entity_ref_nodes\", 0),\n            (\"entities\", 0)],\n        (\"entities\", 1): [\n            (\"entities\", 1)],\n        (\"whitespace_in_element_content\", 0): [\n            (\"whitespace_in_element_content\", 0)],\n        (\"whitespace_in_element_content\", 1): [\n            (\"whitespace_in_element_content\", 1)],\n        (\"cdata_sections\", 0): [\n            (\"cdata_sections\", 0)],\n        (\"cdata_sections\", 1): [\n            (\"cdata_sections\", 1)],\n        (\"comments\", 0): [\n            (\"comments\", 0)],\n        (\"comments\", 1): [\n            (\"comments\", 1)],\n        (\"charset_overrides_xml_encoding\", 0): [\n            (\"charset_overrides_xml_encoding\", 0)],\n        (\"charset_overrides_xml_encoding\", 1): [\n            (\"charset_overrides_xml_encoding\", 1)],\n        (\"infoset\", 0): [],\n        (\"infoset\", 1): [\n            (\"namespace_declarations\", 0),\n            (\"validate_if_schema\", 0),\n            (\"create_entity_ref_nodes\", 0),\n            (\"entities\", 0),\n            (\"cdata_sections\", 0),\n            (\"datatype_normalization\", 1),\n            (\"whitespace_in_element_content\", 1),\n            (\"comments\", 1),\n            (\"charset_overrides_xml_encoding\", 1)],\n        (\"supported_mediatypes_only\", 0): [\n            (\"supported_mediatypes_only\", 0)],\n        (\"namespaces\", 0): [\n            (\"namespaces\", 0)],\n        (\"namespaces\", 1): [\n            (\"namespaces\", 1)],\n    }\n\n    def getFeature(self, name):\n        xname = _name_xform(name)\n        try:\n            return getattr(self._options, xname)\n        except AttributeError:\n            if name == \"infoset\":\n                options = self._options\n                return (options.datatype_normalization\n                        and options.whitespace_in_element_content\n                        and options.comments\n                        and options.charset_overrides_xml_encoding\n                        and not (options.namespace_declarations\n                                 or options.validate_if_schema\n                                 or options.create_entity_ref_nodes\n                                 or options.entities\n                                 or options.cdata_sections))\n            raise xml.dom.NotFoundErr(\"feature %s not known\" % repr(name))\n\n    def parseURI(self, uri):\n        if self.entityResolver:\n            input = self.entityResolver.resolveEntity(None, uri)\n        else:\n            input = DOMEntityResolver().resolveEntity(None, uri)\n        return self.parse(input)\n\n    def parse(self, input):\n        options = copy.copy(self._options)\n        options.filter = self.filter\n        options.errorHandler = self.errorHandler\n        fp = input.byteStream\n        if fp is None and options.systemId:\n            import urllib.request\n            fp = urllib.request.urlopen(input.systemId)\n        return self._parse_bytestream(fp, options)\n\n    def parseWithContext(self, input, cnode, action):\n        if action not in self._legal_actions:\n            raise ValueError(\"not a legal action\")\n        raise NotImplementedError(\"Haven't written this yet...\")\n\n    def _parse_bytestream(self, stream, options):\n        import xml.dom.expatbuilder\n        builder = xml.dom.expatbuilder.makeBuilder(options)\n        return builder.parseFile(stream)\n\n\ndef _name_xform(name):\n    return name.lower().replace('-', '_')\n\n\nclass DOMEntityResolver(object):\n    __slots__ = '_opener',\n\n    def resolveEntity(self, publicId, systemId):\n        assert systemId is not None\n        source = DOMInputSource()\n        source.publicId = publicId\n        source.systemId = systemId\n        source.byteStream = self._get_opener().open(systemId)\n\n        # determine the encoding if the transport provided it\n        source.encoding = self._guess_media_encoding(source)\n\n        # determine the base URI is we can\n        import posixpath, urllib.parse\n        parts = urllib.parse.urlparse(systemId)\n        scheme, netloc, path, params, query, fragment = parts\n        # XXX should we check the scheme here as well?\n        if path and not path.endswith(\"/\"):\n            path = posixpath.dirname(path) + \"/\"\n            parts = scheme, netloc, path, params, query, fragment\n            source.baseURI = urllib.parse.urlunparse(parts)\n\n        return source\n\n    def _get_opener(self):\n        try:\n            return self._opener\n        except AttributeError:\n            self._opener = self._create_opener()\n            return self._opener\n\n    def _create_opener(self):\n        import urllib.request\n        return urllib.request.build_opener()\n\n    def _guess_media_encoding(self, source):\n        info = source.byteStream.info()\n        if \"Content-Type\" in info:\n            for param in info.getplist():\n                if param.startswith(\"charset=\"):\n                    return param.split(\"=\", 1)[1].lower()\n\n\nclass DOMInputSource(object):\n    __slots__ = ('byteStream', 'characterStream', 'stringData',\n                 'encoding', 'publicId', 'systemId', 'baseURI')\n\n    def __init__(self):\n        self.byteStream = None\n        self.characterStream = None\n        self.stringData = None\n        self.encoding = None\n        self.publicId = None\n        self.systemId = None\n        self.baseURI = None\n\n    def _get_byteStream(self):\n        return self.byteStream\n    def _set_byteStream(self, byteStream):\n        self.byteStream = byteStream\n\n    def _get_characterStream(self):\n        return self.characterStream\n    def _set_characterStream(self, characterStream):\n        self.characterStream = characterStream\n\n    def _get_stringData(self):\n        return self.stringData\n    def _set_stringData(self, data):\n        self.stringData = data\n\n    def _get_encoding(self):\n        return self.encoding\n    def _set_encoding(self, encoding):\n        self.encoding = encoding\n\n    def _get_publicId(self):\n        return self.publicId\n    def _set_publicId(self, publicId):\n        self.publicId = publicId\n\n    def _get_systemId(self):\n        return self.systemId\n    def _set_systemId(self, systemId):\n        self.systemId = systemId\n\n    def _get_baseURI(self):\n        return self.baseURI\n    def _set_baseURI(self, uri):\n        self.baseURI = uri\n\n\nclass DOMBuilderFilter:\n    \"\"\"Element filter which can be used to tailor construction of\n    a DOM instance.\n    \"\"\"\n\n    # There's really no need for this class; concrete implementations\n    # should just implement the endElement() and startElement()\n    # methods as appropriate.  Using this makes it easy to only\n    # implement one of them.\n\n    FILTER_ACCEPT = 1\n    FILTER_REJECT = 2\n    FILTER_SKIP = 3\n    FILTER_INTERRUPT = 4\n\n    whatToShow = NodeFilter.SHOW_ALL\n\n    def _get_whatToShow(self):\n        return self.whatToShow\n\n    def acceptNode(self, element):\n        return self.FILTER_ACCEPT\n\n    def startContainer(self, element):\n        return self.FILTER_ACCEPT\n\ndel NodeFilter\n\n\nclass DocumentLS:\n    \"\"\"Mixin to create documents that conform to the load/save spec.\"\"\"\n\n    async = False\n\n    def _get_async(self):\n        return False\n    def _set_async(self, async):\n        if async:\n            raise xml.dom.NotSupportedErr(\n                \"asynchronous document loading is not supported\")\n\n    def abort(self):\n        # What does it mean to \"clear\" a document?  Does the\n        # documentElement disappear?\n        raise NotImplementedError(\n            \"haven't figured out what this means yet\")\n\n    def load(self, uri):\n        raise NotImplementedError(\"haven't written this yet\")\n\n    def loadXML(self, source):\n        raise NotImplementedError(\"haven't written this yet\")\n\n    def saveXML(self, snode):\n        if snode is None:\n            snode = self\n        elif snode.ownerDocument is not self:\n            raise xml.dom.WrongDocumentErr()\n        return snode.toxml()\n\n\nclass DOMImplementationLS:\n    MODE_SYNCHRONOUS = 1\n    MODE_ASYNCHRONOUS = 2\n\n    def createDOMBuilder(self, mode, schemaType):\n        if schemaType is not None:\n            raise xml.dom.NotSupportedErr(\n                \"schemaType not yet supported\")\n        if mode == self.MODE_SYNCHRONOUS:\n            return DOMBuilder()\n        if mode == self.MODE_ASYNCHRONOUS:\n            raise xml.dom.NotSupportedErr(\n                \"asynchronous builders are not supported\")\n        raise ValueError(\"unknown value for mode\")\n\n    def createDOMWriter(self):\n        raise NotImplementedError(\n            \"the writer interface hasn't been written yet!\")\n\n    def createDOMInputSource(self):\n        return DOMInputSource()\n"], "os": [".py", "r\"\"\"OS routines for Mac, NT, or Posix depending on what system we're on.\n\nThis exports:\n  - all functions from posix, nt, os2, or ce, e.g. unlink, stat, etc.\n  - os.path is either posixpath or ntpath\n  - os.name is either 'posix', 'nt', 'os2' or 'ce'.\n  - os.curdir is a string representing the current directory ('.' or ':')\n  - os.pardir is a string representing the parent directory ('..' or '::')\n  - os.sep is the (or a most common) pathname separator ('/' or ':' or '\\\\')\n  - os.extsep is the extension separator (always '.')\n  - os.altsep is the alternate pathname separator (None or '/')\n  - os.pathsep is the component separator used in $PATH etc\n  - os.linesep is the line separator in text files ('\\r' or '\\n' or '\\r\\n')\n  - os.defpath is the default search path for executables\n  - os.devnull is the file path of the null device ('/dev/null', etc.)\n\nPrograms that import and use 'os' stand a better chance of being\nportable between different platforms.  Of course, they must then\nonly use functions that are defined by all platforms (e.g., unlink\nand opendir), and leave all pathname manipulation to os.path\n(e.g., split and join).\n\"\"\"\n\nimport sys, errno\nimport stat as st\n\n_names = sys.builtin_module_names\n\n# Note:  more names are added to __all__ later.\n__all__ = [\"altsep\", \"curdir\", \"pardir\", \"sep\", \"pathsep\", \"linesep\",\n           \"defpath\", \"name\", \"path\", \"devnull\", \"SEEK_SET\", \"SEEK_CUR\",\n           \"SEEK_END\", \"fsencode\", \"fsdecode\", \"get_exec_path\", \"fdopen\",\n           \"popen\", \"extsep\"]\n\ndef _exists(name):\n    return name in globals()\n\ndef _get_exports_list(module):\n    try:\n        return list(module.__all__)\n    except AttributeError:\n        return [n for n in dir(module) if n[0] != '_']\n\n# Any new dependencies of the os module and/or changes in path separator\n# requires updating importlib as well.\nif 'posix' in _names:\n    name = 'posix'\n    linesep = '\\n'\n    from posix import *\n    try:\n        from posix import _exit\n        __all__.append('_exit')\n    except ImportError:\n        pass\n    import posixpath as path\n\n    try:\n        from posix import _have_functions\n    except ImportError:\n        pass\n\nelif 'nt' in _names:\n    name = 'nt'\n    linesep = '\\r\\n'\n    from nt import *\n    try:\n        from nt import _exit\n        __all__.append('_exit')\n    except ImportError:\n        pass\n    import ntpath as path\n\n    import nt\n    __all__.extend(_get_exports_list(nt))\n    del nt\n\n    try:\n        from nt import _have_functions\n    except ImportError:\n        pass\n\nelif 'os2' in _names:\n    name = 'os2'\n    linesep = '\\r\\n'\n    from os2 import *\n    try:\n        from os2 import _exit\n        __all__.append('_exit')\n    except ImportError:\n        pass\n    if sys.version.find('EMX GCC') == -1:\n        import ntpath as path\n    else:\n        import os2emxpath as path\n        from _emx_link import link\n\n    import os2\n    __all__.extend(_get_exports_list(os2))\n    del os2\n\n    try:\n        from os2 import _have_functions\n    except ImportError:\n        pass\n\nelif 'ce' in _names:\n    name = 'ce'\n    linesep = '\\r\\n'\n    from ce import *\n    try:\n        from ce import _exit\n        __all__.append('_exit')\n    except ImportError:\n        pass\n    # We can use the standard Windows path.\n    import ntpath as path\n\n    import ce\n    __all__.extend(_get_exports_list(ce))\n    del ce\n\n    try:\n        from ce import _have_functions\n    except ImportError:\n        pass\n\nelse:\n    raise ImportError('no os specific module found')\n\nsys.modules['os.path'] = path\nfrom os.path import (curdir, pardir, sep, pathsep, defpath, extsep, altsep,\n    devnull)\n\ndel _names\n\n\nif _exists(\"_have_functions\"):\n    _globals = globals()\n    def _add(str, fn):\n        if (fn in _globals) and (str in _have_functions):\n            _set.add(_globals[fn])\n\n    _set = set()\n    _add(\"HAVE_FACCESSAT\",  \"access\")\n    _add(\"HAVE_FCHMODAT\",   \"chmod\")\n    _add(\"HAVE_FCHOWNAT\",   \"chown\")\n    _add(\"HAVE_FSTATAT\",    \"stat\")\n    _add(\"HAVE_FUTIMESAT\",  \"utime\")\n    _add(\"HAVE_LINKAT\",     \"link\")\n    _add(\"HAVE_MKDIRAT\",    \"mkdir\")\n    _add(\"HAVE_MKFIFOAT\",   \"mkfifo\")\n    _add(\"HAVE_MKNODAT\",    \"mknod\")\n    _add(\"HAVE_OPENAT\",     \"open\")\n    _add(\"HAVE_READLINKAT\", \"readlink\")\n    _add(\"HAVE_RENAMEAT\",   \"rename\")\n    _add(\"HAVE_SYMLINKAT\",  \"symlink\")\n    _add(\"HAVE_UNLINKAT\",   \"unlink\")\n    _add(\"HAVE_UNLINKAT\",   \"rmdir\")\n    _add(\"HAVE_UTIMENSAT\",  \"utime\")\n    supports_dir_fd = _set\n\n    _set = set()\n    _add(\"HAVE_FACCESSAT\",  \"access\")\n    supports_effective_ids = _set\n\n    _set = set()\n    _add(\"HAVE_FCHDIR\",     \"chdir\")\n    _add(\"HAVE_FCHMOD\",     \"chmod\")\n    _add(\"HAVE_FCHOWN\",     \"chown\")\n    _add(\"HAVE_FDOPENDIR\",  \"listdir\")\n    _add(\"HAVE_FEXECVE\",    \"execve\")\n    _set.add(stat) # fstat always works\n    _add(\"HAVE_FTRUNCATE\",  \"truncate\")\n    _add(\"HAVE_FUTIMENS\",   \"utime\")\n    _add(\"HAVE_FUTIMES\",    \"utime\")\n    _add(\"HAVE_FPATHCONF\",  \"pathconf\")\n    if _exists(\"statvfs\") and _exists(\"fstatvfs\"): # mac os x10.3\n        _add(\"HAVE_FSTATVFS\", \"statvfs\")\n    supports_fd = _set\n\n    _set = set()\n    _add(\"HAVE_FACCESSAT\",  \"access\")\n    # Some platforms don't support lchmod().  Often the function exists\n    # anyway, as a stub that always returns ENOSUP or perhaps EOPNOTSUPP.\n    # (No, I don't know why that's a good design.)  ./configure will detect\n    # this and reject it--so HAVE_LCHMOD still won't be defined on such\n    # platforms.  This is Very Helpful.\n    #\n    # However, sometimes platforms without a working lchmod() *do* have\n    # fchmodat().  (Examples: Linux kernel 3.2 with glibc 2.15,\n    # OpenIndiana 3.x.)  And fchmodat() has a flag that theoretically makes\n    # it behave like lchmod().  So in theory it would be a suitable\n    # replacement for lchmod().  But when lchmod() doesn't work, fchmodat()'s\n    # flag doesn't work *either*.  Sadly ./configure isn't sophisticated\n    # enough to detect this condition--it only determines whether or not\n    # fchmodat() minimally works.\n    #\n    # Therefore we simply ignore fchmodat() when deciding whether or not\n    # os.chmod supports follow_symlinks.  Just checking lchmod() is\n    # sufficient.  After all--if you have a working fchmodat(), your\n    # lchmod() almost certainly works too.\n    #\n    # _add(\"HAVE_FCHMODAT\",   \"chmod\")\n    _add(\"HAVE_FCHOWNAT\",   \"chown\")\n    _add(\"HAVE_FSTATAT\",    \"stat\")\n    _add(\"HAVE_LCHFLAGS\",   \"chflags\")\n    _add(\"HAVE_LCHMOD\",     \"chmod\")\n    if _exists(\"lchown\"): # mac os x10.3\n        _add(\"HAVE_LCHOWN\", \"chown\")\n    _add(\"HAVE_LINKAT\",     \"link\")\n    _add(\"HAVE_LUTIMES\",    \"utime\")\n    _add(\"HAVE_LSTAT\",      \"stat\")\n    _add(\"HAVE_FSTATAT\",    \"stat\")\n    _add(\"HAVE_UTIMENSAT\",  \"utime\")\n    _add(\"MS_WINDOWS\",      \"stat\")\n    supports_follow_symlinks = _set\n\n    del _set\n    del _have_functions\n    del _globals\n    del _add\n\n\n# Python uses fixed values for the SEEK_ constants; they are mapped\n# to native constants if necessary in posixmodule.c\n# Other possible SEEK values are directly imported from posixmodule.c\nSEEK_SET = 0\nSEEK_CUR = 1\nSEEK_END = 2\n\n\ndef _get_masked_mode(mode):\n    mask = umask(0)\n    umask(mask)\n    return mode & ~mask\n\n# Super directory utilities.\n# (Inspired by Eric Raymond; the doc strings are mostly his)\n\ndef makedirs(name, mode=0o777, exist_ok=False):\n    \"\"\"makedirs(path [, mode=0o777][, exist_ok=False])\n\n    Super-mkdir; create a leaf directory and all intermediate ones.\n    Works like mkdir, except that any intermediate path segment (not\n    just the rightmost) will be created if it does not exist. If the\n    target directory with the same mode as we specified already exists,\n    raises an OSError if exist_ok is False, otherwise no exception is\n    raised.  This is recursive.\n\n    \"\"\"\n    head, tail = path.split(name)\n    if not tail:\n        head, tail = path.split(head)\n    if head and tail and not path.exists(head):\n        try:\n            makedirs(head, mode, exist_ok)\n        except OSError as e:\n            # be happy if someone already created the path\n            if e.errno != errno.EEXIST:\n                raise\n        cdir = curdir\n        if isinstance(tail, bytes):\n            cdir = bytes(curdir, 'ASCII')\n        if tail == cdir:           # xxx/newdir/. exists if xxx/newdir exists\n            return\n    try:\n        mkdir(name, mode)\n    except OSError as e:\n        dir_exists = path.isdir(name)\n        expected_mode = _get_masked_mode(mode)\n        if dir_exists:\n            # S_ISGID is automatically copied by the OS from parent to child\n            # directories on mkdir.  Don't consider it being set to be a mode\n            # mismatch as mkdir does not unset it when not specified in mode.\n            actual_mode = st.S_IMODE(lstat(name).st_mode) & ~st.S_ISGID\n        else:\n            actual_mode = -1\n        if not (e.errno == errno.EEXIST and exist_ok and dir_exists and\n                actual_mode == expected_mode):\n            if dir_exists and actual_mode != expected_mode:\n                e.strerror += ' (mode %o != expected mode %o)' % (\n                        actual_mode, expected_mode)\n            raise\n\ndef removedirs(name):\n    \"\"\"removedirs(path)\n\n    Super-rmdir; remove a leaf directory and all empty intermediate\n    ones.  Works like rmdir except that, if the leaf directory is\n    successfully removed, directories corresponding to rightmost path\n    segments will be pruned away until either the whole path is\n    consumed or an error occurs.  Errors during this latter phase are\n    ignored -- they generally mean that a directory was not empty.\n\n    \"\"\"\n    rmdir(name)\n    head, tail = path.split(name)\n    if not tail:\n        head, tail = path.split(head)\n    while head and tail:\n        try:\n            rmdir(head)\n        except error:\n            break\n        head, tail = path.split(head)\n\ndef renames(old, new):\n    \"\"\"renames(old, new)\n\n    Super-rename; create directories as necessary and delete any left\n    empty.  Works like rename, except creation of any intermediate\n    directories needed to make the new pathname good is attempted\n    first.  After the rename, directories corresponding to rightmost\n    path segments of the old name will be pruned way until either the\n    whole path is consumed or a nonempty directory is found.\n\n    Note: this function can fail with the new directory structure made\n    if you lack permissions needed to unlink the leaf directory or\n    file.\n\n    \"\"\"\n    head, tail = path.split(new)\n    if head and tail and not path.exists(head):\n        makedirs(head)\n    rename(old, new)\n    head, tail = path.split(old)\n    if head and tail:\n        try:\n            removedirs(head)\n        except error:\n            pass\n\n__all__.extend([\"makedirs\", \"removedirs\", \"renames\"])\n\ndef walk(top, topdown=True, onerror=None, followlinks=False):\n    \"\"\"Directory tree generator.\n\n    For each directory in the directory tree rooted at top (including top\n    itself, but excluding '.' and '..'), yields a 3-tuple\n\n        dirpath, dirnames, filenames\n\n    dirpath is a string, the path to the directory.  dirnames is a list of\n    the names of the subdirectories in dirpath (excluding '.' and '..').\n    filenames is a list of the names of the non-directory files in dirpath.\n    Note that the names in the lists are just names, with no path components.\n    To get a full path (which begins with top) to a file or directory in\n    dirpath, do os.path.join(dirpath, name).\n\n    If optional arg 'topdown' is true or not specified, the triple for a\n    directory is generated before the triples for any of its subdirectories\n    (directories are generated top down).  If topdown is false, the triple\n    for a directory is generated after the triples for all of its\n    subdirectories (directories are generated bottom up).\n\n    When topdown is true, the caller can modify the dirnames list in-place\n    (e.g., via del or slice assignment), and walk will only recurse into the\n    subdirectories whose names remain in dirnames; this can be used to prune\n    the search, or to impose a specific order of visiting.  Modifying\n    dirnames when topdown is false is ineffective, since the directories in\n    dirnames have already been generated by the time dirnames itself is\n    generated.\n\n    By default errors from the os.listdir() call are ignored.  If\n    optional arg 'onerror' is specified, it should be a function; it\n    will be called with one argument, an os.error instance.  It can\n    report the error to continue with the walk, or raise the exception\n    to abort the walk.  Note that the filename is available as the\n    filename attribute of the exception object.\n\n    By default, os.walk does not follow symbolic links to subdirectories on\n    systems that support them.  In order to get this functionality, set the\n    optional argument 'followlinks' to true.\n\n    Caution:  if you pass a relative pathname for top, don't change the\n    current working directory between resumptions of walk.  walk never\n    changes the current directory, and assumes that the client doesn't\n    either.\n\n    Example:\n\n    import os\n    from os.path import join, getsize\n    for root, dirs, files in os.walk('python/Lib/email'):\n        print(root, \"consumes\", end=\"\")\n        print(sum([getsize(join(root, name)) for name in files]), end=\"\")\n        print(\"bytes in\", len(files), \"non-directory files\")\n        if 'CVS' in dirs:\n            dirs.remove('CVS')  # don't visit CVS directories\n    \"\"\"\n\n    islink, join, isdir = path.islink, path.join, path.isdir\n\n    # We may not have read permission for top, in which case we can't\n    # get a list of the files the directory contains.  os.walk\n    # always suppressed the exception then, rather than blow up for a\n    # minor reason when (say) a thousand readable directories are still\n    # left to visit.  That logic is copied here.\n    try:\n        # Note that listdir and error are globals in this module due\n        # to earlier import-*.\n        names = listdir(top)\n    except error as err:\n        if onerror is not None:\n            onerror(err)\n        return\n\n    dirs, nondirs = [], []\n    for name in names:\n        if isdir(join(top, name)):\n            dirs.append(name)\n        else:\n            nondirs.append(name)\n\n    if topdown:\n        yield top, dirs, nondirs\n    for name in dirs:\n        new_path = join(top, name)\n        if followlinks or not islink(new_path):\n            yield from walk(new_path, topdown, onerror, followlinks)\n    if not topdown:\n        yield top, dirs, nondirs\n\n__all__.append(\"walk\")\n\nif {open, stat} <= supports_dir_fd and {listdir, stat} <= supports_fd:\n\n    def fwalk(top=\".\", topdown=True, onerror=None, *, follow_symlinks=False, dir_fd=None):\n        \"\"\"Directory tree generator.\n\n        This behaves exactly like walk(), except that it yields a 4-tuple\n\n            dirpath, dirnames, filenames, dirfd\n\n        `dirpath`, `dirnames` and `filenames` are identical to walk() output,\n        and `dirfd` is a file descriptor referring to the directory `dirpath`.\n\n        The advantage of fwalk() over walk() is that it's safe against symlink\n        races (when follow_symlinks is False).\n\n        If dir_fd is not None, it should be a file descriptor open to a directory,\n          and top should be relative; top will then be relative to that directory.\n          (dir_fd is always supported for fwalk.)\n\n        Caution:\n        Since fwalk() yields file descriptors, those are only valid until the\n        next iteration step, so you should dup() them if you want to keep them\n        for a longer period.\n\n        Example:\n\n        import os\n        for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):\n            print(root, \"consumes\", end=\"\")\n            print(sum([os.stat(name, dir_fd=rootfd).st_size for name in files]),\n                  end=\"\")\n            print(\"bytes in\", len(files), \"non-directory files\")\n            if 'CVS' in dirs:\n                dirs.remove('CVS')  # don't visit CVS directories\n        \"\"\"\n        # Note: To guard against symlink races, we use the standard\n        # lstat()/open()/fstat() trick.\n        orig_st = stat(top, follow_symlinks=False, dir_fd=dir_fd)\n        topfd = open(top, O_RDONLY, dir_fd=dir_fd)\n        try:\n            if (follow_symlinks or (st.S_ISDIR(orig_st.st_mode) and\n                                    path.samestat(orig_st, stat(topfd)))):\n                yield from _fwalk(topfd, top, topdown, onerror, follow_symlinks)\n        finally:\n            close(topfd)\n\n    def _fwalk(topfd, toppath, topdown, onerror, follow_symlinks):\n        # Note: This uses O(depth of the directory tree) file descriptors: if\n        # necessary, it can be adapted to only require O(1) FDs, see issue\n        # #13734.\n\n        names = listdir(topfd)\n        dirs, nondirs = [], []\n        for name in names:\n            try:\n                # Here, we don't use AT_SYMLINK_NOFOLLOW to be consistent with\n                # walk() which reports symlinks to directories as directories.\n                # We do however check for symlinks before recursing into\n                # a subdirectory.\n                if st.S_ISDIR(stat(name, dir_fd=topfd).st_mode):\n                    dirs.append(name)\n                else:\n                    nondirs.append(name)\n            except FileNotFoundError:\n                try:\n                    # Add dangling symlinks, ignore disappeared files\n                    if st.S_ISLNK(stat(name, dir_fd=topfd, follow_symlinks=False)\n                                .st_mode):\n                        nondirs.append(name)\n                except FileNotFoundError:\n                    continue\n\n        if topdown:\n            yield toppath, dirs, nondirs, topfd\n\n        for name in dirs:\n            try:\n                orig_st = stat(name, dir_fd=topfd, follow_symlinks=follow_symlinks)\n                dirfd = open(name, O_RDONLY, dir_fd=topfd)\n            except error as err:\n                if onerror is not None:\n                    onerror(err)\n                return\n            try:\n                if follow_symlinks or path.samestat(orig_st, stat(dirfd)):\n                    dirpath = path.join(toppath, name)\n                    yield from _fwalk(dirfd, dirpath, topdown, onerror, follow_symlinks)\n            finally:\n                close(dirfd)\n\n        if not topdown:\n            yield toppath, dirs, nondirs, topfd\n\n    __all__.append(\"fwalk\")\n\n# Make sure os.environ exists, at least\ntry:\n    environ\nexcept NameError:\n    environ = {}\n\ndef execl(file, *args):\n    \"\"\"execl(file, *args)\n\n    Execute the executable file with argument list args, replacing the\n    current process. \"\"\"\n    execv(file, args)\n\ndef execle(file, *args):\n    \"\"\"execle(file, *args, env)\n\n    Execute the executable file with argument list args and\n    environment env, replacing the current process. \"\"\"\n    env = args[-1]\n    execve(file, args[:-1], env)\n\ndef execlp(file, *args):\n    \"\"\"execlp(file, *args)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args, replacing the current process. \"\"\"\n    execvp(file, args)\n\ndef execlpe(file, *args):\n    \"\"\"execlpe(file, *args, env)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args and environment env, replacing the current\n    process. \"\"\"\n    env = args[-1]\n    execvpe(file, args[:-1], env)\n\ndef execvp(file, args):\n    \"\"\"execvp(file, args)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args, replacing the current process.\n    args may be a list or tuple of strings. \"\"\"\n    _execvpe(file, args)\n\ndef execvpe(file, args, env):\n    \"\"\"execvpe(file, args, env)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args and environment env , replacing the\n    current process.\n    args may be a list or tuple of strings. \"\"\"\n    _execvpe(file, args, env)\n\n__all__.extend([\"execl\",\"execle\",\"execlp\",\"execlpe\",\"execvp\",\"execvpe\"])\n\ndef _execvpe(file, args, env=None):\n    if env is not None:\n        exec_func = execve\n        argrest = (args, env)\n    else:\n        exec_func = execv\n        argrest = (args,)\n        env = environ\n\n    head, tail = path.split(file)\n    if head:\n        exec_func(file, *argrest)\n        return\n    last_exc = saved_exc = None\n    saved_tb = None\n    path_list = get_exec_path(env)\n    if name != 'nt':\n        file = fsencode(file)\n        path_list = map(fsencode, path_list)\n    for dir in path_list:\n        fullname = path.join(dir, file)\n        try:\n            exec_func(fullname, *argrest)\n        except error as e:\n            last_exc = e\n            tb = sys.exc_info()[2]\n            if (e.errno != errno.ENOENT and e.errno != errno.ENOTDIR\n                and saved_exc is None):\n                saved_exc = e\n                saved_tb = tb\n    if saved_exc:\n        raise saved_exc.with_traceback(saved_tb)\n    raise last_exc.with_traceback(tb)\n\n\ndef get_exec_path(env=None):\n    \"\"\"Returns the sequence of directories that will be searched for the\n    named executable (similar to a shell) when launching a process.\n\n    *env* must be an environment variable dict or None.  If *env* is None,\n    os.environ will be used.\n    \"\"\"\n    # Use a local import instead of a global import to limit the number of\n    # modules loaded at startup: the os module is always loaded at startup by\n    # Python. It may also avoid a bootstrap issue.\n    import warnings\n\n    if env is None:\n        env = environ\n\n    # {b'PATH': ...}.get('PATH') and {'PATH': ...}.get(b'PATH') emit a\n    # BytesWarning when using python -b or python -bb: ignore the warning\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", BytesWarning)\n\n        try:\n            path_list = env.get('PATH')\n        except TypeError:\n            path_list = None\n\n        if supports_bytes_environ:\n            try:\n                path_listb = env[b'PATH']\n            except (KeyError, TypeError):\n                pass\n            else:\n                if path_list is not None:\n                    raise ValueError(\n                        \"env cannot contain 'PATH' and b'PATH' keys\")\n                path_list = path_listb\n\n            if path_list is not None and isinstance(path_list, bytes):\n                path_list = fsdecode(path_list)\n\n    if path_list is None:\n        path_list = defpath\n    return path_list.split(pathsep)\n\n\n# Change environ to automatically call putenv(), unsetenv if they exist.\nfrom collections.abc import MutableMapping\n\nclass _Environ(MutableMapping):\n    def __init__(self, data, encodekey, decodekey, encodevalue, decodevalue, putenv, unsetenv):\n        self.encodekey = encodekey\n        self.decodekey = decodekey\n        self.encodevalue = encodevalue\n        self.decodevalue = decodevalue\n        self.putenv = putenv\n        self.unsetenv = unsetenv\n        self._data = data\n\n    def __getitem__(self, key):\n        try:\n            value = self._data[self.encodekey(key)]\n        except KeyError:\n            # raise KeyError with the original key value\n            raise KeyError(key) from None\n        return self.decodevalue(value)\n\n    def __setitem__(self, key, value):\n        key = self.encodekey(key)\n        value = self.encodevalue(value)\n        self.putenv(key, value)\n        self._data[key] = value\n\n    def __delitem__(self, key):\n        encodedkey = self.encodekey(key)\n        self.unsetenv(encodedkey)\n        try:\n            del self._data[encodedkey]\n        except KeyError:\n            # raise KeyError with the original key value\n            raise KeyError(key) from None\n\n    def __iter__(self):\n        for key in self._data:\n            yield self.decodekey(key)\n\n    def __len__(self):\n        return len(self._data)\n\n    def __repr__(self):\n        return 'environ({{{}}})'.format(', '.join(\n            ('{!r}: {!r}'.format(self.decodekey(key), self.decodevalue(value))\n            for key, value in self._data.items())))\n\n    def copy(self):\n        return dict(self)\n\n    def setdefault(self, key, value):\n        if key not in self:\n            self[key] = value\n        return self[key]\n\ntry:\n    _putenv = putenv\nexcept NameError:\n    _putenv = lambda key, value: None\nelse:\n    __all__.append(\"putenv\")\n\ntry:\n    _unsetenv = unsetenv\nexcept NameError:\n    _unsetenv = lambda key: _putenv(key, \"\")\nelse:\n    __all__.append(\"unsetenv\")\n\ndef _createenviron():\n    if name in ('os2', 'nt'):\n        # Where Env Var Names Must Be UPPERCASE\n        def check_str(value):\n            if not isinstance(value, str):\n                raise TypeError(\"str expected, not %s\" % type(value).__name__)\n            return value\n        encode = check_str\n        decode = str\n        def encodekey(key):\n            return encode(key).upper()\n        data = {}\n        for key, value in environ.items():\n            data[encodekey(key)] = value\n    else:\n        # Where Env Var Names Can Be Mixed Case\n        encoding = sys.getfilesystemencoding()\n        def encode(value):\n            if not isinstance(value, str):\n                raise TypeError(\"str expected, not %s\" % type(value).__name__)\n            return value.encode(encoding, 'surrogateescape')\n        def decode(value):\n            return value.decode(encoding, 'surrogateescape')\n        encodekey = encode\n        data = environ\n    return _Environ(data,\n        encodekey, decode,\n        encode, decode,\n        _putenv, _unsetenv)\n\n# unicode environ\nenviron = _createenviron()\ndel _createenviron\n\n\ndef getenv(key, default=None):\n    \"\"\"Get an environment variable, return None if it doesn't exist.\n    The optional second argument can specify an alternate default.\n    key, default and the result are str.\"\"\"\n    return environ.get(key, default)\n\nsupports_bytes_environ = name not in ('os2', 'nt')\n__all__.extend((\"getenv\", \"supports_bytes_environ\"))\n\nif supports_bytes_environ:\n    def _check_bytes(value):\n        if not isinstance(value, bytes):\n            raise TypeError(\"bytes expected, not %s\" % type(value).__name__)\n        return value\n\n    # bytes environ\n    environb = _Environ(environ._data,\n        _check_bytes, bytes,\n        _check_bytes, bytes,\n        _putenv, _unsetenv)\n    del _check_bytes\n\n    def getenvb(key, default=None):\n        \"\"\"Get an environment variable, return None if it doesn't exist.\n        The optional second argument can specify an alternate default.\n        key, default and the result are bytes.\"\"\"\n        return environb.get(key, default)\n\n    __all__.extend((\"environb\", \"getenvb\"))\n\ndef _fscodec():\n    encoding = sys.getfilesystemencoding()\n    if encoding == 'mbcs':\n        errors = 'strict'\n    else:\n        errors = 'surrogateescape'\n\n    def fsencode(filename):\n        \"\"\"\n        Encode filename to the filesystem encoding with 'surrogateescape' error\n        handler, return bytes unchanged. On Windows, use 'strict' error handler if\n        the file system encoding is 'mbcs' (which is the default encoding).\n        \"\"\"\n        if isinstance(filename, bytes):\n            return filename\n        elif isinstance(filename, str):\n            return filename.encode(encoding, errors)\n        else:\n            raise TypeError(\"expect bytes or str, not %s\" % type(filename).__name__)\n\n    def fsdecode(filename):\n        \"\"\"\n        Decode filename from the filesystem encoding with 'surrogateescape' error\n        handler, return str unchanged. On Windows, use 'strict' error handler if\n        the file system encoding is 'mbcs' (which is the default encoding).\n        \"\"\"\n        if isinstance(filename, str):\n            return filename\n        elif isinstance(filename, bytes):\n            return filename.decode(encoding, errors)\n        else:\n            raise TypeError(\"expect bytes or str, not %s\" % type(filename).__name__)\n\n    return fsencode, fsdecode\n\nfsencode, fsdecode = _fscodec()\ndel _fscodec\n\n# Supply spawn*() (probably only for Unix)\nif _exists(\"fork\") and not _exists(\"spawnv\") and _exists(\"execv\"):\n\n    P_WAIT = 0\n    P_NOWAIT = P_NOWAITO = 1\n\n    __all__.extend([\"P_WAIT\", \"P_NOWAIT\", \"P_NOWAITO\"])\n\n    # XXX Should we support P_DETACH?  I suppose it could fork()**2\n    # and close the std I/O streams.  Also, P_OVERLAY is the same\n    # as execv*()?\n\n    def _spawnvef(mode, file, args, env, func):\n        # Internal helper; func is the exec*() function to use\n        pid = fork()\n        if not pid:\n            # Child\n            try:\n                if env is None:\n                    func(file, args)\n                else:\n                    func(file, args, env)\n            except:\n                _exit(127)\n        else:\n            # Parent\n            if mode == P_NOWAIT:\n                return pid # Caller is responsible for waiting!\n            while 1:\n                wpid, sts = waitpid(pid, 0)\n                if WIFSTOPPED(sts):\n                    continue\n                elif WIFSIGNALED(sts):\n                    return -WTERMSIG(sts)\n                elif WIFEXITED(sts):\n                    return WEXITSTATUS(sts)\n                else:\n                    raise error(\"Not stopped, signaled or exited???\")\n\n    def spawnv(mode, file, args):\n        \"\"\"spawnv(mode, file, args) -> integer\n\nExecute file with arguments from args in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, None, execv)\n\n    def spawnve(mode, file, args, env):\n        \"\"\"spawnve(mode, file, args, env) -> integer\n\nExecute file with arguments from args in a subprocess with the\nspecified environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, env, execve)\n\n    # Note: spawnvp[e] is't currently supported on Windows\n\n    def spawnvp(mode, file, args):\n        \"\"\"spawnvp(mode, file, args) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, None, execvp)\n\n    def spawnvpe(mode, file, args, env):\n        \"\"\"spawnvpe(mode, file, args, env) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, env, execvpe)\n\nif _exists(\"spawnv\"):\n    # These aren't supplied by the basic Windows code\n    # but can be easily implemented in Python\n\n    def spawnl(mode, file, *args):\n        \"\"\"spawnl(mode, file, *args) -> integer\n\nExecute file with arguments from args in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return spawnv(mode, file, args)\n\n    def spawnle(mode, file, *args):\n        \"\"\"spawnle(mode, file, *args, env) -> integer\n\nExecute file with arguments from args in a subprocess with the\nsupplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        env = args[-1]\n        return spawnve(mode, file, args[:-1], env)\n\n\n    __all__.extend([\"spawnv\", \"spawnve\", \"spawnl\", \"spawnle\",])\n\n\nif _exists(\"spawnvp\"):\n    # At the moment, Windows doesn't implement spawnvp[e],\n    # so it won't have spawnlp[e] either.\n    def spawnlp(mode, file, *args):\n        \"\"\"spawnlp(mode, file, *args) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return spawnvp(mode, file, args)\n\n    def spawnlpe(mode, file, *args):\n        \"\"\"spawnlpe(mode, file, *args, env) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        env = args[-1]\n        return spawnvpe(mode, file, args[:-1], env)\n\n\n    __all__.extend([\"spawnvp\", \"spawnvpe\", \"spawnlp\", \"spawnlpe\",])\n\nimport copyreg as _copyreg\n\ndef _make_stat_result(tup, dict):\n    return stat_result(tup, dict)\n\ndef _pickle_stat_result(sr):\n    (type, args) = sr.__reduce__()\n    return (_make_stat_result, args)\n\ntry:\n    _copyreg.pickle(stat_result, _pickle_stat_result, _make_stat_result)\nexcept NameError: # stat_result may not exist\n    pass\n\ndef _make_statvfs_result(tup, dict):\n    return statvfs_result(tup, dict)\n\ndef _pickle_statvfs_result(sr):\n    (type, args) = sr.__reduce__()\n    return (_make_statvfs_result, args)\n\ntry:\n    _copyreg.pickle(statvfs_result, _pickle_statvfs_result,\n                     _make_statvfs_result)\nexcept NameError: # statvfs_result may not exist\n    pass\n\n# Supply os.popen()\ndef popen(cmd, mode=\"r\", buffering=-1):\n    if not isinstance(cmd, str):\n        raise TypeError(\"invalid cmd type (%s, expected string)\" % type(cmd))\n    if mode not in (\"r\", \"w\"):\n        raise ValueError(\"invalid mode %r\" % mode)\n    if buffering == 0 or buffering is None:\n        raise ValueError(\"popen() does not support unbuffered streams\")\n    import subprocess, io\n    if mode == \"r\":\n        proc = subprocess.Popen(cmd,\n                                shell=True,\n                                stdout=subprocess.PIPE,\n                                bufsize=buffering)\n        return _wrap_close(io.TextIOWrapper(proc.stdout), proc)\n    else:\n        proc = subprocess.Popen(cmd,\n                                shell=True,\n                                stdin=subprocess.PIPE,\n                                bufsize=buffering)\n        return _wrap_close(io.TextIOWrapper(proc.stdin), proc)\n\n# Helper for popen() -- a proxy for a file whose close waits for the process\nclass _wrap_close:\n    def __init__(self, stream, proc):\n        self._stream = stream\n        self._proc = proc\n    def close(self):\n        self._stream.close()\n        returncode = self._proc.wait()\n        if returncode == 0:\n            return None\n        if name == 'nt':\n            return returncode\n        else:\n            return returncode << 8  # Shift left to match old behavior\n    def __enter__(self):\n        return self\n    def __exit__(self, *args):\n        self.close()\n    def __getattr__(self, name):\n        return getattr(self._stream, name)\n    def __iter__(self):\n        return iter(self._stream)\n\n# Supply os.fdopen()\ndef fdopen(fd, *args, **kwargs):\n    if not isinstance(fd, int):\n        raise TypeError(\"invalid fd type (%s, expected integer)\" % type(fd))\n    import io\n    return io.open(fd, *args, **kwargs)\n"], "marshal": [".js", "var $module = (function($B){\n\nvar _b_ = $B.builtins\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\n//for(var $py_builtin in _b_) eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")\n\nfunction _py(obj){\n    if(obj===null){return None}\n    if(isinstance(obj,list)){\n        var res = []\n        for(var i=0;i<obj.length;i++){\n            res.push(_py(obj[i]))\n        }\n        return res\n    }\n    if(obj.__class__!==undefined){\n        if(obj.__class__===list){\n            for(var i=0;i<obj.length;i++){\n                obj[i] = _py(obj[i])\n            }\n        }\n        return obj\n    }\n    if(typeof obj==='object' && obj.__class__===undefined){\n        // transform JS object into a Python dict\n        var res = dict()\n        for(var attr in obj){\n            getattr(res,'__setitem__')(attr,_py(obj[attr]))\n        }\n        return res\n    }\n    return $B.JSObject(obj)\n}\nfunction _js(obj){\n    // obj is a Python object\n    if (isinstance(obj,[int,str])) return obj\n    if(obj===None) return null\n    if(obj===True) return true\n    if(obj===False) return false\n    if(isinstance(obj,float)) return obj.value\n    if(isinstance(obj,[list,tuple])){\n        var res = []\n        for(var i=0;i<obj.length;i++){res.push(_js(obj[i]))}\n        return res\n    }\n    if(isinstance(obj,dict)){\n        var res = new Object()\n        for(var i=0;i<obj.$keys.length;i++){\n            res[_js(obj.$keys[i])]=_js(obj.$values[i])\n        }\n        return res\n    }\n\n    throw TypeError(str(obj)+' is not JSON serializable')\n}\n\nreturn  {\n    loads : function(json_obj){return _py(JSON.parse(json_obj))},\n    dumps : function(obj){return JSON.stringify(_js(obj))},\n}\n\n})(__BRYTHON__)\n"], "ui.slider": [".py", "from . import widget\nfrom browser import doc,html\n\nclass Slider(widget.Widget):\n\n  def __init__(self, id=None, label=False):\n\n      self._div_shell=html.DIV(Class=\"ui-slider ui-slider-horizontal ui-widget ui-widget-content ui-corner-all\")\n\n      widget.Widget.__init__(self, self._div_shell, 'slider', id)\n\n      self._handle=html.A(Class=\"ui-slider-handle ui-state-default ui-corner-all\",\n                          Href='#', style={'left': '0px'})\n      self._value=0\n      self._isMouseDown=False\n\n      def startSlide(e):\n          self._isMouseDown=True\n          self._upperBound = self._div_shell.offsetWidth - self._handle.offsetWidth\n\n          pos = widget.getMousePosition(e)\n          self._startMouseX=pos['x']\n\n          self._lastElementLeft = parseInt(self._handle.style.left)\n          updatePosition(e)\n\n      def updatePosition(e):\n          pos = widget.getMousePosition(e)\n          #print('mose pos',pos)\n          _newPos = self._lastElementLeft + pos['x'] - self._startMouseX\n          \n          _newPos = max(0, _newPos)\n          _newPos = min(_newPos, self._upperBound)\n\n          self._handle.style.left = '%spx' % _newPos\n          #print('new position',self._handle.style.left)\n          self._lastElementLeft = _newPos\n\n      def moving(e):\n          if self._isMouseDown:\n             updatePosition(e)\n\n      def dropCallback(e):\n          self._isMouseDown=False\n          self._handle.unbind('mousemove', moving)\n\n\n      self._handle.bind('mousemove', moving)\n      self._handle.bind('mouseup', dropCallback)\n      #self._handle.bind('mouseout', dropCallback)\n      self._handle.bind('mousedown', startSlide)\n\n      def mouseover(e):\n          _class=self._handle.getAttribute('class')\n          self._handle.setAttribute('class', '%s %s' % (_class, 'ui-state-hover'))\n\n      def mouseout(e):\n          self._isMouseDown=False\n          _class=self._handle.getAttribute('class')\n          self._handle.setAttribute('class', _class.replace('ui-state-hover', ''))\n\n      self._handle.bind('mouseover', mouseover)\n      self._handle.bind('mouseout', mouseout)\n\n      self._div_shell <= self._handle\n\n  def get_value(self):\n      return self._value\n\n  #def set_value(self, value):\n  #    self._value=value\n  #   self._handle.style.left='%spx' % value\n"], "pprint": [".py", "#  Author:      Fred L. Drake, Jr.\n#               fdrake@acm.org\n#\n#  This is a simple little module I wrote to make life easier.  I didn't\n#  see anything quite like it in the library, though I may have overlooked\n#  something.  I wrote this when I was trying to read some heavily nested\n#  tuples with fairly non-descriptive content.  This is modeled very much\n#  after Lisp/Scheme - style pretty-printing of lists.  If you find it\n#  useful, thank small children who sleep at night.\n\n\"\"\"Support to pretty-print lists, tuples, & dictionaries recursively.\n\nVery simple, but useful, especially in debugging data structures.\n\nClasses\n-------\n\nPrettyPrinter()\n    Handle pretty-printing operations onto a stream using a configured\n    set of formatting parameters.\n\nFunctions\n---------\n\npformat()\n    Format a Python object into a pretty-printed representation.\n\npprint()\n    Pretty-print a Python object to a stream [default is sys.stdout].\n\nsaferepr()\n    Generate a 'standard' repr()-like value, but protect against recursive\n    data structures.\n\n\"\"\"\n\nimport sys as _sys\nfrom collections import OrderedDict as _OrderedDict\nfrom io import StringIO as _StringIO\n\n__all__ = [\"pprint\",\"pformat\",\"isreadable\",\"isrecursive\",\"saferepr\",\n           \"PrettyPrinter\"]\n\n# cache these for faster access:\n_commajoin = \", \".join\n_id = id\n_len = len\n_type = type\n\n\ndef pprint(object, stream=None, indent=1, width=80, depth=None):\n    \"\"\"Pretty-print a Python object to a stream [default is sys.stdout].\"\"\"\n    printer = PrettyPrinter(\n        stream=stream, indent=indent, width=width, depth=depth)\n    printer.pprint(object)\n\ndef pformat(object, indent=1, width=80, depth=None):\n    \"\"\"Format a Python object into a pretty-printed representation.\"\"\"\n    return PrettyPrinter(indent=indent, width=width, depth=depth).pformat(object)\n\ndef saferepr(object):\n    \"\"\"Version of repr() which can handle recursive data structures.\"\"\"\n    return _safe_repr(object, {}, None, 0)[0]\n\ndef isreadable(object):\n    \"\"\"Determine if saferepr(object) is readable by eval().\"\"\"\n    return _safe_repr(object, {}, None, 0)[1]\n\ndef isrecursive(object):\n    \"\"\"Determine if object requires a recursive representation.\"\"\"\n    return _safe_repr(object, {}, None, 0)[2]\n\nclass _safe_key:\n    \"\"\"Helper function for key functions when sorting unorderable objects.\n\n    The wrapped-object will fallback to an Py2.x style comparison for\n    unorderable types (sorting first comparing the type name and then by\n    the obj ids).  Does not work recursively, so dict.items() must have\n    _safe_key applied to both the key and the value.\n\n    \"\"\"\n\n    __slots__ = ['obj']\n\n    def __init__(self, obj):\n        self.obj = obj\n\n    def __lt__(self, other):\n        try:\n            rv = self.obj.__lt__(other.obj)\n        except TypeError:\n            rv = NotImplemented\n\n        if rv is NotImplemented:\n            rv = (str(type(self.obj)), id(self.obj)) < \\\n                 (str(type(other.obj)), id(other.obj))\n        return rv\n\ndef _safe_tuple(t):\n    \"Helper function for comparing 2-tuples\"\n    return _safe_key(t[0]), _safe_key(t[1])\n\nclass PrettyPrinter:\n    def __init__(self, indent=1, width=80, depth=None, stream=None):\n        \"\"\"Handle pretty printing operations onto a stream using a set of\n        configured parameters.\n\n        indent\n            Number of spaces to indent for each level of nesting.\n\n        width\n            Attempted maximum number of columns in the output.\n\n        depth\n            The maximum depth to print out nested structures.\n\n        stream\n            The desired output stream.  If omitted (or false), the standard\n            output stream available at construction will be used.\n\n        \"\"\"\n        indent = int(indent)\n        width = int(width)\n        assert indent >= 0, \"indent must be >= 0\"\n        assert depth is None or depth > 0, \"depth must be > 0\"\n        assert width, \"width must be != 0\"\n        self._depth = depth\n        self._indent_per_level = indent\n        self._width = width\n        if stream is not None:\n            self._stream = stream\n        else:\n            self._stream = _sys.stdout\n\n    def pprint(self, object):\n        self._format(object, self._stream, 0, 0, {}, 0)\n        self._stream.write(\"\\n\")\n\n    def pformat(self, object):\n        sio = _StringIO()\n        self._format(object, sio, 0, 0, {}, 0)\n        return sio.getvalue()\n\n    def isrecursive(self, object):\n        return self.format(object, {}, 0, 0)[2]\n\n    def isreadable(self, object):\n        s, readable, recursive = self.format(object, {}, 0, 0)\n        return readable and not recursive\n\n    def _format(self, object, stream, indent, allowance, context, level):\n        level = level + 1\n        import sys\n        sys.stderr.write(str(object))\n        objid = _id(object)\n        if objid in context:\n            stream.write(_recursion(object))\n            self._recursive = True\n            self._readable = False\n            return\n        rep = self._repr(object, context, level - 1)\n        typ = _type(object)\n        sepLines = _len(rep) > (self._width - 1 - indent - allowance)\n        write = stream.write\n\n        if self._depth and level > self._depth:\n            write(rep)\n            return\n\n        if sepLines:\n            r = getattr(typ, \"__repr__\", None)\n            if issubclass(typ, dict):\n                write('{')\n                if self._indent_per_level > 1:\n                    write((self._indent_per_level - 1) * ' ')\n                length = _len(object)\n                if length:\n                    context[objid] = 1\n                    indent = indent + self._indent_per_level\n                    if issubclass(typ, _OrderedDict):\n                        items = list(object.items())\n                    else:\n                        items = sorted(object.items(), key=_safe_tuple)\n                    key, ent = items[0]\n                    rep = self._repr(key, context, level)\n                    write(rep)\n                    write(': ')\n                    self._format(ent, stream, indent + _len(rep) + 2,\n                                  allowance + 1, context, level)\n                    if length > 1:\n                        for key, ent in items[1:]:\n                            rep = self._repr(key, context, level)\n                            write(',\\n%s%s: ' % (' '*indent, rep))\n                            self._format(ent, stream, indent + _len(rep) + 2,\n                                          allowance + 1, context, level)\n                    indent = indent - self._indent_per_level\n                    del context[objid]\n                write('}')\n                return\n\n            if ((issubclass(typ, list) and r is list.__repr__) or\n                (issubclass(typ, tuple) and r is tuple.__repr__) or\n                (issubclass(typ, set) and r is set.__repr__) or\n                (issubclass(typ, frozenset) and r is frozenset.__repr__)\n               ):\n                length = _len(object)\n                if issubclass(typ, list):\n                    write('[')\n                    endchar = ']'\n                elif issubclass(typ, tuple):\n                    write('(')\n                    endchar = ')'\n                else:\n                    if not length:\n                        write(rep)\n                        return\n                    if typ is set:\n                        write('{')\n                        endchar = '}'\n                    else:\n                        write(typ.__name__)\n                        write('({')\n                        endchar = '})'\n                        indent += len(typ.__name__) + 1\n                    object = sorted(object, key=_safe_key)\n                if self._indent_per_level > 1:\n                    write((self._indent_per_level - 1) * ' ')\n                if length:\n                    context[objid] = 1\n                    indent = indent + self._indent_per_level\n                    self._format(object[0], stream, indent, allowance + 1,\n                                 context, level)\n                    if length > 1:\n                        for ent in object[1:]:\n                            write(',\\n' + ' '*indent)\n                            self._format(ent, stream, indent,\n                                          allowance + 1, context, level)\n                    indent = indent - self._indent_per_level\n                    del context[objid]\n                if issubclass(typ, tuple) and length == 1:\n                    write(',')\n                write(endchar)\n                return\n\n        write(rep)\n\n    def _repr(self, object, context, level):\n        repr, readable, recursive = self.format(object, context.copy(),\n                                                self._depth, level)\n        if not readable:\n            self._readable = False\n        if recursive:\n            self._recursive = True\n        return repr\n\n    def format(self, object, context, maxlevels, level):\n        \"\"\"Format object for a specific context, returning a string\n        and flags indicating whether the representation is 'readable'\n        and whether the object represents a recursive construct.\n        \"\"\"\n        return _safe_repr(object, context, maxlevels, level)\n\n\n# Return triple (repr_string, isreadable, isrecursive).\n\ndef _safe_repr(object, context, maxlevels, level):\n    typ = _type(object)\n    if typ is str:\n        if 'locale' not in _sys.modules:\n            return repr(object), True, False\n        if \"'\" in object and '\"' not in object:\n            closure = '\"'\n            quotes = {'\"': '\\\\\"'}\n        else:\n            closure = \"'\"\n            quotes = {\"'\": \"\\\\'\"}\n        qget = quotes.get\n        sio = _StringIO()\n        write = sio.write\n        for char in object:\n            if char.isalpha():\n                write(char)\n            else:\n                write(qget(char, repr(char)[1:-1]))\n        return (\"%s%s%s\" % (closure, sio.getvalue(), closure)), True, False\n\n    r = getattr(typ, \"__repr__\", None)\n    if issubclass(typ, dict) and r is dict.__repr__:\n        if not object:\n            return \"{}\", True, False\n        objid = _id(object)\n        if maxlevels and level >= maxlevels:\n            return \"{...}\", False, objid in context\n        if objid in context:\n            return _recursion(object), False, True\n        context[objid] = 1\n        readable = True\n        recursive = False\n        components = []\n        append = components.append\n        level += 1\n        saferepr = _safe_repr\n        items = sorted(object.items(), key=_safe_tuple)\n        for k, v in items:\n            krepr, kreadable, krecur = saferepr(k, context, maxlevels, level)\n            vrepr, vreadable, vrecur = saferepr(v, context, maxlevels, level)\n            append(\"%s: %s\" % (krepr, vrepr))\n            readable = readable and kreadable and vreadable\n            if krecur or vrecur:\n                recursive = True\n        del context[objid]\n        return \"{%s}\" % _commajoin(components), readable, recursive\n\n    if (issubclass(typ, list) and r is list.__repr__) or \\\n       (issubclass(typ, tuple) and r is tuple.__repr__):\n        if issubclass(typ, list):\n            if not object:\n                return \"[]\", True, False\n            format = \"[%s]\"\n        elif _len(object) == 1:\n            format = \"(%s,)\"\n        else:\n            if not object:\n                return \"()\", True, False\n            format = \"(%s)\"\n        objid = _id(object)\n        if maxlevels and level >= maxlevels:\n            return format % \"...\", False, objid in context\n        if objid in context:\n            return _recursion(object), False, True\n        context[objid] = 1\n        readable = True\n        recursive = False\n        components = []\n        append = components.append\n        level += 1\n        for o in object:\n            orepr, oreadable, orecur = _safe_repr(o, context, maxlevels, level)\n            append(orepr)\n            if not oreadable:\n                readable = False\n            if orecur:\n                recursive = True\n        del context[objid]\n        return format % _commajoin(components), readable, recursive\n\n    rep = repr(object)\n    return rep, (rep and not rep.startswith('<')), False\n\n\ndef _recursion(object):\n    return (\"<Recursion on %s with id=%s>\"\n            % (_type(object).__name__, _id(object)))\n\n\ndef _perfcheck(object=None):\n    import time\n    if object is None:\n        object = [(\"string\", (1, 2), [3, 4], {5: 6, 7: 8})] * 100000\n    p = PrettyPrinter()\n    t1 = time.time()\n    _safe_repr(object, {}, None, 0)\n    t2 = time.time()\n    p.pformat(object)\n    t3 = time.time()\n    print(\"_safe_repr:\", t2 - t1)\n    print(\"pformat:\", t3 - t2)\n\nif __name__ == \"__main__\":\n    _perfcheck()\n"], "unittest.__main__": [".py", "\"\"\"Main entry point\"\"\"\n\nimport sys\nif sys.argv[0].endswith(\"__main__.py\"):\n    import os.path\n    # We change sys.argv[0] to make help message more useful\n    # use executable without path, unquoted\n    # (it's just a hint anyway)\n    # (if you have spaces in your executable you get what you deserve!)\n    executable = os.path.basename(sys.executable)\n    sys.argv[0] = executable + \" -m unittest\"\n    del os\n\n__unittest = True\n\nfrom .main import main, TestProgram, USAGE_AS_MAIN\nTestProgram.USAGE = USAGE_AS_MAIN\n\nmain(module=None)\n"], "_collections": [".py", "# \"High performance data structures\n# \"\n# copied from pypy repo\n\n#\n# Copied and completed from the sandbox of CPython\n#   (nondist/sandbox/collections/pydeque.py rev 1.1, Raymond Hettinger)\n#\n# edited for Brython line 558 : catch ImportError instead of AttributeError\n\nimport operator\n#try:\n#    from thread import get_ident as _thread_ident\n#except ImportError:\ndef _thread_ident():\n    return -1\n\n\nn = 30\nLFTLNK = n\nRGTLNK = n+1\nBLOCKSIZ = n+2\n\n# The deque's size limit is d.maxlen.  The limit can be zero or positive, or\n# None.  After an item is added to a deque, we check to see if the size has\n# grown past the limit. If it has, we get the size back down to the limit by\n# popping an item off of the opposite end.  The methods that can trigger this\n# are append(), appendleft(), extend(), and extendleft().\n\n#class deque(object):\nclass deque:\n\n    def __new__(cls, iterable=(), *args, **kw):\n        #fixme\n        #self = super(deque, cls).__new__(cls, *args, **kw)\n        self=object.__new__(cls, *args, **kw)\n        self.clear()\n        return self\n\n    def __init__(self, iterable=(), maxlen=None):\n        object.__init__(self)\n        self.clear()\n        if maxlen is not None:\n            if maxlen < 0:\n                raise ValueError(\"maxlen must be non-negative\")\n        self._maxlen = maxlen\n        add = self.append\n        for elem in iterable:\n            add(elem)\n\n    @property\n    def maxlen(self):\n        return self._maxlen\n\n    def clear(self):\n        self.right = self.left = [None] * BLOCKSIZ\n        self.rightndx = n//2   # points to last written element\n        self.leftndx = n//2+1\n        self.length = 0\n        self.state = 0\n\n    def append(self, x):\n        self.state += 1\n        self.rightndx += 1\n        if self.rightndx == n:\n            newblock = [None] * BLOCKSIZ\n            self.right[RGTLNK] = newblock\n            newblock[LFTLNK] = self.right\n            self.right = newblock\n            self.rightndx = 0\n        self.length += 1\n        self.right[self.rightndx] = x\n        if self.maxlen is not None and self.length > self.maxlen:\n            self.popleft()\n\n    def appendleft(self, x):\n        self.state += 1\n        self.leftndx -= 1\n        if self.leftndx == -1:\n            newblock = [None] * BLOCKSIZ\n            self.left[LFTLNK] = newblock\n            newblock[RGTLNK] = self.left\n            self.left = newblock\n            self.leftndx = n-1\n        self.length += 1\n        self.left[self.leftndx] = x\n        if self.maxlen is not None and self.length > self.maxlen:\n            self.pop()\n\n    def extend(self, iterable):\n        if iterable is self:\n            iterable = list(iterable)\n        for elem in iterable:\n            self.append(elem)\n\n    def extendleft(self, iterable):\n        if iterable is self:\n            iterable = list(iterable)\n        for elem in iterable:\n            self.appendleft(elem)\n\n    def pop(self):\n        if self.left is self.right and self.leftndx > self.rightndx:\n            #raise IndexError, \"pop from an empty deque\"  # does not work in brython\n            raise IndexError(\"pop from an empty deque\")\n        x = self.right[self.rightndx]\n        self.right[self.rightndx] = None\n        self.length -= 1\n        self.rightndx -= 1\n        self.state += 1\n        if self.rightndx == -1:\n            prevblock = self.right[LFTLNK]\n            if prevblock is None:\n                # the deque has become empty; recenter instead of freeing block\n                self.rightndx = n//2\n                self.leftndx = n//2+1\n            else:\n                prevblock[RGTLNK] = None\n                self.right[LFTLNK] = None\n                self.right = prevblock\n                self.rightndx = n-1\n        return x\n\n    def popleft(self):\n        if self.left is self.right and self.leftndx > self.rightndx:\n            #raise IndexError, \"pop from an empty deque\"\n            raise IndexError(\"pop from an empty deque\")\n        x = self.left[self.leftndx]\n        self.left[self.leftndx] = None\n        self.length -= 1\n        self.leftndx += 1\n        self.state += 1\n        if self.leftndx == n:\n            prevblock = self.left[RGTLNK]\n            if prevblock is None:\n                # the deque has become empty; recenter instead of freeing block\n                self.rightndx = n//2\n                self.leftndx = n//2+1\n            else:\n                prevblock[LFTLNK] = None\n                self.left[RGTLNK] = None\n                self.left = prevblock\n                self.leftndx = 0\n        return x\n\n    def count(self, value):\n        c = 0\n        for item in self:\n            if item == value:\n                c += 1\n        return c\n\n    def remove(self, value):\n        # Need to be defensive for mutating comparisons\n        for i in range(len(self)):\n            if self[i] == value:\n                del self[i]\n                return\n        raise ValueError(\"deque.remove(x): x not in deque\")\n\n    def rotate(self, n=1):\n        length = len(self)\n        if length == 0:\n            return\n        halflen = (length+1) >> 1\n        if n > halflen or n < -halflen:\n            n %= length\n            if n > halflen:\n                n -= length\n            elif n < -halflen:\n                n += length\n        while n > 0:\n            self.appendleft(self.pop())\n            n -= 1\n        while n < 0:\n            self.append(self.popleft())\n            n += 1\n\n    def reverse(self):\n        \"reverse *IN PLACE*\"\n        leftblock = self.left\n        rightblock = self.right\n        leftindex = self.leftndx\n        rightindex = self.rightndx\n        for i in range(self.length // 2):\n            # Validate that pointers haven't met in the middle\n            assert leftblock != rightblock or leftindex < rightindex\n\n            # Swap\n            (rightblock[rightindex], leftblock[leftindex]) = (\n                leftblock[leftindex], rightblock[rightindex])\n\n            # Advance left block/index pair\n            leftindex += 1\n            if leftindex == n:\n                leftblock = leftblock[RGTLNK]\n                assert leftblock is not None\n                leftindex = 0\n\n            # Step backwards with the right block/index pair\n            rightindex -= 1\n            if rightindex == -1:\n                rightblock = rightblock[LFTLNK]\n                assert rightblock is not None\n                rightindex = n - 1\n\n    def __repr__(self):\n        threadlocalattr = '__repr' + str(_thread_ident())\n        if threadlocalattr in self.__dict__:\n            return 'deque([...])'\n        else:\n            self.__dict__[threadlocalattr] = True\n            try:\n                if self.maxlen is not None:\n                    return 'deque(%r, maxlen=%s)' % (list(self), self.maxlen)\n                else:\n                    return 'deque(%r)' % (list(self),)\n            finally:\n                del self.__dict__[threadlocalattr]\n\n    def __iter__(self):\n        return deque_iterator(self, self._iter_impl)\n\n    def _iter_impl(self, original_state, giveup):\n        if self.state != original_state:\n            giveup()\n        block = self.left\n        while block:\n            l, r = 0, n\n            if block is self.left:\n                l = self.leftndx\n            if block is self.right:\n                r = self.rightndx + 1\n            for elem in block[l:r]:\n                yield elem\n                if self.state != original_state:\n                    giveup()\n            block = block[RGTLNK]\n\n    def __reversed__(self):\n        return deque_iterator(self, self._reversed_impl)\n\n    def _reversed_impl(self, original_state, giveup):\n        if self.state != original_state:\n            giveup()\n        block = self.right\n        while block:\n            l, r = 0, n\n            if block is self.left:\n                l = self.leftndx\n            if block is self.right:\n                r = self.rightndx + 1\n            for elem in reversed(block[l:r]):\n                yield elem\n                if self.state != original_state:\n                    giveup()\n            block = block[LFTLNK]\n\n    def __len__(self):\n        #sum = 0\n        #block = self.left\n        #while block:\n        #    sum += n\n        #    block = block[RGTLNK]\n        #return sum + self.rightndx - self.leftndx + 1 - n\n        return self.length\n\n    def __getref(self, index):\n        if index >= 0:\n            block = self.left\n            while block:\n                l, r = 0, n\n                if block is self.left:\n                    l = self.leftndx\n                if block is self.right:\n                    r = self.rightndx + 1\n                span = r-l\n                if index < span:\n                    return block, l+index\n                index -= span\n                block = block[RGTLNK]\n        else:\n            block = self.right\n            while block:\n                l, r = 0, n\n                if block is self.left:\n                    l = self.leftndx\n                if block is self.right:\n                    r = self.rightndx + 1\n                negative_span = l-r\n                if index >= negative_span:\n                    return block, r+index\n                index -= negative_span\n                block = block[LFTLNK]\n        raise IndexError(\"deque index out of range\")\n\n    def __getitem__(self, index):\n        block, index = self.__getref(index)\n        return block[index]\n\n    def __setitem__(self, index, value):\n        block, index = self.__getref(index)\n        block[index] = value\n\n    def __delitem__(self, index):\n        length = len(self)\n        if index >= 0:\n            if index >= length:\n                raise IndexError(\"deque index out of range\")\n            self.rotate(-index)\n            self.popleft()\n            self.rotate(index)\n        else:\n            #index = ~index      #todo until bit wise operators are in bython\n            index= index^(2**31)\n            if index >= length:\n                raise IndexError(\"deque index out of range\")\n            self.rotate(index)\n            self.pop()\n            self.rotate(-index)\n\n    def __reduce_ex__(self, proto):\n        return type(self), (list(self), self.maxlen)\n\n    def __hash__(self):\n        #raise TypeError, \"deque objects are unhashable\"\n        raise TypeError(\"deque objects are unhashable\")\n\n    def __copy__(self):\n        return self.__class__(self, self.maxlen)\n\n    # XXX make comparison more efficient\n    def __eq__(self, other):\n        if isinstance(other, deque):\n            return list(self) == list(other)\n        else:\n            return NotImplemented\n\n    def __ne__(self, other):\n        if isinstance(other, deque):\n            return list(self) != list(other)\n        else:\n            return NotImplemented\n\n    def __lt__(self, other):\n        if isinstance(other, deque):\n            return list(self) < list(other)\n        else:\n            return NotImplemented\n\n    def __le__(self, other):\n        if isinstance(other, deque):\n            return list(self) <= list(other)\n        else:\n            return NotImplemented\n\n    def __gt__(self, other):\n        if isinstance(other, deque):\n            return list(self) > list(other)\n        else:\n            return NotImplemented\n\n    def __ge__(self, other):\n        if isinstance(other, deque):\n            return list(self) >= list(other)\n        else:\n            return NotImplemented\n\n    def __iadd__(self, other):\n        self.extend(other)\n        return self\n\n\nclass deque_iterator(object):\n\n    def __init__(self, deq, itergen):\n        self.counter = len(deq)\n        def giveup():\n            self.counter = 0\n            #raise RuntimeError, \"deque mutated during iteration\"\n            raise RuntimeError(\"deque mutated during iteration\")\n        self._gen = itergen(deq.state, giveup)\n\n    def next(self):\n        res =  self._gen.next()\n        self.counter -= 1\n        return res\n\n    def __iter__(self):\n        return self\n\nclass defaultdict(dict):\n    \n    def __init__(self, *args, **kwds):\n        if len(args) > 0:\n            default_factory = args[0]\n            args = args[1:]\n            if not callable(default_factory) and default_factory is not None:\n                raise TypeError(\"first argument must be callable\")\n        else:\n            default_factory = None\n        dict.__init__(self, args, kwds)\n        self.default_factory = default_factory\n        self.update(args, kwds)\n        #super(defaultdict, self).__init__(*args, **kwds)\n\n    #fixme..  had to add this function to get defaultdict working with brython correctly\n    def __getitem__(self, key):\n        if self.__contains__(key):  \n           return dict.__getitem__(self,key)\n    \n        return self.__missing__(key)\n\n    def __missing__(self, key):\n        # from defaultdict docs\n        if self.default_factory is None: \n            raise KeyError(key)\n        self[key] = value = self.default_factory()\n        return value\n\n    def __repr__(self, recurse=set()):\n        if id(self) in recurse:\n            return \"defaultdict(...)\"\n        try:\n            recurse.add(id(self))\n            return \"defaultdict(%s, %s)\" % (repr(self.default_factory), super(defaultdict, self).__repr__())\n        finally:\n            recurse.remove(id(self))\n\n    def copy(self):\n        return type(self)(self.default_factory, self)\n    \n    def __copy__(self):\n        return self.copy()\n\n    def __reduce__(self):\n        #\n        #__reduce__ must return a 5-tuple as follows:\n        #\n        #   - factory function\n        #   - tuple of args for the factory function\n        #   - additional state (here None)\n        #   - sequence iterator (here None)\n        #   - dictionary iterator (yielding successive (key, value) pairs\n\n        #   This API is used by pickle.py and copy.py.\n        #\n        return (type(self), (self.default_factory,), None, None, self.iteritems())\n\nfrom operator import itemgetter as _itemgetter\nfrom keyword import iskeyword as _iskeyword\nimport sys as _sys\n\ndef namedtuple(typename, field_names, verbose=False, rename=False):\n    \"\"\"Returns a new subclass of tuple with named fields.\n\n    >>> Point = namedtuple('Point', 'x y')\n    >>> Point.__doc__                   # docstring for the new class\n    'Point(x, y)'\n    >>> p = Point(11, y=22)             # instantiate with positional args or keywords\n    >>> p[0] + p[1]                     # indexable like a plain tuple\n    33\n    >>> x, y = p                        # unpack like a regular tuple\n    >>> x, y\n    (11, 22)\n    >>> p.x + p.y                       # fields also accessable by name\n    33\n    >>> d = p._asdict()                 # convert to a dictionary\n    >>> d['x']\n    11\n    >>> Point(**d)                      # convert from a dictionary\n    Point(x=11, y=22)\n    >>> p._replace(x=100)               # _replace() is like str.replace() but targets named fields\n    Point(x=100, y=22)\n\n    \"\"\"\n\n    # Parse and validate the field names.  Validation serves two purposes,\n    # generating informative error messages and preventing template injection attacks.\n    if isinstance(field_names, str):\n        field_names = field_names.replace(',', ' ').split() # names separated by whitespace and/or commas\n    field_names = tuple(map(str, field_names))\n    if rename:\n        names = list(field_names)\n        seen = set()\n        for i, name in enumerate(names):\n            if (not min(c.isalnum() or c=='_' for c in name) or _iskeyword(name)\n                or not name or name[0].isdigit() or name.startswith('_')\n                or name in seen):\n                    names[i] = '_%d' % i\n            seen.add(name)\n        field_names = tuple(names)\n    for name in (typename,) + field_names:\n        if not min(c.isalnum() or c=='_' for c in name):\n            raise ValueError('Type names and field names can only contain alphanumeric characters and underscores: %r' % name)\n        if _iskeyword(name):\n            raise ValueError('Type names and field names cannot be a keyword: %r' % name)\n        if name[0].isdigit():\n            raise ValueError('Type names and field names cannot start with a number: %r' % name)\n    seen_names = set()\n    for name in field_names:\n        if name.startswith('_') and not rename:\n            raise ValueError('Field names cannot start with an underscore: %r' % name)\n        if name in seen_names:\n            raise ValueError('Encountered duplicate field name: %r' % name)\n        seen_names.add(name)\n\n    # Create and fill-in the class template\n    numfields = len(field_names)\n    argtxt = repr(field_names).replace(\"'\", \"\")[1:-1]   # tuple repr without parens or quotes\n    reprtxt = ', '.join('%s=%%r' % name for name in field_names)\n    template = '''class %(typename)s(tuple):\n        '%(typename)s(%(argtxt)s)' \\n\n        __slots__ = () \\n\n        _fields = %(field_names)r \\n\n        def __new__(_cls, %(argtxt)s):\n            return _tuple.__new__(_cls, (%(argtxt)s)) \\n\n        @classmethod\n        def _make(cls, iterable, new=tuple.__new__, len=len):\n            'Make a new %(typename)s object from a sequence or iterable'\n            result = new(cls, iterable)\n            if len(result) != %(numfields)d:\n                raise TypeError('Expected %(numfields)d arguments, got %%d' %% len(result))\n            return result \\n\n        def __repr__(self):\n            return '%(typename)s(%(reprtxt)s)' %% self \\n\n        def _asdict(self):\n            'Return a new dict which maps field names to their values'\n            return dict(zip(self._fields, self)) \\n\n        def _replace(_self, **kwds):\n            'Return a new %(typename)s object replacing specified fields with new values'\n            result = _self._make(map(kwds.pop, %(field_names)r, _self))\n            if kwds:\n                raise ValueError('Got unexpected field names: %%r' %% kwds.keys())\n            return result \\n\n        def __getnewargs__(self):\n            return tuple(self) \\n\\n''' % locals()\n    for i, name in enumerate(field_names):\n        template += '        %s = _property(_itemgetter(%d))\\n' % (name, i)\n    \n    if verbose:\n        print(template)\n\n    # Execute the template string in a temporary namespace\n    namespace = dict(_itemgetter=_itemgetter, __name__='namedtuple_%s' % typename,\n                     _property=property, _tuple=tuple)\n    try:\n        exec(template,namespace)\n    except SyntaxError as e:\n        raise SyntaxError(e.message + ':\\n' + template)\n    result = namespace[typename]\n\n    # For pickling to work, the __module__ variable needs to be set to the frame\n    # where the named tuple is created.  Bypass this step in enviroments where\n    # sys._getframe is not defined (Jython for example) or sys._getframe is not\n    # defined for arguments greater than 0 (IronPython).\n    try:\n        result.__module__ = _sys._getframe(1).f_globals.get('__name__', '__main__')\n    except (AttributeError, ValueError):\n        pass\n\n    return result\n\nif __name__ == '__main__':\n    Point = namedtuple('Point', ['x', 'y'])\n    p = Point(11, y=22)\n    print(p[0]+p[1])\n    x,y=p\n    print(x,y)\n    print(p.x+p.y)\n    print(p)\n"], "xml.dom": [".py", "\"\"\"W3C Document Object Model implementation for Python.\n\nThe Python mapping of the Document Object Model is documented in the\nPython Library Reference in the section on the xml.dom package.\n\nThis package contains the following modules:\n\nminidom -- A simple implementation of the Level 1 DOM with namespace\n           support added (based on the Level 2 specification) and other\n           minor Level 2 functionality.\n\npulldom -- DOM builder supporting on-demand tree-building for selected\n           subtrees of the document.\n\n\"\"\"\n\n\nclass Node:\n    \"\"\"Class giving the NodeType constants.\"\"\"\n    __slots__ = ()\n\n    # DOM implementations may use this as a base class for their own\n    # Node implementations.  If they don't, the constants defined here\n    # should still be used as the canonical definitions as they match\n    # the values given in the W3C recommendation.  Client code can\n    # safely refer to these values in all tests of Node.nodeType\n    # values.\n\n    ELEMENT_NODE                = 1\n    ATTRIBUTE_NODE              = 2\n    TEXT_NODE                   = 3\n    CDATA_SECTION_NODE          = 4\n    ENTITY_REFERENCE_NODE       = 5\n    ENTITY_NODE                 = 6\n    PROCESSING_INSTRUCTION_NODE = 7\n    COMMENT_NODE                = 8\n    DOCUMENT_NODE               = 9\n    DOCUMENT_TYPE_NODE          = 10\n    DOCUMENT_FRAGMENT_NODE      = 11\n    NOTATION_NODE               = 12\n\n\n#ExceptionCode\nINDEX_SIZE_ERR                 = 1\nDOMSTRING_SIZE_ERR             = 2\nHIERARCHY_REQUEST_ERR          = 3\nWRONG_DOCUMENT_ERR             = 4\nINVALID_CHARACTER_ERR          = 5\nNO_DATA_ALLOWED_ERR            = 6\nNO_MODIFICATION_ALLOWED_ERR    = 7\nNOT_FOUND_ERR                  = 8\nNOT_SUPPORTED_ERR              = 9\nINUSE_ATTRIBUTE_ERR            = 10\nINVALID_STATE_ERR              = 11\nSYNTAX_ERR                     = 12\nINVALID_MODIFICATION_ERR       = 13\nNAMESPACE_ERR                  = 14\nINVALID_ACCESS_ERR             = 15\nVALIDATION_ERR                 = 16\n\n\nclass DOMException(Exception):\n    \"\"\"Abstract base class for DOM exceptions.\n    Exceptions with specific codes are specializations of this class.\"\"\"\n\n    def __init__(self, *args, **kw):\n        if self.__class__ is DOMException:\n            raise RuntimeError(\n                \"DOMException should not be instantiated directly\")\n        Exception.__init__(self, *args, **kw)\n\n    def _get_code(self):\n        return self.code\n\n\nclass IndexSizeErr(DOMException):\n    code = INDEX_SIZE_ERR\n\nclass DomstringSizeErr(DOMException):\n    code = DOMSTRING_SIZE_ERR\n\nclass HierarchyRequestErr(DOMException):\n    code = HIERARCHY_REQUEST_ERR\n\nclass WrongDocumentErr(DOMException):\n    code = WRONG_DOCUMENT_ERR\n\nclass InvalidCharacterErr(DOMException):\n    code = INVALID_CHARACTER_ERR\n\nclass NoDataAllowedErr(DOMException):\n    code = NO_DATA_ALLOWED_ERR\n\nclass NoModificationAllowedErr(DOMException):\n    code = NO_MODIFICATION_ALLOWED_ERR\n\nclass NotFoundErr(DOMException):\n    code = NOT_FOUND_ERR\n\nclass NotSupportedErr(DOMException):\n    code = NOT_SUPPORTED_ERR\n\nclass InuseAttributeErr(DOMException):\n    code = INUSE_ATTRIBUTE_ERR\n\nclass InvalidStateErr(DOMException):\n    code = INVALID_STATE_ERR\n\nclass SyntaxErr(DOMException):\n    code = SYNTAX_ERR\n\nclass InvalidModificationErr(DOMException):\n    code = INVALID_MODIFICATION_ERR\n\nclass NamespaceErr(DOMException):\n    code = NAMESPACE_ERR\n\nclass InvalidAccessErr(DOMException):\n    code = INVALID_ACCESS_ERR\n\nclass ValidationErr(DOMException):\n    code = VALIDATION_ERR\n\nclass UserDataHandler:\n    \"\"\"Class giving the operation constants for UserDataHandler.handle().\"\"\"\n\n    # Based on DOM Level 3 (WD 9 April 2002)\n\n    NODE_CLONED   = 1\n    NODE_IMPORTED = 2\n    NODE_DELETED  = 3\n    NODE_RENAMED  = 4\n\nXML_NAMESPACE = \"http://www.w3.org/XML/1998/namespace\"\nXMLNS_NAMESPACE = \"http://www.w3.org/2000/xmlns/\"\nXHTML_NAMESPACE = \"http://www.w3.org/1999/xhtml\"\nEMPTY_NAMESPACE = None\nEMPTY_PREFIX = None\n\nfrom .domreg import getDOMImplementation, registerDOMImplementation\n", 1], "_sre": [".py", "# NOT_RPYTHON\n\"\"\"\nA pure Python reimplementation of the _sre module from CPython 2.4\nCopyright 2005 Nik Haldimann, licensed under the MIT license\n\nThis code is based on material licensed under CNRI's Python 1.6 license and\ncopyrighted by: Copyright (c) 1997-2001 by Secret Labs AB\n\"\"\"\n\nMAXREPEAT = 2147483648\n\n#import array\nimport operator, sys\nfrom sre_constants import ATCODES, OPCODES, CHCODES\nfrom sre_constants import SRE_INFO_PREFIX, SRE_INFO_LITERAL\nfrom sre_constants import SRE_FLAG_UNICODE, SRE_FLAG_LOCALE\n\n\nimport sys\n\n# Identifying as _sre from Python 2.3 or 2.4\n#if sys.version_info[:2] >= (2, 4):\nMAGIC = 20031017\n#else:\n#    MAGIC = 20030419\n\n# In _sre.c this is bytesize of the code word type of the C implementation.\n# There it's 2 for normal Python builds and more for wide unicode builds (large \n# enough to hold a 32-bit UCS-4 encoded character). Since here in pure Python\n# we only see re bytecodes as Python longs, we shouldn't have to care about the\n# codesize. But sre_compile will compile some stuff differently depending on the\n# codesize (e.g., charsets).\n# starting with python 3.3  CODESIZE is 4\n#if sys.maxunicode == 65535:\n#    CODESIZE = 2\n#else:\nCODESIZE = 4\n\ncopyright = \"_sre.py 2.4c Copyright 2005 by Nik Haldimann\"\n\n\ndef getcodesize():\n    return CODESIZE\n\ndef compile(pattern, flags, code, groups=0, groupindex={}, indexgroup=[None]):\n    \"\"\"Compiles (or rather just converts) a pattern descriptor to a SRE_Pattern\n    object. Actual compilation to opcodes happens in sre_compile.\"\"\"\n    return SRE_Pattern(pattern, flags, code, groups, groupindex, indexgroup)\n    \ndef getlower(char_ord, flags):\n    if (char_ord < 128) or (flags & SRE_FLAG_UNICODE) \\\n                              or (flags & SRE_FLAG_LOCALE and char_ord < 256):\n        #return ord(unichr(char_ord).lower())\n        return ord(chr(char_ord).lower())\n    else:\n        return char_ord\n\n\nclass SRE_Pattern:\n\n    def __init__(self, pattern, flags, code, groups=0, groupindex={}, indexgroup=[None]):\n        self.pattern = pattern\n        self.flags = flags\n        self.groups = groups\n        self.groupindex = groupindex # Maps group names to group indices\n        self._indexgroup = indexgroup # Maps indices to group names\n        self._code = code\n    \n    def match(self, string, pos=0, endpos=sys.maxsize):\n        \"\"\"If zero or more characters at the beginning of string match this\n        regular expression, return a corresponding MatchObject instance. Return\n        None if the string does not match the pattern.\"\"\"\n        state = _State(string, pos, endpos, self.flags)\n        if state.match(self._code):\n            return SRE_Match(self, state)\n        return None\n\n    def search(self, string, pos=0, endpos=sys.maxsize):\n        \"\"\"Scan through string looking for a location where this regular\n        expression produces a match, and return a corresponding MatchObject\n        instance. Return None if no position in the string matches the\n        pattern.\"\"\"\n        state = _State(string, pos, endpos, self.flags)\n        if state.search(self._code):\n            return SRE_Match(self, state)\n        else:\n            return None\n\n    def findall(self, string, pos=0, endpos=sys.maxsize):\n        \"\"\"Return a list of all non-overlapping matches of pattern in string.\"\"\"\n        matchlist = []\n        state = _State(string, pos, endpos, self.flags)\n        while state.start <= state.end:\n            state.reset()\n            state.string_position = state.start\n            if not state.search(self._code):\n                break\n            match = SRE_Match(self, state)\n            if self.groups == 0 or self.groups == 1:\n                item = match.group(self.groups)\n            else:\n                item = match.groups(\"\")\n            matchlist.append(item)\n            if state.string_position == state.start:\n                state.start += 1\n            else:\n                state.start = state.string_position\n        return matchlist        \n        \n    def _subx(self, template, string, count=0, subn=False):\n        filter = template\n        if not callable(template) and \"\\\\\" in template:\n            # handle non-literal strings ; hand it over to the template compiler\n            #import sre  #sre was renamed to re\n            #fix me brython\n            #print(\"possible issue at _sre.py line 116\")\n            import pyre as sre\n            filter = sre._subx(self, template)\n        state = _State(string, 0, sys.maxsize, self.flags)\n        sublist = []\n        \n        n = last_pos = 0\n        while not count or n < count:\n            state.reset()\n            state.string_position = state.start\n            if not state.search(self._code):\n                break\n            if last_pos < state.start:\n                sublist.append(string[last_pos:state.start])\n            if not (last_pos == state.start and\n                                last_pos == state.string_position and n > 0):\n                # the above ignores empty matches on latest position\n                if callable(filter):\n                    sublist.append(filter(SRE_Match(self, state)))\n                else:\n                    sublist.append(filter)\n                last_pos = state.string_position\n                n += 1\n            if state.string_position == state.start:\n                state.start += 1\n            else:\n                state.start = state.string_position\n\n        if last_pos < state.end:\n            sublist.append(string[last_pos:state.end])\n        item = \"\".join(sublist)\n        if subn:\n            return item, n\n        else:\n            return item\n\n    def sub(self, repl, string, count=0):\n        \"\"\"Return the string obtained by replacing the leftmost non-overlapping\n        occurrences of pattern in string by the replacement repl.\"\"\"\n        return self._subx(repl, string, count, False)\n\n    def subn(self, repl, string, count=0):\n        \"\"\"Return the tuple (new_string, number_of_subs_made) found by replacing\n        the leftmost non-overlapping occurrences of pattern with the replacement\n        repl.\"\"\"\n        return self._subx(repl, string, count, True)\n        \n    def split(self, string, maxsplit=0):\n        \"\"\"Split string by the occurrences of pattern.\"\"\"\n        splitlist = []\n        state = _State(string, 0, sys.maxsize, self.flags)\n        n = 0\n        last = state.start\n        while not maxsplit or n < maxsplit:\n            state.reset()\n            state.string_position = state.start\n            if not state.search(self._code):\n                break\n            if state.start == state.string_position: # zero-width match\n                if last == state.end:                # or end of string\n                    break\n                state.start += 1\n                continue\n            splitlist.append(string[last:state.start])\n            # add groups (if any)\n            if self.groups:\n                match = SRE_Match(self, state)\n                splitlist.extend(list(match.groups(None)))\n            n += 1\n            last = state.start = state.string_position\n        splitlist.append(string[last:state.end])\n        return splitlist\n\n    def finditer(self, string, pos=0, endpos=sys.maxsize):\n        \"\"\"Return a list of all non-overlapping matches of pattern in string.\"\"\"\n        #scanner = self.scanner(string, pos, endpos)\n        _list=[]\n        _m=self.scanner(string, pos, endpos)\n        _re=SRE_Scanner(self, string, pos, endpos)\n        _m=_re.search()\n        while _m:\n           _list.append(_m)\n           _m=_re.search()\n        return _list\n        #return iter(scanner.search, None)\n\n    def scanner(self, string, start=0, end=sys.maxsize):\n        return SRE_Scanner(self, string, start, end)\n    \n    def __copy__(self):\n        raise TypeError(\"cannot copy this pattern object\")\n\n    def __deepcopy__(self):\n        raise TypeError(\"cannot copy this pattern object\")\n\nclass SRE_Scanner:\n    \"\"\"Undocumented scanner interface of sre.\"\"\"\n    \n    def __init__(self, pattern, string, start, end):\n        self.pattern = pattern\n        self._state = _State(string, start, end, self.pattern.flags)\n\n    def _match_search(self, matcher):\n        state = self._state\n        state.reset()\n        state.string_position = state.start\n        match = None\n        if matcher(self.pattern._code):\n            match = SRE_Match(self.pattern, state)\n        if match is None or state.string_position == state.start:\n            state.start += 1\n        else:\n            state.start = state.string_position\n        return match\n\n    def match(self):\n        return self._match_search(self._state.match)\n\n    def search(self):\n        return self._match_search(self._state.search)\n\nclass SRE_Match:\n\n    def __init__(self, pattern, state):\n        self.re = pattern\n        self.string = state.string\n        self.pos = state.pos\n        self.endpos = state.end\n        self.lastindex = state.lastindex\n        if self.lastindex < 0:\n            self.lastindex = None\n        self.regs = self._create_regs(state)\n        \n        #statement below is not valid under python3 ( 0 <= None)\n        #if pattern._indexgroup and 0 <= self.lastindex < len(pattern._indexgroup):\n        if self.lastindex is not None and pattern._indexgroup and 0 <= self.lastindex < len(pattern._indexgroup):\n            # The above upper-bound check should not be necessary, as the re\n            # compiler is supposed to always provide an _indexgroup list long\n            # enough. But the re.Scanner class seems to screw up something\n            # there, test_scanner in test_re won't work without upper-bound\n            # checking. XXX investigate this and report bug to CPython.\n            self.lastgroup = pattern._indexgroup[self.lastindex]\n        else:\n            self.lastgroup = None\n\n    def _create_regs(self, state):\n        \"\"\"Creates a tuple of index pairs representing matched groups.\"\"\"\n        regs = [(state.start, state.string_position)]\n        for group in range(self.re.groups):\n            mark_index = 2 * group\n            if mark_index + 1 < len(state.marks) \\\n                                    and state.marks[mark_index] is not None \\\n                                    and state.marks[mark_index + 1] is not None:\n                regs.append((state.marks[mark_index], state.marks[mark_index + 1]))\n            else:\n                regs.append((-1, -1))\n        return tuple(regs)\n\n    def _get_index(self, group):\n        if isinstance(group, int):\n            if group >= 0 and group <= self.re.groups:\n                return group\n        else:\n            if group in self.re.groupindex:\n                return self.re.groupindex[group]\n        raise IndexError(\"no such group\")\n\n    def _get_slice(self, group, default):\n        group_indices = self.regs[group]\n        if group_indices[0] >= 0:\n            return self.string[group_indices[0]:group_indices[1]]\n        else:\n            return default\n\n    def start(self, group=0):\n        \"\"\"Returns the indices of the start of the substring matched by group;\n        group defaults to zero (meaning the whole matched substring). Returns -1\n        if group exists but did not contribute to the match.\"\"\"\n        return self.regs[self._get_index(group)][0]\n\n    def end(self, group=0):\n        \"\"\"Returns the indices of the end of the substring matched by group;\n        group defaults to zero (meaning the whole matched substring). Returns -1\n        if group exists but did not contribute to the match.\"\"\"\n        return self.regs[self._get_index(group)][1]\n\n    def span(self, group=0):\n        \"\"\"Returns the 2-tuple (m.start(group), m.end(group)).\"\"\"\n        return self.start(group), self.end(group)\n        \n    def expand(self, template):\n        \"\"\"Return the string obtained by doing backslash substitution and\n        resolving group references on template.\"\"\"\n        import sre\n        return sre._expand(self.re, self, template)\n        \n    def groups(self, default=None):\n        \"\"\"Returns a tuple containing all the subgroups of the match. The\n        default argument is used for groups that did not participate in the\n        match (defaults to None).\"\"\"\n        groups = []\n        for indices in self.regs[1:]:\n            if indices[0] >= 0:\n                groups.append(self.string[indices[0]:indices[1]])\n            else:\n                groups.append(default)\n        return tuple(groups)\n        \n    def groupdict(self, default=None):\n        \"\"\"Return a dictionary containing all the named subgroups of the match.\n        The default argument is used for groups that did not participate in the\n        match (defaults to None).\"\"\"\n        groupdict = {}\n        for key, value in self.re.groupindex.items():\n            groupdict[key] = self._get_slice(value, default)\n        return groupdict\n\n    def group(self, *args):\n        \"\"\"Returns one or more subgroups of the match. Each argument is either a\n        group index or a group name.\"\"\"\n        if len(args) == 0:\n            args = (0,)\n        grouplist = []\n        for group in args:\n            grouplist.append(self._get_slice(self._get_index(group), None))\n        if len(grouplist) == 1:\n            return grouplist[0]\n        else:\n            return tuple(grouplist)\n\n    def __copy__():\n        raise TypeError(\"cannot copy this pattern object\")\n\n    def __deepcopy__():\n        raise TypeError(\"cannot copy this pattern object\")\n\n\nclass _State:\n\n    def __init__(self, string, start, end, flags):\n        self.string = string\n        if start < 0:\n            start = 0\n        if end > len(string):\n            end = len(string)\n        self.start = start\n        self.string_position = self.start\n        self.end = end\n        self.pos = start\n        self.flags = flags\n        self.reset()\n\n    def reset(self):\n        self.marks = []\n        self.lastindex = -1\n        self.marks_stack = []\n        self.context_stack = []\n        self.repeat = None\n\n    def match(self, pattern_codes):\n        # Optimization: Check string length. pattern_codes[3] contains the\n        # minimum length for a string to possibly match.\n        # brython..  the optimization doesn't work \n        #if pattern_codes[0] == OPCODES[\"info\"] and pattern_codes[3]:\n        #    if self.end - self.string_position < pattern_codes[3]:\n        #        #_log(\"reject (got %d chars, need %d)\"\n        #        #         % (self.end - self.string_position, pattern_codes[3]))\n        #        return False\n        \n        dispatcher = _OpcodeDispatcher()\n        self.context_stack.append(_MatchContext(self, pattern_codes))\n        has_matched = None\n        while len(self.context_stack) > 0:\n            context = self.context_stack[-1]\n            has_matched = dispatcher.match(context)\n            if has_matched is not None: # don't pop if context isn't done\n                self.context_stack.pop()\n        return has_matched\n\n    def search(self, pattern_codes):\n        flags = 0\n        if pattern_codes[0] == OPCODES[\"info\"]:\n            # optimization info block\n            # <INFO> <1=skip> <2=flags> <3=min> <4=max> <5=prefix info>\n            if pattern_codes[2] & SRE_INFO_PREFIX and pattern_codes[5] > 1:\n                return self.fast_search(pattern_codes)\n            flags = pattern_codes[2]\n            pattern_codes = pattern_codes[pattern_codes[1] + 1:]\n\n        string_position = self.start\n        if pattern_codes[0] == OPCODES[\"literal\"]:\n            # Special case: Pattern starts with a literal character. This is\n            # used for short prefixes\n            character = pattern_codes[1]\n            while True:\n                while string_position < self.end \\\n                        and ord(self.string[string_position]) != character:\n                    string_position += 1\n                if string_position >= self.end:\n                    return False\n                self.start = string_position\n                string_position += 1\n                self.string_position = string_position\n                if flags & SRE_INFO_LITERAL:\n                    return True\n                if self.match(pattern_codes[2:]):\n                    return True\n            return False\n\n        # General case\n        while string_position <= self.end:\n            self.reset()\n            self.start = self.string_position = string_position\n            if self.match(pattern_codes):\n                return True\n            string_position += 1\n        return False\n\n    def fast_search(self, pattern_codes):\n        \"\"\"Skips forward in a string as fast as possible using information from\n        an optimization info block.\"\"\"\n        # pattern starts with a known prefix\n        # <5=length> <6=skip> <7=prefix data> <overlap data>\n        flags = pattern_codes[2]\n        prefix_len = pattern_codes[5]\n        prefix_skip = pattern_codes[6] # don't really know what this is good for\n        prefix = pattern_codes[7:7 + prefix_len]\n        overlap = pattern_codes[7 + prefix_len - 1:pattern_codes[1] + 1]\n        pattern_codes = pattern_codes[pattern_codes[1] + 1:]\n        i = 0\n        string_position = self.string_position\n        while string_position < self.end:\n            while True:\n                if ord(self.string[string_position]) != prefix[i]:\n                    if i == 0:\n                        break\n                    else:\n                        i = overlap[i]\n                else:\n                    i += 1\n                    if i == prefix_len:\n                        # found a potential match\n                        self.start = string_position + 1 - prefix_len\n                        self.string_position = string_position + 1 \\\n                                                     - prefix_len + prefix_skip\n                        if flags & SRE_INFO_LITERAL:\n                            return True # matched all of pure literal pattern\n                        if self.match(pattern_codes[2 * prefix_skip:]):\n                            return True\n                        i = overlap[i]\n                    break\n            string_position += 1\n        return False\n\n    def set_mark(self, mark_nr, position):\n        if mark_nr & 1:\n            # This id marks the end of a group.\n            # fix python 3 division incompatability\n            #self.lastindex = mark_nr / 2 + 1\n            self.lastindex = mark_nr // 2 + 1\n        if mark_nr >= len(self.marks):\n            self.marks.extend([None] * (mark_nr - len(self.marks) + 1))\n        self.marks[mark_nr] = position\n\n    def get_marks(self, group_index):\n        marks_index = 2 * group_index\n        if len(self.marks) > marks_index + 1:\n            return self.marks[marks_index], self.marks[marks_index + 1]\n        else:\n            return None, None\n\n    def marks_push(self):\n        self.marks_stack.append((self.marks[:], self.lastindex))\n\n    def marks_pop(self):\n        self.marks, self.lastindex = self.marks_stack.pop()\n\n    def marks_pop_keep(self):\n        self.marks, self.lastindex = self.marks_stack[-1]\n\n    def marks_pop_discard(self):\n        self.marks_stack.pop()\n\n    def lower(self, char_ord):\n        return getlower(char_ord, self.flags)\n\n\nclass _MatchContext:\n\n    def __init__(self, state, pattern_codes):\n        self.state = state\n        self.pattern_codes = pattern_codes\n        self.string_position = state.string_position\n        self.code_position = 0\n        self.has_matched = None\n\n    def push_new_context(self, pattern_offset):\n        \"\"\"Creates a new child context of this context and pushes it on the\n        stack. pattern_offset is the offset off the current code position to\n        start interpreting from.\"\"\"\n        child_context = _MatchContext(self.state,\n            self.pattern_codes[self.code_position + pattern_offset:])\n        #print(\"_sre.py:517:pushing new context\") #, child_context.has_matched)\n        #print(self.state.string_position)\n        #print(self.pattern_codes[self.code_position + pattern_offset:])\n        #print(pattern_offset)\n        self.state.context_stack.append(child_context)\n        return child_context\n\n    def peek_char(self, peek=0):\n        return self.state.string[self.string_position + peek]\n\n    def skip_char(self, skip_count):\n        self.string_position += skip_count\n\n    def remaining_chars(self):\n        return self.state.end - self.string_position\n\n    def peek_code(self, peek=0):\n        return self.pattern_codes[self.code_position + peek]\n\n    def skip_code(self, skip_count):\n        self.code_position += skip_count\n\n    def remaining_codes(self):\n        return len(self.pattern_codes) - self.code_position\n\n    def at_beginning(self):\n        return self.string_position == 0\n\n    def at_end(self):\n        return self.string_position == self.state.end\n\n    def at_linebreak(self):\n        return not self.at_end() and _is_linebreak(self.peek_char())\n\n    def at_boundary(self, word_checker):\n        if self.at_beginning() and self.at_end():\n            return False\n        that = not self.at_beginning() and word_checker(self.peek_char(-1))\n        this = not self.at_end() and word_checker(self.peek_char())\n        return this != that\n\n\nclass _RepeatContext(_MatchContext):\n    \n    def __init__(self, context):\n        _MatchContext.__init__(self, context.state,\n                            context.pattern_codes[context.code_position:])\n        self.count = -1\n        #print('569:repeat', context.state.repeat)\n        self.previous = context.state.repeat\n        self.last_position = None\n\n\nclass _Dispatcher:\n\n    DISPATCH_TABLE = None\n\n    def dispatch(self, code, context):\n        method = self.DISPATCH_TABLE.get(code, self.__class__.unknown)\n        return method(self, context)\n\n    def unknown(self, code, ctx):\n        raise NotImplementedError()\n\n    def build_dispatch_table(cls, code_dict, method_prefix):\n        if cls.DISPATCH_TABLE is not None:\n            return\n        table = {}\n        for key, value in code_dict.items():\n            if hasattr(cls, \"%s%s\" % (method_prefix, key)):\n                table[value] = getattr(cls, \"%s%s\" % (method_prefix, key))\n        cls.DISPATCH_TABLE = table\n\n    build_dispatch_table = classmethod(build_dispatch_table)\n\n\nclass _OpcodeDispatcher(_Dispatcher):\n    \n    def __init__(self):\n        self.executing_contexts = {}\n        self.at_dispatcher = _AtcodeDispatcher()\n        self.ch_dispatcher = _ChcodeDispatcher()\n        self.set_dispatcher = _CharsetDispatcher()\n        \n    def match(self, context):\n        \"\"\"Returns True if the current context matches, False if it doesn't and\n        None if matching is not finished, ie must be resumed after child\n        contexts have been matched.\"\"\"\n        while context.remaining_codes() > 0 and context.has_matched is None:\n            opcode = context.peek_code()\n            if not self.dispatch(opcode, context):\n                return None\n        if context.has_matched is None:\n            context.has_matched = False\n        return context.has_matched\n\n    def dispatch(self, opcode, context):\n        \"\"\"Dispatches a context on a given opcode. Returns True if the context\n        is done matching, False if it must be resumed when next encountered.\"\"\"\n        #if self.executing_contexts.has_key(id(context)):\n        if id(context) in self.executing_contexts:\n            generator = self.executing_contexts[id(context)]\n            del self.executing_contexts[id(context)]\n            has_finished = next(generator)\n        else:\n            method = self.DISPATCH_TABLE.get(opcode, _OpcodeDispatcher.unknown)\n            has_finished = method(self, context)\n            if hasattr(has_finished, \"__next__\"): # avoid using the types module\n                generator = has_finished\n                has_finished = next(generator)\n        if not has_finished:\n            self.executing_contexts[id(context)] = generator\n        return has_finished\n\n    def op_success(self, ctx):\n        # end of pattern\n        #self._log(ctx, \"SUCCESS\")\n        ctx.state.string_position = ctx.string_position\n        ctx.has_matched = True\n        return True\n\n    def op_failure(self, ctx):\n        # immediate failure\n        #self._log(ctx, \"FAILURE\")\n        ctx.has_matched = False\n        return True\n\n    def general_op_literal(self, ctx, compare, decorate=lambda x: x):\n        #print(ctx.peek_char())\n        if ctx.at_end() or not compare(decorate(ord(ctx.peek_char())),\n                                            decorate(ctx.peek_code(1))):\n            ctx.has_matched = False\n        ctx.skip_code(2)\n        ctx.skip_char(1)\n\n    def op_literal(self, ctx):\n        # match literal string\n        # <LITERAL> <code>\n        #self._log(ctx, \"LITERAL\", ctx.peek_code(1))\n        self.general_op_literal(ctx, operator.eq)\n        return True\n\n    def op_not_literal(self, ctx):\n        # match anything that is not the given literal character\n        # <NOT_LITERAL> <code>\n        #self._log(ctx, \"NOT_LITERAL\", ctx.peek_code(1))\n        self.general_op_literal(ctx, operator.ne)\n        return True\n\n    def op_literal_ignore(self, ctx):\n        # match literal regardless of case\n        # <LITERAL_IGNORE> <code>\n        #self._log(ctx, \"LITERAL_IGNORE\", ctx.peek_code(1))\n        self.general_op_literal(ctx, operator.eq, ctx.state.lower)\n        return True\n\n    def op_not_literal_ignore(self, ctx):\n        # match literal regardless of case\n        # <LITERAL_IGNORE> <code>\n        #self._log(ctx, \"LITERAL_IGNORE\", ctx.peek_code(1))\n        self.general_op_literal(ctx, operator.ne, ctx.state.lower)\n        return True\n\n    def op_at(self, ctx):\n        # match at given position\n        # <AT> <code>\n        #self._log(ctx, \"AT\", ctx.peek_code(1))\n        if not self.at_dispatcher.dispatch(ctx.peek_code(1), ctx):\n            ctx.has_matched = False\n            #print('_sre.py:line693, update context.has_matched variable')\n            return True\n        ctx.skip_code(2)\n        return True\n\n    def op_category(self, ctx):\n        # match at given category\n        # <CATEGORY> <code>\n        #self._log(ctx, \"CATEGORY\", ctx.peek_code(1))\n        if ctx.at_end() or not self.ch_dispatcher.dispatch(ctx.peek_code(1), ctx):\n            ctx.has_matched = False\n            #print('_sre.py:line703, update context.has_matched variable')\n            return True\n        ctx.skip_code(2)\n        ctx.skip_char(1)\n        return True\n\n    def op_any(self, ctx):\n        # match anything (except a newline)\n        # <ANY>\n        #self._log(ctx, \"ANY\")\n        if ctx.at_end() or ctx.at_linebreak():\n            ctx.has_matched = False\n            #print('_sre.py:line714, update context.has_matched variable')\n            return True\n        ctx.skip_code(1)\n        ctx.skip_char(1)\n        return True\n\n    def op_any_all(self, ctx):\n        # match anything\n        # <ANY_ALL>\n        #self._log(ctx, \"ANY_ALL\")\n        if ctx.at_end():\n            ctx.has_matched = False\n            #print('_sre.py:line725, update context.has_matched variable')\n            return True\n        ctx.skip_code(1)\n        ctx.skip_char(1)\n        return True\n\n    def general_op_in(self, ctx, decorate=lambda x: x):\n        #self._log(ctx, \"OP_IN\")\n        #print('general_op_in')\n        if ctx.at_end():\n            ctx.has_matched = False\n            #print('_sre.py:line734, update context.has_matched variable')\n            return\n        skip = ctx.peek_code(1)\n        ctx.skip_code(2) # set op pointer to the set code\n        #print(ctx.peek_char(), ord(ctx.peek_char()), \n        #      decorate(ord(ctx.peek_char())))\n        if not self.check_charset(ctx, decorate(ord(ctx.peek_char()))):\n            #print('_sre.py:line738, update context.has_matched variable')\n            ctx.has_matched = False\n            return\n        ctx.skip_code(skip - 1)\n        ctx.skip_char(1)\n        #print('end:general_op_in')\n\n    def op_in(self, ctx):\n        # match set member (or non_member)\n        # <IN> <skip> <set>\n        #self._log(ctx, \"OP_IN\")\n        self.general_op_in(ctx)\n        return True\n\n    def op_in_ignore(self, ctx):\n        # match set member (or non_member), disregarding case of current char\n        # <IN_IGNORE> <skip> <set>\n        #self._log(ctx, \"OP_IN_IGNORE\")\n        self.general_op_in(ctx, ctx.state.lower)\n        return True\n\n    def op_jump(self, ctx):\n        # jump forward\n        # <JUMP> <offset>\n        #self._log(ctx, \"JUMP\", ctx.peek_code(1))\n        ctx.skip_code(ctx.peek_code(1) + 1)\n        return True\n\n    # skip info\n    # <INFO> <skip>\n    op_info = op_jump\n\n    def op_mark(self, ctx):\n        # set mark\n        # <MARK> <gid>\n        #self._log(ctx, \"OP_MARK\", ctx.peek_code(1))\n        ctx.state.set_mark(ctx.peek_code(1), ctx.string_position)\n        ctx.skip_code(2)\n        return True\n\n    def op_branch(self, ctx):\n        # alternation\n        # <BRANCH> <0=skip> code <JUMP> ... <NULL>\n        #self._log(ctx, \"BRANCH\")\n        ctx.state.marks_push()\n        ctx.skip_code(1)\n        current_branch_length = ctx.peek_code(0)\n        while current_branch_length:\n            # The following tries to shortcut branches starting with a\n            # (unmatched) literal. _sre.c also shortcuts charsets here.\n            if not (ctx.peek_code(1) == OPCODES[\"literal\"] and \\\n                    (ctx.at_end() or ctx.peek_code(2) != ord(ctx.peek_char()))):\n                ctx.state.string_position = ctx.string_position\n                child_context = ctx.push_new_context(1)\n                #print(\"_sre.py:803:op_branch\")\n                yield False\n                if child_context.has_matched:\n                    ctx.has_matched = True\n                    yield True\n                ctx.state.marks_pop_keep()\n            ctx.skip_code(current_branch_length)\n            current_branch_length = ctx.peek_code(0)\n        ctx.state.marks_pop_discard()\n        ctx.has_matched = False\n        #print('_sre.py:line805, update context.has_matched variable')\n        yield True\n\n    def op_repeat_one(self, ctx):\n        # match repeated sequence (maximizing).\n        # this operator only works if the repeated item is exactly one character\n        # wide, and we're not already collecting backtracking points.\n        # <REPEAT_ONE> <skip> <1=min> <2=max> item <SUCCESS> tail\n        mincount = ctx.peek_code(2)\n        maxcount = ctx.peek_code(3)\n        #print(\"repeat one\", mincount, maxcount)\n        #self._log(ctx, \"REPEAT_ONE\", mincount, maxcount)\n\n        if ctx.remaining_chars() < mincount:\n            ctx.has_matched = False\n            yield True\n        ctx.state.string_position = ctx.string_position\n        count = self.count_repetitions(ctx, maxcount)\n        ctx.skip_char(count)\n        if count < mincount:\n            ctx.has_matched = False\n            yield True\n        if ctx.peek_code(ctx.peek_code(1) + 1) == OPCODES[\"success\"]:\n            # tail is empty.  we're finished\n            ctx.state.string_position = ctx.string_position\n            ctx.has_matched = True\n            yield True\n\n        ctx.state.marks_push()\n        if ctx.peek_code(ctx.peek_code(1) + 1) == OPCODES[\"literal\"]:\n            # Special case: Tail starts with a literal. Skip positions where\n            # the rest of the pattern cannot possibly match.\n            char = ctx.peek_code(ctx.peek_code(1) + 2)\n            while True:\n                while count >= mincount and \\\n                                (ctx.at_end() or ord(ctx.peek_char()) != char):\n                    ctx.skip_char(-1)\n                    count -= 1\n                if count < mincount:\n                    break\n                ctx.state.string_position = ctx.string_position\n                child_context = ctx.push_new_context(ctx.peek_code(1) + 1)\n                #print(\"_sre.py:856:push_new_context\")\n                yield False\n                if child_context.has_matched:\n                    ctx.has_matched = True\n                    yield True\n                ctx.skip_char(-1)\n                count -= 1\n                ctx.state.marks_pop_keep()\n        \n        else:\n            # General case: backtracking\n            while count >= mincount:\n                ctx.state.string_position = ctx.string_position\n                child_context = ctx.push_new_context(ctx.peek_code(1) + 1)\n                yield False\n                if child_context.has_matched:\n                    ctx.has_matched = True\n                    yield True\n                ctx.skip_char(-1)\n                count -= 1\n                ctx.state.marks_pop_keep()\n\n        ctx.state.marks_pop_discard()\n        ctx.has_matched = False\n        #ctx.has_matched = True      # <== this should be True (so match object gets returned to program)\n        yield True\n\n    def op_min_repeat_one(self, ctx):\n        # match repeated sequence (minimizing)\n        # <MIN_REPEAT_ONE> <skip> <1=min> <2=max> item <SUCCESS> tail\n        mincount = ctx.peek_code(2)\n        maxcount = ctx.peek_code(3)\n        #self._log(ctx, \"MIN_REPEAT_ONE\", mincount, maxcount)\n\n        if ctx.remaining_chars() < mincount:\n            ctx.has_matched = False\n            yield True\n        ctx.state.string_position = ctx.string_position\n        if mincount == 0:\n            count = 0\n        else:\n            count = self.count_repetitions(ctx, mincount)\n            if count < mincount:\n                ctx.has_matched = False\n                #print('_sre.py:line891, update context.has_matched variable')\n                yield True\n            ctx.skip_char(count)\n        if ctx.peek_code(ctx.peek_code(1) + 1) == OPCODES[\"success\"]:\n            # tail is empty.  we're finished\n            ctx.state.string_position = ctx.string_position\n            ctx.has_matched = True\n            yield True\n\n        ctx.state.marks_push()\n        while maxcount == MAXREPEAT or count <= maxcount:\n            ctx.state.string_position = ctx.string_position\n            child_context = ctx.push_new_context(ctx.peek_code(1) + 1)\n            #print('_sre.py:916:push new context')\n            yield False\n            if child_context.has_matched:\n                ctx.has_matched = True\n                yield True\n            ctx.state.string_position = ctx.string_position\n            if self.count_repetitions(ctx, 1) == 0:\n                break\n            ctx.skip_char(1)\n            count += 1\n            ctx.state.marks_pop_keep()\n\n        ctx.state.marks_pop_discard()\n        ctx.has_matched = False\n        yield True\n\n    def op_repeat(self, ctx):\n        # create repeat context.  all the hard work is done by the UNTIL\n        # operator (MAX_UNTIL, MIN_UNTIL)\n        # <REPEAT> <skip> <1=min> <2=max> item <UNTIL> tail\n        #self._log(ctx, \"REPEAT\", ctx.peek_code(2), ctx.peek_code(3))\n\n        #if ctx.state.repeat is None:\n        #   print(\"951:ctx.state.repeat is None\")\n        #   #ctx.state.repeat=_RepeatContext(ctx)\n\n        repeat = _RepeatContext(ctx)\n        ctx.state.repeat = repeat\n        ctx.state.string_position = ctx.string_position\n        child_context = ctx.push_new_context(ctx.peek_code(1) + 1)\n        #print(\"_sre.py:941:push new context\", id(child_context))\n        #print(child_context.state.repeat)\n        #print(ctx.state.repeat)\n        # are these two yields causing the issue?\n        yield False\n        ctx.state.repeat = repeat.previous\n        ctx.has_matched = child_context.has_matched\n        yield True\n\n    def op_max_until(self, ctx):\n        # maximizing repeat\n        # <REPEAT> <skip> <1=min> <2=max> item <MAX_UNTIL> tail\n        repeat = ctx.state.repeat\n        #print(\"op_max_until\") #, id(ctx.state.repeat))\n        if repeat is None:\n            #print(id(ctx), id(ctx.state))\n            raise RuntimeError(\"Internal re error: MAX_UNTIL without REPEAT.\")\n        mincount = repeat.peek_code(2)\n        maxcount = repeat.peek_code(3)\n        ctx.state.string_position = ctx.string_position\n        count = repeat.count + 1\n        #self._log(ctx, \"MAX_UNTIL\", count)\n\n        if count < mincount:\n            # not enough matches\n            repeat.count = count\n            child_context = repeat.push_new_context(4)\n            yield False\n            ctx.has_matched = child_context.has_matched\n            if not ctx.has_matched:\n                repeat.count = count - 1\n                ctx.state.string_position = ctx.string_position\n            yield True\n\n        if (count < maxcount or maxcount == MAXREPEAT) \\\n                      and ctx.state.string_position != repeat.last_position:\n            # we may have enough matches, if we can match another item, do so\n            repeat.count = count\n            ctx.state.marks_push()\n            save_last_position = repeat.last_position # zero-width match protection\n            repeat.last_position = ctx.state.string_position\n            child_context = repeat.push_new_context(4)\n            yield False\n            repeat.last_position = save_last_position\n            if child_context.has_matched:\n                ctx.state.marks_pop_discard()\n                ctx.has_matched = True\n                yield True\n            ctx.state.marks_pop()\n            repeat.count = count - 1\n            ctx.state.string_position = ctx.string_position\n\n        # cannot match more repeated items here.  make sure the tail matches\n        ctx.state.repeat = repeat.previous\n        child_context = ctx.push_new_context(1)\n        #print(\"_sre.py:987:op_max_until\")\n        yield False\n        ctx.has_matched = child_context.has_matched\n        if not ctx.has_matched:\n            ctx.state.repeat = repeat\n            ctx.state.string_position = ctx.string_position\n        yield True\n\n    def op_min_until(self, ctx):\n        # minimizing repeat\n        # <REPEAT> <skip> <1=min> <2=max> item <MIN_UNTIL> tail\n        repeat = ctx.state.repeat\n        if repeat is None:\n            raise RuntimeError(\"Internal re error: MIN_UNTIL without REPEAT.\")\n        mincount = repeat.peek_code(2)\n        maxcount = repeat.peek_code(3)\n        ctx.state.string_position = ctx.string_position\n        count = repeat.count + 1\n        #self._log(ctx, \"MIN_UNTIL\", count)\n\n        if count < mincount:\n            # not enough matches\n            repeat.count = count\n            child_context = repeat.push_new_context(4)\n            yield False\n            ctx.has_matched = child_context.has_matched\n            if not ctx.has_matched:\n                repeat.count = count - 1\n                ctx.state.string_position = ctx.string_position\n            yield True\n\n        # see if the tail matches\n        ctx.state.marks_push()\n        ctx.state.repeat = repeat.previous\n        child_context = ctx.push_new_context(1)\n        #print('_sre.py:1022:push new context')\n        yield False\n        if child_context.has_matched:\n            ctx.has_matched = True\n            yield True\n        ctx.state.repeat = repeat\n        ctx.state.string_position = ctx.string_position\n        ctx.state.marks_pop()\n\n        # match more until tail matches\n        if count >= maxcount and maxcount != MAXREPEAT:\n            ctx.has_matched = False\n            #print('_sre.py:line1022, update context.has_matched variable')\n            yield True\n        repeat.count = count\n        child_context = repeat.push_new_context(4)\n        yield False\n        ctx.has_matched = child_context.has_matched\n        if not ctx.has_matched:\n            repeat.count = count - 1\n            ctx.state.string_position = ctx.string_position\n        yield True\n\n    def general_op_groupref(self, ctx, decorate=lambda x: x):\n        group_start, group_end = ctx.state.get_marks(ctx.peek_code(1))\n        if group_start is None or group_end is None or group_end < group_start:\n            ctx.has_matched = False\n            return True\n        while group_start < group_end:\n            if ctx.at_end() or decorate(ord(ctx.peek_char())) \\\n                                != decorate(ord(ctx.state.string[group_start])):\n                ctx.has_matched = False\n                #print('_sre.py:line1042, update context.has_matched variable')\n                return True\n            group_start += 1\n            ctx.skip_char(1)\n        ctx.skip_code(2)\n        return True\n\n    def op_groupref(self, ctx):\n        # match backreference\n        # <GROUPREF> <zero-based group index>\n        #self._log(ctx, \"GROUPREF\", ctx.peek_code(1))\n        return self.general_op_groupref(ctx)\n\n    def op_groupref_ignore(self, ctx):\n        # match backreference case-insensitive\n        # <GROUPREF_IGNORE> <zero-based group index>\n        #self._log(ctx, \"GROUPREF_IGNORE\", ctx.peek_code(1))\n        return self.general_op_groupref(ctx, ctx.state.lower)\n\n    def op_groupref_exists(self, ctx):\n        # <GROUPREF_EXISTS> <group> <skip> codeyes <JUMP> codeno ...\n        #self._log(ctx, \"GROUPREF_EXISTS\", ctx.peek_code(1))\n        group_start, group_end = ctx.state.get_marks(ctx.peek_code(1))\n        if group_start is None or group_end is None or group_end < group_start:\n            ctx.skip_code(ctx.peek_code(2) + 1)\n        else:\n            ctx.skip_code(3)\n        return True\n\n    def op_assert(self, ctx):\n        # assert subpattern\n        # <ASSERT> <skip> <back> <pattern>\n        #self._log(ctx, \"ASSERT\", ctx.peek_code(2))\n        ctx.state.string_position = ctx.string_position - ctx.peek_code(2)\n        if ctx.state.string_position < 0:\n            ctx.has_matched = False\n            yield True\n        child_context = ctx.push_new_context(3)\n        yield False\n        if child_context.has_matched:\n            ctx.skip_code(ctx.peek_code(1) + 1)\n        else:\n            ctx.has_matched = False\n        yield True\n\n    def op_assert_not(self, ctx):\n        # assert not subpattern\n        # <ASSERT_NOT> <skip> <back> <pattern>\n        #self._log(ctx, \"ASSERT_NOT\", ctx.peek_code(2))\n        ctx.state.string_position = ctx.string_position - ctx.peek_code(2)\n        if ctx.state.string_position >= 0:\n            child_context = ctx.push_new_context(3)\n            yield False\n            if child_context.has_matched:\n                ctx.has_matched = False\n                yield True\n        ctx.skip_code(ctx.peek_code(1) + 1)\n        yield True\n        \n    def unknown(self, ctx):\n        #self._log(ctx, \"UNKNOWN\", ctx.peek_code())\n        raise RuntimeError(\"Internal re error. Unknown opcode: %s\" % ctx.peek_code())\n                \n    def check_charset(self, ctx, char):\n        \"\"\"Checks whether a character matches set of arbitrary length. Assumes\n        the code pointer is at the first member of the set.\"\"\"\n        self.set_dispatcher.reset(char)\n        save_position = ctx.code_position\n        result = None\n        while result is None:\n            result = self.set_dispatcher.dispatch(ctx.peek_code(), ctx)\n        ctx.code_position = save_position\n        #print(\"_sre.py:1123:check_charset\", result)\n        return result\n\n    def count_repetitions(self, ctx, maxcount):\n        \"\"\"Returns the number of repetitions of a single item, starting from the\n        current string position. The code pointer is expected to point to a\n        REPEAT_ONE operation (with the repeated 4 ahead).\"\"\"\n        count = 0\n        real_maxcount = ctx.state.end - ctx.string_position\n        if maxcount < real_maxcount and maxcount != MAXREPEAT:\n            real_maxcount = maxcount\n        # XXX could special case every single character pattern here, as in C.\n        # This is a general solution, a bit hackisch, but works and should be\n        # efficient.\n        code_position = ctx.code_position\n        string_position = ctx.string_position\n        ctx.skip_code(4)\n        reset_position = ctx.code_position\n        while count < real_maxcount:\n            # this works because the single character pattern is followed by\n            # a success opcode\n            ctx.code_position = reset_position\n            self.dispatch(ctx.peek_code(), ctx)\n            #print(\"count_repetitions\", ctx.has_matched, count)\n            if ctx.has_matched is False: # could be None as well\n                break\n            count += 1\n        ctx.has_matched = None\n        ctx.code_position = code_position\n        ctx.string_position = string_position\n        return count\n\n    def _log(self, context, opname, *args):\n        arg_string = (\"%s \" * len(args)) % args\n        _log(\"|%s|%s|%s %s\" % (context.pattern_codes,\n            context.string_position, opname, arg_string))\n\n_OpcodeDispatcher.build_dispatch_table(OPCODES, \"op_\")\n\n\nclass _CharsetDispatcher(_Dispatcher):\n\n    def __init__(self):\n        self.ch_dispatcher = _ChcodeDispatcher()\n\n    def reset(self, char):\n        self.char = char\n        self.ok = True\n\n    def set_failure(self, ctx):\n        return not self.ok\n    def set_literal(self, ctx):\n        # <LITERAL> <code>\n        if ctx.peek_code(1) == self.char:\n            return self.ok\n        else:\n            ctx.skip_code(2)\n    def set_category(self, ctx):\n        # <CATEGORY> <code>\n        if self.ch_dispatcher.dispatch(ctx.peek_code(1), ctx):\n            return self.ok\n        else:\n            ctx.skip_code(2)\n    def set_charset(self, ctx):\n        # <CHARSET> <bitmap> (16 bits per code word)\n        char_code = self.char\n        ctx.skip_code(1) # point to beginning of bitmap\n        if CODESIZE == 2:\n            if char_code < 256 and ctx.peek_code(char_code >> 4) \\\n                                            & (1 << (char_code & 15)):\n                return self.ok\n            ctx.skip_code(16) # skip bitmap\n        else:\n            if char_code < 256 and ctx.peek_code(char_code >> 5) \\\n                                            & (1 << (char_code & 31)):\n                return self.ok\n            ctx.skip_code(8) # skip bitmap\n    def set_range(self, ctx):\n        # <RANGE> <lower> <upper>\n        if ctx.peek_code(1) <= self.char <= ctx.peek_code(2):\n            return self.ok\n        ctx.skip_code(3)\n    def set_negate(self, ctx):\n        self.ok = not self.ok\n        ctx.skip_code(1)\n    \n    #fixme brython.   array module doesn't exist\n    def set_bigcharset(self, ctx):\n        raise NotImplementationError(\"_sre.py: set_bigcharset, array not implemented\")\n        # <BIGCHARSET> <blockcount> <256 blockindices> <blocks>\n        char_code = self.char\n        count = ctx.peek_code(1)\n        ctx.skip_code(2)\n        if char_code < 65536:\n            block_index = char_code >> 8\n            # NB: there are CODESIZE block indices per bytecode\n            a = array.array(\"B\")\n            a.fromstring(array.array(CODESIZE == 2 and \"H\" or \"I\",\n                    [ctx.peek_code(block_index // CODESIZE)]).tostring())\n            block = a[block_index % CODESIZE]\n            ctx.skip_code(256 // CODESIZE) # skip block indices\n            block_value = ctx.peek_code(block * (32 // CODESIZE)\n                    + ((char_code & 255) >> (CODESIZE == 2 and 4 or 5)))\n            if block_value & (1 << (char_code & ((8 * CODESIZE) - 1))):\n                return self.ok\n        else:\n            ctx.skip_code(256 // CODESIZE) # skip block indices\n        ctx.skip_code(count * (32 // CODESIZE)) # skip blocks\n    \n    def unknown(self, ctx):\n        return False\n\n_CharsetDispatcher.build_dispatch_table(OPCODES, \"set_\")\n\n\nclass _AtcodeDispatcher(_Dispatcher):\n\n    def at_beginning(self, ctx):\n        return ctx.at_beginning()\n    at_beginning_string = at_beginning\n    def at_beginning_line(self, ctx):\n        return ctx.at_beginning() or _is_linebreak(ctx.peek_char(-1))\n    def at_end(self, ctx):\n        return (ctx.remaining_chars() == 1 and ctx.at_linebreak()) or ctx.at_end()\n    def at_end_line(self, ctx):\n        return ctx.at_linebreak() or ctx.at_end()\n    def at_end_string(self, ctx):\n        return ctx.at_end()\n    def at_boundary(self, ctx):\n        return ctx.at_boundary(_is_word)\n    def at_non_boundary(self, ctx):\n        return not ctx.at_boundary(_is_word)\n    def at_loc_boundary(self, ctx):\n        return ctx.at_boundary(_is_loc_word)\n    def at_loc_non_boundary(self, ctx):\n        return not ctx.at_boundary(_is_loc_word)\n    def at_uni_boundary(self, ctx):\n        return ctx.at_boundary(_is_uni_word)\n    def at_uni_non_boundary(self, ctx):\n        return not ctx.at_boundary(_is_uni_word)\n    def unknown(self, ctx):\n        return False\n\n_AtcodeDispatcher.build_dispatch_table(ATCODES, \"\")\n\n\nclass _ChcodeDispatcher(_Dispatcher):\n\n    def category_digit(self, ctx):\n        return _is_digit(ctx.peek_char())\n    def category_not_digit(self, ctx):\n        return not _is_digit(ctx.peek_char())\n    def category_space(self, ctx):\n        return _is_space(ctx.peek_char())\n    def category_not_space(self, ctx):\n        return not _is_space(ctx.peek_char())\n    def category_word(self, ctx):\n        return _is_word(ctx.peek_char())\n    def category_not_word(self, ctx):\n        return not _is_word(ctx.peek_char())\n    def category_linebreak(self, ctx):\n        return _is_linebreak(ctx.peek_char())\n    def category_not_linebreak(self, ctx):\n        return not _is_linebreak(ctx.peek_char())\n    def category_loc_word(self, ctx):\n        return _is_loc_word(ctx.peek_char())\n    def category_loc_not_word(self, ctx):\n        return not _is_loc_word(ctx.peek_char())\n    def category_uni_digit(self, ctx):\n        return ctx.peek_char().isdigit()\n    def category_uni_not_digit(self, ctx):\n        return not ctx.peek_char().isdigit()\n    def category_uni_space(self, ctx):\n        return ctx.peek_char().isspace()\n    def category_uni_not_space(self, ctx):\n        return not ctx.peek_char().isspace()\n    def category_uni_word(self, ctx):\n        return _is_uni_word(ctx.peek_char())\n    def category_uni_not_word(self, ctx):\n        return not _is_uni_word(ctx.peek_char())\n    def category_uni_linebreak(self, ctx):\n        return ord(ctx.peek_char()) in _uni_linebreaks\n    def category_uni_not_linebreak(self, ctx):\n        return ord(ctx.peek_char()) not in _uni_linebreaks\n    def unknown(self, ctx):\n        return False\n\n_ChcodeDispatcher.build_dispatch_table(CHCODES, \"\")\n\n\n_ascii_char_info = [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 2,\n2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 25, 25, 25, 25, 25, 25, 25,\n25, 25, 0, 0, 0, 0, 0, 0, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 0, 0,\n0, 0, 16, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 0, 0, 0, 0, 0 ]\n\ndef _is_digit(char):\n    code = ord(char)\n    return code < 128 and _ascii_char_info[code] & 1\n\ndef _is_space(char):\n    code = ord(char)\n    return code < 128 and _ascii_char_info[code] & 2\n\ndef _is_word(char):\n    # NB: non-ASCII chars aren't words according to _sre.c\n    code = ord(char)\n    return code < 128 and _ascii_char_info[code] & 16\n\ndef _is_loc_word(char):\n    return (not (ord(char) & ~255) and char.isalnum()) or char == '_'\n\ndef _is_uni_word(char):\n    # not valid in python 3\n    #return unichr(ord(char)).isalnum() or char == '_'\n    return chr(ord(char)).isalnum() or char == '_'\n\ndef _is_linebreak(char):\n    return char == \"\\n\"\n\n# Static list of all unicode codepoints reported by Py_UNICODE_ISLINEBREAK.\n_uni_linebreaks = [10, 13, 28, 29, 30, 133, 8232, 8233]\n\ndef _log(message):\n    if 0:\n        print(message)\n"], "unittest": [".py", "\"\"\"\nPython unit testing framework, based on Erich Gamma's JUnit and Kent Beck's\nSmalltalk testing framework.\n\nThis module contains the core framework classes that form the basis of\nspecific test cases and suites (TestCase, TestSuite etc.), and also a\ntext-based utility class for running the tests and reporting the results\n (TextTestRunner).\n\nSimple usage:\n\n    import unittest\n\n    class IntegerArithmeticTestCase(unittest.TestCase):\n        def testAdd(self):  ## test method names begin 'test*'\n            self.assertEqual((1 + 2), 3)\n            self.assertEqual(0 + 1, 1)\n        def testMultiply(self):\n            self.assertEqual((0 * 10), 0)\n            self.assertEqual((5 * 8), 40)\n\n    if __name__ == '__main__':\n        unittest.main()\n\nFurther information is available in the bundled documentation, and from\n\n  http://docs.python.org/library/unittest.html\n\nCopyright (c) 1999-2003 Steve Purcell\nCopyright (c) 2003-2010 Python Software Foundation\nThis module is free software, and you may redistribute it and/or modify\nit under the same terms as Python itself, so long as this copyright message\nand disclaimer are retained in their original form.\n\nIN NO EVENT SHALL THE AUTHOR BE LIABLE TO ANY PARTY FOR DIRECT, INDIRECT,\nSPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OF\nTHIS CODE, EVEN IF THE AUTHOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH\nDAMAGE.\n\nTHE AUTHOR SPECIFICALLY DISCLAIMS ANY WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE.  THE CODE PROVIDED HEREUNDER IS ON AN \"AS IS\" BASIS,\nAND THERE IS NO OBLIGATION WHATSOEVER TO PROVIDE MAINTENANCE,\nSUPPORT, UPDATES, ENHANCEMENTS, OR MODIFICATIONS.\n\"\"\"\n\n__all__ = ['TestResult', 'TestCase', 'TestSuite',\n           'TextTestRunner', 'TestLoader', 'FunctionTestCase', 'main',\n           'defaultTestLoader', 'SkipTest', 'skip', 'skipIf', 'skipUnless',\n           'expectedFailure', 'TextTestResult', 'installHandler',\n           'registerResult', 'removeResult', 'removeHandler']\n\n# Expose obsolete functions for backwards compatibility\n__all__.extend(['getTestCaseNames', 'makeSuite', 'findTestCases'])\n\n__unittest = True\n\nfrom .result import TestResult\nfrom .case import (TestCase, FunctionTestCase, SkipTest, skip, skipIf,\n                   skipUnless, expectedFailure)\nfrom .suite import BaseTestSuite, TestSuite\nfrom .loader import (TestLoader, defaultTestLoader, makeSuite, getTestCaseNames,\n                     findTestCases)\nfrom .main import TestProgram, main\nfrom .runner import TextTestRunner, TextTestResult\nfrom .signals import installHandler, registerResult, removeResult, removeHandler\n\n# deprecated\n_TextTestResult = TextTestResult\n", 1], "_string": [".py", "\"\"\"string helper module\"\"\"\n\nimport pyre as re\n\nclass __loader__(object):\n    pass\n\ndef formatter_field_name_split(*args,**kw):\n    \"\"\"split the argument as a field name\"\"\"\n    pass\n\ndef formatter_parser(*args,**kw):\n    \"\"\"parse the argument as a format string\"\"\"\n\n    assert len(args)==1\n    assert isinstance(args[0], str)\n\n    _result=[]\n    for _match in re.finditer(\"([^{]*)?(\\{[^}]*\\})?\", args[0]):\n        _pre, _fmt = _match.groups()\n        if _fmt is None:\n           _result.append((_pre, None, None, None))\n        elif _fmt == '{}':\n           _result.append((_pre, '', '', None))\n        else:\n           _m=re.match(\"\\{([^!]*)!?(.*)?\\}\", _fmt)\n           _name=_m.groups(0)\n           _flags=_m.groups(1)\n\n           _result.append((_pre, _name, _flags, None))\n\n    return _result\n"], "xml.parsers": [".py", "\"\"\"Python interfaces to XML parsers.\n\nThis package contains one module:\n\nexpat -- Python wrapper for James Clark's Expat parser, with namespace\n         support.\n\n\"\"\"\n", 1], "test.support": [".py", "\"\"\"Supporting definitions for the Python regression tests.\"\"\"\n\nif __name__ != 'test.support':\n    raise ImportError('support must be imported from the test package')\n\nimport contextlib\nimport errno\nimport functools\nimport gc\nimport socket\nimport sys\nimport os\nimport platform\nimport shutil\nimport warnings\nimport unittest\nimport importlib\nimport collections.abc\nimport re\nimport subprocess\nimport imp\nimport time\nimport sysconfig\nimport fnmatch\nimport logging.handlers\nimport struct\nimport tempfile\nimport _testcapi\n\ntry:\n    import _thread, threading\nexcept ImportError:\n    _thread = None\n    threading = None\n\n# BCE fixme brython.\n# causes an undefined is not a function error.  Will track down later.\n#try:\n#    import multiprocessing.process\n#except ImportError:\n#    multiprocessing = None\nmultiprocessing = None\n\ntry:\n    import zlib\nexcept ImportError:\n    zlib = None\n\ntry:\n    import bz2\nexcept ImportError:\n    bz2 = None\n\ntry:\n    import lzma\nexcept ImportError:\n    lzma = None\n\n__all__ = [\n    \"Error\", \"TestFailed\", \"ResourceDenied\", \"import_module\", \"verbose\",\n    \"use_resources\", \"max_memuse\", \"record_original_stdout\",\n    \"get_original_stdout\", \"unload\", \"unlink\", \"rmtree\", \"forget\",\n    \"is_resource_enabled\", \"requires\", \"requires_freebsd_version\",\n    \"requires_linux_version\", \"requires_mac_ver\", \"find_unused_port\",\n    \"bind_port\", \"IPV6_ENABLED\", \"is_jython\", \"TESTFN\", \"HOST\", \"SAVEDCWD\",\n    \"temp_cwd\", \"findfile\", \"create_empty_file\", \"sortdict\",\n    \"check_syntax_error\", \"open_urlresource\", \"check_warnings\", \"CleanImport\",\n    \"EnvironmentVarGuard\", \"TransientResource\", \"captured_stdout\",\n    \"captured_stdin\", \"captured_stderr\", \"time_out\", \"socket_peer_reset\",\n    \"ioerror_peer_reset\", \"run_with_locale\", 'temp_umask',\n    \"transient_internet\", \"set_memlimit\", \"bigmemtest\", \"bigaddrspacetest\",\n    \"BasicTestRunner\", \"run_unittest\", \"run_doctest\", \"threading_setup\",\n    \"threading_cleanup\", \"reap_children\", \"cpython_only\", \"check_impl_detail\",\n    \"get_attribute\", \"swap_item\", \"swap_attr\", \"requires_IEEE_754\",\n    \"TestHandler\", \"Matcher\", \"can_symlink\", \"skip_unless_symlink\",\n    \"skip_unless_xattr\", \"import_fresh_module\", \"requires_zlib\",\n    \"PIPE_MAX_SIZE\", \"failfast\", \"anticipate_failure\", \"run_with_tz\",\n    \"requires_bz2\", \"requires_lzma\", \"suppress_crash_popup\",\n    ]\n\nclass Error(Exception):\n    \"\"\"Base class for regression test exceptions.\"\"\"\n\nclass TestFailed(Error):\n    \"\"\"Test failed.\"\"\"\n\nclass ResourceDenied(unittest.SkipTest):\n    \"\"\"Test skipped because it requested a disallowed resource.\n\n    This is raised when a test calls requires() for a resource that\n    has not be enabled.  It is used to distinguish between expected\n    and unexpected skips.\n    \"\"\"\n\n@contextlib.contextmanager\ndef _ignore_deprecated_imports(ignore=True):\n    \"\"\"Context manager to suppress package and module deprecation\n    warnings when importing them.\n\n    If ignore is False, this context manager has no effect.\"\"\"\n    if ignore:\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\"ignore\", \".+ (module|package)\",\n                                    DeprecationWarning)\n            yield\n    else:\n        yield\n\n\ndef import_module(name, deprecated=False):\n    \"\"\"Import and return the module to be tested, raising SkipTest if\n    it is not available.\n\n    If deprecated is True, any module or package deprecation messages\n    will be suppressed.\"\"\"\n    with _ignore_deprecated_imports(deprecated):\n        try:\n            return importlib.import_module(name)\n        except ImportError as msg:\n            raise unittest.SkipTest(str(msg))\n\n\ndef _save_and_remove_module(name, orig_modules):\n    \"\"\"Helper function to save and remove a module from sys.modules\n\n       Raise ImportError if the module can't be imported.\"\"\"\n    # try to import the module and raise an error if it can't be imported\n    if name not in sys.modules:\n        __import__(name)\n        del sys.modules[name]\n    for modname in list(sys.modules):\n        if modname == name or modname.startswith(name + '.'):\n            orig_modules[modname] = sys.modules[modname]\n            del sys.modules[modname]\n\ndef _save_and_block_module(name, orig_modules):\n    \"\"\"Helper function to save and block a module in sys.modules\n\n       Return True if the module was in sys.modules, False otherwise.\"\"\"\n    saved = True\n    try:\n        orig_modules[name] = sys.modules[name]\n    except KeyError:\n        saved = False\n    sys.modules[name] = None\n    return saved\n\n\ndef anticipate_failure(condition):\n    \"\"\"Decorator to mark a test that is known to be broken in some cases\n\n       Any use of this decorator should have a comment identifying the\n       associated tracker issue.\n    \"\"\"\n    if condition:\n        return unittest.expectedFailure\n    return lambda f: f\n\n\ndef import_fresh_module(name, fresh=(), blocked=(), deprecated=False):\n    \"\"\"Imports and returns a module, deliberately bypassing the sys.modules cache\n    and importing a fresh copy of the module. Once the import is complete,\n    the sys.modules cache is restored to its original state.\n\n    Modules named in fresh are also imported anew if needed by the import.\n    If one of these modules can't be imported, None is returned.\n\n    Importing of modules named in blocked is prevented while the fresh import\n    takes place.\n\n    If deprecated is True, any module or package deprecation messages\n    will be suppressed.\"\"\"\n    # NOTE: test_heapq, test_json and test_warnings include extra sanity checks\n    # to make sure that this utility function is working as expected\n    with _ignore_deprecated_imports(deprecated):\n        # Keep track of modules saved for later restoration as well\n        # as those which just need a blocking entry removed\n        orig_modules = {}\n        names_to_remove = []\n        _save_and_remove_module(name, orig_modules)\n        try:\n            for fresh_name in fresh:\n                _save_and_remove_module(fresh_name, orig_modules)\n            for blocked_name in blocked:\n                if not _save_and_block_module(blocked_name, orig_modules):\n                    names_to_remove.append(blocked_name)\n            fresh_module = importlib.import_module(name)\n        except ImportError:\n            fresh_module = None\n        finally:\n            for orig_name, module in orig_modules.items():\n                sys.modules[orig_name] = module\n            for name_to_remove in names_to_remove:\n                del sys.modules[name_to_remove]\n        return fresh_module\n\n\ndef get_attribute(obj, name):\n    \"\"\"Get an attribute, raising SkipTest if AttributeError is raised.\"\"\"\n    try:\n        attribute = getattr(obj, name)\n    except AttributeError:\n        raise unittest.SkipTest(\"object %r has no attribute %r\" % (obj, name))\n    else:\n        return attribute\n\nverbose = 1              # Flag set to 0 by regrtest.py\nuse_resources = None     # Flag set to [] by regrtest.py\nmax_memuse = 0           # Disable bigmem tests (they will still be run with\n                         # small sizes, to make sure they work.)\nreal_max_memuse = 0\nfailfast = False\nmatch_tests = None\n\n# _original_stdout is meant to hold stdout at the time regrtest began.\n# This may be \"the real\" stdout, or IDLE's emulation of stdout, or whatever.\n# The point is to have some flavor of stdout the user can actually see.\n_original_stdout = None\ndef record_original_stdout(stdout):\n    global _original_stdout\n    _original_stdout = stdout\n\ndef get_original_stdout():\n    return _original_stdout or sys.stdout\n\ndef unload(name):\n    try:\n        del sys.modules[name]\n    except KeyError:\n        pass\n\nif sys.platform.startswith(\"win\"):\n    def _waitfor(func, pathname, waitall=False):\n        # Peform the operation\n        func(pathname)\n        # Now setup the wait loop\n        if waitall:\n            dirname = pathname\n        else:\n            dirname, name = os.path.split(pathname)\n            dirname = dirname or '.'\n        # Check for `pathname` to be removed from the filesystem.\n        # The exponential backoff of the timeout amounts to a total\n        # of ~1 second after which the deletion is probably an error\n        # anyway.\n        # Testing on a i7@4.3GHz shows that usually only 1 iteration is\n        # required when contention occurs.\n        timeout = 0.001\n        while timeout < 1.0:\n            # Note we are only testing for the existance of the file(s) in\n            # the contents of the directory regardless of any security or\n            # access rights.  If we have made it this far, we have sufficient\n            # permissions to do that much using Python's equivalent of the\n            # Windows API FindFirstFile.\n            # Other Windows APIs can fail or give incorrect results when\n            # dealing with files that are pending deletion.\n            L = os.listdir(dirname)\n            if not (L if waitall else name in L):\n                return\n            # Increase the timeout and try again\n            time.sleep(timeout)\n            timeout *= 2\n        warnings.warn('tests may fail, delete still pending for ' + pathname,\n                      RuntimeWarning, stacklevel=4)\n\n    def _unlink(filename):\n        _waitfor(os.unlink, filename)\n\n    def _rmdir(dirname):\n        _waitfor(os.rmdir, dirname)\n\n    def _rmtree(path):\n        def _rmtree_inner(path):\n            for name in os.listdir(path):\n                fullname = os.path.join(path, name)\n                if os.path.isdir(fullname):\n                    _waitfor(_rmtree_inner, fullname, waitall=True)\n                    os.rmdir(fullname)\n                else:\n                    os.unlink(fullname)\n        _waitfor(_rmtree_inner, path, waitall=True)\n        _waitfor(os.rmdir, path)\nelse:\n    _unlink = os.unlink\n    _rmdir = os.rmdir\n    _rmtree = shutil.rmtree\n\ndef unlink(filename):\n    try:\n        _unlink(filename)\n    except OSError as error:\n        # The filename need not exist.\n        if error.errno not in (errno.ENOENT, errno.ENOTDIR):\n            raise\n\ndef rmdir(dirname):\n    try:\n        _rmdir(dirname)\n    except OSError as error:\n        # The directory need not exist.\n        if error.errno != errno.ENOENT:\n            raise\n\ndef rmtree(path):\n    try:\n        _rmtree(path)\n    except OSError as error:\n        if error.errno != errno.ENOENT:\n            raise\n\ndef make_legacy_pyc(source):\n    \"\"\"Move a PEP 3147 pyc/pyo file to its legacy pyc/pyo location.\n\n    The choice of .pyc or .pyo extension is done based on the __debug__ flag\n    value.\n\n    :param source: The file system path to the source file.  The source file\n        does not need to exist, however the PEP 3147 pyc file must exist.\n    :return: The file system path to the legacy pyc file.\n    \"\"\"\n    pyc_file = imp.cache_from_source(source)\n    up_one = os.path.dirname(os.path.abspath(source))\n    legacy_pyc = os.path.join(up_one, source + ('c' if __debug__ else 'o'))\n    os.rename(pyc_file, legacy_pyc)\n    return legacy_pyc\n\ndef forget(modname):\n    \"\"\"'Forget' a module was ever imported.\n\n    This removes the module from sys.modules and deletes any PEP 3147 or\n    legacy .pyc and .pyo files.\n    \"\"\"\n    unload(modname)\n    for dirname in sys.path:\n        source = os.path.join(dirname, modname + '.py')\n        # It doesn't matter if they exist or not, unlink all possible\n        # combinations of PEP 3147 and legacy pyc and pyo files.\n        unlink(source + 'c')\n        unlink(source + 'o')\n        unlink(imp.cache_from_source(source, debug_override=True))\n        unlink(imp.cache_from_source(source, debug_override=False))\n\n# On some platforms, should not run gui test even if it is allowed\n# in `use_resources'.\nif sys.platform.startswith('win'):\n    import ctypes\n    import ctypes.wintypes\n    def _is_gui_available():\n        UOI_FLAGS = 1\n        WSF_VISIBLE = 0x0001\n        class USEROBJECTFLAGS(ctypes.Structure):\n            _fields_ = [(\"fInherit\", ctypes.wintypes.BOOL),\n                        (\"fReserved\", ctypes.wintypes.BOOL),\n                        (\"dwFlags\", ctypes.wintypes.DWORD)]\n        dll = ctypes.windll.user32\n        h = dll.GetProcessWindowStation()\n        if not h:\n            raise ctypes.WinError()\n        uof = USEROBJECTFLAGS()\n        needed = ctypes.wintypes.DWORD()\n        res = dll.GetUserObjectInformationW(h,\n            UOI_FLAGS,\n            ctypes.byref(uof),\n            ctypes.sizeof(uof),\n            ctypes.byref(needed))\n        if not res:\n            raise ctypes.WinError()\n        return bool(uof.dwFlags & WSF_VISIBLE)\nelse:\n    def _is_gui_available():\n        return True\n\ndef is_resource_enabled(resource):\n    \"\"\"Test whether a resource is enabled.  Known resources are set by\n    regrtest.py.\"\"\"\n    return use_resources is not None and resource in use_resources\n\ndef requires(resource, msg=None):\n    \"\"\"Raise ResourceDenied if the specified resource is not available.\n\n    If the caller's module is __main__ then automatically return True.  The\n    possibility of False being returned occurs when regrtest.py is\n    executing.\n    \"\"\"\n    if resource == 'gui' and not _is_gui_available():\n        raise unittest.SkipTest(\"Cannot use the 'gui' resource\")\n    # see if the caller's module is __main__ - if so, treat as if\n    # the resource was set\n    if sys._getframe(1).f_globals.get(\"__name__\") == \"__main__\":\n        return\n    if not is_resource_enabled(resource):\n        if msg is None:\n            msg = \"Use of the %r resource not enabled\" % resource\n        raise ResourceDenied(msg)\n\ndef _requires_unix_version(sysname, min_version):\n    \"\"\"Decorator raising SkipTest if the OS is `sysname` and the version is less\n    than `min_version`.\n\n    For example, @_requires_unix_version('FreeBSD', (7, 2)) raises SkipTest if\n    the FreeBSD version is less than 7.2.\n    \"\"\"\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            if platform.system() == sysname:\n                version_txt = platform.release().split('-', 1)[0]\n                try:\n                    version = tuple(map(int, version_txt.split('.')))\n                except ValueError:\n                    pass\n                else:\n                    if version < min_version:\n                        min_version_txt = '.'.join(map(str, min_version))\n                        raise unittest.SkipTest(\n                            \"%s version %s or higher required, not %s\"\n                            % (sysname, min_version_txt, version_txt))\n        return wrapper\n    return decorator\n\ndef requires_freebsd_version(*min_version):\n    \"\"\"Decorator raising SkipTest if the OS is FreeBSD and the FreeBSD version is\n    less than `min_version`.\n\n    For example, @requires_freebsd_version(7, 2) raises SkipTest if the FreeBSD\n    version is less than 7.2.\n    \"\"\"\n    return _requires_unix_version('FreeBSD', min_version)\n\ndef requires_linux_version(*min_version):\n    \"\"\"Decorator raising SkipTest if the OS is Linux and the Linux version is\n    less than `min_version`.\n\n    For example, @requires_linux_version(2, 6, 32) raises SkipTest if the Linux\n    version is less than 2.6.32.\n    \"\"\"\n    return _requires_unix_version('Linux', min_version)\n\ndef requires_mac_ver(*min_version):\n    \"\"\"Decorator raising SkipTest if the OS is Mac OS X and the OS X\n    version if less than min_version.\n\n    For example, @requires_mac_ver(10, 5) raises SkipTest if the OS X version\n    is lesser than 10.5.\n    \"\"\"\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            if sys.platform == 'darwin':\n                version_txt = platform.mac_ver()[0]\n                try:\n                    version = tuple(map(int, version_txt.split('.')))\n                except ValueError:\n                    pass\n                else:\n                    if version < min_version:\n                        min_version_txt = '.'.join(map(str, min_version))\n                        raise unittest.SkipTest(\n                            \"Mac OS X %s or higher required, not %s\"\n                            % (min_version_txt, version_txt))\n            return func(*args, **kw)\n        wrapper.min_version = min_version\n        return wrapper\n    return decorator\n\n\nHOST = 'localhost'\n\ndef find_unused_port(family=socket.AF_INET, socktype=socket.SOCK_STREAM):\n    \"\"\"Returns an unused port that should be suitable for binding.  This is\n    achieved by creating a temporary socket with the same family and type as\n    the 'sock' parameter (default is AF_INET, SOCK_STREAM), and binding it to\n    the specified host address (defaults to 0.0.0.0) with the port set to 0,\n    eliciting an unused ephemeral port from the OS.  The temporary socket is\n    then closed and deleted, and the ephemeral port is returned.\n\n    Either this method or bind_port() should be used for any tests where a\n    server socket needs to be bound to a particular port for the duration of\n    the test.  Which one to use depends on whether the calling code is creating\n    a python socket, or if an unused port needs to be provided in a constructor\n    or passed to an external program (i.e. the -accept argument to openssl's\n    s_server mode).  Always prefer bind_port() over find_unused_port() where\n    possible.  Hard coded ports should *NEVER* be used.  As soon as a server\n    socket is bound to a hard coded port, the ability to run multiple instances\n    of the test simultaneously on the same host is compromised, which makes the\n    test a ticking time bomb in a buildbot environment. On Unix buildbots, this\n    may simply manifest as a failed test, which can be recovered from without\n    intervention in most cases, but on Windows, the entire python process can\n    completely and utterly wedge, requiring someone to log in to the buildbot\n    and manually kill the affected process.\n\n    (This is easy to reproduce on Windows, unfortunately, and can be traced to\n    the SO_REUSEADDR socket option having different semantics on Windows versus\n    Unix/Linux.  On Unix, you can't have two AF_INET SOCK_STREAM sockets bind,\n    listen and then accept connections on identical host/ports.  An EADDRINUSE\n    socket.error will be raised at some point (depending on the platform and\n    the order bind and listen were called on each socket).\n\n    However, on Windows, if SO_REUSEADDR is set on the sockets, no EADDRINUSE\n    will ever be raised when attempting to bind two identical host/ports. When\n    accept() is called on each socket, the second caller's process will steal\n    the port from the first caller, leaving them both in an awkwardly wedged\n    state where they'll no longer respond to any signals or graceful kills, and\n    must be forcibly killed via OpenProcess()/TerminateProcess().\n\n    The solution on Windows is to use the SO_EXCLUSIVEADDRUSE socket option\n    instead of SO_REUSEADDR, which effectively affords the same semantics as\n    SO_REUSEADDR on Unix.  Given the propensity of Unix developers in the Open\n    Source world compared to Windows ones, this is a common mistake.  A quick\n    look over OpenSSL's 0.9.8g source shows that they use SO_REUSEADDR when\n    openssl.exe is called with the 's_server' option, for example. See\n    http://bugs.python.org/issue2550 for more info.  The following site also\n    has a very thorough description about the implications of both REUSEADDR\n    and EXCLUSIVEADDRUSE on Windows:\n    http://msdn2.microsoft.com/en-us/library/ms740621(VS.85).aspx)\n\n    XXX: although this approach is a vast improvement on previous attempts to\n    elicit unused ports, it rests heavily on the assumption that the ephemeral\n    port returned to us by the OS won't immediately be dished back out to some\n    other process when we close and delete our temporary socket but before our\n    calling code has a chance to bind the returned port.  We can deal with this\n    issue if/when we come across it.\n    \"\"\"\n\n    tempsock = socket.socket(family, socktype)\n    port = bind_port(tempsock)\n    tempsock.close()\n    del tempsock\n    return port\n\ndef bind_port(sock, host=HOST):\n    \"\"\"Bind the socket to a free port and return the port number.  Relies on\n    ephemeral ports in order to ensure we are using an unbound port.  This is\n    important as many tests may be running simultaneously, especially in a\n    buildbot environment.  This method raises an exception if the sock.family\n    is AF_INET and sock.type is SOCK_STREAM, *and* the socket has SO_REUSEADDR\n    or SO_REUSEPORT set on it.  Tests should *never* set these socket options\n    for TCP/IP sockets.  The only case for setting these options is testing\n    multicasting via multiple UDP sockets.\n\n    Additionally, if the SO_EXCLUSIVEADDRUSE socket option is available (i.e.\n    on Windows), it will be set on the socket.  This will prevent anyone else\n    from bind()'ing to our host/port for the duration of the test.\n    \"\"\"\n\n    if sock.family == socket.AF_INET and sock.type == socket.SOCK_STREAM:\n        if hasattr(socket, 'SO_REUSEADDR'):\n            if sock.getsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR) == 1:\n                raise TestFailed(\"tests should never set the SO_REUSEADDR \"   \\\n                                 \"socket option on TCP/IP sockets!\")\n        if hasattr(socket, 'SO_REUSEPORT'):\n            if sock.getsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT) == 1:\n                raise TestFailed(\"tests should never set the SO_REUSEPORT \"   \\\n                                 \"socket option on TCP/IP sockets!\")\n        if hasattr(socket, 'SO_EXCLUSIVEADDRUSE'):\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_EXCLUSIVEADDRUSE, 1)\n\n    sock.bind((host, 0))\n    port = sock.getsockname()[1]\n    return port\n\ndef _is_ipv6_enabled():\n    \"\"\"Check whether IPv6 is enabled on this host.\"\"\"\n    if socket.has_ipv6:\n        sock = None\n        try:\n            sock = socket.socket(socket.AF_INET6, socket.SOCK_STREAM)\n            sock.bind(('::1', 0))\n            return True\n        except (socket.error, socket.gaierror):\n            pass\n        finally:\n            if sock:\n                sock.close()\n    return False\n\nIPV6_ENABLED = _is_ipv6_enabled()\n\n\n# A constant likely larger than the underlying OS pipe buffer size.\n# Windows limit seems to be around 512B, and many Unix kernels have a 64K pipe\n# buffer size or 16*PAGE_SIZE: take a few megs to be sure.  This\nPIPE_MAX_SIZE = 3 * 1000 * 1000\n\n\n# decorator for skipping tests on non-IEEE 754 platforms\nrequires_IEEE_754 = unittest.skipUnless(\n    float.__getformat__(\"double\").startswith(\"IEEE\"),\n    \"test requires IEEE 754 doubles\")\n\nrequires_zlib = unittest.skipUnless(zlib, 'requires zlib')\n\nrequires_bz2 = unittest.skipUnless(bz2, 'requires bz2')\n\nrequires_lzma = unittest.skipUnless(lzma, 'requires lzma')\n\nis_jython = sys.platform.startswith('java')\n\n# Filename used for testing\nif os.name == 'java':\n    # Jython disallows @ in module names\n    TESTFN = '$test'\nelse:\n    TESTFN = '@test'\n\n# Disambiguate TESTFN for parallel testing, while letting it remain a valid\n# module name.\nTESTFN = \"{}_{}_tmp\".format(TESTFN, os.getpid())\n\n# FS_NONASCII: non-ASCII character encodable by os.fsencode(),\n# or None if there is no such character.\nFS_NONASCII = None\nfor character in (\n    # First try printable and common characters to have a readable filename.\n    # For each character, the encoding list are just example of encodings able\n    # to encode the character (the list is not exhaustive).\n\n    # U+00E6 (Latin Small Letter Ae): cp1252, iso-8859-1\n    '\\u00E6',\n    # U+0130 (Latin Capital Letter I With Dot Above): cp1254, iso8859_3\n    '\\u0130',\n    # U+0141 (Latin Capital Letter L With Stroke): cp1250, cp1257\n    '\\u0141',\n    # U+03C6 (Greek Small Letter Phi): cp1253\n    '\\u03C6',\n    # U+041A (Cyrillic Capital Letter Ka): cp1251\n    '\\u041A',\n    # U+05D0 (Hebrew Letter Alef): Encodable to cp424\n    '\\u05D0',\n    # U+060C (Arabic Comma): cp864, cp1006, iso8859_6, mac_arabic\n    '\\u060C',\n    # U+062A (Arabic Letter Teh): cp720\n    '\\u062A',\n    # U+0E01 (Thai Character Ko Kai): cp874\n    '\\u0E01',\n\n    # Then try more \"special\" characters. \"special\" because they may be\n    # interpreted or displayed differently depending on the exact locale\n    # encoding and the font.\n\n    # U+00A0 (No-Break Space)\n    '\\u00A0',\n    # U+20AC (Euro Sign)\n    '\\u20AC',\n):\n    try:\n        os.fsdecode(os.fsencode(character))\n    except UnicodeError:\n        pass\n    else:\n        FS_NONASCII = character\n        break\n\n# TESTFN_UNICODE is a non-ascii filename\nTESTFN_UNICODE = TESTFN + \"-\\xe0\\xf2\\u0258\\u0141\\u011f\"\nif sys.platform == 'darwin':\n    # In Mac OS X's VFS API file names are, by definition, canonically\n    # decomposed Unicode, encoded using UTF-8. See QA1173:\n    # http://developer.apple.com/mac/library/qa/qa2001/qa1173.html\n    import unicodedata\n    TESTFN_UNICODE = unicodedata.normalize('NFD', TESTFN_UNICODE)\nTESTFN_ENCODING = sys.getfilesystemencoding()\n\n# TESTFN_UNENCODABLE is a filename (str type) that should *not* be able to be\n# encoded by the filesystem encoding (in strict mode). It can be None if we\n# cannot generate such filename.\nTESTFN_UNENCODABLE = None\nif os.name in ('nt', 'ce'):\n    # skip win32s (0) or Windows 9x/ME (1)\n    if sys.getwindowsversion().platform >= 2:\n        # Different kinds of characters from various languages to minimize the\n        # probability that the whole name is encodable to MBCS (issue #9819)\n        TESTFN_UNENCODABLE = TESTFN + \"-\\u5171\\u0141\\u2661\\u0363\\uDC80\"\n        try:\n            TESTFN_UNENCODABLE.encode(TESTFN_ENCODING)\n        except UnicodeEncodeError:\n            pass\n        else:\n            print('WARNING: The filename %r CAN be encoded by the filesystem encoding (%s). '\n                  'Unicode filename tests may not be effective'\n                  % (TESTFN_UNENCODABLE, TESTFN_ENCODING))\n            TESTFN_UNENCODABLE = None\n# Mac OS X denies unencodable filenames (invalid utf-8)\nelif sys.platform != 'darwin':\n    try:\n        # ascii and utf-8 cannot encode the byte 0xff\n        b'\\xff'.decode(TESTFN_ENCODING)\n    except UnicodeDecodeError:\n        # 0xff will be encoded using the surrogate character u+DCFF\n        TESTFN_UNENCODABLE = TESTFN \\\n            + b'-\\xff'.decode(TESTFN_ENCODING, 'surrogateescape')\n    else:\n        # File system encoding (eg. ISO-8859-* encodings) can encode\n        # the byte 0xff. Skip some unicode filename tests.\n        pass\n\n# TESTFN_UNDECODABLE is a filename (bytes type) that should *not* be able to be\n# decoded from the filesystem encoding (in strict mode). It can be None if we\n# cannot generate such filename (ex: the latin1 encoding can decode any byte\n# sequence). On UNIX, TESTFN_UNDECODABLE can be decoded by os.fsdecode() thanks\n# to the surrogateescape error handler (PEP 383), but not from the filesystem\n# encoding in strict mode.\nTESTFN_UNDECODABLE = None\n'''  #fixme brython\nfor name in (\n    # b'\\xff' is not decodable by os.fsdecode() with code page 932. Windows\n    # accepts it to create a file or a directory, or don't accept to enter to\n    # such directory (when the bytes name is used). So test b'\\xe7' first: it is\n    # not decodable from cp932.\n    b'\\xe7w\\xf0',\n    # undecodable from ASCII, UTF-8\n    b'\\xff',\n    # undecodable from iso8859-3, iso8859-6, iso8859-7, cp424, iso8859-8, cp856\n    # and cp857\n    b'\\xae\\xd5'\n    # undecodable from UTF-8 (UNIX and Mac OS X)\n    b'\\xed\\xb2\\x80', b'\\xed\\xb4\\x80',\n    # undecodable from shift_jis, cp869, cp874, cp932, cp1250, cp1251, cp1252,\n    # cp1253, cp1254, cp1255, cp1257, cp1258\n    b'\\x81\\x98',\n):\n    try:\n        name.decode(TESTFN_ENCODING)\n    except UnicodeDecodeError:\n        TESTFN_UNDECODABLE = os.fsencode(TESTFN) + name\n        break\n'''\nif FS_NONASCII:\n    TESTFN_NONASCII = TESTFN + '-' + FS_NONASCII\nelse:\n    TESTFN_NONASCII = None\n\n# Save the initial cwd\nSAVEDCWD = os.getcwd()\n\n@contextlib.contextmanager\ndef temp_cwd(name='tempcwd', quiet=False, path=None):\n    \"\"\"\n    Context manager that temporarily changes the CWD.\n\n    An existing path may be provided as *path*, in which case this\n    function makes no changes to the file system.\n\n    Otherwise, the new CWD is created in the current directory and it's\n    named *name*. If *quiet* is False (default) and it's not possible to\n    create or change the CWD, an error is raised.  If it's True, only a\n    warning is raised and the original CWD is used.\n    \"\"\"\n    saved_dir = os.getcwd()\n    is_temporary = False\n    if path is None:\n        path = name\n        try:\n            os.mkdir(name)\n            is_temporary = True\n        except OSError:\n            if not quiet:\n                raise\n            warnings.warn('tests may fail, unable to create temp CWD ' + name,\n                          RuntimeWarning, stacklevel=3)\n    try:\n        os.chdir(path)\n    except OSError:\n        if not quiet:\n            raise\n        warnings.warn('tests may fail, unable to change the CWD to ' + path,\n                      RuntimeWarning, stacklevel=3)\n    try:\n        yield os.getcwd()\n    finally:\n        os.chdir(saved_dir)\n        if is_temporary:\n            rmtree(name)\n\n\nif hasattr(os, \"umask\"):\n    @contextlib.contextmanager\n    def temp_umask(umask):\n        \"\"\"Context manager that temporarily sets the process umask.\"\"\"\n        oldmask = os.umask(umask)\n        try:\n            yield\n        finally:\n            os.umask(oldmask)\n\n\ndef findfile(file, here=__file__, subdir=None):\n    \"\"\"Try to find a file on sys.path and the working directory.  If it is not\n    found the argument passed to the function is returned (this does not\n    necessarily signal failure; could still be the legitimate path).\"\"\"\n    if os.path.isabs(file):\n        return file\n    if subdir is not None:\n        file = os.path.join(subdir, file)\n    path = sys.path\n    path = [os.path.dirname(here)] + path\n    for dn in path:\n        fn = os.path.join(dn, file)\n        if os.path.exists(fn): return fn\n    return file\n\ndef create_empty_file(filename):\n    \"\"\"Create an empty file. If the file already exists, truncate it.\"\"\"\n    fd = os.open(filename, os.O_WRONLY | os.O_CREAT | os.O_TRUNC)\n    os.close(fd)\n\ndef sortdict(dict):\n    \"Like repr(dict), but in sorted order.\"\n    items = sorted(dict.items())\n    reprpairs = [\"%r: %r\" % pair for pair in items]\n    withcommas = \", \".join(reprpairs)\n    return \"{%s}\" % withcommas\n\ndef make_bad_fd():\n    \"\"\"\n    Create an invalid file descriptor by opening and closing a file and return\n    its fd.\n    \"\"\"\n    file = open(TESTFN, \"wb\")\n    try:\n        return file.fileno()\n    finally:\n        file.close()\n        unlink(TESTFN)\n\ndef check_syntax_error(testcase, statement):\n    testcase.assertRaises(SyntaxError, compile, statement,\n                          '<test string>', 'exec')\n\ndef open_urlresource(url, *args, **kw):\n    import urllib.request, urllib.parse\n\n    check = kw.pop('check', None)\n\n    filename = urllib.parse.urlparse(url)[2].split('/')[-1] # '/': it's URL!\n\n    fn = os.path.join(os.path.dirname(__file__), \"data\", filename)\n\n    def check_valid_file(fn):\n        f = open(fn, *args, **kw)\n        if check is None:\n            return f\n        elif check(f):\n            f.seek(0)\n            return f\n        f.close()\n\n    if os.path.exists(fn):\n        f = check_valid_file(fn)\n        if f is not None:\n            return f\n        unlink(fn)\n\n    # Verify the requirement before downloading the file\n    requires('urlfetch')\n\n    print('\\tfetching %s ...' % url, file=get_original_stdout())\n    f = urllib.request.urlopen(url, timeout=15)\n    try:\n        with open(fn, \"wb\") as out:\n            s = f.read()\n            while s:\n                out.write(s)\n                s = f.read()\n    finally:\n        f.close()\n\n    f = check_valid_file(fn)\n    if f is not None:\n        return f\n    raise TestFailed('invalid resource %r' % fn)\n\n\nclass WarningsRecorder(object):\n    \"\"\"Convenience wrapper for the warnings list returned on\n       entry to the warnings.catch_warnings() context manager.\n    \"\"\"\n    def __init__(self, warnings_list):\n        self._warnings = warnings_list\n        self._last = 0\n\n    def __getattr__(self, attr):\n        if len(self._warnings) > self._last:\n            return getattr(self._warnings[-1], attr)\n        elif attr in warnings.WarningMessage._WARNING_DETAILS:\n            return None\n        raise AttributeError(\"%r has no attribute %r\" % (self, attr))\n\n    @property\n    def warnings(self):\n        return self._warnings[self._last:]\n\n    def reset(self):\n        self._last = len(self._warnings)\n\n\ndef _filterwarnings(filters, quiet=False):\n    \"\"\"Catch the warnings, then check if all the expected\n    warnings have been raised and re-raise unexpected warnings.\n    If 'quiet' is True, only re-raise the unexpected warnings.\n    \"\"\"\n    # Clear the warning registry of the calling module\n    # in order to re-raise the warnings.\n    frame = sys._getframe(2)\n    registry = frame.f_globals.get('__warningregistry__')\n    if registry:\n        registry.clear()\n    with warnings.catch_warnings(record=True) as w:\n        # Set filter \"always\" to record all warnings.  Because\n        # test_warnings swap the module, we need to look up in\n        # the sys.modules dictionary.\n        sys.modules['warnings'].simplefilter(\"always\")\n        yield WarningsRecorder(w)\n    # Filter the recorded warnings\n    reraise = list(w)\n    missing = []\n    for msg, cat in filters:\n        seen = False\n        for w in reraise[:]:\n            warning = w.message\n            # Filter out the matching messages\n            if (re.match(msg, str(warning), re.I) and\n                issubclass(warning.__class__, cat)):\n                seen = True\n                reraise.remove(w)\n        if not seen and not quiet:\n            # This filter caught nothing\n            missing.append((msg, cat.__name__))\n    if reraise:\n        raise AssertionError(\"unhandled warning %s\" % reraise[0])\n    if missing:\n        raise AssertionError(\"filter (%r, %s) did not catch any warning\" %\n                             missing[0])\n\n\n@contextlib.contextmanager\ndef check_warnings(*filters, **kwargs):\n    \"\"\"Context manager to silence warnings.\n\n    Accept 2-tuples as positional arguments:\n        (\"message regexp\", WarningCategory)\n\n    Optional argument:\n     - if 'quiet' is True, it does not fail if a filter catches nothing\n        (default True without argument,\n         default False if some filters are defined)\n\n    Without argument, it defaults to:\n        check_warnings((\"\", Warning), quiet=True)\n    \"\"\"\n    quiet = kwargs.get('quiet')\n    if not filters:\n        filters = ((\"\", Warning),)\n        # Preserve backward compatibility\n        if quiet is None:\n            quiet = True\n    return _filterwarnings(filters, quiet)\n\n\nclass CleanImport(object):\n    \"\"\"Context manager to force import to return a new module reference.\n\n    This is useful for testing module-level behaviours, such as\n    the emission of a DeprecationWarning on import.\n\n    Use like this:\n\n        with CleanImport(\"foo\"):\n            importlib.import_module(\"foo\") # new reference\n    \"\"\"\n\n    def __init__(self, *module_names):\n        self.original_modules = sys.modules.copy()\n        for module_name in module_names:\n            if module_name in sys.modules:\n                module = sys.modules[module_name]\n                # It is possible that module_name is just an alias for\n                # another module (e.g. stub for modules renamed in 3.x).\n                # In that case, we also need delete the real module to clear\n                # the import cache.\n                if module.__name__ != module_name:\n                    del sys.modules[module.__name__]\n                del sys.modules[module_name]\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *ignore_exc):\n        sys.modules.update(self.original_modules)\n\n\nclass EnvironmentVarGuard(collections.abc.MutableMapping):\n\n    \"\"\"Class to help protect the environment variable properly.  Can be used as\n    a context manager.\"\"\"\n\n    def __init__(self):\n        self._environ = os.environ\n        self._changed = {}\n\n    def __getitem__(self, envvar):\n        return self._environ[envvar]\n\n    def __setitem__(self, envvar, value):\n        # Remember the initial value on the first access\n        if envvar not in self._changed:\n            self._changed[envvar] = self._environ.get(envvar)\n        self._environ[envvar] = value\n\n    def __delitem__(self, envvar):\n        # Remember the initial value on the first access\n        if envvar not in self._changed:\n            self._changed[envvar] = self._environ.get(envvar)\n        if envvar in self._environ:\n            del self._environ[envvar]\n\n    def keys(self):\n        return self._environ.keys()\n\n    def __iter__(self):\n        return iter(self._environ)\n\n    def __len__(self):\n        return len(self._environ)\n\n    def set(self, envvar, value):\n        self[envvar] = value\n\n    def unset(self, envvar):\n        del self[envvar]\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *ignore_exc):\n        for (k, v) in self._changed.items():\n            if v is None:\n                if k in self._environ:\n                    del self._environ[k]\n            else:\n                self._environ[k] = v\n        os.environ = self._environ\n\n\nclass DirsOnSysPath(object):\n    \"\"\"Context manager to temporarily add directories to sys.path.\n\n    This makes a copy of sys.path, appends any directories given\n    as positional arguments, then reverts sys.path to the copied\n    settings when the context ends.\n\n    Note that *all* sys.path modifications in the body of the\n    context manager, including replacement of the object,\n    will be reverted at the end of the block.\n    \"\"\"\n\n    def __init__(self, *paths):\n        self.original_value = sys.path[:]\n        self.original_object = sys.path\n        sys.path.extend(paths)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *ignore_exc):\n        sys.path = self.original_object\n        sys.path[:] = self.original_value\n\n\nclass TransientResource(object):\n\n    \"\"\"Raise ResourceDenied if an exception is raised while the context manager\n    is in effect that matches the specified exception and attributes.\"\"\"\n\n    def __init__(self, exc, **kwargs):\n        self.exc = exc\n        self.attrs = kwargs\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type_=None, value=None, traceback=None):\n        \"\"\"If type_ is a subclass of self.exc and value has attributes matching\n        self.attrs, raise ResourceDenied.  Otherwise let the exception\n        propagate (if any).\"\"\"\n        if type_ is not None and issubclass(self.exc, type_):\n            for attr, attr_value in self.attrs.items():\n                if not hasattr(value, attr):\n                    break\n                if getattr(value, attr) != attr_value:\n                    break\n            else:\n                raise ResourceDenied(\"an optional resource is not available\")\n\n# Context managers that raise ResourceDenied when various issues\n# with the Internet connection manifest themselves as exceptions.\n# XXX deprecate these and use transient_internet() instead\ntime_out = TransientResource(IOError, errno=errno.ETIMEDOUT)\nsocket_peer_reset = TransientResource(socket.error, errno=errno.ECONNRESET)\nioerror_peer_reset = TransientResource(IOError, errno=errno.ECONNRESET)\n\n\n@contextlib.contextmanager\ndef transient_internet(resource_name, *, timeout=30.0, errnos=()):\n    \"\"\"Return a context manager that raises ResourceDenied when various issues\n    with the Internet connection manifest themselves as exceptions.\"\"\"\n    default_errnos = [\n        ('ECONNREFUSED', 111),\n        ('ECONNRESET', 104),\n        ('EHOSTUNREACH', 113),\n        ('ENETUNREACH', 101),\n        ('ETIMEDOUT', 110),\n    ]\n    default_gai_errnos = [\n        ('EAI_AGAIN', -3),\n        ('EAI_FAIL', -4),\n        ('EAI_NONAME', -2),\n        ('EAI_NODATA', -5),\n        # Encountered when trying to resolve IPv6-only hostnames\n        ('WSANO_DATA', 11004),\n    ]\n\n    denied = ResourceDenied(\"Resource %r is not available\" % resource_name)\n    captured_errnos = errnos\n    gai_errnos = []\n    if not captured_errnos:\n        captured_errnos = [getattr(errno, name, num)\n                           for (name, num) in default_errnos]\n        gai_errnos = [getattr(socket, name, num)\n                      for (name, num) in default_gai_errnos]\n\n    def filter_error(err):\n        n = getattr(err, 'errno', None)\n        if (isinstance(err, socket.timeout) or\n            (isinstance(err, socket.gaierror) and n in gai_errnos) or\n            n in captured_errnos):\n            if not verbose:\n                sys.stderr.write(denied.args[0] + \"\\n\")\n            raise denied from err\n\n    old_timeout = socket.getdefaulttimeout()\n    try:\n        if timeout is not None:\n            socket.setdefaulttimeout(timeout)\n        yield\n    except IOError as err:\n        # urllib can wrap original socket errors multiple times (!), we must\n        # unwrap to get at the original error.\n        while True:\n            a = err.args\n            if len(a) >= 1 and isinstance(a[0], IOError):\n                err = a[0]\n            # The error can also be wrapped as args[1]:\n            #    except socket.error as msg:\n            #        raise IOError('socket error', msg).with_traceback(sys.exc_info()[2])\n            elif len(a) >= 2 and isinstance(a[1], IOError):\n                err = a[1]\n            else:\n                break\n        filter_error(err)\n        raise\n    # XXX should we catch generic exceptions and look for their\n    # __cause__ or __context__?\n    finally:\n        socket.setdefaulttimeout(old_timeout)\n\n\n@contextlib.contextmanager\ndef captured_output(stream_name):\n    \"\"\"Return a context manager used by captured_stdout/stdin/stderr\n    that temporarily replaces the sys stream *stream_name* with a StringIO.\"\"\"\n    import io\n    orig_stdout = getattr(sys, stream_name)\n    setattr(sys, stream_name, io.StringIO())\n    try:\n        yield getattr(sys, stream_name)\n    finally:\n        setattr(sys, stream_name, orig_stdout)\n\ndef captured_stdout():\n    \"\"\"Capture the output of sys.stdout:\n\n       with captured_stdout() as s:\n           print(\"hello\")\n       self.assertEqual(s.getvalue(), \"hello\")\n    \"\"\"\n    return captured_output(\"stdout\")\n\ndef captured_stderr():\n    return captured_output(\"stderr\")\n\ndef captured_stdin():\n    return captured_output(\"stdin\")\n\n\ndef gc_collect():\n    \"\"\"Force as many objects as possible to be collected.\n\n    In non-CPython implementations of Python, this is needed because timely\n    deallocation is not guaranteed by the garbage collector.  (Even in CPython\n    this can be the case in case of reference cycles.)  This means that __del__\n    methods may be called later than expected and weakrefs may remain alive for\n    longer than expected.  This function tries its best to force all garbage\n    objects to disappear.\n    \"\"\"\n    gc.collect()\n    if is_jython:\n        time.sleep(0.1)\n    gc.collect()\n    gc.collect()\n\n@contextlib.contextmanager\ndef disable_gc():\n    have_gc = gc.isenabled()\n    gc.disable()\n    try:\n        yield\n    finally:\n        if have_gc:\n            gc.enable()\n\n\ndef python_is_optimized():\n    \"\"\"Find if Python was built with optimizations.\"\"\"\n    cflags = sysconfig.get_config_var('PY_CFLAGS') or ''\n    final_opt = \"\"\n    for opt in cflags.split():\n        if opt.startswith('-O'):\n            final_opt = opt\n    return final_opt != '' and final_opt != '-O0'\n\n\n_header = 'nP'\n_align = '0n'\nif hasattr(sys, \"gettotalrefcount\"):\n    _header = '2P' + _header\n    _align = '0P'\n_vheader = _header + 'n'\n\ndef calcobjsize(fmt):\n    return struct.calcsize(_header + fmt + _align)\n\ndef calcvobjsize(fmt):\n    return struct.calcsize(_vheader + fmt + _align)\n\n\n_TPFLAGS_HAVE_GC = 1<<14\n_TPFLAGS_HEAPTYPE = 1<<9\n\ndef check_sizeof(test, o, size):\n    result = sys.getsizeof(o)\n    # add GC header size\n    if ((type(o) == type) and (o.__flags__ & _TPFLAGS_HEAPTYPE) or\\\n        ((type(o) != type) and (type(o).__flags__ & _TPFLAGS_HAVE_GC))):\n        size += _testcapi.SIZEOF_PYGC_HEAD\n    msg = 'wrong size for %s: got %d, expected %d' \\\n            % (type(o), result, size)\n    test.assertEqual(result, size, msg)\n\n#=======================================================================\n# Decorator for running a function in a different locale, correctly resetting\n# it afterwards.\n\ndef run_with_locale(catstr, *locales):\n    def decorator(func):\n        def inner(*args, **kwds):\n            try:\n                import locale\n                category = getattr(locale, catstr)\n                orig_locale = locale.setlocale(category)\n            except AttributeError:\n                # if the test author gives us an invalid category string\n                raise\n            except:\n                # cannot retrieve original locale, so do nothing\n                locale = orig_locale = None\n            else:\n                for loc in locales:\n                    try:\n                        locale.setlocale(category, loc)\n                        break\n                    except:\n                        pass\n\n            # now run the function, resetting the locale on exceptions\n            try:\n                return func(*args, **kwds)\n            finally:\n                if locale and orig_locale:\n                    locale.setlocale(category, orig_locale)\n        inner.__name__ = func.__name__\n        inner.__doc__ = func.__doc__\n        return inner\n    return decorator\n\n#=======================================================================\n# Decorator for running a function in a specific timezone, correctly\n# resetting it afterwards.\n\ndef run_with_tz(tz):\n    def decorator(func):\n        def inner(*args, **kwds):\n            try:\n                tzset = time.tzset\n            except AttributeError:\n                raise unittest.SkipTest(\"tzset required\")\n            if 'TZ' in os.environ:\n                orig_tz = os.environ['TZ']\n            else:\n                orig_tz = None\n            os.environ['TZ'] = tz\n            tzset()\n\n            # now run the function, resetting the tz on exceptions\n            try:\n                return func(*args, **kwds)\n            finally:\n                if orig_tz is None:\n                    del os.environ['TZ']\n                else:\n                    os.environ['TZ'] = orig_tz\n                time.tzset()\n\n        inner.__name__ = func.__name__\n        inner.__doc__ = func.__doc__\n        return inner\n    return decorator\n\n#=======================================================================\n# Big-memory-test support. Separate from 'resources' because memory use\n# should be configurable.\n\n# Some handy shorthands. Note that these are used for byte-limits as well\n# as size-limits, in the various bigmem tests\n_1M = 1024*1024\n_1G = 1024 * _1M\n_2G = 2 * _1G\n_4G = 4 * _1G\n\nMAX_Py_ssize_t = sys.maxsize\n\ndef set_memlimit(limit):\n    global max_memuse\n    global real_max_memuse\n    sizes = {\n        'k': 1024,\n        'm': _1M,\n        'g': _1G,\n        't': 1024*_1G,\n    }\n    m = re.match(r'(\\d+(\\.\\d+)?) (K|M|G|T)b?$', limit,\n                 re.IGNORECASE | re.VERBOSE)\n    if m is None:\n        raise ValueError('Invalid memory limit %r' % (limit,))\n    memlimit = int(float(m.group(1)) * sizes[m.group(3).lower()])\n    real_max_memuse = memlimit\n    if memlimit > MAX_Py_ssize_t:\n        memlimit = MAX_Py_ssize_t\n    if memlimit < _2G - 1:\n        raise ValueError('Memory limit %r too low to be useful' % (limit,))\n    max_memuse = memlimit\n\nclass _MemoryWatchdog:\n    \"\"\"An object which periodically watches the process' memory consumption\n    and prints it out.\n    \"\"\"\n\n    def __init__(self):\n        self.procfile = '/proc/{pid}/statm'.format(pid=os.getpid())\n        self.started = False\n\n    def start(self):\n        try:\n            f = open(self.procfile, 'r')\n        except OSError as e:\n            warnings.warn('/proc not available for stats: {}'.format(e),\n                          RuntimeWarning)\n            sys.stderr.flush()\n            return\n\n        watchdog_script = findfile(\"memory_watchdog.py\")\n        self.mem_watchdog = subprocess.Popen([sys.executable, watchdog_script],\n                                             stdin=f, stderr=subprocess.DEVNULL)\n        f.close()\n        self.started = True\n\n    def stop(self):\n        if self.started:\n            self.mem_watchdog.terminate()\n            self.mem_watchdog.wait()\n\n\ndef bigmemtest(size, memuse, dry_run=True):\n    \"\"\"Decorator for bigmem tests.\n\n    'minsize' is the minimum useful size for the test (in arbitrary,\n    test-interpreted units.) 'memuse' is the number of 'bytes per size' for\n    the test, or a good estimate of it.\n\n    if 'dry_run' is False, it means the test doesn't support dummy runs\n    when -M is not specified.\n    \"\"\"\n    def decorator(f):\n        def wrapper(self):\n            size = wrapper.size\n            memuse = wrapper.memuse\n            if not real_max_memuse:\n                maxsize = 5147\n            else:\n                maxsize = size\n\n            if ((real_max_memuse or not dry_run)\n                and real_max_memuse < maxsize * memuse):\n                raise unittest.SkipTest(\n                    \"not enough memory: %.1fG minimum needed\"\n                    % (size * memuse / (1024 ** 3)))\n\n            if real_max_memuse and verbose:\n                print()\n                print(\" ... expected peak memory use: {peak:.1f}G\"\n                      .format(peak=size * memuse / (1024 ** 3)))\n                watchdog = _MemoryWatchdog()\n                watchdog.start()\n            else:\n                watchdog = None\n\n            try:\n                return f(self, maxsize)\n            finally:\n                if watchdog:\n                    watchdog.stop()\n\n        wrapper.size = size\n        wrapper.memuse = memuse\n        return wrapper\n    return decorator\n\ndef bigaddrspacetest(f):\n    \"\"\"Decorator for tests that fill the address space.\"\"\"\n    def wrapper(self):\n        if max_memuse < MAX_Py_ssize_t:\n            if MAX_Py_ssize_t >= 2**63 - 1 and max_memuse >= 2**31:\n                raise unittest.SkipTest(\n                    \"not enough memory: try a 32-bit build instead\")\n            else:\n                raise unittest.SkipTest(\n                    \"not enough memory: %.1fG minimum needed\"\n                    % (MAX_Py_ssize_t / (1024 ** 3)))\n        else:\n            return f(self)\n    return wrapper\n\n#=======================================================================\n# unittest integration.\n\nclass BasicTestRunner:\n    def run(self, test):\n        result = unittest.TestResult()\n        test(result)\n        return result\n\ndef _id(obj):\n    return obj\n\ndef requires_resource(resource):\n    if resource == 'gui' and not _is_gui_available():\n        return unittest.skip(\"resource 'gui' is not available\")\n    if is_resource_enabled(resource):\n        return _id\n    else:\n        return unittest.skip(\"resource {0!r} is not enabled\".format(resource))\n\ndef cpython_only(test):\n    \"\"\"\n    Decorator for tests only applicable on CPython.\n    \"\"\"\n    return impl_detail(cpython=True)(test)\n\ndef impl_detail(msg=None, **guards):\n    if check_impl_detail(**guards):\n        return _id\n    if msg is None:\n        guardnames, default = _parse_guards(guards)\n        if default:\n            msg = \"implementation detail not available on {0}\"\n        else:\n            msg = \"implementation detail specific to {0}\"\n        guardnames = sorted(guardnames.keys())\n        msg = msg.format(' or '.join(guardnames))\n    return unittest.skip(msg)\n\ndef _parse_guards(guards):\n    # Returns a tuple ({platform_name: run_me}, default_value)\n    if not guards:\n        return ({'cpython': True}, False)\n    is_true = list(guards.values())[0]\n    assert list(guards.values()) == [is_true] * len(guards)   # all True or all False\n    return (guards, not is_true)\n\n# Use the following check to guard CPython's implementation-specific tests --\n# or to run them only on the implementation(s) guarded by the arguments.\ndef check_impl_detail(**guards):\n    \"\"\"This function returns True or False depending on the host platform.\n       Examples:\n          if check_impl_detail():               # only on CPython (default)\n          if check_impl_detail(jython=True):    # only on Jython\n          if check_impl_detail(cpython=False):  # everywhere except on CPython\n    \"\"\"\n    guards, default = _parse_guards(guards)\n    return guards.get(platform.python_implementation().lower(), default)\n\n\ndef no_tracing(func):\n    \"\"\"Decorator to temporarily turn off tracing for the duration of a test.\"\"\"\n    if not hasattr(sys, 'gettrace'):\n        return func\n    else:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            original_trace = sys.gettrace()\n            try:\n                sys.settrace(None)\n                return func(*args, **kwargs)\n            finally:\n                sys.settrace(original_trace)\n        return wrapper\n\n\ndef refcount_test(test):\n    \"\"\"Decorator for tests which involve reference counting.\n\n    To start, the decorator does not run the test if is not run by CPython.\n    After that, any trace function is unset during the test to prevent\n    unexpected refcounts caused by the trace function.\n\n    \"\"\"\n    return no_tracing(cpython_only(test))\n\n\ndef _filter_suite(suite, pred):\n    \"\"\"Recursively filter test cases in a suite based on a predicate.\"\"\"\n    newtests = []\n    for test in suite._tests:\n        if isinstance(test, unittest.TestSuite):\n            _filter_suite(test, pred)\n            newtests.append(test)\n        else:\n            if pred(test):\n                newtests.append(test)\n    suite._tests = newtests\n\ndef _run_suite(suite):\n    \"\"\"Run tests from a unittest.TestSuite-derived class.\"\"\"\n    if verbose:\n        runner = unittest.TextTestRunner(sys.stdout, verbosity=2,\n                                         failfast=failfast)\n    else:\n        runner = BasicTestRunner()\n\n    result = runner.run(suite)\n    if not result.wasSuccessful():\n        if len(result.errors) == 1 and not result.failures:\n            err = result.errors[0][1]\n        elif len(result.failures) == 1 and not result.errors:\n            err = result.failures[0][1]\n        else:\n            err = \"multiple errors occurred\"\n            if not verbose: err += \"; run in verbose mode for details\"\n        raise TestFailed(err)\n\n\ndef run_unittest(*classes):\n    \"\"\"Run tests from unittest.TestCase-derived classes.\"\"\"\n    valid_types = (unittest.TestSuite, unittest.TestCase)\n    suite = unittest.TestSuite()\n    for cls in classes:\n        if isinstance(cls, str):\n            if cls in sys.modules:\n                suite.addTest(unittest.findTestCases(sys.modules[cls]))\n            else:\n                raise ValueError(\"str arguments must be keys in sys.modules\")\n        elif isinstance(cls, valid_types):\n            suite.addTest(cls)\n        else:\n            suite.addTest(unittest.makeSuite(cls))\n    def case_pred(test):\n        if match_tests is None:\n            return True\n        for name in test.id().split(\".\"):\n            if fnmatch.fnmatchcase(name, match_tests):\n                return True\n        return False\n    _filter_suite(suite, case_pred)\n    _run_suite(suite)\n\n#=======================================================================\n# Check for the presence of docstrings.\n\nHAVE_DOCSTRINGS = (check_impl_detail(cpython=False) or\n                   sys.platform == 'win32' or\n                   sysconfig.get_config_var('WITH_DOC_STRINGS'))\n\nrequires_docstrings = unittest.skipUnless(HAVE_DOCSTRINGS,\n                                          \"test requires docstrings\")\n\n\n#=======================================================================\n# doctest driver.\n\ndef run_doctest(module, verbosity=None, optionflags=0):\n    \"\"\"Run doctest on the given module.  Return (#failures, #tests).\n\n    If optional argument verbosity is not specified (or is None), pass\n    support's belief about verbosity on to doctest.  Else doctest's\n    usual behavior is used (it searches sys.argv for -v).\n    \"\"\"\n\n    import doctest\n\n    if verbosity is None:\n        verbosity = verbose\n    else:\n        verbosity = None\n\n    f, t = doctest.testmod(module, verbose=verbosity, optionflags=optionflags)\n    if f:\n        raise TestFailed(\"%d of %d doctests failed\" % (f, t))\n    if verbose:\n        print('doctest (%s) ... %d tests with zero failures' %\n              (module.__name__, t))\n    return f, t\n\n\n#=======================================================================\n# Support for saving and restoring the imported modules.\n\ndef modules_setup():\n    return sys.modules.copy(),\n\ndef modules_cleanup(oldmodules):\n    # Encoders/decoders are registered permanently within the internal\n    # codec cache. If we destroy the corresponding modules their\n    # globals will be set to None which will trip up the cached functions.\n    encodings = [(k, v) for k, v in sys.modules.items()\n                 if k.startswith('encodings.')]\n    sys.modules.clear()\n    sys.modules.update(encodings)\n    # XXX: This kind of problem can affect more than just encodings. In particular\n    # extension modules (such as _ssl) don't cope with reloading properly.\n    # Really, test modules should be cleaning out the test specific modules they\n    # know they added (ala test_runpy) rather than relying on this function (as\n    # test_importhooks and test_pkg do currently).\n    # Implicitly imported *real* modules should be left alone (see issue 10556).\n    sys.modules.update(oldmodules)\n\n#=======================================================================\n# Threading support to prevent reporting refleaks when running regrtest.py -R\n\n# NOTE: we use thread._count() rather than threading.enumerate() (or the\n# moral equivalent thereof) because a threading.Thread object is still alive\n# until its __bootstrap() method has returned, even after it has been\n# unregistered from the threading module.\n# thread._count(), on the other hand, only gets decremented *after* the\n# __bootstrap() method has returned, which gives us reliable reference counts\n# at the end of a test run.\n\ndef threading_setup():\n    if _thread:\n        return _thread._count(), threading._dangling.copy()\n    else:\n        return 1, ()\n\ndef threading_cleanup(*original_values):\n    if not _thread:\n        return\n    _MAX_COUNT = 10\n    for count in range(_MAX_COUNT):\n        values = _thread._count(), threading._dangling\n        if values == original_values:\n            break\n        time.sleep(0.1)\n        gc_collect()\n    # XXX print a warning in case of failure?\n\ndef reap_threads(func):\n    \"\"\"Use this function when threads are being used.  This will\n    ensure that the threads are cleaned up even when the test fails.\n    If threading is unavailable this function does nothing.\n    \"\"\"\n    if not _thread:\n        return func\n\n    @functools.wraps(func)\n    def decorator(*args):\n        key = threading_setup()\n        try:\n            return func(*args)\n        finally:\n            threading_cleanup(*key)\n    return decorator\n\ndef reap_children():\n    \"\"\"Use this function at the end of test_main() whenever sub-processes\n    are started.  This will help ensure that no extra children (zombies)\n    stick around to hog resources and create problems when looking\n    for refleaks.\n    \"\"\"\n\n    # Reap all our dead child processes so we don't leave zombies around.\n    # These hog resources and might be causing some of the buildbots to die.\n    if hasattr(os, 'waitpid'):\n        any_process = -1\n        while True:\n            try:\n                # This will raise an exception on Windows.  That's ok.\n                pid, status = os.waitpid(any_process, os.WNOHANG)\n                if pid == 0:\n                    break\n            except:\n                break\n\n@contextlib.contextmanager\ndef swap_attr(obj, attr, new_val):\n    \"\"\"Temporary swap out an attribute with a new object.\n\n    Usage:\n        with swap_attr(obj, \"attr\", 5):\n            ...\n\n        This will set obj.attr to 5 for the duration of the with: block,\n        restoring the old value at the end of the block. If `attr` doesn't\n        exist on `obj`, it will be created and then deleted at the end of the\n        block.\n    \"\"\"\n    if hasattr(obj, attr):\n        real_val = getattr(obj, attr)\n        setattr(obj, attr, new_val)\n        try:\n            yield\n        finally:\n            setattr(obj, attr, real_val)\n    else:\n        setattr(obj, attr, new_val)\n        try:\n            yield\n        finally:\n            delattr(obj, attr)\n\n@contextlib.contextmanager\ndef swap_item(obj, item, new_val):\n    \"\"\"Temporary swap out an item with a new object.\n\n    Usage:\n        with swap_item(obj, \"item\", 5):\n            ...\n\n        This will set obj[\"item\"] to 5 for the duration of the with: block,\n        restoring the old value at the end of the block. If `item` doesn't\n        exist on `obj`, it will be created and then deleted at the end of the\n        block.\n    \"\"\"\n    if item in obj:\n        real_val = obj[item]\n        obj[item] = new_val\n        try:\n            yield\n        finally:\n            obj[item] = real_val\n    else:\n        obj[item] = new_val\n        try:\n            yield\n        finally:\n            del obj[item]\n\ndef strip_python_stderr(stderr):\n    \"\"\"Strip the stderr of a Python process from potential debug output\n    emitted by the interpreter.\n\n    This will typically be run on the result of the communicate() method\n    of a subprocess.Popen object.\n    \"\"\"\n    stderr = re.sub(br\"\\[\\d+ refs\\]\\r?\\n?\", b\"\", stderr).strip()\n    return stderr\n\ndef args_from_interpreter_flags():\n    \"\"\"Return a list of command-line arguments reproducing the current\n    settings in sys.flags and sys.warnoptions.\"\"\"\n    return subprocess._args_from_interpreter_flags()\n\n#============================================================\n# Support for assertions about logging.\n#============================================================\n\nclass TestHandler(logging.handlers.BufferingHandler):\n    def __init__(self, matcher):\n        # BufferingHandler takes a \"capacity\" argument\n        # so as to know when to flush. As we're overriding\n        # shouldFlush anyway, we can set a capacity of zero.\n        # You can call flush() manually to clear out the\n        # buffer.\n        logging.handlers.BufferingHandler.__init__(self, 0)\n        self.matcher = matcher\n\n    def shouldFlush(self):\n        return False\n\n    def emit(self, record):\n        self.format(record)\n        self.buffer.append(record.__dict__)\n\n    def matches(self, **kwargs):\n        \"\"\"\n        Look for a saved dict whose keys/values match the supplied arguments.\n        \"\"\"\n        result = False\n        for d in self.buffer:\n            if self.matcher.matches(d, **kwargs):\n                result = True\n                break\n        return result\n\nclass Matcher(object):\n\n    _partial_matches = ('msg', 'message')\n\n    def matches(self, d, **kwargs):\n        \"\"\"\n        Try to match a single dict with the supplied arguments.\n\n        Keys whose values are strings and which are in self._partial_matches\n        will be checked for partial (i.e. substring) matches. You can extend\n        this scheme to (for example) do regular expression matching, etc.\n        \"\"\"\n        result = True\n        for k in kwargs:\n            v = kwargs[k]\n            dv = d.get(k)\n            if not self.match_value(k, dv, v):\n                result = False\n                break\n        return result\n\n    def match_value(self, k, dv, v):\n        \"\"\"\n        Try to match a single stored value (dv) with a supplied value (v).\n        \"\"\"\n        if type(v) != type(dv):\n            result = False\n        elif type(dv) is not str or k not in self._partial_matches:\n            result = (v == dv)\n        else:\n            result = dv.find(v) >= 0\n        return result\n\n\n_can_symlink = None\ndef can_symlink():\n    global _can_symlink\n    if _can_symlink is not None:\n        return _can_symlink\n    symlink_path = TESTFN + \"can_symlink\"\n    try:\n        os.symlink(TESTFN, symlink_path)\n        can = True\n    except (OSError, NotImplementedError, AttributeError):\n        can = False\n    else:\n        os.remove(symlink_path)\n    _can_symlink = can\n    return can\n\ndef skip_unless_symlink(test):\n    \"\"\"Skip decorator for tests that require functional symlink\"\"\"\n    ok = can_symlink()\n    msg = \"Requires functional symlink implementation\"\n    return test if ok else unittest.skip(msg)(test)\n\n_can_xattr = None\ndef can_xattr():\n    global _can_xattr\n    if _can_xattr is not None:\n        return _can_xattr\n    if not hasattr(os, \"setxattr\"):\n        can = False\n    else:\n        tmp_fp, tmp_name = tempfile.mkstemp()\n        try:\n            with open(TESTFN, \"wb\") as fp:\n                try:\n                    # TESTFN & tempfile may use different file systems with\n                    # different capabilities\n                    os.setxattr(tmp_fp, b\"user.test\", b\"\")\n                    os.setxattr(fp.fileno(), b\"user.test\", b\"\")\n                    # Kernels < 2.6.39 don't respect setxattr flags.\n                    kernel_version = platform.release()\n                    m = re.match(\"2.6.(\\d{1,2})\", kernel_version)\n                    can = m is None or int(m.group(1)) >= 39\n                except OSError:\n                    can = False\n        finally:\n            unlink(TESTFN)\n            unlink(tmp_name)\n    _can_xattr = can\n    return can\n\ndef skip_unless_xattr(test):\n    \"\"\"Skip decorator for tests that require functional extended attributes\"\"\"\n    ok = can_xattr()\n    msg = \"no non-broken extended attribute support\"\n    return test if ok else unittest.skip(msg)(test)\n\n\nif sys.platform.startswith('win'):\n    @contextlib.contextmanager\n    def suppress_crash_popup():\n        \"\"\"Disable Windows Error Reporting dialogs using SetErrorMode.\"\"\"\n        # see http://msdn.microsoft.com/en-us/library/windows/desktop/ms680621%28v=vs.85%29.aspx\n        # GetErrorMode is not available on Windows XP and Windows Server 2003,\n        # but SetErrorMode returns the previous value, so we can use that\n        import ctypes\n        k32 = ctypes.windll.kernel32\n        SEM_NOGPFAULTERRORBOX = 0x02\n        old_error_mode = k32.SetErrorMode(SEM_NOGPFAULTERRORBOX)\n        k32.SetErrorMode(old_error_mode | SEM_NOGPFAULTERRORBOX)\n        try:\n            yield\n        finally:\n            k32.SetErrorMode(old_error_mode)\nelse:\n    # this is a no-op for other platforms\n    @contextlib.contextmanager\n    def suppress_crash_popup():\n        yield\n\n\ndef patch(test_instance, object_to_patch, attr_name, new_value):\n    \"\"\"Override 'object_to_patch'.'attr_name' with 'new_value'.\n\n    Also, add a cleanup procedure to 'test_instance' to restore\n    'object_to_patch' value for 'attr_name'.\n    The 'attr_name' should be a valid attribute for 'object_to_patch'.\n\n    \"\"\"\n    # check that 'attr_name' is a real attribute for 'object_to_patch'\n    # will raise AttributeError if it does not exist\n    getattr(object_to_patch, attr_name)\n\n    # keep a copy of the old value\n    attr_is_local = False\n    try:\n        old_value = object_to_patch.__dict__[attr_name]\n    except (AttributeError, KeyError):\n        old_value = getattr(object_to_patch, attr_name, None)\n    else:\n        attr_is_local = True\n\n    # restore the value when the test is done\n    def cleanup():\n        if attr_is_local:\n            setattr(object_to_patch, attr_name, old_value)\n        else:\n            delattr(object_to_patch, attr_name)\n\n    test_instance.addCleanup(cleanup)\n\n    # actually override the attribute\n    setattr(object_to_patch, attr_name, new_value)\n\n"], "xml.sax.xmlreader": [".py", "\"\"\"An XML Reader is the SAX 2 name for an XML parser. XML Parsers\nshould be based on this code. \"\"\"\n\nfrom . import handler\n\nfrom ._exceptions import SAXNotSupportedException, SAXNotRecognizedException\n\n\n# ===== XMLREADER =====\n\nclass XMLReader:\n    \"\"\"Interface for reading an XML document using callbacks.\n\n    XMLReader is the interface that an XML parser's SAX2 driver must\n    implement. This interface allows an application to set and query\n    features and properties in the parser, to register event handlers\n    for document processing, and to initiate a document parse.\n\n    All SAX interfaces are assumed to be synchronous: the parse\n    methods must not return until parsing is complete, and readers\n    must wait for an event-handler callback to return before reporting\n    the next event.\"\"\"\n\n    def __init__(self):\n        self._cont_handler = handler.ContentHandler()\n        self._dtd_handler = handler.DTDHandler()\n        self._ent_handler = handler.EntityResolver()\n        self._err_handler = handler.ErrorHandler()\n\n    def parse(self, source):\n        \"Parse an XML document from a system identifier or an InputSource.\"\n        raise NotImplementedError(\"This method must be implemented!\")\n\n    def getContentHandler(self):\n        \"Returns the current ContentHandler.\"\n        return self._cont_handler\n\n    def setContentHandler(self, handler):\n        \"Registers a new object to receive document content events.\"\n        self._cont_handler = handler\n\n    def getDTDHandler(self):\n        \"Returns the current DTD handler.\"\n        return self._dtd_handler\n\n    def setDTDHandler(self, handler):\n        \"Register an object to receive basic DTD-related events.\"\n        self._dtd_handler = handler\n\n    def getEntityResolver(self):\n        \"Returns the current EntityResolver.\"\n        return self._ent_handler\n\n    def setEntityResolver(self, resolver):\n        \"Register an object to resolve external entities.\"\n        self._ent_handler = resolver\n\n    def getErrorHandler(self):\n        \"Returns the current ErrorHandler.\"\n        return self._err_handler\n\n    def setErrorHandler(self, handler):\n        \"Register an object to receive error-message events.\"\n        self._err_handler = handler\n\n    def setLocale(self, locale):\n        \"\"\"Allow an application to set the locale for errors and warnings.\n\n        SAX parsers are not required to provide localization for errors\n        and warnings; if they cannot support the requested locale,\n        however, they must raise a SAX exception. Applications may\n        request a locale change in the middle of a parse.\"\"\"\n        raise SAXNotSupportedException(\"Locale support not implemented\")\n\n    def getFeature(self, name):\n        \"Looks up and returns the state of a SAX2 feature.\"\n        raise SAXNotRecognizedException(\"Feature '%s' not recognized\" % name)\n\n    def setFeature(self, name, state):\n        \"Sets the state of a SAX2 feature.\"\n        raise SAXNotRecognizedException(\"Feature '%s' not recognized\" % name)\n\n    def getProperty(self, name):\n        \"Looks up and returns the value of a SAX2 property.\"\n        raise SAXNotRecognizedException(\"Property '%s' not recognized\" % name)\n\n    def setProperty(self, name, value):\n        \"Sets the value of a SAX2 property.\"\n        raise SAXNotRecognizedException(\"Property '%s' not recognized\" % name)\n\nclass IncrementalParser(XMLReader):\n    \"\"\"This interface adds three extra methods to the XMLReader\n    interface that allow XML parsers to support incremental\n    parsing. Support for this interface is optional, since not all\n    underlying XML parsers support this functionality.\n\n    When the parser is instantiated it is ready to begin accepting\n    data from the feed method immediately. After parsing has been\n    finished with a call to close the reset method must be called to\n    make the parser ready to accept new data, either from feed or\n    using the parse method.\n\n    Note that these methods must _not_ be called during parsing, that\n    is, after parse has been called and before it returns.\n\n    By default, the class also implements the parse method of the XMLReader\n    interface using the feed, close and reset methods of the\n    IncrementalParser interface as a convenience to SAX 2.0 driver\n    writers.\"\"\"\n\n    def __init__(self, bufsize=2**16):\n        self._bufsize = bufsize\n        XMLReader.__init__(self)\n\n    def parse(self, source):\n        from . import saxutils\n        source = saxutils.prepare_input_source(source)\n\n        self.prepareParser(source)\n        file = source.getByteStream()\n        buffer = file.read(self._bufsize)\n        while buffer:\n            self.feed(buffer)\n            buffer = file.read(self._bufsize)\n        self.close()\n\n    def feed(self, data):\n        \"\"\"This method gives the raw XML data in the data parameter to\n        the parser and makes it parse the data, emitting the\n        corresponding events. It is allowed for XML constructs to be\n        split across several calls to feed.\n\n        feed may raise SAXException.\"\"\"\n        raise NotImplementedError(\"This method must be implemented!\")\n\n    def prepareParser(self, source):\n        \"\"\"This method is called by the parse implementation to allow\n        the SAX 2.0 driver to prepare itself for parsing.\"\"\"\n        raise NotImplementedError(\"prepareParser must be overridden!\")\n\n    def close(self):\n        \"\"\"This method is called when the entire XML document has been\n        passed to the parser through the feed method, to notify the\n        parser that there are no more data. This allows the parser to\n        do the final checks on the document and empty the internal\n        data buffer.\n\n        The parser will not be ready to parse another document until\n        the reset method has been called.\n\n        close may raise SAXException.\"\"\"\n        raise NotImplementedError(\"This method must be implemented!\")\n\n    def reset(self):\n        \"\"\"This method is called after close has been called to reset\n        the parser so that it is ready to parse new documents. The\n        results of calling parse or feed after close without calling\n        reset are undefined.\"\"\"\n        raise NotImplementedError(\"This method must be implemented!\")\n\n# ===== LOCATOR =====\n\nclass Locator:\n    \"\"\"Interface for associating a SAX event with a document\n    location. A locator object will return valid results only during\n    calls to DocumentHandler methods; at any other time, the\n    results are unpredictable.\"\"\"\n\n    def getColumnNumber(self):\n        \"Return the column number where the current event ends.\"\n        return -1\n\n    def getLineNumber(self):\n        \"Return the line number where the current event ends.\"\n        return -1\n\n    def getPublicId(self):\n        \"Return the public identifier for the current event.\"\n        return None\n\n    def getSystemId(self):\n        \"Return the system identifier for the current event.\"\n        return None\n\n# ===== INPUTSOURCE =====\n\nclass InputSource:\n    \"\"\"Encapsulation of the information needed by the XMLReader to\n    read entities.\n\n    This class may include information about the public identifier,\n    system identifier, byte stream (possibly with character encoding\n    information) and/or the character stream of an entity.\n\n    Applications will create objects of this class for use in the\n    XMLReader.parse method and for returning from\n    EntityResolver.resolveEntity.\n\n    An InputSource belongs to the application, the XMLReader is not\n    allowed to modify InputSource objects passed to it from the\n    application, although it may make copies and modify those.\"\"\"\n\n    def __init__(self, system_id = None):\n        self.__system_id = system_id\n        self.__public_id = None\n        self.__encoding  = None\n        self.__bytefile  = None\n        self.__charfile  = None\n\n    def setPublicId(self, public_id):\n        \"Sets the public identifier of this InputSource.\"\n        self.__public_id = public_id\n\n    def getPublicId(self):\n        \"Returns the public identifier of this InputSource.\"\n        return self.__public_id\n\n    def setSystemId(self, system_id):\n        \"Sets the system identifier of this InputSource.\"\n        self.__system_id = system_id\n\n    def getSystemId(self):\n        \"Returns the system identifier of this InputSource.\"\n        return self.__system_id\n\n    def setEncoding(self, encoding):\n        \"\"\"Sets the character encoding of this InputSource.\n\n        The encoding must be a string acceptable for an XML encoding\n        declaration (see section 4.3.3 of the XML recommendation).\n\n        The encoding attribute of the InputSource is ignored if the\n        InputSource also contains a character stream.\"\"\"\n        self.__encoding = encoding\n\n    def getEncoding(self):\n        \"Get the character encoding of this InputSource.\"\n        return self.__encoding\n\n    def setByteStream(self, bytefile):\n        \"\"\"Set the byte stream (a Python file-like object which does\n        not perform byte-to-character conversion) for this input\n        source.\n\n        The SAX parser will ignore this if there is also a character\n        stream specified, but it will use a byte stream in preference\n        to opening a URI connection itself.\n\n        If the application knows the character encoding of the byte\n        stream, it should set it with the setEncoding method.\"\"\"\n        self.__bytefile = bytefile\n\n    def getByteStream(self):\n        \"\"\"Get the byte stream for this input source.\n\n        The getEncoding method will return the character encoding for\n        this byte stream, or None if unknown.\"\"\"\n        return self.__bytefile\n\n    def setCharacterStream(self, charfile):\n        \"\"\"Set the character stream for this input source. (The stream\n        must be a Python 2.0 Unicode-wrapped file-like that performs\n        conversion to Unicode strings.)\n\n        If there is a character stream specified, the SAX parser will\n        ignore any byte stream and will not attempt to open a URI\n        connection to the system identifier.\"\"\"\n        self.__charfile = charfile\n\n    def getCharacterStream(self):\n        \"Get the character stream for this input source.\"\n        return self.__charfile\n\n# ===== ATTRIBUTESIMPL =====\n\nclass AttributesImpl:\n\n    def __init__(self, attrs):\n        \"\"\"Non-NS-aware implementation.\n\n        attrs should be of the form {name : value}.\"\"\"\n        self._attrs = attrs\n\n    def getLength(self):\n        return len(self._attrs)\n\n    def getType(self, name):\n        return \"CDATA\"\n\n    def getValue(self, name):\n        return self._attrs[name]\n\n    def getValueByQName(self, name):\n        return self._attrs[name]\n\n    def getNameByQName(self, name):\n        if name not in self._attrs:\n            raise KeyError(name)\n        return name\n\n    def getQNameByName(self, name):\n        if name not in self._attrs:\n            raise KeyError(name)\n        return name\n\n    def getNames(self):\n        return list(self._attrs.keys())\n\n    def getQNames(self):\n        return list(self._attrs.keys())\n\n    def __len__(self):\n        return len(self._attrs)\n\n    def __getitem__(self, name):\n        return self._attrs[name]\n\n    def keys(self):\n        return list(self._attrs.keys())\n\n    def __contains__(self, name):\n        return name in self._attrs\n\n    def get(self, name, alternative=None):\n        return self._attrs.get(name, alternative)\n\n    def copy(self):\n        return self.__class__(self._attrs)\n\n    def items(self):\n        return list(self._attrs.items())\n\n    def values(self):\n        return list(self._attrs.values())\n\n# ===== ATTRIBUTESNSIMPL =====\n\nclass AttributesNSImpl(AttributesImpl):\n\n    def __init__(self, attrs, qnames):\n        \"\"\"NS-aware implementation.\n\n        attrs should be of the form {(ns_uri, lname): value, ...}.\n        qnames of the form {(ns_uri, lname): qname, ...}.\"\"\"\n        self._attrs = attrs\n        self._qnames = qnames\n\n    def getValueByQName(self, name):\n        for (nsname, qname) in self._qnames.items():\n            if qname == name:\n                return self._attrs[nsname]\n\n        raise KeyError(name)\n\n    def getNameByQName(self, name):\n        for (nsname, qname) in self._qnames.items():\n            if qname == name:\n                return nsname\n\n        raise KeyError(name)\n\n    def getQNameByName(self, name):\n        return self._qnames[name]\n\n    def getQNames(self):\n        return list(self._qnames.values())\n\n    def copy(self):\n        return self.__class__(self._attrs, self._qnames)\n\n\ndef _test():\n    XMLReader()\n    IncrementalParser()\n    Locator()\n\nif __name__ == \"__main__\":\n    _test()\n"], "unittest.test.dummy": [".py", "# Empty module for testing the loading of modules\n"], "operator": [".py", "#!/usr/bin/env python3\n\"\"\"\nOperator Interface\n\nThis module exports a set of functions corresponding to the intrinsic \noperators of Python.  For example, operator.add(x, y) is equivalent \nto the expression x+y.  The function names are those used for special \nmethods; variants without leading and trailing '__' are also provided \nfor convenience.\n\nThis is the pure Python implementation of the module.\n\"\"\"\n\n# downloaded from http://bugs.python.org/file28327/operator.py\n\n#import builtins as _bi  #there is no builtins module\n\ndef lt(a, b):\n    \"Same as a < b.\"\n    return a < b\n__lt__ = lt\n\ndef le(a, b):\n    \"Same as a <= b.\"\n    return a <= b\n__le__ = le\n\ndef eq(a, b):\n    \"Same as a == b.\"\n    return a == b\n__eq__ = eq\n\ndef ne(a, b):\n    \"Same as a != b.\"\n    return a != b\n__ne__ = ne\n\ndef ge(a, b):\n    \"Same as a >= b.\"\n    return a >= b\n__ge__ = ge\n\ndef gt(a, b):\n    \"Same as a > b.\"\n    return a > b\n__gt__ = gt\n\ndef not_(a):\n    \"Same as not a.\"\n    return not a\n__not__ = not_\n\ndef truth(a):\n    \"Return True if a is true, False otherwise.\"\n    #return _bi.bool(a)\n    return bool(a)\n\ndef is_(a, b):\n    \"Same as a is b.\"\n    return a is b\n\n# brython does not like  (causes syntax error)\n#def is_not(a, b):\n#    \"Same as a is not b.\"\n#    return a is not b\n\n#recursion error or just comment out and add code below function\n#def abs(a):\n#    \"Same as abs(a).\"\n#    #return _bi.abs(a)\n#    return abs(a)\n__abs__ = abs\nabs=abs\n\n\ndef add(a, b):\n    \"Same as a + b.\"\n    return a + b\n__add__ = add\n\ndef and_(a, b):\n    \"Same as a & b.\"\n    return a & b\n__and__ = and_\n\ndef floordiv(a, b):\n    \"Same as a // b.\"\n    return a // b\n__floordiv__ = floordiv\n\ndef index(a):\n    \"Same as a.__index__().\"\n    return a.__index__()\n__index__ = index\n\ndef inv(a):\n    \"Same as ~a.\"\n    return ~a    #brython does not like\n    #return a^(2**31)\ninvert = __inv__ = __invert__ = inv\n\ndef lshift(a, b):\n    \"Same as a << b.\"\n    return a << b\n__lshift__ = lshift\n\ndef mod(a, b):\n    \"Same as a % b.\"\n    return a % b\n__mod__ = mod\n\ndef mul(a, b):\n    \"Same as a * b.\"\n    return a * b\n__mul__ = mul\n\ndef neg(a):\n    \"Same as -a.\"\n    return -a\n__neg__ = neg\n\ndef or_(a, b):\n    \"Same as a | b.\"\n    return a | b\n__or__ = or_\n\ndef pos(a):\n    \"Same as +a.\"\n    return +a    #brython does not like\n    if a >= 0: return a\n    return -a\n__pos__ = pos\n\ndef pow(a, b):\n    \"Same as a ** b.\"\n    return a ** b\n__pow__ = pow\n\ndef rshift(a, b):\n    \"Same as a >> b.\"\n    return a >> b\n__rshift__ = rshift\n\ndef sub(a, b):\n    \"Same as a - b.\"\n    return a - b\n__sub__ = sub\n\ndef truediv(a, b):\n    \"Same as a / b.\"\n    return a / b\n__truediv__ = truediv\n\ndef xor(a, b):\n    \"Same as a ^ b.\"\n    return a ^ b\n__xor__ = xor\n\ndef concat(a, b):\n    \"Same as a + b, for a and b sequences.\"\n    if not (hasattr(a, '__getitem__') and hasattr(b, '__getitem__')):\n        raise TypeError('a and b must be sequences')\n    return a + b\n__concat__ = concat\n\ndef contains(a, b):\n    \"Same as b in a (note reversed operands).\"\n    return b in a\n__contains__ = contains\n\ndef countOf(a, b):\n    \"Return the number of times b occurs in a.\"\n    count = 0\n    for i in a:\n        if i == b:\n            count += 1\n    return count\n\ndef delitem(a, b):\n    \"Same as del a[b].\"\n    del a[b]\n__delitem__ = delitem\n\ndef getitem(a, b):\n    \"Same as a[b].\"\n    return a[b]\n__getitem__ = getitem\n\n#fixme  brython doesn't like this function\ndef indexOf(a, b):\n    \"Return the first index of b in a.\"\n    #for i, j in _bi.enumerate(a):\n    for i, j in enumerate(a):\n        if j == b:\n            return i\n    else:\n        raise ValueError('b not found in a')\n\ndef setitem(a, b, c):\n    \"Same as a[b] = c.\"\n    a[b] = c\n__setitem__ = setitem\n\n\n\nclass attrgetter:\n    \"\"\"\n    Return a callable object that fetches the given attribute(s) from its operand.\n    After f=attrgetter('name'), the call f(r) returns r.name.\n    After g=attrgetter('name', 'date'), the call g(r) returns (r.name, r.date).\n    After h=attrgetter('name.first', 'name.last'), the call h(r) returns\n    (r.name.first, r.name.last).\n    \"\"\"\n    def __init__(self, attr, *attrs):\n        self._attrs = (attr,)\n        self._attrs += attrs\n        if any(not isinstance(attr, str) for attr in self._attrs):\n            raise TypeError('attribute name must be a string')\n\n    @staticmethod\n    def _resolve_attr(obj, attr):\n        for name in attr.split('.'):\n            #obj = _bi.getattr(obj, name)\n            obj = getattr(obj, name)\n        return obj\n\n    def __call__(self, obj):\n        if len(self._attrs) == 1:\n            return self._resolve_attr(obj, self._attrs[0])\n        return tuple(self._resolve_attr(obj, attr) for attr in self._attrs)\n\nclass itemgetter:\n    \"\"\"\n    Return a callable object that fetches the given item(s) from its operand.\n    After f=itemgetter(2), the call f(r) returns r[2].\n    After g=itemgetter(2,5,3), the call g(r) returns (r[2], r[5], r[3])\n    \"\"\"\n    def __init__(self, item, *items):\n        self._items = (item,)\n        self._items += items\n\n    def __call__(self, obj):\n        if len(self._items) == 1:\n            return obj[self._items[0]]\n        return tuple(obj[item] for item in self._items)\n\nclass methodcaller:\n    \"\"\"\n    Return a callable object that calls the given method on its operand.\n    After f = methodcaller('name'), the call f(r) returns r.name().\n    After g = methodcaller('name', 'date', foo=1), the call g(r) returns\n    r.name('date', foo=1).\n    \"\"\"\n\n    def __init__(self, name, *args, **kwargs):\n        self._name = name\n        self._args = args\n        self._kwargs = kwargs\n\n    def __call__(self, obj):\n        return getattr(obj, self._name)(*self._args, **self._kwargs)\n\n\ndef iadd(a, b):\n    \"Same as a += b.\"\n    a += b\n    return a\n__iadd__ = iadd\n\ndef iand(a, b):\n    \"Same as a &= b.\"\n    a &= b\n    return a\n__iand__ = iand\n\ndef iconcat(a, b):\n    \"Same as a += b, for a and b sequences.\"\n    if not (hasattr(a, '__getitem__') and hasattr(b, '__getitem__')):\n        raise TypeError('a and b must be sequences')\n    a += b\n    return a\n__iconcat__ = iconcat\n\ndef ifloordiv(a, b):\n    \"Same as a //= b.\"\n    a //= b\n    return a\n__ifloordiv__ = ifloordiv\n\ndef ilshift(a, b):\n    \"Same as a <<= b.\"\n    a <<= b\n    return a\n__ilshift__ = ilshift\n\ndef imod(a, b):\n    \"Same as a %= b.\"\n    a %= b\n    return a\n__imod__ = imod\n\ndef imul(a, b):\n    \"Same as a *= b.\"\n    a *= b\n    return a\n__imul__ = imul\n\ndef ior(a, b):\n    \"Same as a |= b.\"\n    a |= b\n    return a\n__ior__ = ior\n\ndef ipow(a, b):\n    \"Same as a **= b.\"\n    a **=b\n    return a\n__ipow__ = ipow\n\ndef irshift(a, b):\n    \"Same as a >>= b.\"\n    a >>= b\n    return a\n__irshift__ = irshift\n\ndef isub(a, b):\n    \"Same as a -= b.\"\n    a -= b\n    return a\n__isub__ = isub\n\ndef itruediv(a, b):\n    \"Same as a /= b.\"\n    a /= b\n    return a\n__itruediv__ = itruediv\n\ndef ixor(a, b):\n    \"Same as a ^= b.\"\n    a ^= b\n    return a\n__ixor__ = ixor\n\ndef length_hint(obj, default=0):\n    \"\"\"\n    Return an estimate of the number of items in obj.\n    This is useful for presizing containers when building from an iterable.\n\n    If the object supports len(), the result will be exact. Otherwise, it may\n    over- or under-estimate by an arbitrary amount. The result will be an\n    integer >= 0.\n    \"\"\"\n    try:\n        return len(obj)\n    except TypeError:\n        try:\n            val = obj.__length_hint__()\n            if val is NotImplemented:\n                raise TypeError\n        except (AttributeError, TypeError):\n            return default\n        else:\n            if not val > 0:\n                raise ValueError('default must be > 0')\n            return val\n\n#try:\n#    from _operator import *\n#    from _operator import __doc__\n#except ImportError:\n#   pass\n"], "xml.dom.pulldom": [".py", "import xml.sax\nimport xml.sax.handler\n\nSTART_ELEMENT = \"START_ELEMENT\"\nEND_ELEMENT = \"END_ELEMENT\"\nCOMMENT = \"COMMENT\"\nSTART_DOCUMENT = \"START_DOCUMENT\"\nEND_DOCUMENT = \"END_DOCUMENT\"\nPROCESSING_INSTRUCTION = \"PROCESSING_INSTRUCTION\"\nIGNORABLE_WHITESPACE = \"IGNORABLE_WHITESPACE\"\nCHARACTERS = \"CHARACTERS\"\n\nclass PullDOM(xml.sax.ContentHandler):\n    _locator = None\n    document = None\n\n    def __init__(self, documentFactory=None):\n        from xml.dom import XML_NAMESPACE\n        self.documentFactory = documentFactory\n        self.firstEvent = [None, None]\n        self.lastEvent = self.firstEvent\n        self.elementStack = []\n        self.push = self.elementStack.append\n        try:\n            self.pop = self.elementStack.pop\n        except AttributeError:\n            # use class' pop instead\n            pass\n        self._ns_contexts = [{XML_NAMESPACE:'xml'}] # contains uri -> prefix dicts\n        self._current_context = self._ns_contexts[-1]\n        self.pending_events = []\n\n    def pop(self):\n        result = self.elementStack[-1]\n        del self.elementStack[-1]\n        return result\n\n    def setDocumentLocator(self, locator):\n        self._locator = locator\n\n    def startPrefixMapping(self, prefix, uri):\n        if not hasattr(self, '_xmlns_attrs'):\n            self._xmlns_attrs = []\n        self._xmlns_attrs.append((prefix or 'xmlns', uri))\n        self._ns_contexts.append(self._current_context.copy())\n        self._current_context[uri] = prefix or None\n\n    def endPrefixMapping(self, prefix):\n        self._current_context = self._ns_contexts.pop()\n\n    def startElementNS(self, name, tagName , attrs):\n        # Retrieve xml namespace declaration attributes.\n        xmlns_uri = 'http://www.w3.org/2000/xmlns/'\n        xmlns_attrs = getattr(self, '_xmlns_attrs', None)\n        if xmlns_attrs is not None:\n            for aname, value in xmlns_attrs:\n                attrs._attrs[(xmlns_uri, aname)] = value\n            self._xmlns_attrs = []\n        uri, localname = name\n        if uri:\n            # When using namespaces, the reader may or may not\n            # provide us with the original name. If not, create\n            # *a* valid tagName from the current context.\n            if tagName is None:\n                prefix = self._current_context[uri]\n                if prefix:\n                    tagName = prefix + \":\" + localname\n                else:\n                    tagName = localname\n            if self.document:\n                node = self.document.createElementNS(uri, tagName)\n            else:\n                node = self.buildDocument(uri, tagName)\n        else:\n            # When the tagname is not prefixed, it just appears as\n            # localname\n            if self.document:\n                node = self.document.createElement(localname)\n            else:\n                node = self.buildDocument(None, localname)\n\n        for aname,value in attrs.items():\n            a_uri, a_localname = aname\n            if a_uri == xmlns_uri:\n                if a_localname == 'xmlns':\n                    qname = a_localname\n                else:\n                    qname = 'xmlns:' + a_localname\n                attr = self.document.createAttributeNS(a_uri, qname)\n                node.setAttributeNodeNS(attr)\n            elif a_uri:\n                prefix = self._current_context[a_uri]\n                if prefix:\n                    qname = prefix + \":\" + a_localname\n                else:\n                    qname = a_localname\n                attr = self.document.createAttributeNS(a_uri, qname)\n                node.setAttributeNodeNS(attr)\n            else:\n                attr = self.document.createAttribute(a_localname)\n                node.setAttributeNode(attr)\n            attr.value = value\n\n        self.lastEvent[1] = [(START_ELEMENT, node), None]\n        self.lastEvent = self.lastEvent[1]\n        self.push(node)\n\n    def endElementNS(self, name, tagName):\n        self.lastEvent[1] = [(END_ELEMENT, self.pop()), None]\n        self.lastEvent = self.lastEvent[1]\n\n    def startElement(self, name, attrs):\n        if self.document:\n            node = self.document.createElement(name)\n        else:\n            node = self.buildDocument(None, name)\n\n        for aname,value in attrs.items():\n            attr = self.document.createAttribute(aname)\n            attr.value = value\n            node.setAttributeNode(attr)\n\n        self.lastEvent[1] = [(START_ELEMENT, node), None]\n        self.lastEvent = self.lastEvent[1]\n        self.push(node)\n\n    def endElement(self, name):\n        self.lastEvent[1] = [(END_ELEMENT, self.pop()), None]\n        self.lastEvent = self.lastEvent[1]\n\n    def comment(self, s):\n        if self.document:\n            node = self.document.createComment(s)\n            self.lastEvent[1] = [(COMMENT, node), None]\n            self.lastEvent = self.lastEvent[1]\n        else:\n            event = [(COMMENT, s), None]\n            self.pending_events.append(event)\n\n    def processingInstruction(self, target, data):\n        if self.document:\n            node = self.document.createProcessingInstruction(target, data)\n            self.lastEvent[1] = [(PROCESSING_INSTRUCTION, node), None]\n            self.lastEvent = self.lastEvent[1]\n        else:\n            event = [(PROCESSING_INSTRUCTION, target, data), None]\n            self.pending_events.append(event)\n\n    def ignorableWhitespace(self, chars):\n        node = self.document.createTextNode(chars)\n        self.lastEvent[1] = [(IGNORABLE_WHITESPACE, node), None]\n        self.lastEvent = self.lastEvent[1]\n\n    def characters(self, chars):\n        node = self.document.createTextNode(chars)\n        self.lastEvent[1] = [(CHARACTERS, node), None]\n        self.lastEvent = self.lastEvent[1]\n\n    def startDocument(self):\n        if self.documentFactory is None:\n            import xml.dom.minidom\n            self.documentFactory = xml.dom.minidom.Document.implementation\n\n    def buildDocument(self, uri, tagname):\n        # Can't do that in startDocument, since we need the tagname\n        # XXX: obtain DocumentType\n        node = self.documentFactory.createDocument(uri, tagname, None)\n        self.document = node\n        self.lastEvent[1] = [(START_DOCUMENT, node), None]\n        self.lastEvent = self.lastEvent[1]\n        self.push(node)\n        # Put everything we have seen so far into the document\n        for e in self.pending_events:\n            if e[0][0] == PROCESSING_INSTRUCTION:\n                _,target,data = e[0]\n                n = self.document.createProcessingInstruction(target, data)\n                e[0] = (PROCESSING_INSTRUCTION, n)\n            elif e[0][0] == COMMENT:\n                n = self.document.createComment(e[0][1])\n                e[0] = (COMMENT, n)\n            else:\n                raise AssertionError(\"Unknown pending event \",e[0][0])\n            self.lastEvent[1] = e\n            self.lastEvent = e\n        self.pending_events = None\n        return node.firstChild\n\n    def endDocument(self):\n        self.lastEvent[1] = [(END_DOCUMENT, self.document), None]\n        self.pop()\n\n    def clear(self):\n        \"clear(): Explicitly release parsing structures\"\n        self.document = None\n\nclass ErrorHandler:\n    def warning(self, exception):\n        print(exception)\n    def error(self, exception):\n        raise exception\n    def fatalError(self, exception):\n        raise exception\n\nclass DOMEventStream:\n    def __init__(self, stream, parser, bufsize):\n        self.stream = stream\n        self.parser = parser\n        self.bufsize = bufsize\n        if not hasattr(self.parser, 'feed'):\n            self.getEvent = self._slurp\n        self.reset()\n\n    def reset(self):\n        self.pulldom = PullDOM()\n        # This content handler relies on namespace support\n        self.parser.setFeature(xml.sax.handler.feature_namespaces, 1)\n        self.parser.setContentHandler(self.pulldom)\n\n    def __getitem__(self, pos):\n        rc = self.getEvent()\n        if rc:\n            return rc\n        raise IndexError\n\n    def __next__(self):\n        rc = self.getEvent()\n        if rc:\n            return rc\n        raise StopIteration\n\n    def __iter__(self):\n        return self\n\n    def expandNode(self, node):\n        event = self.getEvent()\n        parents = [node]\n        while event:\n            token, cur_node = event\n            if cur_node is node:\n                return\n            if token != END_ELEMENT:\n                parents[-1].appendChild(cur_node)\n            if token == START_ELEMENT:\n                parents.append(cur_node)\n            elif token == END_ELEMENT:\n                del parents[-1]\n            event = self.getEvent()\n\n    def getEvent(self):\n        # use IncrementalParser interface, so we get the desired\n        # pull effect\n        if not self.pulldom.firstEvent[1]:\n            self.pulldom.lastEvent = self.pulldom.firstEvent\n        while not self.pulldom.firstEvent[1]:\n            buf = self.stream.read(self.bufsize)\n            if not buf:\n                self.parser.close()\n                return None\n            self.parser.feed(buf)\n        rc = self.pulldom.firstEvent[1][0]\n        self.pulldom.firstEvent[1] = self.pulldom.firstEvent[1][1]\n        return rc\n\n    def _slurp(self):\n        \"\"\" Fallback replacement for getEvent() using the\n            standard SAX2 interface, which means we slurp the\n            SAX events into memory (no performance gain, but\n            we are compatible to all SAX parsers).\n        \"\"\"\n        self.parser.parse(self.stream)\n        self.getEvent = self._emit\n        return self._emit()\n\n    def _emit(self):\n        \"\"\" Fallback replacement for getEvent() that emits\n            the events that _slurp() read previously.\n        \"\"\"\n        rc = self.pulldom.firstEvent[1][0]\n        self.pulldom.firstEvent[1] = self.pulldom.firstEvent[1][1]\n        return rc\n\n    def clear(self):\n        \"\"\"clear(): Explicitly release parsing objects\"\"\"\n        self.pulldom.clear()\n        del self.pulldom\n        self.parser = None\n        self.stream = None\n\nclass SAX2DOM(PullDOM):\n\n    def startElementNS(self, name, tagName , attrs):\n        PullDOM.startElementNS(self, name, tagName, attrs)\n        curNode = self.elementStack[-1]\n        parentNode = self.elementStack[-2]\n        parentNode.appendChild(curNode)\n\n    def startElement(self, name, attrs):\n        PullDOM.startElement(self, name, attrs)\n        curNode = self.elementStack[-1]\n        parentNode = self.elementStack[-2]\n        parentNode.appendChild(curNode)\n\n    def processingInstruction(self, target, data):\n        PullDOM.processingInstruction(self, target, data)\n        node = self.lastEvent[0][1]\n        parentNode = self.elementStack[-1]\n        parentNode.appendChild(node)\n\n    def ignorableWhitespace(self, chars):\n        PullDOM.ignorableWhitespace(self, chars)\n        node = self.lastEvent[0][1]\n        parentNode = self.elementStack[-1]\n        parentNode.appendChild(node)\n\n    def characters(self, chars):\n        PullDOM.characters(self, chars)\n        node = self.lastEvent[0][1]\n        parentNode = self.elementStack[-1]\n        parentNode.appendChild(node)\n\n\ndefault_bufsize = (2 ** 14) - 20\n\ndef parse(stream_or_string, parser=None, bufsize=None):\n    if bufsize is None:\n        bufsize = default_bufsize\n    if isinstance(stream_or_string, str):\n        stream = open(stream_or_string, 'rb')\n    else:\n        stream = stream_or_string\n    if not parser:\n        parser = xml.sax.make_parser()\n    return DOMEventStream(stream, parser, bufsize)\n\ndef parseString(string, parser=None):\n    from io import StringIO\n\n    bufsize = len(string)\n    buf = StringIO(string)\n    if not parser:\n        parser = xml.sax.make_parser()\n    return DOMEventStream(buf, parser, bufsize)\n"], "select": [".py", "\"\"\"\nborrowed from jython\nhttps://bitbucket.org/jython/jython/raw/28a66ba038620292520470a0bb4dc9bb8ac2e403/Lib/select.py\n\"\"\"\n\n#import java.nio.channels.SelectableChannel\n#import java.nio.channels.SelectionKey\n#import java.nio.channels.Selector\n#from java.nio.channels.SelectionKey import OP_ACCEPT, OP_CONNECT, OP_WRITE, OP_READ\n\nimport errno\nimport os\nimport queue\nimport socket\n\nclass error(Exception): pass\n\nALL = None\n\n_exception_map = {\n\n# (<javaexception>, <circumstance>) : lambda: <code that raises the python equivalent>\n\n#(java.nio.channels.ClosedChannelException, ALL) : error(errno.ENOTCONN, 'Socket is not connected'),\n#(java.nio.channels.CancelledKeyException, ALL) : error(errno.ENOTCONN, 'Socket is not connected'),\n#(java.nio.channels.IllegalBlockingModeException, ALL) : error(errno.ESOCKISBLOCKING, 'socket must be in non-blocking mode'),\n}\n\ndef _map_exception(exc, circumstance=ALL):\n    try:\n        mapped_exception = _exception_map[(exc.__class__, circumstance)]\n        mapped_exception.java_exception = exc\n        return mapped_exception\n    except KeyError:\n        return error(-1, 'Unmapped java exception: <%s:%s>' % (exc.toString(), circumstance))\n\nPOLLIN   = 1\nPOLLOUT  = 2\n\n# The following event types are completely ignored on jython\n# Java does not support them, AFAICT\n# They are declared only to support code compatibility with cpython\n\nPOLLPRI  = 4\nPOLLERR  = 8\nPOLLHUP  = 16\nPOLLNVAL = 32\n\ndef _getselectable(selectable_object):\n    try:\n        channel = selectable_object.getchannel()\n    except:\n        try:\n            channel = selectable_object.fileno().getChannel()\n        except:\n            raise TypeError(\"Object '%s' is not watchable\" % selectable_object,\n                            errno.ENOTSOCK)\n    \n    if channel and not isinstance(channel, java.nio.channels.SelectableChannel):\n        raise TypeError(\"Object '%s' is not watchable\" % selectable_object,\n                        errno.ENOTSOCK)\n    return channel\n\nclass poll:\n\n    def __init__(self):\n        self.selector = java.nio.channels.Selector.open()\n        self.chanmap = {}\n        self.unconnected_sockets = []\n\n    def _register_channel(self, socket_object, channel, mask):\n        jmask = 0\n        if mask & POLLIN:\n            # Note that OP_READ is NOT a valid event on server socket channels.\n            if channel.validOps() & OP_ACCEPT:\n                jmask = OP_ACCEPT\n            else:\n                jmask = OP_READ\n        if mask & POLLOUT:\n            if channel.validOps() & OP_WRITE:\n                jmask |= OP_WRITE\n            if channel.validOps() & OP_CONNECT:\n                jmask |= OP_CONNECT\n        selectionkey = channel.register(self.selector, jmask)\n        self.chanmap[channel] = (socket_object, selectionkey)\n\n    def _check_unconnected_sockets(self):\n        temp_list = []\n        for socket_object, mask in self.unconnected_sockets:\n            channel = _getselectable(socket_object)\n            if channel is not None:\n                self._register_channel(socket_object, channel, mask)\n            else:\n                temp_list.append( (socket_object, mask) )\n        self.unconnected_sockets = temp_list\n\n    def register(self, socket_object, mask = POLLIN|POLLOUT|POLLPRI):\n        try:\n            channel = _getselectable(socket_object)\n            if channel is None:\n                # The socket is not yet connected, and thus has no channel\n                # Add it to a pending list, and return\n                self.unconnected_sockets.append( (socket_object, mask) )\n                return\n            self._register_channel(socket_object, channel, mask)\n        except BaseException:\n        #except java.lang.Exception, jlx:\n            raise _map_exception(jlx)\n\n    def unregister(self, socket_object):\n        try:\n            channel = _getselectable(socket_object)\n            self.chanmap[channel][1].cancel()\n            del self.chanmap[channel]\n        except BaseException:\n        #except java.lang.Exception, jlx:\n            raise _map_exception(jlx)\n\n    def _dopoll(self, timeout):\n        if timeout is None or timeout < 0:\n            self.selector.select()\n        else:\n            try:\n                timeout = int(timeout)\n                if not timeout:\n                    self.selector.selectNow()\n                else:\n                    # No multiplication required: both cpython and java use millisecond timeouts\n                    self.selector.select(timeout)\n            except ValueError as vx:\n                raise error(\"poll timeout must be a number of milliseconds or None\", errno.EINVAL)\n        # The returned selectedKeys cannot be used from multiple threads!\n        return self.selector.selectedKeys()\n\n    def poll(self, timeout=None):\n        try:\n            self._check_unconnected_sockets()\n            selectedkeys = self._dopoll(timeout)\n            results = []\n            for k in selectedkeys.iterator():\n                jmask = k.readyOps()\n                pymask = 0\n                if jmask & OP_READ: pymask |= POLLIN\n                if jmask & OP_WRITE: pymask |= POLLOUT\n                if jmask & OP_ACCEPT: pymask |= POLLIN\n                if jmask & OP_CONNECT: pymask |= POLLOUT\n                # Now return the original userobject, and the return event mask\n                results.append( (self.chanmap[k.channel()][0], pymask) )\n            return results\n        except BaseException:\n        #except java.lang.Exception, jlx:\n            raise _map_exception(jlx)\n\n    def _deregister_all(self):\n        try:\n            for k in self.selector.keys():\n                k.cancel()\n            # Keys are not actually removed from the selector until the next select operation.\n            self.selector.selectNow()\n        except BaseException:\n        #except java.lang.Exception, jlx:\n            raise _map_exception(jlx)\n\n    def close(self):\n        try:\n            self._deregister_all()\n            self.selector.close()\n        except BaseException:\n        #except java.lang.Exception, jlx:\n            raise _map_exception(jlx)\n\ndef _calcselecttimeoutvalue(value):\n    if value is None:\n        return None\n    try:\n        floatvalue = float(value)\n    except Exception as x:\n        raise TypeError(\"Select timeout value must be a number or None\")\n    if value < 0:\n        raise error(\"Select timeout value cannot be negative\", errno.EINVAL)\n    if floatvalue < 0.000001:\n        return 0\n    return int(floatvalue * 1000) # Convert to milliseconds\n\n# This cache for poll objects is required because of a bug in java on MS Windows\n# http://bugs.jython.org/issue1291\n\nclass poll_object_cache:\n\n    def __init__(self):\n        self.is_windows = os.name == 'nt'\n        if self.is_windows:\n            self.poll_object_queue = Queue.Queue()\n        import atexit\n        atexit.register(self.finalize)\n\n    def get_poll_object(self):\n        if not self.is_windows:\n            return poll()\n        try:\n            return self.poll_object_queue.get(False)\n        except Queue.Empty:\n            return poll()\n\n    def release_poll_object(self, pobj):\n        if self.is_windows:\n            pobj._deregister_all()\n            self.poll_object_queue.put(pobj)\n        else:\n            pobj.close()\n\n    def finalize(self):\n        if self.is_windows:\n            while True:\n                try:\n                    p = self.poll_object_queue.get(False)\n                    p.close()\n                except Queue.Empty:\n                    return\n\n_poll_object_cache = poll_object_cache()\n\ndef native_select(read_fd_list, write_fd_list, outofband_fd_list, timeout=None):\n    timeout = _calcselecttimeoutvalue(timeout)\n    # First create a poll object to do the actual watching.\n    pobj = _poll_object_cache.get_poll_object()\n    try:\n        registered_for_read = {}\n        # Check the read list\n        for fd in read_fd_list:\n            pobj.register(fd, POLLIN)\n            registered_for_read[fd] = 1\n        # And now the write list\n        for fd in write_fd_list:\n            if fd in registered_for_read:\n                # registering a second time overwrites the first\n                pobj.register(fd, POLLIN|POLLOUT)\n            else:\n                pobj.register(fd, POLLOUT)\n        results = pobj.poll(timeout)\n        # Now start preparing the results\n        read_ready_list, write_ready_list, oob_ready_list = [], [], []\n        for fd, mask in results:\n            if mask & POLLIN:\n                read_ready_list.append(fd)\n            if mask & POLLOUT:\n                write_ready_list.append(fd)\n        return read_ready_list, write_ready_list, oob_ready_list\n    finally:\n        _poll_object_cache.release_poll_object(pobj)\n\nselect = native_select\n\ndef cpython_compatible_select(read_fd_list, write_fd_list, outofband_fd_list, timeout=None):\n    # First turn all sockets to non-blocking\n    # keeping track of which ones have changed\n    modified_channels = []\n    try:\n        for socket_list in [read_fd_list, write_fd_list, outofband_fd_list]:\n            for s in socket_list:\n                channel = _getselectable(s)\n                if channel.isBlocking():\n                    modified_channels.append(channel)\n                    channel.configureBlocking(0)\n        return native_select(read_fd_list, write_fd_list, outofband_fd_list, timeout)\n    finally:\n        for channel in modified_channels:\n            channel.configureBlocking(1)\n"], "unittest.test.testmock.testwith": [".py", "import unittest\nfrom warnings import catch_warnings\n\nfrom unittest.test.testmock.support import is_instance\nfrom unittest.mock import MagicMock, Mock, patch, sentinel, mock_open, call\n\n\n\nsomething  = sentinel.Something\nsomething_else  = sentinel.SomethingElse\n\n\n\nclass WithTest(unittest.TestCase):\n\n    def test_with_statement(self):\n        with patch('%s.something' % __name__, sentinel.Something2):\n            self.assertEqual(something, sentinel.Something2, \"unpatched\")\n        self.assertEqual(something, sentinel.Something)\n\n\n    def test_with_statement_exception(self):\n        try:\n            with patch('%s.something' % __name__, sentinel.Something2):\n                self.assertEqual(something, sentinel.Something2, \"unpatched\")\n                raise Exception('pow')\n        except Exception:\n            pass\n        else:\n            self.fail(\"patch swallowed exception\")\n        self.assertEqual(something, sentinel.Something)\n\n\n    def test_with_statement_as(self):\n        with patch('%s.something' % __name__) as mock_something:\n            self.assertEqual(something, mock_something, \"unpatched\")\n            self.assertTrue(is_instance(mock_something, MagicMock),\n                            \"patching wrong type\")\n        self.assertEqual(something, sentinel.Something)\n\n\n    def test_patch_object_with_statement(self):\n        class Foo(object):\n            something = 'foo'\n        original = Foo.something\n        with patch.object(Foo, 'something'):\n            self.assertNotEqual(Foo.something, original, \"unpatched\")\n        self.assertEqual(Foo.something, original)\n\n\n    def test_with_statement_nested(self):\n        with catch_warnings(record=True):\n            with patch('%s.something' % __name__) as mock_something, patch('%s.something_else' % __name__) as mock_something_else:\n                self.assertEqual(something, mock_something, \"unpatched\")\n                self.assertEqual(something_else, mock_something_else,\n                                 \"unpatched\")\n\n        self.assertEqual(something, sentinel.Something)\n        self.assertEqual(something_else, sentinel.SomethingElse)\n\n\n    def test_with_statement_specified(self):\n        with patch('%s.something' % __name__, sentinel.Patched) as mock_something:\n            self.assertEqual(something, mock_something, \"unpatched\")\n            self.assertEqual(mock_something, sentinel.Patched, \"wrong patch\")\n        self.assertEqual(something, sentinel.Something)\n\n\n    def testContextManagerMocking(self):\n        mock = Mock()\n        mock.__enter__ = Mock()\n        mock.__exit__ = Mock()\n        mock.__exit__.return_value = False\n\n        with mock as m:\n            self.assertEqual(m, mock.__enter__.return_value)\n        mock.__enter__.assert_called_with()\n        mock.__exit__.assert_called_with(None, None, None)\n\n\n    def test_context_manager_with_magic_mock(self):\n        mock = MagicMock()\n\n        with self.assertRaises(TypeError):\n            with mock:\n                'foo' + 3\n        mock.__enter__.assert_called_with()\n        self.assertTrue(mock.__exit__.called)\n\n\n    def test_with_statement_same_attribute(self):\n        with patch('%s.something' % __name__, sentinel.Patched) as mock_something:\n            self.assertEqual(something, mock_something, \"unpatched\")\n\n            with patch('%s.something' % __name__) as mock_again:\n                self.assertEqual(something, mock_again, \"unpatched\")\n\n            self.assertEqual(something, mock_something,\n                             \"restored with wrong instance\")\n\n        self.assertEqual(something, sentinel.Something, \"not restored\")\n\n\n    def test_with_statement_imbricated(self):\n        with patch('%s.something' % __name__) as mock_something:\n            self.assertEqual(something, mock_something, \"unpatched\")\n\n            with patch('%s.something_else' % __name__) as mock_something_else:\n                self.assertEqual(something_else, mock_something_else,\n                                 \"unpatched\")\n\n        self.assertEqual(something, sentinel.Something)\n        self.assertEqual(something_else, sentinel.SomethingElse)\n\n\n    def test_dict_context_manager(self):\n        foo = {}\n        with patch.dict(foo, {'a': 'b'}):\n            self.assertEqual(foo, {'a': 'b'})\n        self.assertEqual(foo, {})\n\n        with self.assertRaises(NameError):\n            with patch.dict(foo, {'a': 'b'}):\n                self.assertEqual(foo, {'a': 'b'})\n                raise NameError('Konrad')\n\n        self.assertEqual(foo, {})\n\n\n\nclass TestMockOpen(unittest.TestCase):\n\n    def test_mock_open(self):\n        mock = mock_open()\n        with patch('%s.open' % __name__, mock, create=True) as patched:\n            self.assertIs(patched, mock)\n            open('foo')\n\n        mock.assert_called_once_with('foo')\n\n\n    def test_mock_open_context_manager(self):\n        mock = mock_open()\n        handle = mock.return_value\n        with patch('%s.open' % __name__, mock, create=True):\n            with open('foo') as f:\n                f.read()\n\n        expected_calls = [call('foo'), call().__enter__(), call().read(),\n                          call().__exit__(None, None, None)]\n        self.assertEqual(mock.mock_calls, expected_calls)\n        self.assertIs(f, handle)\n\n\n    def test_explicit_mock(self):\n        mock = MagicMock()\n        mock_open(mock)\n\n        with patch('%s.open' % __name__, mock, create=True) as patched:\n            self.assertIs(patched, mock)\n            open('foo')\n\n        mock.assert_called_once_with('foo')\n\n\n    def test_read_data(self):\n        mock = mock_open(read_data='foo')\n        with patch('%s.open' % __name__, mock, create=True):\n            h = open('bar')\n            result = h.read()\n\n        self.assertEqual(result, 'foo')\n\n\nif __name__ == '__main__':\n    unittest.main()\n"], "_threading_local": [".py", "\"\"\"Thread-local objects.\n\n(Note that this module provides a Python version of the threading.local\n class.  Depending on the version of Python you're using, there may be a\n faster one available.  You should always import the `local` class from\n `threading`.)\n\nThread-local objects support the management of thread-local data.\nIf you have data that you want to be local to a thread, simply create\na thread-local object and use its attributes:\n\n  >>> mydata = local()\n  >>> mydata.number = 42\n  >>> mydata.number\n  42\n\nYou can also access the local-object's dictionary:\n\n  >>> mydata.__dict__\n  {'number': 42}\n  >>> mydata.__dict__.setdefault('widgets', [])\n  []\n  >>> mydata.widgets\n  []\n\nWhat's important about thread-local objects is that their data are\nlocal to a thread. If we access the data in a different thread:\n\n  >>> log = []\n  >>> def f():\n  ...     items = sorted(mydata.__dict__.items())\n  ...     log.append(items)\n  ...     mydata.number = 11\n  ...     log.append(mydata.number)\n\n  >>> import threading\n  >>> thread = threading.Thread(target=f)\n  >>> thread.start()\n  >>> thread.join()\n  >>> log\n  [[], 11]\n\nwe get different data.  Furthermore, changes made in the other thread\ndon't affect data seen in this thread:\n\n  >>> mydata.number\n  42\n\nOf course, values you get from a local object, including a __dict__\nattribute, are for whatever thread was current at the time the\nattribute was read.  For that reason, you generally don't want to save\nthese values across threads, as they apply only to the thread they\ncame from.\n\nYou can create custom local objects by subclassing the local class:\n\n  >>> class MyLocal(local):\n  ...     number = 2\n  ...     initialized = False\n  ...     def __init__(self, **kw):\n  ...         if self.initialized:\n  ...             raise SystemError('__init__ called too many times')\n  ...         self.initialized = True\n  ...         self.__dict__.update(kw)\n  ...     def squared(self):\n  ...         return self.number ** 2\n\nThis can be useful to support default values, methods and\ninitialization.  Note that if you define an __init__ method, it will be\ncalled each time the local object is used in a separate thread.  This\nis necessary to initialize each thread's dictionary.\n\nNow if we create a local object:\n\n  >>> mydata = MyLocal(color='red')\n\nNow we have a default number:\n\n  >>> mydata.number\n  2\n\nan initial color:\n\n  >>> mydata.color\n  'red'\n  >>> del mydata.color\n\nAnd a method that operates on the data:\n\n  >>> mydata.squared()\n  4\n\nAs before, we can access the data in a separate thread:\n\n  >>> log = []\n  >>> thread = threading.Thread(target=f)\n  >>> thread.start()\n  >>> thread.join()\n  >>> log\n  [[('color', 'red'), ('initialized', True)], 11]\n\nwithout affecting this thread's data:\n\n  >>> mydata.number\n  2\n  >>> mydata.color\n  Traceback (most recent call last):\n  ...\n  AttributeError: 'MyLocal' object has no attribute 'color'\n\nNote that subclasses can define slots, but they are not thread\nlocal. They are shared across threads:\n\n  >>> class MyLocal(local):\n  ...     __slots__ = 'number'\n\n  >>> mydata = MyLocal()\n  >>> mydata.number = 42\n  >>> mydata.color = 'red'\n\nSo, the separate thread:\n\n  >>> thread = threading.Thread(target=f)\n  >>> thread.start()\n  >>> thread.join()\n\naffects what we see:\n\n  >>> mydata.number\n  11\n\n>>> del mydata\n\"\"\"\n\nfrom weakref import ref\nfrom contextlib import contextmanager\n\n__all__ = [\"local\"]\n\n# We need to use objects from the threading module, but the threading\n# module may also want to use our `local` class, if support for locals\n# isn't compiled in to the `thread` module.  This creates potential problems\n# with circular imports.  For that reason, we don't import `threading`\n# until the bottom of this file (a hack sufficient to worm around the\n# potential problems).  Note that all platforms on CPython do have support\n# for locals in the `thread` module, and there is no circular import problem\n# then, so problems introduced by fiddling the order of imports here won't\n# manifest.\n\nclass _localimpl:\n    \"\"\"A class managing thread-local dicts\"\"\"\n    __slots__ = 'key', 'dicts', 'localargs', 'locallock', '__weakref__'\n\n    def __init__(self):\n        # The key used in the Thread objects' attribute dicts.\n        # We keep it a string for speed but make it unlikely to clash with\n        # a \"real\" attribute.\n        self.key = '_threading_local._localimpl.' + str(id(self))\n        # { id(Thread) -> (ref(Thread), thread-local dict) }\n        self.dicts = {}\n\n    def get_dict(self):\n        \"\"\"Return the dict for the current thread. Raises KeyError if none\n        defined.\"\"\"\n        thread = current_thread()\n        return self.dicts[id(thread)][1]\n\n    def create_dict(self):\n        \"\"\"Create a new dict for the current thread, and return it.\"\"\"\n        localdict = {}\n        key = self.key\n        thread = current_thread()\n        idt = id(thread)\n        def local_deleted(_, key=key):\n            # When the localimpl is deleted, remove the thread attribute.\n            thread = wrthread()\n            if thread is not None:\n                del thread.__dict__[key]\n        def thread_deleted(_, idt=idt):\n            # When the thread is deleted, remove the local dict.\n            # Note that this is suboptimal if the thread object gets\n            # caught in a reference loop. We would like to be called\n            # as soon as the OS-level thread ends instead.\n            local = wrlocal()\n            if local is not None:\n                dct = local.dicts.pop(idt)\n        wrlocal = ref(self, local_deleted)\n        wrthread = ref(thread, thread_deleted)\n        thread.__dict__[key] = wrlocal\n        self.dicts[idt] = wrthread, localdict\n        return localdict\n\n\n@contextmanager\ndef _patch(self):\n    impl = object.__getattribute__(self, '_local__impl')\n    try:\n        dct = impl.get_dict()\n    except KeyError:\n        dct = impl.create_dict()\n        args, kw = impl.localargs\n        self.__init__(*args, **kw)\n    with impl.locallock:\n        object.__setattr__(self, '__dict__', dct)\n        yield\n\n\nclass local:\n    __slots__ = '_local__impl', '__dict__'\n\n    def __new__(cls, *args, **kw):\n        if (args or kw) and (cls.__init__ is object.__init__):\n            raise TypeError(\"Initialization arguments are not supported\")\n        self = object.__new__(cls)\n        impl = _localimpl()\n        impl.localargs = (args, kw)\n        impl.locallock = RLock()\n        object.__setattr__(self, '_local__impl', impl)\n        # We need to create the thread dict in anticipation of\n        # __init__ being called, to make sure we don't call it\n        # again ourselves.\n        impl.create_dict()\n        return self\n\n    def __getattribute__(self, name):\n        with _patch(self):\n            return object.__getattribute__(self, name)\n\n    def __setattr__(self, name, value):\n        if name == '__dict__':\n            raise AttributeError(\n                \"%r object attribute '__dict__' is read-only\"\n                % self.__class__.__name__)\n        with _patch(self):\n            return object.__setattr__(self, name, value)\n\n    def __delattr__(self, name):\n        if name == '__dict__':\n            raise AttributeError(\n                \"%r object attribute '__dict__' is read-only\"\n                % self.__class__.__name__)\n        with _patch(self):\n            return object.__delattr__(self, name)\n\n\nfrom threading import current_thread, RLock\n"], "unittest.test._test_warnings": [".py", "# helper module for test_runner.Test_TextTestRunner.test_warnings\n\n\"\"\"\nThis module has a number of tests that raise different kinds of warnings.\nWhen the tests are run, the warnings are caught and their messages are printed\nto stdout.  This module also accepts an arg that is then passed to\nunittest.main to affect the behavior of warnings.\nTest_TextTestRunner.test_warnings executes this script with different\ncombinations of warnings args and -W flags and check that the output is correct.\nSee #10535.\n\"\"\"\n\nimport sys\nimport unittest\nimport warnings\n\ndef warnfun():\n    warnings.warn('rw', RuntimeWarning)\n\nclass TestWarnings(unittest.TestCase):\n    # unittest warnings will be printed at most once per type (max one message\n    # for the fail* methods, and one for the assert* methods)\n    def test_assert(self):\n        self.assertEquals(2+2, 4)\n        self.assertEquals(2*2, 4)\n        self.assertEquals(2**2, 4)\n\n    def test_fail(self):\n        self.failUnless(1)\n        self.failUnless(True)\n\n    def test_other_unittest(self):\n        self.assertAlmostEqual(2+2, 4)\n        self.assertNotAlmostEqual(4+4, 2)\n\n    # these warnings are normally silenced, but they are printed in unittest\n    def test_deprecation(self):\n        warnings.warn('dw', DeprecationWarning)\n        warnings.warn('dw', DeprecationWarning)\n        warnings.warn('dw', DeprecationWarning)\n\n    def test_import(self):\n        warnings.warn('iw', ImportWarning)\n        warnings.warn('iw', ImportWarning)\n        warnings.warn('iw', ImportWarning)\n\n    # user warnings should always be printed\n    def test_warning(self):\n        warnings.warn('uw')\n        warnings.warn('uw')\n        warnings.warn('uw')\n\n    # these warnings come from the same place; they will be printed\n    # only once by default or three times if the 'always' filter is used\n    def test_function(self):\n\n        warnfun()\n        warnfun()\n        warnfun()\n\n\n\nif __name__ == '__main__':\n    with warnings.catch_warnings(record=True) as ws:\n        # if an arg is provided pass it to unittest.main as 'warnings'\n        if len(sys.argv) == 2:\n            unittest.main(exit=False, warnings=sys.argv.pop())\n        else:\n            unittest.main(exit=False)\n\n    # print all the warning messages collected\n    for w in ws:\n        print(w.message)\n"], "posixpath": [".py", "\"\"\"Common operations on Posix pathnames.\n\nInstead of importing this module directly, import os and refer to\nthis module as os.path.  The \"os.path\" name is an alias for this\nmodule on Posix systems; on other systems (e.g. Mac, Windows),\nos.path provides the same operations in a manner specific to that\nplatform, and is an alias to another module (e.g. macpath, ntpath).\n\nSome of this can actually be useful on non-Posix systems too, e.g.\nfor manipulation of the pathname component of URLs.\n\"\"\"\n\nimport os\nimport sys\nimport stat\nimport genericpath\nfrom genericpath import *\n\n__all__ = [\"normcase\",\"isabs\",\"join\",\"splitdrive\",\"split\",\"splitext\",\n           \"basename\",\"dirname\",\"commonprefix\",\"getsize\",\"getmtime\",\n           \"getatime\",\"getctime\",\"islink\",\"exists\",\"lexists\",\"isdir\",\"isfile\",\n           \"ismount\", \"expanduser\",\"expandvars\",\"normpath\",\"abspath\",\n           \"samefile\",\"sameopenfile\",\"samestat\",\n           \"curdir\",\"pardir\",\"sep\",\"pathsep\",\"defpath\",\"altsep\",\"extsep\",\n           \"devnull\",\"realpath\",\"supports_unicode_filenames\",\"relpath\"]\n\n# Strings representing various path-related bits and pieces.\n# These are primarily for export; internally, they are hardcoded.\ncurdir = '.'\npardir = '..'\nextsep = '.'\nsep = '/'\npathsep = ':'\ndefpath = ':/bin:/usr/bin'\naltsep = None\ndevnull = '/dev/null'\n\ndef _get_sep(path):\n    if isinstance(path, bytes):\n        return b'/'\n    else:\n        return '/'\n\n# Normalize the case of a pathname.  Trivial in Posix, string.lower on Mac.\n# On MS-DOS this may also turn slashes into backslashes; however, other\n# normalizations (such as optimizing '../' away) are not allowed\n# (another function should be defined to do that).\n\ndef normcase(s):\n    \"\"\"Normalize case of pathname.  Has no effect under Posix\"\"\"\n    # TODO: on Mac OS X, this should really return s.lower().\n    if not isinstance(s, (bytes, str)):\n        raise TypeError(\"normcase() argument must be str or bytes, \"\n                        \"not '{}'\".format(s.__class__.__name__))\n    return s\n\n\n# Return whether a path is absolute.\n# Trivial in Posix, harder on the Mac or MS-DOS.\n\ndef isabs(s):\n    \"\"\"Test whether a path is absolute\"\"\"\n    sep = _get_sep(s)\n    return s.startswith(sep)\n\n\n# Join pathnames.\n# Ignore the previous parts if a part is absolute.\n# Insert a '/' unless the first part is empty or already ends in '/'.\n\ndef join(a, *p):\n    \"\"\"Join two or more pathname components, inserting '/' as needed.\n    If any component is an absolute path, all previous path components\n    will be discarded.  An empty last part will result in a path that\n    ends with a separator.\"\"\"\n    sep = _get_sep(a)\n    path = a\n    try:\n        for b in p:\n            if b.startswith(sep):\n                path = b\n            elif not path or path.endswith(sep):\n                path += b\n            else:\n                path += sep + b\n    except TypeError:\n        valid_types = all(isinstance(s, (str, bytes, bytearray))\n                          for s in (a, ) + p)\n        if valid_types:\n            # Must have a mixture of text and binary data\n            raise TypeError(\"Can't mix strings and bytes in path \"\n                            \"components.\") from None\n        raise\n    return path\n\n\n# Split a path in head (everything up to the last '/') and tail (the\n# rest).  If the path ends in '/', tail will be empty.  If there is no\n# '/' in the path, head  will be empty.\n# Trailing '/'es are stripped from head unless it is the root.\n\ndef split(p):\n    \"\"\"Split a pathname.  Returns tuple \"(head, tail)\" where \"tail\" is\n    everything after the final slash.  Either part may be empty.\"\"\"\n    sep = _get_sep(p)\n    i = p.rfind(sep) + 1\n    head, tail = p[:i], p[i:]\n    if head and head != sep*len(head):\n        head = head.rstrip(sep)\n    return head, tail\n\n\n# Split a path in root and extension.\n# The extension is everything starting at the last dot in the last\n# pathname component; the root is everything before that.\n# It is always true that root + ext == p.\n\ndef splitext(p):\n    if isinstance(p, bytes):\n        sep = b'/'\n        extsep = b'.'\n    else:\n        sep = '/'\n        extsep = '.'\n    return genericpath._splitext(p, sep, None, extsep)\nsplitext.__doc__ = genericpath._splitext.__doc__\n\n# Split a pathname into a drive specification and the rest of the\n# path.  Useful on DOS/Windows/NT; on Unix, the drive is always empty.\n\ndef splitdrive(p):\n    \"\"\"Split a pathname into drive and path. On Posix, drive is always\n    empty.\"\"\"\n    return p[:0], p\n\n\n# Return the tail (basename) part of a path, same as split(path)[1].\n\ndef basename(p):\n    \"\"\"Returns the final component of a pathname\"\"\"\n    sep = _get_sep(p)\n    i = p.rfind(sep) + 1\n    return p[i:]\n\n\n# Return the head (dirname) part of a path, same as split(path)[0].\n\ndef dirname(p):\n    \"\"\"Returns the directory component of a pathname\"\"\"\n    sep = _get_sep(p)\n    i = p.rfind(sep) + 1\n    head = p[:i]\n    if head and head != sep*len(head):\n        head = head.rstrip(sep)\n    return head\n\n\n# Is a path a symbolic link?\n# This will always return false on systems where os.lstat doesn't exist.\n\ndef islink(path):\n    \"\"\"Test whether a path is a symbolic link\"\"\"\n    try:\n        st = os.lstat(path)\n    except (os.error, AttributeError):\n        return False\n    return stat.S_ISLNK(st.st_mode)\n\n# Being true for dangling symbolic links is also useful.\n\ndef lexists(path):\n    \"\"\"Test whether a path exists.  Returns True for broken symbolic links\"\"\"\n    try:\n        os.lstat(path)\n    except os.error:\n        return False\n    return True\n\n\n# Are two filenames really pointing to the same file?\n\ndef samefile(f1, f2):\n    \"\"\"Test whether two pathnames reference the same actual file\"\"\"\n    s1 = os.stat(f1)\n    s2 = os.stat(f2)\n    return samestat(s1, s2)\n\n\n# Are two open files really referencing the same file?\n# (Not necessarily the same file descriptor!)\n\ndef sameopenfile(fp1, fp2):\n    \"\"\"Test whether two open file objects reference the same file\"\"\"\n    s1 = os.fstat(fp1)\n    s2 = os.fstat(fp2)\n    return samestat(s1, s2)\n\n\n# Are two stat buffers (obtained from stat, fstat or lstat)\n# describing the same file?\n\ndef samestat(s1, s2):\n    \"\"\"Test whether two stat buffers reference the same file\"\"\"\n    return s1.st_ino == s2.st_ino and \\\n           s1.st_dev == s2.st_dev\n\n\n# Is a path a mount point?\n# (Does this work for all UNIXes?  Is it even guaranteed to work by Posix?)\n\ndef ismount(path):\n    \"\"\"Test whether a path is a mount point\"\"\"\n    if islink(path):\n        # A symlink can never be a mount point\n        return False\n    try:\n        s1 = os.lstat(path)\n        if isinstance(path, bytes):\n            parent = join(path, b'..')\n        else:\n            parent = join(path, '..')\n        s2 = os.lstat(parent)\n    except os.error:\n        return False # It doesn't exist -- so not a mount point :-)\n    dev1 = s1.st_dev\n    dev2 = s2.st_dev\n    if dev1 != dev2:\n        return True     # path/.. on a different device as path\n    ino1 = s1.st_ino\n    ino2 = s2.st_ino\n    if ino1 == ino2:\n        return True     # path/.. is the same i-node as path\n    return False\n\n\n# Expand paths beginning with '~' or '~user'.\n# '~' means $HOME; '~user' means that user's home directory.\n# If the path doesn't begin with '~', or if the user or $HOME is unknown,\n# the path is returned unchanged (leaving error reporting to whatever\n# function is called with the expanded path as argument).\n# See also module 'glob' for expansion of *, ? and [...] in pathnames.\n# (A function should also be defined to do full *sh-style environment\n# variable expansion.)\n\ndef expanduser(path):\n    \"\"\"Expand ~ and ~user constructions.  If user or $HOME is unknown,\n    do nothing.\"\"\"\n    if isinstance(path, bytes):\n        tilde = b'~'\n    else:\n        tilde = '~'\n    if not path.startswith(tilde):\n        return path\n    sep = _get_sep(path)\n    i = path.find(sep, 1)\n    if i < 0:\n        i = len(path)\n    if i == 1:\n        if 'HOME' not in os.environ:\n            import pwd\n            userhome = pwd.getpwuid(os.getuid()).pw_dir\n        else:\n            userhome = os.environ['HOME']\n    else:\n        import pwd\n        name = path[1:i]\n        if isinstance(name, bytes):\n            name = str(name, 'ASCII')\n        try:\n            pwent = pwd.getpwnam(name)\n        except KeyError:\n            return path\n        userhome = pwent.pw_dir\n    if isinstance(path, bytes):\n        userhome = os.fsencode(userhome)\n        root = b'/'\n    else:\n        root = '/'\n    userhome = userhome.rstrip(root)\n    return (userhome + path[i:]) or root\n\n\n# Expand paths containing shell variable substitutions.\n# This expands the forms $variable and ${variable} only.\n# Non-existent variables are left unchanged.\n\n_varprog = None\n_varprogb = None\n\ndef expandvars(path):\n    \"\"\"Expand shell variables of form $var and ${var}.  Unknown variables\n    are left unchanged.\"\"\"\n    global _varprog, _varprogb\n    if isinstance(path, bytes):\n        if b'$' not in path:\n            return path\n        if not _varprogb:\n            import re\n            _varprogb = re.compile(br'\\$(\\w+|\\{[^}]*\\})', re.ASCII)\n        search = _varprogb.search\n        start = b'{'\n        end = b'}'\n    else:\n        if '$' not in path:\n            return path\n        if not _varprog:\n            import re\n            _varprog = re.compile(r'\\$(\\w+|\\{[^}]*\\})', re.ASCII)\n        search = _varprog.search\n        start = '{'\n        end = '}'\n    i = 0\n    while True:\n        m = search(path, i)\n        if not m:\n            break\n        i, j = m.span(0)\n        name = m.group(1)\n        if name.startswith(start) and name.endswith(end):\n            name = name[1:-1]\n        if isinstance(name, bytes):\n            name = str(name, 'ASCII')\n        if name in os.environ:\n            tail = path[j:]\n            value = os.environ[name]\n            if isinstance(path, bytes):\n                value = value.encode('ASCII')\n            path = path[:i] + value\n            i = len(path)\n            path += tail\n        else:\n            i = j\n    return path\n\n\n# Normalize a path, e.g. A//B, A/./B and A/foo/../B all become A/B.\n# It should be understood that this may change the meaning of the path\n# if it contains symbolic links!\n\ndef normpath(path):\n    \"\"\"Normalize path, eliminating double slashes, etc.\"\"\"\n    if isinstance(path, bytes):\n        sep = b'/'\n        empty = b''\n        dot = b'.'\n        dotdot = b'..'\n    else:\n        sep = '/'\n        empty = ''\n        dot = '.'\n        dotdot = '..'\n    if path == empty:\n        return dot\n    initial_slashes = path.startswith(sep)\n    # POSIX allows one or two initial slashes, but treats three or more\n    # as single slash.\n    if (initial_slashes and\n        path.startswith(sep*2) and not path.startswith(sep*3)):\n        initial_slashes = 2\n    comps = path.split(sep)\n    new_comps = []\n    for comp in comps:\n        if comp in (empty, dot):\n            continue\n        if (comp != dotdot or (not initial_slashes and not new_comps) or\n             (new_comps and new_comps[-1] == dotdot)):\n            new_comps.append(comp)\n        elif new_comps:\n            new_comps.pop()\n    comps = new_comps\n    path = sep.join(comps)\n    if initial_slashes:\n        path = sep*initial_slashes + path\n    return path or dot\n\n\ndef abspath(path):\n    \"\"\"Return an absolute path.\"\"\"\n    if not isabs(path):\n        if isinstance(path, bytes):\n            cwd = os.getcwdb()\n        else:\n            cwd = os.getcwd()\n        path = join(cwd, path)\n    return normpath(path)\n\n\n# Return a canonical path (i.e. the absolute location of a file on the\n# filesystem).\n\ndef realpath(filename):\n    \"\"\"Return the canonical path of the specified filename, eliminating any\nsymbolic links encountered in the path.\"\"\"\n    path, ok = _joinrealpath(filename[:0], filename, {})\n    return abspath(path)\n\n# Join two paths, normalizing ang eliminating any symbolic links\n# encountered in the second path.\ndef _joinrealpath(path, rest, seen):\n    if isinstance(path, bytes):\n        sep = b'/'\n        curdir = b'.'\n        pardir = b'..'\n    else:\n        sep = '/'\n        curdir = '.'\n        pardir = '..'\n\n    if isabs(rest):\n        rest = rest[1:]\n        path = sep\n\n    while rest:\n        name, _, rest = rest.partition(sep)\n        if not name or name == curdir:\n            # current dir\n            continue\n        if name == pardir:\n            # parent dir\n            if path:\n                path, name = split(path)\n                if name == pardir:\n                    path = join(path, pardir, pardir)\n            else:\n                path = pardir\n            continue\n        newpath = join(path, name)\n        if not islink(newpath):\n            path = newpath\n            continue\n        # Resolve the symbolic link\n        if newpath in seen:\n            # Already seen this path\n            path = seen[newpath]\n            if path is not None:\n                # use cached value\n                continue\n            # The symlink is not resolved, so we must have a symlink loop.\n            # Return already resolved part + rest of the path unchanged.\n            return join(newpath, rest), False\n        seen[newpath] = None # not resolved symlink\n        path, ok = _joinrealpath(path, os.readlink(newpath), seen)\n        if not ok:\n            return join(path, rest), False\n        seen[newpath] = path # resolved symlink\n\n    return path, True\n\n\nsupports_unicode_filenames = (sys.platform == 'darwin')\n\ndef relpath(path, start=None):\n    \"\"\"Return a relative version of a path\"\"\"\n\n    if not path:\n        raise ValueError(\"no path specified\")\n\n    if isinstance(path, bytes):\n        curdir = b'.'\n        sep = b'/'\n        pardir = b'..'\n    else:\n        curdir = '.'\n        sep = '/'\n        pardir = '..'\n\n    if start is None:\n        start = curdir\n\n    start_list = [x for x in abspath(start).split(sep) if x]\n    path_list = [x for x in abspath(path).split(sep) if x]\n\n    # Work out how much of the filepath is shared by start and path.\n    i = len(commonprefix([start_list, path_list]))\n\n    rel_list = [pardir] * (len(start_list)-i) + path_list[i:]\n    if not rel_list:\n        return curdir\n    return join(*rel_list)\n"], "imp": [".py", "\"\"\"This module provides the components needed to build your own __import__\nfunction.  Undocumented functions are obsolete.\n\nIn most cases it is preferred you consider using the importlib module's\nfunctionality over this module.\n\n\"\"\"\n# (Probably) need to stay in _imp\nfrom _imp import (lock_held, acquire_lock, release_lock,\n                  get_frozen_object, is_frozen_package,\n                  init_builtin, init_frozen, is_builtin, is_frozen,\n                  _fix_co_filename)\ntry:\n    from _imp import load_dynamic\nexcept ImportError:\n    # Platform doesn't support dynamic loading.\n    load_dynamic = None\n\n# Directly exposed by this module\nfrom importlib._bootstrap import new_module\nfrom importlib._bootstrap import cache_from_source, source_from_cache\n\n\nfrom importlib import _bootstrap\n#fixme brython\n#from importlib import machinery\nimport importlib.machinery as machinery\nimport os\nimport sys\nimport tokenize\nimport warnings\n\n\n# DEPRECATED\nSEARCH_ERROR = 0\nPY_SOURCE = 1\nPY_COMPILED = 2\nC_EXTENSION = 3\nPY_RESOURCE = 4\nPKG_DIRECTORY = 5\nC_BUILTIN = 6\nPY_FROZEN = 7\nPY_CODERESOURCE = 8\nIMP_HOOK = 9\n\n\ndef get_magic():\n    \"\"\"Return the magic number for .pyc or .pyo files.\"\"\"\n    return _bootstrap._MAGIC_BYTES\n\n\ndef get_tag():\n    \"\"\"Return the magic tag for .pyc or .pyo files.\"\"\"\n    return sys.implementation.cache_tag\n\n\ndef get_suffixes():\n    warnings.warn('imp.get_suffixes() is deprecated; use the constants '\n                  'defined on importlib.machinery instead',\n                  DeprecationWarning, 2)\n    extensions = [(s, 'rb', C_EXTENSION) for s in machinery.EXTENSION_SUFFIXES]\n    source = [(s, 'U', PY_SOURCE) for s in machinery.SOURCE_SUFFIXES]\n    bytecode = [(s, 'rb', PY_COMPILED) for s in machinery.BYTECODE_SUFFIXES]\n\n    return extensions + source + bytecode\n\n\nclass NullImporter:\n\n    \"\"\"Null import object.\"\"\"\n\n    def __init__(self, path):\n        if path == '':\n            raise ImportError('empty pathname', path='')\n        elif os.path.isdir(path):\n            raise ImportError('existing directory', path=path)\n\n    def find_module(self, fullname):\n        \"\"\"Always returns None.\"\"\"\n        return None\n\n\nclass _HackedGetData:\n\n    \"\"\"Compatibiilty support for 'file' arguments of various load_*()\n    functions.\"\"\"\n\n    def __init__(self, fullname, path, file=None):\n        super().__init__(fullname, path)\n        self.file = file\n\n    def get_data(self, path):\n        \"\"\"Gross hack to contort loader to deal w/ load_*()'s bad API.\"\"\"\n        if self.file and path == self.path:\n            if not self.file.closed:\n                file = self.file\n            else:\n                self.file = file = open(self.path, 'r')\n\n            with file:\n                # Technically should be returning bytes, but\n                # SourceLoader.get_code() just passed what is returned to\n                # compile() which can handle str. And converting to bytes would\n                # require figuring out the encoding to decode to and\n                # tokenize.detect_encoding() only accepts bytes.\n                return file.read()\n        else:\n            return super().get_data(path)\n\n\nclass _LoadSourceCompatibility(_HackedGetData, _bootstrap.SourceFileLoader):\n\n    \"\"\"Compatibility support for implementing load_source().\"\"\"\n    #brython fix me\n    pass\n\ndef load_source(name, pathname, file=None):\n    msg = ('imp.load_source() is deprecated; use '\n           'importlib.machinery.SourceFileLoader(name, pathname).load_module()'\n           ' instead')\n    warnings.warn(msg, DeprecationWarning, 2)\n    _LoadSourceCompatibility(name, pathname, file).load_module(name)\n    module = sys.modules[name]\n    # To allow reloading to potentially work, use a non-hacked loader which\n    # won't rely on a now-closed file object.\n    module.__loader__ = _bootstrap.SourceFileLoader(name, pathname)\n    return module\n\n\nclass _LoadCompiledCompatibility(_HackedGetData,\n        _bootstrap.SourcelessFileLoader):\n\n    \"\"\"Compatibility support for implementing load_compiled().\"\"\"\n    #brython fix me\n    pass\n\ndef load_compiled(name, pathname, file=None):\n    msg = ('imp.load_compiled() is deprecated; use '\n           'importlib.machinery.SourcelessFileLoader(name, pathname).'\n           'load_module() instead ')\n    warnings.warn(msg, DeprecationWarning, 2)\n    _LoadCompiledCompatibility(name, pathname, file).load_module(name)\n    module = sys.modules[name]\n    # To allow reloading to potentially work, use a non-hacked loader which\n    # won't rely on a now-closed file object.\n    module.__loader__ = _bootstrap.SourcelessFileLoader(name, pathname)\n    return module\n\n\ndef load_package(name, path):\n    msg = ('imp.load_package() is deprecated; use either '\n           'importlib.machinery.SourceFileLoader() or '\n           'importlib.machinery.SourcelessFileLoader() instead')\n    warnings.warn(msg, DeprecationWarning, 2)\n    if os.path.isdir(path):\n        extensions = (machinery.SOURCE_SUFFIXES[:] +\n                      machinery.BYTECODE_SUFFIXES[:])\n        for extension in extensions:\n            path = os.path.join(path, '__init__'+extension)\n            if os.path.exists(path):\n                break\n        else:\n            raise ValueError('{!r} is not a package'.format(path))\n    return _bootstrap.SourceFileLoader(name, path).load_module(name)\n\n\ndef load_module(name, file, filename, details):\n    \"\"\"**DEPRECATED**\n\n    Load a module, given information returned by find_module().\n\n    The module name must include the full package name, if any.\n\n    \"\"\"\n    suffix, mode, type_ = details\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        if mode and (not mode.startswith(('r', 'U')) or '+' in mode):\n            raise ValueError('invalid file open mode {!r}'.format(mode))\n        elif file is None and type_ in {PY_SOURCE, PY_COMPILED}:\n            msg = 'file object required for import (type code {})'.format(type_)\n            raise ValueError(msg)\n        elif type_ == PY_SOURCE:\n            return load_source(name, filename, file)\n        elif type_ == PY_COMPILED:\n            return load_compiled(name, filename, file)\n        elif type_ == C_EXTENSION and load_dynamic is not None:\n            if file is None:\n                with open(filename, 'rb') as opened_file:\n                    return load_dynamic(name, filename, opened_file)\n            else:\n                return load_dynamic(name, filename, file)\n        elif type_ == PKG_DIRECTORY:\n            return load_package(name, filename)\n        elif type_ == C_BUILTIN:\n            return init_builtin(name)\n        elif type_ == PY_FROZEN:\n            return init_frozen(name)\n        else:\n            msg =  \"Don't know how to import {} (type code {})\".format(name, type_)\n            raise ImportError(msg, name=name)\n\n\ndef find_module(name, path=None):\n    \"\"\"**DEPRECATED**\n\n    Search for a module.\n\n    If path is omitted or None, search for a built-in, frozen or special\n    module and continue search in sys.path. The module name cannot\n    contain '.'; to search for a submodule of a package, pass the\n    submodule name and the package's __path__.\n\n    \"\"\"\n    if not isinstance(name, str):\n        raise TypeError(\"'name' must be a str, not {}\".format(type(name)))\n    elif not isinstance(path, (type(None), list)):\n        # Backwards-compatibility\n        raise RuntimeError(\"'list' must be None or a list, \"\n                           \"not {}\".format(type(name)))\n\n    if path is None:\n        if is_builtin(name):\n            return None, None, ('', '', C_BUILTIN)\n        elif is_frozen(name):\n            return None, None, ('', '', PY_FROZEN)\n        else:\n            path = sys.path\n\n    for entry in path:\n        package_directory = os.path.join(entry, name)\n        for suffix in ['.py', machinery.BYTECODE_SUFFIXES[0]]:\n            package_file_name = '__init__' + suffix\n            file_path = os.path.join(package_directory, package_file_name)\n            if os.path.isfile(file_path):\n                return None, package_directory, ('', '', PKG_DIRECTORY)\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore')\n            for suffix, mode, type_ in get_suffixes():\n                file_name = name + suffix\n                file_path = os.path.join(entry, file_name)\n                if os.path.isfile(file_path):\n                    break\n            else:\n                continue\n            break  # Break out of outer loop when breaking out of inner loop.\n    else:\n        raise ImportError(_bootstrap._ERR_MSG.format(name), name=name)\n\n    encoding = None\n    if mode == 'U':\n        with open(file_path, 'rb') as file:\n            encoding = tokenize.detect_encoding(file.readline)[0]\n    file = open(file_path, mode, encoding=encoding)\n    return file, file_path, (suffix, mode, type_)\n\n\n_RELOADING = {}\n\ndef reload(module):\n    \"\"\"Reload the module and return it.\n\n    The module must have been successfully imported before.\n\n    \"\"\"\n    if not module or type(module) != type(sys):\n        raise TypeError(\"reload() argument must be module\")\n    name = module.__name__\n    if name not in sys.modules:\n        msg = \"module {} not in sys.modules\"\n        raise ImportError(msg.format(name), name=name)\n    if name in _RELOADING:\n        return _RELOADING[name]\n    _RELOADING[name] = module\n    try:\n        parent_name = name.rpartition('.')[0]\n        if parent_name and parent_name not in sys.modules:\n            msg = \"parent {!r} not in sys.modules\"\n            raise ImportError(msg.format(parent_name), name=parent_name)\n        module.__loader__.load_module(name)\n        # The module may have replaced itself in sys.modules!\n        return sys.modules[module.__name__]\n    finally:\n        try:\n            del _RELOADING[name]\n        except KeyError:\n            pass\n"], "errno": [".py", "\"\"\"\nThis module makes available standard errno system symbols.\nThe value of each symbol is the corresponding integer value,\ne.g., on most systems, errno.ENOENT equals the integer 2.\nThe dictionary errno.errorcode maps numeric codes to symbol names,\ne.g., errno.errorcode[2] could be the string 'ENOENT'.\n\nSymbols that are not relevant to the underlying system are not defined.\n\nTo map error codes to error messages, use the function os.strerror(),\ne.g. os.strerror(2) could return 'No such file or directory'.\n\"\"\"\n\nerrorcode= {1: 'EPERM', 2: 'ENOENT', 3: 'ESRCH', 4: 'EINTR', 5: 'EIO', \n6: 'ENXIO', 7: 'E2BIG', 8: 'ENOEXEC', 9: 'EBADF', 10: 'ECHILD', 11: 'EAGAIN', \n12: 'ENOMEM', 13: 'EACCES', 14: 'EFAULT', 15: 'ENOTBLK', 16: 'EBUSY', \n17: 'EEXIST', 18: 'EXDEV', 19: 'ENODEV', 20: 'ENOTDIR', 21: 'EISDIR', \n22: 'EINVAL', 23: 'ENFILE', 24: 'EMFILE', 25: 'ENOTTY', 26: 'ETXTBSY', \n27: 'EFBIG', 28: 'ENOSPC', 29: 'ESPIPE', 30: 'EROFS', 31: 'EMLINK', \n32: 'EPIPE', 33: 'EDOM', 34: 'ERANGE', 35: 'EDEADLOCK', 36: 'ENAMETOOLONG', \n37: 'ENOLCK', 38: 'ENOSYS', 39: 'ENOTEMPTY', 40: 'ELOOP', 42: 'ENOMSG', \n43: 'EIDRM', 44: 'ECHRNG', 45: 'EL2NSYNC', 46: 'EL3HLT', 47: 'EL3RST', \n48: 'ELNRNG', 49: 'EUNATCH', 50: 'ENOCSI', 51: 'EL2HLT', 52: 'EBADE', \n53: 'EBADR', 54: 'EXFULL', 55: 'ENOANO', 56: 'EBADRQC', 57: 'EBADSLT', \n59: 'EBFONT', 60: 'ENOSTR', 61: 'ENODATA', 62: 'ETIME', 63: 'ENOSR', \n64: 'ENONET', 65: 'ENOPKG', 66: 'EREMOTE', 67: 'ENOLINK', 68: 'EADV', \n69: 'ESRMNT', 70: 'ECOMM', 71: 'EPROTO', 72: 'EMULTIHOP', 73: 'EDOTDOT', \n74: 'EBADMSG', 75: 'EOVERFLOW', 76: 'ENOTUNIQ', 77: 'EBADFD', 78: 'EREMCHG', \n79: 'ELIBACC', 80: 'ELIBBAD', 81: 'ELIBSCN', 82: 'ELIBMAX', 83: 'ELIBEXEC', \n84: 'EILSEQ', 85: 'ERESTART', 86: 'ESTRPIPE', 87: 'EUSERS', 88: 'ENOTSOCK', \n89: 'EDESTADDRREQ', 90: 'EMSGSIZE', 91: 'EPROTOTYPE', 92: 'ENOPROTOOPT', \n93: 'EPROTONOSUPPORT', 94: 'ESOCKTNOSUPPORT', 95: 'ENOTSUP', \n96: 'EPFNOSUPPORT', 97: 'EAFNOSUPPORT', 98: 'EADDRINUSE', \n99: 'EADDRNOTAVAIL', 100: 'ENETDOWN', 101: 'ENETUNREACH', 102: 'ENETRESET', \n103: 'ECONNABORTED', 104: 'ECONNRESET', 105: 'ENOBUFS', 106: 'EISCONN', \n107: 'ENOTCONN', 108: 'ESHUTDOWN', 109: 'ETOOMANYREFS', 110: 'ETIMEDOUT', \n111: 'ECONNREFUSED', 112: 'EHOSTDOWN', 113: 'EHOSTUNREACH', 114: 'EALREADY', \n115: 'EINPROGRESS', 116: 'ESTALE', 117: 'EUCLEAN', 118: 'ENOTNAM', \n119: 'ENAVAIL', 120: 'EISNAM', 121: 'EREMOTEIO', 122: 'EDQUOT', \n123: 'ENOMEDIUM', 124: 'EMEDIUMTYPE', 125: 'ECANCELED', 126: 'ENOKEY', \n127: 'EKEYEXPIRED', 128: 'EKEYREVOKED', 129: 'EKEYREJECTED', \n130: 'EOWNERDEAD', 131: 'ENOTRECOVERABLE', 132: 'ERFKILL'}\n\n# now put the attributes of the errorcode dict into this modules namespace\n_codes=[]\nfor _num, _code in errorcode.items():\n    _codes.append('%s=%s' % (_code, _num))\n\neval(';'.join(_codes))\n"], "_socket": [".py", "\"\"\"Implementation module for socket operations.\n\nSee the socket module for documentation.\"\"\"\n\n\nAF_APPLETALK = 16\n\nAF_DECnet = 12\n\nAF_INET = 2\n\nAF_INET6 = 23\n\nAF_IPX = 6\n\nAF_IRDA = 26\n\nAF_SNA = 11\n\nAF_UNSPEC = 0\n\nAI_ADDRCONFIG = 1024\n\nAI_ALL = 256\n\nAI_CANONNAME = 2\n\nAI_NUMERICHOST = 4\n\nAI_NUMERICSERV = 8\n\nAI_PASSIVE = 1\n\nAI_V4MAPPED = 2048\n\nCAPI = '<capsule object \"_socket.CAPI\" at 0x00BC4F38>'\n\nEAI_AGAIN = 11002\n\nEAI_BADFLAGS = 10022\n\nEAI_FAIL = 11003\n\nEAI_FAMILY = 10047\n\nEAI_MEMORY = 8\n\nEAI_NODATA = 11001\n\nEAI_NONAME = 11001\n\nEAI_SERVICE = 10109\n\nEAI_SOCKTYPE = 10044\n\nINADDR_ALLHOSTS_GROUP = -536870911\n\nINADDR_ANY = 0\n\nINADDR_BROADCAST = -1\n\nINADDR_LOOPBACK = 2130706433\n\nINADDR_MAX_LOCAL_GROUP = -536870657\n\nINADDR_NONE = -1\n\nINADDR_UNSPEC_GROUP = -536870912\n\nIPPORT_RESERVED = 1024\n\nIPPORT_USERRESERVED = 5000\n\nIPPROTO_ICMP = 1\n\nIPPROTO_IP = 0\n\nIPPROTO_RAW = 255\n\nIPPROTO_TCP = 6\n\nIPPROTO_UDP = 17\n\nIPV6_CHECKSUM = 26\n\nIPV6_DONTFRAG = 14\n\nIPV6_HOPLIMIT = 21\n\nIPV6_HOPOPTS = 1\n\nIPV6_JOIN_GROUP = 12\n\nIPV6_LEAVE_GROUP = 13\n\nIPV6_MULTICAST_HOPS = 10\n\nIPV6_MULTICAST_IF = 9\n\nIPV6_MULTICAST_LOOP = 11\n\nIPV6_PKTINFO = 19\n\nIPV6_RECVRTHDR = 38\n\nIPV6_RECVTCLASS = 40\n\nIPV6_RTHDR = 32\n\nIPV6_TCLASS = 39\n\nIPV6_UNICAST_HOPS = 4\n\nIPV6_V6ONLY = 27\n\nIP_ADD_MEMBERSHIP = 12\n\nIP_DROP_MEMBERSHIP = 13\n\nIP_HDRINCL = 2\n\nIP_MULTICAST_IF = 9\n\nIP_MULTICAST_LOOP = 11\n\nIP_MULTICAST_TTL = 10\n\nIP_OPTIONS = 1\n\nIP_RECVDSTADDR = 25\n\nIP_TOS = 3\n\nIP_TTL = 4\n\nMSG_BCAST = 1024\n\nMSG_CTRUNC = 512\n\nMSG_DONTROUTE = 4\n\nMSG_MCAST = 2048\n\nMSG_OOB = 1\n\nMSG_PEEK = 2\n\nMSG_TRUNC = 256\n\nNI_DGRAM = 16\n\nNI_MAXHOST = 1025\n\nNI_MAXSERV = 32\n\nNI_NAMEREQD = 4\n\nNI_NOFQDN = 1\n\nNI_NUMERICHOST = 2\n\nNI_NUMERICSERV = 8\n\nRCVALL_MAX = 3\n\nRCVALL_OFF = 0\n\nRCVALL_ON = 1\n\nRCVALL_SOCKETLEVELONLY = 2\n\nSHUT_RD = 0\n\nSHUT_RDWR = 2\n\nSHUT_WR = 1\n\nSIO_KEEPALIVE_VALS = 2550136836\n\nSIO_RCVALL = 2550136833\n\nSOCK_DGRAM = 2\n\nSOCK_RAW = 3\n\nSOCK_RDM = 4\n\nSOCK_SEQPACKET = 5\n\nSOCK_STREAM = 1\n\nSOL_IP = 0\n\nSOL_SOCKET = 65535\n\nSOL_TCP = 6\n\nSOL_UDP = 17\n\nSOMAXCONN = 2147483647\n\nSO_ACCEPTCONN = 2\n\nSO_BROADCAST = 32\n\nSO_DEBUG = 1\n\nSO_DONTROUTE = 16\n\nSO_ERROR = 4103\n\nSO_EXCLUSIVEADDRUSE = -5\n\nSO_KEEPALIVE = 8\n\nSO_LINGER = 128\n\nSO_OOBINLINE = 256\n\nSO_RCVBUF = 4098\n\nSO_RCVLOWAT = 4100\n\nSO_RCVTIMEO = 4102\n\nSO_REUSEADDR = 4\n\nSO_SNDBUF = 4097\n\nSO_SNDLOWAT = 4099\n\nSO_SNDTIMEO = 4101\n\nSO_TYPE = 4104\n\nSO_USELOOPBACK = 64\n\nclass SocketType:\n    pass\n\nTCP_MAXSEG = 4\n\nTCP_NODELAY = 1\n\n__loader__ = '<_frozen_importlib.ExtensionFileLoader object at 0x00CA2D90>'\n\ndef dup(*args,**kw):\n    \"\"\"dup(integer) -> integer    \n    Duplicate an integer socket file descriptor.  This is like os.dup(), but for\n    sockets; on some platforms os.dup() won't work for socket file descriptors.\"\"\"\n    pass\n\nclass error:\n    pass\n\nclass gaierror:\n    pass\n\ndef getaddrinfo(*args,**kw):\n    \"\"\"getaddrinfo(host, port [, family, socktype, proto, flags])        -> list of (family, socktype, proto, canonname, sockaddr)\n    \n    Resolve host and port into addrinfo struct.\"\"\"\n    pass\n\ndef getdefaulttimeout(*args,**kw):\n    \"\"\"getdefaulttimeout() -> timeout    \n    Returns the default timeout in seconds (float) for new socket objects.\n    A value of None indicates that new socket objects have no timeout.\n    When the socket module is first imported, the default is None.\"\"\"\n    pass\n\ndef gethostbyaddr(*args,**kw):\n    \"\"\"gethostbyaddr(host) -> (name, aliaslist, addresslist)    \n    Return the true host name, a list of aliases, and a list of IP addresses,\n    for a host.  The host argument is a string giving a host name or IP number.\"\"\"\n    pass\n\ndef gethostbyname(*args,**kw):\n    \"\"\"gethostbyname(host) -> address    \n    Return the IP address (a string of the form '255.255.255.255') for a host.\"\"\"\n    pass\n\ndef gethostbyname_ex(*args,**kw):\n    \"\"\"gethostbyname_ex(host) -> (name, aliaslist, addresslist)    \n    Return the true host name, a list of aliases, and a list of IP addresses,\n    for a host.  The host argument is a string giving a host name or IP number.\"\"\"\n    pass\n\ndef gethostname(*args,**kw):\n    \"\"\"gethostname() -> string    \n    Return the current host name.\"\"\"\n    pass\n\ndef getnameinfo(*args,**kw):\n    \"\"\"getnameinfo(sockaddr, flags) --> (host, port)    \n    Get host and port for a sockaddr.\"\"\"\n    pass\n\ndef getprotobyname(*args,**kw):\n    \"\"\"getprotobyname(name) -> integer    \n    Return the protocol number for the named protocol.  (Rarely used.)\"\"\"\n    pass\n\ndef getservbyname(*args,**kw):\n    \"\"\"getservbyname(servicename[, protocolname]) -> integer    \n    Return a port number from a service name and protocol name.\n    The optional protocol name, if given, should be 'tcp' or 'udp',\n    otherwise any protocol will match.\"\"\"\n    pass\n\ndef getservbyport(*args,**kw):\n    \"\"\"getservbyport(port[, protocolname]) -> string    \n    Return the service name from a port number and protocol name.\n    The optional protocol name, if given, should be 'tcp' or 'udp',\n    otherwise any protocol will match.\"\"\"\n    pass\n\nhas_ipv6 = True\n\nclass herror:\n    pass\n\ndef htonl(*args,**kw):\n    \"\"\"htonl(integer) -> integer    \n    Convert a 32-bit integer from host to network byte order.\"\"\"\n    pass\n\ndef htons(*args,**kw):\n    \"\"\"htons(integer) -> integer    \n    Convert a 16-bit integer from host to network byte order.\"\"\"\n    pass\n\ndef inet_aton(*args,**kw):\n    \"\"\"inet_aton(string) -> bytes giving packed 32-bit IP representation    \n    Convert an IP address in string format (123.45.67.89) to the 32-bit packed\n    binary format used in low-level network functions.\"\"\"\n    pass\n\ndef inet_ntoa(*args,**kw):\n    \"\"\"inet_ntoa(packed_ip) -> ip_address_string    \n    Convert an IP address from 32-bit packed binary format to string format\"\"\"\n    pass\n\ndef ntohl(*args,**kw):\n    \"\"\"ntohl(integer) -> integer    \n    Convert a 32-bit integer from network to host byte order.\"\"\"\n    pass\n\ndef ntohs(*args,**kw):\n    \"\"\"ntohs(integer) -> integer    \n    Convert a 16-bit integer from network to host byte order.\"\"\"\n    pass\n\ndef setdefaulttimeout(*args,**kw):\n    \"\"\"setdefaulttimeout(timeout)    \n    Set the default timeout in seconds (float) for new socket objects.\n    A value of None indicates that new socket objects have no timeout.\n    When the socket module is first imported, the default is None.\"\"\"\n    pass\n\nclass socket:\n    def __init__(self,*args,**kw):\n        pass\n    def bind(self,*args,**kw):\n        pass\n    def close(self):\n        pass\n\nclass timeout:\n    pass\n"], "binascii": [".py", "\"\"\"A pure Python implementation of binascii.\n\nRather slow and buggy in corner cases.\nPyPy provides an RPython version too.\n\"\"\"\n\n# borrowed from https://bitbucket.org/pypy/pypy/src/f2bf94943a41/lib_pypy/binascii.py\n\nclass Error(Exception):\n    pass\n\nclass Done(Exception):\n    pass\n\nclass Incomplete(Exception):\n    pass\n\ndef a2b_uu(s):\n    if not s:\n        return ''\n    \n    length = (ord(s[0]) - 0x20) % 64\n\n    def quadruplets_gen(s):\n        while s:\n            try:\n                yield ord(s[0]), ord(s[1]), ord(s[2]), ord(s[3])\n            except IndexError:\n                s += '   '\n                yield ord(s[0]), ord(s[1]), ord(s[2]), ord(s[3])\n                return\n            s = s[4:]\n\n    try:\n        result = [''.join(\n            [chr((A - 0x20) << 2 | (((B - 0x20) >> 4) & 0x3)),\n            chr(((B - 0x20) & 0xf) << 4 | (((C - 0x20) >> 2) & 0xf)),\n            chr(((C - 0x20) & 0x3) << 6 | ((D - 0x20) & 0x3f))\n            ]) for A, B, C, D in quadruplets_gen(s[1:].rstrip())]\n    except ValueError:\n        raise Error('Illegal char')\n    result = ''.join(result)\n    trailingdata = result[length:]\n    if trailingdata.strip('\\x00'):\n        raise Error('Trailing garbage')\n    result = result[:length]\n    if len(result) < length:\n        result += ((length - len(result)) * '\\x00')\n    return bytes(result, __BRYTHON__.charset)\n\n\ndef b2a_uu(s):\n    length = len(s)\n    if length > 45:\n        raise Error('At most 45 bytes at once')\n\n    def triples_gen(s):\n        while s:\n            try:\n                yield ord(s[0]), ord(s[1]), ord(s[2])\n            except IndexError:\n                s += '\\0\\0'\n                yield ord(s[0]), ord(s[1]), ord(s[2])\n                return\n            s = s[3:]\n\n    result = [''.join(\n        [chr(0x20 + (( A >> 2                    ) & 0x3F)),\n         chr(0x20 + (((A << 4) | ((B >> 4) & 0xF)) & 0x3F)),\n         chr(0x20 + (((B << 2) | ((C >> 6) & 0x3)) & 0x3F)),\n         chr(0x20 + (( C                         ) & 0x3F))])\n              for A, B, C in triples_gen(s)]\n    return chr(ord(' ') + (length & 0o77)) + ''.join(result) + '\\n'\n\n\ntable_a2b_base64 = {\n    'A': 0,\n    'B': 1,\n    'C': 2,\n    'D': 3,\n    'E': 4,\n    'F': 5,\n    'G': 6,\n    'H': 7,\n    'I': 8,\n    'J': 9,\n    'K': 10,\n    'L': 11,\n    'M': 12,\n    'N': 13,\n    'O': 14,\n    'P': 15,\n    'Q': 16,\n    'R': 17,\n    'S': 18,\n    'T': 19,\n    'U': 20,\n    'V': 21,\n    'W': 22,\n    'X': 23,\n    'Y': 24,\n    'Z': 25,\n    'a': 26,\n    'b': 27,\n    'c': 28,\n    'd': 29,\n    'e': 30,\n    'f': 31,\n    'g': 32,\n    'h': 33,\n    'i': 34,\n    'j': 35,\n    'k': 36,\n    'l': 37,\n    'm': 38,\n    'n': 39,\n    'o': 40,\n    'p': 41,\n    'q': 42,\n    'r': 43,\n    's': 44,\n    't': 45,\n    'u': 46,\n    'v': 47,\n    'w': 48,\n    'x': 49,\n    'y': 50,\n    'z': 51,\n    '0': 52,\n    '1': 53,\n    '2': 54,\n    '3': 55,\n    '4': 56,\n    '5': 57,\n    '6': 58,\n    '7': 59,\n    '8': 60,\n    '9': 61,\n    '+': 62,\n    '/': 63,\n    '=': 0,\n}\n\n\ndef a2b_base64(s):\n    if not isinstance(s, (str, bytes)):\n        raise TypeError(\"expected string, got %r\" % (s,))\n    s = s.rstrip()\n    # clean out all invalid characters, this also strips the final '=' padding\n    # check for correct padding\n\n    def next_valid_char(s, pos):\n        for i in range(pos + 1, len(s)):\n            c = s[i]\n            if c < '\\x7f':\n                try:\n                    table_a2b_base64[c]\n                    return c\n                except KeyError:\n                    pass\n        return None\n    \n    quad_pos = 0\n    leftbits = 0\n    leftchar = 0\n    res = []\n    for i, c in enumerate(s):\n        if isinstance(c, int):\n            c = chr(c)\n        if c > '\\x7f' or c == '\\n' or c == '\\r' or c == ' ':\n            continue\n        if c == '=':\n            if quad_pos < 2 or (quad_pos == 2 and next_valid_char(s, i) != '='):\n                continue\n            else:\n                leftbits = 0\n                break\n        try:\n            next_c = table_a2b_base64[c]\n        except KeyError:\n            continue\n        quad_pos = (quad_pos + 1) & 0x03\n        leftchar = (leftchar << 6) | next_c\n        leftbits += 6\n        if leftbits >= 8:\n            leftbits -= 8\n            res.append((leftchar >> leftbits & 0xff))\n            leftchar &= ((1 << leftbits) - 1)\n    if leftbits != 0:\n        raise Error('Incorrect padding')\n\n    return bytes(''.join([chr(i) for i in res]),__BRYTHON__.charset)\n    \ntable_b2a_base64 = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\\\n    \"0123456789+/\"\n\ndef b2a_base64(s):\n    length = len(s)\n    final_length = length % 3\n\n    def triples_gen(s):\n        while s:\n            try:\n                yield s[0], s[1], s[2]\n            except IndexError:\n                s += b'\\0\\0'\n                yield s[0], s[1], s[2]\n                return\n            s = s[3:]\n\n    a = triples_gen(s[ :length - final_length])\n\n    result = [''.join(\n        [table_b2a_base64[( A >> 2                    ) & 0x3F],\n         table_b2a_base64[((A << 4) | ((B >> 4) & 0xF)) & 0x3F],\n         table_b2a_base64[((B << 2) | ((C >> 6) & 0x3)) & 0x3F],\n         table_b2a_base64[( C                         ) & 0x3F]])\n              for A, B, C in a]\n\n    final = s[length - final_length:]\n    if final_length == 0:\n        snippet = ''\n    elif final_length == 1:\n        a = ord(final[0])\n        snippet = table_b2a_base64[(a >> 2 ) & 0x3F] + \\\n                  table_b2a_base64[(a << 4 ) & 0x3F] + '=='\n    else:\n        a = ord(final[0])\n        b = ord(final[1])\n        snippet = table_b2a_base64[(a >> 2) & 0x3F] + \\\n                  table_b2a_base64[((a << 4) | (b >> 4) & 0xF) & 0x3F] + \\\n                  table_b2a_base64[(b << 2) & 0x3F] + '='\n\n    return bytes(''.join(result) + snippet + '\\n',__BRYTHON__.charset)\n\ndef a2b_qp(s, header=False):\n    inp = 0\n    odata = []\n    while inp < len(s):\n        if s[inp] == '=':\n            inp += 1\n            if inp >= len(s):\n                break\n            # Soft line breaks\n            if (s[inp] == '\\n') or (s[inp] == '\\r'):\n                if s[inp] != '\\n':\n                    while inp < len(s) and s[inp] != '\\n':\n                        inp += 1\n                if inp < len(s):\n                    inp += 1\n            elif s[inp] == '=':\n                # broken case from broken python qp\n                odata.append('=')\n                inp += 1\n            elif s[inp] in hex_numbers and s[inp + 1] in hex_numbers:\n                ch = chr(int(s[inp:inp+2], 16))\n                inp += 2\n                odata.append(ch)\n            else:\n                odata.append('=')\n        elif header and s[inp] == '_':\n            odata.append(' ')\n            inp += 1\n        else:\n            odata.append(s[inp])\n            inp += 1\n    return bytes(''.join(odata), __BRYTHON__.charset)\n\ndef b2a_qp(data, quotetabs=False, istext=True, header=False):\n    \"\"\"quotetabs=True means that tab and space characters are always\n       quoted.\n       istext=False means that \\r and \\n are treated as regular characters\n       header=True encodes space characters with '_' and requires\n       real '_' characters to be quoted.\n    \"\"\"\n    MAXLINESIZE = 76\n\n    # See if this string is using CRLF line ends\n    lf = data.find('\\n')\n    crlf = lf > 0 and data[lf-1] == '\\r'\n\n    inp = 0\n    linelen = 0\n    odata = []\n    while inp < len(data):\n        c = data[inp]\n        if (c > '~' or\n            c == '=' or\n            (header and c == '_') or\n            (c == '.' and linelen == 0 and (inp+1 == len(data) or\n                                            data[inp+1] == '\\n' or\n                                            data[inp+1] == '\\r')) or\n            (not istext and (c == '\\r' or c == '\\n')) or\n            ((c == '\\t' or c == ' ') and (inp + 1 == len(data))) or\n            (c <= ' ' and c != '\\r' and c != '\\n' and\n             (quotetabs or (not quotetabs and (c != '\\t' and c != ' '))))):\n            linelen += 3\n            if linelen >= MAXLINESIZE:\n                odata.append('=')\n                if crlf: odata.append('\\r')\n                odata.append('\\n')\n                linelen = 3\n            odata.append('=' + two_hex_digits(ord(c)))\n            inp += 1\n        else:\n            if (istext and\n                (c == '\\n' or (inp+1 < len(data) and c == '\\r' and\n                               data[inp+1] == '\\n'))):\n                linelen = 0\n                # Protect against whitespace on end of line\n                if (len(odata) > 0 and\n                    (odata[-1] == ' ' or odata[-1] == '\\t')):\n                    ch = ord(odata[-1])\n                    odata[-1] = '='\n                    odata.append(two_hex_digits(ch))\n\n                if crlf: odata.append('\\r')\n                odata.append('\\n')\n                if c == '\\r':\n                    inp += 2\n                else:\n                    inp += 1\n            else:\n                if (inp + 1 < len(data) and\n                    data[inp+1] != '\\n' and\n                    (linelen + 1) >= MAXLINESIZE):\n                    odata.append('=')\n                    if crlf: odata.append('\\r')\n                    odata.append('\\n')\n                    linelen = 0\n\n                linelen += 1\n                if header and c == ' ':\n                    c = '_'\n                odata.append(c)\n                inp += 1\n    return ''.join(odata)\n\nhex_numbers = '0123456789ABCDEF'\ndef hex(n):\n    if n == 0:\n        return '0'\n    \n    if n < 0:\n        n = -n\n        sign = '-'\n    else:\n        sign = ''\n    arr = []\n\n    def hex_gen(n):\n        \"\"\" Yield a nibble at a time. \"\"\"\n        while n:\n            yield n % 0x10\n            n = n / 0x10\n\n    for nibble in hex_gen(n):\n        arr = [hex_numbers[nibble]] + arr\n    return sign + ''.join(arr)\n\ndef two_hex_digits(n):\n    return hex_numbers[n / 0x10] + hex_numbers[n % 0x10]\n    \n\ndef strhex_to_int(s):\n    i = 0\n    for c in s:\n        i = i * 0x10 + hex_numbers.index(c)\n    return i\n\nhqx_encoding = '!\"#$%&\\'()*+,-012345689@ABCDEFGHIJKLMNPQRSTUVXYZ[`abcdefhijklmpqr'\n\nDONE = 0x7f\nSKIP = 0x7e\nFAIL = 0x7d\n    \ntable_a2b_hqx = [\n    #^@    ^A    ^B    ^C    ^D    ^E    ^F    ^G   \n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    #\\b    \\t    \\n    ^K    ^L    \\r    ^N    ^O   \n    FAIL, FAIL, SKIP, FAIL, FAIL, SKIP, FAIL, FAIL,\n    #^P    ^Q    ^R    ^S    ^T    ^U    ^V    ^W   \n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    #^X    ^Y    ^Z    ^[    ^\\    ^]    ^^    ^_   \n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    #      !     \"     #     $     %     &     '   \n    FAIL, 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06,\n    #(     )     *     +     ,     -     .     /   \n    0x07, 0x08, 0x09, 0x0A, 0x0B, 0x0C, FAIL, FAIL,\n    #0     1     2     3     4     5     6     7   \n    0x0D, 0x0E, 0x0F, 0x10, 0x11, 0x12, 0x13, FAIL,\n    #8     9     :     ;     <     =     >     ?   \n    0x14, 0x15, DONE, FAIL, FAIL, FAIL, FAIL, FAIL,\n    #@     A     B     C     D     E     F     G   \n    0x16, 0x17, 0x18, 0x19, 0x1A, 0x1B, 0x1C, 0x1D,\n    #H     I     J     K     L     M     N     O   \n    0x1E, 0x1F, 0x20, 0x21, 0x22, 0x23, 0x24, FAIL,\n    #P     Q     R     S     T     U     V     W   \n    0x25, 0x26, 0x27, 0x28, 0x29, 0x2A, 0x2B, FAIL,\n    #X     Y     Z     [     \\     ]     ^     _   \n    0x2C, 0x2D, 0x2E, 0x2F, FAIL, FAIL, FAIL, FAIL,\n    #`     a     b     c     d     e     f     g   \n    0x30, 0x31, 0x32, 0x33, 0x34, 0x35, 0x36, FAIL,\n    #h     i     j     k     l     m     n     o   \n    0x37, 0x38, 0x39, 0x3A, 0x3B, 0x3C, FAIL, FAIL,\n    #p     q     r     s     t     u     v     w   \n    0x3D, 0x3E, 0x3F, FAIL, FAIL, FAIL, FAIL, FAIL,\n    #x     y     z     {     |     }     ~    ^?   \n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n    FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n]\n\ndef a2b_hqx(s):\n    result = []\n\n    def quadruples_gen(s):\n        t = []\n        for c in s:\n            res = table_a2b_hqx[ord(c)]\n            if res == SKIP:\n                continue\n            elif res == FAIL:\n                raise Error('Illegal character')\n            elif res == DONE:\n                yield t\n                raise Done\n            else:\n                t.append(res)\n            if len(t) == 4:\n                yield t\n                t = []\n        yield t\n        \n    done = 0\n    try:\n        for snippet in quadruples_gen(s):\n            length = len(snippet)\n            if length == 4:\n                result.append(chr(((snippet[0] & 0x3f) << 2) | (snippet[1] >> 4))) \n                result.append(chr(((snippet[1] & 0x0f) << 4) | (snippet[2] >> 2))) \n                result.append(chr(((snippet[2] & 0x03) << 6) | (snippet[3]))) \n            elif length == 3:\n                result.append(chr(((snippet[0] & 0x3f) << 2) | (snippet[1] >> 4))) \n                result.append(chr(((snippet[1] & 0x0f) << 4) | (snippet[2] >> 2))) \n            elif length == 2:\n                result.append(chr(((snippet[0] & 0x3f) << 2) | (snippet[1] >> 4))) \n    except Done:\n        done = 1\n    except Error:\n        raise\n    return (''.join(result), done)\n    # should this return a bytes object?\n    #return (bytes(''.join(result), __BRYTHON__.charset), done)\n\ndef b2a_hqx(s):\n    result =[]\n\n    def triples_gen(s):\n        while s:\n            try:\n                yield ord(s[0]), ord(s[1]), ord(s[2])\n            except IndexError:\n                yield tuple([ord(c) for c in s])\n            s = s[3:]\n\n    for snippet in triples_gen(s):\n        length = len(snippet)\n        if length == 3:\n            result.append(\n                hqx_encoding[(snippet[0] & 0xfc) >> 2])\n            result.append(hqx_encoding[\n                ((snippet[0] & 0x03) << 4) | ((snippet[1] & 0xf0) >> 4)])\n            result.append(hqx_encoding[\n                (snippet[1] & 0x0f) << 2 | ((snippet[2] & 0xc0) >> 6)])\n            result.append(hqx_encoding[snippet[2] & 0x3f])\n        elif length == 2:\n            result.append(\n                hqx_encoding[(snippet[0] & 0xfc) >> 2])\n            result.append(hqx_encoding[\n                ((snippet[0] & 0x03) << 4) | ((snippet[1] & 0xf0) >> 4)])\n            result.append(hqx_encoding[\n                (snippet[1] & 0x0f) << 2])\n        elif length == 1:\n            result.append(\n                hqx_encoding[(snippet[0] & 0xfc) >> 2])\n            result.append(hqx_encoding[\n                ((snippet[0] & 0x03) << 4)])\n    return ''.join(result)\n\ncrctab_hqx = [\n        0x0000, 0x1021, 0x2042, 0x3063, 0x4084, 0x50a5, 0x60c6, 0x70e7,\n        0x8108, 0x9129, 0xa14a, 0xb16b, 0xc18c, 0xd1ad, 0xe1ce, 0xf1ef,\n        0x1231, 0x0210, 0x3273, 0x2252, 0x52b5, 0x4294, 0x72f7, 0x62d6,\n        0x9339, 0x8318, 0xb37b, 0xa35a, 0xd3bd, 0xc39c, 0xf3ff, 0xe3de,\n        0x2462, 0x3443, 0x0420, 0x1401, 0x64e6, 0x74c7, 0x44a4, 0x5485,\n        0xa56a, 0xb54b, 0x8528, 0x9509, 0xe5ee, 0xf5cf, 0xc5ac, 0xd58d,\n        0x3653, 0x2672, 0x1611, 0x0630, 0x76d7, 0x66f6, 0x5695, 0x46b4,\n        0xb75b, 0xa77a, 0x9719, 0x8738, 0xf7df, 0xe7fe, 0xd79d, 0xc7bc,\n        0x48c4, 0x58e5, 0x6886, 0x78a7, 0x0840, 0x1861, 0x2802, 0x3823,\n        0xc9cc, 0xd9ed, 0xe98e, 0xf9af, 0x8948, 0x9969, 0xa90a, 0xb92b,\n        0x5af5, 0x4ad4, 0x7ab7, 0x6a96, 0x1a71, 0x0a50, 0x3a33, 0x2a12,\n        0xdbfd, 0xcbdc, 0xfbbf, 0xeb9e, 0x9b79, 0x8b58, 0xbb3b, 0xab1a,\n        0x6ca6, 0x7c87, 0x4ce4, 0x5cc5, 0x2c22, 0x3c03, 0x0c60, 0x1c41,\n        0xedae, 0xfd8f, 0xcdec, 0xddcd, 0xad2a, 0xbd0b, 0x8d68, 0x9d49,\n        0x7e97, 0x6eb6, 0x5ed5, 0x4ef4, 0x3e13, 0x2e32, 0x1e51, 0x0e70,\n        0xff9f, 0xefbe, 0xdfdd, 0xcffc, 0xbf1b, 0xaf3a, 0x9f59, 0x8f78,\n        0x9188, 0x81a9, 0xb1ca, 0xa1eb, 0xd10c, 0xc12d, 0xf14e, 0xe16f,\n        0x1080, 0x00a1, 0x30c2, 0x20e3, 0x5004, 0x4025, 0x7046, 0x6067,\n        0x83b9, 0x9398, 0xa3fb, 0xb3da, 0xc33d, 0xd31c, 0xe37f, 0xf35e,\n        0x02b1, 0x1290, 0x22f3, 0x32d2, 0x4235, 0x5214, 0x6277, 0x7256,\n        0xb5ea, 0xa5cb, 0x95a8, 0x8589, 0xf56e, 0xe54f, 0xd52c, 0xc50d,\n        0x34e2, 0x24c3, 0x14a0, 0x0481, 0x7466, 0x6447, 0x5424, 0x4405,\n        0xa7db, 0xb7fa, 0x8799, 0x97b8, 0xe75f, 0xf77e, 0xc71d, 0xd73c,\n        0x26d3, 0x36f2, 0x0691, 0x16b0, 0x6657, 0x7676, 0x4615, 0x5634,\n        0xd94c, 0xc96d, 0xf90e, 0xe92f, 0x99c8, 0x89e9, 0xb98a, 0xa9ab,\n        0x5844, 0x4865, 0x7806, 0x6827, 0x18c0, 0x08e1, 0x3882, 0x28a3,\n        0xcb7d, 0xdb5c, 0xeb3f, 0xfb1e, 0x8bf9, 0x9bd8, 0xabbb, 0xbb9a,\n        0x4a75, 0x5a54, 0x6a37, 0x7a16, 0x0af1, 0x1ad0, 0x2ab3, 0x3a92,\n        0xfd2e, 0xed0f, 0xdd6c, 0xcd4d, 0xbdaa, 0xad8b, 0x9de8, 0x8dc9,\n        0x7c26, 0x6c07, 0x5c64, 0x4c45, 0x3ca2, 0x2c83, 0x1ce0, 0x0cc1,\n        0xef1f, 0xff3e, 0xcf5d, 0xdf7c, 0xaf9b, 0xbfba, 0x8fd9, 0x9ff8,\n        0x6e17, 0x7e36, 0x4e55, 0x5e74, 0x2e93, 0x3eb2, 0x0ed1, 0x1ef0,\n]\n\ndef crc_hqx(s, crc):\n    for c in s:\n        crc = ((crc << 8) & 0xff00) ^ crctab_hqx[((crc >> 8) & 0xff) ^ ord(c)]\n\n    return crc\n\ndef rlecode_hqx(s):\n    \"\"\"\n    Run length encoding for binhex4.\n    The CPython implementation does not do run length encoding\n    of \\x90 characters. This implementation does.\n    \"\"\"\n    if not s:\n        return ''\n    result = []\n    prev = s[0]\n    count = 1\n    # Add a dummy character to get the loop to go one extra round.\n    # The dummy must be different from the last character of s.\n    # In the same step we remove the first character, which has\n    # already been stored in prev.\n    if s[-1] == '!':\n        s = s[1:] + '?'\n    else:\n        s = s[1:] + '!'\n        \n    for c in s:\n        if c == prev and count < 255:\n            count += 1\n        else:\n            if count == 1:\n                if prev != '\\x90':\n                    result.append(prev)\n                else:\n                    result.extend(['\\x90', '\\x00'])\n            elif count < 4:\n                if prev != '\\x90':\n                    result.extend([prev] * count)\n                else:\n                    result.extend(['\\x90', '\\x00'] * count)\n            else:\n                if prev != '\\x90':\n                    result.extend([prev, '\\x90', chr(count)])\n                else:\n                    result.extend(['\\x90', '\\x00', '\\x90', chr(count)]) \n            count = 1\n            prev = c\n        \n    return ''.join(result)\n\ndef rledecode_hqx(s):\n    s = s.split('\\x90')\n    result = [s[0]]\n    prev = s[0]\n    for snippet in s[1:]:\n        count = ord(snippet[0])\n        if count > 0:\n            result.append(prev[-1] * (count-1))\n            prev = snippet\n        else:\n            result.append('\\x90')\n            prev = '\\x90'\n        result.append(snippet[1:])\n\n    return ''.join(result)\n\ncrc_32_tab = [\n    0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419,\n    0x706af48f, 0xe963a535, 0x9e6495a3, 0x0edb8832, 0x79dcb8a4,\n    0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07,\n    0x90bf1d91, 0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de,\n    0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7, 0x136c9856,\n    0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9,\n    0xfa0f3d63, 0x8d080df5, 0x3b6e20c8, 0x4c69105e, 0xd56041e4,\n    0xa2677172, 0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b,\n    0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3,\n    0x45df5c75, 0xdcd60dcf, 0xabd13d59, 0x26d930ac, 0x51de003a,\n    0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423, 0xcfba9599,\n    0xb8bda50f, 0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924,\n    0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d, 0x76dc4190,\n    0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f,\n    0x9fbfe4a5, 0xe8b8d433, 0x7807c9a2, 0x0f00f934, 0x9609a88e,\n    0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01,\n    0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed,\n    0x1b01a57b, 0x8208f4c1, 0xf50fc457, 0x65b0d9c6, 0x12b7e950,\n    0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3,\n    0xfbd44c65, 0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2,\n    0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb, 0x4369e96a,\n    0x346ed9fc, 0xad678846, 0xda60b8d0, 0x44042d73, 0x33031de5,\n    0xaa0a4c5f, 0xdd0d7cc9, 0x5005713c, 0x270241aa, 0xbe0b1010,\n    0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,\n    0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17,\n    0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad, 0xedb88320, 0x9abfb3b6,\n    0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615,\n    0x73dc1683, 0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8,\n    0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1, 0xf00f9344,\n    0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb,\n    0x196c3671, 0x6e6b06e7, 0xfed41b76, 0x89d32be0, 0x10da7a5a,\n    0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5,\n    0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252, 0xd1bb67f1,\n    0xa6bc5767, 0x3fb506dd, 0x48b2364b, 0xd80d2bda, 0xaf0a1b4c,\n    0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef,\n    0x4669be79, 0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236,\n    0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f, 0xc5ba3bbe,\n    0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31,\n    0x2cd99e8b, 0x5bdeae1d, 0x9b64c2b0, 0xec63f226, 0x756aa39c,\n    0x026d930a, 0x9c0906a9, 0xeb0e363f, 0x72076785, 0x05005713,\n    0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b,\n    0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21, 0x86d3d2d4, 0xf1d4e242,\n    0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1,\n    0x18b74777, 0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c,\n    0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45, 0xa00ae278,\n    0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7,\n    0x4969474d, 0x3e6e77db, 0xaed16a4a, 0xd9d65adc, 0x40df0b66,\n    0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,\n    0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605,\n    0xcdd70693, 0x54de5729, 0x23d967bf, 0xb3667a2e, 0xc4614ab8,\n    0x5d681b02, 0x2a6f2b94, 0xb40bbe37, 0xc30c8ea1, 0x5a05df1b,\n    0x2d02ef8d\n]\n\ndef crc32(s, crc=0):\n    result = 0\n    crc = ~int(crc) & 0xffffffff\n    #crc = ~long(crc) & 0xffffffffL\n    for c in s:\n        crc = crc_32_tab[(crc ^ int(ord(c))) & 0xff] ^ (crc >> 8)\n        #crc = crc_32_tab[(crc ^ long(ord(c))) & 0xffL] ^ (crc >> 8)\n        #/* Note:  (crc >> 8) MUST zero fill on left\n\n    result = crc ^ 0xffffffff\n    \n    if result > 2**31:\n        result = ((result + 2**31) % 2**32) - 2**31\n\n    return result\n\ndef b2a_hex(s):\n    result = []\n    for char in s:\n        c = (ord(char) >> 4) & 0xf\n        if c > 9:\n            c = c + ord('a') - 10\n        else:\n            c = c + ord('0')\n        result.append(chr(c))\n        c = ord(char) & 0xf\n        if c > 9:\n            c = c + ord('a') - 10\n        else:\n            c = c + ord('0')\n        result.append(chr(c))\n    return ''.join(result)\n\nhexlify = b2a_hex\n\ntable_hex = [\n    -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n    -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n    -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n    0, 1, 2, 3,  4, 5, 6, 7,  8, 9,-1,-1, -1,-1,-1,-1,\n    -1,10,11,12, 13,14,15,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n    -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n    -1,10,11,12, 13,14,15,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n    -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1\n]\n\n\ndef a2b_hex(t):\n    result = []\n\n    def pairs_gen(s):\n        while s:\n            try:\n                yield table_hex[ord(s[0])], table_hex[ord(s[1])]\n            except IndexError:\n                if len(s):\n                    raise TypeError('Odd-length string')\n                return\n            s = s[2:]\n\n    for a, b in pairs_gen(t):\n        if a < 0 or b < 0:\n            raise TypeError('Non-hexadecimal digit found')\n        result.append(chr((a << 4) + b))\n    return bytes(''.join(result), __BRYTHON__.charset)\n    \n\nunhexlify = a2b_hex\n"], "sre_constants": [".py", "#\n# Secret Labs' Regular Expression Engine\n#\n# various symbols used by the regular expression engine.\n# run this script to update the _sre include files!\n#\n# Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\n#\n# See the sre.py file for information on usage and redistribution.\n#\n\n\"\"\"Internal support module for sre\"\"\"\n\n# update when constants are added or removed\n\nMAGIC = 20031017\n\n#MAXREPEAT = 2147483648\n#from _sre import MAXREPEAT\n\n# SRE standard exception (access as sre.error)\n# should this really be here?\n\nclass error(Exception):\n    pass\n\n# operators\n\nFAILURE = \"failure\"\nSUCCESS = \"success\"\n\nANY = \"any\"\nANY_ALL = \"any_all\"\nASSERT = \"assert\"\nASSERT_NOT = \"assert_not\"\nAT = \"at\"\nBIGCHARSET = \"bigcharset\"\nBRANCH = \"branch\"\nCALL = \"call\"\nCATEGORY = \"category\"\nCHARSET = \"charset\"\nGROUPREF = \"groupref\"\nGROUPREF_IGNORE = \"groupref_ignore\"\nGROUPREF_EXISTS = \"groupref_exists\"\nIN = \"in\"\nIN_IGNORE = \"in_ignore\"\nINFO = \"info\"\nJUMP = \"jump\"\nLITERAL = \"literal\"\nLITERAL_IGNORE = \"literal_ignore\"\nMARK = \"mark\"\nMAX_REPEAT = \"max_repeat\"\nMAX_UNTIL = \"max_until\"\nMIN_REPEAT = \"min_repeat\"\nMIN_UNTIL = \"min_until\"\nNEGATE = \"negate\"\nNOT_LITERAL = \"not_literal\"\nNOT_LITERAL_IGNORE = \"not_literal_ignore\"\nRANGE = \"range\"\nREPEAT = \"repeat\"\nREPEAT_ONE = \"repeat_one\"\nSUBPATTERN = \"subpattern\"\nMIN_REPEAT_ONE = \"min_repeat_one\"\n\n# positions\nAT_BEGINNING = \"at_beginning\"\nAT_BEGINNING_LINE = \"at_beginning_line\"\nAT_BEGINNING_STRING = \"at_beginning_string\"\nAT_BOUNDARY = \"at_boundary\"\nAT_NON_BOUNDARY = \"at_non_boundary\"\nAT_END = \"at_end\"\nAT_END_LINE = \"at_end_line\"\nAT_END_STRING = \"at_end_string\"\nAT_LOC_BOUNDARY = \"at_loc_boundary\"\nAT_LOC_NON_BOUNDARY = \"at_loc_non_boundary\"\nAT_UNI_BOUNDARY = \"at_uni_boundary\"\nAT_UNI_NON_BOUNDARY = \"at_uni_non_boundary\"\n\n# categories\nCATEGORY_DIGIT = \"category_digit\"\nCATEGORY_NOT_DIGIT = \"category_not_digit\"\nCATEGORY_SPACE = \"category_space\"\nCATEGORY_NOT_SPACE = \"category_not_space\"\nCATEGORY_WORD = \"category_word\"\nCATEGORY_NOT_WORD = \"category_not_word\"\nCATEGORY_LINEBREAK = \"category_linebreak\"\nCATEGORY_NOT_LINEBREAK = \"category_not_linebreak\"\nCATEGORY_LOC_WORD = \"category_loc_word\"\nCATEGORY_LOC_NOT_WORD = \"category_loc_not_word\"\nCATEGORY_UNI_DIGIT = \"category_uni_digit\"\nCATEGORY_UNI_NOT_DIGIT = \"category_uni_not_digit\"\nCATEGORY_UNI_SPACE = \"category_uni_space\"\nCATEGORY_UNI_NOT_SPACE = \"category_uni_not_space\"\nCATEGORY_UNI_WORD = \"category_uni_word\"\nCATEGORY_UNI_NOT_WORD = \"category_uni_not_word\"\nCATEGORY_UNI_LINEBREAK = \"category_uni_linebreak\"\nCATEGORY_UNI_NOT_LINEBREAK = \"category_uni_not_linebreak\"\n\nOPCODES = [\n\n    # failure=0 success=1 (just because it looks better that way :-)\n    FAILURE, SUCCESS,\n\n    ANY, ANY_ALL,\n    ASSERT, ASSERT_NOT,\n    AT,\n    BRANCH,\n    CALL,\n    CATEGORY,\n    CHARSET, BIGCHARSET,\n    GROUPREF, GROUPREF_EXISTS, GROUPREF_IGNORE,\n    IN, IN_IGNORE,\n    INFO,\n    JUMP,\n    LITERAL, LITERAL_IGNORE,\n    MARK,\n    MAX_UNTIL,\n    MIN_UNTIL,\n    NOT_LITERAL, NOT_LITERAL_IGNORE,\n    NEGATE,\n    RANGE,\n    REPEAT,\n    REPEAT_ONE,\n    SUBPATTERN,\n    MIN_REPEAT_ONE\n\n]\n\nATCODES = [\n    AT_BEGINNING, AT_BEGINNING_LINE, AT_BEGINNING_STRING, AT_BOUNDARY,\n    AT_NON_BOUNDARY, AT_END, AT_END_LINE, AT_END_STRING,\n    AT_LOC_BOUNDARY, AT_LOC_NON_BOUNDARY, AT_UNI_BOUNDARY,\n    AT_UNI_NON_BOUNDARY\n]\n\nCHCODES = [\n    CATEGORY_DIGIT, CATEGORY_NOT_DIGIT, CATEGORY_SPACE,\n    CATEGORY_NOT_SPACE, CATEGORY_WORD, CATEGORY_NOT_WORD,\n    CATEGORY_LINEBREAK, CATEGORY_NOT_LINEBREAK, CATEGORY_LOC_WORD,\n    CATEGORY_LOC_NOT_WORD, CATEGORY_UNI_DIGIT, CATEGORY_UNI_NOT_DIGIT,\n    CATEGORY_UNI_SPACE, CATEGORY_UNI_NOT_SPACE, CATEGORY_UNI_WORD,\n    CATEGORY_UNI_NOT_WORD, CATEGORY_UNI_LINEBREAK,\n    CATEGORY_UNI_NOT_LINEBREAK\n]\n\ndef makedict(list):\n    d = {}\n    i = 0\n    for item in list:\n        d[item] = i\n        i = i + 1\n    return d\n\nOPCODES = makedict(OPCODES)\nATCODES = makedict(ATCODES)\nCHCODES = makedict(CHCODES)\n\n# replacement operations for \"ignore case\" mode\nOP_IGNORE = {\n    GROUPREF: GROUPREF_IGNORE,\n    IN: IN_IGNORE,\n    LITERAL: LITERAL_IGNORE,\n    NOT_LITERAL: NOT_LITERAL_IGNORE\n}\n\nAT_MULTILINE = {\n    AT_BEGINNING: AT_BEGINNING_LINE,\n    AT_END: AT_END_LINE\n}\n\nAT_LOCALE = {\n    AT_BOUNDARY: AT_LOC_BOUNDARY,\n    AT_NON_BOUNDARY: AT_LOC_NON_BOUNDARY\n}\n\nAT_UNICODE = {\n    AT_BOUNDARY: AT_UNI_BOUNDARY,\n    AT_NON_BOUNDARY: AT_UNI_NON_BOUNDARY\n}\n\nCH_LOCALE = {\n    CATEGORY_DIGIT: CATEGORY_DIGIT,\n    CATEGORY_NOT_DIGIT: CATEGORY_NOT_DIGIT,\n    CATEGORY_SPACE: CATEGORY_SPACE,\n    CATEGORY_NOT_SPACE: CATEGORY_NOT_SPACE,\n    CATEGORY_WORD: CATEGORY_LOC_WORD,\n    CATEGORY_NOT_WORD: CATEGORY_LOC_NOT_WORD,\n    CATEGORY_LINEBREAK: CATEGORY_LINEBREAK,\n    CATEGORY_NOT_LINEBREAK: CATEGORY_NOT_LINEBREAK\n}\n\nCH_UNICODE = {\n    CATEGORY_DIGIT: CATEGORY_UNI_DIGIT,\n    CATEGORY_NOT_DIGIT: CATEGORY_UNI_NOT_DIGIT,\n    CATEGORY_SPACE: CATEGORY_UNI_SPACE,\n    CATEGORY_NOT_SPACE: CATEGORY_UNI_NOT_SPACE,\n    CATEGORY_WORD: CATEGORY_UNI_WORD,\n    CATEGORY_NOT_WORD: CATEGORY_UNI_NOT_WORD,\n    CATEGORY_LINEBREAK: CATEGORY_UNI_LINEBREAK,\n    CATEGORY_NOT_LINEBREAK: CATEGORY_UNI_NOT_LINEBREAK\n}\n\n# flags\nSRE_FLAG_TEMPLATE = 1 # template mode (disable backtracking)\nSRE_FLAG_IGNORECASE = 2 # case insensitive\nSRE_FLAG_LOCALE = 4 # honour system locale\nSRE_FLAG_MULTILINE = 8 # treat target as multiline string\nSRE_FLAG_DOTALL = 16 # treat target as a single string\nSRE_FLAG_UNICODE = 32 # use unicode \"locale\"\nSRE_FLAG_VERBOSE = 64 # ignore whitespace and comments\nSRE_FLAG_DEBUG = 128 # debugging\nSRE_FLAG_ASCII = 256 # use ascii \"locale\"\n\n# flags for INFO primitive\nSRE_INFO_PREFIX = 1 # has prefix\nSRE_INFO_LITERAL = 2 # entire pattern is literal (given by prefix)\nSRE_INFO_CHARSET = 4 # pattern starts with character from given set\n\nif __name__ == \"__main__\":\n    def dump(f, d, prefix):\n        items = sorted(d.items(), key=lambda a: a[1])\n        for k, v in items:\n            f.write(\"#define %s_%s %s\\n\" % (prefix, k.upper(), v))\n    f = open(\"sre_constants.h\", \"w\")\n    f.write(\"\"\"\\\n/*\n * Secret Labs' Regular Expression Engine\n *\n * regular expression matching engine\n *\n * NOTE: This file is generated by sre_constants.py.  If you need\n * to change anything in here, edit sre_constants.py and run it.\n *\n * Copyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.\n *\n * See the _sre.c file for information on usage and redistribution.\n */\n\n\"\"\")\n\n    f.write(\"#define SRE_MAGIC %d\\n\" % MAGIC)\n\n    dump(f, OPCODES, \"SRE_OP\")\n    dump(f, ATCODES, \"SRE\")\n    dump(f, CHCODES, \"SRE\")\n\n    f.write(\"#define SRE_FLAG_TEMPLATE %d\\n\" % SRE_FLAG_TEMPLATE)\n    f.write(\"#define SRE_FLAG_IGNORECASE %d\\n\" % SRE_FLAG_IGNORECASE)\n    f.write(\"#define SRE_FLAG_LOCALE %d\\n\" % SRE_FLAG_LOCALE)\n    f.write(\"#define SRE_FLAG_MULTILINE %d\\n\" % SRE_FLAG_MULTILINE)\n    f.write(\"#define SRE_FLAG_DOTALL %d\\n\" % SRE_FLAG_DOTALL)\n    f.write(\"#define SRE_FLAG_UNICODE %d\\n\" % SRE_FLAG_UNICODE)\n    f.write(\"#define SRE_FLAG_VERBOSE %d\\n\" % SRE_FLAG_VERBOSE)\n\n    f.write(\"#define SRE_INFO_PREFIX %d\\n\" % SRE_INFO_PREFIX)\n    f.write(\"#define SRE_INFO_LITERAL %d\\n\" % SRE_INFO_LITERAL)\n    f.write(\"#define SRE_INFO_CHARSET %d\\n\" % SRE_INFO_CHARSET)\n\n    f.close()\n    print(\"done\")\n"], "unittest.test.testmock.testpatch": [".py", "# Copyright (C) 2007-2012 Michael Foord & the mock team\n# E-mail: fuzzyman AT voidspace DOT org DOT uk\n# http://www.voidspace.org.uk/python/mock/\n\nimport os\nimport sys\n\nimport unittest\nfrom unittest.test.testmock import support\nfrom unittest.test.testmock.support import SomeClass, is_instance\n\nfrom unittest.mock import (\n    NonCallableMock, CallableMixin, patch, sentinel,\n    MagicMock, Mock, NonCallableMagicMock, patch, _patch,\n    DEFAULT, call, _get_target\n)\n\n\nbuiltin_string = 'builtins'\n\nPTModule = sys.modules[__name__]\nMODNAME = '%s.PTModule' % __name__\n\n\ndef _get_proxy(obj, get_only=True):\n    class Proxy(object):\n        def __getattr__(self, name):\n            return getattr(obj, name)\n    if not get_only:\n        def __setattr__(self, name, value):\n            setattr(obj, name, value)\n        def __delattr__(self, name):\n            delattr(obj, name)\n        Proxy.__setattr__ = __setattr__\n        Proxy.__delattr__ = __delattr__\n    return Proxy()\n\n\n# for use in the test\nsomething  = sentinel.Something\nsomething_else  = sentinel.SomethingElse\n\n\nclass Foo(object):\n    def __init__(self, a):\n        pass\n    def f(self, a):\n        pass\n    def g(self):\n        pass\n    foo = 'bar'\n\n    class Bar(object):\n        def a(self):\n            pass\n\nfoo_name = '%s.Foo' % __name__\n\n\ndef function(a, b=Foo):\n    pass\n\n\nclass Container(object):\n    def __init__(self):\n        self.values = {}\n\n    def __getitem__(self, name):\n        return self.values[name]\n\n    def __setitem__(self, name, value):\n        self.values[name] = value\n\n    def __delitem__(self, name):\n        del self.values[name]\n\n    def __iter__(self):\n        return iter(self.values)\n\n\n\nclass PatchTest(unittest.TestCase):\n\n    def assertNotCallable(self, obj, magic=True):\n        MockClass = NonCallableMagicMock\n        if not magic:\n            MockClass = NonCallableMock\n\n        self.assertRaises(TypeError, obj)\n        self.assertTrue(is_instance(obj, MockClass))\n        self.assertFalse(is_instance(obj, CallableMixin))\n\n\n    def test_single_patchobject(self):\n        class Something(object):\n            attribute = sentinel.Original\n\n        @patch.object(Something, 'attribute', sentinel.Patched)\n        def test():\n            self.assertEqual(Something.attribute, sentinel.Patched, \"unpatched\")\n\n        test()\n        self.assertEqual(Something.attribute, sentinel.Original,\n                         \"patch not restored\")\n\n\n    def test_patchobject_with_none(self):\n        class Something(object):\n            attribute = sentinel.Original\n\n        @patch.object(Something, 'attribute', None)\n        def test():\n            self.assertIsNone(Something.attribute, \"unpatched\")\n\n        test()\n        self.assertEqual(Something.attribute, sentinel.Original,\n                         \"patch not restored\")\n\n\n    def test_multiple_patchobject(self):\n        class Something(object):\n            attribute = sentinel.Original\n            next_attribute = sentinel.Original2\n\n        @patch.object(Something, 'attribute', sentinel.Patched)\n        @patch.object(Something, 'next_attribute', sentinel.Patched2)\n        def test():\n            self.assertEqual(Something.attribute, sentinel.Patched,\n                             \"unpatched\")\n            self.assertEqual(Something.next_attribute, sentinel.Patched2,\n                             \"unpatched\")\n\n        test()\n        self.assertEqual(Something.attribute, sentinel.Original,\n                         \"patch not restored\")\n        self.assertEqual(Something.next_attribute, sentinel.Original2,\n                         \"patch not restored\")\n\n\n    def test_object_lookup_is_quite_lazy(self):\n        global something\n        original = something\n        @patch('%s.something' % __name__, sentinel.Something2)\n        def test():\n            pass\n\n        try:\n            something = sentinel.replacement_value\n            test()\n            self.assertEqual(something, sentinel.replacement_value)\n        finally:\n            something = original\n\n\n    def test_patch(self):\n        @patch('%s.something' % __name__, sentinel.Something2)\n        def test():\n            self.assertEqual(PTModule.something, sentinel.Something2,\n                             \"unpatched\")\n\n        test()\n        self.assertEqual(PTModule.something, sentinel.Something,\n                         \"patch not restored\")\n\n        @patch('%s.something' % __name__, sentinel.Something2)\n        @patch('%s.something_else' % __name__, sentinel.SomethingElse)\n        def test():\n            self.assertEqual(PTModule.something, sentinel.Something2,\n                             \"unpatched\")\n            self.assertEqual(PTModule.something_else, sentinel.SomethingElse,\n                             \"unpatched\")\n\n        self.assertEqual(PTModule.something, sentinel.Something,\n                         \"patch not restored\")\n        self.assertEqual(PTModule.something_else, sentinel.SomethingElse,\n                         \"patch not restored\")\n\n        # Test the patching and restoring works a second time\n        test()\n\n        self.assertEqual(PTModule.something, sentinel.Something,\n                         \"patch not restored\")\n        self.assertEqual(PTModule.something_else, sentinel.SomethingElse,\n                         \"patch not restored\")\n\n        mock = Mock()\n        mock.return_value = sentinel.Handle\n        @patch('%s.open' % builtin_string, mock)\n        def test():\n            self.assertEqual(open('filename', 'r'), sentinel.Handle,\n                             \"open not patched\")\n        test()\n        test()\n\n        self.assertNotEqual(open, mock, \"patch not restored\")\n\n\n    def test_patch_class_attribute(self):\n        @patch('%s.SomeClass.class_attribute' % __name__,\n               sentinel.ClassAttribute)\n        def test():\n            self.assertEqual(PTModule.SomeClass.class_attribute,\n                             sentinel.ClassAttribute, \"unpatched\")\n        test()\n\n        self.assertIsNone(PTModule.SomeClass.class_attribute,\n                          \"patch not restored\")\n\n\n    def test_patchobject_with_default_mock(self):\n        class Test(object):\n            something = sentinel.Original\n            something2 = sentinel.Original2\n\n        @patch.object(Test, 'something')\n        def test(mock):\n            self.assertEqual(mock, Test.something,\n                             \"Mock not passed into test function\")\n            self.assertIsInstance(mock, MagicMock,\n                            \"patch with two arguments did not create a mock\")\n\n        test()\n\n        @patch.object(Test, 'something')\n        @patch.object(Test, 'something2')\n        def test(this1, this2, mock1, mock2):\n            self.assertEqual(this1, sentinel.this1,\n                             \"Patched function didn't receive initial argument\")\n            self.assertEqual(this2, sentinel.this2,\n                             \"Patched function didn't receive second argument\")\n            self.assertEqual(mock1, Test.something2,\n                             \"Mock not passed into test function\")\n            self.assertEqual(mock2, Test.something,\n                             \"Second Mock not passed into test function\")\n            self.assertIsInstance(mock2, MagicMock,\n                            \"patch with two arguments did not create a mock\")\n            self.assertIsInstance(mock2, MagicMock,\n                            \"patch with two arguments did not create a mock\")\n\n            # A hack to test that new mocks are passed the second time\n            self.assertNotEqual(outerMock1, mock1, \"unexpected value for mock1\")\n            self.assertNotEqual(outerMock2, mock2, \"unexpected value for mock1\")\n            return mock1, mock2\n\n        outerMock1 = outerMock2 = None\n        outerMock1, outerMock2 = test(sentinel.this1, sentinel.this2)\n\n        # Test that executing a second time creates new mocks\n        test(sentinel.this1, sentinel.this2)\n\n\n    def test_patch_with_spec(self):\n        @patch('%s.SomeClass' % __name__, spec=SomeClass)\n        def test(MockSomeClass):\n            self.assertEqual(SomeClass, MockSomeClass)\n            self.assertTrue(is_instance(SomeClass.wibble, MagicMock))\n            self.assertRaises(AttributeError, lambda: SomeClass.not_wibble)\n\n        test()\n\n\n    def test_patchobject_with_spec(self):\n        @patch.object(SomeClass, 'class_attribute', spec=SomeClass)\n        def test(MockAttribute):\n            self.assertEqual(SomeClass.class_attribute, MockAttribute)\n            self.assertTrue(is_instance(SomeClass.class_attribute.wibble,\n                                       MagicMock))\n            self.assertRaises(AttributeError,\n                              lambda: SomeClass.class_attribute.not_wibble)\n\n        test()\n\n\n    def test_patch_with_spec_as_list(self):\n        @patch('%s.SomeClass' % __name__, spec=['wibble'])\n        def test(MockSomeClass):\n            self.assertEqual(SomeClass, MockSomeClass)\n            self.assertTrue(is_instance(SomeClass.wibble, MagicMock))\n            self.assertRaises(AttributeError, lambda: SomeClass.not_wibble)\n\n        test()\n\n\n    def test_patchobject_with_spec_as_list(self):\n        @patch.object(SomeClass, 'class_attribute', spec=['wibble'])\n        def test(MockAttribute):\n            self.assertEqual(SomeClass.class_attribute, MockAttribute)\n            self.assertTrue(is_instance(SomeClass.class_attribute.wibble,\n                                       MagicMock))\n            self.assertRaises(AttributeError,\n                              lambda: SomeClass.class_attribute.not_wibble)\n\n        test()\n\n\n    def test_nested_patch_with_spec_as_list(self):\n        # regression test for nested decorators\n        @patch('%s.open' % builtin_string)\n        @patch('%s.SomeClass' % __name__, spec=['wibble'])\n        def test(MockSomeClass, MockOpen):\n            self.assertEqual(SomeClass, MockSomeClass)\n            self.assertTrue(is_instance(SomeClass.wibble, MagicMock))\n            self.assertRaises(AttributeError, lambda: SomeClass.not_wibble)\n        test()\n\n\n    def test_patch_with_spec_as_boolean(self):\n        @patch('%s.SomeClass' % __name__, spec=True)\n        def test(MockSomeClass):\n            self.assertEqual(SomeClass, MockSomeClass)\n            # Should not raise attribute error\n            MockSomeClass.wibble\n\n            self.assertRaises(AttributeError, lambda: MockSomeClass.not_wibble)\n\n        test()\n\n\n    def test_patch_object_with_spec_as_boolean(self):\n        @patch.object(PTModule, 'SomeClass', spec=True)\n        def test(MockSomeClass):\n            self.assertEqual(SomeClass, MockSomeClass)\n            # Should not raise attribute error\n            MockSomeClass.wibble\n\n            self.assertRaises(AttributeError, lambda: MockSomeClass.not_wibble)\n\n        test()\n\n\n    def test_patch_class_acts_with_spec_is_inherited(self):\n        @patch('%s.SomeClass' % __name__, spec=True)\n        def test(MockSomeClass):\n            self.assertTrue(is_instance(MockSomeClass, MagicMock))\n            instance = MockSomeClass()\n            self.assertNotCallable(instance)\n            # Should not raise attribute error\n            instance.wibble\n\n            self.assertRaises(AttributeError, lambda: instance.not_wibble)\n\n        test()\n\n\n    def test_patch_with_create_mocks_non_existent_attributes(self):\n        @patch('%s.frooble' % builtin_string, sentinel.Frooble, create=True)\n        def test():\n            self.assertEqual(frooble, sentinel.Frooble)\n\n        test()\n        self.assertRaises(NameError, lambda: frooble)\n\n\n    def test_patchobject_with_create_mocks_non_existent_attributes(self):\n        @patch.object(SomeClass, 'frooble', sentinel.Frooble, create=True)\n        def test():\n            self.assertEqual(SomeClass.frooble, sentinel.Frooble)\n\n        test()\n        self.assertFalse(hasattr(SomeClass, 'frooble'))\n\n\n    def test_patch_wont_create_by_default(self):\n        try:\n            @patch('%s.frooble' % builtin_string, sentinel.Frooble)\n            def test():\n                self.assertEqual(frooble, sentinel.Frooble)\n\n            test()\n        except AttributeError:\n            pass\n        else:\n            self.fail('Patching non existent attributes should fail')\n\n        self.assertRaises(NameError, lambda: frooble)\n\n\n    def test_patchobject_wont_create_by_default(self):\n        try:\n            @patch.object(SomeClass, 'frooble', sentinel.Frooble)\n            def test():\n                self.fail('Patching non existent attributes should fail')\n\n            test()\n        except AttributeError:\n            pass\n        else:\n            self.fail('Patching non existent attributes should fail')\n        self.assertFalse(hasattr(SomeClass, 'frooble'))\n\n\n    def test_patch_with_static_methods(self):\n        class Foo(object):\n            @staticmethod\n            def woot():\n                return sentinel.Static\n\n        @patch.object(Foo, 'woot', staticmethod(lambda: sentinel.Patched))\n        def anonymous():\n            self.assertEqual(Foo.woot(), sentinel.Patched)\n        anonymous()\n\n        self.assertEqual(Foo.woot(), sentinel.Static)\n\n\n    def test_patch_local(self):\n        foo = sentinel.Foo\n        @patch.object(sentinel, 'Foo', 'Foo')\n        def anonymous():\n            self.assertEqual(sentinel.Foo, 'Foo')\n        anonymous()\n\n        self.assertEqual(sentinel.Foo, foo)\n\n\n    def test_patch_slots(self):\n        class Foo(object):\n            __slots__ = ('Foo',)\n\n        foo = Foo()\n        foo.Foo = sentinel.Foo\n\n        @patch.object(foo, 'Foo', 'Foo')\n        def anonymous():\n            self.assertEqual(foo.Foo, 'Foo')\n        anonymous()\n\n        self.assertEqual(foo.Foo, sentinel.Foo)\n\n\n    def test_patchobject_class_decorator(self):\n        class Something(object):\n            attribute = sentinel.Original\n\n        class Foo(object):\n            def test_method(other_self):\n                self.assertEqual(Something.attribute, sentinel.Patched,\n                                 \"unpatched\")\n            def not_test_method(other_self):\n                self.assertEqual(Something.attribute, sentinel.Original,\n                                 \"non-test method patched\")\n\n        Foo = patch.object(Something, 'attribute', sentinel.Patched)(Foo)\n\n        f = Foo()\n        f.test_method()\n        f.not_test_method()\n\n        self.assertEqual(Something.attribute, sentinel.Original,\n                         \"patch not restored\")\n\n\n    def test_patch_class_decorator(self):\n        class Something(object):\n            attribute = sentinel.Original\n\n        class Foo(object):\n            def test_method(other_self, mock_something):\n                self.assertEqual(PTModule.something, mock_something,\n                                 \"unpatched\")\n            def not_test_method(other_self):\n                self.assertEqual(PTModule.something, sentinel.Something,\n                                 \"non-test method patched\")\n        Foo = patch('%s.something' % __name__)(Foo)\n\n        f = Foo()\n        f.test_method()\n        f.not_test_method()\n\n        self.assertEqual(Something.attribute, sentinel.Original,\n                         \"patch not restored\")\n        self.assertEqual(PTModule.something, sentinel.Something,\n                         \"patch not restored\")\n\n\n    def test_patchobject_twice(self):\n        class Something(object):\n            attribute = sentinel.Original\n            next_attribute = sentinel.Original2\n\n        @patch.object(Something, 'attribute', sentinel.Patched)\n        @patch.object(Something, 'attribute', sentinel.Patched)\n        def test():\n            self.assertEqual(Something.attribute, sentinel.Patched, \"unpatched\")\n\n        test()\n\n        self.assertEqual(Something.attribute, sentinel.Original,\n                         \"patch not restored\")\n\n\n    def test_patch_dict(self):\n        foo = {'initial': object(), 'other': 'something'}\n        original = foo.copy()\n\n        @patch.dict(foo)\n        def test():\n            foo['a'] = 3\n            del foo['initial']\n            foo['other'] = 'something else'\n\n        test()\n\n        self.assertEqual(foo, original)\n\n        @patch.dict(foo, {'a': 'b'})\n        def test():\n            self.assertEqual(len(foo), 3)\n            self.assertEqual(foo['a'], 'b')\n\n        test()\n\n        self.assertEqual(foo, original)\n\n        @patch.dict(foo, [('a', 'b')])\n        def test():\n            self.assertEqual(len(foo), 3)\n            self.assertEqual(foo['a'], 'b')\n\n        test()\n\n        self.assertEqual(foo, original)\n\n\n    def test_patch_dict_with_container_object(self):\n        foo = Container()\n        foo['initial'] = object()\n        foo['other'] =  'something'\n\n        original = foo.values.copy()\n\n        @patch.dict(foo)\n        def test():\n            foo['a'] = 3\n            del foo['initial']\n            foo['other'] = 'something else'\n\n        test()\n\n        self.assertEqual(foo.values, original)\n\n        @patch.dict(foo, {'a': 'b'})\n        def test():\n            self.assertEqual(len(foo.values), 3)\n            self.assertEqual(foo['a'], 'b')\n\n        test()\n\n        self.assertEqual(foo.values, original)\n\n\n    def test_patch_dict_with_clear(self):\n        foo = {'initial': object(), 'other': 'something'}\n        original = foo.copy()\n\n        @patch.dict(foo, clear=True)\n        def test():\n            self.assertEqual(foo, {})\n            foo['a'] = 3\n            foo['other'] = 'something else'\n\n        test()\n\n        self.assertEqual(foo, original)\n\n        @patch.dict(foo, {'a': 'b'}, clear=True)\n        def test():\n            self.assertEqual(foo, {'a': 'b'})\n\n        test()\n\n        self.assertEqual(foo, original)\n\n        @patch.dict(foo, [('a', 'b')], clear=True)\n        def test():\n            self.assertEqual(foo, {'a': 'b'})\n\n        test()\n\n        self.assertEqual(foo, original)\n\n\n    def test_patch_dict_with_container_object_and_clear(self):\n        foo = Container()\n        foo['initial'] = object()\n        foo['other'] =  'something'\n\n        original = foo.values.copy()\n\n        @patch.dict(foo, clear=True)\n        def test():\n            self.assertEqual(foo.values, {})\n            foo['a'] = 3\n            foo['other'] = 'something else'\n\n        test()\n\n        self.assertEqual(foo.values, original)\n\n        @patch.dict(foo, {'a': 'b'}, clear=True)\n        def test():\n            self.assertEqual(foo.values, {'a': 'b'})\n\n        test()\n\n        self.assertEqual(foo.values, original)\n\n\n    def test_name_preserved(self):\n        foo = {}\n\n        @patch('%s.SomeClass' % __name__, object())\n        @patch('%s.SomeClass' % __name__, object(), autospec=True)\n        @patch.object(SomeClass, object())\n        @patch.dict(foo)\n        def some_name():\n            pass\n\n        self.assertEqual(some_name.__name__, 'some_name')\n\n\n    def test_patch_with_exception(self):\n        foo = {}\n\n        @patch.dict(foo, {'a': 'b'})\n        def test():\n            raise NameError('Konrad')\n        try:\n            test()\n        except NameError:\n            pass\n        else:\n            self.fail('NameError not raised by test')\n\n        self.assertEqual(foo, {})\n\n\n    def test_patch_dict_with_string(self):\n        @patch.dict('os.environ', {'konrad_delong': 'some value'})\n        def test():\n            self.assertIn('konrad_delong', os.environ)\n\n        test()\n\n\n    def test_patch_descriptor(self):\n        # would be some effort to fix this - we could special case the\n        # builtin descriptors: classmethod, property, staticmethod\n        return\n        class Nothing(object):\n            foo = None\n\n        class Something(object):\n            foo = {}\n\n            @patch.object(Nothing, 'foo', 2)\n            @classmethod\n            def klass(cls):\n                self.assertIs(cls, Something)\n\n            @patch.object(Nothing, 'foo', 2)\n            @staticmethod\n            def static(arg):\n                return arg\n\n            @patch.dict(foo)\n            @classmethod\n            def klass_dict(cls):\n                self.assertIs(cls, Something)\n\n            @patch.dict(foo)\n            @staticmethod\n            def static_dict(arg):\n                return arg\n\n        # these will raise exceptions if patching descriptors is broken\n        self.assertEqual(Something.static('f00'), 'f00')\n        Something.klass()\n        self.assertEqual(Something.static_dict('f00'), 'f00')\n        Something.klass_dict()\n\n        something = Something()\n        self.assertEqual(something.static('f00'), 'f00')\n        something.klass()\n        self.assertEqual(something.static_dict('f00'), 'f00')\n        something.klass_dict()\n\n\n    def test_patch_spec_set(self):\n        @patch('%s.SomeClass' % __name__, spec=SomeClass, spec_set=True)\n        def test(MockClass):\n            MockClass.z = 'foo'\n\n        self.assertRaises(AttributeError, test)\n\n        @patch.object(support, 'SomeClass', spec=SomeClass, spec_set=True)\n        def test(MockClass):\n            MockClass.z = 'foo'\n\n        self.assertRaises(AttributeError, test)\n        @patch('%s.SomeClass' % __name__, spec_set=True)\n        def test(MockClass):\n            MockClass.z = 'foo'\n\n        self.assertRaises(AttributeError, test)\n\n        @patch.object(support, 'SomeClass', spec_set=True)\n        def test(MockClass):\n            MockClass.z = 'foo'\n\n        self.assertRaises(AttributeError, test)\n\n\n    def test_spec_set_inherit(self):\n        @patch('%s.SomeClass' % __name__, spec_set=True)\n        def test(MockClass):\n            instance = MockClass()\n            instance.z = 'foo'\n\n        self.assertRaises(AttributeError, test)\n\n\n    def test_patch_start_stop(self):\n        original = something\n        patcher = patch('%s.something' % __name__)\n        self.assertIs(something, original)\n        mock = patcher.start()\n        try:\n            self.assertIsNot(mock, original)\n            self.assertIs(something, mock)\n        finally:\n            patcher.stop()\n        self.assertIs(something, original)\n\n\n    def test_stop_without_start(self):\n        patcher = patch(foo_name, 'bar', 3)\n\n        # calling stop without start used to produce a very obscure error\n        self.assertRaises(RuntimeError, patcher.stop)\n\n\n    def test_patchobject_start_stop(self):\n        original = something\n        patcher = patch.object(PTModule, 'something', 'foo')\n        self.assertIs(something, original)\n        replaced = patcher.start()\n        try:\n            self.assertEqual(replaced, 'foo')\n            self.assertIs(something, replaced)\n        finally:\n            patcher.stop()\n        self.assertIs(something, original)\n\n\n    def test_patch_dict_start_stop(self):\n        d = {'foo': 'bar'}\n        original = d.copy()\n        patcher = patch.dict(d, [('spam', 'eggs')], clear=True)\n        self.assertEqual(d, original)\n\n        patcher.start()\n        try:\n            self.assertEqual(d, {'spam': 'eggs'})\n        finally:\n            patcher.stop()\n        self.assertEqual(d, original)\n\n\n    def test_patch_dict_class_decorator(self):\n        this = self\n        d = {'spam': 'eggs'}\n        original = d.copy()\n\n        class Test(object):\n            def test_first(self):\n                this.assertEqual(d, {'foo': 'bar'})\n            def test_second(self):\n                this.assertEqual(d, {'foo': 'bar'})\n\n        Test = patch.dict(d, {'foo': 'bar'}, clear=True)(Test)\n        self.assertEqual(d, original)\n\n        test = Test()\n\n        test.test_first()\n        self.assertEqual(d, original)\n\n        test.test_second()\n        self.assertEqual(d, original)\n\n        test = Test()\n\n        test.test_first()\n        self.assertEqual(d, original)\n\n        test.test_second()\n        self.assertEqual(d, original)\n\n\n    def test_get_only_proxy(self):\n        class Something(object):\n            foo = 'foo'\n        class SomethingElse:\n            foo = 'foo'\n\n        for thing in Something, SomethingElse, Something(), SomethingElse:\n            proxy = _get_proxy(thing)\n\n            @patch.object(proxy, 'foo', 'bar')\n            def test():\n                self.assertEqual(proxy.foo, 'bar')\n            test()\n            self.assertEqual(proxy.foo, 'foo')\n            self.assertEqual(thing.foo, 'foo')\n            self.assertNotIn('foo', proxy.__dict__)\n\n\n    def test_get_set_delete_proxy(self):\n        class Something(object):\n            foo = 'foo'\n        class SomethingElse:\n            foo = 'foo'\n\n        for thing in Something, SomethingElse, Something(), SomethingElse:\n            proxy = _get_proxy(Something, get_only=False)\n\n            @patch.object(proxy, 'foo', 'bar')\n            def test():\n                self.assertEqual(proxy.foo, 'bar')\n            test()\n            self.assertEqual(proxy.foo, 'foo')\n            self.assertEqual(thing.foo, 'foo')\n            self.assertNotIn('foo', proxy.__dict__)\n\n\n    def test_patch_keyword_args(self):\n        kwargs = {'side_effect': KeyError, 'foo.bar.return_value': 33,\n                  'foo': MagicMock()}\n\n        patcher = patch(foo_name, **kwargs)\n        mock = patcher.start()\n        patcher.stop()\n\n        self.assertRaises(KeyError, mock)\n        self.assertEqual(mock.foo.bar(), 33)\n        self.assertIsInstance(mock.foo, MagicMock)\n\n\n    def test_patch_object_keyword_args(self):\n        kwargs = {'side_effect': KeyError, 'foo.bar.return_value': 33,\n                  'foo': MagicMock()}\n\n        patcher = patch.object(Foo, 'f', **kwargs)\n        mock = patcher.start()\n        patcher.stop()\n\n        self.assertRaises(KeyError, mock)\n        self.assertEqual(mock.foo.bar(), 33)\n        self.assertIsInstance(mock.foo, MagicMock)\n\n\n    def test_patch_dict_keyword_args(self):\n        original = {'foo': 'bar'}\n        copy = original.copy()\n\n        patcher = patch.dict(original, foo=3, bar=4, baz=5)\n        patcher.start()\n\n        try:\n            self.assertEqual(original, dict(foo=3, bar=4, baz=5))\n        finally:\n            patcher.stop()\n\n        self.assertEqual(original, copy)\n\n\n    def test_autospec(self):\n        class Boo(object):\n            def __init__(self, a):\n                pass\n            def f(self, a):\n                pass\n            def g(self):\n                pass\n            foo = 'bar'\n\n            class Bar(object):\n                def a(self):\n                    pass\n\n        def _test(mock):\n            mock(1)\n            mock.assert_called_with(1)\n            self.assertRaises(TypeError, mock)\n\n        def _test2(mock):\n            mock.f(1)\n            mock.f.assert_called_with(1)\n            self.assertRaises(TypeError, mock.f)\n\n            mock.g()\n            mock.g.assert_called_with()\n            self.assertRaises(TypeError, mock.g, 1)\n\n            self.assertRaises(AttributeError, getattr, mock, 'h')\n\n            mock.foo.lower()\n            mock.foo.lower.assert_called_with()\n            self.assertRaises(AttributeError, getattr, mock.foo, 'bar')\n\n            mock.Bar()\n            mock.Bar.assert_called_with()\n\n            mock.Bar.a()\n            mock.Bar.a.assert_called_with()\n            self.assertRaises(TypeError, mock.Bar.a, 1)\n\n            mock.Bar().a()\n            mock.Bar().a.assert_called_with()\n            self.assertRaises(TypeError, mock.Bar().a, 1)\n\n            self.assertRaises(AttributeError, getattr, mock.Bar, 'b')\n            self.assertRaises(AttributeError, getattr, mock.Bar(), 'b')\n\n        def function(mock):\n            _test(mock)\n            _test2(mock)\n            _test2(mock(1))\n            self.assertIs(mock, Foo)\n            return mock\n\n        test = patch(foo_name, autospec=True)(function)\n\n        mock = test()\n        self.assertIsNot(Foo, mock)\n        # test patching a second time works\n        test()\n\n        module = sys.modules[__name__]\n        test = patch.object(module, 'Foo', autospec=True)(function)\n\n        mock = test()\n        self.assertIsNot(Foo, mock)\n        # test patching a second time works\n        test()\n\n\n    def test_autospec_function(self):\n        @patch('%s.function' % __name__, autospec=True)\n        def test(mock):\n            function(1)\n            function.assert_called_with(1)\n            function(2, 3)\n            function.assert_called_with(2, 3)\n\n            self.assertRaises(TypeError, function)\n            self.assertRaises(AttributeError, getattr, function, 'foo')\n\n        test()\n\n\n    def test_autospec_keywords(self):\n        @patch('%s.function' % __name__, autospec=True,\n               return_value=3)\n        def test(mock_function):\n            #self.assertEqual(function.abc, 'foo')\n            return function(1, 2)\n\n        result = test()\n        self.assertEqual(result, 3)\n\n\n    def test_autospec_with_new(self):\n        patcher = patch('%s.function' % __name__, new=3, autospec=True)\n        self.assertRaises(TypeError, patcher.start)\n\n        module = sys.modules[__name__]\n        patcher = patch.object(module, 'function', new=3, autospec=True)\n        self.assertRaises(TypeError, patcher.start)\n\n\n    def test_autospec_with_object(self):\n        class Bar(Foo):\n            extra = []\n\n        patcher = patch(foo_name, autospec=Bar)\n        mock = patcher.start()\n        try:\n            self.assertIsInstance(mock, Bar)\n            self.assertIsInstance(mock.extra, list)\n        finally:\n            patcher.stop()\n\n\n    def test_autospec_inherits(self):\n        FooClass = Foo\n        patcher = patch(foo_name, autospec=True)\n        mock = patcher.start()\n        try:\n            self.assertIsInstance(mock, FooClass)\n            self.assertIsInstance(mock(3), FooClass)\n        finally:\n            patcher.stop()\n\n\n    def test_autospec_name(self):\n        patcher = patch(foo_name, autospec=True)\n        mock = patcher.start()\n\n        try:\n            self.assertIn(\" name='Foo'\", repr(mock))\n            self.assertIn(\" name='Foo.f'\", repr(mock.f))\n            self.assertIn(\" name='Foo()'\", repr(mock(None)))\n            self.assertIn(\" name='Foo().f'\", repr(mock(None).f))\n        finally:\n            patcher.stop()\n\n\n    def test_tracebacks(self):\n        @patch.object(Foo, 'f', object())\n        def test():\n            raise AssertionError\n        try:\n            test()\n        except:\n            err = sys.exc_info()\n\n        result = unittest.TextTestResult(None, None, 0)\n        traceback = result._exc_info_to_string(err, self)\n        self.assertIn('raise AssertionError', traceback)\n\n\n    def test_new_callable_patch(self):\n        patcher = patch(foo_name, new_callable=NonCallableMagicMock)\n\n        m1 = patcher.start()\n        patcher.stop()\n        m2 = patcher.start()\n        patcher.stop()\n\n        self.assertIsNot(m1, m2)\n        for mock in m1, m2:\n            self.assertNotCallable(m1)\n\n\n    def test_new_callable_patch_object(self):\n        patcher = patch.object(Foo, 'f', new_callable=NonCallableMagicMock)\n\n        m1 = patcher.start()\n        patcher.stop()\n        m2 = patcher.start()\n        patcher.stop()\n\n        self.assertIsNot(m1, m2)\n        for mock in m1, m2:\n            self.assertNotCallable(m1)\n\n\n    def test_new_callable_keyword_arguments(self):\n        class Bar(object):\n            kwargs = None\n            def __init__(self, **kwargs):\n                Bar.kwargs = kwargs\n\n        patcher = patch(foo_name, new_callable=Bar, arg1=1, arg2=2)\n        m = patcher.start()\n        try:\n            self.assertIs(type(m), Bar)\n            self.assertEqual(Bar.kwargs, dict(arg1=1, arg2=2))\n        finally:\n            patcher.stop()\n\n\n    def test_new_callable_spec(self):\n        class Bar(object):\n            kwargs = None\n            def __init__(self, **kwargs):\n                Bar.kwargs = kwargs\n\n        patcher = patch(foo_name, new_callable=Bar, spec=Bar)\n        patcher.start()\n        try:\n            self.assertEqual(Bar.kwargs, dict(spec=Bar))\n        finally:\n            patcher.stop()\n\n        patcher = patch(foo_name, new_callable=Bar, spec_set=Bar)\n        patcher.start()\n        try:\n            self.assertEqual(Bar.kwargs, dict(spec_set=Bar))\n        finally:\n            patcher.stop()\n\n\n    def test_new_callable_create(self):\n        non_existent_attr = '%s.weeeee' % foo_name\n        p = patch(non_existent_attr, new_callable=NonCallableMock)\n        self.assertRaises(AttributeError, p.start)\n\n        p = patch(non_existent_attr, new_callable=NonCallableMock,\n                  create=True)\n        m = p.start()\n        try:\n            self.assertNotCallable(m, magic=False)\n        finally:\n            p.stop()\n\n\n    def test_new_callable_incompatible_with_new(self):\n        self.assertRaises(\n            ValueError, patch, foo_name, new=object(), new_callable=MagicMock\n        )\n        self.assertRaises(\n            ValueError, patch.object, Foo, 'f', new=object(),\n            new_callable=MagicMock\n        )\n\n\n    def test_new_callable_incompatible_with_autospec(self):\n        self.assertRaises(\n            ValueError, patch, foo_name, new_callable=MagicMock,\n            autospec=True\n        )\n        self.assertRaises(\n            ValueError, patch.object, Foo, 'f', new_callable=MagicMock,\n            autospec=True\n        )\n\n\n    def test_new_callable_inherit_for_mocks(self):\n        class MockSub(Mock):\n            pass\n\n        MockClasses = (\n            NonCallableMock, NonCallableMagicMock, MagicMock, Mock, MockSub\n        )\n        for Klass in MockClasses:\n            for arg in 'spec', 'spec_set':\n                kwargs = {arg: True}\n                p = patch(foo_name, new_callable=Klass, **kwargs)\n                m = p.start()\n                try:\n                    instance = m.return_value\n                    self.assertRaises(AttributeError, getattr, instance, 'x')\n                finally:\n                    p.stop()\n\n\n    def test_new_callable_inherit_non_mock(self):\n        class NotAMock(object):\n            def __init__(self, spec):\n                self.spec = spec\n\n        p = patch(foo_name, new_callable=NotAMock, spec=True)\n        m = p.start()\n        try:\n            self.assertTrue(is_instance(m, NotAMock))\n            self.assertRaises(AttributeError, getattr, m, 'return_value')\n        finally:\n            p.stop()\n\n        self.assertEqual(m.spec, Foo)\n\n\n    def test_new_callable_class_decorating(self):\n        test = self\n        original = Foo\n        class SomeTest(object):\n\n            def _test(self, mock_foo):\n                test.assertIsNot(Foo, original)\n                test.assertIs(Foo, mock_foo)\n                test.assertIsInstance(Foo, SomeClass)\n\n            def test_two(self, mock_foo):\n                self._test(mock_foo)\n            def test_one(self, mock_foo):\n                self._test(mock_foo)\n\n        SomeTest = patch(foo_name, new_callable=SomeClass)(SomeTest)\n        SomeTest().test_one()\n        SomeTest().test_two()\n        self.assertIs(Foo, original)\n\n\n    def test_patch_multiple(self):\n        original_foo = Foo\n        original_f = Foo.f\n        original_g = Foo.g\n\n        patcher1 = patch.multiple(foo_name, f=1, g=2)\n        patcher2 = patch.multiple(Foo, f=1, g=2)\n\n        for patcher in patcher1, patcher2:\n            patcher.start()\n            try:\n                self.assertIs(Foo, original_foo)\n                self.assertEqual(Foo.f, 1)\n                self.assertEqual(Foo.g, 2)\n            finally:\n                patcher.stop()\n\n            self.assertIs(Foo, original_foo)\n            self.assertEqual(Foo.f, original_f)\n            self.assertEqual(Foo.g, original_g)\n\n\n        @patch.multiple(foo_name, f=3, g=4)\n        def test():\n            self.assertIs(Foo, original_foo)\n            self.assertEqual(Foo.f, 3)\n            self.assertEqual(Foo.g, 4)\n\n        test()\n\n\n    def test_patch_multiple_no_kwargs(self):\n        self.assertRaises(ValueError, patch.multiple, foo_name)\n        self.assertRaises(ValueError, patch.multiple, Foo)\n\n\n    def test_patch_multiple_create_mocks(self):\n        original_foo = Foo\n        original_f = Foo.f\n        original_g = Foo.g\n\n        @patch.multiple(foo_name, f=DEFAULT, g=3, foo=DEFAULT)\n        def test(f, foo):\n            self.assertIs(Foo, original_foo)\n            self.assertIs(Foo.f, f)\n            self.assertEqual(Foo.g, 3)\n            self.assertIs(Foo.foo, foo)\n            self.assertTrue(is_instance(f, MagicMock))\n            self.assertTrue(is_instance(foo, MagicMock))\n\n        test()\n        self.assertEqual(Foo.f, original_f)\n        self.assertEqual(Foo.g, original_g)\n\n\n    def test_patch_multiple_create_mocks_different_order(self):\n        # bug revealed by Jython!\n        original_f = Foo.f\n        original_g = Foo.g\n\n        patcher = patch.object(Foo, 'f', 3)\n        patcher.attribute_name = 'f'\n\n        other = patch.object(Foo, 'g', DEFAULT)\n        other.attribute_name = 'g'\n        patcher.additional_patchers = [other]\n\n        @patcher\n        def test(g):\n            self.assertIs(Foo.g, g)\n            self.assertEqual(Foo.f, 3)\n\n        test()\n        self.assertEqual(Foo.f, original_f)\n        self.assertEqual(Foo.g, original_g)\n\n\n    def test_patch_multiple_stacked_decorators(self):\n        original_foo = Foo\n        original_f = Foo.f\n        original_g = Foo.g\n\n        @patch.multiple(foo_name, f=DEFAULT)\n        @patch.multiple(foo_name, foo=DEFAULT)\n        @patch(foo_name + '.g')\n        def test1(g, **kwargs):\n            _test(g, **kwargs)\n\n        @patch.multiple(foo_name, f=DEFAULT)\n        @patch(foo_name + '.g')\n        @patch.multiple(foo_name, foo=DEFAULT)\n        def test2(g, **kwargs):\n            _test(g, **kwargs)\n\n        @patch(foo_name + '.g')\n        @patch.multiple(foo_name, f=DEFAULT)\n        @patch.multiple(foo_name, foo=DEFAULT)\n        def test3(g, **kwargs):\n            _test(g, **kwargs)\n\n        def _test(g, **kwargs):\n            f = kwargs.pop('f')\n            foo = kwargs.pop('foo')\n            self.assertFalse(kwargs)\n\n            self.assertIs(Foo, original_foo)\n            self.assertIs(Foo.f, f)\n            self.assertIs(Foo.g, g)\n            self.assertIs(Foo.foo, foo)\n            self.assertTrue(is_instance(f, MagicMock))\n            self.assertTrue(is_instance(g, MagicMock))\n            self.assertTrue(is_instance(foo, MagicMock))\n\n        test1()\n        test2()\n        test3()\n        self.assertEqual(Foo.f, original_f)\n        self.assertEqual(Foo.g, original_g)\n\n\n    def test_patch_multiple_create_mocks_patcher(self):\n        original_foo = Foo\n        original_f = Foo.f\n        original_g = Foo.g\n\n        patcher = patch.multiple(foo_name, f=DEFAULT, g=3, foo=DEFAULT)\n\n        result = patcher.start()\n        try:\n            f = result['f']\n            foo = result['foo']\n            self.assertEqual(set(result), set(['f', 'foo']))\n\n            self.assertIs(Foo, original_foo)\n            self.assertIs(Foo.f, f)\n            self.assertIs(Foo.foo, foo)\n            self.assertTrue(is_instance(f, MagicMock))\n            self.assertTrue(is_instance(foo, MagicMock))\n        finally:\n            patcher.stop()\n\n        self.assertEqual(Foo.f, original_f)\n        self.assertEqual(Foo.g, original_g)\n\n\n    def test_patch_multiple_decorating_class(self):\n        test = self\n        original_foo = Foo\n        original_f = Foo.f\n        original_g = Foo.g\n\n        class SomeTest(object):\n\n            def _test(self, f, foo):\n                test.assertIs(Foo, original_foo)\n                test.assertIs(Foo.f, f)\n                test.assertEqual(Foo.g, 3)\n                test.assertIs(Foo.foo, foo)\n                test.assertTrue(is_instance(f, MagicMock))\n                test.assertTrue(is_instance(foo, MagicMock))\n\n            def test_two(self, f, foo):\n                self._test(f, foo)\n            def test_one(self, f, foo):\n                self._test(f, foo)\n\n        SomeTest = patch.multiple(\n            foo_name, f=DEFAULT, g=3, foo=DEFAULT\n        )(SomeTest)\n\n        thing = SomeTest()\n        thing.test_one()\n        thing.test_two()\n\n        self.assertEqual(Foo.f, original_f)\n        self.assertEqual(Foo.g, original_g)\n\n\n    def test_patch_multiple_create(self):\n        patcher = patch.multiple(Foo, blam='blam')\n        self.assertRaises(AttributeError, patcher.start)\n\n        patcher = patch.multiple(Foo, blam='blam', create=True)\n        patcher.start()\n        try:\n            self.assertEqual(Foo.blam, 'blam')\n        finally:\n            patcher.stop()\n\n        self.assertFalse(hasattr(Foo, 'blam'))\n\n\n    def test_patch_multiple_spec_set(self):\n        # if spec_set works then we can assume that spec and autospec also\n        # work as the underlying machinery is the same\n        patcher = patch.multiple(Foo, foo=DEFAULT, spec_set=['a', 'b'])\n        result = patcher.start()\n        try:\n            self.assertEqual(Foo.foo, result['foo'])\n            Foo.foo.a(1)\n            Foo.foo.b(2)\n            Foo.foo.a.assert_called_with(1)\n            Foo.foo.b.assert_called_with(2)\n            self.assertRaises(AttributeError, setattr, Foo.foo, 'c', None)\n        finally:\n            patcher.stop()\n\n\n    def test_patch_multiple_new_callable(self):\n        class Thing(object):\n            pass\n\n        patcher = patch.multiple(\n            Foo, f=DEFAULT, g=DEFAULT, new_callable=Thing\n        )\n        result = patcher.start()\n        try:\n            self.assertIs(Foo.f, result['f'])\n            self.assertIs(Foo.g, result['g'])\n            self.assertIsInstance(Foo.f, Thing)\n            self.assertIsInstance(Foo.g, Thing)\n            self.assertIsNot(Foo.f, Foo.g)\n        finally:\n            patcher.stop()\n\n\n    def test_nested_patch_failure(self):\n        original_f = Foo.f\n        original_g = Foo.g\n\n        @patch.object(Foo, 'g', 1)\n        @patch.object(Foo, 'missing', 1)\n        @patch.object(Foo, 'f', 1)\n        def thing1():\n            pass\n\n        @patch.object(Foo, 'missing', 1)\n        @patch.object(Foo, 'g', 1)\n        @patch.object(Foo, 'f', 1)\n        def thing2():\n            pass\n\n        @patch.object(Foo, 'g', 1)\n        @patch.object(Foo, 'f', 1)\n        @patch.object(Foo, 'missing', 1)\n        def thing3():\n            pass\n\n        for func in thing1, thing2, thing3:\n            self.assertRaises(AttributeError, func)\n            self.assertEqual(Foo.f, original_f)\n            self.assertEqual(Foo.g, original_g)\n\n\n    def test_new_callable_failure(self):\n        original_f = Foo.f\n        original_g = Foo.g\n        original_foo = Foo.foo\n\n        def crasher():\n            raise NameError('crasher')\n\n        @patch.object(Foo, 'g', 1)\n        @patch.object(Foo, 'foo', new_callable=crasher)\n        @patch.object(Foo, 'f', 1)\n        def thing1():\n            pass\n\n        @patch.object(Foo, 'foo', new_callable=crasher)\n        @patch.object(Foo, 'g', 1)\n        @patch.object(Foo, 'f', 1)\n        def thing2():\n            pass\n\n        @patch.object(Foo, 'g', 1)\n        @patch.object(Foo, 'f', 1)\n        @patch.object(Foo, 'foo', new_callable=crasher)\n        def thing3():\n            pass\n\n        for func in thing1, thing2, thing3:\n            self.assertRaises(NameError, func)\n            self.assertEqual(Foo.f, original_f)\n            self.assertEqual(Foo.g, original_g)\n            self.assertEqual(Foo.foo, original_foo)\n\n\n    def test_patch_multiple_failure(self):\n        original_f = Foo.f\n        original_g = Foo.g\n\n        patcher = patch.object(Foo, 'f', 1)\n        patcher.attribute_name = 'f'\n\n        good = patch.object(Foo, 'g', 1)\n        good.attribute_name = 'g'\n\n        bad = patch.object(Foo, 'missing', 1)\n        bad.attribute_name = 'missing'\n\n        for additionals in [good, bad], [bad, good]:\n            patcher.additional_patchers = additionals\n\n            @patcher\n            def func():\n                pass\n\n            self.assertRaises(AttributeError, func)\n            self.assertEqual(Foo.f, original_f)\n            self.assertEqual(Foo.g, original_g)\n\n\n    def test_patch_multiple_new_callable_failure(self):\n        original_f = Foo.f\n        original_g = Foo.g\n        original_foo = Foo.foo\n\n        def crasher():\n            raise NameError('crasher')\n\n        patcher = patch.object(Foo, 'f', 1)\n        patcher.attribute_name = 'f'\n\n        good = patch.object(Foo, 'g', 1)\n        good.attribute_name = 'g'\n\n        bad = patch.object(Foo, 'foo', new_callable=crasher)\n        bad.attribute_name = 'foo'\n\n        for additionals in [good, bad], [bad, good]:\n            patcher.additional_patchers = additionals\n\n            @patcher\n            def func():\n                pass\n\n            self.assertRaises(NameError, func)\n            self.assertEqual(Foo.f, original_f)\n            self.assertEqual(Foo.g, original_g)\n            self.assertEqual(Foo.foo, original_foo)\n\n\n    def test_patch_multiple_string_subclasses(self):\n        Foo = type('Foo', (str,), {'fish': 'tasty'})\n        foo = Foo()\n        @patch.multiple(foo, fish='nearly gone')\n        def test():\n            self.assertEqual(foo.fish, 'nearly gone')\n\n        test()\n        self.assertEqual(foo.fish, 'tasty')\n\n\n    @patch('unittest.mock.patch.TEST_PREFIX', 'foo')\n    def test_patch_test_prefix(self):\n        class Foo(object):\n            thing = 'original'\n\n            def foo_one(self):\n                return self.thing\n            def foo_two(self):\n                return self.thing\n            def test_one(self):\n                return self.thing\n            def test_two(self):\n                return self.thing\n\n        Foo = patch.object(Foo, 'thing', 'changed')(Foo)\n\n        foo = Foo()\n        self.assertEqual(foo.foo_one(), 'changed')\n        self.assertEqual(foo.foo_two(), 'changed')\n        self.assertEqual(foo.test_one(), 'original')\n        self.assertEqual(foo.test_two(), 'original')\n\n\n    @patch('unittest.mock.patch.TEST_PREFIX', 'bar')\n    def test_patch_dict_test_prefix(self):\n        class Foo(object):\n            def bar_one(self):\n                return dict(the_dict)\n            def bar_two(self):\n                return dict(the_dict)\n            def test_one(self):\n                return dict(the_dict)\n            def test_two(self):\n                return dict(the_dict)\n\n        the_dict = {'key': 'original'}\n        Foo = patch.dict(the_dict, key='changed')(Foo)\n\n        foo =Foo()\n        self.assertEqual(foo.bar_one(), {'key': 'changed'})\n        self.assertEqual(foo.bar_two(), {'key': 'changed'})\n        self.assertEqual(foo.test_one(), {'key': 'original'})\n        self.assertEqual(foo.test_two(), {'key': 'original'})\n\n\n    def test_patch_with_spec_mock_repr(self):\n        for arg in ('spec', 'autospec', 'spec_set'):\n            p = patch('%s.SomeClass' % __name__, **{arg: True})\n            m = p.start()\n            try:\n                self.assertIn(\" name='SomeClass'\", repr(m))\n                self.assertIn(\" name='SomeClass.class_attribute'\",\n                              repr(m.class_attribute))\n                self.assertIn(\" name='SomeClass()'\", repr(m()))\n                self.assertIn(\" name='SomeClass().class_attribute'\",\n                              repr(m().class_attribute))\n            finally:\n                p.stop()\n\n\n    def test_patch_nested_autospec_repr(self):\n        with patch('unittest.test.testmock.support', autospec=True) as m:\n            self.assertIn(\" name='support.SomeClass.wibble()'\",\n                          repr(m.SomeClass.wibble()))\n            self.assertIn(\" name='support.SomeClass().wibble()'\",\n                          repr(m.SomeClass().wibble()))\n\n\n\n    def test_mock_calls_with_patch(self):\n        for arg in ('spec', 'autospec', 'spec_set'):\n            p = patch('%s.SomeClass' % __name__, **{arg: True})\n            m = p.start()\n            try:\n                m.wibble()\n\n                kalls = [call.wibble()]\n                self.assertEqual(m.mock_calls, kalls)\n                self.assertEqual(m.method_calls, kalls)\n                self.assertEqual(m.wibble.mock_calls, [call()])\n\n                result = m()\n                kalls.append(call())\n                self.assertEqual(m.mock_calls, kalls)\n\n                result.wibble()\n                kalls.append(call().wibble())\n                self.assertEqual(m.mock_calls, kalls)\n\n                self.assertEqual(result.mock_calls, [call.wibble()])\n                self.assertEqual(result.wibble.mock_calls, [call()])\n                self.assertEqual(result.method_calls, [call.wibble()])\n            finally:\n                p.stop()\n\n\n    def test_patch_imports_lazily(self):\n        sys.modules.pop('squizz', None)\n\n        p1 = patch('squizz.squozz')\n        self.assertRaises(ImportError, p1.start)\n\n        squizz = Mock()\n        squizz.squozz = 6\n        sys.modules['squizz'] = squizz\n        p1 = patch('squizz.squozz')\n        squizz.squozz = 3\n        p1.start()\n        p1.stop()\n        self.assertEqual(squizz.squozz, 3)\n\n\n    def test_patch_propogrates_exc_on_exit(self):\n        class holder:\n            exc_info = None, None, None\n\n        class custom_patch(_patch):\n            def __exit__(self, etype=None, val=None, tb=None):\n                _patch.__exit__(self, etype, val, tb)\n                holder.exc_info = etype, val, tb\n            stop = __exit__\n\n        def with_custom_patch(target):\n            getter, attribute = _get_target(target)\n            return custom_patch(\n                getter, attribute, DEFAULT, None, False, None,\n                None, None, {}\n            )\n\n        @with_custom_patch('squizz.squozz')\n        def test(mock):\n            raise RuntimeError\n\n        self.assertRaises(RuntimeError, test)\n        self.assertIs(holder.exc_info[0], RuntimeError)\n        self.assertIsNotNone(holder.exc_info[1],\n                            'exception value not propgated')\n        self.assertIsNotNone(holder.exc_info[2],\n                            'exception traceback not propgated')\n\n\n    def test_create_and_specs(self):\n        for kwarg in ('spec', 'spec_set', 'autospec'):\n            p = patch('%s.doesnotexist' % __name__, create=True,\n                      **{kwarg: True})\n            self.assertRaises(TypeError, p.start)\n            self.assertRaises(NameError, lambda: doesnotexist)\n\n            # check that spec with create is innocuous if the original exists\n            p = patch(MODNAME, create=True, **{kwarg: True})\n            p.start()\n            p.stop()\n\n\n    def test_multiple_specs(self):\n        original = PTModule\n        for kwarg in ('spec', 'spec_set'):\n            p = patch(MODNAME, autospec=0, **{kwarg: 0})\n            self.assertRaises(TypeError, p.start)\n            self.assertIs(PTModule, original)\n\n        for kwarg in ('spec', 'autospec'):\n            p = patch(MODNAME, spec_set=0, **{kwarg: 0})\n            self.assertRaises(TypeError, p.start)\n            self.assertIs(PTModule, original)\n\n        for kwarg in ('spec_set', 'autospec'):\n            p = patch(MODNAME, spec=0, **{kwarg: 0})\n            self.assertRaises(TypeError, p.start)\n            self.assertIs(PTModule, original)\n\n\n    def test_specs_false_instead_of_none(self):\n        p = patch(MODNAME, spec=False, spec_set=False, autospec=False)\n        mock = p.start()\n        try:\n            # no spec should have been set, so attribute access should not fail\n            mock.does_not_exist\n            mock.does_not_exist = 3\n        finally:\n            p.stop()\n\n\n    def test_falsey_spec(self):\n        for kwarg in ('spec', 'autospec', 'spec_set'):\n            p = patch(MODNAME, **{kwarg: 0})\n            m = p.start()\n            try:\n                self.assertRaises(AttributeError, getattr, m, 'doesnotexit')\n            finally:\n                p.stop()\n\n\n    def test_spec_set_true(self):\n        for kwarg in ('spec', 'autospec'):\n            p = patch(MODNAME, spec_set=True, **{kwarg: True})\n            m = p.start()\n            try:\n                self.assertRaises(AttributeError, setattr, m,\n                                  'doesnotexist', 'something')\n                self.assertRaises(AttributeError, getattr, m, 'doesnotexist')\n            finally:\n                p.stop()\n\n\n    def test_callable_spec_as_list(self):\n        spec = ('__call__',)\n        p = patch(MODNAME, spec=spec)\n        m = p.start()\n        try:\n            self.assertTrue(callable(m))\n        finally:\n            p.stop()\n\n\n    def test_not_callable_spec_as_list(self):\n        spec = ('foo', 'bar')\n        p = patch(MODNAME, spec=spec)\n        m = p.start()\n        try:\n            self.assertFalse(callable(m))\n        finally:\n            p.stop()\n\n\n    def test_patch_stopall(self):\n        unlink = os.unlink\n        chdir = os.chdir\n        path = os.path\n        patch('os.unlink', something).start()\n        patch('os.chdir', something_else).start()\n\n        @patch('os.path')\n        def patched(mock_path):\n            patch.stopall()\n            self.assertIs(os.path, mock_path)\n            self.assertIs(os.unlink, unlink)\n            self.assertIs(os.chdir, chdir)\n\n        patched()\n        self.assertIs(os.path, path)\n\n\n\nif __name__ == '__main__':\n    unittest.main()\n"], "json": [".js", "var $module = (function($B){\n\nvar _b_ = $B.builtins\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\n//for(var $py_builtin in _b_) eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")\n\nfunction _py(obj){\n    if(obj===null){return None}\n    if(isinstance(obj,list)){\n        var res = []\n        for(var i=0;i<obj.length;i++){\n            res.push(_py(obj[i]))\n        }\n        return res\n    }\n    if(obj.__class__!==undefined){\n        if(obj.__class__===list){\n            for(var i=0;i<obj.length;i++){\n                obj[i] = _py(obj[i])\n            }\n        }\n        return obj\n    }\n    if(typeof obj==='object' && obj.__class__===undefined){\n        // transform JS object into a Python dict\n        var res = dict()\n        for(var attr in obj){\n            getattr(res,'__setitem__')(attr,_py(obj[attr]))\n        }\n        return res\n    }\n    return $B.JSObject(obj)\n}\nfunction _js(obj){\n    // obj is a Python object\n    if (isinstance(obj,[int,str])) return obj\n    if(obj===None) return null\n    if(obj===True) return true\n    if(obj===False) return false\n    if(isinstance(obj,float)) return obj.value\n    if(isinstance(obj,[list,tuple])){\n        var res = []\n        for(var i=0;i<obj.length;i++){res.push(_js(obj[i]))}\n        return res\n    }\n    if(isinstance(obj,dict)){\n        var res = new Object()\n        for(var i=0;i<obj.$keys.length;i++){\n            res[_js(obj.$keys[i])]=_js(obj.$values[i])\n        }\n        return res\n    }\n    throw _b_.TypeError(str(obj)+' is not JSON serializable')\n}\n\nreturn  {\n    loads : function(json_obj){return _py(JSON.parse(json_obj))},\n    dumps : function(obj){return JSON.stringify(_js(obj))},\n}\n\n})(__BRYTHON__)\n"], "logging.config": [".py", "# Copyright 2001-2013 by Vinay Sajip. All Rights Reserved.\n#\n# Permission to use, copy, modify, and distribute this software and its\n# documentation for any purpose and without fee is hereby granted,\n# provided that the above copyright notice appear in all copies and that\n# both that copyright notice and this permission notice appear in\n# supporting documentation, and that the name of Vinay Sajip\n# not be used in advertising or publicity pertaining to distribution\n# of the software without specific, written prior permission.\n# VINAY SAJIP DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING\n# ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\n# VINAY SAJIP BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR\n# ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER\n# IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\n# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n\"\"\"\nConfiguration functions for the logging package for Python. The core package\nis based on PEP 282 and comments thereto in comp.lang.python, and influenced\nby Apache's log4j system.\n\nCopyright (C) 2001-2013 Vinay Sajip. All Rights Reserved.\n\nTo use, simply 'import logging' and log away!\n\"\"\"\n\nimport sys, logging, logging.handlers, socket, struct, traceback, re\nimport io\n\ntry:\n    import _thread as thread\n    import threading\nexcept ImportError: #pragma: no cover\n    thread = None\n\nfrom socketserver import ThreadingTCPServer, StreamRequestHandler\n\n\nDEFAULT_LOGGING_CONFIG_PORT = 9030\n\nif sys.platform == \"win32\":\n    RESET_ERROR = 10054   #WSAECONNRESET\nelse:\n    RESET_ERROR = 104     #ECONNRESET\n\n#\n#   The following code implements a socket listener for on-the-fly\n#   reconfiguration of logging.\n#\n#   _listener holds the server object doing the listening\n_listener = None\n\ndef fileConfig(fname, defaults=None, disable_existing_loggers=True):\n    \"\"\"\n    Read the logging configuration from a ConfigParser-format file.\n\n    This can be called several times from an application, allowing an end user\n    the ability to select from various pre-canned configurations (if the\n    developer provides a mechanism to present the choices and load the chosen\n    configuration).\n    \"\"\"\n    import configparser\n\n    cp = configparser.ConfigParser(defaults)\n    if hasattr(fname, 'readline'):\n        cp.read_file(fname)\n    else:\n        cp.read(fname)\n\n    formatters = _create_formatters(cp)\n\n    # critical section\n    logging._acquireLock()\n    try:\n        logging._handlers.clear()\n        del logging._handlerList[:]\n        # Handlers add themselves to logging._handlers\n        handlers = _install_handlers(cp, formatters)\n        _install_loggers(cp, handlers, disable_existing_loggers)\n    finally:\n        logging._releaseLock()\n\n\ndef _resolve(name):\n    \"\"\"Resolve a dotted name to a global object.\"\"\"\n    name = name.split('.')\n    used = name.pop(0)\n    found = __import__(used)\n    for n in name:\n        used = used + '.' + n\n        try:\n            found = getattr(found, n)\n        except AttributeError:\n            __import__(used)\n            found = getattr(found, n)\n    return found\n\ndef _strip_spaces(alist):\n    return map(lambda x: x.strip(), alist)\n\ndef _create_formatters(cp):\n    \"\"\"Create and return formatters\"\"\"\n    flist = cp[\"formatters\"][\"keys\"]\n    if not len(flist):\n        return {}\n    flist = flist.split(\",\")\n    flist = _strip_spaces(flist)\n    formatters = {}\n    for form in flist:\n        sectname = \"formatter_%s\" % form\n        fs = cp.get(sectname, \"format\", raw=True, fallback=None)\n        dfs = cp.get(sectname, \"datefmt\", raw=True, fallback=None)\n        c = logging.Formatter\n        class_name = cp[sectname].get(\"class\")\n        if class_name:\n            c = _resolve(class_name)\n        f = c(fs, dfs)\n        formatters[form] = f\n    return formatters\n\n\ndef _install_handlers(cp, formatters):\n    \"\"\"Install and return handlers\"\"\"\n    hlist = cp[\"handlers\"][\"keys\"]\n    if not len(hlist):\n        return {}\n    hlist = hlist.split(\",\")\n    hlist = _strip_spaces(hlist)\n    handlers = {}\n    fixups = [] #for inter-handler references\n    for hand in hlist:\n        section = cp[\"handler_%s\" % hand]\n        klass = section[\"class\"]\n        fmt = section.get(\"formatter\", \"\")\n        try:\n            klass = eval(klass, vars(logging))\n        except (AttributeError, NameError):\n            klass = _resolve(klass)\n        args = section[\"args\"]\n        args = eval(args, vars(logging))\n        h = klass(*args)\n        if \"level\" in section:\n            level = section[\"level\"]\n            h.setLevel(logging._levelNames[level])\n        if len(fmt):\n            h.setFormatter(formatters[fmt])\n        if issubclass(klass, logging.handlers.MemoryHandler):\n            target = section.get(\"target\", \"\")\n            if len(target): #the target handler may not be loaded yet, so keep for later...\n                fixups.append((h, target))\n        handlers[hand] = h\n    #now all handlers are loaded, fixup inter-handler references...\n    for h, t in fixups:\n        h.setTarget(handlers[t])\n    return handlers\n\ndef _handle_existing_loggers(existing, child_loggers, disable_existing):\n    \"\"\"\n    When (re)configuring logging, handle loggers which were in the previous\n    configuration but are not in the new configuration. There's no point\n    deleting them as other threads may continue to hold references to them;\n    and by disabling them, you stop them doing any logging.\n\n    However, don't disable children of named loggers, as that's probably not\n    what was intended by the user. Also, allow existing loggers to NOT be\n    disabled if disable_existing is false.\n    \"\"\"\n    root = logging.root\n    for log in existing:\n        logger = root.manager.loggerDict[log]\n        if log in child_loggers:\n            logger.level = logging.NOTSET\n            logger.handlers = []\n            logger.propagate = True\n        else:\n            logger.disabled = disable_existing\n\ndef _install_loggers(cp, handlers, disable_existing):\n    \"\"\"Create and install loggers\"\"\"\n\n    # configure the root first\n    llist = cp[\"loggers\"][\"keys\"]\n    llist = llist.split(\",\")\n    llist = list(map(lambda x: x.strip(), llist))\n    llist.remove(\"root\")\n    section = cp[\"logger_root\"]\n    root = logging.root\n    log = root\n    if \"level\" in section:\n        level = section[\"level\"]\n        log.setLevel(logging._levelNames[level])\n    for h in root.handlers[:]:\n        root.removeHandler(h)\n    hlist = section[\"handlers\"]\n    if len(hlist):\n        hlist = hlist.split(\",\")\n        hlist = _strip_spaces(hlist)\n        for hand in hlist:\n            log.addHandler(handlers[hand])\n\n    #and now the others...\n    #we don't want to lose the existing loggers,\n    #since other threads may have pointers to them.\n    #existing is set to contain all existing loggers,\n    #and as we go through the new configuration we\n    #remove any which are configured. At the end,\n    #what's left in existing is the set of loggers\n    #which were in the previous configuration but\n    #which are not in the new configuration.\n    existing = list(root.manager.loggerDict.keys())\n    #The list needs to be sorted so that we can\n    #avoid disabling child loggers of explicitly\n    #named loggers. With a sorted list it is easier\n    #to find the child loggers.\n    existing.sort()\n    #We'll keep the list of existing loggers\n    #which are children of named loggers here...\n    child_loggers = []\n    #now set up the new ones...\n    for log in llist:\n        section = cp[\"logger_%s\" % log]\n        qn = section[\"qualname\"]\n        propagate = section.getint(\"propagate\", fallback=1)\n        logger = logging.getLogger(qn)\n        if qn in existing:\n            i = existing.index(qn) + 1 # start with the entry after qn\n            prefixed = qn + \".\"\n            pflen = len(prefixed)\n            num_existing = len(existing)\n            while i < num_existing:\n                if existing[i][:pflen] == prefixed:\n                    child_loggers.append(existing[i])\n                i += 1\n            existing.remove(qn)\n        if \"level\" in section:\n            level = section[\"level\"]\n            logger.setLevel(logging._levelNames[level])\n        for h in logger.handlers[:]:\n            logger.removeHandler(h)\n        logger.propagate = propagate\n        logger.disabled = 0\n        hlist = section[\"handlers\"]\n        if len(hlist):\n            hlist = hlist.split(\",\")\n            hlist = _strip_spaces(hlist)\n            for hand in hlist:\n                logger.addHandler(handlers[hand])\n\n    #Disable any old loggers. There's no point deleting\n    #them as other threads may continue to hold references\n    #and by disabling them, you stop them doing any logging.\n    #However, don't disable children of named loggers, as that's\n    #probably not what was intended by the user.\n    #for log in existing:\n    #    logger = root.manager.loggerDict[log]\n    #    if log in child_loggers:\n    #        logger.level = logging.NOTSET\n    #        logger.handlers = []\n    #        logger.propagate = 1\n    #    elif disable_existing_loggers:\n    #        logger.disabled = 1\n    _handle_existing_loggers(existing, child_loggers, disable_existing)\n\nIDENTIFIER = re.compile('^[a-z_][a-z0-9_]*$', re.I)\n\n\ndef valid_ident(s):\n    m = IDENTIFIER.match(s)\n    if not m:\n        raise ValueError('Not a valid Python identifier: %r' % s)\n    return True\n\n\n# The ConvertingXXX classes are wrappers around standard Python containers,\n# and they serve to convert any suitable values in the container. The\n# conversion converts base dicts, lists and tuples to their wrapped\n# equivalents, whereas strings which match a conversion format are converted\n# appropriately.\n#\n# Each wrapper should have a configurator attribute holding the actual\n# configurator to use for conversion.\n\nclass ConvertingDict(dict):\n    \"\"\"A converting dictionary wrapper.\"\"\"\n\n    def __getitem__(self, key):\n        value = dict.__getitem__(self, key)\n        result = self.configurator.convert(value)\n        #If the converted value is different, save for next time\n        if value is not result:\n            self[key] = result\n            if type(result) in (ConvertingDict, ConvertingList,\n                                ConvertingTuple):\n                result.parent = self\n                result.key = key\n        return result\n\n    def get(self, key, default=None):\n        value = dict.get(self, key, default)\n        result = self.configurator.convert(value)\n        #If the converted value is different, save for next time\n        if value is not result:\n            self[key] = result\n            if type(result) in (ConvertingDict, ConvertingList,\n                                ConvertingTuple):\n                result.parent = self\n                result.key = key\n        return result\n\n    def pop(self, key, default=None):\n        value = dict.pop(self, key, default)\n        result = self.configurator.convert(value)\n        if value is not result:\n            if type(result) in (ConvertingDict, ConvertingList,\n                                ConvertingTuple):\n                result.parent = self\n                result.key = key\n        return result\n\nclass ConvertingList(list):\n    \"\"\"A converting list wrapper.\"\"\"\n    def __getitem__(self, key):\n        value = list.__getitem__(self, key)\n        result = self.configurator.convert(value)\n        #If the converted value is different, save for next time\n        if value is not result:\n            self[key] = result\n            if type(result) in (ConvertingDict, ConvertingList,\n                                ConvertingTuple):\n                result.parent = self\n                result.key = key\n        return result\n\n    def pop(self, idx=-1):\n        value = list.pop(self, idx)\n        result = self.configurator.convert(value)\n        if value is not result:\n            if type(result) in (ConvertingDict, ConvertingList,\n                                ConvertingTuple):\n                result.parent = self\n        return result\n\nclass ConvertingTuple(tuple):\n    \"\"\"A converting tuple wrapper.\"\"\"\n    def __getitem__(self, key):\n        value = tuple.__getitem__(self, key)\n        result = self.configurator.convert(value)\n        if value is not result:\n            if type(result) in (ConvertingDict, ConvertingList,\n                                ConvertingTuple):\n                result.parent = self\n                result.key = key\n        return result\n\nclass BaseConfigurator(object):\n    \"\"\"\n    The configurator base class which defines some useful defaults.\n    \"\"\"\n\n    CONVERT_PATTERN = re.compile(r'^(?P<prefix>[a-z]+)://(?P<suffix>.*)$')\n\n    WORD_PATTERN = re.compile(r'^\\s*(\\w+)\\s*')\n    DOT_PATTERN = re.compile(r'^\\.\\s*(\\w+)\\s*')\n    INDEX_PATTERN = re.compile(r'^\\[\\s*(\\w+)\\s*\\]\\s*')\n    DIGIT_PATTERN = re.compile(r'^\\d+$')\n\n    value_converters = {\n        'ext' : 'ext_convert',\n        'cfg' : 'cfg_convert',\n    }\n\n    # We might want to use a different one, e.g. importlib\n    importer = staticmethod(__import__)\n\n    def __init__(self, config):\n        self.config = ConvertingDict(config)\n        self.config.configurator = self\n\n    def resolve(self, s):\n        \"\"\"\n        Resolve strings to objects using standard import and attribute\n        syntax.\n        \"\"\"\n        name = s.split('.')\n        used = name.pop(0)\n        try:\n            found = self.importer(used)\n            for frag in name:\n                used += '.' + frag\n                try:\n                    found = getattr(found, frag)\n                except AttributeError:\n                    self.importer(used)\n                    found = getattr(found, frag)\n            return found\n        except ImportError:\n            e, tb = sys.exc_info()[1:]\n            v = ValueError('Cannot resolve %r: %s' % (s, e))\n            v.__cause__, v.__traceback__ = e, tb\n            raise v\n\n    def ext_convert(self, value):\n        \"\"\"Default converter for the ext:// protocol.\"\"\"\n        return self.resolve(value)\n\n    def cfg_convert(self, value):\n        \"\"\"Default converter for the cfg:// protocol.\"\"\"\n        rest = value\n        m = self.WORD_PATTERN.match(rest)\n        if m is None:\n            raise ValueError(\"Unable to convert %r\" % value)\n        else:\n            rest = rest[m.end():]\n            d = self.config[m.groups()[0]]\n            #print d, rest\n            while rest:\n                m = self.DOT_PATTERN.match(rest)\n                if m:\n                    d = d[m.groups()[0]]\n                else:\n                    m = self.INDEX_PATTERN.match(rest)\n                    if m:\n                        idx = m.groups()[0]\n                        if not self.DIGIT_PATTERN.match(idx):\n                            d = d[idx]\n                        else:\n                            try:\n                                n = int(idx) # try as number first (most likely)\n                                d = d[n]\n                            except TypeError:\n                                d = d[idx]\n                if m:\n                    rest = rest[m.end():]\n                else:\n                    raise ValueError('Unable to convert '\n                                     '%r at %r' % (value, rest))\n        #rest should be empty\n        return d\n\n    def convert(self, value):\n        \"\"\"\n        Convert values to an appropriate type. dicts, lists and tuples are\n        replaced by their converting alternatives. Strings are checked to\n        see if they have a conversion format and are converted if they do.\n        \"\"\"\n        if not isinstance(value, ConvertingDict) and isinstance(value, dict):\n            value = ConvertingDict(value)\n            value.configurator = self\n        elif not isinstance(value, ConvertingList) and isinstance(value, list):\n            value = ConvertingList(value)\n            value.configurator = self\n        elif not isinstance(value, ConvertingTuple) and\\\n                 isinstance(value, tuple):\n            value = ConvertingTuple(value)\n            value.configurator = self\n        elif isinstance(value, str): # str for py3k\n            m = self.CONVERT_PATTERN.match(value)\n            if m:\n                d = m.groupdict()\n                prefix = d['prefix']\n                converter = self.value_converters.get(prefix, None)\n                if converter:\n                    suffix = d['suffix']\n                    converter = getattr(self, converter)\n                    value = converter(suffix)\n        return value\n\n    def configure_custom(self, config):\n        \"\"\"Configure an object with a user-supplied factory.\"\"\"\n        c = config.pop('()')\n        if not callable(c):\n            c = self.resolve(c)\n        props = config.pop('.', None)\n        # Check for valid identifiers\n        kwargs = dict([(k, config[k]) for k in config if valid_ident(k)])\n        result = c(**kwargs)\n        if props:\n            for name, value in props.items():\n                setattr(result, name, value)\n        return result\n\n    def as_tuple(self, value):\n        \"\"\"Utility function which converts lists to tuples.\"\"\"\n        if isinstance(value, list):\n            value = tuple(value)\n        return value\n\nclass DictConfigurator(BaseConfigurator):\n    \"\"\"\n    Configure logging using a dictionary-like object to describe the\n    configuration.\n    \"\"\"\n\n    def configure(self):\n        \"\"\"Do the configuration.\"\"\"\n\n        config = self.config\n        if 'version' not in config:\n            raise ValueError(\"dictionary doesn't specify a version\")\n        if config['version'] != 1:\n            raise ValueError(\"Unsupported version: %s\" % config['version'])\n        incremental = config.pop('incremental', False)\n        EMPTY_DICT = {}\n        logging._acquireLock()\n        try:\n            if incremental:\n                handlers = config.get('handlers', EMPTY_DICT)\n                for name in handlers:\n                    if name not in logging._handlers:\n                        raise ValueError('No handler found with '\n                                         'name %r'  % name)\n                    else:\n                        try:\n                            handler = logging._handlers[name]\n                            handler_config = handlers[name]\n                            level = handler_config.get('level', None)\n                            if level:\n                                handler.setLevel(logging._checkLevel(level))\n                        except Exception as e:\n                            raise ValueError('Unable to configure handler '\n                                             '%r: %s' % (name, e))\n                loggers = config.get('loggers', EMPTY_DICT)\n                for name in loggers:\n                    try:\n                        self.configure_logger(name, loggers[name], True)\n                    except Exception as e:\n                        raise ValueError('Unable to configure logger '\n                                         '%r: %s' % (name, e))\n                root = config.get('root', None)\n                if root:\n                    try:\n                        self.configure_root(root, True)\n                    except Exception as e:\n                        raise ValueError('Unable to configure root '\n                                         'logger: %s' % e)\n            else:\n                disable_existing = config.pop('disable_existing_loggers', True)\n\n                logging._handlers.clear()\n                del logging._handlerList[:]\n\n                # Do formatters first - they don't refer to anything else\n                formatters = config.get('formatters', EMPTY_DICT)\n                for name in formatters:\n                    try:\n                        formatters[name] = self.configure_formatter(\n                                                            formatters[name])\n                    except Exception as e:\n                        raise ValueError('Unable to configure '\n                                         'formatter %r: %s' % (name, e))\n                # Next, do filters - they don't refer to anything else, either\n                filters = config.get('filters', EMPTY_DICT)\n                for name in filters:\n                    try:\n                        filters[name] = self.configure_filter(filters[name])\n                    except Exception as e:\n                        raise ValueError('Unable to configure '\n                                         'filter %r: %s' % (name, e))\n\n                # Next, do handlers - they refer to formatters and filters\n                # As handlers can refer to other handlers, sort the keys\n                # to allow a deterministic order of configuration\n                handlers = config.get('handlers', EMPTY_DICT)\n                deferred = []\n                for name in sorted(handlers):\n                    try:\n                        handler = self.configure_handler(handlers[name])\n                        handler.name = name\n                        handlers[name] = handler\n                    except Exception as e:\n                        if 'target not configured yet' in str(e):\n                            deferred.append(name)\n                        else:\n                            raise ValueError('Unable to configure handler '\n                                             '%r: %s' % (name, e))\n\n                # Now do any that were deferred\n                for name in deferred:\n                    try:\n                        handler = self.configure_handler(handlers[name])\n                        handler.name = name\n                        handlers[name] = handler\n                    except Exception as e:\n                        raise ValueError('Unable to configure handler '\n                                         '%r: %s' % (name, e))\n\n                # Next, do loggers - they refer to handlers and filters\n\n                #we don't want to lose the existing loggers,\n                #since other threads may have pointers to them.\n                #existing is set to contain all existing loggers,\n                #and as we go through the new configuration we\n                #remove any which are configured. At the end,\n                #what's left in existing is the set of loggers\n                #which were in the previous configuration but\n                #which are not in the new configuration.\n                root = logging.root\n                existing = list(root.manager.loggerDict.keys())\n                #The list needs to be sorted so that we can\n                #avoid disabling child loggers of explicitly\n                #named loggers. With a sorted list it is easier\n                #to find the child loggers.\n                existing.sort()\n                #We'll keep the list of existing loggers\n                #which are children of named loggers here...\n                child_loggers = []\n                #now set up the new ones...\n                loggers = config.get('loggers', EMPTY_DICT)\n                for name in loggers:\n                    if name in existing:\n                        i = existing.index(name) + 1 # look after name\n                        prefixed = name + \".\"\n                        pflen = len(prefixed)\n                        num_existing = len(existing)\n                        while i < num_existing:\n                            if existing[i][:pflen] == prefixed:\n                                child_loggers.append(existing[i])\n                            i += 1\n                        existing.remove(name)\n                    try:\n                        self.configure_logger(name, loggers[name])\n                    except Exception as e:\n                        raise ValueError('Unable to configure logger '\n                                         '%r: %s' % (name, e))\n\n                #Disable any old loggers. There's no point deleting\n                #them as other threads may continue to hold references\n                #and by disabling them, you stop them doing any logging.\n                #However, don't disable children of named loggers, as that's\n                #probably not what was intended by the user.\n                #for log in existing:\n                #    logger = root.manager.loggerDict[log]\n                #    if log in child_loggers:\n                #        logger.level = logging.NOTSET\n                #        logger.handlers = []\n                #        logger.propagate = True\n                #    elif disable_existing:\n                #        logger.disabled = True\n                _handle_existing_loggers(existing, child_loggers,\n                                         disable_existing)\n\n                # And finally, do the root logger\n                root = config.get('root', None)\n                if root:\n                    try:\n                        self.configure_root(root)\n                    except Exception as e:\n                        raise ValueError('Unable to configure root '\n                                         'logger: %s' % e)\n        finally:\n            logging._releaseLock()\n\n    def configure_formatter(self, config):\n        \"\"\"Configure a formatter from a dictionary.\"\"\"\n        if '()' in config:\n            factory = config['()'] # for use in exception handler\n            try:\n                result = self.configure_custom(config)\n            except TypeError as te:\n                if \"'format'\" not in str(te):\n                    raise\n                #Name of parameter changed from fmt to format.\n                #Retry with old name.\n                #This is so that code can be used with older Python versions\n                #(e.g. by Django)\n                config['fmt'] = config.pop('format')\n                config['()'] = factory\n                result = self.configure_custom(config)\n        else:\n            fmt = config.get('format', None)\n            dfmt = config.get('datefmt', None)\n            style = config.get('style', '%')\n            result = logging.Formatter(fmt, dfmt, style)\n        return result\n\n    def configure_filter(self, config):\n        \"\"\"Configure a filter from a dictionary.\"\"\"\n        if '()' in config:\n            result = self.configure_custom(config)\n        else:\n            name = config.get('name', '')\n            result = logging.Filter(name)\n        return result\n\n    def add_filters(self, filterer, filters):\n        \"\"\"Add filters to a filterer from a list of names.\"\"\"\n        for f in filters:\n            try:\n                filterer.addFilter(self.config['filters'][f])\n            except Exception as e:\n                raise ValueError('Unable to add filter %r: %s' % (f, e))\n\n    def configure_handler(self, config):\n        \"\"\"Configure a handler from a dictionary.\"\"\"\n        config_copy = dict(config)  # for restoring in case of error\n        formatter = config.pop('formatter', None)\n        if formatter:\n            try:\n                formatter = self.config['formatters'][formatter]\n            except Exception as e:\n                raise ValueError('Unable to set formatter '\n                                 '%r: %s' % (formatter, e))\n        level = config.pop('level', None)\n        filters = config.pop('filters', None)\n        if '()' in config:\n            c = config.pop('()')\n            if not callable(c):\n                c = self.resolve(c)\n            factory = c\n        else:\n            cname = config.pop('class')\n            klass = self.resolve(cname)\n            #Special case for handler which refers to another handler\n            if issubclass(klass, logging.handlers.MemoryHandler) and\\\n                'target' in config:\n                try:\n                    th = self.config['handlers'][config['target']]\n                    if not isinstance(th, logging.Handler):\n                        config.update(config_copy)  # restore for deferred cfg\n                        raise TypeError('target not configured yet')\n                    config['target'] = th\n                except Exception as e:\n                    raise ValueError('Unable to set target handler '\n                                     '%r: %s' % (config['target'], e))\n            elif issubclass(klass, logging.handlers.SMTPHandler) and\\\n                'mailhost' in config:\n                config['mailhost'] = self.as_tuple(config['mailhost'])\n            elif issubclass(klass, logging.handlers.SysLogHandler) and\\\n                'address' in config:\n                config['address'] = self.as_tuple(config['address'])\n            factory = klass\n        kwargs = dict([(k, config[k]) for k in config if valid_ident(k)])\n        try:\n            result = factory(**kwargs)\n        except TypeError as te:\n            if \"'stream'\" not in str(te):\n                raise\n            #The argument name changed from strm to stream\n            #Retry with old name.\n            #This is so that code can be used with older Python versions\n            #(e.g. by Django)\n            kwargs['strm'] = kwargs.pop('stream')\n            result = factory(**kwargs)\n        if formatter:\n            result.setFormatter(formatter)\n        if level is not None:\n            result.setLevel(logging._checkLevel(level))\n        if filters:\n            self.add_filters(result, filters)\n        return result\n\n    def add_handlers(self, logger, handlers):\n        \"\"\"Add handlers to a logger from a list of names.\"\"\"\n        for h in handlers:\n            try:\n                logger.addHandler(self.config['handlers'][h])\n            except Exception as e:\n                raise ValueError('Unable to add handler %r: %s' % (h, e))\n\n    def common_logger_config(self, logger, config, incremental=False):\n        \"\"\"\n        Perform configuration which is common to root and non-root loggers.\n        \"\"\"\n        level = config.get('level', None)\n        if level is not None:\n            logger.setLevel(logging._checkLevel(level))\n        if not incremental:\n            #Remove any existing handlers\n            for h in logger.handlers[:]:\n                logger.removeHandler(h)\n            handlers = config.get('handlers', None)\n            if handlers:\n                self.add_handlers(logger, handlers)\n            filters = config.get('filters', None)\n            if filters:\n                self.add_filters(logger, filters)\n\n    def configure_logger(self, name, config, incremental=False):\n        \"\"\"Configure a non-root logger from a dictionary.\"\"\"\n        logger = logging.getLogger(name)\n        self.common_logger_config(logger, config, incremental)\n        propagate = config.get('propagate', None)\n        if propagate is not None:\n            logger.propagate = propagate\n\n    def configure_root(self, config, incremental=False):\n        \"\"\"Configure a root logger from a dictionary.\"\"\"\n        root = logging.getLogger()\n        self.common_logger_config(root, config, incremental)\n\ndictConfigClass = DictConfigurator\n\ndef dictConfig(config):\n    \"\"\"Configure logging using a dictionary.\"\"\"\n    dictConfigClass(config).configure()\n\n\ndef listen(port=DEFAULT_LOGGING_CONFIG_PORT):\n    \"\"\"\n    Start up a socket server on the specified port, and listen for new\n    configurations.\n\n    These will be sent as a file suitable for processing by fileConfig().\n    Returns a Thread object on which you can call start() to start the server,\n    and which you can join() when appropriate. To stop the server, call\n    stopListening().\n    \"\"\"\n    if not thread: #pragma: no cover\n        raise NotImplementedError(\"listen() needs threading to work\")\n\n    class ConfigStreamHandler(StreamRequestHandler):\n        \"\"\"\n        Handler for a logging configuration request.\n\n        It expects a completely new logging configuration and uses fileConfig\n        to install it.\n        \"\"\"\n        def handle(self):\n            \"\"\"\n            Handle a request.\n\n            Each request is expected to be a 4-byte length, packed using\n            struct.pack(\">L\", n), followed by the config file.\n            Uses fileConfig() to do the grunt work.\n            \"\"\"\n            try:\n                conn = self.connection\n                chunk = conn.recv(4)\n                if len(chunk) == 4:\n                    slen = struct.unpack(\">L\", chunk)[0]\n                    chunk = self.connection.recv(slen)\n                    while len(chunk) < slen:\n                        chunk = chunk + conn.recv(slen - len(chunk))\n                    chunk = chunk.decode(\"utf-8\")\n                    try:\n                        import json\n                        d =json.loads(chunk)\n                        assert isinstance(d, dict)\n                        dictConfig(d)\n                    except:\n                        #Apply new configuration.\n\n                        file = io.StringIO(chunk)\n                        try:\n                            fileConfig(file)\n                        except (KeyboardInterrupt, SystemExit): #pragma: no cover\n                            raise\n                        except:\n                            traceback.print_exc()\n                    if self.server.ready:\n                        self.server.ready.set()\n            except socket.error as e:\n                if not isinstance(e.args, tuple):\n                    raise\n                else:\n                    errcode = e.args[0]\n                    if errcode != RESET_ERROR:\n                        raise\n\n    class ConfigSocketReceiver(ThreadingTCPServer):\n        \"\"\"\n        A simple TCP socket-based logging config receiver.\n        \"\"\"\n\n        allow_reuse_address = 1\n\n        def __init__(self, host='localhost', port=DEFAULT_LOGGING_CONFIG_PORT,\n                     handler=None, ready=None):\n            ThreadingTCPServer.__init__(self, (host, port), handler)\n            logging._acquireLock()\n            self.abort = 0\n            logging._releaseLock()\n            self.timeout = 1\n            self.ready = ready\n\n        def serve_until_stopped(self):\n            import select\n            abort = 0\n            while not abort:\n                rd, wr, ex = select.select([self.socket.fileno()],\n                                           [], [],\n                                           self.timeout)\n                if rd:\n                    self.handle_request()\n                logging._acquireLock()\n                abort = self.abort\n                logging._releaseLock()\n            self.socket.close()\n\n    class Server(threading.Thread):\n\n        def __init__(self, rcvr, hdlr, port):\n            super(Server, self).__init__()\n            self.rcvr = rcvr\n            self.hdlr = hdlr\n            self.port = port\n            self.ready = threading.Event()\n\n        def run(self):\n            server = self.rcvr(port=self.port, handler=self.hdlr,\n                               ready=self.ready)\n            if self.port == 0:\n                self.port = server.server_address[1]\n            self.ready.set()\n            global _listener\n            logging._acquireLock()\n            _listener = server\n            logging._releaseLock()\n            server.serve_until_stopped()\n\n    return Server(ConfigSocketReceiver, ConfigStreamHandler, port)\n\ndef stopListening():\n    \"\"\"\n    Stop the listening server which was created with a call to listen().\n    \"\"\"\n    global _listener\n    logging._acquireLock()\n    try:\n        if _listener:\n            _listener.abort = 1\n            _listener = None\n    finally:\n        logging._releaseLock()\n"], "xml.sax.handler": [".py", "\"\"\"\nThis module contains the core classes of version 2.0 of SAX for Python.\nThis file provides only default classes with absolutely minimum\nfunctionality, from which drivers and applications can be subclassed.\n\nMany of these classes are empty and are included only as documentation\nof the interfaces.\n\n$Id$\n\"\"\"\n\nversion = '2.0beta'\n\n#============================================================================\n#\n# HANDLER INTERFACES\n#\n#============================================================================\n\n# ===== ERRORHANDLER =====\n\nclass ErrorHandler:\n    \"\"\"Basic interface for SAX error handlers.\n\n    If you create an object that implements this interface, then\n    register the object with your XMLReader, the parser will call the\n    methods in your object to report all warnings and errors. There\n    are three levels of errors available: warnings, (possibly)\n    recoverable errors, and unrecoverable errors. All methods take a\n    SAXParseException as the only parameter.\"\"\"\n\n    def error(self, exception):\n        \"Handle a recoverable error.\"\n        raise exception\n\n    def fatalError(self, exception):\n        \"Handle a non-recoverable error.\"\n        raise exception\n\n    def warning(self, exception):\n        \"Handle a warning.\"\n        print(exception)\n\n\n# ===== CONTENTHANDLER =====\n\nclass ContentHandler:\n    \"\"\"Interface for receiving logical document content events.\n\n    This is the main callback interface in SAX, and the one most\n    important to applications. The order of events in this interface\n    mirrors the order of the information in the document.\"\"\"\n\n    def __init__(self):\n        self._locator = None\n\n    def setDocumentLocator(self, locator):\n        \"\"\"Called by the parser to give the application a locator for\n        locating the origin of document events.\n\n        SAX parsers are strongly encouraged (though not absolutely\n        required) to supply a locator: if it does so, it must supply\n        the locator to the application by invoking this method before\n        invoking any of the other methods in the DocumentHandler\n        interface.\n\n        The locator allows the application to determine the end\n        position of any document-related event, even if the parser is\n        not reporting an error. Typically, the application will use\n        this information for reporting its own errors (such as\n        character content that does not match an application's\n        business rules). The information returned by the locator is\n        probably not sufficient for use with a search engine.\n\n        Note that the locator will return correct information only\n        during the invocation of the events in this interface. The\n        application should not attempt to use it at any other time.\"\"\"\n        self._locator = locator\n\n    def startDocument(self):\n        \"\"\"Receive notification of the beginning of a document.\n\n        The SAX parser will invoke this method only once, before any\n        other methods in this interface or in DTDHandler (except for\n        setDocumentLocator).\"\"\"\n\n    def endDocument(self):\n        \"\"\"Receive notification of the end of a document.\n\n        The SAX parser will invoke this method only once, and it will\n        be the last method invoked during the parse. The parser shall\n        not invoke this method until it has either abandoned parsing\n        (because of an unrecoverable error) or reached the end of\n        input.\"\"\"\n\n    def startPrefixMapping(self, prefix, uri):\n        \"\"\"Begin the scope of a prefix-URI Namespace mapping.\n\n        The information from this event is not necessary for normal\n        Namespace processing: the SAX XML reader will automatically\n        replace prefixes for element and attribute names when the\n        http://xml.org/sax/features/namespaces feature is true (the\n        default).\n\n        There are cases, however, when applications need to use\n        prefixes in character data or in attribute values, where they\n        cannot safely be expanded automatically; the\n        start/endPrefixMapping event supplies the information to the\n        application to expand prefixes in those contexts itself, if\n        necessary.\n\n        Note that start/endPrefixMapping events are not guaranteed to\n        be properly nested relative to each-other: all\n        startPrefixMapping events will occur before the corresponding\n        startElement event, and all endPrefixMapping events will occur\n        after the corresponding endElement event, but their order is\n        not guaranteed.\"\"\"\n\n    def endPrefixMapping(self, prefix):\n        \"\"\"End the scope of a prefix-URI mapping.\n\n        See startPrefixMapping for details. This event will always\n        occur after the corresponding endElement event, but the order\n        of endPrefixMapping events is not otherwise guaranteed.\"\"\"\n\n    def startElement(self, name, attrs):\n        \"\"\"Signals the start of an element in non-namespace mode.\n\n        The name parameter contains the raw XML 1.0 name of the\n        element type as a string and the attrs parameter holds an\n        instance of the Attributes class containing the attributes of\n        the element.\"\"\"\n\n    def endElement(self, name):\n        \"\"\"Signals the end of an element in non-namespace mode.\n\n        The name parameter contains the name of the element type, just\n        as with the startElement event.\"\"\"\n\n    def startElementNS(self, name, qname, attrs):\n        \"\"\"Signals the start of an element in namespace mode.\n\n        The name parameter contains the name of the element type as a\n        (uri, localname) tuple, the qname parameter the raw XML 1.0\n        name used in the source document, and the attrs parameter\n        holds an instance of the Attributes class containing the\n        attributes of the element.\n\n        The uri part of the name tuple is None for elements which have\n        no namespace.\"\"\"\n\n    def endElementNS(self, name, qname):\n        \"\"\"Signals the end of an element in namespace mode.\n\n        The name parameter contains the name of the element type, just\n        as with the startElementNS event.\"\"\"\n\n    def characters(self, content):\n        \"\"\"Receive notification of character data.\n\n        The Parser will call this method to report each chunk of\n        character data. SAX parsers may return all contiguous\n        character data in a single chunk, or they may split it into\n        several chunks; however, all of the characters in any single\n        event must come from the same external entity so that the\n        Locator provides useful information.\"\"\"\n\n    def ignorableWhitespace(self, whitespace):\n        \"\"\"Receive notification of ignorable whitespace in element content.\n\n        Validating Parsers must use this method to report each chunk\n        of ignorable whitespace (see the W3C XML 1.0 recommendation,\n        section 2.10): non-validating parsers may also use this method\n        if they are capable of parsing and using content models.\n\n        SAX parsers may return all contiguous whitespace in a single\n        chunk, or they may split it into several chunks; however, all\n        of the characters in any single event must come from the same\n        external entity, so that the Locator provides useful\n        information.\"\"\"\n\n    def processingInstruction(self, target, data):\n        \"\"\"Receive notification of a processing instruction.\n\n        The Parser will invoke this method once for each processing\n        instruction found: note that processing instructions may occur\n        before or after the main document element.\n\n        A SAX parser should never report an XML declaration (XML 1.0,\n        section 2.8) or a text declaration (XML 1.0, section 4.3.1)\n        using this method.\"\"\"\n\n    def skippedEntity(self, name):\n        \"\"\"Receive notification of a skipped entity.\n\n        The Parser will invoke this method once for each entity\n        skipped. Non-validating processors may skip entities if they\n        have not seen the declarations (because, for example, the\n        entity was declared in an external DTD subset). All processors\n        may skip external entities, depending on the values of the\n        http://xml.org/sax/features/external-general-entities and the\n        http://xml.org/sax/features/external-parameter-entities\n        properties.\"\"\"\n\n\n# ===== DTDHandler =====\n\nclass DTDHandler:\n    \"\"\"Handle DTD events.\n\n    This interface specifies only those DTD events required for basic\n    parsing (unparsed entities and attributes).\"\"\"\n\n    def notationDecl(self, name, publicId, systemId):\n        \"Handle a notation declaration event.\"\n\n    def unparsedEntityDecl(self, name, publicId, systemId, ndata):\n        \"Handle an unparsed entity declaration event.\"\n\n\n# ===== ENTITYRESOLVER =====\n\nclass EntityResolver:\n    \"\"\"Basic interface for resolving entities. If you create an object\n    implementing this interface, then register the object with your\n    Parser, the parser will call the method in your object to\n    resolve all external entities. Note that DefaultHandler implements\n    this interface with the default behaviour.\"\"\"\n\n    def resolveEntity(self, publicId, systemId):\n        \"\"\"Resolve the system identifier of an entity and return either\n        the system identifier to read from as a string, or an InputSource\n        to read from.\"\"\"\n        return systemId\n\n\n#============================================================================\n#\n# CORE FEATURES\n#\n#============================================================================\n\nfeature_namespaces = \"http://xml.org/sax/features/namespaces\"\n# true: Perform Namespace processing (default).\n# false: Optionally do not perform Namespace processing\n#        (implies namespace-prefixes).\n# access: (parsing) read-only; (not parsing) read/write\n\nfeature_namespace_prefixes = \"http://xml.org/sax/features/namespace-prefixes\"\n# true: Report the original prefixed names and attributes used for Namespace\n#       declarations.\n# false: Do not report attributes used for Namespace declarations, and\n#        optionally do not report original prefixed names (default).\n# access: (parsing) read-only; (not parsing) read/write\n\nfeature_string_interning = \"http://xml.org/sax/features/string-interning\"\n# true: All element names, prefixes, attribute names, Namespace URIs, and\n#       local names are interned using the built-in intern function.\n# false: Names are not necessarily interned, although they may be (default).\n# access: (parsing) read-only; (not parsing) read/write\n\nfeature_validation = \"http://xml.org/sax/features/validation\"\n# true: Report all validation errors (implies external-general-entities and\n#       external-parameter-entities).\n# false: Do not report validation errors.\n# access: (parsing) read-only; (not parsing) read/write\n\nfeature_external_ges = \"http://xml.org/sax/features/external-general-entities\"\n# true: Include all external general (text) entities.\n# false: Do not include external general entities.\n# access: (parsing) read-only; (not parsing) read/write\n\nfeature_external_pes = \"http://xml.org/sax/features/external-parameter-entities\"\n# true: Include all external parameter entities, including the external\n#       DTD subset.\n# false: Do not include any external parameter entities, even the external\n#        DTD subset.\n# access: (parsing) read-only; (not parsing) read/write\n\nall_features = [feature_namespaces,\n                feature_namespace_prefixes,\n                feature_string_interning,\n                feature_validation,\n                feature_external_ges,\n                feature_external_pes]\n\n\n#============================================================================\n#\n# CORE PROPERTIES\n#\n#============================================================================\n\nproperty_lexical_handler = \"http://xml.org/sax/properties/lexical-handler\"\n# data type: xml.sax.sax2lib.LexicalHandler\n# description: An optional extension handler for lexical events like comments.\n# access: read/write\n\nproperty_declaration_handler = \"http://xml.org/sax/properties/declaration-handler\"\n# data type: xml.sax.sax2lib.DeclHandler\n# description: An optional extension handler for DTD-related events other\n#              than notations and unparsed entities.\n# access: read/write\n\nproperty_dom_node = \"http://xml.org/sax/properties/dom-node\"\n# data type: org.w3c.dom.Node\n# description: When parsing, the current DOM node being visited if this is\n#              a DOM iterator; when not parsing, the root DOM node for\n#              iteration.\n# access: (parsing) read-only; (not parsing) read/write\n\nproperty_xml_string = \"http://xml.org/sax/properties/xml-string\"\n# data type: String\n# description: The literal string of characters that was the source for\n#              the current event.\n# access: read-only\n\nproperty_encoding = \"http://www.python.org/sax/properties/encoding\"\n# data type: String\n# description: The name of the encoding to assume for input data.\n# access: write: set the encoding, e.g. established by a higher-level\n#                protocol. May change during parsing (e.g. after\n#                processing a META tag)\n#         read:  return the current encoding (possibly established through\n#                auto-detection.\n# initial value: UTF-8\n#\n\nproperty_interning_dict = \"http://www.python.org/sax/properties/interning-dict\"\n# data type: Dictionary\n# description: The dictionary used to intern common strings in the document\n# access: write: Request that the parser uses a specific dictionary, to\n#                allow interning across different documents\n#         read:  return the current interning dictionary, or None\n#\n\nall_properties = [property_lexical_handler,\n                  property_dom_node,\n                  property_declaration_handler,\n                  property_xml_string,\n                  property_encoding,\n                  property_interning_dict]\n"], "importlib.machinery": [".py", "\"\"\"The machinery of importlib: finders, loaders, hooks, etc.\"\"\"\n\nimport _imp\n\nfrom ._bootstrap import (SOURCE_SUFFIXES, DEBUG_BYTECODE_SUFFIXES,\n                         OPTIMIZED_BYTECODE_SUFFIXES, #BYTECODE_SUFFIXES,\n                         EXTENSION_SUFFIXES)\nfrom ._bootstrap import BuiltinImporter\nfrom ._bootstrap import FrozenImporter\nfrom ._bootstrap import WindowsRegistryFinder\nfrom ._bootstrap import PathFinder\nfrom ._bootstrap import FileFinder\nfrom ._bootstrap import SourceFileLoader\nfrom ._bootstrap import SourcelessFileLoader\nfrom ._bootstrap import ExtensionFileLoader\n\n\n#def all_suffixes():\n#    \"\"\"Returns a list of all recognized module suffixes for this process\"\"\"\n#    return SOURCE_SUFFIXES + BYTECODE_SUFFIXES + EXTENSION_SUFFIXES\n"], "tokenize": [".py", "\"\"\"Tokenization help for Python programs.\n\ntokenize(readline) is a generator that breaks a stream of bytes into\nPython tokens.  It decodes the bytes according to PEP-0263 for\ndetermining source file encoding.\n\nIt accepts a readline-like method which is called repeatedly to get the\nnext line of input (or b\"\" for EOF).  It generates 5-tuples with these\nmembers:\n\n    the token type (see token.py)\n    the token (a string)\n    the starting (row, column) indices of the token (a 2-tuple of ints)\n    the ending (row, column) indices of the token (a 2-tuple of ints)\n    the original line (string)\n\nIt is designed to match the working of the Python tokenizer exactly, except\nthat it produces COMMENT tokens for comments and gives type OP for all\noperators.  Additionally, all token lists start with an ENCODING token\nwhich tells you which encoding was used to decode the bytes stream.\n\"\"\"\n\n__author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__credits__ = ('GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, '\n               'Skip Montanaro, Raymond Hettinger, Trent Nelson, '\n               'Michael Foord')\nimport builtins\nimport re\nimport sys\nfrom token import *\nfrom codecs import lookup, BOM_UTF8\nimport collections\nfrom io import TextIOWrapper\ncookie_re = re.compile(r'^[ \\t\\f]*#.*coding[:=][ \\t]*([-\\w.]+)', re.ASCII)\n\nimport token\n__all__ = token.__all__ + [\"COMMENT\", \"tokenize\", \"detect_encoding\",\n                           \"NL\", \"untokenize\", \"ENCODING\", \"TokenInfo\"]\ndel token\n\nCOMMENT = N_TOKENS\ntok_name[COMMENT] = 'COMMENT'\nNL = N_TOKENS + 1\ntok_name[NL] = 'NL'\nENCODING = N_TOKENS + 2\ntok_name[ENCODING] = 'ENCODING'\nN_TOKENS += 3\nEXACT_TOKEN_TYPES = {\n    '(':   LPAR,\n    ')':   RPAR,\n    '[':   LSQB,\n    ']':   RSQB,\n    ':':   COLON,\n    ',':   COMMA,\n    ';':   SEMI,\n    '+':   PLUS,\n    '-':   MINUS,\n    '*':   STAR,\n    '/':   SLASH,\n    '|':   VBAR,\n    '&':   AMPER,\n    '<':   LESS,\n    '>':   GREATER,\n    '=':   EQUAL,\n    '.':   DOT,\n    '%':   PERCENT,\n    '{':   LBRACE,\n    '}':   RBRACE,\n    '==':  EQEQUAL,\n    '!=':  NOTEQUAL,\n    '<=':  LESSEQUAL,\n    '>=':  GREATEREQUAL,\n    '~':   TILDE,\n    '^':   CIRCUMFLEX,\n    '<<':  LEFTSHIFT,\n    '>>':  RIGHTSHIFT,\n    '**':  DOUBLESTAR,\n    '+=':  PLUSEQUAL,\n    '-=':  MINEQUAL,\n    '*=':  STAREQUAL,\n    '/=':  SLASHEQUAL,\n    '%=':  PERCENTEQUAL,\n    '&=':  AMPEREQUAL,\n    '|=':  VBAREQUAL,\n    '^=': CIRCUMFLEXEQUAL,\n    '<<=': LEFTSHIFTEQUAL,\n    '>>=': RIGHTSHIFTEQUAL,\n    '**=': DOUBLESTAREQUAL,\n    '//':  DOUBLESLASH,\n    '//=': DOUBLESLASHEQUAL,\n    '@':   AT\n}\n\nclass TokenInfo(collections.namedtuple('TokenInfo', 'type string start end line')):\n    def __repr__(self):\n        annotated_type = '%d (%s)' % (self.type, tok_name[self.type])\n        return ('TokenInfo(type=%s, string=%r, start=%r, end=%r, line=%r)' %\n                self._replace(type=annotated_type))\n\n    @property\n    def exact_type(self):\n        if self.type == OP and self.string in EXACT_TOKEN_TYPES:\n            return EXACT_TOKEN_TYPES[self.string]\n        else:\n            return self.type\n\ndef group(*choices): return '(' + '|'.join(choices) + ')'\ndef any(*choices): return group(*choices) + '*'\ndef maybe(*choices): return group(*choices) + '?'\n\n# Note: we use unicode matching for names (\"\\w\") but ascii matching for\n# number literals.\nWhitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'\n\nHexnumber = r'0[xX][0-9a-fA-F]+'\nBinnumber = r'0[bB][01]+'\nOctnumber = r'0[oO][0-7]+'\nDecnumber = r'(?:0+|[1-9][0-9]*)'\nIntnumber = group(Hexnumber, Binnumber, Octnumber, Decnumber)\nExponent = r'[eE][-+]?[0-9]+'\nPointfloat = group(r'[0-9]+\\.[0-9]*', r'\\.[0-9]+') + maybe(Exponent)\nExpfloat = r'[0-9]+' + Exponent\nFloatnumber = group(Pointfloat, Expfloat)\nImagnumber = group(r'[0-9]+[jJ]', Floatnumber + r'[jJ]')\nNumber = group(Imagnumber, Floatnumber, Intnumber)\n\nStringPrefix = r'(?:[bB][rR]?|[rR][bB]?|[uU])?'\n\n# Tail end of ' string.\nSingle = r\"[^'\\\\]*(?:\\\\.[^'\\\\]*)*'\"\n# Tail end of \" string.\nDouble = r'[^\"\\\\]*(?:\\\\.[^\"\\\\]*)*\"'\n# Tail end of ''' string.\nSingle3 = r\"[^'\\\\]*(?:(?:\\\\.|'(?!''))[^'\\\\]*)*'''\"\n# Tail end of \"\"\" string.\nDouble3 = r'[^\"\\\\]*(?:(?:\\\\.|\"(?!\"\"))[^\"\\\\]*)*\"\"\"'\nTriple = group(StringPrefix + \"'''\", StringPrefix + '\"\"\"')\n# Single-line ' or \" string.\nString = group(StringPrefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n               StringPrefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"')\n\n# Because of leftmost-then-longest match semantics, be sure to put the\n# longest operators first (e.g., if = came before ==, == would get\n# recognized as two instances of =).\nOperator = group(r\"\\*\\*=?\", r\">>=?\", r\"<<=?\", r\"!=\",\n                 r\"//=?\", r\"->\",\n                 r\"[+\\-*/%&|^=<>]=?\",\n                 r\"~\")\n\nBracket = '[][(){}]'\nSpecial = group(r'\\r?\\n', r'\\.\\.\\.', r'[:;.,@]')\nFunny = group(Operator, Bracket, Special)\n\nPlainToken = group(Number, Funny, String, Name)\nToken = Ignore + PlainToken\n\n# First (or only) line of ' or \" string.\nContStr = group(StringPrefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\n                group(\"'\", r'\\\\\\r?\\n'),\n                StringPrefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\n                group('\"', r'\\\\\\r?\\n'))\nPseudoExtras = group(r'\\\\\\r?\\n|\\Z', Comment, Triple)\nPseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)\n\ndef _compile(expr):\n    return re.compile(expr, re.UNICODE)\n\nendpats = {\"'\": Single, '\"': Double,\n           \"'''\": Single3, '\"\"\"': Double3,\n           \"r'''\": Single3, 'r\"\"\"': Double3,\n           \"b'''\": Single3, 'b\"\"\"': Double3,\n           \"R'''\": Single3, 'R\"\"\"': Double3,\n           \"B'''\": Single3, 'B\"\"\"': Double3,\n           \"br'''\": Single3, 'br\"\"\"': Double3,\n           \"bR'''\": Single3, 'bR\"\"\"': Double3,\n           \"Br'''\": Single3, 'Br\"\"\"': Double3,\n           \"BR'''\": Single3, 'BR\"\"\"': Double3,\n           \"rb'''\": Single3, 'rb\"\"\"': Double3,\n           \"Rb'''\": Single3, 'Rb\"\"\"': Double3,\n           \"rB'''\": Single3, 'rB\"\"\"': Double3,\n           \"RB'''\": Single3, 'RB\"\"\"': Double3,\n           \"u'''\": Single3, 'u\"\"\"': Double3,\n           \"R'''\": Single3, 'R\"\"\"': Double3,\n           \"U'''\": Single3, 'U\"\"\"': Double3,\n           'r': None, 'R': None, 'b': None, 'B': None,\n           'u': None, 'U': None}\n\ntriple_quoted = {}\nfor t in (\"'''\", '\"\"\"',\n          \"r'''\", 'r\"\"\"', \"R'''\", 'R\"\"\"',\n          \"b'''\", 'b\"\"\"', \"B'''\", 'B\"\"\"',\n          \"br'''\", 'br\"\"\"', \"Br'''\", 'Br\"\"\"',\n          \"bR'''\", 'bR\"\"\"', \"BR'''\", 'BR\"\"\"',\n          \"rb'''\", 'rb\"\"\"', \"rB'''\", 'rB\"\"\"',\n          \"Rb'''\", 'Rb\"\"\"', \"RB'''\", 'RB\"\"\"',\n          \"u'''\", 'u\"\"\"', \"U'''\", 'U\"\"\"',\n          ):\n    triple_quoted[t] = t\nsingle_quoted = {}\nfor t in (\"'\", '\"',\n          \"r'\", 'r\"', \"R'\", 'R\"',\n          \"b'\", 'b\"', \"B'\", 'B\"',\n          \"br'\", 'br\"', \"Br'\", 'Br\"',\n          \"bR'\", 'bR\"', \"BR'\", 'BR\"' ,\n          \"rb'\", 'rb\"', \"rB'\", 'rB\"',\n          \"Rb'\", 'Rb\"', \"RB'\", 'RB\"' ,\n          \"u'\", 'u\"', \"U'\", 'U\"',\n          ):\n    single_quoted[t] = t\n\ntabsize = 8\n\nclass TokenError(Exception): pass\n\nclass StopTokenizing(Exception): pass\n\n\nclass Untokenizer:\n\n    def __init__(self):\n        self.tokens = []\n        self.prev_row = 1\n        self.prev_col = 0\n        self.encoding = None\n\n    def add_whitespace(self, start):\n        row, col = start\n        assert row <= self.prev_row\n        col_offset = col - self.prev_col\n        if col_offset:\n            self.tokens.append(\" \" * col_offset)\n\n    def untokenize(self, iterable):\n        for t in iterable:\n            if len(t) == 2:\n                self.compat(t, iterable)\n                break\n            tok_type, token, start, end, line = t\n            if tok_type == ENCODING:\n                self.encoding = token\n                continue\n            self.add_whitespace(start)\n            self.tokens.append(token)\n            self.prev_row, self.prev_col = end\n            if tok_type in (NEWLINE, NL):\n                self.prev_row += 1\n                self.prev_col = 0\n        return \"\".join(self.tokens)\n\n    def compat(self, token, iterable):\n        startline = False\n        indents = []\n        toks_append = self.tokens.append\n        toknum, tokval = token\n\n        if toknum in (NAME, NUMBER):\n            tokval += ' '\n        if toknum in (NEWLINE, NL):\n            startline = True\n        prevstring = False\n        for tok in iterable:\n            toknum, tokval = tok[:2]\n            if toknum == ENCODING:\n                self.encoding = tokval\n                continue\n\n            if toknum in (NAME, NUMBER):\n                tokval += ' '\n\n            # Insert a space between two consecutive strings\n            if toknum == STRING:\n                if prevstring:\n                    tokval = ' ' + tokval\n                prevstring = True\n            else:\n                prevstring = False\n\n            if toknum == INDENT:\n                indents.append(tokval)\n                continue\n            elif toknum == DEDENT:\n                indents.pop()\n                continue\n            elif toknum in (NEWLINE, NL):\n                startline = True\n            elif startline and indents:\n                toks_append(indents[-1])\n                startline = False\n            toks_append(tokval)\n\n\ndef untokenize(iterable):\n    \"\"\"Transform tokens back into Python source code.\n    It returns a bytes object, encoded using the ENCODING\n    token, which is the first token sequence output by tokenize.\n\n    Each element returned by the iterable must be a token sequence\n    with at least two elements, a token number and token value.  If\n    only two tokens are passed, the resulting output is poor.\n\n    Round-trip invariant for full input:\n        Untokenized source will match input source exactly\n\n    Round-trip invariant for limited intput:\n        # Output bytes will tokenize the back to the input\n        t1 = [tok[:2] for tok in tokenize(f.readline)]\n        newcode = untokenize(t1)\n        readline = BytesIO(newcode).readline\n        t2 = [tok[:2] for tok in tokenize(readline)]\n        assert t1 == t2\n    \"\"\"\n    ut = Untokenizer()\n    out = ut.untokenize(iterable)\n    if ut.encoding is not None:\n        out = out.encode(ut.encoding)\n    return out\n\n\ndef _get_normal_name(orig_enc):\n    \"\"\"Imitates get_normal_name in tokenizer.c.\"\"\"\n    # Only care about the first 12 characters.\n    enc = orig_enc[:12].lower().replace(\"_\", \"-\")\n    if enc == \"utf-8\" or enc.startswith(\"utf-8-\"):\n        return \"utf-8\"\n    if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or \\\n       enc.startswith((\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")):\n        return \"iso-8859-1\"\n    return orig_enc\n\ndef detect_encoding(readline):\n    \"\"\"\n    The detect_encoding() function is used to detect the encoding that should\n    be used to decode a Python source file.  It requires one argment, readline,\n    in the same way as the tokenize() generator.\n\n    It will call readline a maximum of twice, and return the encoding used\n    (as a string) and a list of any lines (left as bytes) it has read in.\n\n    It detects the encoding from the presence of a utf-8 bom or an encoding\n    cookie as specified in pep-0263.  If both a bom and a cookie are present,\n    but disagree, a SyntaxError will be raised.  If the encoding cookie is an\n    invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found,\n    'utf-8-sig' is returned.\n\n    If no encoding is specified, then the default of 'utf-8' will be returned.\n    \"\"\"\n    try:\n        filename = readline.__self__.name\n    except AttributeError:\n        filename = None\n    bom_found = False\n    encoding = None\n    default = 'utf-8'\n    def read_or_stop():\n        try:\n            return readline()\n        except StopIteration:\n            return b''\n\n    def find_cookie(line):\n        try:\n            # Decode as UTF-8. Either the line is an encoding declaration,\n            # in which case it should be pure ASCII, or it must be UTF-8\n            # per default encoding.\n            line_string = line.decode('utf-8')\n        except UnicodeDecodeError:\n            msg = \"invalid or missing encoding declaration\"\n            if filename is not None:\n                msg = '{} for {!r}'.format(msg, filename)\n            raise SyntaxError(msg)\n\n        match = cookie_re.match(line_string)\n        if not match:\n            return None\n        encoding = _get_normal_name(match.group(1))\n        try:\n            codec = lookup(encoding)\n        except LookupError:\n            # This behaviour mimics the Python interpreter\n            if filename is None:\n                msg = \"unknown encoding: \" + encoding\n            else:\n                msg = \"unknown encoding for {!r}: {}\".format(filename,\n                        encoding)\n            raise SyntaxError(msg)\n\n        if bom_found:\n            if encoding != 'utf-8':\n                # This behaviour mimics the Python interpreter\n                if filename is None:\n                    msg = 'encoding problem: utf-8'\n                else:\n                    msg = 'encoding problem for {!r}: utf-8'.format(filename)\n                raise SyntaxError(msg)\n            encoding += '-sig'\n        return encoding\n\n    first = read_or_stop()\n    if first.startswith(BOM_UTF8):\n        bom_found = True\n        first = first[3:]\n        default = 'utf-8-sig'\n    if not first:\n        return default, []\n\n    encoding = find_cookie(first)\n    if encoding:\n        return encoding, [first]\n\n    second = read_or_stop()\n    if not second:\n        return default, [first]\n\n    encoding = find_cookie(second)\n    if encoding:\n        return encoding, [first, second]\n\n    return default, [first, second]\n\n\ndef open(filename):\n    \"\"\"Open a file in read only mode using the encoding detected by\n    detect_encoding().\n    \"\"\"\n    buffer = builtins.open(filename, 'rb')\n    encoding, lines = detect_encoding(buffer.readline)\n    buffer.seek(0)\n    text = TextIOWrapper(buffer, encoding, line_buffering=True)\n    text.mode = 'r'\n    return text\n\n\ndef tokenize(readline):\n    \"\"\"\n    The tokenize() generator requires one argment, readline, which\n    must be a callable object which provides the same interface as the\n    readline() method of built-in file objects.  Each call to the function\n    should return one line of input as bytes.  Alternately, readline\n    can be a callable function terminating with StopIteration:\n        readline = open(myfile, 'rb').__next__  # Example of alternate readline\n\n    The generator produces 5-tuples with these members: the token type; the\n    token string; a 2-tuple (srow, scol) of ints specifying the row and\n    column where the token begins in the source; a 2-tuple (erow, ecol) of\n    ints specifying the row and column where the token ends in the source;\n    and the line on which the token was found.  The line passed is the\n    logical line; continuation lines are included.\n\n    The first token sequence will always be an ENCODING token\n    which tells you which encoding was used to decode the bytes stream.\n    \"\"\"\n    # This import is here to avoid problems when the itertools module is not\n    # built yet and tokenize is imported.\n    from itertools import chain, repeat\n    encoding, consumed = detect_encoding(readline)\n    rl_gen = iter(readline, b\"\")\n    empty = repeat(b\"\")\n    return _tokenize(chain(consumed, rl_gen, empty).__next__, encoding)\n\n\ndef _tokenize(readline, encoding):\n    lnum = parenlev = continued = 0\n    numchars = '0123456789'\n    contstr, needcont = '', 0\n    contline = None\n    indents = [0]\n\n    if encoding is not None:\n        if encoding == \"utf-8-sig\":\n            # BOM will already have been stripped.\n            encoding = \"utf-8\"\n        yield TokenInfo(ENCODING, encoding, (0, 0), (0, 0), '')\n    while True:             # loop over lines in stream\n        try:\n            line = readline()\n        except StopIteration:\n            line = b''\n\n        if encoding is not None:\n            line = line.decode(encoding)\n        lnum += 1\n        pos, max = 0, len(line)\n\n        if contstr:                            # continued string\n            if not line:\n                raise TokenError(\"EOF in multi-line string\", strstart)\n            endmatch = endprog.match(line)\n            if endmatch:\n                pos = end = endmatch.end(0)\n                yield TokenInfo(STRING, contstr + line[:end],\n                       strstart, (lnum, end), contline + line)\n                contstr, needcont = '', 0\n                contline = None\n            elif needcont and line[-2:] != '\\\\\\n' and line[-3:] != '\\\\\\r\\n':\n                yield TokenInfo(ERRORTOKEN, contstr + line,\n                           strstart, (lnum, len(line)), contline)\n                contstr = ''\n                contline = None\n                continue\n            else:\n                contstr = contstr + line\n                contline = contline + line\n                continue\n\n        elif parenlev == 0 and not continued:  # new statement\n            if not line: break\n            column = 0\n            while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ':\n                    column += 1\n                elif line[pos] == '\\t':\n                    column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f':\n                    column = 0\n                else:\n                    break\n                pos += 1\n            if pos == max:\n                break\n\n            if line[pos] in '#\\r\\n':           # skip comments or blank lines\n                if line[pos] == '#':\n                    comment_token = line[pos:].rstrip('\\r\\n')\n                    nl_pos = pos + len(comment_token)\n                    yield TokenInfo(COMMENT, comment_token,\n                           (lnum, pos), (lnum, pos + len(comment_token)), line)\n                    yield TokenInfo(NL, line[nl_pos:],\n                           (lnum, nl_pos), (lnum, len(line)), line)\n                else:\n                    yield TokenInfo((NL, COMMENT)[line[pos] == '#'], line[pos:],\n                           (lnum, pos), (lnum, len(line)), line)\n                continue\n\n            if column > indents[-1]:           # count indents or dedents\n                indents.append(column)\n                yield TokenInfo(INDENT, line[:pos], (lnum, 0), (lnum, pos), line)\n            while column < indents[-1]:\n                if column not in indents:\n                    raise IndentationError(\n                        \"unindent does not match any outer indentation level\",\n                        (\"<tokenize>\", lnum, pos, line))\n                indents = indents[:-1]\n                yield TokenInfo(DEDENT, '', (lnum, pos), (lnum, pos), line)\n\n        else:                                  # continued statement\n            if not line:\n                raise TokenError(\"EOF in multi-line statement\", (lnum, 0))\n            continued = 0\n\n        while pos < max:\n            pseudomatch = _compile(PseudoToken).match(line, pos)\n            if pseudomatch:                                # scan for tokens\n                start, end = pseudomatch.span(1)\n                spos, epos, pos = (lnum, start), (lnum, end), end\n                if start == end:\n                    continue\n                token, initial = line[start:end], line[start]\n\n                if (initial in numchars or                  # ordinary number\n                    (initial == '.' and token != '.' and token != '...')):\n                    yield TokenInfo(NUMBER, token, spos, epos, line)\n                elif initial in '\\r\\n':\n                    yield TokenInfo(NL if parenlev > 0 else NEWLINE,\n                           token, spos, epos, line)\n                elif initial == '#':\n                    assert not token.endswith(\"\\n\")\n                    yield TokenInfo(COMMENT, token, spos, epos, line)\n                elif token in triple_quoted:\n                    endprog = _compile(endpats[token])\n                    endmatch = endprog.match(line, pos)\n                    if endmatch:                           # all on one line\n                        pos = endmatch.end(0)\n                        token = line[start:pos]\n                        yield TokenInfo(STRING, token, spos, (lnum, pos), line)\n                    else:\n                        strstart = (lnum, start)           # multiple lines\n                        contstr = line[start:]\n                        contline = line\n                        break\n                elif initial in single_quoted or \\\n                    token[:2] in single_quoted or \\\n                    token[:3] in single_quoted:\n                    if token[-1] == '\\n':                  # continued string\n                        strstart = (lnum, start)\n                        endprog = _compile(endpats[initial] or\n                                           endpats[token[1]] or\n                                           endpats[token[2]])\n                        contstr, needcont = line[start:], 1\n                        contline = line\n                        break\n                    else:                                  # ordinary string\n                        yield TokenInfo(STRING, token, spos, epos, line)\n                elif initial.isidentifier():               # ordinary name\n                    yield TokenInfo(NAME, token, spos, epos, line)\n                elif initial == '\\\\':                      # continued stmt\n                    continued = 1\n                else:\n                    if initial in '([{':\n                        parenlev += 1\n                    elif initial in ')]}':\n                        parenlev -= 1\n                    yield TokenInfo(OP, token, spos, epos, line)\n            else:\n                yield TokenInfo(ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line)\n                pos += 1\n\n    for indent in indents[1:]:                 # pop remaining indent levels\n        yield TokenInfo(DEDENT, '', (lnum, 0), (lnum, 0), '')\n    yield TokenInfo(ENDMARKER, '', (lnum, 0), (lnum, 0), '')\n\n\n# An undocumented, backwards compatible, API for all the places in the standard\n# library that expect to be able to use tokenize with strings\ndef generate_tokens(readline):\n    return _tokenize(readline, None)\n\ndef main():\n    import argparse\n\n    # Helper error handling routines\n    def perror(message):\n        print(message, file=sys.stderr)\n\n    def error(message, filename=None, location=None):\n        if location:\n            args = (filename,) + location + (message,)\n            perror(\"%s:%d:%d: error: %s\" % args)\n        elif filename:\n            perror(\"%s: error: %s\" % (filename, message))\n        else:\n            perror(\"error: %s\" % message)\n        sys.exit(1)\n\n    # Parse the arguments and options\n    parser = argparse.ArgumentParser(prog='python -m tokenize')\n    parser.add_argument(dest='filename', nargs='?',\n                        metavar='filename.py',\n                        help='the file to tokenize; defaults to stdin')\n    parser.add_argument('-e', '--exact', dest='exact', action='store_true',\n                        help='display token names using the exact type')\n    args = parser.parse_args()\n\n    try:\n        # Tokenize the input\n        if args.filename:\n            filename = args.filename\n            with builtins.open(filename, 'rb') as f:\n                tokens = list(tokenize(f.readline))\n        else:\n            filename = \"<stdin>\"\n            tokens = _tokenize(sys.stdin.readline, None)\n\n        # Output the tokenization\n        for token in tokens:\n            token_type = token.type\n            if args.exact:\n                token_type = token.exact_type\n            token_range = \"%d,%d-%d,%d:\" % (token.start + token.end)\n            print(\"%-20s%-15s%-15r\" %\n                  (token_range, tok_name[token_type], token.string))\n    except IndentationError as err:\n        line, column = err.args[1][1:3]\n        error(err.args[0], filename, (line, column))\n    except TokenError as err:\n        line, column = err.args[1]\n        error(err.args[0], filename, (line, column))\n    except SyntaxError as err:\n        error(err, filename)\n    except IOError as err:\n        error(err)\n    except KeyboardInterrupt:\n        print(\"interrupted\\n\")\n    except Exception as err:\n        perror(\"unexpected error: %s\" % err)\n        raise\n\nif __name__ == \"__main__\":\n    main()\n"], "_warnings": [".py", "\"\"\"_warnings provides basic warning filtering support.\nIt is a helper module to speed up interpreter start-up.\"\"\"\n\n\ndefault_action = \"\"\"default\"\"\"\n\nfilters = \"[('ignore', None, <type 'exceptions.DeprecationWarning'>, None, 0), \n    ('ignore', None, <type 'exceptions.PendingDeprecationWarning'>, None, 0), \n    ('ignore', None, <type 'exceptions.ImportWarning'>, None, 0), \n    ('ignore', None, <type 'exceptions.BytesWarning'>, None, 0)]\"\n\nonce_registry = {}\n\ndef warn(*args,**kw):\n    \"\"\"Issue a warning, or maybe ignore it or raise an exception.\"\"\"\n    pass\n\ndef warn_explicit(*args,**kw):\n    \"\"\"Low-level inferface to warnings functionality.\"\"\"\n    pass\n"], "ui.dialog": [".py", "from . import widget\nfrom browser import html, document\n\nclass Dialog(widget.DraggableWidget):\n  def __init__(self, id=None):\n      self._div_shell=html.DIV(\n         Class=\"ui-dialog ui-widget ui-widget-content ui-corner-all ui-front ui-draggable ui-resizable\",\n         style={'position': 'absolute', 'height': 'auto', 'width': '300px',\n                'top': '98px', 'left': '140px', 'display': 'block'})\n\n      widget.DraggableWidget.__init__(self, self._div_shell, 'dialog', id)\n\n      _div_titlebar=html.DIV(Id=\"titlebar\",\n           Class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix\")\n      self._div_shell <= _div_titlebar\n\n      self._div_title=html.SPAN(Id=\"title\", Class=\"ui-dialog-title\")\n        \n      _div_titlebar <= self._div_title\n\n      self._title_button=html.BUTTON(Title=\"close\",\n            Class=\"ui-button ui-widget ui-state-default ui-corner-all ui-button-icon-only ui-dialog-titlebar-close\")\n\n      def dialog_close(e):\n          #del document[self._div_shell.id]\n          del document[self._div_shell.id]\n\n      self._title_button.bind('click', dialog_close)\n      _span=html.SPAN(Class=\"ui-button-icon-primary ui-icon ui-icon-closethick\")\n      self._title_button <= _span\n\n      _span=html.SPAN('close', Class=\"ui-button-text\")\n      self._title_button <= _span\n\n      _div_titlebar <= self._title_button\n\n      self._div_dialog=html.DIV(Class=\"ui-dialog-content ui-widget-content\",\n           style={'width': 'auto', 'min-height': '105px', \n                  'max-height': 'none', 'height': 'auto'})\n\n      self._div_shell <= self._div_dialog\n\n      for _i in ['n', 'e', 's', 'w', 'se', 'sw', 'ne', 'nw']:\n          if _i == 'se':\n             _class=\"ui-resizable-handle ui-resizable-%s ui-icon ui-icon-gripsmall-diagonal-%s\" % (_i, _i)\n          else:\n             _class=\"ui-resizable-handle ui-resizable-%s\" % _i\n\n          self._div_shell <= html.DIV(Class=_class, style={'z-index': '90'})\n\n      document <= self._div_shell\n\n  def set_title(self, title):\n      self._div_title.set_text(title)\n\n  def set_body(self, body):\n      self._div_dialog.set_html(body)\n\nclass EntryDialog(Dialog):\n\n    def __init__(self, title, prompt, action, _id=None):\n        Dialog.__init__(self, _id)\n        self.set_title(title)\n        self.action = action\n        d_prompt = html.DIV(prompt, Class=\"ui-widget\", \n            style=dict(float=\"left\",paddingRight=\"10px\"))\n        self.entry = html.INPUT()\n        body = html.DIV(d_prompt+self.entry,\n            style={'padding':'15px'})\n        b_ok = html.BUTTON(\"Ok\")\n        b_ok.bind('click', self.ok)\n        b_cancel = html.BUTTON(\"Cancel\")\n        b_cancel.bind('click', self.cancel)\n        body += html.DIV(b_ok+b_cancel, style={'padding':'15px'})\n        self._div_dialog <= body\n    \n    def ok(self, ev):\n        self.result = self._div_shell.get(selector='INPUT')[0].value\n        self.action(self.result)\n        document.remove(self._div_shell)\n\n    def cancel(self, ev):\n        document.remove(self._div_shell)\n\nclass SelectDialog(Dialog):\n\n    def __init__(self, title, prompt, options, action, _id=None):\n        Dialog.__init__(self, _id)\n        self.set_title(title)\n        self.options = options\n        self.action = action\n        d_prompt = html.DIV(prompt, Class=\"ui-widget\", \n            style=dict(float=\"left\",paddingRight=\"10px\"))\n        self.select = html.SELECT()\n        for option in options:\n            self.select <= html.OPTION(option)\n        body = html.DIV(d_prompt+self.select,\n            style={'padding':'15px'})\n        b_ok = html.BUTTON(\"Ok\")\n        b_ok.bind('click', self.ok)\n        b_cancel = html.BUTTON(\"Cancel\")\n        b_cancel.bind('click', self.cancel)\n        body += html.DIV(b_ok+b_cancel, style={'padding':'15px'})\n        self._div_dialog <= body\n    \n    def ok(self, ev):\n        ix = self._div_shell.get(selector='SELECT')[0].selectedIndex\n        document.remove(self._div_shell)\n        self.action(self.options[ix])\n\n    def cancel(self, ev):\n        document.remove(self._div_shell)\n\nclass YesNoDialog(Dialog):\n\n    def __init__(self, title, prompt, action_if_yes, action_if_no, _id=None):\n        Dialog.__init__(self, _id)\n        self.set_title(title)\n        \n        self.action_if_yes = action_if_yes\n        self.action_if_no = action_if_no\n        \n        d_prompt = html.DIV(prompt, Class=\"ui-widget\", \n            style=dict(float=\"left\",paddingRight=\"10px\"))\n        body = html.DIV(d_prompt, style={'padding':'15px'})\n        b_ok = html.BUTTON(\"Yes\")\n        b_ok.bind('click', self.yes)\n        b_cancel = html.BUTTON(\"No\")\n        b_cancel.bind('click', self.no)\n        body += html.DIV(b_ok+b_cancel, style={'padding':'15px'})\n        self._div_dialog <= body\n    \n    def yes(self, ev):\n        document.remove(self._div_shell)\n        self.action_if_yes(self)\n\n    def no(self, ev):\n        document.remove(self._div_shell)\n        if self.action_if_no is not None:\n            self.action_if_no(self)\n"], "fractions": [".py", "# Originally contributed by Sjoerd Mullender.\n# Significantly modified by Jeffrey Yasskin <jyasskin at gmail.com>.\n\n\"\"\"Fraction, infinite-precision, real numbers.\"\"\"\n\nfrom decimal import Decimal\nimport math\nimport numbers\nimport operator\nimport re\nimport sys\n\n__all__ = ['Fraction', 'gcd']\n\n\n\ndef gcd(a, b):\n    \"\"\"Calculate the Greatest Common Divisor of a and b.\n\n    Unless b==0, the result will have the same sign as b (so that when\n    b is divided by it, the result comes out positive).\n    \"\"\"\n    while b:\n        a, b = b, a%b\n    return a\n\n# Constants related to the hash implementation;  hash(x) is based\n# on the reduction of x modulo the prime _PyHASH_MODULUS.\n_PyHASH_MODULUS = sys.hash_info.modulus\n# Value to be used for rationals that reduce to infinity modulo\n# _PyHASH_MODULUS.\n_PyHASH_INF = sys.hash_info.inf\n\n_RATIONAL_FORMAT = re.compile(r\"\"\"\n    \\A\\s*                      # optional whitespace at the start, then\n    (?P<sign>[-+]?)            # an optional sign, then\n    (?=\\d|\\.\\d)                # lookahead for digit or .digit\n    (?P<num>\\d*)               # numerator (possibly empty)\n    (?:                        # followed by\n       (?:/(?P<denom>\\d+))?    # an optional denominator\n    |                          # or\n       (?:\\.(?P<decimal>\\d*))? # an optional fractional part\n       (?:E(?P<exp>[-+]?\\d+))? # and optional exponent\n    )\n    \\s*\\Z                      # and optional whitespace to finish\n\"\"\", re.VERBOSE | re.IGNORECASE)\n\n\nclass Fraction(numbers.Rational):\n    \"\"\"This class implements rational numbers.\n\n    In the two-argument form of the constructor, Fraction(8, 6) will\n    produce a rational number equivalent to 4/3. Both arguments must\n    be Rational. The numerator defaults to 0 and the denominator\n    defaults to 1 so that Fraction(3) == 3 and Fraction() == 0.\n\n    Fractions can also be constructed from:\n\n      - numeric strings similar to those accepted by the\n        float constructor (for example, '-2.3' or '1e10')\n\n      - strings of the form '123/456'\n\n      - float and Decimal instances\n\n      - other Rational instances (including integers)\n\n    \"\"\"\n\n    __slots__ = ('_numerator', '_denominator')\n\n    # We're immutable, so use __new__ not __init__\n    def __new__(cls, numerator=0, denominator=None):\n        \"\"\"Constructs a Rational.\n\n        Takes a string like '3/2' or '1.5', another Rational instance, a\n        numerator/denominator pair, or a float.\n\n        Examples\n        --------\n\n        >>> Fraction(10, -8)\n        Fraction(-5, 4)\n        >>> Fraction(Fraction(1, 7), 5)\n        Fraction(1, 35)\n        >>> Fraction(Fraction(1, 7), Fraction(2, 3))\n        Fraction(3, 14)\n        >>> Fraction('314')\n        Fraction(314, 1)\n        >>> Fraction('-35/4')\n        Fraction(-35, 4)\n        >>> Fraction('3.1415') # conversion from numeric string\n        Fraction(6283, 2000)\n        >>> Fraction('-47e-2') # string may include a decimal exponent\n        Fraction(-47, 100)\n        >>> Fraction(1.47)  # direct construction from float (exact conversion)\n        Fraction(6620291452234629, 4503599627370496)\n        >>> Fraction(2.25)\n        Fraction(9, 4)\n        >>> Fraction(Decimal('1.47'))\n        Fraction(147, 100)\n\n        \"\"\"\n        self = super(Fraction, cls).__new__(cls)\n\n        if denominator is None:\n            if isinstance(numerator, numbers.Rational):\n                self._numerator = numerator.numerator\n                self._denominator = numerator.denominator\n                return self\n\n            elif isinstance(numerator, float):\n                # Exact conversion from float\n                value = Fraction.from_float(numerator)\n                self._numerator = value._numerator\n                self._denominator = value._denominator\n                return self\n\n            elif isinstance(numerator, Decimal):\n                value = Fraction.from_decimal(numerator)\n                self._numerator = value._numerator\n                self._denominator = value._denominator\n                return self\n\n            elif isinstance(numerator, str):\n                # Handle construction from strings.\n                m = _RATIONAL_FORMAT.match(numerator)\n                if m is None:\n                    raise ValueError('Invalid literal for Fraction: %r' %\n                                     numerator)\n                numerator = int(m.group('num') or '0')\n                denom = m.group('denom')\n                if denom:\n                    denominator = int(denom)\n                else:\n                    denominator = 1\n                    decimal = m.group('decimal')\n                    if decimal:\n                        scale = 10**len(decimal)\n                        numerator = numerator * scale + int(decimal)\n                        denominator *= scale\n                    exp = m.group('exp')\n                    if exp:\n                        exp = int(exp)\n                        if exp >= 0:\n                            numerator *= 10**exp\n                        else:\n                            denominator *= 10**-exp\n                if m.group('sign') == '-':\n                    numerator = -numerator\n\n            else:\n                raise TypeError(\"argument should be a string \"\n                                \"or a Rational instance\")\n\n        elif (isinstance(numerator, numbers.Rational) and\n            isinstance(denominator, numbers.Rational)):\n            numerator, denominator = (\n                numerator.numerator * denominator.denominator,\n                denominator.numerator * numerator.denominator\n                )\n        else:\n            raise TypeError(\"both arguments should be \"\n                            \"Rational instances\")\n\n        if denominator == 0:\n            raise ZeroDivisionError('Fraction(%s, 0)' % numerator)\n        g = gcd(numerator, denominator)\n        self._numerator = numerator // g\n        self._denominator = denominator // g\n        return self\n\n    @classmethod\n    def from_float(cls, f):\n        \"\"\"Converts a finite float to a rational number, exactly.\n\n        Beware that Fraction.from_float(0.3) != Fraction(3, 10).\n\n        \"\"\"\n        if isinstance(f, numbers.Integral):\n            return cls(f)\n        elif not isinstance(f, float):\n            raise TypeError(\"%s.from_float() only takes floats, not %r (%s)\" %\n                            (cls.__name__, f, type(f).__name__))\n        if math.isnan(f):\n            raise ValueError(\"Cannot convert %r to %s.\" % (f, cls.__name__))\n        if math.isinf(f):\n            raise OverflowError(\"Cannot convert %r to %s.\" % (f, cls.__name__))\n        return cls(*f.as_integer_ratio())\n\n    @classmethod\n    def from_decimal(cls, dec):\n        \"\"\"Converts a finite Decimal instance to a rational number, exactly.\"\"\"\n        from decimal import Decimal\n        if isinstance(dec, numbers.Integral):\n            dec = Decimal(int(dec))\n        elif not isinstance(dec, Decimal):\n            raise TypeError(\n                \"%s.from_decimal() only takes Decimals, not %r (%s)\" %\n                (cls.__name__, dec, type(dec).__name__))\n        if dec.is_infinite():\n            raise OverflowError(\n                \"Cannot convert %s to %s.\" % (dec, cls.__name__))\n        if dec.is_nan():\n            raise ValueError(\"Cannot convert %s to %s.\" % (dec, cls.__name__))\n        sign, digits, exp = dec.as_tuple()\n        digits = int(''.join(map(str, digits)))\n        if sign:\n            digits = -digits\n        if exp >= 0:\n            return cls(digits * 10 ** exp)\n        else:\n            return cls(digits, 10 ** -exp)\n\n    def limit_denominator(self, max_denominator=1000000):\n        \"\"\"Closest Fraction to self with denominator at most max_denominator.\n\n        >>> Fraction('3.141592653589793').limit_denominator(10)\n        Fraction(22, 7)\n        >>> Fraction('3.141592653589793').limit_denominator(100)\n        Fraction(311, 99)\n        >>> Fraction(4321, 8765).limit_denominator(10000)\n        Fraction(4321, 8765)\n\n        \"\"\"\n        # Algorithm notes: For any real number x, define a *best upper\n        # approximation* to x to be a rational number p/q such that:\n        #\n        #   (1) p/q >= x, and\n        #   (2) if p/q > r/s >= x then s > q, for any rational r/s.\n        #\n        # Define *best lower approximation* similarly.  Then it can be\n        # proved that a rational number is a best upper or lower\n        # approximation to x if, and only if, it is a convergent or\n        # semiconvergent of the (unique shortest) continued fraction\n        # associated to x.\n        #\n        # To find a best rational approximation with denominator <= M,\n        # we find the best upper and lower approximations with\n        # denominator <= M and take whichever of these is closer to x.\n        # In the event of a tie, the bound with smaller denominator is\n        # chosen.  If both denominators are equal (which can happen\n        # only when max_denominator == 1 and self is midway between\n        # two integers) the lower bound---i.e., the floor of self, is\n        # taken.\n\n        if max_denominator < 1:\n            raise ValueError(\"max_denominator should be at least 1\")\n        if self._denominator <= max_denominator:\n            return Fraction(self)\n\n        p0, q0, p1, q1 = 0, 1, 1, 0\n        n, d = self._numerator, self._denominator\n        while True:\n            a = n//d\n            q2 = q0+a*q1\n            if q2 > max_denominator:\n                break\n            p0, q0, p1, q1 = p1, q1, p0+a*p1, q2\n            n, d = d, n-a*d\n\n        k = (max_denominator-q0)//q1\n        bound1 = Fraction(p0+k*p1, q0+k*q1)\n        bound2 = Fraction(p1, q1)\n        if abs(bound2 - self) <= abs(bound1-self):\n            return bound2\n        else:\n            return bound1\n\n    @property\n    def numerator(a):\n        return a._numerator\n\n    @property\n    def denominator(a):\n        return a._denominator\n\n    def __repr__(self):\n        \"\"\"repr(self)\"\"\"\n        return ('Fraction(%s, %s)' % (self._numerator, self._denominator))\n\n    def __str__(self):\n        \"\"\"str(self)\"\"\"\n        if self._denominator == 1:\n            return str(self._numerator)\n        else:\n            return '%s/%s' % (self._numerator, self._denominator)\n\n    def _operator_fallbacks(monomorphic_operator, fallback_operator):\n        \"\"\"Generates forward and reverse operators given a purely-rational\n        operator and a function from the operator module.\n\n        Use this like:\n        __op__, __rop__ = _operator_fallbacks(just_rational_op, operator.op)\n\n        In general, we want to implement the arithmetic operations so\n        that mixed-mode operations either call an implementation whose\n        author knew about the types of both arguments, or convert both\n        to the nearest built in type and do the operation there. In\n        Fraction, that means that we define __add__ and __radd__ as:\n\n            def __add__(self, other):\n                # Both types have numerators/denominator attributes,\n                # so do the operation directly\n                if isinstance(other, (int, Fraction)):\n                    return Fraction(self.numerator * other.denominator +\n                                    other.numerator * self.denominator,\n                                    self.denominator * other.denominator)\n                # float and complex don't have those operations, but we\n                # know about those types, so special case them.\n                elif isinstance(other, float):\n                    return float(self) + other\n                elif isinstance(other, complex):\n                    return complex(self) + other\n                # Let the other type take over.\n                return NotImplemented\n\n            def __radd__(self, other):\n                # radd handles more types than add because there's\n                # nothing left to fall back to.\n                if isinstance(other, numbers.Rational):\n                    return Fraction(self.numerator * other.denominator +\n                                    other.numerator * self.denominator,\n                                    self.denominator * other.denominator)\n                elif isinstance(other, Real):\n                    return float(other) + float(self)\n                elif isinstance(other, Complex):\n                    return complex(other) + complex(self)\n                return NotImplemented\n\n\n        There are 5 different cases for a mixed-type addition on\n        Fraction. I'll refer to all of the above code that doesn't\n        refer to Fraction, float, or complex as \"boilerplate\". 'r'\n        will be an instance of Fraction, which is a subtype of\n        Rational (r : Fraction <: Rational), and b : B <:\n        Complex. The first three involve 'r + b':\n\n            1. If B <: Fraction, int, float, or complex, we handle\n               that specially, and all is well.\n            2. If Fraction falls back to the boilerplate code, and it\n               were to return a value from __add__, we'd miss the\n               possibility that B defines a more intelligent __radd__,\n               so the boilerplate should return NotImplemented from\n               __add__. In particular, we don't handle Rational\n               here, even though we could get an exact answer, in case\n               the other type wants to do something special.\n            3. If B <: Fraction, Python tries B.__radd__ before\n               Fraction.__add__. This is ok, because it was\n               implemented with knowledge of Fraction, so it can\n               handle those instances before delegating to Real or\n               Complex.\n\n        The next two situations describe 'b + r'. We assume that b\n        didn't know about Fraction in its implementation, and that it\n        uses similar boilerplate code:\n\n            4. If B <: Rational, then __radd_ converts both to the\n               builtin rational type (hey look, that's us) and\n               proceeds.\n            5. Otherwise, __radd__ tries to find the nearest common\n               base ABC, and fall back to its builtin type. Since this\n               class doesn't subclass a concrete type, there's no\n               implementation to fall back to, so we need to try as\n               hard as possible to return an actual value, or the user\n               will get a TypeError.\n\n        \"\"\"\n        def forward(a, b):\n            if isinstance(b, (int, Fraction)):\n                return monomorphic_operator(a, b)\n            elif isinstance(b, float):\n                return fallback_operator(float(a), b)\n            elif isinstance(b, complex):\n                return fallback_operator(complex(a), b)\n            else:\n                return NotImplemented\n        forward.__name__ = '__' + fallback_operator.__name__ + '__'\n        forward.__doc__ = monomorphic_operator.__doc__\n\n        def reverse(b, a):\n            if isinstance(a, numbers.Rational):\n                # Includes ints.\n                return monomorphic_operator(a, b)\n            elif isinstance(a, numbers.Real):\n                return fallback_operator(float(a), float(b))\n            elif isinstance(a, numbers.Complex):\n                return fallback_operator(complex(a), complex(b))\n            else:\n                return NotImplemented\n        reverse.__name__ = '__r' + fallback_operator.__name__ + '__'\n        reverse.__doc__ = monomorphic_operator.__doc__\n\n        return forward, reverse\n\n    def _add(a, b):\n        \"\"\"a + b\"\"\"\n        return Fraction(a.numerator * b.denominator +\n                        b.numerator * a.denominator,\n                        a.denominator * b.denominator)\n\n    __add__, __radd__ = _operator_fallbacks(_add, operator.add)\n\n    def _sub(a, b):\n        \"\"\"a - b\"\"\"\n        return Fraction(a.numerator * b.denominator -\n                        b.numerator * a.denominator,\n                        a.denominator * b.denominator)\n\n    __sub__, __rsub__ = _operator_fallbacks(_sub, operator.sub)\n\n    def _mul(a, b):\n        \"\"\"a * b\"\"\"\n        return Fraction(a.numerator * b.numerator, a.denominator * b.denominator)\n\n    __mul__, __rmul__ = _operator_fallbacks(_mul, operator.mul)\n\n    def _div(a, b):\n        \"\"\"a / b\"\"\"\n        return Fraction(a.numerator * b.denominator,\n                        a.denominator * b.numerator)\n\n    __truediv__, __rtruediv__ = _operator_fallbacks(_div, operator.truediv)\n\n    def __floordiv__(a, b):\n        \"\"\"a // b\"\"\"\n        return math.floor(a / b)\n\n    def __rfloordiv__(b, a):\n        \"\"\"a // b\"\"\"\n        return math.floor(a / b)\n\n    def __mod__(a, b):\n        \"\"\"a % b\"\"\"\n        div = a // b\n        return a - b * div\n\n    def __rmod__(b, a):\n        \"\"\"a % b\"\"\"\n        div = a // b\n        return a - b * div\n\n    def __pow__(a, b):\n        \"\"\"a ** b\n\n        If b is not an integer, the result will be a float or complex\n        since roots are generally irrational. If b is an integer, the\n        result will be rational.\n\n        \"\"\"\n        if isinstance(b, numbers.Rational):\n            if b.denominator == 1:\n                power = b.numerator\n                if power >= 0:\n                    return Fraction(a._numerator ** power,\n                                    a._denominator ** power)\n                else:\n                    return Fraction(a._denominator ** -power,\n                                    a._numerator ** -power)\n            else:\n                # A fractional power will generally produce an\n                # irrational number.\n                return float(a) ** float(b)\n        else:\n            return float(a) ** b\n\n    def __rpow__(b, a):\n        \"\"\"a ** b\"\"\"\n        if b._denominator == 1 and b._numerator >= 0:\n            # If a is an int, keep it that way if possible.\n            return a ** b._numerator\n\n        if isinstance(a, numbers.Rational):\n            return Fraction(a.numerator, a.denominator) ** b\n\n        if b._denominator == 1:\n            return a ** b._numerator\n\n        return a ** float(b)\n\n    def __pos__(a):\n        \"\"\"+a: Coerces a subclass instance to Fraction\"\"\"\n        return Fraction(a._numerator, a._denominator)\n\n    def __neg__(a):\n        \"\"\"-a\"\"\"\n        return Fraction(-a._numerator, a._denominator)\n\n    def __abs__(a):\n        \"\"\"abs(a)\"\"\"\n        return Fraction(abs(a._numerator), a._denominator)\n\n    def __trunc__(a):\n        \"\"\"trunc(a)\"\"\"\n        if a._numerator < 0:\n            return -(-a._numerator // a._denominator)\n        else:\n            return a._numerator // a._denominator\n\n    def __floor__(a):\n        \"\"\"Will be math.floor(a) in 3.0.\"\"\"\n        return a.numerator // a.denominator\n\n    def __ceil__(a):\n        \"\"\"Will be math.ceil(a) in 3.0.\"\"\"\n        # The negations cleverly convince floordiv to return the ceiling.\n        return -(-a.numerator // a.denominator)\n\n    def __round__(self, ndigits=None):\n        \"\"\"Will be round(self, ndigits) in 3.0.\n\n        Rounds half toward even.\n        \"\"\"\n        if ndigits is None:\n            floor, remainder = divmod(self.numerator, self.denominator)\n            if remainder * 2 < self.denominator:\n                return floor\n            elif remainder * 2 > self.denominator:\n                return floor + 1\n            # Deal with the half case:\n            elif floor % 2 == 0:\n                return floor\n            else:\n                return floor + 1\n        shift = 10**abs(ndigits)\n        # See _operator_fallbacks.forward to check that the results of\n        # these operations will always be Fraction and therefore have\n        # round().\n        if ndigits > 0:\n            return Fraction(round(self * shift), shift)\n        else:\n            return Fraction(round(self / shift) * shift)\n\n    def __hash__(self):\n        \"\"\"hash(self)\"\"\"\n\n        # XXX since this method is expensive, consider caching the result\n\n        # In order to make sure that the hash of a Fraction agrees\n        # with the hash of a numerically equal integer, float or\n        # Decimal instance, we follow the rules for numeric hashes\n        # outlined in the documentation.  (See library docs, 'Built-in\n        # Types').\n\n        # dinv is the inverse of self._denominator modulo the prime\n        # _PyHASH_MODULUS, or 0 if self._denominator is divisible by\n        # _PyHASH_MODULUS.\n        dinv = pow(self._denominator, _PyHASH_MODULUS - 2, _PyHASH_MODULUS)\n        if not dinv:\n            hash_ = _PyHASH_INF\n        else:\n            hash_ = abs(self._numerator) * dinv % _PyHASH_MODULUS\n        result = hash_ if self >= 0 else -hash_\n        return -2 if result == -1 else result\n\n    def __eq__(a, b):\n        \"\"\"a == b\"\"\"\n        if isinstance(b, numbers.Rational):\n            return (a._numerator == b.numerator and\n                    a._denominator == b.denominator)\n        if isinstance(b, numbers.Complex) and b.imag == 0:\n            b = b.real\n        if isinstance(b, float):\n            if math.isnan(b) or math.isinf(b):\n                # comparisons with an infinity or nan should behave in\n                # the same way for any finite a, so treat a as zero.\n                return 0.0 == b\n            else:\n                return a == a.from_float(b)\n        else:\n            # Since a doesn't know how to compare with b, let's give b\n            # a chance to compare itself with a.\n            return NotImplemented\n\n    def _richcmp(self, other, op):\n        \"\"\"Helper for comparison operators, for internal use only.\n\n        Implement comparison between a Rational instance `self`, and\n        either another Rational instance or a float `other`.  If\n        `other` is not a Rational instance or a float, return\n        NotImplemented. `op` should be one of the six standard\n        comparison operators.\n\n        \"\"\"\n        # convert other to a Rational instance where reasonable.\n        if isinstance(other, numbers.Rational):\n            return op(self._numerator * other.denominator,\n                      self._denominator * other.numerator)\n        if isinstance(other, float):\n            if math.isnan(other) or math.isinf(other):\n                return op(0.0, other)\n            else:\n                return op(self, self.from_float(other))\n        else:\n            return NotImplemented\n\n    def __lt__(a, b):\n        \"\"\"a < b\"\"\"\n        return a._richcmp(b, operator.lt)\n\n    def __gt__(a, b):\n        \"\"\"a > b\"\"\"\n        return a._richcmp(b, operator.gt)\n\n    def __le__(a, b):\n        \"\"\"a <= b\"\"\"\n        return a._richcmp(b, operator.le)\n\n    def __ge__(a, b):\n        \"\"\"a >= b\"\"\"\n        return a._richcmp(b, operator.ge)\n\n    def __bool__(a):\n        \"\"\"a != 0\"\"\"\n        return a._numerator != 0\n\n    # support for pickling, copy, and deepcopy\n\n    def __reduce__(self):\n        return (self.__class__, (str(self),))\n\n    def __copy__(self):\n        if type(self) == Fraction:\n            return self     # I'm immutable; therefore I am my own clone\n        return self.__class__(self._numerator, self._denominator)\n\n    def __deepcopy__(self, memo):\n        if type(self) == Fraction:\n            return self     # My components are also immutable\n        return self.__class__(self._numerator, self._denominator)\n"], "xml.dom.NodeFilter": [".py", "# This is the Python mapping for interface NodeFilter from\n# DOM2-Traversal-Range. It contains only constants.\n\nclass NodeFilter:\n    \"\"\"\n    This is the DOM2 NodeFilter interface. It contains only constants.\n    \"\"\"\n    FILTER_ACCEPT = 1\n    FILTER_REJECT = 2\n    FILTER_SKIP   = 3\n\n    SHOW_ALL                    = 0xFFFFFFFF\n    SHOW_ELEMENT                = 0x00000001\n    SHOW_ATTRIBUTE              = 0x00000002\n    SHOW_TEXT                   = 0x00000004\n    SHOW_CDATA_SECTION          = 0x00000008\n    SHOW_ENTITY_REFERENCE       = 0x00000010\n    SHOW_ENTITY                 = 0x00000020\n    SHOW_PROCESSING_INSTRUCTION = 0x00000040\n    SHOW_COMMENT                = 0x00000080\n    SHOW_DOCUMENT               = 0x00000100\n    SHOW_DOCUMENT_TYPE          = 0x00000200\n    SHOW_DOCUMENT_FRAGMENT      = 0x00000400\n    SHOW_NOTATION               = 0x00000800\n\n    def acceptNode(self, node):\n        raise NotImplementedError\n"], "__random": [".js", "$module = (function($B){\n\n    var _b_ = $B.builtins\n    var $s=[]\n    for(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\n    eval($s.join(';'))\n\n    //for(var $py_builtin in _b_){eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")}\n    \n    return {\n        choice:function(seq){\n            var rank = parseInt(getattr(seq,'__len__')()*Math.random())\n            return getattr(seq,'__getitem__')(rank)\n        },\n        random:function(){\n          if(arguments.length > 0){\n            throw TypeError(\"random() takes no arguments (\"+arguments.length+\" given)\")\n          } else {\n            return float(Math.random());\n          }\n        },\n        randint:function(a,b){\n           if (a == undefined) throw _b_.TypeError(\"randint missing 2 required positional arguments: 'a' and 'b'\");\n           if (b == undefined) throw _b_.TypeError(\"randint missing 1 required positional argument: 'b'\");\n\n           if (!(isinstance(a, _b_.int) || isinstance(b, _b_.int))) throw _b_.ValueError(\"non-integer arg 1 for randrange\")\n\n           return int(Math.floor(Math.random()*(b-a+1)+a))\n        },\n        randrange:function(start,stop,step){\n          if(step === undefined) {\n            step=1;\n          } else if(step == 0) { \n            //raise ValueError(\"zero step for randrange()\");\n          }\n    \n          if(stop === undefined) {\n             stop=start;\n             start=0;\n          }\n          var width=stop-start;\n          if (step==1 && width > 0) {\n            return start + int(Math.floor(Math.random()*width));\n          } else {\n            // raise ValueError(\"empty range for randrange() (\"+start+\",\"+stop+','+step+')');\n          }\n          \n          var n;\n          if (step > 0) {\n             n=Math.floor((width+step-1)/step);\n          } else {\n             n=Math.floor((width+step+1)/step);\n          }\n          return start + step*int(Math.floor(Math.random()*n))\n          //return int(Math.random()*(stop/step-start/step)*step + start)\n        },\n        shuffle:function(x, rnd){\n          if (x.length <= 1) { return x}\n    \n          if (rnd === undefined) {\n             rnd=Math.random\n          }\n    \n          for(var j, o, i = x.length; i; j = parseInt(rnd() * i), o = x[--i], x[i] = x[j], x[j] = o);\n        }\n    }\n\n})(__BRYTHON__)\n"], "xml.etree.ElementInclude": [".py", "#\n# ElementTree\n# $Id: ElementInclude.py 3375 2008-02-13 08:05:08Z fredrik $\n#\n# limited xinclude support for element trees\n#\n# history:\n# 2003-08-15 fl   created\n# 2003-11-14 fl   fixed default loader\n#\n# Copyright (c) 2003-2004 by Fredrik Lundh.  All rights reserved.\n#\n# fredrik@pythonware.com\n# http://www.pythonware.com\n#\n# --------------------------------------------------------------------\n# The ElementTree toolkit is\n#\n# Copyright (c) 1999-2008 by Fredrik Lundh\n#\n# By obtaining, using, and/or copying this software and/or its\n# associated documentation, you agree that you have read, understood,\n# and will comply with the following terms and conditions:\n#\n# Permission to use, copy, modify, and distribute this software and\n# its associated documentation for any purpose and without fee is\n# hereby granted, provided that the above copyright notice appears in\n# all copies, and that both that copyright notice and this permission\n# notice appear in supporting documentation, and that the name of\n# Secret Labs AB or the author not be used in advertising or publicity\n# pertaining to distribution of the software without specific, written\n# prior permission.\n#\n# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD\n# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-\n# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR\n# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY\n# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,\n# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE\n# OF THIS SOFTWARE.\n# --------------------------------------------------------------------\n\n# Licensed to PSF under a Contributor Agreement.\n# See http://www.python.org/psf/license for licensing details.\n\n##\n# Limited XInclude support for the ElementTree package.\n##\n\nimport copy\nfrom . import ElementTree\n\nXINCLUDE = \"{http://www.w3.org/2001/XInclude}\"\n\nXINCLUDE_INCLUDE = XINCLUDE + \"include\"\nXINCLUDE_FALLBACK = XINCLUDE + \"fallback\"\n\n##\n# Fatal include error.\n\nclass FatalIncludeError(SyntaxError):\n    pass\n\n##\n# Default loader.  This loader reads an included resource from disk.\n#\n# @param href Resource reference.\n# @param parse Parse mode.  Either \"xml\" or \"text\".\n# @param encoding Optional text encoding (UTF-8 by default for \"text\").\n# @return The expanded resource.  If the parse mode is \"xml\", this\n#    is an ElementTree instance.  If the parse mode is \"text\", this\n#    is a Unicode string.  If the loader fails, it can return None\n#    or raise an IOError exception.\n# @throws IOError If the loader fails to load the resource.\n\ndef default_loader(href, parse, encoding=None):\n    if parse == \"xml\":\n        file = open(href, 'rb')\n        data = ElementTree.parse(file).getroot()\n    else:\n        if not encoding:\n            encoding = 'UTF-8'\n        file = open(href, 'r', encoding=encoding)\n        data = file.read()\n    file.close()\n    return data\n\n##\n# Expand XInclude directives.\n#\n# @param elem Root element.\n# @param loader Optional resource loader.  If omitted, it defaults\n#     to {@link default_loader}.  If given, it should be a callable\n#     that implements the same interface as <b>default_loader</b>.\n# @throws FatalIncludeError If the function fails to include a given\n#     resource, or if the tree contains malformed XInclude elements.\n# @throws IOError If the function fails to load a given resource.\n\ndef include(elem, loader=None):\n    if loader is None:\n        loader = default_loader\n    # look for xinclude elements\n    i = 0\n    while i < len(elem):\n        e = elem[i]\n        if e.tag == XINCLUDE_INCLUDE:\n            # process xinclude directive\n            href = e.get(\"href\")\n            parse = e.get(\"parse\", \"xml\")\n            if parse == \"xml\":\n                node = loader(href, parse)\n                if node is None:\n                    raise FatalIncludeError(\n                        \"cannot load %r as %r\" % (href, parse)\n                        )\n                node = copy.copy(node)\n                if e.tail:\n                    node.tail = (node.tail or \"\") + e.tail\n                elem[i] = node\n            elif parse == \"text\":\n                text = loader(href, parse, e.get(\"encoding\"))\n                if text is None:\n                    raise FatalIncludeError(\n                        \"cannot load %r as %r\" % (href, parse)\n                        )\n                if i:\n                    node = elem[i-1]\n                    node.tail = (node.tail or \"\") + text + (e.tail or \"\")\n                else:\n                    elem.text = (elem.text or \"\") + text + (e.tail or \"\")\n                del elem[i]\n                continue\n            else:\n                raise FatalIncludeError(\n                    \"unknown parse type in xi:include tag (%r)\" % parse\n                )\n        elif e.tag == XINCLUDE_FALLBACK:\n            raise FatalIncludeError(\n                \"xi:fallback tag must be child of xi:include (%r)\" % e.tag\n                )\n        else:\n            include(e, loader)\n        i = i + 1\n"], "site-packages.test_sp": [".py", "test = \"site package\"\n"], "_codecs": [".py", "\ndef ascii_decode(*args,**kw):\n    pass\n\ndef ascii_encode(*args,**kw):\n    pass\n\ndef charbuffer_encode(*args,**kw):\n    pass\n\ndef charmap_build(*args,**kw):\n    pass\n\ndef charmap_decode(*args,**kw):\n    pass\n\ndef charmap_encode(*args,**kw):\n    pass\n\ndef decode(*args,**kw):\n    \"\"\"decode(obj, [encoding[,errors]]) -> object    \n    Decodes obj using the codec registered for encoding. encoding defaults\n    to the default encoding. errors may be given to set a different error\n    handling scheme. Default is 'strict' meaning that encoding errors raise\n    a ValueError. Other possible values are 'ignore' and 'replace'\n    as well as any other name registered with codecs.register_error that is\n    able to handle ValueErrors.\"\"\"\n    pass\n\ndef encode(*args,**kw):\n    \"\"\"encode(obj, [encoding[,errors]]) -> object    \n    Encodes obj using the codec registered for encoding. encoding defaults\n    to the default encoding. errors may be given to set a different error\n    handling scheme. Default is 'strict' meaning that encoding errors raise\n    a ValueError. Other possible values are 'ignore', 'replace' and\n    'xmlcharrefreplace' as well as any other name registered with\n    codecs.register_error that can handle ValueErrors.\"\"\"\n    pass\n\ndef escape_decode(*args,**kw):\n    pass\n\ndef escape_encode(*args,**kw):\n    pass\n\ndef latin_1_decode(*args,**kw):\n    pass\n\ndef latin_1_encode(*args,**kw):\n    pass\n\ndef lookup(encoding):\n    \"\"\"lookup(encoding) -> CodecInfo    \n    Looks up a codec tuple in the Python codec registry and returns\n    a CodecInfo object.\"\"\"\n\n    if encoding in ('utf-8', 'utf_8'):\n       from javascript import console\n       console.log('encoding', encoding)\n       import encodings.utf_8\n       return encodings.utf_8.getregentry()\n\n    LookupError(encoding)\n\ndef lookup_error(*args,**kw):\n    \"\"\"lookup_error(errors) -> handler    \n    Return the error handler for the specified error handling name\n    or raise a LookupError, if no handler exists under this name.\"\"\"\n    pass\n\ndef mbcs_decode(*args,**kw):\n    pass\n\ndef mbcs_encode(*args,**kw):\n    pass\n\ndef raw_unicode_escape_decode(*args,**kw):\n    pass\n\ndef raw_unicode_escape_encode(*args,**kw):\n    pass\n\ndef readbuffer_encode(*args,**kw):\n    pass\n\ndef register(*args,**kw):\n    \"\"\"register(search_function)    \n    Register a codec search function. Search functions are expected to take\n    one argument, the encoding name in all lower case letters, and return\n    a tuple of functions (encoder, decoder, stream_reader, stream_writer)\n    (or a CodecInfo object).\"\"\"\n    pass\n\ndef register_error(*args,**kw):\n    \"\"\"register_error(errors, handler)    \n    Register the specified error handler under the name\n    errors. handler must be a callable object, that\n    will be called with an exception instance containing\n    information about the location of the encoding/decoding\n    error and must return a (replacement, new position) tuple.\"\"\"\n    pass\n\ndef unicode_escape_decode(*args,**kw):\n    pass\n\ndef unicode_escape_encode(*args,**kw):\n    pass\n\ndef unicode_internal_decode(*args,**kw):\n    pass\n\ndef unicode_internal_encode(*args,**kw):\n    pass\n\ndef utf_16_be_decode(*args,**kw):\n    pass\n\ndef utf_16_be_encode(*args,**kw):\n    pass\n\ndef utf_16_decode(*args,**kw):\n    pass\n\ndef utf_16_encode(*args,**kw):\n    pass\n\ndef utf_16_ex_decode(*args,**kw):\n    pass\n\ndef utf_16_le_decode(*args,**kw):\n    pass\n\ndef utf_16_le_encode(*args,**kw):\n    pass\n\ndef utf_32_be_decode(*args,**kw):\n    pass\n\ndef utf_32_be_encode(*args,**kw):\n    pass\n\ndef utf_32_decode(*args,**kw):\n    pass\n\ndef utf_32_encode(*args,**kw):\n    pass\n\ndef utf_32_ex_decode(*args,**kw):\n    pass\n\ndef utf_32_le_decode(*args,**kw):\n    pass\n\ndef utf_32_le_encode(*args,**kw):\n    pass\n\ndef utf_7_decode(*args,**kw):\n    pass\n\ndef utf_7_encode(*args,**kw):\n    pass\n\ndef utf_8_decode(*args,**kw):\n    pass\n\ndef utf_8_encode(*args,**kw):\n    input=args[0]\n    if len(args) == 2:\n       errors = args[1]\n    else:\n       errors=kw.get('errors', 'strict')\n\n    #todo need to deal with errors, but for now assume all is well.\n\n    return (bytes([_f for _f in input], 'utf-8'), len(input))\n"], "xml.etree.ElementTree": [".py", "#\n# ElementTree\n# $Id: ElementTree.py 3440 2008-07-18 14:45:01Z fredrik $\n#\n# light-weight XML support for Python 2.3 and later.\n#\n# history (since 1.2.6):\n# 2005-11-12 fl   added tostringlist/fromstringlist helpers\n# 2006-07-05 fl   merged in selected changes from the 1.3 sandbox\n# 2006-07-05 fl   removed support for 2.1 and earlier\n# 2007-06-21 fl   added deprecation/future warnings\n# 2007-08-25 fl   added doctype hook, added parser version attribute etc\n# 2007-08-26 fl   added new serializer code (better namespace handling, etc)\n# 2007-08-27 fl   warn for broken /tag searches on tree level\n# 2007-09-02 fl   added html/text methods to serializer (experimental)\n# 2007-09-05 fl   added method argument to tostring/tostringlist\n# 2007-09-06 fl   improved error handling\n# 2007-09-13 fl   added itertext, iterfind; assorted cleanups\n# 2007-12-15 fl   added C14N hooks, copy method (experimental)\n#\n# Copyright (c) 1999-2008 by Fredrik Lundh.  All rights reserved.\n#\n# fredrik@pythonware.com\n# http://www.pythonware.com\n#\n# --------------------------------------------------------------------\n# The ElementTree toolkit is\n#\n# Copyright (c) 1999-2008 by Fredrik Lundh\n#\n# By obtaining, using, and/or copying this software and/or its\n# associated documentation, you agree that you have read, understood,\n# and will comply with the following terms and conditions:\n#\n# Permission to use, copy, modify, and distribute this software and\n# its associated documentation for any purpose and without fee is\n# hereby granted, provided that the above copyright notice appears in\n# all copies, and that both that copyright notice and this permission\n# notice appear in supporting documentation, and that the name of\n# Secret Labs AB or the author not be used in advertising or publicity\n# pertaining to distribution of the software without specific, written\n# prior permission.\n#\n# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD\n# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-\n# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR\n# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY\n# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,\n# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE\n# OF THIS SOFTWARE.\n# --------------------------------------------------------------------\n\n# Licensed to PSF under a Contributor Agreement.\n# See http://www.python.org/psf/license for licensing details.\n\n__all__ = [\n    # public symbols\n    \"Comment\",\n    \"dump\",\n    \"Element\", \"ElementTree\",\n    \"fromstring\", \"fromstringlist\",\n    \"iselement\", \"iterparse\",\n    \"parse\", \"ParseError\",\n    \"PI\", \"ProcessingInstruction\",\n    \"QName\",\n    \"SubElement\",\n    \"tostring\", \"tostringlist\",\n    \"TreeBuilder\",\n    \"VERSION\",\n    \"XML\", \"XMLID\",\n    \"XMLParser\", \"XMLTreeBuilder\",\n    \"register_namespace\",\n    ]\n\nVERSION = \"1.3.0\"\n\n##\n# The <b>Element</b> type is a flexible container object, designed to\n# store hierarchical data structures in memory. The type can be\n# described as a cross between a list and a dictionary.\n# <p>\n# Each element has a number of properties associated with it:\n# <ul>\n# <li>a <i>tag</i>. This is a string identifying what kind of data\n# this element represents (the element type, in other words).</li>\n# <li>a number of <i>attributes</i>, stored in a Python dictionary.</li>\n# <li>a <i>text</i> string.</li>\n# <li>an optional <i>tail</i> string.</li>\n# <li>a number of <i>child elements</i>, stored in a Python sequence</li>\n# </ul>\n#\n# To create an element instance, use the {@link #Element} constructor\n# or the {@link #SubElement} factory function.\n# <p>\n# The {@link #ElementTree} class can be used to wrap an element\n# structure, and convert it from and to XML.\n##\n\nimport sys\nimport re\nimport warnings\nimport io\nimport contextlib\n\nfrom . import ElementPath\n\n\n##\n# Parser error.  This is a subclass of <b>SyntaxError</b>.\n# <p>\n# In addition to the exception value, an exception instance contains a\n# specific exception code in the <b>code</b> attribute, and the line and\n# column of the error in the <b>position</b> attribute.\n\nclass ParseError(SyntaxError):\n    pass\n\n# --------------------------------------------------------------------\n\n##\n# Checks if an object appears to be a valid element object.\n#\n# @param An element instance.\n# @return A true value if this is an element object.\n# @defreturn flag\n\ndef iselement(element):\n    # FIXME: not sure about this;\n    # isinstance(element, Element) or look for tag/attrib/text attributes\n    return hasattr(element, 'tag')\n\n##\n# Element class.  This class defines the Element interface, and\n# provides a reference implementation of this interface.\n# <p>\n# The element name, attribute names, and attribute values can be\n# either ASCII strings (ordinary Python strings containing only 7-bit\n# ASCII characters) or Unicode strings.\n#\n# @param tag The element name.\n# @param attrib An optional dictionary, containing element attributes.\n# @param **extra Additional attributes, given as keyword arguments.\n# @see Element\n# @see SubElement\n# @see Comment\n# @see ProcessingInstruction\n\nclass Element:\n    # <tag attrib>text<child/>...</tag>tail\n\n    ##\n    # (Attribute) Element tag.\n\n    tag = None\n\n    ##\n    # (Attribute) Element attribute dictionary.  Where possible, use\n    # {@link #Element.get},\n    # {@link #Element.set},\n    # {@link #Element.keys}, and\n    # {@link #Element.items} to access\n    # element attributes.\n\n    attrib = None\n\n    ##\n    # (Attribute) Text before first subelement.  This is either a\n    # string or the value None.  Note that if there was no text, this\n    # attribute may be either None or an empty string, depending on\n    # the parser.\n\n    text = None\n\n    ##\n    # (Attribute) Text after this element's end tag, but before the\n    # next sibling element's start tag.  This is either a string or\n    # the value None.  Note that if there was no text, this attribute\n    # may be either None or an empty string, depending on the parser.\n\n    tail = None # text after end tag, if any\n\n    # constructor\n\n    def __init__(self, tag, attrib={}, **extra):\n        if not isinstance(attrib, dict):\n            raise TypeError(\"attrib must be dict, not %s\" % (\n                attrib.__class__.__name__,))\n        attrib = attrib.copy()\n        attrib.update(extra)\n        self.tag = tag\n        self.attrib = attrib\n        self._children = []\n\n    def __repr__(self):\n        return \"<Element %s at 0x%x>\" % (repr(self.tag), id(self))\n\n    ##\n    # Creates a new element object of the same type as this element.\n    #\n    # @param tag Element tag.\n    # @param attrib Element attributes, given as a dictionary.\n    # @return A new element instance.\n\n    def makeelement(self, tag, attrib):\n        return self.__class__(tag, attrib)\n\n    ##\n    # (Experimental) Copies the current element.  This creates a\n    # shallow copy; subelements will be shared with the original tree.\n    #\n    # @return A new element instance.\n\n    def copy(self):\n        elem = self.makeelement(self.tag, self.attrib)\n        elem.text = self.text\n        elem.tail = self.tail\n        elem[:] = self\n        return elem\n\n    ##\n    # Returns the number of subelements.  Note that this only counts\n    # full elements; to check if there's any content in an element, you\n    # have to check both the length and the <b>text</b> attribute.\n    #\n    # @return The number of subelements.\n\n    def __len__(self):\n        return len(self._children)\n\n    def __bool__(self):\n        warnings.warn(\n            \"The behavior of this method will change in future versions.  \"\n            \"Use specific 'len(elem)' or 'elem is not None' test instead.\",\n            FutureWarning, stacklevel=2\n            )\n        return len(self._children) != 0 # emulate old behaviour, for now\n\n    ##\n    # Returns the given subelement, by index.\n    #\n    # @param index What subelement to return.\n    # @return The given subelement.\n    # @exception IndexError If the given element does not exist.\n\n    def __getitem__(self, index):\n        return self._children[index]\n\n    ##\n    # Replaces the given subelement, by index.\n    #\n    # @param index What subelement to replace.\n    # @param element The new element value.\n    # @exception IndexError If the given element does not exist.\n\n    def __setitem__(self, index, element):\n        # if isinstance(index, slice):\n        #     for elt in element:\n        #         assert iselement(elt)\n        # else:\n        #     assert iselement(element)\n        self._children[index] = element\n\n    ##\n    # Deletes the given subelement, by index.\n    #\n    # @param index What subelement to delete.\n    # @exception IndexError If the given element does not exist.\n\n    def __delitem__(self, index):\n        del self._children[index]\n\n    ##\n    # Adds a subelement to the end of this element.  In document order,\n    # the new element will appear after the last existing subelement (or\n    # directly after the text, if it's the first subelement), but before\n    # the end tag for this element.\n    #\n    # @param element The element to add.\n\n    def append(self, element):\n        self._assert_is_element(element)\n        self._children.append(element)\n\n    ##\n    # Appends subelements from a sequence.\n    #\n    # @param elements A sequence object with zero or more elements.\n    # @since 1.3\n\n    def extend(self, elements):\n        for element in elements:\n            self._assert_is_element(element)\n        self._children.extend(elements)\n\n    ##\n    # Inserts a subelement at the given position in this element.\n    #\n    # @param index Where to insert the new subelement.\n\n    def insert(self, index, element):\n        self._assert_is_element(element)\n        self._children.insert(index, element)\n\n    def _assert_is_element(self, e):\n        # Need to refer to the actual Python implementation, not the\n        # shadowing C implementation.\n        if not isinstance(e, _Element):\n            raise TypeError('expected an Element, not %s' % type(e).__name__)\n\n    ##\n    # Removes a matching subelement.  Unlike the <b>find</b> methods,\n    # this method compares elements based on identity, not on tag\n    # value or contents.  To remove subelements by other means, the\n    # easiest way is often to use a list comprehension to select what\n    # elements to keep, and use slice assignment to update the parent\n    # element.\n    #\n    # @param element What element to remove.\n    # @exception ValueError If a matching element could not be found.\n\n    def remove(self, element):\n        # assert iselement(element)\n        self._children.remove(element)\n\n    ##\n    # (Deprecated) Returns all subelements.  The elements are returned\n    # in document order.\n    #\n    # @return A list of subelements.\n    # @defreturn list of Element instances\n\n    def getchildren(self):\n        warnings.warn(\n            \"This method will be removed in future versions.  \"\n            \"Use 'list(elem)' or iteration over elem instead.\",\n            DeprecationWarning, stacklevel=2\n            )\n        return self._children\n\n    ##\n    # Finds the first matching subelement, by tag name or path.\n    #\n    # @param path What element to look for.\n    # @keyparam namespaces Optional namespace prefix map.\n    # @return The first matching element, or None if no element was found.\n    # @defreturn Element or None\n\n    def find(self, path, namespaces=None):\n        return ElementPath.find(self, path, namespaces)\n\n    ##\n    # Finds text for the first matching subelement, by tag name or path.\n    #\n    # @param path What element to look for.\n    # @param default What to return if the element was not found.\n    # @keyparam namespaces Optional namespace prefix map.\n    # @return The text content of the first matching element, or the\n    #     default value no element was found.  Note that if the element\n    #     is found, but has no text content, this method returns an\n    #     empty string.\n    # @defreturn string\n\n    def findtext(self, path, default=None, namespaces=None):\n        return ElementPath.findtext(self, path, default, namespaces)\n\n    ##\n    # Finds all matching subelements, by tag name or path.\n    #\n    # @param path What element to look for.\n    # @keyparam namespaces Optional namespace prefix map.\n    # @return A list or other sequence containing all matching elements,\n    #    in document order.\n    # @defreturn list of Element instances\n\n    def findall(self, path, namespaces=None):\n        return ElementPath.findall(self, path, namespaces)\n\n    ##\n    # Finds all matching subelements, by tag name or path.\n    #\n    # @param path What element to look for.\n    # @keyparam namespaces Optional namespace prefix map.\n    # @return An iterator or sequence containing all matching elements,\n    #    in document order.\n    # @defreturn a generated sequence of Element instances\n\n    def iterfind(self, path, namespaces=None):\n        return ElementPath.iterfind(self, path, namespaces)\n\n    ##\n    # Resets an element.  This function removes all subelements, clears\n    # all attributes, and sets the <b>text</b> and <b>tail</b> attributes\n    # to None.\n\n    def clear(self):\n        self.attrib.clear()\n        self._children = []\n        self.text = self.tail = None\n\n    ##\n    # Gets an element attribute.  Equivalent to <b>attrib.get</b>, but\n    # some implementations may handle this a bit more efficiently.\n    #\n    # @param key What attribute to look for.\n    # @param default What to return if the attribute was not found.\n    # @return The attribute value, or the default value, if the\n    #     attribute was not found.\n    # @defreturn string or None\n\n    def get(self, key, default=None):\n        return self.attrib.get(key, default)\n\n    ##\n    # Sets an element attribute.  Equivalent to <b>attrib[key] = value</b>,\n    # but some implementations may handle this a bit more efficiently.\n    #\n    # @param key What attribute to set.\n    # @param value The attribute value.\n\n    def set(self, key, value):\n        self.attrib[key] = value\n\n    ##\n    # Gets a list of attribute names.  The names are returned in an\n    # arbitrary order (just like for an ordinary Python dictionary).\n    # Equivalent to <b>attrib.keys()</b>.\n    #\n    # @return A list of element attribute names.\n    # @defreturn list of strings\n\n    def keys(self):\n        return self.attrib.keys()\n\n    ##\n    # Gets element attributes, as a sequence.  The attributes are\n    # returned in an arbitrary order.  Equivalent to <b>attrib.items()</b>.\n    #\n    # @return A list of (name, value) tuples for all attributes.\n    # @defreturn list of (string, string) tuples\n\n    def items(self):\n        return self.attrib.items()\n\n    ##\n    # Creates a tree iterator.  The iterator loops over this element\n    # and all subelements, in document order, and returns all elements\n    # with a matching tag.\n    # <p>\n    # If the tree structure is modified during iteration, new or removed\n    # elements may or may not be included.  To get a stable set, use the\n    # list() function on the iterator, and loop over the resulting list.\n    #\n    # @param tag What tags to look for (default is to return all elements).\n    # @return An iterator containing all the matching elements.\n    # @defreturn iterator\n\n    def iter(self, tag=None):\n        if tag == \"*\":\n            tag = None\n        if tag is None or self.tag == tag:\n            yield self\n        for e in self._children:\n            for e in e.iter(tag):\n                yield e\n\n    # compatibility\n    def getiterator(self, tag=None):\n        # Change for a DeprecationWarning in 1.4\n        warnings.warn(\n            \"This method will be removed in future versions.  \"\n            \"Use 'elem.iter()' or 'list(elem.iter())' instead.\",\n            PendingDeprecationWarning, stacklevel=2\n        )\n        return list(self.iter(tag))\n\n    ##\n    # Creates a text iterator.  The iterator loops over this element\n    # and all subelements, in document order, and returns all inner\n    # text.\n    #\n    # @return An iterator containing all inner text.\n    # @defreturn iterator\n\n    def itertext(self):\n        tag = self.tag\n        if not isinstance(tag, str) and tag is not None:\n            return\n        if self.text:\n            yield self.text\n        for e in self:\n            for s in e.itertext():\n                yield s\n            if e.tail:\n                yield e.tail\n\n# compatibility\n_Element = _ElementInterface = Element\n\n##\n# Subelement factory.  This function creates an element instance, and\n# appends it to an existing element.\n# <p>\n# The element name, attribute names, and attribute values can be\n# either 8-bit ASCII strings or Unicode strings.\n#\n# @param parent The parent element.\n# @param tag The subelement name.\n# @param attrib An optional dictionary, containing element attributes.\n# @param **extra Additional attributes, given as keyword arguments.\n# @return An element instance.\n# @defreturn Element\n\ndef SubElement(parent, tag, attrib={}, **extra):\n    attrib = attrib.copy()\n    attrib.update(extra)\n    element = parent.makeelement(tag, attrib)\n    parent.append(element)\n    return element\n\n##\n# Comment element factory.  This factory function creates a special\n# element that will be serialized as an XML comment by the standard\n# serializer.\n# <p>\n# The comment string can be either an 8-bit ASCII string or a Unicode\n# string.\n#\n# @param text A string containing the comment string.\n# @return An element instance, representing a comment.\n# @defreturn Element\n\ndef Comment(text=None):\n    element = Element(Comment)\n    element.text = text\n    return element\n\n##\n# PI element factory.  This factory function creates a special element\n# that will be serialized as an XML processing instruction by the standard\n# serializer.\n#\n# @param target A string containing the PI target.\n# @param text A string containing the PI contents, if any.\n# @return An element instance, representing a PI.\n# @defreturn Element\n\ndef ProcessingInstruction(target, text=None):\n    element = Element(ProcessingInstruction)\n    element.text = target\n    if text:\n        element.text = element.text + \" \" + text\n    return element\n\nPI = ProcessingInstruction\n\n##\n# QName wrapper.  This can be used to wrap a QName attribute value, in\n# order to get proper namespace handling on output.\n#\n# @param text A string containing the QName value, in the form {uri}local,\n#     or, if the tag argument is given, the URI part of a QName.\n# @param tag Optional tag.  If given, the first argument is interpreted as\n#     an URI, and this argument is interpreted as a local name.\n# @return An opaque object, representing the QName.\n\nclass QName:\n    def __init__(self, text_or_uri, tag=None):\n        if tag:\n            text_or_uri = \"{%s}%s\" % (text_or_uri, tag)\n        self.text = text_or_uri\n    def __str__(self):\n        return self.text\n    def __repr__(self):\n        return '<QName %r>' % (self.text,)\n    def __hash__(self):\n        return hash(self.text)\n    def __le__(self, other):\n        if isinstance(other, QName):\n            return self.text <= other.text\n        return self.text <= other\n    def __lt__(self, other):\n        if isinstance(other, QName):\n            return self.text < other.text\n        return self.text < other\n    def __ge__(self, other):\n        if isinstance(other, QName):\n            return self.text >= other.text\n        return self.text >= other\n    def __gt__(self, other):\n        if isinstance(other, QName):\n            return self.text > other.text\n        return self.text > other\n    def __eq__(self, other):\n        if isinstance(other, QName):\n            return self.text == other.text\n        return self.text == other\n    def __ne__(self, other):\n        if isinstance(other, QName):\n            return self.text != other.text\n        return self.text != other\n\n# --------------------------------------------------------------------\n\n##\n# ElementTree wrapper class.  This class represents an entire element\n# hierarchy, and adds some extra support for serialization to and from\n# standard XML.\n#\n# @param element Optional root element.\n# @keyparam file Optional file handle or file name.  If given, the\n#     tree is initialized with the contents of this XML file.\n\nclass ElementTree:\n\n    def __init__(self, element=None, file=None):\n        # assert element is None or iselement(element)\n        self._root = element # first node\n        if file:\n            self.parse(file)\n\n    ##\n    # Gets the root element for this tree.\n    #\n    # @return An element instance.\n    # @defreturn Element\n\n    def getroot(self):\n        return self._root\n\n    ##\n    # Replaces the root element for this tree.  This discards the\n    # current contents of the tree, and replaces it with the given\n    # element.  Use with care.\n    #\n    # @param element An element instance.\n\n    def _setroot(self, element):\n        # assert iselement(element)\n        self._root = element\n\n    ##\n    # Loads an external XML document into this element tree.\n    #\n    # @param source A file name or file object.  If a file object is\n    #     given, it only has to implement a <b>read(n)</b> method.\n    # @keyparam parser An optional parser instance.  If not given, the\n    #     standard {@link XMLParser} parser is used.\n    # @return The document root element.\n    # @defreturn Element\n    # @exception ParseError If the parser fails to parse the document.\n\n    def parse(self, source, parser=None):\n        close_source = False\n        if not hasattr(source, \"read\"):\n            source = open(source, \"rb\")\n            close_source = True\n        try:\n            if not parser:\n                parser = XMLParser(target=TreeBuilder())\n            while 1:\n                data = source.read(65536)\n                if not data:\n                    break\n                parser.feed(data)\n            self._root = parser.close()\n            return self._root\n        finally:\n            if close_source:\n                source.close()\n\n    ##\n    # Creates a tree iterator for the root element.  The iterator loops\n    # over all elements in this tree, in document order.\n    #\n    # @param tag What tags to look for (default is to return all elements)\n    # @return An iterator.\n    # @defreturn iterator\n\n    def iter(self, tag=None):\n        # assert self._root is not None\n        return self._root.iter(tag)\n\n    # compatibility\n    def getiterator(self, tag=None):\n        # Change for a DeprecationWarning in 1.4\n        warnings.warn(\n            \"This method will be removed in future versions.  \"\n            \"Use 'tree.iter()' or 'list(tree.iter())' instead.\",\n            PendingDeprecationWarning, stacklevel=2\n        )\n        return list(self.iter(tag))\n\n    ##\n    # Same as getroot().find(path), starting at the root of the tree.\n    #\n    # @param path What element to look for.\n    # @keyparam namespaces Optional namespace prefix map.\n    # @return The first matching element, or None if no element was found.\n    # @defreturn Element or None\n\n    def find(self, path, namespaces=None):\n        # assert self._root is not None\n        if path[:1] == \"/\":\n            path = \".\" + path\n            warnings.warn(\n                \"This search is broken in 1.3 and earlier, and will be \"\n                \"fixed in a future version.  If you rely on the current \"\n                \"behaviour, change it to %r\" % path,\n                FutureWarning, stacklevel=2\n                )\n        return self._root.find(path, namespaces)\n\n    ##\n    # Same as getroot().findtext(path), starting at the root of the tree.\n    #\n    # @param path What element to look for.\n    # @param default What to return if the element was not found.\n    # @keyparam namespaces Optional namespace prefix map.\n    # @return The text content of the first matching element, or the\n    #     default value no element was found.  Note that if the element\n    #     is found, but has no text content, this method returns an\n    #     empty string.\n    # @defreturn string\n\n    def findtext(self, path, default=None, namespaces=None):\n        # assert self._root is not None\n        if path[:1] == \"/\":\n            path = \".\" + path\n            warnings.warn(\n                \"This search is broken in 1.3 and earlier, and will be \"\n                \"fixed in a future version.  If you rely on the current \"\n                \"behaviour, change it to %r\" % path,\n                FutureWarning, stacklevel=2\n                )\n        return self._root.findtext(path, default, namespaces)\n\n    ##\n    # Same as getroot().findall(path), starting at the root of the tree.\n    #\n    # @param path What element to look for.\n    # @keyparam namespaces Optional namespace prefix map.\n    # @return A list or iterator containing all matching elements,\n    #    in document order.\n    # @defreturn list of Element instances\n\n    def findall(self, path, namespaces=None):\n        # assert self._root is not None\n        if path[:1] == \"/\":\n            path = \".\" + path\n            warnings.warn(\n                \"This search is broken in 1.3 and earlier, and will be \"\n                \"fixed in a future version.  If you rely on the current \"\n                \"behaviour, change it to %r\" % path,\n                FutureWarning, stacklevel=2\n                )\n        return self._root.findall(path, namespaces)\n\n    ##\n    # Finds all matching subelements, by tag name or path.\n    # Same as getroot().iterfind(path).\n    #\n    # @param path What element to look for.\n    # @keyparam namespaces Optional namespace prefix map.\n    # @return An iterator or sequence containing all matching elements,\n    #    in document order.\n    # @defreturn a generated sequence of Element instances\n\n    def iterfind(self, path, namespaces=None):\n        # assert self._root is not None\n        if path[:1] == \"/\":\n            path = \".\" + path\n            warnings.warn(\n                \"This search is broken in 1.3 and earlier, and will be \"\n                \"fixed in a future version.  If you rely on the current \"\n                \"behaviour, change it to %r\" % path,\n                FutureWarning, stacklevel=2\n                )\n        return self._root.iterfind(path, namespaces)\n\n    ##\n    # Writes the element tree to a file, as XML.\n    #\n    # @def write(file, **options)\n    # @param file A file name, or a file object opened for writing.\n    # @param **options Options, given as keyword arguments.\n    # @keyparam encoding Optional output encoding (default is US-ASCII).\n    #     Use \"unicode\" to return a Unicode string.\n    # @keyparam xml_declaration Controls if an XML declaration should\n    #     be added to the file.  Use False for never, True for always,\n    #     None for only if not US-ASCII or UTF-8 or Unicode.  None is default.\n    # @keyparam default_namespace Sets the default XML namespace (for \"xmlns\").\n    # @keyparam method Optional output method (\"xml\", \"html\", \"text\" or\n    #     \"c14n\"; default is \"xml\").\n\n    def write(self, file_or_filename,\n              encoding=None,\n              xml_declaration=None,\n              default_namespace=None,\n              method=None):\n        if not method:\n            method = \"xml\"\n        elif method not in _serialize:\n            raise ValueError(\"unknown method %r\" % method)\n        if not encoding:\n            if method == \"c14n\":\n                encoding = \"utf-8\"\n            else:\n                encoding = \"us-ascii\"\n        else:\n            encoding = encoding.lower()\n        with _get_writer(file_or_filename, encoding) as write:\n            if method == \"xml\" and (xml_declaration or\n                    (xml_declaration is None and\n                     encoding not in (\"utf-8\", \"us-ascii\", \"unicode\"))):\n                declared_encoding = encoding\n                if encoding == \"unicode\":\n                    # Retrieve the default encoding for the xml declaration\n                    import locale\n                    declared_encoding = locale.getpreferredencoding()\n                write(\"<?xml version='1.0' encoding='%s'?>\\n\" % (\n                    declared_encoding,))\n            if method == \"text\":\n                _serialize_text(write, self._root)\n            else:\n                qnames, namespaces = _namespaces(self._root, default_namespace)\n                serialize = _serialize[method]\n                serialize(write, self._root, qnames, namespaces)\n\n    def write_c14n(self, file):\n        # lxml.etree compatibility.  use output method instead\n        return self.write(file, method=\"c14n\")\n\n# --------------------------------------------------------------------\n# serialization support\n\n@contextlib.contextmanager\ndef _get_writer(file_or_filename, encoding):\n    # returns text write method and release all resourses after using\n    try:\n        write = file_or_filename.write\n    except AttributeError:\n        # file_or_filename is a file name\n        if encoding == \"unicode\":\n            file = open(file_or_filename, \"w\")\n        else:\n            file = open(file_or_filename, \"w\", encoding=encoding,\n                        errors=\"xmlcharrefreplace\")\n        with file:\n            yield file.write\n    else:\n        # file_or_filename is a file-like object\n        # encoding determines if it is a text or binary writer\n        if encoding == \"unicode\":\n            # use a text writer as is\n            yield write\n        else:\n            # wrap a binary writer with TextIOWrapper\n            with contextlib.ExitStack() as stack:\n                if isinstance(file_or_filename, io.BufferedIOBase):\n                    file = file_or_filename\n                elif isinstance(file_or_filename, io.RawIOBase):\n                    file = io.BufferedWriter(file_or_filename)\n                    # Keep the original file open when the BufferedWriter is\n                    # destroyed\n                    stack.callback(file.detach)\n                else:\n                    # This is to handle passed objects that aren't in the\n                    # IOBase hierarchy, but just have a write method\n                    file = io.BufferedIOBase()\n                    file.writable = lambda: True\n                    file.write = write\n                    try:\n                        # TextIOWrapper uses this methods to determine\n                        # if BOM (for UTF-16, etc) should be added\n                        file.seekable = file_or_filename.seekable\n                        file.tell = file_or_filename.tell\n                    except AttributeError:\n                        pass\n                file = io.TextIOWrapper(file,\n                                        encoding=encoding,\n                                        errors=\"xmlcharrefreplace\",\n                                        newline=\"\\n\")\n                # Keep the original file open when the TextIOWrapper is\n                # destroyed\n                stack.callback(file.detach)\n                yield file.write\n\ndef _namespaces(elem, default_namespace=None):\n    # identify namespaces used in this tree\n\n    # maps qnames to *encoded* prefix:local names\n    qnames = {None: None}\n\n    # maps uri:s to prefixes\n    namespaces = {}\n    if default_namespace:\n        namespaces[default_namespace] = \"\"\n\n    def add_qname(qname):\n        # calculate serialized qname representation\n        try:\n            if qname[:1] == \"{\":\n                uri, tag = qname[1:].rsplit(\"}\", 1)\n                prefix = namespaces.get(uri)\n                if prefix is None:\n                    prefix = _namespace_map.get(uri)\n                    if prefix is None:\n                        prefix = \"ns%d\" % len(namespaces)\n                    if prefix != \"xml\":\n                        namespaces[uri] = prefix\n                if prefix:\n                    qnames[qname] = \"%s:%s\" % (prefix, tag)\n                else:\n                    qnames[qname] = tag # default element\n            else:\n                if default_namespace:\n                    # FIXME: can this be handled in XML 1.0?\n                    raise ValueError(\n                        \"cannot use non-qualified names with \"\n                        \"default_namespace option\"\n                        )\n                qnames[qname] = qname\n        except TypeError:\n            _raise_serialization_error(qname)\n\n    # populate qname and namespaces table\n    for elem in elem.iter():\n        tag = elem.tag\n        if isinstance(tag, QName):\n            if tag.text not in qnames:\n                add_qname(tag.text)\n        elif isinstance(tag, str):\n            if tag not in qnames:\n                add_qname(tag)\n        elif tag is not None and tag is not Comment and tag is not PI:\n            _raise_serialization_error(tag)\n        for key, value in elem.items():\n            if isinstance(key, QName):\n                key = key.text\n            if key not in qnames:\n                add_qname(key)\n            if isinstance(value, QName) and value.text not in qnames:\n                add_qname(value.text)\n        text = elem.text\n        if isinstance(text, QName) and text.text not in qnames:\n            add_qname(text.text)\n    return qnames, namespaces\n\ndef _serialize_xml(write, elem, qnames, namespaces):\n    tag = elem.tag\n    text = elem.text\n    if tag is Comment:\n        write(\"<!--%s-->\" % text)\n    elif tag is ProcessingInstruction:\n        write(\"<?%s?>\" % text)\n    else:\n        tag = qnames[tag]\n        if tag is None:\n            if text:\n                write(_escape_cdata(text))\n            for e in elem:\n                _serialize_xml(write, e, qnames, None)\n        else:\n            write(\"<\" + tag)\n            items = list(elem.items())\n            if items or namespaces:\n                if namespaces:\n                    for v, k in sorted(namespaces.items(),\n                                       key=lambda x: x[1]):  # sort on prefix\n                        if k:\n                            k = \":\" + k\n                        write(\" xmlns%s=\\\"%s\\\"\" % (\n                            k,\n                            _escape_attrib(v)\n                            ))\n                for k, v in sorted(items):  # lexical order\n                    if isinstance(k, QName):\n                        k = k.text\n                    if isinstance(v, QName):\n                        v = qnames[v.text]\n                    else:\n                        v = _escape_attrib(v)\n                    write(\" %s=\\\"%s\\\"\" % (qnames[k], v))\n            if text or len(elem):\n                write(\">\")\n                if text:\n                    write(_escape_cdata(text))\n                for e in elem:\n                    _serialize_xml(write, e, qnames, None)\n                write(\"</\" + tag + \">\")\n            else:\n                write(\" />\")\n    if elem.tail:\n        write(_escape_cdata(elem.tail))\n\nHTML_EMPTY = (\"area\", \"base\", \"basefont\", \"br\", \"col\", \"frame\", \"hr\",\n              \"img\", \"input\", \"isindex\", \"link\", \"meta\", \"param\")\n\ntry:\n    HTML_EMPTY = set(HTML_EMPTY)\nexcept NameError:\n    pass\n\ndef _serialize_html(write, elem, qnames, namespaces):\n    tag = elem.tag\n    text = elem.text\n    if tag is Comment:\n        write(\"<!--%s-->\" % _escape_cdata(text))\n    elif tag is ProcessingInstruction:\n        write(\"<?%s?>\" % _escape_cdata(text))\n    else:\n        tag = qnames[tag]\n        if tag is None:\n            if text:\n                write(_escape_cdata(text))\n            for e in elem:\n                _serialize_html(write, e, qnames, None)\n        else:\n            write(\"<\" + tag)\n            items = list(elem.items())\n            if items or namespaces:\n                if namespaces:\n                    for v, k in sorted(namespaces.items(),\n                                       key=lambda x: x[1]):  # sort on prefix\n                        if k:\n                            k = \":\" + k\n                        write(\" xmlns%s=\\\"%s\\\"\" % (\n                            k,\n                            _escape_attrib(v)\n                            ))\n                for k, v in sorted(items):  # lexical order\n                    if isinstance(k, QName):\n                        k = k.text\n                    if isinstance(v, QName):\n                        v = qnames[v.text]\n                    else:\n                        v = _escape_attrib_html(v)\n                    # FIXME: handle boolean attributes\n                    write(\" %s=\\\"%s\\\"\" % (qnames[k], v))\n            write(\">\")\n            tag = tag.lower()\n            if text:\n                if tag == \"script\" or tag == \"style\":\n                    write(text)\n                else:\n                    write(_escape_cdata(text))\n            for e in elem:\n                _serialize_html(write, e, qnames, None)\n            if tag not in HTML_EMPTY:\n                write(\"</\" + tag + \">\")\n    if elem.tail:\n        write(_escape_cdata(elem.tail))\n\ndef _serialize_text(write, elem):\n    for part in elem.itertext():\n        write(part)\n    if elem.tail:\n        write(elem.tail)\n\n_serialize = {\n    \"xml\": _serialize_xml,\n    \"html\": _serialize_html,\n    \"text\": _serialize_text,\n# this optional method is imported at the end of the module\n#   \"c14n\": _serialize_c14n,\n}\n\n##\n# Registers a namespace prefix.  The registry is global, and any\n# existing mapping for either the given prefix or the namespace URI\n# will be removed.\n#\n# @param prefix Namespace prefix.\n# @param uri Namespace uri.  Tags and attributes in this namespace\n#     will be serialized with the given prefix, if at all possible.\n# @exception ValueError If the prefix is reserved, or is otherwise\n#     invalid.\n\ndef register_namespace(prefix, uri):\n    if re.match(\"ns\\d+$\", prefix):\n        raise ValueError(\"Prefix format reserved for internal use\")\n    for k, v in list(_namespace_map.items()):\n        if k == uri or v == prefix:\n            del _namespace_map[k]\n    _namespace_map[uri] = prefix\n\n_namespace_map = {\n    # \"well-known\" namespace prefixes\n    \"http://www.w3.org/XML/1998/namespace\": \"xml\",\n    \"http://www.w3.org/1999/xhtml\": \"html\",\n    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\": \"rdf\",\n    \"http://schemas.xmlsoap.org/wsdl/\": \"wsdl\",\n    # xml schema\n    \"http://www.w3.org/2001/XMLSchema\": \"xs\",\n    \"http://www.w3.org/2001/XMLSchema-instance\": \"xsi\",\n    # dublin core\n    \"http://purl.org/dc/elements/1.1/\": \"dc\",\n}\n# For tests and troubleshooting\nregister_namespace._namespace_map = _namespace_map\n\ndef _raise_serialization_error(text):\n    raise TypeError(\n        \"cannot serialize %r (type %s)\" % (text, type(text).__name__)\n        )\n\ndef _escape_cdata(text):\n    # escape character data\n    try:\n        # it's worth avoiding do-nothing calls for strings that are\n        # shorter than 500 character, or so.  assume that's, by far,\n        # the most common case in most applications.\n        if \"&\" in text:\n            text = text.replace(\"&\", \"&amp;\")\n        if \"<\" in text:\n            text = text.replace(\"<\", \"&lt;\")\n        if \">\" in text:\n            text = text.replace(\">\", \"&gt;\")\n        return text\n    except (TypeError, AttributeError):\n        _raise_serialization_error(text)\n\ndef _escape_attrib(text):\n    # escape attribute value\n    try:\n        if \"&\" in text:\n            text = text.replace(\"&\", \"&amp;\")\n        if \"<\" in text:\n            text = text.replace(\"<\", \"&lt;\")\n        if \">\" in text:\n            text = text.replace(\">\", \"&gt;\")\n        if \"\\\"\" in text:\n            text = text.replace(\"\\\"\", \"&quot;\")\n        if \"\\n\" in text:\n            text = text.replace(\"\\n\", \"&#10;\")\n        return text\n    except (TypeError, AttributeError):\n        _raise_serialization_error(text)\n\ndef _escape_attrib_html(text):\n    # escape attribute value\n    try:\n        if \"&\" in text:\n            text = text.replace(\"&\", \"&amp;\")\n        if \">\" in text:\n            text = text.replace(\">\", \"&gt;\")\n        if \"\\\"\" in text:\n            text = text.replace(\"\\\"\", \"&quot;\")\n        return text\n    except (TypeError, AttributeError):\n        _raise_serialization_error(text)\n\n# --------------------------------------------------------------------\n\n##\n# Generates a string representation of an XML element, including all\n# subelements.  If encoding is \"unicode\", the return type is a string;\n# otherwise it is a bytes array.\n#\n# @param element An Element instance.\n# @keyparam encoding Optional output encoding (default is US-ASCII).\n#     Use \"unicode\" to return a Unicode string.\n# @keyparam method Optional output method (\"xml\", \"html\", \"text\" or\n#     \"c14n\"; default is \"xml\").\n# @return An (optionally) encoded string containing the XML data.\n# @defreturn string\n\ndef tostring(element, encoding=None, method=None):\n    stream = io.StringIO() if encoding == 'unicode' else io.BytesIO()\n    ElementTree(element).write(stream, encoding, method=method)\n    return stream.getvalue()\n\n##\n# Generates a string representation of an XML element, including all\n# subelements.\n#\n# @param element An Element instance.\n# @keyparam encoding Optional output encoding (default is US-ASCII).\n#     Use \"unicode\" to return a Unicode string.\n# @keyparam method Optional output method (\"xml\", \"html\", \"text\" or\n#     \"c14n\"; default is \"xml\").\n# @return A sequence object containing the XML data.\n# @defreturn sequence\n# @since 1.3\n\nclass _ListDataStream(io.BufferedIOBase):\n    \"\"\" An auxiliary stream accumulating into a list reference\n    \"\"\"\n    def __init__(self, lst):\n        self.lst = lst\n\n    def writable(self):\n        return True\n\n    def seekable(self):\n        return True\n\n    def write(self, b):\n        self.lst.append(b)\n\n    def tell(self):\n        return len(self.lst)\n\ndef tostringlist(element, encoding=None, method=None):\n    lst = []\n    stream = _ListDataStream(lst)\n    ElementTree(element).write(stream, encoding, method=method)\n    return lst\n\n##\n# Writes an element tree or element structure to sys.stdout.  This\n# function should be used for debugging only.\n# <p>\n# The exact output format is implementation dependent.  In this\n# version, it's written as an ordinary XML file.\n#\n# @param elem An element tree or an individual element.\n\ndef dump(elem):\n    # debugging\n    if not isinstance(elem, ElementTree):\n        elem = ElementTree(elem)\n    elem.write(sys.stdout, encoding=\"unicode\")\n    tail = elem.getroot().tail\n    if not tail or tail[-1] != \"\\n\":\n        sys.stdout.write(\"\\n\")\n\n# --------------------------------------------------------------------\n# parsing\n\n##\n# Parses an XML document into an element tree.\n#\n# @param source A filename or file object containing XML data.\n# @param parser An optional parser instance.  If not given, the\n#     standard {@link XMLParser} parser is used.\n# @return An ElementTree instance\n\ndef parse(source, parser=None):\n    tree = ElementTree()\n    tree.parse(source, parser)\n    return tree\n\n##\n# Parses an XML document into an element tree incrementally, and reports\n# what's going on to the user.\n#\n# @param source A filename or file object containing XML data.\n# @param events A list of events to report back.  If omitted, only \"end\"\n#     events are reported.\n# @param parser An optional parser instance.  If not given, the\n#     standard {@link XMLParser} parser is used.\n# @return A (event, elem) iterator.\n\ndef iterparse(source, events=None, parser=None):\n    close_source = False\n    if not hasattr(source, \"read\"):\n        source = open(source, \"rb\")\n        close_source = True\n    if not parser:\n        parser = XMLParser(target=TreeBuilder())\n    return _IterParseIterator(source, events, parser, close_source)\n\nclass _IterParseIterator:\n\n    def __init__(self, source, events, parser, close_source=False):\n        self._file = source\n        self._close_file = close_source\n        self._events = []\n        self._index = 0\n        self._error = None\n        self.root = self._root = None\n        self._parser = parser\n        # wire up the parser for event reporting\n        parser = self._parser._parser\n        append = self._events.append\n        if events is None:\n            events = [\"end\"]\n        for event in events:\n            if event == \"start\":\n                try:\n                    parser.ordered_attributes = 1\n                    parser.specified_attributes = 1\n                    def handler(tag, attrib_in, event=event, append=append,\n                                start=self._parser._start_list):\n                        append((event, start(tag, attrib_in)))\n                    parser.StartElementHandler = handler\n                except AttributeError:\n                    def handler(tag, attrib_in, event=event, append=append,\n                                start=self._parser._start):\n                        append((event, start(tag, attrib_in)))\n                    parser.StartElementHandler = handler\n            elif event == \"end\":\n                def handler(tag, event=event, append=append,\n                            end=self._parser._end):\n                    append((event, end(tag)))\n                parser.EndElementHandler = handler\n            elif event == \"start-ns\":\n                def handler(prefix, uri, event=event, append=append):\n                    append((event, (prefix or \"\", uri or \"\")))\n                parser.StartNamespaceDeclHandler = handler\n            elif event == \"end-ns\":\n                def handler(prefix, event=event, append=append):\n                    append((event, None))\n                parser.EndNamespaceDeclHandler = handler\n            else:\n                raise ValueError(\"unknown event %r\" % event)\n\n    def __next__(self):\n        while 1:\n            try:\n                item = self._events[self._index]\n                self._index += 1\n                return item\n            except IndexError:\n                pass\n            if self._error:\n                e = self._error\n                self._error = None\n                raise e\n            if self._parser is None:\n                self.root = self._root\n                if self._close_file:\n                    self._file.close()\n                raise StopIteration\n            # load event buffer\n            del self._events[:]\n            self._index = 0\n            data = self._file.read(16384)\n            if data:\n                try:\n                    self._parser.feed(data)\n                except SyntaxError as exc:\n                    self._error = exc\n            else:\n                self._root = self._parser.close()\n                self._parser = None\n\n    def __iter__(self):\n        return self\n\n##\n# Parses an XML document from a string constant.  This function can\n# be used to embed \"XML literals\" in Python code.\n#\n# @param source A string containing XML data.\n# @param parser An optional parser instance.  If not given, the\n#     standard {@link XMLParser} parser is used.\n# @return An Element instance.\n# @defreturn Element\n\ndef XML(text, parser=None):\n    if not parser:\n        parser = XMLParser(target=TreeBuilder())\n    parser.feed(text)\n    return parser.close()\n\n##\n# Parses an XML document from a string constant, and also returns\n# a dictionary which maps from element id:s to elements.\n#\n# @param source A string containing XML data.\n# @param parser An optional parser instance.  If not given, the\n#     standard {@link XMLParser} parser is used.\n# @return A tuple containing an Element instance and a dictionary.\n# @defreturn (Element, dictionary)\n\ndef XMLID(text, parser=None):\n    if not parser:\n        parser = XMLParser(target=TreeBuilder())\n    parser.feed(text)\n    tree = parser.close()\n    ids = {}\n    for elem in tree.iter():\n        id = elem.get(\"id\")\n        if id:\n            ids[id] = elem\n    return tree, ids\n\n##\n# Parses an XML document from a string constant.  Same as {@link #XML}.\n#\n# @def fromstring(text)\n# @param source A string containing XML data.\n# @return An Element instance.\n# @defreturn Element\n\nfromstring = XML\n\n##\n# Parses an XML document from a sequence of string fragments.\n#\n# @param sequence A list or other sequence containing XML data fragments.\n# @param parser An optional parser instance.  If not given, the\n#     standard {@link XMLParser} parser is used.\n# @return An Element instance.\n# @defreturn Element\n# @since 1.3\n\ndef fromstringlist(sequence, parser=None):\n    if not parser:\n        parser = XMLParser(target=TreeBuilder())\n    for text in sequence:\n        parser.feed(text)\n    return parser.close()\n\n# --------------------------------------------------------------------\n\n##\n# Generic element structure builder.  This builder converts a sequence\n# of {@link #TreeBuilder.start}, {@link #TreeBuilder.data}, and {@link\n# #TreeBuilder.end} method calls to a well-formed element structure.\n# <p>\n# You can use this class to build an element structure using a custom XML\n# parser, or a parser for some other XML-like format.\n#\n# @param element_factory Optional element factory.  This factory\n#    is called to create new Element instances, as necessary.\n\nclass TreeBuilder:\n\n    def __init__(self, element_factory=None):\n        self._data = [] # data collector\n        self._elem = [] # element stack\n        self._last = None # last element\n        self._tail = None # true if we're after an end tag\n        if element_factory is None:\n            element_factory = Element\n        self._factory = element_factory\n\n    ##\n    # Flushes the builder buffers, and returns the toplevel document\n    # element.\n    #\n    # @return An Element instance.\n    # @defreturn Element\n\n    def close(self):\n        assert len(self._elem) == 0, \"missing end tags\"\n        assert self._last is not None, \"missing toplevel element\"\n        return self._last\n\n    def _flush(self):\n        if self._data:\n            if self._last is not None:\n                text = \"\".join(self._data)\n                if self._tail:\n                    assert self._last.tail is None, \"internal error (tail)\"\n                    self._last.tail = text\n                else:\n                    assert self._last.text is None, \"internal error (text)\"\n                    self._last.text = text\n            self._data = []\n\n    ##\n    # Adds text to the current element.\n    #\n    # @param data A string.  This should be either an 8-bit string\n    #    containing ASCII text, or a Unicode string.\n\n    def data(self, data):\n        self._data.append(data)\n\n    ##\n    # Opens a new element.\n    #\n    # @param tag The element name.\n    # @param attrib A dictionary containing element attributes.\n    # @return The opened element.\n    # @defreturn Element\n\n    def start(self, tag, attrs):\n        self._flush()\n        self._last = elem = self._factory(tag, attrs)\n        if self._elem:\n            self._elem[-1].append(elem)\n        self._elem.append(elem)\n        self._tail = 0\n        return elem\n\n    ##\n    # Closes the current element.\n    #\n    # @param tag The element name.\n    # @return The closed element.\n    # @defreturn Element\n\n    def end(self, tag):\n        self._flush()\n        self._last = self._elem.pop()\n        assert self._last.tag == tag,\\\n               \"end tag mismatch (expected %s, got %s)\" % (\n                   self._last.tag, tag)\n        self._tail = 1\n        return self._last\n\n##\n# Element structure builder for XML source data, based on the\n# <b>expat</b> parser.\n#\n# @keyparam target Target object.  If omitted, the builder uses an\n#     instance of the standard {@link #TreeBuilder} class.\n# @keyparam html Predefine HTML entities.  This flag is not supported\n#     by the current implementation.\n# @keyparam encoding Optional encoding.  If given, the value overrides\n#     the encoding specified in the XML file.\n# @see #ElementTree\n# @see #TreeBuilder\n\nclass XMLParser:\n\n    def __init__(self, html=0, target=None, encoding=None):\n        try:\n            from xml.parsers import expat\n        except ImportError:\n            try:\n                import pyexpat as expat\n            except ImportError:\n                raise ImportError(\n                    \"No module named expat; use SimpleXMLTreeBuilder instead\"\n                    )\n        parser = expat.ParserCreate(encoding, \"}\")\n        if target is None:\n            target = TreeBuilder()\n        # underscored names are provided for compatibility only\n        self.parser = self._parser = parser\n        self.target = self._target = target\n        self._error = expat.error\n        self._names = {} # name memo cache\n        # main callbacks\n        parser.DefaultHandlerExpand = self._default\n        if hasattr(target, 'start'):\n            parser.StartElementHandler = self._start\n        if hasattr(target, 'end'):\n            parser.EndElementHandler = self._end\n        if hasattr(target, 'data'):\n            parser.CharacterDataHandler = target.data\n        # miscellaneous callbacks\n        if hasattr(target, 'comment'):\n            parser.CommentHandler = target.comment\n        if hasattr(target, 'pi'):\n            parser.ProcessingInstructionHandler = target.pi\n        # let expat do the buffering, if supported\n        try:\n            parser.buffer_text = 1\n        except AttributeError:\n            pass\n        # use new-style attribute handling, if supported\n        try:\n            parser.ordered_attributes = 1\n            parser.specified_attributes = 1\n            if hasattr(target, 'start'):\n                parser.StartElementHandler = self._start_list\n        except AttributeError:\n            pass\n        self._doctype = None\n        self.entity = {}\n        try:\n            self.version = \"Expat %d.%d.%d\" % expat.version_info\n        except AttributeError:\n            pass # unknown\n\n    def _raiseerror(self, value):\n        err = ParseError(value)\n        err.code = value.code\n        err.position = value.lineno, value.offset\n        raise err\n\n    def _fixname(self, key):\n        # expand qname, and convert name string to ascii, if possible\n        try:\n            name = self._names[key]\n        except KeyError:\n            name = key\n            if \"}\" in name:\n                name = \"{\" + name\n            self._names[key] = name\n        return name\n\n    def _start(self, tag, attrib_in):\n        fixname = self._fixname\n        tag = fixname(tag)\n        attrib = {}\n        for key, value in attrib_in.items():\n            attrib[fixname(key)] = value\n        return self.target.start(tag, attrib)\n\n    def _start_list(self, tag, attrib_in):\n        fixname = self._fixname\n        tag = fixname(tag)\n        attrib = {}\n        if attrib_in:\n            for i in range(0, len(attrib_in), 2):\n                attrib[fixname(attrib_in[i])] = attrib_in[i+1]\n        return self.target.start(tag, attrib)\n\n    def _end(self, tag):\n        return self.target.end(self._fixname(tag))\n\n    def _default(self, text):\n        prefix = text[:1]\n        if prefix == \"&\":\n            # deal with undefined entities\n            try:\n                data_handler = self.target.data\n            except AttributeError:\n                return\n            try:\n                data_handler(self.entity[text[1:-1]])\n            except KeyError:\n                from xml.parsers import expat\n                err = expat.error(\n                    \"undefined entity %s: line %d, column %d\" %\n                    (text, self.parser.ErrorLineNumber,\n                    self.parser.ErrorColumnNumber)\n                    )\n                err.code = 11 # XML_ERROR_UNDEFINED_ENTITY\n                err.lineno = self.parser.ErrorLineNumber\n                err.offset = self.parser.ErrorColumnNumber\n                raise err\n        elif prefix == \"<\" and text[:9] == \"<!DOCTYPE\":\n            self._doctype = [] # inside a doctype declaration\n        elif self._doctype is not None:\n            # parse doctype contents\n            if prefix == \">\":\n                self._doctype = None\n                return\n            text = text.strip()\n            if not text:\n                return\n            self._doctype.append(text)\n            n = len(self._doctype)\n            if n > 2:\n                type = self._doctype[1]\n                if type == \"PUBLIC\" and n == 4:\n                    name, type, pubid, system = self._doctype\n                    if pubid:\n                        pubid = pubid[1:-1]\n                elif type == \"SYSTEM\" and n == 3:\n                    name, type, system = self._doctype\n                    pubid = None\n                else:\n                    return\n                if hasattr(self.target, \"doctype\"):\n                    self.target.doctype(name, pubid, system[1:-1])\n                elif self.doctype != self._XMLParser__doctype:\n                    # warn about deprecated call\n                    self._XMLParser__doctype(name, pubid, system[1:-1])\n                    self.doctype(name, pubid, system[1:-1])\n                self._doctype = None\n\n    ##\n    # (Deprecated) Handles a doctype declaration.\n    #\n    # @param name Doctype name.\n    # @param pubid Public identifier.\n    # @param system System identifier.\n\n    def doctype(self, name, pubid, system):\n        \"\"\"This method of XMLParser is deprecated.\"\"\"\n        warnings.warn(\n            \"This method of XMLParser is deprecated.  Define doctype() \"\n            \"method on the TreeBuilder target.\",\n            DeprecationWarning,\n            )\n\n    # sentinel, if doctype is redefined in a subclass\n    __doctype = doctype\n\n    ##\n    # Feeds data to the parser.\n    #\n    # @param data Encoded data.\n\n    def feed(self, data):\n        try:\n            self.parser.Parse(data, 0)\n        except self._error as v:\n            self._raiseerror(v)\n\n    ##\n    # Finishes feeding data to the parser.\n    #\n    # @return An element structure.\n    # @defreturn Element\n\n    def close(self):\n        try:\n            self.parser.Parse(\"\", 1) # end of data\n        except self._error as v:\n            self._raiseerror(v)\n        try:\n            close_handler = self.target.close\n        except AttributeError:\n            pass\n        else:\n            return close_handler()\n        finally:\n            # get rid of circular references\n            del self.parser, self._parser\n            del self.target, self._target\n\n\n# Import the C accelerators\ntry:\n    # Element, SubElement, ParseError, TreeBuilder, XMLParser\n    from _elementtree import *\nexcept ImportError:\n    pass\nelse:\n    # Overwrite 'ElementTree.parse' and 'iterparse' to use the C XMLParser\n\n    class ElementTree(ElementTree):\n        def parse(self, source, parser=None):\n            close_source = False\n            if not hasattr(source, 'read'):\n                source = open(source, 'rb')\n                close_source = True\n            try:\n                if parser is not None:\n                    while True:\n                        data = source.read(65536)\n                        if not data:\n                            break\n                        parser.feed(data)\n                    self._root = parser.close()\n                else:\n                    parser = XMLParser()\n                    self._root = parser._parse(source)\n                return self._root\n            finally:\n                if close_source:\n                    source.close()\n\n    class iterparse:\n        \"\"\"Parses an XML section into an element tree incrementally.\n\n        Reports what\u2019s going on to the user. 'source' is a filename or file\n        object containing XML data. 'events' is a list of events to report back.\n        The supported events are the strings \"start\", \"end\", \"start-ns\" and\n        \"end-ns\" (the \"ns\" events are used to get detailed namespace\n        information). If 'events' is omitted, only \"end\" events are reported.\n        'parser' is an optional parser instance. If not given, the standard\n        XMLParser parser is used. Returns an iterator providing\n        (event, elem) pairs.\n        \"\"\"\n\n        root = None\n        def __init__(self, file, events=None, parser=None):\n            self._close_file = False\n            if not hasattr(file, 'read'):\n                file = open(file, 'rb')\n                self._close_file = True\n            self._file = file\n            self._events = []\n            self._index = 0\n            self._error = None\n            self.root = self._root = None\n            if parser is None:\n                parser = XMLParser(target=TreeBuilder())\n            self._parser = parser\n            self._parser._setevents(self._events, events)\n\n        def __next__(self):\n            while True:\n                try:\n                    item = self._events[self._index]\n                    self._index += 1\n                    return item\n                except IndexError:\n                    pass\n                if self._error:\n                    e = self._error\n                    self._error = None\n                    raise e\n                if self._parser is None:\n                    self.root = self._root\n                    if self._close_file:\n                        self._file.close()\n                    raise StopIteration\n                # load event buffer\n                del self._events[:]\n                self._index = 0\n                data = self._file.read(16384)\n                if data:\n                    try:\n                        self._parser.feed(data)\n                    except SyntaxError as exc:\n                        self._error = exc\n                else:\n                    self._root = self._parser.close()\n                    self._parser = None\n\n        def __iter__(self):\n            return self\n\n# compatibility\nXMLTreeBuilder = XMLParser\n\n# workaround circular import.\ntry:\n    from ElementC14N import _serialize_c14n\n    _serialize[\"c14n\"] = _serialize_c14n\nexcept ImportError:\n    pass\n"], "_ajax": [".js", "// ajax\nvar $module = (function($B){\n\nvar _b_ = $B.builtins\n\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n//for(var $py_builtin in _b_){eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")}\n\nvar $XMLHttpDict = {__class__:$B.$type,__name__:'XMLHttp'}\n\n$XMLHttpDict.__getattribute__ = function(self,attr){\n    if(['headers','text','xml'].indexOf(attr)>-1){\n        return $XMLHttpDict[attr](self)\n    }\n    return _b_.object.$dict.__getattribute__(self,attr)\n}\n\n$XMLHttpDict.__mro__ = [$XMLHttpDict, _b_.object.$dict]\n\n$XMLHttpDict.__repr__ = function(self){return '<object XMLHttp>'}\n\n$XMLHttpDict.__str__ = $XMLHttpDict.toString = $XMLHttpDict.__repr__\n\n$XMLHttpDict.text = function(self){return self.responseText}\n    \n$XMLHttpDict.xml = function(self){return $DomObject(self.responseXML)}\n\n$XMLHttpDict.headers = function(self){\n    return list(self.getAllResponseHeaders().split('\\n'))\n}\n\n$XMLHttpDict.get_header = function(){\n    var reqobj = self;\n    return function(header){ return reqobj.getResponseHeader(header) }\n}\n\nvar $AjaxDict = {__class__:$B.$type,__name__:'ajax'}\n\n$AjaxDict.__mro__ = [$AjaxDict, _b_.object.$dict]\n\n$AjaxDict.__repr__ = function(self){return '<object Ajax>'}\n\n$AjaxDict.__str__ = $AjaxDict.toString = $AjaxDict.__repr__\n\n$AjaxDict.bind = function(self,evt,func){\n    // req.bind(evt,func) is the same as req.on_evt = func\n    self['on_'+evt]=func\n}\n\n$AjaxDict.open = function(self,method,url,async){\n    self.$xmlhttp.open(method,url,async)\n}\n\n$AjaxDict.send = function(self,params){\n    // params is a Python dictionary\n    var res = ''\n    if(!params || params.$keys.length==0){self.$xmlhttp.send();return}\n    else if(isinstance(params,str)){\n        res = params\n    }else if(isinstance(params,dict)){\n        for(i=0;i<params.$keys.length;i++){\n            res +=encodeURIComponent(str(params.$keys[i]))+'='+encodeURIComponent(str(params.$values[i]))+'&'\n        }\n        res = res.substr(0,res.length-1)\n    }else{\n        throw _b_.TypeError(\"send() argument must be string or dictonary, not '\"+str(params.__class__)+\"'\")\n    }\n    self.$xmlhttp.send(res)\n}\n\n$AjaxDict.set_header = function(self,key,value){\n    self.$xmlhttp.setRequestHeader(key,value)\n}\n\n$AjaxDict.set_timeout = function(self,seconds,func){\n    self.$xmlhttp.$requestTimer = setTimeout(\n        function() {self.$xmlhttp.abort();func()}, \n        seconds*1000); \n}\n\nfunction ajax(){\n\n    var res = {\n        __class__:$AjaxDict\n    }\n\n    if (window.XMLHttpRequest){// code for IE7+, Firefox, Chrome, Opera, Safari\n        var $xmlhttp=new XMLHttpRequest();\n    }else{// code for IE6, IE5\n        var $xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\");\n    }\n    $xmlhttp.$requestTimer = null\n    $xmlhttp.__class__ = $XMLHttpDict\n    \n    $xmlhttp.onreadystatechange = function(){\n        // here, \"this\" refers to $xmlhttp\n        var state = this.readyState\n        var req = this.$ajax\n        var timer = this.$requestTimer\n        var obj = this\n        if(state===0 && 'on_uninitialized' in req){req.on_uninitialized(obj)}\n        else if(state===1 && 'on_loading' in req){req.on_loading(obj)}\n        else if(state===2 && 'on_loaded' in req){req.on_loaded(obj)}\n        else if(state===3 && 'on_interactive' in req){req.on_interactive(obj)}\n        else if(state===4 && 'on_complete' in req){\n            if(timer !== null){window.clearTimeout(timer)}\n            req.on_complete(obj)\n        }\n    }\n    $xmlhttp.$ajax = res\n    res.$xmlhttp = $xmlhttp\n    return res\n}\n\najax.__class__ = $B.$factory\najax.$dict = $AjaxDict\n\nreturn {ajax:ajax}\n\n})(__BRYTHON__)\n"], "unittest.test.test_program": [".py", "import io\n\nimport os\nimport sys\nimport unittest\n\n\nclass Test_TestProgram(unittest.TestCase):\n\n    def test_discovery_from_dotted_path(self):\n        loader = unittest.TestLoader()\n\n        tests = [self]\n        expectedPath = os.path.abspath(os.path.dirname(unittest.test.__file__))\n\n        self.wasRun = False\n        def _find_tests(start_dir, pattern):\n            self.wasRun = True\n            self.assertEqual(start_dir, expectedPath)\n            return tests\n        loader._find_tests = _find_tests\n        suite = loader.discover('unittest.test')\n        self.assertTrue(self.wasRun)\n        self.assertEqual(suite._tests, tests)\n\n    # Horrible white box test\n    def testNoExit(self):\n        result = object()\n        test = object()\n\n        class FakeRunner(object):\n            def run(self, test):\n                self.test = test\n                return result\n\n        runner = FakeRunner()\n\n        oldParseArgs = unittest.TestProgram.parseArgs\n        def restoreParseArgs():\n            unittest.TestProgram.parseArgs = oldParseArgs\n        unittest.TestProgram.parseArgs = lambda *args: None\n        self.addCleanup(restoreParseArgs)\n\n        def removeTest():\n            del unittest.TestProgram.test\n        unittest.TestProgram.test = test\n        self.addCleanup(removeTest)\n\n        program = unittest.TestProgram(testRunner=runner, exit=False, verbosity=2)\n\n        self.assertEqual(program.result, result)\n        self.assertEqual(runner.test, test)\n        self.assertEqual(program.verbosity, 2)\n\n    class FooBar(unittest.TestCase):\n        def testPass(self):\n            assert True\n        def testFail(self):\n            assert False\n\n    class FooBarLoader(unittest.TestLoader):\n        \"\"\"Test loader that returns a suite containing FooBar.\"\"\"\n        def loadTestsFromModule(self, module):\n            return self.suiteClass(\n                [self.loadTestsFromTestCase(Test_TestProgram.FooBar)])\n\n\n    def test_NonExit(self):\n        program = unittest.main(exit=False,\n                                argv=[\"foobar\"],\n                                testRunner=unittest.TextTestRunner(stream=io.StringIO()),\n                                testLoader=self.FooBarLoader())\n        self.assertTrue(hasattr(program, 'result'))\n\n\n    def test_Exit(self):\n        self.assertRaises(\n            SystemExit,\n            unittest.main,\n            argv=[\"foobar\"],\n            testRunner=unittest.TextTestRunner(stream=io.StringIO()),\n            exit=True,\n            testLoader=self.FooBarLoader())\n\n\n    def test_ExitAsDefault(self):\n        self.assertRaises(\n            SystemExit,\n            unittest.main,\n            argv=[\"foobar\"],\n            testRunner=unittest.TextTestRunner(stream=io.StringIO()),\n            testLoader=self.FooBarLoader())\n\n\nclass InitialisableProgram(unittest.TestProgram):\n    exit = False\n    result = None\n    verbosity = 1\n    defaultTest = None\n    testRunner = None\n    testLoader = unittest.defaultTestLoader\n    module = '__main__'\n    progName = 'test'\n    test = 'test'\n    def __init__(self, *args):\n        pass\n\nRESULT = object()\n\nclass FakeRunner(object):\n    initArgs = None\n    test = None\n    raiseError = False\n\n    def __init__(self, **kwargs):\n        FakeRunner.initArgs = kwargs\n        if FakeRunner.raiseError:\n            FakeRunner.raiseError = False\n            raise TypeError\n\n    def run(self, test):\n        FakeRunner.test = test\n        return RESULT\n\nclass TestCommandLineArgs(unittest.TestCase):\n\n    def setUp(self):\n        self.program = InitialisableProgram()\n        self.program.createTests = lambda: None\n        FakeRunner.initArgs = None\n        FakeRunner.test = None\n        FakeRunner.raiseError = False\n\n    def testVerbosity(self):\n        program = self.program\n\n        for opt in '-q', '--quiet':\n            program.verbosity = 1\n            program.parseArgs([None, opt])\n            self.assertEqual(program.verbosity, 0)\n\n        for opt in '-v', '--verbose':\n            program.verbosity = 1\n            program.parseArgs([None, opt])\n            self.assertEqual(program.verbosity, 2)\n\n    def testBufferCatchFailfast(self):\n        program = self.program\n        for arg, attr in (('buffer', 'buffer'), ('failfast', 'failfast'),\n                      ('catch', 'catchbreak')):\n            if attr == 'catch' and not hasInstallHandler:\n                continue\n\n            short_opt = '-%s' % arg[0]\n            long_opt = '--%s' % arg\n            for opt in short_opt, long_opt:\n                setattr(program, attr, None)\n\n                program.parseArgs([None, opt])\n                self.assertTrue(getattr(program, attr))\n\n            for opt in short_opt, long_opt:\n                not_none = object()\n                setattr(program, attr, not_none)\n\n                program.parseArgs([None, opt])\n                self.assertEqual(getattr(program, attr), not_none)\n\n    def testWarning(self):\n        \"\"\"Test the warnings argument\"\"\"\n        # see #10535\n        class FakeTP(unittest.TestProgram):\n            def parseArgs(self, *args, **kw): pass\n            def runTests(self, *args, **kw): pass\n        warnoptions = sys.warnoptions[:]\n        try:\n            sys.warnoptions[:] = []\n            # no warn options, no arg -> default\n            self.assertEqual(FakeTP().warnings, 'default')\n            # no warn options, w/ arg -> arg value\n            self.assertEqual(FakeTP(warnings='ignore').warnings, 'ignore')\n            sys.warnoptions[:] = ['somevalue']\n            # warn options, no arg -> None\n            # warn options, w/ arg -> arg value\n            self.assertEqual(FakeTP().warnings, None)\n            self.assertEqual(FakeTP(warnings='ignore').warnings, 'ignore')\n        finally:\n            sys.warnoptions[:] = warnoptions\n\n    def testRunTestsRunnerClass(self):\n        program = self.program\n\n        program.testRunner = FakeRunner\n        program.verbosity = 'verbosity'\n        program.failfast = 'failfast'\n        program.buffer = 'buffer'\n        program.warnings = 'warnings'\n\n        program.runTests()\n\n        self.assertEqual(FakeRunner.initArgs, {'verbosity': 'verbosity',\n                                                'failfast': 'failfast',\n                                                'buffer': 'buffer',\n                                                'warnings': 'warnings'})\n        self.assertEqual(FakeRunner.test, 'test')\n        self.assertIs(program.result, RESULT)\n\n    def testRunTestsRunnerInstance(self):\n        program = self.program\n\n        program.testRunner = FakeRunner()\n        FakeRunner.initArgs = None\n\n        program.runTests()\n\n        # A new FakeRunner should not have been instantiated\n        self.assertIsNone(FakeRunner.initArgs)\n\n        self.assertEqual(FakeRunner.test, 'test')\n        self.assertIs(program.result, RESULT)\n\n    def testRunTestsOldRunnerClass(self):\n        program = self.program\n\n        FakeRunner.raiseError = True\n        program.testRunner = FakeRunner\n        program.verbosity = 'verbosity'\n        program.failfast = 'failfast'\n        program.buffer = 'buffer'\n        program.test = 'test'\n\n        program.runTests()\n\n        # If initialising raises a type error it should be retried\n        # without the new keyword arguments\n        self.assertEqual(FakeRunner.initArgs, {})\n        self.assertEqual(FakeRunner.test, 'test')\n        self.assertIs(program.result, RESULT)\n\n    def testCatchBreakInstallsHandler(self):\n        module = sys.modules['unittest.main']\n        original = module.installHandler\n        def restore():\n            module.installHandler = original\n        self.addCleanup(restore)\n\n        self.installed = False\n        def fakeInstallHandler():\n            self.installed = True\n        module.installHandler = fakeInstallHandler\n\n        program = self.program\n        program.catchbreak = True\n\n        program.testRunner = FakeRunner\n\n        program.runTests()\n        self.assertTrue(self.installed)\n\n    def _patch_isfile(self, names, exists=True):\n        def isfile(path):\n            return path in names\n        original = os.path.isfile\n        os.path.isfile = isfile\n        def restore():\n            os.path.isfile = original\n        self.addCleanup(restore)\n\n\n    def testParseArgsFileNames(self):\n        # running tests with filenames instead of module names\n        program = self.program\n        argv = ['progname', 'foo.py', 'bar.Py', 'baz.PY', 'wing.txt']\n        self._patch_isfile(argv)\n\n        program.createTests = lambda: None\n        program.parseArgs(argv)\n\n        # note that 'wing.txt' is not a Python file so the name should\n        # *not* be converted to a module name\n        expected = ['foo', 'bar', 'baz', 'wing.txt']\n        self.assertEqual(program.testNames, expected)\n\n\n    def testParseArgsFilePaths(self):\n        program = self.program\n        argv = ['progname', 'foo/bar/baz.py', 'green\\\\red.py']\n        self._patch_isfile(argv)\n\n        program.createTests = lambda: None\n        program.parseArgs(argv)\n\n        expected = ['foo.bar.baz', 'green.red']\n        self.assertEqual(program.testNames, expected)\n\n\n    def testParseArgsNonExistentFiles(self):\n        program = self.program\n        argv = ['progname', 'foo/bar/baz.py', 'green\\\\red.py']\n        self._patch_isfile([])\n\n        program.createTests = lambda: None\n        program.parseArgs(argv)\n\n        self.assertEqual(program.testNames, argv[1:])\n\n    def testParseArgsAbsolutePathsThatCanBeConverted(self):\n        cur_dir = os.getcwd()\n        program = self.program\n        def _join(name):\n            return os.path.join(cur_dir, name)\n        argv = ['progname', _join('foo/bar/baz.py'), _join('green\\\\red.py')]\n        self._patch_isfile(argv)\n\n        program.createTests = lambda: None\n        program.parseArgs(argv)\n\n        expected = ['foo.bar.baz', 'green.red']\n        self.assertEqual(program.testNames, expected)\n\n    def testParseArgsAbsolutePathsThatCannotBeConverted(self):\n        program = self.program\n        # even on Windows '/...' is considered absolute by os.path.abspath\n        argv = ['progname', '/foo/bar/baz.py', '/green/red.py']\n        self._patch_isfile(argv)\n\n        program.createTests = lambda: None\n        program.parseArgs(argv)\n\n        self.assertEqual(program.testNames, argv[1:])\n\n        # it may be better to use platform specific functions to normalise paths\n        # rather than accepting '.PY' and '\\' as file seprator on Linux / Mac\n        # it would also be better to check that a filename is a valid module\n        # identifier (we have a regex for this in loader.py)\n        # for invalid filenames should we raise a useful error rather than\n        # leaving the current error message (import of filename fails) in place?\n\n\nif __name__ == '__main__':\n    unittest.main()\n"], "pwd": [".py", "\ndef getpwuid():\n    pass\n"], "webbrowser": [".py", "from browser import window\n\n__all__ = [\"Error\", \"open\", \"open_new\", \"open_new_tab\"]\n\nclass Error(Exception):\n    pass\n\n_target = { 0: '', 1: '_blank', 2: '_new' }  # hack...\n\n\ndef open(url, new=0, autoraise=True):\n    \"\"\" \n    new window or tab is not controllable\n    on the client side. autoraise not available.\n    \"\"\"\n    if window.open(url, _target[new]):\n\t\treturn True\n    return False\n\ndef open_new(url):\n    return open(url, 1)\n\ndef open_new_tab(url):\n    return open(url, 2)\n\n\n"], "copy": [".py", "\"\"\"Generic (shallow and deep) copying operations.\n\nInterface summary:\n\n        import copy\n\n        x = copy.copy(y)        # make a shallow copy of y\n        x = copy.deepcopy(y)    # make a deep copy of y\n\nFor module specific errors, copy.Error is raised.\n\nThe difference between shallow and deep copying is only relevant for\ncompound objects (objects that contain other objects, like lists or\nclass instances).\n\n- A shallow copy constructs a new compound object and then (to the\n  extent possible) inserts *the same objects* into it that the\n  original contains.\n\n- A deep copy constructs a new compound object and then, recursively,\n  inserts *copies* into it of the objects found in the original.\n\nTwo problems often exist with deep copy operations that don't exist\nwith shallow copy operations:\n\n a) recursive objects (compound objects that, directly or indirectly,\n    contain a reference to themselves) may cause a recursive loop\n\n b) because deep copy copies *everything* it may copy too much, e.g.\n    administrative data structures that should be shared even between\n    copies\n\nPython's deep copy operation avoids these problems by:\n\n a) keeping a table of objects already copied during the current\n    copying pass\n\n b) letting user-defined classes override the copying operation or the\n    set of components copied\n\nThis version does not copy types like module, class, function, method,\nnor stack trace, stack frame, nor file, socket, window, nor array, nor\nany similar types.\n\nClasses can use the same interfaces to control copying that they use\nto control pickling: they can define methods called __getinitargs__(),\n__getstate__() and __setstate__().  See the documentation for module\n\"pickle\" for information on these methods.\n\"\"\"\n\nimport types\nimport weakref\nfrom copyreg import dispatch_table\nimport builtins\n\nclass Error(Exception):\n    pass\nerror = Error   # backward compatibility\n\ntry:\n    from org.python.core import PyStringMap\nexcept ImportError:\n    PyStringMap = None\n\n__all__ = [\"Error\", \"copy\", \"deepcopy\"]\n\ndef copy(x):\n    \"\"\"Shallow copy operation on arbitrary Python objects.\n\n    See the module's __doc__ string for more info.\n    \"\"\"\n\n    cls = type(x)\n\n    copier = _copy_dispatch.get(cls)\n    if copier:\n        return copier(x)\n\n    copier = getattr(cls, \"__copy__\", None)\n    if copier:\n        return copier(x)\n\n    reductor = dispatch_table.get(cls)\n    if reductor:\n        rv = reductor(x)\n    else:\n        reductor = getattr(x, \"__reduce_ex__\", None)\n        if reductor:\n            rv = reductor(2)\n        else:\n            reductor = getattr(x, \"__reduce__\", None)\n            if reductor:\n                rv = reductor()\n            else:\n                raise Error(\"un(shallow)copyable object of type %s\" % cls)\n\n    return _reconstruct(x, rv, 0)\n\n\n_copy_dispatch = d = {}\n\ndef _copy_immutable(x):\n    return x\nfor t in (type(None), int, float, bool, str, tuple,\n          frozenset, type, range,\n          types.BuiltinFunctionType, type(Ellipsis),\n          types.FunctionType, weakref.ref):\n    d[t] = _copy_immutable\nt = getattr(types, \"CodeType\", None)\nif t is not None:\n    d[t] = _copy_immutable\nfor name in (\"complex\", \"unicode\"):\n    t = getattr(builtins, name, None)\n    if t is not None:\n        d[t] = _copy_immutable\n\ndef _copy_with_constructor(x):\n    return type(x)(x)\nfor t in (list, dict, set):\n    d[t] = _copy_with_constructor\n\ndef _copy_with_copy_method(x):\n    return x.copy()\nif PyStringMap is not None:\n    d[PyStringMap] = _copy_with_copy_method\n\ndel d\n\ndef deepcopy(x, memo=None, _nil=[]):\n    \"\"\"Deep copy operation on arbitrary Python objects.\n\n    See the module's __doc__ string for more info.\n    \"\"\"\n\n    if memo is None:\n        memo = {}\n\n    d = id(x)\n    y = memo.get(d, _nil)\n    if y is not _nil:\n        return y\n\n    cls = type(x)\n\n    copier = _deepcopy_dispatch.get(cls)\n    if copier:\n        y = copier(x, memo)\n    else:\n        try:\n            issc = issubclass(cls, type)\n        except TypeError: # cls is not a class (old Boost; see SF #502085)\n            issc = 0\n        if issc:\n            y = _deepcopy_atomic(x, memo)\n        else:\n            copier = getattr(x, \"__deepcopy__\", None)\n            if copier:\n                y = copier(memo)\n            else:\n                reductor = dispatch_table.get(cls)\n                if reductor:\n                    rv = reductor(x)\n                else:\n                    reductor = getattr(x, \"__reduce_ex__\", None)\n                    if reductor:\n                        rv = reductor(2)\n                    else:\n                        reductor = getattr(x, \"__reduce__\", None)\n                        if reductor:\n                            rv = reductor()\n                        else:\n                            raise Error(\n                                \"un(deep)copyable object of type %s\" % cls)\n                y = _reconstruct(x, rv, 1, memo)\n\n    # If is its own copy, don't memoize.\n    if y is not x:\n        memo[d] = y\n        _keep_alive(x, memo) # Make sure x lives at least as long as d\n    return y\n\n_deepcopy_dispatch = d = {}\n\ndef _deepcopy_atomic(x, memo):\n    return x\nd[type(None)] = _deepcopy_atomic\nd[type(Ellipsis)] = _deepcopy_atomic\nd[int] = _deepcopy_atomic\nd[float] = _deepcopy_atomic\nd[bool] = _deepcopy_atomic\ntry:\n    d[complex] = _deepcopy_atomic\nexcept NameError:\n    pass\nd[bytes] = _deepcopy_atomic\nd[str] = _deepcopy_atomic\ntry:\n    d[types.CodeType] = _deepcopy_atomic\nexcept AttributeError:\n    pass\nd[type] = _deepcopy_atomic\nd[range] = _deepcopy_atomic\nd[types.BuiltinFunctionType] = _deepcopy_atomic\nd[types.FunctionType] = _deepcopy_atomic\nd[weakref.ref] = _deepcopy_atomic\n\ndef _deepcopy_list(x, memo):\n    y = []\n    memo[id(x)] = y\n    for a in x:\n        y.append(deepcopy(a, memo))\n    return y\nd[list] = _deepcopy_list\n\ndef _deepcopy_tuple(x, memo):\n    y = []\n    for a in x:\n        y.append(deepcopy(a, memo))\n    # We're not going to put the tuple in the memo, but it's still important we\n    # check for it, in case the tuple contains recursive mutable structures.\n    try:\n        return memo[id(x)]\n    except KeyError:\n        pass\n    for i in range(len(x)):\n        if x[i] is not y[i]:\n            y = tuple(y)\n            break\n    else:\n        y = x\n    return y\nd[tuple] = _deepcopy_tuple\n\ndef _deepcopy_dict(x, memo):\n    y = {}\n    memo[id(x)] = y\n    for key, value in x.items():\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    return y\nd[dict] = _deepcopy_dict\nif PyStringMap is not None:\n    d[PyStringMap] = _deepcopy_dict\n\ndef _deepcopy_method(x, memo): # Copy instance methods\n    return type(x)(x.__func__, deepcopy(x.__self__, memo))\n_deepcopy_dispatch[types.MethodType] = _deepcopy_method\n\ndef _keep_alive(x, memo):\n    \"\"\"Keeps a reference to the object x in the memo.\n\n    Because we remember objects by their id, we have\n    to assure that possibly temporary objects are kept\n    alive by referencing them.\n    We store a reference at the id of the memo, which should\n    normally not be used unless someone tries to deepcopy\n    the memo itself...\n    \"\"\"\n    try:\n        memo[id(memo)].append(x)\n    except KeyError:\n        # aha, this is the first one :-)\n        memo[id(memo)]=[x]\n\ndef _reconstruct(x, info, deep, memo=None):\n    if isinstance(info, str):\n        return x\n    assert isinstance(info, tuple)\n    if memo is None:\n        memo = {}\n    n = len(info)\n    assert n in (2, 3, 4, 5)\n    callable, args = info[:2]\n    if n > 2:\n        state = info[2]\n    else:\n        state = {}\n    if n > 3:\n        listiter = info[3]\n    else:\n        listiter = None\n    if n > 4:\n        dictiter = info[4]\n    else:\n        dictiter = None\n    if deep:\n        args = deepcopy(args, memo)\n    y = callable(*args)\n    memo[id(x)] = y\n\n    if state:\n        if deep:\n            state = deepcopy(state, memo)\n        if hasattr(y, '__setstate__'):\n            y.__setstate__(state)\n        else:\n            if isinstance(state, tuple) and len(state) == 2:\n                state, slotstate = state\n            else:\n                slotstate = None\n            if state is not None:\n                y.__dict__.update(state)\n            if slotstate is not None:\n                for key, value in slotstate.items():\n                    setattr(y, key, value)\n\n    if listiter is not None:\n        for item in listiter:\n            if deep:\n                item = deepcopy(item, memo)\n            y.append(item)\n    if dictiter is not None:\n        for key, value in dictiter:\n            if deep:\n                key = deepcopy(key, memo)\n                value = deepcopy(value, memo)\n            y[key] = value\n    return y\n\ndel d\n\ndel types\n\n# Helper for instance creation without calling __init__\nclass _EmptyClass:\n    pass\n"], "_sysconfigdata": [".py", "build_time_vars={'HAVE_SYS_WAIT_H': 1, 'HAVE_UTIL_H': 0, 'HAVE_SYMLINKAT': 1, 'HAVE_LIBSENDFILE': 0, 'SRCDIRS': 'Parser Grammar Objects Python Modules Mac', 'SIZEOF_OFF_T': 8, 'BASECFLAGS': '-Wno-unused-result', 'HAVE_UTIME_H': 1, 'EXTRAMACHDEPPATH': '', 'HAVE_SYS_TIME_H': 1, 'CFLAGSFORSHARED': '-fPIC', 'HAVE_HYPOT': 1, 'PGSRCS': '\\\\', 'HAVE_LIBUTIL_H': 0, 'HAVE_COMPUTED_GOTOS': 1, 'HAVE_LUTIMES': 1, 'HAVE_MAKEDEV': 1, 'HAVE_REALPATH': 1, 'HAVE_LINUX_TIPC_H': 1, 'MULTIARCH': 'i386-linux-gnu', 'HAVE_GETWD': 1, 'HAVE_GCC_ASM_FOR_X64': 0, 'HAVE_INET_PTON': 1, 'HAVE_GETHOSTBYNAME_R_6_ARG': 1, 'SIZEOF__BOOL': 1, 'HAVE_ZLIB_COPY': 1, 'ASDLGEN': 'python3.3 ../Parser/asdl_c.py', 'GRAMMAR_INPUT': '../Grammar/Grammar', 'HOST_GNU_TYPE': 'i686-pc-linux-gnu', 'HAVE_SCHED_RR_GET_INTERVAL': 1, 'HAVE_BLUETOOTH_H': 0, 'HAVE_MKFIFO': 1, 'TIMEMODULE_LIB': 0, 'LIBM': '-lm', 'PGENOBJS': '\\\\ \\\\', 'PYTHONFRAMEWORK': '', 'GETPGRP_HAVE_ARG': 0, 'HAVE_MMAP': 1, 'SHLIB_SUFFIX': '.so', 'SIZEOF_FLOAT': 4, 'HAVE_RENAMEAT': 1, 'HAVE_LANGINFO_H': 1, 'HAVE_STDLIB_H': 1, 'PY_CORE_CFLAGS': '-Wno-unused-result -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security   -I. -IInclude -I../Include -D_FORTIFY_SOURCE=2 -fPIC -DPy_BUILD_CORE', 'HAVE_BROKEN_PIPE_BUF': 0, 'HAVE_CONFSTR': 1, 'HAVE_SIGTIMEDWAIT': 1, 'HAVE_FTELLO': 1, 'READELF': 'readelf', 'HAVE_SIGALTSTACK': 1, 'TESTTIMEOUT': 3600, 'PYTHONPATH': ':plat-i386-linux-gnu', 'SIZEOF_WCHAR_T': 4, 'LIBOBJS': '', 'HAVE_SYSCONF': 1, 'MAKESETUP': '../Modules/makesetup', 'HAVE_UTIMENSAT': 1, 'HAVE_FCHOWNAT': 1, 'HAVE_WORKING_TZSET': 1, 'HAVE_FINITE': 1, 'HAVE_ASINH': 1, 'HAVE_SETEUID': 1, 'CONFIGFILES': 'configure configure.ac acconfig.h pyconfig.h.in Makefile.pre.in', 'HAVE_SETGROUPS': 1, 'PARSER_OBJS': '\\\\ Parser/myreadline.o Parser/parsetok.o Parser/tokenizer.o', 'HAVE_MBRTOWC': 1, 'SIZEOF_INT': 4, 'HAVE_STDARG_PROTOTYPES': 1, 'TM_IN_SYS_TIME': 0, 'HAVE_SYS_TIMES_H': 1, 'HAVE_LCHOWN': 1, 'HAVE_SSIZE_T': 1, 'HAVE_PAUSE': 1, 'SYSLIBS': '-lm', 'POSIX_SEMAPHORES_NOT_ENABLED': 0, 'HAVE_DEVICE_MACROS': 1, 'BLDSHARED': 'i686-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wno-unused-result -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security  ', 'LIBSUBDIRS': 'tkinter tkinter/test tkinter/test/test_tkinter \\\\', 'HAVE_SYS_UN_H': 1, 'HAVE_SYS_STAT_H': 1, 'VPATH': '..', 'INCLDIRSTOMAKE': '/usr/include /usr/include /usr/include/python3.3m /usr/include/python3.3m', 'HAVE_BROKEN_SEM_GETVALUE': 0, 'HAVE_TIMEGM': 1, 'PACKAGE_VERSION': 0, 'MAJOR_IN_SYSMACROS': 0, 'HAVE_ATANH': 1, 'HAVE_GAI_STRERROR': 1, 'HAVE_SYS_POLL_H': 1, 'SIZEOF_PTHREAD_T': 4, 'SIZEOF_FPOS_T': 16, 'HAVE_CTERMID': 1, 'HAVE_TMPFILE': 1, 'HAVE_SETUID': 1, 'CXX': 'i686-linux-gnu-g++ -pthread', 'srcdir': '..', 'HAVE_UINT32_T': 1, 'HAVE_ADDRINFO': 1, 'HAVE_GETSPENT': 1, 'SIZEOF_DOUBLE': 8, 'HAVE_INT32_T': 1, 'LIBRARY_OBJS_OMIT_FROZEN': '\\\\', 'HAVE_FUTIMES': 1, 'CONFINCLUDEPY': '/usr/include/python3.3m', 'HAVE_RL_COMPLETION_APPEND_CHARACTER': 1, 'LIBFFI_INCLUDEDIR': '', 'HAVE_SETGID': 1, 'HAVE_UINT64_T': 1, 'EXEMODE': 755, 'UNIVERSALSDK': '', 'HAVE_LIBDL': 1, 'HAVE_GETNAMEINFO': 1, 'HAVE_STDINT_H': 1, 'COREPYTHONPATH': ':plat-i386-linux-gnu', 'HAVE_SOCKADDR_STORAGE': 1, 'HAVE_WAITID': 1, 'EXTRAPLATDIR': '@EXTRAPLATDIR@', 'HAVE_ACCEPT4': 1, 'RUNSHARED': 'LD_LIBRARY_PATH=/build/buildd/python3.3-3.3.1/build-shared:', 'EXE': '', 'HAVE_SIGACTION': 1, 'HAVE_CHOWN': 1, 'HAVE_GETLOGIN': 1, 'HAVE_TZNAME': 0, 'PACKAGE_NAME': 0, 'HAVE_GETPGID': 1, 'HAVE_GLIBC_MEMMOVE_BUG': 0, 'BUILD_GNU_TYPE': 'i686-pc-linux-gnu', 'HAVE_LINUX_CAN_H': 1, 'DYNLOADFILE': 'dynload_shlib.o', 'HAVE_PWRITE': 1, 'BUILDEXE': '', 'HAVE_OPENPTY': 1, 'HAVE_LOCKF': 1, 'HAVE_COPYSIGN': 1, 'HAVE_PREAD': 1, 'HAVE_DLOPEN': 1, 'HAVE_SYS_KERN_CONTROL_H': 0, 'PY_FORMAT_LONG_LONG': '\"ll\"', 'HAVE_TCSETPGRP': 1, 'HAVE_SETSID': 1, 'HAVE_STRUCT_STAT_ST_BIRTHTIME': 0, 'HAVE_STRING_H': 1, 'LDLIBRARY': 'libpython3.3m.so', 'INSTALL_SCRIPT': '/usr/bin/install -c', 'HAVE_SYS_XATTR_H': 1, 'HAVE_CURSES_IS_TERM_RESIZED': 1, 'HAVE_TMPNAM_R': 1, 'STRICT_SYSV_CURSES': \"/* Don't use ncurses extensions */\", 'WANT_SIGFPE_HANDLER': 1, 'HAVE_INT64_T': 1, 'HAVE_STAT_TV_NSEC': 1, 'HAVE_SYS_MKDEV_H': 0, 'HAVE_BROKEN_POLL': 0, 'HAVE_IF_NAMEINDEX': 1, 'HAVE_GETPWENT': 1, 'PSRCS': '\\\\', 'RANLIB': 'ranlib', 'HAVE_WCSCOLL': 1, 'WITH_NEXT_FRAMEWORK': 0, 'ASDLGEN_FILES': '../Parser/asdl.py ../Parser/asdl_c.py', 'HAVE_RL_PRE_INPUT_HOOK': 1, 'PACKAGE_URL': 0, 'SHLIB_EXT': 0, 'HAVE_SYS_LOADAVG_H': 0, 'HAVE_LIBIEEE': 0, 'HAVE_SEM_OPEN': 1, 'HAVE_TERM_H': 1, 'IO_OBJS': '\\\\', 'IO_H': 'Modules/_io/_iomodule.h', 'HAVE_STATVFS': 1, 'VERSION': '3.3', 'HAVE_GETC_UNLOCKED': 1, 'MACHDEPS': 'plat-i386-linux-gnu @EXTRAPLATDIR@', 'SUBDIRSTOO': 'Include Lib Misc', 'HAVE_SETREUID': 1, 'HAVE_ERFC': 1, 'HAVE_SETRESUID': 1, 'LINKFORSHARED': '-Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions', 'HAVE_SYS_TYPES_H': 1, 'HAVE_GETPAGESIZE': 1, 'HAVE_SETEGID': 1, 'HAVE_PTY_H': 1, 'HAVE_STRUCT_STAT_ST_FLAGS': 0, 'HAVE_WCHAR_H': 1, 'HAVE_FSEEKO': 1, 'Py_ENABLE_SHARED': 1, 'HAVE_SIGRELSE': 1, 'HAVE_PTHREAD_INIT': 0, 'FILEMODE': 644, 'HAVE_SYS_RESOURCE_H': 1, 'HAVE_READLINKAT': 1, 'PYLONG_BITS_IN_DIGIT': 0, 'LINKCC': 'i686-linux-gnu-gcc -pthread', 'HAVE_SETLOCALE': 1, 'HAVE_CHROOT': 1, 'HAVE_OPENAT': 1, 'HAVE_FEXECVE': 1, 'LDCXXSHARED': 'i686-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions', 'DIST': 'README ChangeLog configure configure.ac acconfig.h pyconfig.h.in Makefile.pre.in Include Lib Misc Ext-dummy', 'HAVE_MKNOD': 1, 'PY_LDFLAGS': '-Wl,-Bsymbolic-functions -Wl,-z,relro', 'HAVE_BROKEN_MBSTOWCS': 0, 'LIBRARY_OBJS': '\\\\', 'HAVE_LOG1P': 1, 'SIZEOF_VOID_P': 4, 'HAVE_FCHOWN': 1, 'PYTHONFRAMEWORKPREFIX': '', 'HAVE_LIBDLD': 0, 'HAVE_TGAMMA': 1, 'HAVE_ERRNO_H': 1, 'HAVE_IO_H': 0, 'OTHER_LIBTOOL_OPT': '', 'HAVE_POLL_H': 1, 'PY_CPPFLAGS': '-I. -IInclude -I../Include -D_FORTIFY_SOURCE=2', 'XMLLIBSUBDIRS': 'xml xml/dom xml/etree xml/parsers xml/sax', 'GRAMMAR_H': 'Include/graminit.h', 'TANH_PRESERVES_ZERO_SIGN': 1, 'HAVE_GETLOADAVG': 1, 'UNICODE_DEPS': '\\\\ \\\\', 'HAVE_GETCWD': 1, 'MANDIR': '/usr/share/man', 'MACHDESTLIB': '/usr/lib/python3.3', 'GRAMMAR_C': 'Python/graminit.c', 'PGOBJS': '\\\\', 'HAVE_DEV_PTMX': 1, 'HAVE_UINTPTR_T': 1, 'HAVE_SCHED_SETAFFINITY': 1, 'PURIFY': '', 'HAVE_DECL_ISINF': 1, 'HAVE_RL_CALLBACK': 1, 'HAVE_WRITEV': 1, 'HAVE_GETHOSTBYNAME_R_5_ARG': 0, 'HAVE_SYS_AUDIOIO_H': 0, 'EXT_SUFFIX': '.cpython-33m.so', 'SIZEOF_LONG_LONG': 8, 'DLINCLDIR': '.', 'HAVE_PATHCONF': 1, 'HAVE_UNLINKAT': 1, 'MKDIR_P': '/bin/mkdir -p', 'HAVE_ALTZONE': 0, 'SCRIPTDIR': '/usr/lib', 'OPCODETARGETGEN_FILES': '\\\\', 'HAVE_GETSPNAM': 1, 'HAVE_SYS_TERMIO_H': 0, 'HAVE_ATTRIBUTE_FORMAT_PARSETUPLE': 0, 'HAVE_PTHREAD_H': 1, 'Py_DEBUG': 0, 'HAVE_STRUCT_STAT_ST_BLOCKS': 1, 'X87_DOUBLE_ROUNDING': 1, 'SIZEOF_TIME_T': 4, 'HAVE_DYNAMIC_LOADING': 1, 'HAVE_DIRECT_H': 0, 'SRC_GDB_HOOKS': '../Tools/gdb/libpython.py', 'HAVE_GETADDRINFO': 1, 'HAVE_BROKEN_NICE': 0, 'HAVE_DIRENT_H': 1, 'HAVE_WCSXFRM': 1, 'HAVE_RL_COMPLETION_DISPLAY_MATCHES_HOOK': 1, 'HAVE_FSTATVFS': 1, 'PYTHON': 'python', 'HAVE_OSX105_SDK': 0, 'BINDIR': '/usr/bin', 'TESTPYTHON': 'LD_LIBRARY_PATH=/build/buildd/python3.3-3.3.1/build-shared: ./python', 'ARFLAGS': 'rc', 'PLATDIR': 'plat-i386-linux-gnu', 'HAVE_ASM_TYPES_H': 1, 'PY3LIBRARY': 'libpython3.so', 'HAVE_PLOCK': 0, 'FLOCK_NEEDS_LIBBSD': 0, 'WITH_TSC': 0, 'HAVE_LIBREADLINE': 1, 'MACHDEP': 'linux', 'HAVE_SELECT': 1, 'LDFLAGS': '-Wl,-Bsymbolic-functions -Wl,-z,relro', 'HAVE_HSTRERROR': 1, 'SOABI': 'cpython-33m', 'HAVE_GETTIMEOFDAY': 1, 'HAVE_LIBRESOLV': 0, 'HAVE_UNSETENV': 1, 'HAVE_TM_ZONE': 1, 'HAVE_GETPGRP': 1, 'HAVE_FLOCK': 1, 'HAVE_SYS_BSDTTY_H': 0, 'SUBDIRS': '', 'PYTHONFRAMEWORKINSTALLDIR': '', 'PACKAGE_BUGREPORT': 0, 'HAVE_CLOCK': 1, 'HAVE_GETPEERNAME': 1, 'SIZEOF_PID_T': 4, 'HAVE_CONIO_H': 0, 'HAVE_FSTATAT': 1, 'HAVE_NETPACKET_PACKET_H': 1, 'HAVE_WAIT3': 1, 'DESTPATH': '', 'HAVE_STAT_TV_NSEC2': 0, 'HAVE_GETRESGID': 1, 'HAVE_UCS4_TCL': 0, 'SIGNED_RIGHT_SHIFT_ZERO_FILLS': 0, 'HAVE_TIMES': 1, 'HAVE_UNAME': 1, 'HAVE_ERF': 1, 'SIZEOF_SHORT': 2, 'HAVE_NCURSES_H': 1, 'HAVE_SYS_SENDFILE_H': 1, 'HAVE_CTERMID_R': 0, 'HAVE_TMPNAM': 1, 'prefix': '/usr', 'HAVE_NICE': 1, 'WITH_THREAD': 1, 'LN': 'ln', 'TESTRUNNER': 'LD_LIBRARY_PATH=/build/buildd/python3.3-3.3.1/build-shared: ./python ../Tools/scripts/run_tests.py', 'HAVE_SIGINTERRUPT': 1, 'HAVE_SETPGID': 1, 'RETSIGTYPE': 'void', 'HAVE_SCHED_GET_PRIORITY_MAX': 1, 'HAVE_SYS_SYS_DOMAIN_H': 0, 'HAVE_SYS_DIR_H': 0, 'HAVE__GETPTY': 0, 'HAVE_BLUETOOTH_BLUETOOTH_H': 1, 'HAVE_BIND_TEXTDOMAIN_CODESET': 1, 'HAVE_POLL': 1, 'PYTHON_OBJS': '\\\\', 'HAVE_WAITPID': 1, 'USE_INLINE': 1, 'HAVE_FUTIMENS': 1, 'USE_COMPUTED_GOTOS': 1, 'MAINCC': 'i686-linux-gnu-gcc -pthread', 'HAVE_SOCKETPAIR': 1, 'HAVE_PROCESS_H': 0, 'HAVE_SETVBUF': 1, 'HAVE_FDOPENDIR': 1, 'CONFINCLUDEDIR': '/usr/include', 'BINLIBDEST': '/usr/lib/python3.3', 'HAVE_SYS_IOCTL_H': 1, 'HAVE_SYSEXITS_H': 1, 'LDLAST': '', 'HAVE_SYS_FILE_H': 1, 'HAVE_RL_COMPLETION_SUPPRESS_APPEND': 1, 'HAVE_RL_COMPLETION_MATCHES': 1, 'HAVE_TCGETPGRP': 1, 'SIZEOF_SIZE_T': 4, 'HAVE_EPOLL_CREATE1': 1, 'HAVE_SYS_SELECT_H': 1, 'HAVE_CLOCK_GETTIME': 1, 'CFLAGS': '-Wno-unused-result -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security  ', 'HAVE_SNPRINTF': 1, 'BLDLIBRARY': '-lpython3.3m', 'PARSER_HEADERS': '\\\\', 'SO': '.so', 'LIBRARY': 'libpython3.3m.a', 'HAVE_FPATHCONF': 1, 'HAVE_TERMIOS_H': 1, 'HAVE_BROKEN_PTHREAD_SIGMASK': 0, 'AST_H': 'Include/Python-ast.h', 'HAVE_GCC_UINT128_T': 0, 'HAVE_ACOSH': 1, 'MODOBJS': 'Modules/_threadmodule.o  Modules/signalmodule.o  Modules/arraymodule.o  Modules/mathmodule.o Modules/_math.o  Modules/_struct.o  Modules/timemodule.o  Modules/_randommodule.o  Modules/atexitmodule.o  Modules/_elementtree.o  Modules/_pickle.o  Modules/_datetimemodule.o  Modules/_bisectmodule.o  Modules/_heapqmodule.o  Modules/unicodedata.o  Modules/fcntlmodule.o  Modules/spwdmodule.o  Modules/grpmodule.o  Modules/selectmodule.o  Modules/socketmodule.o  Modules/_posixsubprocess.o  Modules/md5module.o  Modules/sha1module.o  Modules/sha256module.o  Modules/sha512module.o  Modules/syslogmodule.o  Modules/binascii.o  Modules/zlibmodule.o  Modules/pyexpat.o  Modules/posixmodule.o  Modules/errnomodule.o  Modules/pwdmodule.o  Modules/_sre.o  Modules/_codecsmodule.o  Modules/_weakref.o  Modules/_functoolsmodule.o  Modules/operator.o  Modules/_collectionsmodule.o  Modules/itertoolsmodule.o  Modules/_localemodule.o  Modules/_iomodule.o Modules/iobase.o Modules/fileio.o Modules/bytesio.o Modules/bufferedio.o Modules/textio.o Modules/stringio.o  Modules/zipimport.o  Modules/faulthandler.o  Modules/symtablemodule.o  Modules/xxsubtype.o', 'AST_C': 'Python/Python-ast.c', 'HAVE_SYS_NDIR_H': 0, 'DESTDIRS': '/usr /usr/lib /usr/lib/python3.3 /usr/lib/python3.3/lib-dynload', 'HAVE_SIGNAL_H': 1, 'PACKAGE_TARNAME': 0, 'HAVE_GETPRIORITY': 1, 'INCLUDEDIR': '/usr/include', 'HAVE_INTTYPES_H': 1, 'SIGNAL_OBJS': '', 'HAVE_READV': 1, 'HAVE_SETHOSTNAME': 1, 'MODLIBS': '-lrt    -lexpat                   -L/usr/lib -lz  -lexpat', 'CC': 'i686-linux-gnu-gcc -pthread', 'HAVE_LCHMOD': 0, 'SIZEOF_UINTPTR_T': 4, 'LIBPC': '/usr/lib/i386-linux-gnu/pkgconfig', 'BYTESTR_DEPS': '\\\\', 'HAVE_MKDIRAT': 1, 'LIBPL': '/usr/lib/python3.3/config-3.3m-i386-linux-gnu', 'HAVE_SHADOW_H': 1, 'HAVE_SYS_EVENT_H': 0, 'INSTALL': '/usr/bin/install -c', 'HAVE_GCC_ASM_FOR_X87': 1, 'HAVE_BROKEN_UNSETENV': 0, 'BASECPPFLAGS': '', 'DOUBLE_IS_BIG_ENDIAN_IEEE754': 0, 'HAVE_STRUCT_STAT_ST_RDEV': 1, 'HAVE_SEM_UNLINK': 1, 'BUILDPYTHON': 'python', 'HAVE_RL_CATCH_SIGNAL': 1, 'HAVE_DECL_TZNAME': 0, 'RESSRCDIR': 'Mac/Resources/framework', 'HAVE_PTHREAD_SIGMASK': 1, 'HAVE_UTIMES': 1, 'DISTDIRS': 'Include Lib Misc Ext-dummy', 'HAVE_FDATASYNC': 1, 'HAVE_USABLE_WCHAR_T': 0, 'PY_FORMAT_SIZE_T': '\"z\"', 'HAVE_SCHED_SETSCHEDULER': 1, 'VA_LIST_IS_ARRAY': 0, 'HAVE_LINUX_NETLINK_H': 1, 'HAVE_SETREGID': 1, 'HAVE_STROPTS_H': 1, 'LDVERSION': '3.3m', 'abs_builddir': '/build/buildd/python3.3-3.3.1/build-shared', 'SITEPATH': '', 'HAVE_GETHOSTBYNAME': 0, 'HAVE_SIGPENDING': 1, 'HAVE_KQUEUE': 0, 'HAVE_SYNC': 1, 'HAVE_GETSID': 1, 'HAVE_ROUND': 1, 'HAVE_STRFTIME': 1, 'AST_H_DIR': 'Include', 'HAVE_PIPE2': 1, 'AST_C_DIR': 'Python', 'TESTPYTHONOPTS': '', 'HAVE_DEV_PTC': 0, 'GETTIMEOFDAY_NO_TZ': 0, 'HAVE_NET_IF_H': 1, 'HAVE_SENDFILE': 1, 'HAVE_SETPGRP': 1, 'HAVE_SEM_GETVALUE': 1, 'CONFIGURE_LDFLAGS': '-Wl,-Bsymbolic-functions -Wl,-z,relro', 'DLLLIBRARY': '', 'PYTHON_FOR_BUILD': './python -E', 'SETPGRP_HAVE_ARG': 0, 'HAVE_INET_ATON': 1, 'INSTALL_SHARED': '/usr/bin/install -c -m 555', 'WITH_DOC_STRINGS': 1, 'OPCODETARGETS_H': '\\\\', 'HAVE_INITGROUPS': 1, 'HAVE_LINKAT': 1, 'BASEMODLIBS': '', 'SGI_ABI': '', 'HAVE_SCHED_SETPARAM': 1, 'OPT': '-DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes', 'HAVE_POSIX_FADVISE': 1, 'datarootdir': '/usr/share', 'HAVE_MEMRCHR': 1, 'HGTAG': '', 'HAVE_MEMMOVE': 1, 'HAVE_GETRESUID': 1, 'DOUBLE_IS_ARM_MIXED_ENDIAN_IEEE754': 0, 'HAVE_LSTAT': 1, 'AR': 'ar', 'HAVE_WAIT4': 1, 'HAVE_SYS_MODEM_H': 0, 'INSTSONAME': 'libpython3.3m.so.1.0', 'HAVE_SYS_STATVFS_H': 1, 'HAVE_LGAMMA': 1, 'HAVE_PROTOTYPES': 1, 'HAVE_SYS_UIO_H': 1, 'MAJOR_IN_MKDEV': 0, 'QUICKTESTOPTS': '-x test_subprocess test_io test_lib2to3 \\\\', 'HAVE_SYS_DEVPOLL_H': 0, 'HAVE_CHFLAGS': 0, 'HAVE_FSYNC': 1, 'HAVE_FCHMOD': 1, 'INCLUDEPY': '/usr/include/python3.3m', 'HAVE_SEM_TIMEDWAIT': 1, 'LDLIBRARYDIR': '', 'HAVE_STRUCT_TM_TM_ZONE': 1, 'HAVE_CURSES_H': 1, 'TIME_WITH_SYS_TIME': 1, 'HAVE_DUP2': 1, 'ENABLE_IPV6': 1, 'WITH_VALGRIND': 0, 'HAVE_SETITIMER': 1, 'THREADOBJ': 'Python/thread.o', 'LOCALMODLIBS': '-lrt    -lexpat                   -L/usr/lib -lz  -lexpat', 'HAVE_MEMORY_H': 1, 'HAVE_GETITIMER': 1, 'HAVE_C99_BOOL': 1, 'INSTALL_DATA': '/usr/bin/install -c -m 644', 'PGEN': 'Parser/pgen', 'HAVE_GRP_H': 1, 'HAVE_WCSFTIME': 1, 'AIX_GENUINE_CPLUSPLUS': 0, 'HAVE_LIBINTL_H': 1, 'SHELL': '/bin/sh', 'HAVE_UNISTD_H': 1, 'EXTRATESTOPTS': '', 'HAVE_EXECV': 1, 'HAVE_FSEEK64': 0, 'MVWDELCH_IS_EXPRESSION': 1, 'DESTSHARED': '/usr/lib/python3.3/lib-dynload', 'OPCODETARGETGEN': '\\\\', 'LIBDEST': '/usr/lib/python3.3', 'CCSHARED': '-fPIC', 'HAVE_EXPM1': 1, 'HAVE_DLFCN_H': 1, 'exec_prefix': '/usr', 'HAVE_READLINK': 1, 'WINDOW_HAS_FLAGS': 1, 'HAVE_FTELL64': 0, 'HAVE_STRLCPY': 0, 'MACOSX_DEPLOYMENT_TARGET': '', 'HAVE_SYS_SYSCALL_H': 1, 'DESTLIB': '/usr/lib/python3.3', 'LDSHARED': 'i686-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wno-unused-result -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security  ', 'HGVERSION': '', 'PYTHON_HEADERS': '\\\\', 'HAVE_STRINGS_H': 1, 'DOUBLE_IS_LITTLE_ENDIAN_IEEE754': 1, 'HAVE_POSIX_FALLOCATE': 1, 'HAVE_DIRFD': 1, 'HAVE_LOG2': 1, 'HAVE_GETPID': 1, 'HAVE_ALARM': 1, 'MACHDEP_OBJS': '', 'HAVE_SPAWN_H': 1, 'HAVE_FORK': 1, 'HAVE_SETRESGID': 1, 'HAVE_FCHMODAT': 1, 'HAVE_CLOCK_GETRES': 1, 'MACHDEPPATH': ':plat-i386-linux-gnu', 'STDC_HEADERS': 1, 'HAVE_SETPRIORITY': 1, 'LIBC': '', 'HAVE_SYS_EPOLL_H': 1, 'HAVE_SYS_UTSNAME_H': 1, 'HAVE_PUTENV': 1, 'HAVE_CURSES_RESIZE_TERM': 1, 'HAVE_FUTIMESAT': 1, 'WITH_DYLD': 0, 'INSTALL_PROGRAM': '/usr/bin/install -c', 'LIBS': '-lpthread -ldl  -lutil', 'HAVE_TRUNCATE': 1, 'TESTOPTS': '', 'PROFILE_TASK': '../Tools/pybench/pybench.py -n 2 --with-gc --with-syscheck', 'HAVE_CURSES_RESIZETERM': 1, 'ABIFLAGS': 'm', 'HAVE_GETGROUPLIST': 1, 'OBJECT_OBJS': '\\\\', 'HAVE_MKNODAT': 1, 'HAVE_ST_BLOCKS': 1, 'HAVE_STRUCT_STAT_ST_GEN': 0, 'SYS_SELECT_WITH_SYS_TIME': 1, 'SHLIBS': '-lpthread -ldl  -lutil', 'HAVE_GETGROUPS': 1, 'MODULE_OBJS': '\\\\', 'PYTHONFRAMEWORKDIR': 'no-framework', 'HAVE_FCNTL_H': 1, 'HAVE_LINK': 1, 'HAVE_SIGWAIT': 1, 'HAVE_GAMMA': 1, 'HAVE_SYS_LOCK_H': 0, 'HAVE_FORKPTY': 1, 'HAVE_SOCKADDR_SA_LEN': 0, 'HAVE_TEMPNAM': 1, 'HAVE_STRUCT_STAT_ST_BLKSIZE': 1, 'HAVE_MKFIFOAT': 1, 'HAVE_SIGWAITINFO': 1, 'HAVE_FTIME': 1, 'HAVE_EPOLL': 1, 'HAVE_SYS_SOCKET_H': 1, 'HAVE_LARGEFILE_SUPPORT': 1, 'CONFIGURE_CFLAGS': '-g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security', 'HAVE_PTHREAD_DESTRUCTOR': 0, 'CONFIGURE_CPPFLAGS': '-D_FORTIFY_SOURCE=2', 'HAVE_SYMLINK': 1, 'HAVE_LONG_LONG': 1, 'HAVE_IEEEFP_H': 0, 'LIBDIR': '/usr/lib', 'HAVE_PTHREAD_KILL': 1, 'TESTPATH': '', 'HAVE_STRDUP': 1, 'POBJS': '\\\\', 'NO_AS_NEEDED': '-Wl,--no-as-needed', 'HAVE_LONG_DOUBLE': 1, 'HGBRANCH': '', 'DISTFILES': 'README ChangeLog configure configure.ac acconfig.h pyconfig.h.in Makefile.pre.in', 'PTHREAD_SYSTEM_SCHED_SUPPORTED': 1, 'HAVE_FACCESSAT': 1, 'AST_ASDL': '../Parser/Python.asdl', 'CPPFLAGS': '-I. -IInclude -I../Include -D_FORTIFY_SOURCE=2', 'HAVE_MKTIME': 1, 'HAVE_NDIR_H': 0, 'PY_CFLAGS': '-Wno-unused-result -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security  ', 'LIBOBJDIR': 'Python/', 'HAVE_LINUX_CAN_RAW_H': 1, 'HAVE_GETHOSTBYNAME_R_3_ARG': 0, 'PACKAGE_STRING': 0, 'GNULD': 'yes', 'LOG1P_DROPS_ZERO_SIGN': 0, 'HAVE_FTRUNCATE': 1, 'WITH_LIBINTL': 0, 'HAVE_MREMAP': 1, 'HAVE_DECL_ISNAN': 1, 'HAVE_KILLPG': 1, 'SIZEOF_LONG': 4, 'HAVE_DECL_ISFINITE': 1, 'HAVE_IPA_PURE_CONST_BUG': 0, 'WITH_PYMALLOC': 1, 'abs_srcdir': '/build/buildd/python3.3-3.3.1/build-shared/..', 'HAVE_FCHDIR': 1, 'HAVE_BROKEN_POSIX_SEMAPHORES': 0, 'AC_APPLE_UNIVERSAL_BUILD': 0, 'PGENSRCS': '\\\\ \\\\', 'DIRMODE': 755, 'HAVE_GETHOSTBYNAME_R': 1, 'HAVE_LCHFLAGS': 0, 'HAVE_SYS_PARAM_H': 1, 'SIZEOF_LONG_DOUBLE': 12, 'CONFIG_ARGS': \"'--enable-shared' '--prefix=/usr' '--enable-ipv6' '--enable-loadable-sqlite-extensions' '--with-dbmliborder=bdb:gdbm' '--with-computed-gotos' '--with-system-expat' '--with-system-ffi' '--with-fpectl' 'CC=i686-linux-gnu-gcc' 'CFLAGS=-g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security ' 'LDFLAGS=-Wl,-Bsymbolic-functions -Wl,-z,relro' 'CPPFLAGS=-D_FORTIFY_SOURCE=2'\", 'HAVE_SCHED_H': 1, 'HAVE_KILL': 1}\n\n"], "_struct": [".py", "#\n# This module is a pure Python version of pypy.module.struct.\n# It is only imported if the vastly faster pypy.module.struct is not\n# compiled in.  For now we keep this version for reference and\n# because pypy.module.struct is not ootype-backend-friendly yet.\n#\n\n# this module 'borrowed' from \n# https://bitbucket.org/pypy/pypy/src/18626459a9b2/lib_pypy/_struct.py?at=py3k-listview_str\n\n\"\"\"Functions to convert between Python values and C structs.\nPython strings are used to hold the data representing the C struct\nand also as format strings to describe the layout of data in the C struct.\n\nThe optional first format char indicates byte order, size and alignment:\n @: native order, size & alignment (default)\n =: native order, std. size & alignment\n <: little-endian, std. size & alignment\n >: big-endian, std. size & alignment\n !: same as >\n\nThe remaining chars indicate types of args and must match exactly;\nthese can be preceded by a decimal repeat count:\n   x: pad byte (no data);\n   c:char;\n   b:signed byte;\n   B:unsigned byte;\n   h:short;\n   H:unsigned short;\n   i:int;\n   I:unsigned int;\n   l:long;\n   L:unsigned long;\n   f:float;\n   d:double.\nSpecial cases (preceding decimal count indicates length):\n   s:string (array of char); p: pascal string (with count byte).\nSpecial case (only available in native format):\n   P:an integer type that is wide enough to hold a pointer.\nSpecial case (not in native mode unless 'long long' in platform C):\n   q:long long;\n   Q:unsigned long long\nWhitespace between formats is ignored.\n\nThe variable struct.error is an exception raised on errors.\"\"\"\n\nimport math, sys\n\n# TODO: XXX Find a way to get information on native sizes and alignments\nclass StructError(Exception):\n    pass\nerror = StructError\ndef unpack_int(data,index,size,le):\n    bytes = [b for b in data[index:index+size]]\n    if le == 'little':\n        bytes.reverse()\n    number = 0\n    for b in bytes:\n        number = number << 8 | b\n    return int(number)\n\ndef unpack_signed_int(data,index,size,le):\n    number = unpack_int(data,index,size,le)\n    max = 2**(size*8)\n    if number > 2**(size*8 - 1) - 1:\n        number = int(-1*(max - number))\n    return number\n\nINFINITY = 1e200 * 1e200\nNAN = INFINITY / INFINITY\n\ndef unpack_char(data,index,size,le):\n    return data[index:index+size]\n\ndef pack_int(number,size,le):\n    x=number\n    res=[]\n    for i in range(size):\n        res.append(x&0xff)\n        x >>= 8\n    if le == 'big':\n        res.reverse()\n    return bytes(res)\n\ndef pack_signed_int(number,size,le):\n    if not isinstance(number, int):\n        raise StructError(\"argument for i,I,l,L,q,Q,h,H must be integer\")\n    if  number > 2**(8*size-1)-1 or number < -1*2**(8*size-1):\n        raise OverflowError(\"Number:%i too large to convert\" % number)\n    return pack_int(number,size,le)\n\ndef pack_unsigned_int(number,size,le):\n    if not isinstance(number, int):\n        raise StructError(\"argument for i,I,l,L,q,Q,h,H must be integer\")\n    if number < 0:\n        raise TypeError(\"can't convert negative long to unsigned\")\n    if number > 2**(8*size)-1:\n        raise OverflowError(\"Number:%i too large to convert\" % number)\n    return pack_int(number,size,le)\n\ndef pack_char(char,size,le):\n    return bytes(char)\n\ndef isinf(x):\n    return x != 0.0 and x / 2 == x\ndef isnan(v):\n    return v != v*1.0 or (v == 1.0 and v == 2.0)\n\ndef pack_float(x, size, le):\n    unsigned = float_pack(x, size)\n    result = []\n    for i in range(8):\n        result.append((unsigned >> (i * 8)) & 0xFF)\n    if le == \"big\":\n        result.reverse()\n    return bytes(result)\n\ndef unpack_float(data, index, size, le):\n    binary = [data[i] for i in range(index, index + 8)]\n    if le == \"big\":\n        binary.reverse()\n    unsigned = 0\n    for i in range(8):\n        unsigned |= binary[i] << (i * 8)\n    return float_unpack(unsigned, size, le)\n\ndef round_to_nearest(x):\n    \"\"\"Python 3 style round:  round a float x to the nearest int, but\n    unlike the builtin Python 2.x round function:\n\n      - return an int, not a float\n      - do round-half-to-even, not round-half-away-from-zero.\n\n    We assume that x is finite and nonnegative; except wrong results\n    if you use this for negative x.\n\n    \"\"\"\n    int_part = int(x)\n    frac_part = x - int_part\n    if frac_part > 0.5 or frac_part == 0.5 and int_part & 1 == 1:\n        int_part += 1\n    return int_part\n\ndef float_unpack(Q, size, le):\n    \"\"\"Convert a 32-bit or 64-bit integer created\n    by float_pack into a Python float.\"\"\"\n\n    if size == 8:\n        MIN_EXP = -1021  # = sys.float_info.min_exp\n        MAX_EXP = 1024   # = sys.float_info.max_exp\n        MANT_DIG = 53    # = sys.float_info.mant_dig\n        BITS = 64\n    elif size == 4:\n        MIN_EXP = -125   # C's FLT_MIN_EXP\n        MAX_EXP = 128    # FLT_MAX_EXP\n        MANT_DIG = 24    # FLT_MANT_DIG\n        BITS = 32\n    else:\n        raise ValueError(\"invalid size value\")\n\n    if Q >> BITS:\n         raise ValueError(\"input out of range\")\n\n    # extract pieces\n    sign = Q >> BITS - 1\n    exp = (Q & ((1 << BITS - 1) - (1 << MANT_DIG - 1))) >> MANT_DIG - 1\n    mant = Q & ((1 << MANT_DIG - 1) - 1)\n\n    if exp == MAX_EXP - MIN_EXP + 2:\n        # nan or infinity\n        result = float('nan') if mant else float('inf')\n    elif exp == 0:\n        # subnormal or zero\n        result = math.ldexp(float(mant), MIN_EXP - MANT_DIG)\n    else:\n        # normal\n        mant += 1 << MANT_DIG - 1\n        result = math.ldexp(float(mant), exp + MIN_EXP - MANT_DIG - 1)\n    return -result if sign else result\n\n\ndef float_pack(x, size):\n    \"\"\"Convert a Python float x into a 64-bit unsigned integer\n    with the same byte representation.\"\"\"\n\n    if size == 8:\n        MIN_EXP = -1021  # = sys.float_info.min_exp\n        MAX_EXP = 1024   # = sys.float_info.max_exp\n        MANT_DIG = 53    # = sys.float_info.mant_dig\n        BITS = 64\n    elif size == 4:\n        MIN_EXP = -125   # C's FLT_MIN_EXP\n        MAX_EXP = 128    # FLT_MAX_EXP\n        MANT_DIG = 24    # FLT_MANT_DIG\n        BITS = 32\n    else:\n        raise ValueError(\"invalid size value\")\n\n    sign = math.copysign(1.0, x) < 0.0\n    if math.isinf(x):\n        mant = 0\n        exp = MAX_EXP - MIN_EXP + 2\n    elif math.isnan(x):\n        mant = 1 << (MANT_DIG-2) # other values possible\n        exp = MAX_EXP - MIN_EXP + 2\n    elif x == 0.0:\n        mant = 0\n        exp = 0\n    else:\n        m, e = math.frexp(abs(x))  # abs(x) == m * 2**e\n        exp = e - (MIN_EXP - 1)\n        if exp > 0:\n            # Normal case.\n            mant = round_to_nearest(m * (1 << MANT_DIG))\n            mant -= 1 << MANT_DIG - 1\n        else:\n            # Subnormal case.\n            if exp + MANT_DIG - 1 >= 0:\n                mant = round_to_nearest(m * (1 << exp + MANT_DIG - 1))\n            else:\n                mant = 0\n            exp = 0\n\n        # Special case: rounding produced a MANT_DIG-bit mantissa.\n        assert 0 <= mant <= 1 << MANT_DIG - 1\n        if mant == 1 << MANT_DIG - 1:\n            mant = 0\n            exp += 1\n\n        # Raise on overflow (in some circumstances, may want to return\n        # infinity instead).\n        if exp >= MAX_EXP - MIN_EXP + 2:\n             raise OverflowError(\"float too large to pack in this format\")\n\n    # check constraints\n    assert 0 <= mant < 1 << MANT_DIG - 1\n    assert 0 <= exp <= MAX_EXP - MIN_EXP + 2\n    assert 0 <= sign <= 1\n    return ((sign << BITS - 1) | (exp << MANT_DIG - 1)) | mant\n\n\nbig_endian_format = {\n    'x':{ 'size' : 1, 'alignment' : 0, 'pack' : None, 'unpack' : None},\n    'b':{ 'size' : 1, 'alignment' : 0, 'pack' : pack_signed_int, 'unpack' : unpack_signed_int},\n    'B':{ 'size' : 1, 'alignment' : 0, 'pack' : pack_unsigned_int, 'unpack' : unpack_int},\n    'c':{ 'size' : 1, 'alignment' : 0, 'pack' : pack_char, 'unpack' : unpack_char},\n    's':{ 'size' : 1, 'alignment' : 0, 'pack' : None, 'unpack' : None},\n    'p':{ 'size' : 1, 'alignment' : 0, 'pack' : None, 'unpack' : None},\n    'h':{ 'size' : 2, 'alignment' : 0, 'pack' : pack_signed_int, 'unpack' : unpack_signed_int},\n    'H':{ 'size' : 2, 'alignment' : 0, 'pack' : pack_unsigned_int, 'unpack' : unpack_int},\n    'i':{ 'size' : 4, 'alignment' : 0, 'pack' : pack_signed_int, 'unpack' : unpack_signed_int},\n    'I':{ 'size' : 4, 'alignment' : 0, 'pack' : pack_unsigned_int, 'unpack' : unpack_int},\n    'l':{ 'size' : 4, 'alignment' : 0, 'pack' : pack_signed_int, 'unpack' : unpack_signed_int},\n    'L':{ 'size' : 4, 'alignment' : 0, 'pack' : pack_unsigned_int, 'unpack' : unpack_int},\n    'q':{ 'size' : 8, 'alignment' : 0, 'pack' : pack_signed_int, 'unpack' : unpack_signed_int},\n    'Q':{ 'size' : 8, 'alignment' : 0, 'pack' : pack_unsigned_int, 'unpack' : unpack_int},\n    'f':{ 'size' : 4, 'alignment' : 0, 'pack' : pack_float, 'unpack' : unpack_float},\n    'd':{ 'size' : 8, 'alignment' : 0, 'pack' : pack_float, 'unpack' : unpack_float},\n    }\ndefault = big_endian_format\nformatmode={ '<' : (default, 'little'),\n             '>' : (default, 'big'),\n             '!' : (default, 'big'),\n             '=' : (default, sys.byteorder),\n             '@' : (default, sys.byteorder)\n            }\n\ndef getmode(fmt):\n    try:\n        formatdef,endianness = formatmode[fmt[0]]\n        index = 1\n    except (IndexError, KeyError):\n        formatdef,endianness = formatmode['@']\n        index = 0\n    return formatdef,endianness,index\ndef getNum(fmt,i):\n    num=None\n    cur = fmt[i]\n    while ('0'<= cur ) and ( cur <= '9'):\n        if num == None:\n            num = int(cur)\n        else:\n            num = 10*num + int(cur)\n        i += 1\n        cur = fmt[i]\n    return num,i\n\ndef calcsize(fmt):\n    \"\"\"calcsize(fmt) -> int\n    Return size of C struct described by format string fmt.\n    See struct.__doc__ for more on format strings.\"\"\"\n\n    formatdef,endianness,i = getmode(fmt)\n    num = 0\n    result = 0\n    while i<len(fmt):\n        num,i = getNum(fmt,i)\n        cur = fmt[i]\n        try:\n            format = formatdef[cur]\n        except KeyError:\n            raise StructError(\"%s is not a valid format\" % cur)\n        if num != None :\n            result += num*format['size']\n        else:\n            result += format['size']\n        num = 0\n        i += 1\n    return result\n\ndef pack(fmt,*args):\n    \"\"\"pack(fmt, v1, v2, ...) -> string\n       Return string containing values v1, v2, ... packed according to fmt.\n       See struct.__doc__ for more on format strings.\"\"\"\n    formatdef,endianness,i = getmode(fmt)\n    args = list(args)\n    n_args = len(args)\n    result = []\n    while i<len(fmt):\n        num,i = getNum(fmt,i)\n        cur = fmt[i]\n        try:\n            format = formatdef[cur]\n        except KeyError:\n            raise StructError(\"%s is not a valid format\" % cur)\n        if num == None :\n            num_s = 0\n            num = 1\n        else:\n            num_s = num\n\n        if cur == 'x':\n            result += [b'\\0'*num]\n        elif cur == 's':\n            if isinstance(args[0], bytes):\n                padding = num - len(args[0])\n                result += [args[0][:num] + b'\\0'*padding]\n                args.pop(0)\n            else:\n                raise StructError(\"arg for string format not a string\")\n        elif cur == 'p':\n            if isinstance(args[0], bytes):\n                padding = num - len(args[0]) - 1\n\n                if padding > 0:\n                    result += [bytes([len(args[0])]) + args[0][:num-1] + b'\\0'*padding]\n                else:\n                    if num<255:\n                        result += [bytes([num-1]) + args[0][:num-1]]\n                    else:\n                        result += [bytes([255]) + args[0][:num-1]]\n                args.pop(0)\n            else:\n                raise StructError(\"arg for string format not a string\")\n\n        else:\n            if len(args) < num:\n                raise StructError(\"insufficient arguments to pack\")\n            for var in args[:num]:\n                result += [format['pack'](var,format['size'],endianness)]\n            args=args[num:]\n        num = None\n        i += 1\n    if len(args) != 0:\n        raise StructError(\"too many arguments for pack format\")\n    return b''.join(result)\n\ndef unpack(fmt,data):\n    \"\"\"unpack(fmt, string) -> (v1, v2, ...)\n       Unpack the string, containing packed C structure data, according\n       to fmt.  Requires len(string)==calcsize(fmt).\n       See struct.__doc__ for more on format strings.\"\"\"\n    formatdef,endianness,i = getmode(fmt)\n    j = 0\n    num = 0\n    result = []\n    length= calcsize(fmt)\n    if length != len (data):\n        raise StructError(\"unpack str size does not match format\")\n    while i<len(fmt):\n        num,i=getNum(fmt,i)\n        cur = fmt[i]\n        i += 1\n        try:\n            format = formatdef[cur]\n        except KeyError:\n            raise StructError(\"%s is not a valid format\" % cur)\n\n        if not num :\n            num = 1\n\n        if cur == 'x':\n            j += num\n        elif cur == 's':\n            result.append(data[j:j+num])\n            j += num\n        elif cur == 'p':\n            n=data[j]\n            if n >= num:\n                n = num-1\n            result.append(data[j+1:j+n+1])\n            j += num\n        else:\n            for n in range(num):\n                result += [format['unpack'](data,j,format['size'],endianness)]\n                j += format['size']\n\n    return tuple(result)\n\ndef pack_into(fmt, buf, offset, *args):\n    data = pack(fmt, *args)\n    buffer(buf)[offset:offset+len(data)] = data\n\ndef unpack_from(fmt, buf, offset=0):\n    size = calcsize(fmt)\n    data = buffer(buf)[offset:offset+size]\n    if len(data) != size:\n        raise error(\"unpack_from requires a buffer of at least %d bytes\"\n                    % (size,))\n    return unpack(fmt, data)\n\ndef _clearcache():\n    \"Clear the internal cache.\"\n    # No cache in this implementation\n"], "xml.parsers.expat": [".py", "\"\"\"Interface to the Expat non-validating XML parser.\"\"\"\nimport sys\n\nfrom pyexpat import *\n\n# provide pyexpat submodules as xml.parsers.expat submodules\nsys.modules['xml.parsers.expat.model'] = model\nsys.modules['xml.parsers.expat.errors'] = errors\n"], "hashlib": [".js", "var $module=(function($B){\n\nvar _b_ = $B.builtins\n\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n//for(var $py_builtin in _b_){eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")}\n\nvar $mod = {\n\n    __getattr__ : function(attr){\n        if (attr == 'new') return $hashlib_new;\n        return this[attr]\n    },\n    md5: function() {return $hashlib_new('md5')},\n    sha1: function() {return $hashlib_new('sha1')},\n    sha224: function() {return $hashlib_new('sha224')},\n    sha256: function() {return $hashlib_new('sha256')},\n    sha384: function() {return $hashlib_new('sha384')},\n    sha512: function() {return $hashlib_new('sha512')},\n\n    algorithms_guaranteed: ['md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512'],\n    algorithms_available:  ['md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512']\n}\n\n\n//todo: eventually move this function to a \"utility\" file or use ajax module?\nfunction $get_CryptoJS_lib(alg) {\n   var imp=$importer()\n   var $xmlhttp=imp[0], fake_qs=imp[1], timer=imp[2], res=null\n\n   $xmlhttp.onreadystatechange = function(){\n        if($xmlhttp.readyState==4){\n            window.clearTimeout(timer)\n            if($xmlhttp.status==200 || $xmlhttp.status==0){res=$xmlhttp.responseText}\n            else{\n                // don't throw an exception here, it will not be caught (issue #30)\n                res = Error()\n                res.name = 'NotFoundError'\n                res.message = \"No CryptoJS lib named '\"+alg+\"'\"\n            }\n        }\n   }\n\n   $xmlhttp.open('GET', $B.brython_path+'libs/crypto_js/rollups/'+alg+'.js'+fake_qs,false)\n   if('overrideMimeType' in $xmlhttp){$xmlhttp.overrideMimeType(\"text/plain\")}\n   $xmlhttp.send()\n   if(res.constructor===Error){throw res} // module not found\n\n   try{\n      eval(res + \"; $B.CryptoJS=CryptoJS;\")\n   } catch (err) { \n      throw Error(\"JS Eval Error\", \"Cannot eval CryptoJS algorithm '\" + alg + \"' : error:\" + err);\n   }\n}\n\nfunction $hashlib_new(alg) {\n    if (alg == 'md5') {\n       if ($B.Crypto === undefined || \n           $B.CryptoJS.algo.MD5 === undefined) $get_CryptoJS_lib('md5')\n       this.hash = $B.CryptoJS.algo.MD5.create()\n    } else if (alg == 'sha1') {\n       if ($B.Crypto === undefined ||\n           $B.CryptoJS.algo.SHA1 === undefined) $get_CryptoJS_lib('sha1')\n       this.hash = $B.CryptoJS.algo.SHA1.create()\n    } else if (alg == 'sha224') {\n       if ($B.Crypto === undefined || \n           $B.CryptoJS.algo.SHA224 === undefined) $get_CryptoJS_lib('sha224')\n       this.hash = $B.CryptoJS.algo.SHA224.create()\n    } else if (alg == 'sha256') {\n       if ($B.Crypto === undefined || \n           $B.CryptoJS.algo.SHA256 === undefined) $get_CryptoJS_lib('sha256')\n       this.hash = $B.CryptoJS.algo.SHA256.create()\n    } else if (alg == 'sha384') {\n       if ($B.Crypto === undefined || \n           $B.CryptoJS.algo.SHA384 === undefined) $get_CryptoJS_lib('sha384')\n       this.hash = $B.CryptoJS.algo.SHA384.create()\n    } else if (alg == 'sha512') {\n       if ($B.Crypto === undefined || \n           $B.CryptoJS.algo.SHA512 === undefined) $get_CryptoJS_lib('sha512')\n       this.hash = $B.CryptoJS.algo.SHA512.create()\n    } else {\n       $raise('AttributeError', 'Invalid hash algorithm:' + alg)\n    }\n \n    this.__class__ = $B.$type\n    this.__getattr__ = function(attr){return $getattr(this,attr)}\n    this.__str__ = function(){return this.hexdigest()}\n    this.update = function(msg){this.hash.update(msg)}\n    this.copy = function(){return this.hash.clone()}\n\n    this.hexdigest = function() {\n        var temp=this.hash.clone();\n        temp=temp.finalize();\n        return temp.toString();\n    }\n\n    return this;\n}\n\nreturn $mod\n\n})(__BRYTHON__)\n"], "keyword": [".py", "#! /usr/bin/env python3\n\n\"\"\"Keywords (from \"graminit.c\")\n\nThis file is automatically generated; please don't muck it up!\n\nTo update the symbols in this file, 'cd' to the top directory of\nthe python source tree after building the interpreter and run:\n\n    ./python Lib/keyword.py\n\"\"\"\n\n__all__ = [\"iskeyword\", \"kwlist\"]\n\nkwlist = [\n#--start keywords--\n        'False',\n        'None',\n        'True',\n        'and',\n        'as',\n        'assert',\n        'break',\n        'class',\n        'continue',\n        'def',\n        'del',\n        'elif',\n        'else',\n        'except',\n        'finally',\n        'for',\n        'from',\n        'global',\n        'if',\n        'import',\n        'in',\n        'is',\n        'lambda',\n        'nonlocal',\n        'not',\n        'or',\n        'pass',\n        'raise',\n        'return',\n        'try',\n        'while',\n        'with',\n        'yield',\n#--end keywords--\n        ]\n\niskeyword = frozenset(kwlist).__contains__\n\ndef main():\n    import sys, re\n\n    args = sys.argv[1:]\n    iptfile = args and args[0] or \"Python/graminit.c\"\n    if len(args) > 1: optfile = args[1]\n    else: optfile = \"Lib/keyword.py\"\n\n    # scan the source file for keywords\n    with open(iptfile) as fp:\n        strprog = re.compile('\"([^\"]+)\"')\n        lines = []\n        for line in fp:\n            if '{1, \"' in line:\n                match = strprog.search(line)\n                if match:\n                    lines.append(\"        '\" + match.group(1) + \"',\\n\")\n    lines.sort()\n\n    # load the output skeleton from the target\n    with open(optfile) as fp:\n        format = fp.readlines()\n\n    # insert the lines of keywords\n    try:\n        start = format.index(\"#--start keywords--\\n\") + 1\n        end = format.index(\"#--end keywords--\\n\")\n        format[start:end] = lines\n    except ValueError:\n        sys.stderr.write(\"target does not contain format markers\\n\")\n        sys.exit(1)\n\n    # write the output file\n    fp = open(optfile, 'w')\n    fp.write(''.join(format))\n    fp.close()\n\nif __name__ == \"__main__\":\n    main()\n"], "unittest.test.testmock.testhelpers": [".py", "import unittest\n\nfrom unittest.mock import (\n    call, _Call, create_autospec, MagicMock,\n    Mock, ANY, _CallList, patch, PropertyMock\n)\n\nfrom datetime import datetime\n\nclass SomeClass(object):\n    def one(self, a, b):\n        pass\n    def two(self):\n        pass\n    def three(self, a=None):\n        pass\n\n\n\nclass AnyTest(unittest.TestCase):\n\n    def test_any(self):\n        self.assertEqual(ANY, object())\n\n        mock = Mock()\n        mock(ANY)\n        mock.assert_called_with(ANY)\n\n        mock = Mock()\n        mock(foo=ANY)\n        mock.assert_called_with(foo=ANY)\n\n    def test_repr(self):\n        self.assertEqual(repr(ANY), '<ANY>')\n        self.assertEqual(str(ANY), '<ANY>')\n\n\n    def test_any_and_datetime(self):\n        mock = Mock()\n        mock(datetime.now(), foo=datetime.now())\n\n        mock.assert_called_with(ANY, foo=ANY)\n\n\n    def test_any_mock_calls_comparison_order(self):\n        mock = Mock()\n        d = datetime.now()\n        class Foo(object):\n            def __eq__(self, other):\n                return False\n            def __ne__(self, other):\n                return True\n\n        for d in datetime.now(), Foo():\n            mock.reset_mock()\n\n            mock(d, foo=d, bar=d)\n            mock.method(d, zinga=d, alpha=d)\n            mock().method(a1=d, z99=d)\n\n            expected = [\n                call(ANY, foo=ANY, bar=ANY),\n                call.method(ANY, zinga=ANY, alpha=ANY),\n                call(), call().method(a1=ANY, z99=ANY)\n            ]\n            self.assertEqual(expected, mock.mock_calls)\n            self.assertEqual(mock.mock_calls, expected)\n\n\n\nclass CallTest(unittest.TestCase):\n\n    def test_call_with_call(self):\n        kall = _Call()\n        self.assertEqual(kall, _Call())\n        self.assertEqual(kall, _Call(('',)))\n        self.assertEqual(kall, _Call(((),)))\n        self.assertEqual(kall, _Call(({},)))\n        self.assertEqual(kall, _Call(('', ())))\n        self.assertEqual(kall, _Call(('', {})))\n        self.assertEqual(kall, _Call(('', (), {})))\n        self.assertEqual(kall, _Call(('foo',)))\n        self.assertEqual(kall, _Call(('bar', ())))\n        self.assertEqual(kall, _Call(('baz', {})))\n        self.assertEqual(kall, _Call(('spam', (), {})))\n\n        kall = _Call(((1, 2, 3),))\n        self.assertEqual(kall, _Call(((1, 2, 3),)))\n        self.assertEqual(kall, _Call(('', (1, 2, 3))))\n        self.assertEqual(kall, _Call(((1, 2, 3), {})))\n        self.assertEqual(kall, _Call(('', (1, 2, 3), {})))\n\n        kall = _Call(((1, 2, 4),))\n        self.assertNotEqual(kall, _Call(('', (1, 2, 3))))\n        self.assertNotEqual(kall, _Call(('', (1, 2, 3), {})))\n\n        kall = _Call(('foo', (1, 2, 4),))\n        self.assertNotEqual(kall, _Call(('', (1, 2, 4))))\n        self.assertNotEqual(kall, _Call(('', (1, 2, 4), {})))\n        self.assertNotEqual(kall, _Call(('bar', (1, 2, 4))))\n        self.assertNotEqual(kall, _Call(('bar', (1, 2, 4), {})))\n\n        kall = _Call(({'a': 3},))\n        self.assertEqual(kall, _Call(('', (), {'a': 3})))\n        self.assertEqual(kall, _Call(('', {'a': 3})))\n        self.assertEqual(kall, _Call(((), {'a': 3})))\n        self.assertEqual(kall, _Call(({'a': 3},)))\n\n\n    def test_empty__Call(self):\n        args = _Call()\n\n        self.assertEqual(args, ())\n        self.assertEqual(args, ('foo',))\n        self.assertEqual(args, ((),))\n        self.assertEqual(args, ('foo', ()))\n        self.assertEqual(args, ('foo',(), {}))\n        self.assertEqual(args, ('foo', {}))\n        self.assertEqual(args, ({},))\n\n\n    def test_named_empty_call(self):\n        args = _Call(('foo', (), {}))\n\n        self.assertEqual(args, ('foo',))\n        self.assertEqual(args, ('foo', ()))\n        self.assertEqual(args, ('foo',(), {}))\n        self.assertEqual(args, ('foo', {}))\n\n        self.assertNotEqual(args, ((),))\n        self.assertNotEqual(args, ())\n        self.assertNotEqual(args, ({},))\n        self.assertNotEqual(args, ('bar',))\n        self.assertNotEqual(args, ('bar', ()))\n        self.assertNotEqual(args, ('bar', {}))\n\n\n    def test_call_with_args(self):\n        args = _Call(((1, 2, 3), {}))\n\n        self.assertEqual(args, ((1, 2, 3),))\n        self.assertEqual(args, ('foo', (1, 2, 3)))\n        self.assertEqual(args, ('foo', (1, 2, 3), {}))\n        self.assertEqual(args, ((1, 2, 3), {}))\n\n\n    def test_named_call_with_args(self):\n        args = _Call(('foo', (1, 2, 3), {}))\n\n        self.assertEqual(args, ('foo', (1, 2, 3)))\n        self.assertEqual(args, ('foo', (1, 2, 3), {}))\n\n        self.assertNotEqual(args, ((1, 2, 3),))\n        self.assertNotEqual(args, ((1, 2, 3), {}))\n\n\n    def test_call_with_kwargs(self):\n        args = _Call(((), dict(a=3, b=4)))\n\n        self.assertEqual(args, (dict(a=3, b=4),))\n        self.assertEqual(args, ('foo', dict(a=3, b=4)))\n        self.assertEqual(args, ('foo', (), dict(a=3, b=4)))\n        self.assertEqual(args, ((), dict(a=3, b=4)))\n\n\n    def test_named_call_with_kwargs(self):\n        args = _Call(('foo', (), dict(a=3, b=4)))\n\n        self.assertEqual(args, ('foo', dict(a=3, b=4)))\n        self.assertEqual(args, ('foo', (), dict(a=3, b=4)))\n\n        self.assertNotEqual(args, (dict(a=3, b=4),))\n        self.assertNotEqual(args, ((), dict(a=3, b=4)))\n\n\n    def test_call_with_args_call_empty_name(self):\n        args = _Call(((1, 2, 3), {}))\n        self.assertEqual(args, call(1, 2, 3))\n        self.assertEqual(call(1, 2, 3), args)\n        self.assertTrue(call(1, 2, 3) in [args])\n\n\n    def test_call_ne(self):\n        self.assertNotEqual(_Call(((1, 2, 3),)), call(1, 2))\n        self.assertFalse(_Call(((1, 2, 3),)) != call(1, 2, 3))\n        self.assertTrue(_Call(((1, 2), {})) != call(1, 2, 3))\n\n\n    def test_call_non_tuples(self):\n        kall = _Call(((1, 2, 3),))\n        for value in 1, None, self, int:\n            self.assertNotEqual(kall, value)\n            self.assertFalse(kall == value)\n\n\n    def test_repr(self):\n        self.assertEqual(repr(_Call()), 'call()')\n        self.assertEqual(repr(_Call(('foo',))), 'call.foo()')\n\n        self.assertEqual(repr(_Call(((1, 2, 3), {'a': 'b'}))),\n                         \"call(1, 2, 3, a='b')\")\n        self.assertEqual(repr(_Call(('bar', (1, 2, 3), {'a': 'b'}))),\n                         \"call.bar(1, 2, 3, a='b')\")\n\n        self.assertEqual(repr(call), 'call')\n        self.assertEqual(str(call), 'call')\n\n        self.assertEqual(repr(call()), 'call()')\n        self.assertEqual(repr(call(1)), 'call(1)')\n        self.assertEqual(repr(call(zz='thing')), \"call(zz='thing')\")\n\n        self.assertEqual(repr(call().foo), 'call().foo')\n        self.assertEqual(repr(call(1).foo.bar(a=3).bing),\n                         'call().foo.bar().bing')\n        self.assertEqual(\n            repr(call().foo(1, 2, a=3)),\n            \"call().foo(1, 2, a=3)\"\n        )\n        self.assertEqual(repr(call()()), \"call()()\")\n        self.assertEqual(repr(call(1)(2)), \"call()(2)\")\n        self.assertEqual(\n            repr(call()().bar().baz.beep(1)),\n            \"call()().bar().baz.beep(1)\"\n        )\n\n\n    def test_call(self):\n        self.assertEqual(call(), ('', (), {}))\n        self.assertEqual(call('foo', 'bar', one=3, two=4),\n                         ('', ('foo', 'bar'), {'one': 3, 'two': 4}))\n\n        mock = Mock()\n        mock(1, 2, 3)\n        mock(a=3, b=6)\n        self.assertEqual(mock.call_args_list,\n                         [call(1, 2, 3), call(a=3, b=6)])\n\n    def test_attribute_call(self):\n        self.assertEqual(call.foo(1), ('foo', (1,), {}))\n        self.assertEqual(call.bar.baz(fish='eggs'),\n                         ('bar.baz', (), {'fish': 'eggs'}))\n\n        mock = Mock()\n        mock.foo(1, 2 ,3)\n        mock.bar.baz(a=3, b=6)\n        self.assertEqual(mock.method_calls,\n                         [call.foo(1, 2, 3), call.bar.baz(a=3, b=6)])\n\n\n    def test_extended_call(self):\n        result = call(1).foo(2).bar(3, a=4)\n        self.assertEqual(result, ('().foo().bar', (3,), dict(a=4)))\n\n        mock = MagicMock()\n        mock(1, 2, a=3, b=4)\n        self.assertEqual(mock.call_args, call(1, 2, a=3, b=4))\n        self.assertNotEqual(mock.call_args, call(1, 2, 3))\n\n        self.assertEqual(mock.call_args_list, [call(1, 2, a=3, b=4)])\n        self.assertEqual(mock.mock_calls, [call(1, 2, a=3, b=4)])\n\n        mock = MagicMock()\n        mock.foo(1).bar()().baz.beep(a=6)\n\n        last_call = call.foo(1).bar()().baz.beep(a=6)\n        self.assertEqual(mock.mock_calls[-1], last_call)\n        self.assertEqual(mock.mock_calls, last_call.call_list())\n\n\n    def test_call_list(self):\n        mock = MagicMock()\n        mock(1)\n        self.assertEqual(call(1).call_list(), mock.mock_calls)\n\n        mock = MagicMock()\n        mock(1).method(2)\n        self.assertEqual(call(1).method(2).call_list(),\n                         mock.mock_calls)\n\n        mock = MagicMock()\n        mock(1).method(2)(3)\n        self.assertEqual(call(1).method(2)(3).call_list(),\n                         mock.mock_calls)\n\n        mock = MagicMock()\n        int(mock(1).method(2)(3).foo.bar.baz(4)(5))\n        kall = call(1).method(2)(3).foo.bar.baz(4)(5).__int__()\n        self.assertEqual(kall.call_list(), mock.mock_calls)\n\n\n    def test_call_any(self):\n        self.assertEqual(call, ANY)\n\n        m = MagicMock()\n        int(m)\n        self.assertEqual(m.mock_calls, [ANY])\n        self.assertEqual([ANY], m.mock_calls)\n\n\n    def test_two_args_call(self):\n        args = _Call(((1, 2), {'a': 3}), two=True)\n        self.assertEqual(len(args), 2)\n        self.assertEqual(args[0], (1, 2))\n        self.assertEqual(args[1], {'a': 3})\n\n        other_args = _Call(((1, 2), {'a': 3}))\n        self.assertEqual(args, other_args)\n\n\nclass SpecSignatureTest(unittest.TestCase):\n\n    def _check_someclass_mock(self, mock):\n        self.assertRaises(AttributeError, getattr, mock, 'foo')\n        mock.one(1, 2)\n        mock.one.assert_called_with(1, 2)\n        self.assertRaises(AssertionError,\n                          mock.one.assert_called_with, 3, 4)\n        self.assertRaises(TypeError, mock.one, 1)\n\n        mock.two()\n        mock.two.assert_called_with()\n        self.assertRaises(AssertionError,\n                          mock.two.assert_called_with, 3)\n        self.assertRaises(TypeError, mock.two, 1)\n\n        mock.three()\n        mock.three.assert_called_with()\n        self.assertRaises(AssertionError,\n                          mock.three.assert_called_with, 3)\n        self.assertRaises(TypeError, mock.three, 3, 2)\n\n        mock.three(1)\n        mock.three.assert_called_with(1)\n\n        mock.three(a=1)\n        mock.three.assert_called_with(a=1)\n\n\n    def test_basic(self):\n        for spec in (SomeClass, SomeClass()):\n            mock = create_autospec(spec)\n            self._check_someclass_mock(mock)\n\n\n    def test_create_autospec_return_value(self):\n        def f():\n            pass\n        mock = create_autospec(f, return_value='foo')\n        self.assertEqual(mock(), 'foo')\n\n        class Foo(object):\n            pass\n\n        mock = create_autospec(Foo, return_value='foo')\n        self.assertEqual(mock(), 'foo')\n\n\n    def test_autospec_reset_mock(self):\n        m = create_autospec(int)\n        int(m)\n        m.reset_mock()\n        self.assertEqual(m.__int__.call_count, 0)\n\n\n    def test_mocking_unbound_methods(self):\n        class Foo(object):\n            def foo(self, foo):\n                pass\n        p = patch.object(Foo, 'foo')\n        mock_foo = p.start()\n        Foo().foo(1)\n\n        mock_foo.assert_called_with(1)\n\n\n    def test_create_autospec_unbound_methods(self):\n        # see mock issue 128\n        # this is expected to fail until the issue is fixed\n        return\n        class Foo(object):\n            def foo(self):\n                pass\n\n        klass = create_autospec(Foo)\n        instance = klass()\n        self.assertRaises(TypeError, instance.foo, 1)\n\n        # Note: no type checking on the \"self\" parameter\n        klass.foo(1)\n        klass.foo.assert_called_with(1)\n        self.assertRaises(TypeError, klass.foo)\n\n\n    def test_create_autospec_keyword_arguments(self):\n        class Foo(object):\n            a = 3\n        m = create_autospec(Foo, a='3')\n        self.assertEqual(m.a, '3')\n\n\n    def test_create_autospec_keyword_only_arguments(self):\n        def foo(a, *, b=None):\n            pass\n\n        m = create_autospec(foo)\n        m(1)\n        m.assert_called_with(1)\n        self.assertRaises(TypeError, m, 1, 2)\n\n        m(2, b=3)\n        m.assert_called_with(2, b=3)\n\n\n    def test_function_as_instance_attribute(self):\n        obj = SomeClass()\n        def f(a):\n            pass\n        obj.f = f\n\n        mock = create_autospec(obj)\n        mock.f('bing')\n        mock.f.assert_called_with('bing')\n\n\n    def test_spec_as_list(self):\n        # because spec as a list of strings in the mock constructor means\n        # something very different we treat a list instance as the type.\n        mock = create_autospec([])\n        mock.append('foo')\n        mock.append.assert_called_with('foo')\n\n        self.assertRaises(AttributeError, getattr, mock, 'foo')\n\n        class Foo(object):\n            foo = []\n\n        mock = create_autospec(Foo)\n        mock.foo.append(3)\n        mock.foo.append.assert_called_with(3)\n        self.assertRaises(AttributeError, getattr, mock.foo, 'foo')\n\n\n    def test_attributes(self):\n        class Sub(SomeClass):\n            attr = SomeClass()\n\n        sub_mock = create_autospec(Sub)\n\n        for mock in (sub_mock, sub_mock.attr):\n            self._check_someclass_mock(mock)\n\n\n    def test_builtin_functions_types(self):\n        # we could replace builtin functions / methods with a function\n        # with *args / **kwargs signature. Using the builtin method type\n        # as a spec seems to work fairly well though.\n        class BuiltinSubclass(list):\n            def bar(self, arg):\n                pass\n            sorted = sorted\n            attr = {}\n\n        mock = create_autospec(BuiltinSubclass)\n        mock.append(3)\n        mock.append.assert_called_with(3)\n        self.assertRaises(AttributeError, getattr, mock.append, 'foo')\n\n        mock.bar('foo')\n        mock.bar.assert_called_with('foo')\n        self.assertRaises(TypeError, mock.bar, 'foo', 'bar')\n        self.assertRaises(AttributeError, getattr, mock.bar, 'foo')\n\n        mock.sorted([1, 2])\n        mock.sorted.assert_called_with([1, 2])\n        self.assertRaises(AttributeError, getattr, mock.sorted, 'foo')\n\n        mock.attr.pop(3)\n        mock.attr.pop.assert_called_with(3)\n        self.assertRaises(AttributeError, getattr, mock.attr, 'foo')\n\n\n    def test_method_calls(self):\n        class Sub(SomeClass):\n            attr = SomeClass()\n\n        mock = create_autospec(Sub)\n        mock.one(1, 2)\n        mock.two()\n        mock.three(3)\n\n        expected = [call.one(1, 2), call.two(), call.three(3)]\n        self.assertEqual(mock.method_calls, expected)\n\n        mock.attr.one(1, 2)\n        mock.attr.two()\n        mock.attr.three(3)\n\n        expected.extend(\n            [call.attr.one(1, 2), call.attr.two(), call.attr.three(3)]\n        )\n        self.assertEqual(mock.method_calls, expected)\n\n\n    def test_magic_methods(self):\n        class BuiltinSubclass(list):\n            attr = {}\n\n        mock = create_autospec(BuiltinSubclass)\n        self.assertEqual(list(mock), [])\n        self.assertRaises(TypeError, int, mock)\n        self.assertRaises(TypeError, int, mock.attr)\n        self.assertEqual(list(mock), [])\n\n        self.assertIsInstance(mock['foo'], MagicMock)\n        self.assertIsInstance(mock.attr['foo'], MagicMock)\n\n\n    def test_spec_set(self):\n        class Sub(SomeClass):\n            attr = SomeClass()\n\n        for spec in (Sub, Sub()):\n            mock = create_autospec(spec, spec_set=True)\n            self._check_someclass_mock(mock)\n\n            self.assertRaises(AttributeError, setattr, mock, 'foo', 'bar')\n            self.assertRaises(AttributeError, setattr, mock.attr, 'foo', 'bar')\n\n\n    def test_descriptors(self):\n        class Foo(object):\n            @classmethod\n            def f(cls, a, b):\n                pass\n            @staticmethod\n            def g(a, b):\n                pass\n\n        class Bar(Foo):\n            pass\n\n        class Baz(SomeClass, Bar):\n            pass\n\n        for spec in (Foo, Foo(), Bar, Bar(), Baz, Baz()):\n            mock = create_autospec(spec)\n            mock.f(1, 2)\n            mock.f.assert_called_once_with(1, 2)\n\n            mock.g(3, 4)\n            mock.g.assert_called_once_with(3, 4)\n\n\n    def test_recursive(self):\n        class A(object):\n            def a(self):\n                pass\n            foo = 'foo bar baz'\n            bar = foo\n\n        A.B = A\n        mock = create_autospec(A)\n\n        mock()\n        self.assertFalse(mock.B.called)\n\n        mock.a()\n        mock.B.a()\n        self.assertEqual(mock.method_calls, [call.a(), call.B.a()])\n\n        self.assertIs(A.foo, A.bar)\n        self.assertIsNot(mock.foo, mock.bar)\n        mock.foo.lower()\n        self.assertRaises(AssertionError, mock.bar.lower.assert_called_with)\n\n\n    def test_spec_inheritance_for_classes(self):\n        class Foo(object):\n            def a(self):\n                pass\n            class Bar(object):\n                def f(self):\n                    pass\n\n        class_mock = create_autospec(Foo)\n\n        self.assertIsNot(class_mock, class_mock())\n\n        for this_mock in class_mock, class_mock():\n            this_mock.a()\n            this_mock.a.assert_called_with()\n            self.assertRaises(TypeError, this_mock.a, 'foo')\n            self.assertRaises(AttributeError, getattr, this_mock, 'b')\n\n        instance_mock = create_autospec(Foo())\n        instance_mock.a()\n        instance_mock.a.assert_called_with()\n        self.assertRaises(TypeError, instance_mock.a, 'foo')\n        self.assertRaises(AttributeError, getattr, instance_mock, 'b')\n\n        # The return value isn't isn't callable\n        self.assertRaises(TypeError, instance_mock)\n\n        instance_mock.Bar.f()\n        instance_mock.Bar.f.assert_called_with()\n        self.assertRaises(AttributeError, getattr, instance_mock.Bar, 'g')\n\n        instance_mock.Bar().f()\n        instance_mock.Bar().f.assert_called_with()\n        self.assertRaises(AttributeError, getattr, instance_mock.Bar(), 'g')\n\n\n    def test_inherit(self):\n        class Foo(object):\n            a = 3\n\n        Foo.Foo = Foo\n\n        # class\n        mock = create_autospec(Foo)\n        instance = mock()\n        self.assertRaises(AttributeError, getattr, instance, 'b')\n\n        attr_instance = mock.Foo()\n        self.assertRaises(AttributeError, getattr, attr_instance, 'b')\n\n        # instance\n        mock = create_autospec(Foo())\n        self.assertRaises(AttributeError, getattr, mock, 'b')\n        self.assertRaises(TypeError, mock)\n\n        # attribute instance\n        call_result = mock.Foo()\n        self.assertRaises(AttributeError, getattr, call_result, 'b')\n\n\n    def test_builtins(self):\n        # used to fail with infinite recursion\n        create_autospec(1)\n\n        create_autospec(int)\n        create_autospec('foo')\n        create_autospec(str)\n        create_autospec({})\n        create_autospec(dict)\n        create_autospec([])\n        create_autospec(list)\n        create_autospec(set())\n        create_autospec(set)\n        create_autospec(1.0)\n        create_autospec(float)\n        create_autospec(1j)\n        create_autospec(complex)\n        create_autospec(False)\n        create_autospec(True)\n\n\n    def test_function(self):\n        def f(a, b):\n            pass\n\n        mock = create_autospec(f)\n        self.assertRaises(TypeError, mock)\n        mock(1, 2)\n        mock.assert_called_with(1, 2)\n\n        f.f = f\n        mock = create_autospec(f)\n        self.assertRaises(TypeError, mock.f)\n        mock.f(3, 4)\n        mock.f.assert_called_with(3, 4)\n\n\n    def test_skip_attributeerrors(self):\n        class Raiser(object):\n            def __get__(self, obj, type=None):\n                if obj is None:\n                    raise AttributeError('Can only be accessed via an instance')\n\n        class RaiserClass(object):\n            raiser = Raiser()\n\n            @staticmethod\n            def existing(a, b):\n                return a + b\n\n        s = create_autospec(RaiserClass)\n        self.assertRaises(TypeError, lambda x: s.existing(1, 2, 3))\n        s.existing(1, 2)\n        self.assertRaises(AttributeError, lambda: s.nonexisting)\n\n        # check we can fetch the raiser attribute and it has no spec\n        obj = s.raiser\n        obj.foo, obj.bar\n\n\n    def test_signature_class(self):\n        class Foo(object):\n            def __init__(self, a, b=3):\n                pass\n\n        mock = create_autospec(Foo)\n\n        self.assertRaises(TypeError, mock)\n        mock(1)\n        mock.assert_called_once_with(1)\n\n        mock(4, 5)\n        mock.assert_called_with(4, 5)\n\n\n    def test_class_with_no_init(self):\n        # this used to raise an exception\n        # due to trying to get a signature from object.__init__\n        class Foo(object):\n            pass\n        create_autospec(Foo)\n\n\n    def test_signature_callable(self):\n        class Callable(object):\n            def __init__(self):\n                pass\n            def __call__(self, a):\n                pass\n\n        mock = create_autospec(Callable)\n        mock()\n        mock.assert_called_once_with()\n        self.assertRaises(TypeError, mock, 'a')\n\n        instance = mock()\n        self.assertRaises(TypeError, instance)\n        instance(a='a')\n        instance.assert_called_once_with(a='a')\n        instance('a')\n        instance.assert_called_with('a')\n\n        mock = create_autospec(Callable())\n        mock(a='a')\n        mock.assert_called_once_with(a='a')\n        self.assertRaises(TypeError, mock)\n        mock('a')\n        mock.assert_called_with('a')\n\n\n    def test_signature_noncallable(self):\n        class NonCallable(object):\n            def __init__(self):\n                pass\n\n        mock = create_autospec(NonCallable)\n        instance = mock()\n        mock.assert_called_once_with()\n        self.assertRaises(TypeError, mock, 'a')\n        self.assertRaises(TypeError, instance)\n        self.assertRaises(TypeError, instance, 'a')\n\n        mock = create_autospec(NonCallable())\n        self.assertRaises(TypeError, mock)\n        self.assertRaises(TypeError, mock, 'a')\n\n\n    def test_create_autospec_none(self):\n        class Foo(object):\n            bar = None\n\n        mock = create_autospec(Foo)\n        none = mock.bar\n        self.assertNotIsInstance(none, type(None))\n\n        none.foo()\n        none.foo.assert_called_once_with()\n\n\n    def test_autospec_functions_with_self_in_odd_place(self):\n        class Foo(object):\n            def f(a, self):\n                pass\n\n        a = create_autospec(Foo)\n        a.f(self=10)\n        a.f.assert_called_with(self=10)\n\n\n    def test_autospec_property(self):\n        class Foo(object):\n            @property\n            def foo(self):\n                return 3\n\n        foo = create_autospec(Foo)\n        mock_property = foo.foo\n\n        # no spec on properties\n        self.assertTrue(isinstance(mock_property, MagicMock))\n        mock_property(1, 2, 3)\n        mock_property.abc(4, 5, 6)\n        mock_property.assert_called_once_with(1, 2, 3)\n        mock_property.abc.assert_called_once_with(4, 5, 6)\n\n\n    def test_autospec_slots(self):\n        class Foo(object):\n            __slots__ = ['a']\n\n        foo = create_autospec(Foo)\n        mock_slot = foo.a\n\n        # no spec on slots\n        mock_slot(1, 2, 3)\n        mock_slot.abc(4, 5, 6)\n        mock_slot.assert_called_once_with(1, 2, 3)\n        mock_slot.abc.assert_called_once_with(4, 5, 6)\n\n\nclass TestCallList(unittest.TestCase):\n\n    def test_args_list_contains_call_list(self):\n        mock = Mock()\n        self.assertIsInstance(mock.call_args_list, _CallList)\n\n        mock(1, 2)\n        mock(a=3)\n        mock(3, 4)\n        mock(b=6)\n\n        for kall in call(1, 2), call(a=3), call(3, 4), call(b=6):\n            self.assertTrue(kall in mock.call_args_list)\n\n        calls = [call(a=3), call(3, 4)]\n        self.assertTrue(calls in mock.call_args_list)\n        calls = [call(1, 2), call(a=3)]\n        self.assertTrue(calls in mock.call_args_list)\n        calls = [call(3, 4), call(b=6)]\n        self.assertTrue(calls in mock.call_args_list)\n        calls = [call(3, 4)]\n        self.assertTrue(calls in mock.call_args_list)\n\n        self.assertFalse(call('fish') in mock.call_args_list)\n        self.assertFalse([call('fish')] in mock.call_args_list)\n\n\n    def test_call_list_str(self):\n        mock = Mock()\n        mock(1, 2)\n        mock.foo(a=3)\n        mock.foo.bar().baz('fish', cat='dog')\n\n        expected = (\n            \"[call(1, 2),\\n\"\n            \" call.foo(a=3),\\n\"\n            \" call.foo.bar(),\\n\"\n            \" call.foo.bar().baz('fish', cat='dog')]\"\n        )\n        self.assertEqual(str(mock.mock_calls), expected)\n\n\n    def test_propertymock(self):\n        p = patch('%s.SomeClass.one' % __name__, new_callable=PropertyMock)\n        mock = p.start()\n        try:\n            SomeClass.one\n            mock.assert_called_once_with()\n\n            s = SomeClass()\n            s.one\n            mock.assert_called_with()\n            self.assertEqual(mock.mock_calls, [call(), call()])\n\n            s.one = 3\n            self.assertEqual(mock.mock_calls, [call(), call(), call(3)])\n        finally:\n            p.stop()\n\n\n    def test_propertymock_returnvalue(self):\n        m = MagicMock()\n        p = PropertyMock()\n        type(m).foo = p\n\n        returned = m.foo\n        p.assert_called_once_with()\n        self.assertIsInstance(returned, MagicMock)\n        self.assertNotIsInstance(returned, PropertyMock)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"], "this": [".py", "s = \"\"\"Gur Mra bs Clguba, ol Gvz Crgref\n\nOrnhgvshy vf orggre guna htyl.\nRkcyvpvg vf orggre guna vzcyvpvg.\nFvzcyr vf orggre guna pbzcyrk.\nPbzcyrk vf orggre guna pbzcyvpngrq.\nSyng vf orggre guna arfgrq.\nFcnefr vf orggre guna qrafr.\nErnqnovyvgl pbhagf.\nFcrpvny pnfrf nera'g fcrpvny rabhtu gb oernx gur ehyrf.\nNygubhtu cenpgvpnyvgl orngf chevgl.\nReebef fubhyq arire cnff fvyragyl.\nHayrff rkcyvpvgyl fvyraprq.\nVa gur snpr bs nzovthvgl, ershfr gur grzcgngvba gb thrff.\nGurer fubhyq or bar-- naq cersrenoyl bayl bar --boivbhf jnl gb qb vg.\nNygubhtu gung jnl znl abg or boivbhf ng svefg hayrff lbh'er Qhgpu.\nAbj vf orggre guna arire.\nNygubhtu arire vf bsgra orggre guna *evtug* abj.\nVs gur vzcyrzragngvba vf uneq gb rkcynva, vg'f n onq vqrn.\nVs gur vzcyrzragngvba vf rnfl gb rkcynva, vg znl or n tbbq vqrn.\nAnzrfcnprf ner bar ubaxvat terng vqrn -- yrg'f qb zber bs gubfr!\"\"\"\n\nd = {}\nfor c in (65, 97):\n    for i in range(26):\n        d[chr(i+c)] = chr((i+13) % 26 + c)\n\nprint(\"\".join([d.get(c, c) for c in s]))\n"], "_csv": [".py", "\"\"\"CSV parsing and writing.\n\n[Copied from PyPy\nhttps://bitbucket-assetroot.s3.amazonaws.com/pypy/pypy/1400171824.19/641/_csv.py?Signature=cc%2Bc8m06cBMbsxt2e15XXXUDACk%3D&Expires=1404136251&AWSAccessKeyId=0EMWEFSGA12Z1HF1TZ82\nand adapted to Python 3 syntax for Brython]\n\n\nThis module provides classes that assist in the reading and writing\nof Comma Separated Value (CSV) files, and implements the interface\ndescribed by PEP 305.  Although many CSV files are simple to parse,\nthe format is not formally defined by a stable specification and\nis subtle enough that parsing lines of a CSV file with something\nlike line.split(\\\",\\\") is bound to fail.  The module supports three\nbasic APIs: reading, writing, and registration of dialects.\n\n\nDIALECT REGISTRATION:\n\nReaders and writers support a dialect argument, which is a convenient\nhandle on a group of settings.  When the dialect argument is a string,\nit identifies one of the dialects previously registered with the module.\nIf it is a class or instance, the attributes of the argument are used as\nthe settings for the reader or writer:\n\n    class excel:\n        delimiter = ','\n        quotechar = '\\\"'\n        escapechar = None\n        doublequote = True\n        skipinitialspace = False\n        lineterminator = '\\\\r\\\\n'\n        quoting = QUOTE_MINIMAL\n\nSETTINGS:\n\n    * quotechar - specifies a one-character string to use as the \n        quoting character.  It defaults to '\\\"'.\n    * delimiter - specifies a one-character string to use as the \n        field separator.  It defaults to ','.\n    * skipinitialspace - specifies how to interpret whitespace which\n        immediately follows a delimiter.  It defaults to False, which\n        means that whitespace immediately following a delimiter is part\n        of the following field.\n    * lineterminator -  specifies the character sequence which should \n        terminate rows.\n    * quoting - controls when quotes should be generated by the writer.\n        It can take on any of the following module constants:\n\n        csv.QUOTE_MINIMAL means only when required, for example, when a\n            field contains either the quotechar or the delimiter\n        csv.QUOTE_ALL means that quotes are always placed around fields.\n        csv.QUOTE_NONNUMERIC means that quotes are always placed around\n            fields which do not parse as integers or floating point\n            numbers.\n        csv.QUOTE_NONE means that quotes are never placed around fields.\n    * escapechar - specifies a one-character string used to escape \n        the delimiter when quoting is set to QUOTE_NONE.\n    * doublequote - controls the handling of quotes inside fields.  When\n        True, two consecutive quotes are interpreted as one during read,\n        and when writing, each quote character embedded in the data is\n        written as two quotes.\n\"\"\"\n\n__version__ = \"1.0\"\n\nQUOTE_MINIMAL, QUOTE_ALL, QUOTE_NONNUMERIC, QUOTE_NONE = range(4)\n_dialects = {}\n_field_limit = 128 * 1024 # max parsed field size\n\nclass Error(Exception):\n    pass\n\nclass Dialect(object):\n    \"\"\"CSV dialect\n\n    The Dialect type records CSV parsing and generation options.\"\"\"\n\n    __slots__ = [\"_delimiter\", \"_doublequote\", \"_escapechar\",\n                 \"_lineterminator\", \"_quotechar\", \"_quoting\",\n                 \"_skipinitialspace\", \"_strict\"]\n\n    def __new__(cls, dialect, **kwargs):\n\n        for name in kwargs:\n            if '_' + name not in Dialect.__slots__:\n                raise TypeError(\"unexpected keyword argument '%s'\" %\n                                (name,))\n\n        if dialect is not None:\n            if isinstance(dialect, str):\n                dialect = get_dialect(dialect)\n\n            # Can we reuse this instance?\n            if (isinstance(dialect, Dialect)\n                and all(value is None for value in kwargs.values())):\n                return dialect\n\n        self = object.__new__(cls)\n\n\n        def set_char(x):\n            if x is None:\n                return None\n            if isinstance(x, str) and len(x) <= 1:\n                return x\n            raise TypeError(\"%r must be a 1-character string\" % (name,))\n        def set_str(x):\n            if isinstance(x, str):\n                return x\n            raise TypeError(\"%r must be a string\" % (name,))\n        def set_quoting(x):\n            if x in range(4):\n                return x\n            raise TypeError(\"bad 'quoting' value\")\n\n        attributes = {\"delimiter\": (',', set_char),\n                      \"doublequote\": (True, bool),\n                      \"escapechar\": (None, set_char),\n                      \"lineterminator\": (\"\\r\\n\", set_str),\n                      \"quotechar\": ('\"', set_char),\n                      \"quoting\": (QUOTE_MINIMAL, set_quoting),\n                      \"skipinitialspace\": (False, bool),\n                      \"strict\": (False, bool),\n                      }\n\n        # Copy attributes\n        notset = object()\n        for name in Dialect.__slots__:\n            name = name[1:]\n            value = notset\n            if name in kwargs:\n                value = kwargs[name]\n            elif dialect is not None:\n                value = getattr(dialect, name, notset)\n\n            # mapping by name: (default, converter)\n            if value is notset:\n                value = attributes[name][0]\n                if name == 'quoting' and not self.quotechar:\n                    value = QUOTE_NONE\n            else:\n                converter = attributes[name][1]\n                if converter:\n                    value = converter(value)\n\n            setattr(self, '_' + name, value)\n\n        if not self.delimiter:\n            raise TypeError(\"delimiter must be set\")\n\n        if self.quoting != QUOTE_NONE and not self.quotechar:\n            raise TypeError(\"quotechar must be set if quoting enabled\")\n\n        if not self.lineterminator:\n            raise TypeError(\"lineterminator must be set\")\n\n        return self\n\n    delimiter        = property(lambda self: self._delimiter)\n    doublequote      = property(lambda self: self._doublequote)\n    escapechar       = property(lambda self: self._escapechar)\n    lineterminator   = property(lambda self: self._lineterminator)\n    quotechar        = property(lambda self: self._quotechar)\n    quoting          = property(lambda self: self._quoting)\n    skipinitialspace = property(lambda self: self._skipinitialspace)\n    strict           = property(lambda self: self._strict)\n\n\ndef _call_dialect(dialect_inst, kwargs):\n    return Dialect(dialect_inst, **kwargs)\n\ndef register_dialect(name, dialect=None, **kwargs):\n    \"\"\"Create a mapping from a string name to a dialect class.\n    dialect = csv.register_dialect(name, dialect)\"\"\"\n    if not isinstance(name, str):\n        raise TypeError(\"dialect name must be a string or unicode\")\n\n    dialect = _call_dialect(dialect, kwargs)\n    _dialects[name] = dialect\n\ndef unregister_dialect(name):\n    \"\"\"Delete the name/dialect mapping associated with a string name.\\n\n    csv.unregister_dialect(name)\"\"\"\n    try:\n        del _dialects[name]\n    except KeyError:\n        raise Error(\"unknown dialect\")\n\ndef get_dialect(name):\n    \"\"\"Return the dialect instance associated with name.\n    dialect = csv.get_dialect(name)\"\"\"\n    try:\n        return _dialects[name]\n    except KeyError:\n        raise Error(\"unknown dialect\")\n\ndef list_dialects():\n    \"\"\"Return a list of all know dialect names\n    names = csv.list_dialects()\"\"\"\n    return list(_dialects)\n\nclass Reader(object):\n    \"\"\"CSV reader\n\n    Reader objects are responsible for reading and parsing tabular data\n    in CSV format.\"\"\"\n\n\n    (START_RECORD, START_FIELD, ESCAPED_CHAR, IN_FIELD,\n     IN_QUOTED_FIELD, ESCAPE_IN_QUOTED_FIELD, QUOTE_IN_QUOTED_FIELD,\n     EAT_CRNL) = range(8)\n\n    def __init__(self, iterator, dialect=None, **kwargs):\n        self.dialect = _call_dialect(dialect, kwargs)\n\n        # null characters are not allowed to be in the string so we can use\n        # it as a fall back\n        self._delimiter = self.dialect.delimiter if self.dialect.delimiter else '\\0'\n        self._quotechar = self.dialect.quotechar if self.dialect.quotechar else '\\0'\n        self._escapechar = self.dialect.escapechar if self.dialect.escapechar else '\\0'\n        self._doublequote = self.dialect.doublequote\n        self._quoting = self.dialect.quoting\n        self._skipinitialspace = self.dialect.skipinitialspace\n        self._strict = self.dialect.strict\n\n        self.input_iter = iter(iterator)\n        self.line_num = 0\n\n        self._parse_reset()\n\n    def _parse_reset(self):\n        self.field = ''\n        self.fields = []\n        self.state = self.START_RECORD\n        self.numeric_field = False\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        self._parse_reset()\n        while True:\n            try:\n                line = next(self.input_iter)\n            except StopIteration:\n                # End of input OR exception\n                if len(self.field) > 0:\n                    raise Error(\"newline inside string\")\n                raise\n\n            self.line_num += 1\n\n            if '\\0' in line:\n                raise Error(\"line contains NULL byte\")\n            self._parse_process_char(line)\n            self._parse_eol()\n\n            if self.state == self.START_RECORD:\n                break\n\n        fields = self.fields\n        self.fields = []\n        return fields\n\n    def _parse_process_char(self, line):\n        pos = 0\n        while pos < len(line):\n            if self.state == self.IN_FIELD:\n                # in unquoted field and have already found one character when starting the field\n                pos2 = pos\n                while pos2 < len(line):\n                    if line[pos2] == '\\n' or line[pos2] == '\\r':\n                        # end of line - return [fields]\n                        if pos2 > pos:\n                            self._parse_add_str(line[pos:pos2])\n                            pos = pos2\n                        self._parse_save_field()\n                        self.state = self.EAT_CRNL\n                        break\n                    elif line[pos2] == self._escapechar[0]:\n                        # possible escaped character\n                        if pos2 > pos:\n                            self._parse_add_str(line[pos:pos2])\n                        pos = pos2\n                        self.state = self.ESCAPED_CHAR\n                        break\n                    elif line[pos2] == self._delimiter[0]:\n                        # save field - wait for new field\n                        if pos2 > pos:\n                            self._parse_add_str(line[pos:pos2])\n                            pos = pos2\n                        self._parse_save_field()\n                        self.state = self.START_FIELD\n                        break\n                    # normal character - save in field\n                    pos2 += 1\n                else:\n                    if pos2 > pos:\n                        self._parse_add_str(line[pos:pos2])\n                        pos = pos2\n                        continue\n\n            elif self.state == self.START_RECORD:\n                if line[pos] == '\\n' or line[pos] == '\\r':\n                    self.state = self.EAT_CRNL\n                else:\n                    self.state = self.START_FIELD\n                    # restart process\n                    continue\n\n            elif self.state == self.START_FIELD:\n                if line[pos] == '\\n' or line[pos] == '\\r':\n                    # save empty field - return [fields]\n                    self._parse_save_field()\n                    self.state = self.EAT_CRNL\n                elif (line[pos] == self._quotechar[0]\n                      and self._quoting != QUOTE_NONE):\n                    # start quoted field\n                    self.state = self.IN_QUOTED_FIELD\n                elif line[pos] == self._escapechar[0]:\n                    # possible escaped character\n                    self.state = self.ESCAPED_CHAR\n                elif self._skipinitialspace and line[pos] == ' ':\n                    # ignore space at start of field\n                    pass\n                elif line[pos] == self._delimiter[0]:\n                    # save empty field\n                    self._parse_save_field()\n                else:\n                    # begin new unquoted field\n                    if self._quoting == QUOTE_NONNUMERIC:\n                        self.numeric_field = True\n                    self.state = self.IN_FIELD\n                    continue\n\n            elif self.state == self.ESCAPED_CHAR:\n                self._parse_add_char(line[pos])\n                self.state = self.IN_FIELD\n\n            elif self.state == self.IN_QUOTED_FIELD:\n                if line[pos] == self._escapechar:\n                    # possible escape character\n                    self.state = self.ESCAPE_IN_QUOTED_FIELD\n                elif (line[pos] == self._quotechar\n                      and self._quoting != QUOTE_NONE):\n                    if self._doublequote:\n                        # doublequote; \" represented by \"\"\n                        self.state = self.QUOTE_IN_QUOTED_FIELD\n                    else:\n                        #end of quote part of field\n                        self.state = self.IN_FIELD\n                else:\n                    # normal character - save in field\n                    self._parse_add_char(line[pos])\n\n            elif self.state == self.ESCAPE_IN_QUOTED_FIELD:\n                self._parse_add_char(line[pos])\n                self.state = self.IN_QUOTED_FIELD\n\n            elif self.state == self.QUOTE_IN_QUOTED_FIELD:\n                # doublequote - seen a quote in a quoted field\n                if (line[pos] == self._quotechar\n                    and self._quoting != QUOTE_NONE):\n                    # save \"\" as \"\n                    self._parse_add_char(line[pos])\n                    self.state = self.IN_QUOTED_FIELD\n                elif line[pos] == self._delimiter[0]:\n                    # save field - wait for new field\n                    self._parse_save_field()\n                    self.state = self.START_FIELD\n                elif line[pos] == '\\r' or line[pos] == '\\n':\n                    # end of line - return [fields]\n                    self._parse_save_field()\n                    self.state = self.EAT_CRNL\n                elif not self._strict:\n                    self._parse_add_char(line[pos])\n                    self.state = self.IN_FIELD\n                else:\n                    raise Error(\"'%c' expected after '%c'\" %\n                                (self._delimiter, self._quotechar))\n\n            elif self.state == self.EAT_CRNL:\n                if line[pos] == '\\r' or line[pos] == '\\n':\n                    pass\n                else:\n                    raise Error(\"new-line character seen in unquoted field - \"\n                                \"do you need to open the file \"\n                                \"in universal-newline mode?\")\n\n            else:\n                raise RuntimeError(\"unknown state: %r\" % (self.state,))\n\n            pos += 1\n\n    def _parse_eol(self):\n        if self.state == self.EAT_CRNL:\n            self.state = self.START_RECORD\n        elif self.state == self.START_RECORD:\n            # empty line - return []\n            pass\n        elif self.state == self.IN_FIELD:\n            # in unquoted field\n            # end of line - return [fields]\n            self._parse_save_field()\n            self.state = self.START_RECORD\n        elif self.state == self.START_FIELD:\n            # save empty field - return [fields]\n            self._parse_save_field()\n            self.state = self.START_RECORD\n        elif self.state == self.ESCAPED_CHAR:\n            self._parse_add_char('\\n')\n            self.state = self.IN_FIELD\n        elif self.state == self.IN_QUOTED_FIELD:\n            pass\n        elif self.state == self.ESCAPE_IN_QUOTED_FIELD:\n            self._parse_add_char('\\n')\n            self.state = self.IN_QUOTED_FIELD\n        elif self.state == self.QUOTE_IN_QUOTED_FIELD:\n            # end of line - return [fields]\n            self._parse_save_field()\n            self.state = self.START_RECORD\n        else:\n            raise RuntimeError(\"unknown state: %r\" % (self.state,))\n\n    def _parse_save_field(self):\n        field, self.field = self.field, ''\n        if self.numeric_field:\n            self.numeric_field = False\n            field = float(field)\n        self.fields.append(field)\n\n    def _parse_add_char(self, c):\n        if len(self.field) + 1 > _field_limit:\n            raise Error(\"field larget than field limit (%d)\" % (_field_limit))\n        self.field += c\n\n    def _parse_add_str(self, s):\n        if len(self.field) + len(s) > _field_limit:\n            raise Error(\"field larget than field limit (%d)\" % (_field_limit))\n        self.field += s\n\n\nclass Writer(object):\n    \"\"\"CSV writer\n\n    Writer objects are responsible for generating tabular data\n    in CSV format from sequence input.\"\"\"\n\n    def __init__(self, file, dialect=None, **kwargs):\n        if not (hasattr(file, 'write') and callable(file.write)):\n            raise TypeError(\"argument 1 must have a 'write' method\")\n        self.writeline = file.write\n        self.dialect = _call_dialect(dialect, kwargs)\n\n    def _join_reset(self):\n        self.rec = []\n        self.num_fields = 0\n\n    def _join_append(self, field, quoted, quote_empty):\n        dialect = self.dialect\n        # If this is not the first field we need a field separator\n        if self.num_fields > 0:\n            self.rec.append(dialect.delimiter)\n\n        if dialect.quoting == QUOTE_NONE:\n            need_escape = tuple(dialect.lineterminator) + (\n                dialect.escapechar,  # escapechar always first\n                dialect.delimiter, dialect.quotechar)\n\n        else:\n            for c in tuple(dialect.lineterminator) + (\n                dialect.delimiter, dialect.escapechar):\n                if c and c in field:\n                    quoted = True\n\n            need_escape = ()\n            if dialect.quotechar in field:\n                if dialect.doublequote:\n                    field = field.replace(dialect.quotechar,\n                                          dialect.quotechar * 2)\n                    quoted = True\n                else:\n                    need_escape = (dialect.quotechar,)\n\n\n        for c in need_escape:\n            if c and c in field:\n                if not dialect.escapechar:\n                    raise Error(\"need to escape, but no escapechar set\")\n                field = field.replace(c, dialect.escapechar + c)\n\n        # If field is empty check if it needs to be quoted\n        if field == '' and quote_empty:\n            if dialect.quoting == QUOTE_NONE:\n                raise Error(\"single empty field record must be quoted\")\n            quoted = 1\n\n        if quoted:\n            field = dialect.quotechar + field + dialect.quotechar\n\n        self.rec.append(field)\n        self.num_fields += 1\n\n\n\n    def writerow(self, row):\n        dialect = self.dialect\n        try:\n            rowlen = len(row)\n        except TypeError:\n            raise Error(\"sequence expected\")\n\n        # join all fields in internal buffer\n        self._join_reset()\n\n        for field in row:\n            quoted = False\n            if dialect.quoting == QUOTE_NONNUMERIC:\n                try:\n                    float(field)\n                except:\n                    quoted = True\n                # This changed since 2.5:\n                # quoted = not isinstance(field, (int, long, float))\n            elif dialect.quoting == QUOTE_ALL:\n                quoted = True\n\n            if field is None:\n                self._join_append(\"\", quoted, rowlen == 1)\n            else:\n                self._join_append(str(field), quoted, rowlen == 1)\n\n        # add line terminator\n        self.rec.append(dialect.lineterminator)\n\n        self.writeline(''.join(self.rec))\n\n    def writerows(self, rows):\n        for row in rows:\n            self.writerow(row)\n\ndef reader(*args, **kwargs):\n    \"\"\"\n    csv_reader = reader(iterable [, dialect='excel']\n                       [optional keyword args])\n    for row in csv_reader:\n        process(row)\n\n    The \"iterable\" argument can be any object that returns a line\n    of input for each iteration, such as a file object or a list.  The\n    optional \\\"dialect\\\" parameter is discussed below.  The function\n    also accepts optional keyword arguments which override settings\n    provided by the dialect.\n\n    The returned object is an iterator.  Each iteration returns a row\n    of the CSV file (which can span multiple input lines)\"\"\"\n\n    return Reader(*args, **kwargs)\n\ndef writer(*args, **kwargs):\n    \"\"\"\n    csv_writer = csv.writer(fileobj [, dialect='excel']\n                            [optional keyword args])\n    for row in sequence:\n        csv_writer.writerow(row)\n\n    [or]\n\n    csv_writer = csv.writer(fileobj [, dialect='excel']\n                            [optional keyword args])\n    csv_writer.writerows(rows)\n\n    The \\\"fileobj\\\" argument can be any object that supports the file API.\"\"\"\n    return Writer(*args, **kwargs)\n\n\nundefined = object()\ndef field_size_limit(limit=undefined):\n    \"\"\"Sets an upper limit on parsed fields.\n    csv.field_size_limit([limit])\n\n    Returns old limit. If limit is not given, no new limit is set and\n    the old limit is returned\"\"\"\n\n    global _field_limit\n    old_limit = _field_limit\n\n    if limit is not undefined:\n        if not isinstance(limit, (int, long)):\n            raise TypeError(\"int expected, got %s\" %\n                            (limit.__class__.__name__,))\n        _field_limit = limit\n\n    return old_limit\n"], "unittest.test.test_functiontestcase": [".py", "import unittest\n\nfrom .support import LoggingResult\n\n\nclass Test_FunctionTestCase(unittest.TestCase):\n\n    # \"Return the number of tests represented by the this test object. For\n    # TestCase instances, this will always be 1\"\n    def test_countTestCases(self):\n        test = unittest.FunctionTestCase(lambda: None)\n\n        self.assertEqual(test.countTestCases(), 1)\n\n    # \"When a setUp() method is defined, the test runner will run that method\n    # prior to each test. Likewise, if a tearDown() method is defined, the\n    # test runner will invoke that method after each test. In the example,\n    # setUp() was used to create a fresh sequence for each test.\"\n    #\n    # Make sure the proper call order is maintained, even if setUp() raises\n    # an exception.\n    def test_run_call_order__error_in_setUp(self):\n        events = []\n        result = LoggingResult(events)\n\n        def setUp():\n            events.append('setUp')\n            raise RuntimeError('raised by setUp')\n\n        def test():\n            events.append('test')\n\n        def tearDown():\n            events.append('tearDown')\n\n        expected = ['startTest', 'setUp', 'addError', 'stopTest']\n        unittest.FunctionTestCase(test, setUp, tearDown).run(result)\n        self.assertEqual(events, expected)\n\n    # \"When a setUp() method is defined, the test runner will run that method\n    # prior to each test. Likewise, if a tearDown() method is defined, the\n    # test runner will invoke that method after each test. In the example,\n    # setUp() was used to create a fresh sequence for each test.\"\n    #\n    # Make sure the proper call order is maintained, even if the test raises\n    # an error (as opposed to a failure).\n    def test_run_call_order__error_in_test(self):\n        events = []\n        result = LoggingResult(events)\n\n        def setUp():\n            events.append('setUp')\n\n        def test():\n            events.append('test')\n            raise RuntimeError('raised by test')\n\n        def tearDown():\n            events.append('tearDown')\n\n        expected = ['startTest', 'setUp', 'test', 'tearDown',\n                    'addError', 'stopTest']\n        unittest.FunctionTestCase(test, setUp, tearDown).run(result)\n        self.assertEqual(events, expected)\n\n    # \"When a setUp() method is defined, the test runner will run that method\n    # prior to each test. Likewise, if a tearDown() method is defined, the\n    # test runner will invoke that method after each test. In the example,\n    # setUp() was used to create a fresh sequence for each test.\"\n    #\n    # Make sure the proper call order is maintained, even if the test signals\n    # a failure (as opposed to an error).\n    def test_run_call_order__failure_in_test(self):\n        events = []\n        result = LoggingResult(events)\n\n        def setUp():\n            events.append('setUp')\n\n        def test():\n            events.append('test')\n            self.fail('raised by test')\n\n        def tearDown():\n            events.append('tearDown')\n\n        expected = ['startTest', 'setUp', 'test', 'tearDown',\n                    'addFailure', 'stopTest']\n        unittest.FunctionTestCase(test, setUp, tearDown).run(result)\n        self.assertEqual(events, expected)\n\n    # \"When a setUp() method is defined, the test runner will run that method\n    # prior to each test. Likewise, if a tearDown() method is defined, the\n    # test runner will invoke that method after each test. In the example,\n    # setUp() was used to create a fresh sequence for each test.\"\n    #\n    # Make sure the proper call order is maintained, even if tearDown() raises\n    # an exception.\n    def test_run_call_order__error_in_tearDown(self):\n        events = []\n        result = LoggingResult(events)\n\n        def setUp():\n            events.append('setUp')\n\n        def test():\n            events.append('test')\n\n        def tearDown():\n            events.append('tearDown')\n            raise RuntimeError('raised by tearDown')\n\n        expected = ['startTest', 'setUp', 'test', 'tearDown', 'addError',\n                    'stopTest']\n        unittest.FunctionTestCase(test, setUp, tearDown).run(result)\n        self.assertEqual(events, expected)\n\n    # \"Return a string identifying the specific test case.\"\n    #\n    # Because of the vague nature of the docs, I'm not going to lock this\n    # test down too much. Really all that can be asserted is that the id()\n    # will be a string (either 8-byte or unicode -- again, because the docs\n    # just say \"string\")\n    def test_id(self):\n        test = unittest.FunctionTestCase(lambda: None)\n\n        self.assertIsInstance(test.id(), str)\n\n    # \"Returns a one-line description of the test, or None if no description\n    # has been provided. The default implementation of this method returns\n    # the first line of the test method's docstring, if available, or None.\"\n    def test_shortDescription__no_docstring(self):\n        test = unittest.FunctionTestCase(lambda: None)\n\n        self.assertEqual(test.shortDescription(), None)\n\n    # \"Returns a one-line description of the test, or None if no description\n    # has been provided. The default implementation of this method returns\n    # the first line of the test method's docstring, if available, or None.\"\n    def test_shortDescription__singleline_docstring(self):\n        desc = \"this tests foo\"\n        test = unittest.FunctionTestCase(lambda: None, description=desc)\n\n        self.assertEqual(test.shortDescription(), \"this tests foo\")\n"], "xml.dom.minidom": [".py", "\"\"\"Simple implementation of the Level 1 DOM.\n\nNamespaces and other minor Level 2 features are also supported.\n\nparse(\"foo.xml\")\n\nparseString(\"<foo><bar/></foo>\")\n\nTodo:\n=====\n * convenience methods for getting elements and text.\n * more testing\n * bring some of the writer and linearizer code into conformance with this\n        interface\n * SAX 2 namespaces\n\"\"\"\n\nimport io\nimport xml.dom\n\nfrom xml.dom import EMPTY_NAMESPACE, EMPTY_PREFIX, XMLNS_NAMESPACE, domreg\nfrom xml.dom.minicompat import *\nfrom xml.dom.xmlbuilder import DOMImplementationLS, DocumentLS\n\n# This is used by the ID-cache invalidation checks; the list isn't\n# actually complete, since the nodes being checked will never be the\n# DOCUMENT_NODE or DOCUMENT_FRAGMENT_NODE.  (The node being checked is\n# the node being added or removed, not the node being modified.)\n#\n_nodeTypes_with_children = (xml.dom.Node.ELEMENT_NODE,\n                            xml.dom.Node.ENTITY_REFERENCE_NODE)\n\n\nclass Node(xml.dom.Node):\n    namespaceURI = None # this is non-null only for elements and attributes\n    parentNode = None\n    ownerDocument = None\n    nextSibling = None\n    previousSibling = None\n\n    prefix = EMPTY_PREFIX # non-null only for NS elements and attributes\n\n    def __bool__(self):\n        return True\n\n    def toxml(self, encoding=None):\n        return self.toprettyxml(\"\", \"\", encoding)\n\n    def toprettyxml(self, indent=\"\\t\", newl=\"\\n\", encoding=None):\n        if encoding is None:\n            writer = io.StringIO()\n        else:\n            writer = io.TextIOWrapper(io.BytesIO(),\n                                      encoding=encoding,\n                                      errors=\"xmlcharrefreplace\",\n                                      newline='\\n')\n        if self.nodeType == Node.DOCUMENT_NODE:\n            # Can pass encoding only to document, to put it into XML header\n            self.writexml(writer, \"\", indent, newl, encoding)\n        else:\n            self.writexml(writer, \"\", indent, newl)\n        if encoding is None:\n            return writer.getvalue()\n        else:\n            return writer.detach().getvalue()\n\n    def hasChildNodes(self):\n        return bool(self.childNodes)\n\n    def _get_childNodes(self):\n        return self.childNodes\n\n    def _get_firstChild(self):\n        if self.childNodes:\n            return self.childNodes[0]\n\n    def _get_lastChild(self):\n        if self.childNodes:\n            return self.childNodes[-1]\n\n    def insertBefore(self, newChild, refChild):\n        if newChild.nodeType == self.DOCUMENT_FRAGMENT_NODE:\n            for c in tuple(newChild.childNodes):\n                self.insertBefore(c, refChild)\n            ### The DOM does not clearly specify what to return in this case\n            return newChild\n        if newChild.nodeType not in self._child_node_types:\n            raise xml.dom.HierarchyRequestErr(\n                \"%s cannot be child of %s\" % (repr(newChild), repr(self)))\n        if newChild.parentNode is not None:\n            newChild.parentNode.removeChild(newChild)\n        if refChild is None:\n            self.appendChild(newChild)\n        else:\n            try:\n                index = self.childNodes.index(refChild)\n            except ValueError:\n                raise xml.dom.NotFoundErr()\n            if newChild.nodeType in _nodeTypes_with_children:\n                _clear_id_cache(self)\n            self.childNodes.insert(index, newChild)\n            newChild.nextSibling = refChild\n            refChild.previousSibling = newChild\n            if index:\n                node = self.childNodes[index-1]\n                node.nextSibling = newChild\n                newChild.previousSibling = node\n            else:\n                newChild.previousSibling = None\n            newChild.parentNode = self\n        return newChild\n\n    def appendChild(self, node):\n        if node.nodeType == self.DOCUMENT_FRAGMENT_NODE:\n            for c in tuple(node.childNodes):\n                self.appendChild(c)\n            ### The DOM does not clearly specify what to return in this case\n            return node\n        if node.nodeType not in self._child_node_types:\n            raise xml.dom.HierarchyRequestErr(\n                \"%s cannot be child of %s\" % (repr(node), repr(self)))\n        elif node.nodeType in _nodeTypes_with_children:\n            _clear_id_cache(self)\n        if node.parentNode is not None:\n            node.parentNode.removeChild(node)\n        _append_child(self, node)\n        node.nextSibling = None\n        return node\n\n    def replaceChild(self, newChild, oldChild):\n        if newChild.nodeType == self.DOCUMENT_FRAGMENT_NODE:\n            refChild = oldChild.nextSibling\n            self.removeChild(oldChild)\n            return self.insertBefore(newChild, refChild)\n        if newChild.nodeType not in self._child_node_types:\n            raise xml.dom.HierarchyRequestErr(\n                \"%s cannot be child of %s\" % (repr(newChild), repr(self)))\n        if newChild is oldChild:\n            return\n        if newChild.parentNode is not None:\n            newChild.parentNode.removeChild(newChild)\n        try:\n            index = self.childNodes.index(oldChild)\n        except ValueError:\n            raise xml.dom.NotFoundErr()\n        self.childNodes[index] = newChild\n        newChild.parentNode = self\n        oldChild.parentNode = None\n        if (newChild.nodeType in _nodeTypes_with_children\n            or oldChild.nodeType in _nodeTypes_with_children):\n            _clear_id_cache(self)\n        newChild.nextSibling = oldChild.nextSibling\n        newChild.previousSibling = oldChild.previousSibling\n        oldChild.nextSibling = None\n        oldChild.previousSibling = None\n        if newChild.previousSibling:\n            newChild.previousSibling.nextSibling = newChild\n        if newChild.nextSibling:\n            newChild.nextSibling.previousSibling = newChild\n        return oldChild\n\n    def removeChild(self, oldChild):\n        try:\n            self.childNodes.remove(oldChild)\n        except ValueError:\n            raise xml.dom.NotFoundErr()\n        if oldChild.nextSibling is not None:\n            oldChild.nextSibling.previousSibling = oldChild.previousSibling\n        if oldChild.previousSibling is not None:\n            oldChild.previousSibling.nextSibling = oldChild.nextSibling\n        oldChild.nextSibling = oldChild.previousSibling = None\n        if oldChild.nodeType in _nodeTypes_with_children:\n            _clear_id_cache(self)\n\n        oldChild.parentNode = None\n        return oldChild\n\n    def normalize(self):\n        L = []\n        for child in self.childNodes:\n            if child.nodeType == Node.TEXT_NODE:\n                if not child.data:\n                    # empty text node; discard\n                    if L:\n                        L[-1].nextSibling = child.nextSibling\n                    if child.nextSibling:\n                        child.nextSibling.previousSibling = child.previousSibling\n                    child.unlink()\n                elif L and L[-1].nodeType == child.nodeType:\n                    # collapse text node\n                    node = L[-1]\n                    node.data = node.data + child.data\n                    node.nextSibling = child.nextSibling\n                    if child.nextSibling:\n                        child.nextSibling.previousSibling = node\n                    child.unlink()\n                else:\n                    L.append(child)\n            else:\n                L.append(child)\n                if child.nodeType == Node.ELEMENT_NODE:\n                    child.normalize()\n        self.childNodes[:] = L\n\n    def cloneNode(self, deep):\n        return _clone_node(self, deep, self.ownerDocument or self)\n\n    def isSupported(self, feature, version):\n        return self.ownerDocument.implementation.hasFeature(feature, version)\n\n    def _get_localName(self):\n        # Overridden in Element and Attr where localName can be Non-Null\n        return None\n\n    # Node interfaces from Level 3 (WD 9 April 2002)\n\n    def isSameNode(self, other):\n        return self is other\n\n    def getInterface(self, feature):\n        if self.isSupported(feature, None):\n            return self\n        else:\n            return None\n\n    # The \"user data\" functions use a dictionary that is only present\n    # if some user data has been set, so be careful not to assume it\n    # exists.\n\n    def getUserData(self, key):\n        try:\n            return self._user_data[key][0]\n        except (AttributeError, KeyError):\n            return None\n\n    def setUserData(self, key, data, handler):\n        old = None\n        try:\n            d = self._user_data\n        except AttributeError:\n            d = {}\n            self._user_data = d\n        if key in d:\n            old = d[key][0]\n        if data is None:\n            # ignore handlers passed for None\n            handler = None\n            if old is not None:\n                del d[key]\n        else:\n            d[key] = (data, handler)\n        return old\n\n    def _call_user_data_handler(self, operation, src, dst):\n        if hasattr(self, \"_user_data\"):\n            for key, (data, handler) in list(self._user_data.items()):\n                if handler is not None:\n                    handler.handle(operation, key, data, src, dst)\n\n    # minidom-specific API:\n\n    def unlink(self):\n        self.parentNode = self.ownerDocument = None\n        if self.childNodes:\n            for child in self.childNodes:\n                child.unlink()\n            self.childNodes = NodeList()\n        self.previousSibling = None\n        self.nextSibling = None\n\n    # A Node is its own context manager, to ensure that an unlink() call occurs.\n    # This is similar to how a file object works.\n    def __enter__(self):\n        return self\n\n    def __exit__(self, et, ev, tb):\n        self.unlink()\n\ndefproperty(Node, \"firstChild\", doc=\"First child node, or None.\")\ndefproperty(Node, \"lastChild\",  doc=\"Last child node, or None.\")\ndefproperty(Node, \"localName\",  doc=\"Namespace-local name of this node.\")\n\n\ndef _append_child(self, node):\n    # fast path with less checks; usable by DOM builders if careful\n    childNodes = self.childNodes\n    if childNodes:\n        last = childNodes[-1]\n        node.previousSibling = last\n        last.nextSibling = node\n    childNodes.append(node)\n    node.parentNode = self\n\ndef _in_document(node):\n    # return True iff node is part of a document tree\n    while node is not None:\n        if node.nodeType == Node.DOCUMENT_NODE:\n            return True\n        node = node.parentNode\n    return False\n\ndef _write_data(writer, data):\n    \"Writes datachars to writer.\"\n    if data:\n        data = data.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\"). \\\n                    replace(\"\\\"\", \"&quot;\").replace(\">\", \"&gt;\")\n        writer.write(data)\n\ndef _get_elements_by_tagName_helper(parent, name, rc):\n    for node in parent.childNodes:\n        if node.nodeType == Node.ELEMENT_NODE and \\\n            (name == \"*\" or node.tagName == name):\n            rc.append(node)\n        _get_elements_by_tagName_helper(node, name, rc)\n    return rc\n\ndef _get_elements_by_tagName_ns_helper(parent, nsURI, localName, rc):\n    for node in parent.childNodes:\n        if node.nodeType == Node.ELEMENT_NODE:\n            if ((localName == \"*\" or node.localName == localName) and\n                (nsURI == \"*\" or node.namespaceURI == nsURI)):\n                rc.append(node)\n            _get_elements_by_tagName_ns_helper(node, nsURI, localName, rc)\n    return rc\n\nclass DocumentFragment(Node):\n    nodeType = Node.DOCUMENT_FRAGMENT_NODE\n    nodeName = \"#document-fragment\"\n    nodeValue = None\n    attributes = None\n    parentNode = None\n    _child_node_types = (Node.ELEMENT_NODE,\n                         Node.TEXT_NODE,\n                         Node.CDATA_SECTION_NODE,\n                         Node.ENTITY_REFERENCE_NODE,\n                         Node.PROCESSING_INSTRUCTION_NODE,\n                         Node.COMMENT_NODE,\n                         Node.NOTATION_NODE)\n\n    def __init__(self):\n        self.childNodes = NodeList()\n\n\nclass Attr(Node):\n    __slots__=('_name', '_value', 'namespaceURI',\n               '_prefix', 'childNodes', '_localName', 'ownerDocument', 'ownerElement')\n    nodeType = Node.ATTRIBUTE_NODE\n    attributes = None\n    specified = False\n    _is_id = False\n\n    _child_node_types = (Node.TEXT_NODE, Node.ENTITY_REFERENCE_NODE)\n\n    def __init__(self, qName, namespaceURI=EMPTY_NAMESPACE, localName=None,\n                 prefix=None):\n        self.ownerElement = None\n        self._name = qName\n        self.namespaceURI = namespaceURI\n        self._prefix = prefix\n        self.childNodes = NodeList()\n\n        # Add the single child node that represents the value of the attr\n        self.childNodes.append(Text())\n\n        # nodeValue and value are set elsewhere\n\n    def _get_localName(self):\n        try:\n            return self._localName\n        except AttributeError:\n            return self.nodeName.split(\":\", 1)[-1]\n\n    def _get_name(self):\n        return self.name\n\n    def _get_specified(self):\n        return self.specified\n\n    def _get_name(self):\n        return self._name\n\n    def _set_name(self, value):\n        self._name = value\n        if self.ownerElement is not None:\n            _clear_id_cache(self.ownerElement)\n\n    nodeName = name = property(_get_name, _set_name)\n\n    def _get_value(self):\n        return self._value\n\n    def _set_value(self, value):\n        self._value = value\n        self.childNodes[0].data = value\n        if self.ownerElement is not None:\n            _clear_id_cache(self.ownerElement)\n        self.childNodes[0].data = value\n\n    nodeValue = value = property(_get_value, _set_value)\n\n    def _get_prefix(self):\n        return self._prefix\n\n    def _set_prefix(self, prefix):\n        nsuri = self.namespaceURI\n        if prefix == \"xmlns\":\n            if nsuri and nsuri != XMLNS_NAMESPACE:\n                raise xml.dom.NamespaceErr(\n                    \"illegal use of 'xmlns' prefix for the wrong namespace\")\n        self._prefix = prefix\n        if prefix is None:\n            newName = self.localName\n        else:\n            newName = \"%s:%s\" % (prefix, self.localName)\n        if self.ownerElement:\n            _clear_id_cache(self.ownerElement)\n        self.name = newName\n\n    prefix = property(_get_prefix, _set_prefix)\n\n    def unlink(self):\n        # This implementation does not call the base implementation\n        # since most of that is not needed, and the expense of the\n        # method call is not warranted.  We duplicate the removal of\n        # children, but that's all we needed from the base class.\n        elem = self.ownerElement\n        if elem is not None:\n            del elem._attrs[self.nodeName]\n            del elem._attrsNS[(self.namespaceURI, self.localName)]\n            if self._is_id:\n                self._is_id = False\n                elem._magic_id_nodes -= 1\n                self.ownerDocument._magic_id_count -= 1\n        for child in self.childNodes:\n            child.unlink()\n        del self.childNodes[:]\n\n    def _get_isId(self):\n        if self._is_id:\n            return True\n        doc = self.ownerDocument\n        elem = self.ownerElement\n        if doc is None or elem is None:\n            return False\n\n        info = doc._get_elem_info(elem)\n        if info is None:\n            return False\n        if self.namespaceURI:\n            return info.isIdNS(self.namespaceURI, self.localName)\n        else:\n            return info.isId(self.nodeName)\n\n    def _get_schemaType(self):\n        doc = self.ownerDocument\n        elem = self.ownerElement\n        if doc is None or elem is None:\n            return _no_type\n\n        info = doc._get_elem_info(elem)\n        if info is None:\n            return _no_type\n        if self.namespaceURI:\n            return info.getAttributeTypeNS(self.namespaceURI, self.localName)\n        else:\n            return info.getAttributeType(self.nodeName)\n\ndefproperty(Attr, \"isId\",       doc=\"True if this attribute is an ID.\")\ndefproperty(Attr, \"localName\",  doc=\"Namespace-local name of this attribute.\")\ndefproperty(Attr, \"schemaType\", doc=\"Schema type for this attribute.\")\n\n\nclass NamedNodeMap(object):\n    \"\"\"The attribute list is a transient interface to the underlying\n    dictionaries.  Mutations here will change the underlying element's\n    dictionary.\n\n    Ordering is imposed artificially and does not reflect the order of\n    attributes as found in an input document.\n    \"\"\"\n\n    __slots__ = ('_attrs', '_attrsNS', '_ownerElement')\n\n    def __init__(self, attrs, attrsNS, ownerElement):\n        self._attrs = attrs\n        self._attrsNS = attrsNS\n        self._ownerElement = ownerElement\n\n    def _get_length(self):\n        return len(self._attrs)\n\n    def item(self, index):\n        try:\n            return self[list(self._attrs.keys())[index]]\n        except IndexError:\n            return None\n\n    def items(self):\n        L = []\n        for node in self._attrs.values():\n            L.append((node.nodeName, node.value))\n        return L\n\n    def itemsNS(self):\n        L = []\n        for node in self._attrs.values():\n            L.append(((node.namespaceURI, node.localName), node.value))\n        return L\n\n    def __contains__(self, key):\n        if isinstance(key, str):\n            return key in self._attrs\n        else:\n            return key in self._attrsNS\n\n    def keys(self):\n        return self._attrs.keys()\n\n    def keysNS(self):\n        return self._attrsNS.keys()\n\n    def values(self):\n        return self._attrs.values()\n\n    def get(self, name, value=None):\n        return self._attrs.get(name, value)\n\n    __len__ = _get_length\n\n    def _cmp(self, other):\n        if self._attrs is getattr(other, \"_attrs\", None):\n            return 0\n        else:\n            return (id(self) > id(other)) - (id(self) < id(other))\n\n    def __eq__(self, other):\n        return self._cmp(other) == 0\n\n    def __ge__(self, other):\n        return self._cmp(other) >= 0\n\n    def __gt__(self, other):\n        return self._cmp(other) > 0\n\n    def __le__(self, other):\n        return self._cmp(other) <= 0\n\n    def __lt__(self, other):\n        return self._cmp(other) < 0\n\n    def __ne__(self, other):\n        return self._cmp(other) != 0\n\n    def __getitem__(self, attname_or_tuple):\n        if isinstance(attname_or_tuple, tuple):\n            return self._attrsNS[attname_or_tuple]\n        else:\n            return self._attrs[attname_or_tuple]\n\n    # same as set\n    def __setitem__(self, attname, value):\n        if isinstance(value, str):\n            try:\n                node = self._attrs[attname]\n            except KeyError:\n                node = Attr(attname)\n                node.ownerDocument = self._ownerElement.ownerDocument\n                self.setNamedItem(node)\n            node.value = value\n        else:\n            if not isinstance(value, Attr):\n                raise TypeError(\"value must be a string or Attr object\")\n            node = value\n            self.setNamedItem(node)\n\n    def getNamedItem(self, name):\n        try:\n            return self._attrs[name]\n        except KeyError:\n            return None\n\n    def getNamedItemNS(self, namespaceURI, localName):\n        try:\n            return self._attrsNS[(namespaceURI, localName)]\n        except KeyError:\n            return None\n\n    def removeNamedItem(self, name):\n        n = self.getNamedItem(name)\n        if n is not None:\n            _clear_id_cache(self._ownerElement)\n            del self._attrs[n.nodeName]\n            del self._attrsNS[(n.namespaceURI, n.localName)]\n            if hasattr(n, 'ownerElement'):\n                n.ownerElement = None\n            return n\n        else:\n            raise xml.dom.NotFoundErr()\n\n    def removeNamedItemNS(self, namespaceURI, localName):\n        n = self.getNamedItemNS(namespaceURI, localName)\n        if n is not None:\n            _clear_id_cache(self._ownerElement)\n            del self._attrsNS[(n.namespaceURI, n.localName)]\n            del self._attrs[n.nodeName]\n            if hasattr(n, 'ownerElement'):\n                n.ownerElement = None\n            return n\n        else:\n            raise xml.dom.NotFoundErr()\n\n    def setNamedItem(self, node):\n        if not isinstance(node, Attr):\n            raise xml.dom.HierarchyRequestErr(\n                \"%s cannot be child of %s\" % (repr(node), repr(self)))\n        old = self._attrs.get(node.name)\n        if old:\n            old.unlink()\n        self._attrs[node.name] = node\n        self._attrsNS[(node.namespaceURI, node.localName)] = node\n        node.ownerElement = self._ownerElement\n        _clear_id_cache(node.ownerElement)\n        return old\n\n    def setNamedItemNS(self, node):\n        return self.setNamedItem(node)\n\n    def __delitem__(self, attname_or_tuple):\n        node = self[attname_or_tuple]\n        _clear_id_cache(node.ownerElement)\n        node.unlink()\n\n    def __getstate__(self):\n        return self._attrs, self._attrsNS, self._ownerElement\n\n    def __setstate__(self, state):\n        self._attrs, self._attrsNS, self._ownerElement = state\n\ndefproperty(NamedNodeMap, \"length\",\n            doc=\"Number of nodes in the NamedNodeMap.\")\n\nAttributeList = NamedNodeMap\n\n\nclass TypeInfo(object):\n    __slots__ = 'namespace', 'name'\n\n    def __init__(self, namespace, name):\n        self.namespace = namespace\n        self.name = name\n\n    def __repr__(self):\n        if self.namespace:\n            return \"<TypeInfo %r (from %r)>\" % (self.name, self.namespace)\n        else:\n            return \"<TypeInfo %r>\" % self.name\n\n    def _get_name(self):\n        return self.name\n\n    def _get_namespace(self):\n        return self.namespace\n\n_no_type = TypeInfo(None, None)\n\nclass Element(Node):\n    __slots__=('ownerDocument', 'parentNode', 'tagName', 'nodeName', 'prefix',\n               'namespaceURI', '_localName', 'childNodes', '_attrs', '_attrsNS',\n               'nextSibling', 'previousSibling')\n    nodeType = Node.ELEMENT_NODE\n    nodeValue = None\n    schemaType = _no_type\n\n    _magic_id_nodes = 0\n\n    _child_node_types = (Node.ELEMENT_NODE,\n                         Node.PROCESSING_INSTRUCTION_NODE,\n                         Node.COMMENT_NODE,\n                         Node.TEXT_NODE,\n                         Node.CDATA_SECTION_NODE,\n                         Node.ENTITY_REFERENCE_NODE)\n\n    def __init__(self, tagName, namespaceURI=EMPTY_NAMESPACE, prefix=None,\n                 localName=None):\n        self.parentNode = None\n        self.tagName = self.nodeName = tagName\n        self.prefix = prefix\n        self.namespaceURI = namespaceURI\n        self.childNodes = NodeList()\n        self.nextSibling = self.previousSibling = None\n\n        # Attribute dictionaries are lazily created\n        # attributes are double-indexed:\n        #    tagName -> Attribute\n        #    URI,localName -> Attribute\n        # in the future: consider lazy generation\n        # of attribute objects this is too tricky\n        # for now because of headaches with\n        # namespaces.\n        self._attrs = None\n        self._attrsNS = None\n\n    def _ensure_attributes(self):\n        if self._attrs is None:\n            self._attrs = {}\n            self._attrsNS = {}\n\n    def _get_localName(self):\n        try:\n            return self._localName\n        except AttributeError:\n            return self.tagName.split(\":\", 1)[-1]\n\n    def _get_tagName(self):\n        return self.tagName\n\n    def unlink(self):\n        if self._attrs is not None:\n            for attr in list(self._attrs.values()):\n                attr.unlink()\n        self._attrs = None\n        self._attrsNS = None\n        Node.unlink(self)\n\n    def getAttribute(self, attname):\n        if self._attrs is None:\n            return \"\"\n        try:\n            return self._attrs[attname].value\n        except KeyError:\n            return \"\"\n\n    def getAttributeNS(self, namespaceURI, localName):\n        if self._attrsNS is None:\n            return \"\"\n        try:\n            return self._attrsNS[(namespaceURI, localName)].value\n        except KeyError:\n            return \"\"\n\n    def setAttribute(self, attname, value):\n        attr = self.getAttributeNode(attname)\n        if attr is None:\n            attr = Attr(attname)\n            attr.value = value # also sets nodeValue\n            attr.ownerDocument = self.ownerDocument\n            self.setAttributeNode(attr)\n        elif value != attr.value:\n            attr.value = value\n            if attr.isId:\n                _clear_id_cache(self)\n\n    def setAttributeNS(self, namespaceURI, qualifiedName, value):\n        prefix, localname = _nssplit(qualifiedName)\n        attr = self.getAttributeNodeNS(namespaceURI, localname)\n        if attr is None:\n            attr = Attr(qualifiedName, namespaceURI, localname, prefix)\n            attr.value = value\n            attr.ownerDocument = self.ownerDocument\n            self.setAttributeNode(attr)\n        else:\n            if value != attr.value:\n                attr.value = value\n                if attr.isId:\n                    _clear_id_cache(self)\n            if attr.prefix != prefix:\n                attr.prefix = prefix\n                attr.nodeName = qualifiedName\n\n    def getAttributeNode(self, attrname):\n        if self._attrs is None:\n            return None\n        return self._attrs.get(attrname)\n\n    def getAttributeNodeNS(self, namespaceURI, localName):\n        if self._attrsNS is None:\n            return None\n        return self._attrsNS.get((namespaceURI, localName))\n\n    def setAttributeNode(self, attr):\n        if attr.ownerElement not in (None, self):\n            raise xml.dom.InuseAttributeErr(\"attribute node already owned\")\n        self._ensure_attributes()\n        old1 = self._attrs.get(attr.name, None)\n        if old1 is not None:\n            self.removeAttributeNode(old1)\n        old2 = self._attrsNS.get((attr.namespaceURI, attr.localName), None)\n        if old2 is not None and old2 is not old1:\n            self.removeAttributeNode(old2)\n        _set_attribute_node(self, attr)\n\n        if old1 is not attr:\n            # It might have already been part of this node, in which case\n            # it doesn't represent a change, and should not be returned.\n            return old1\n        if old2 is not attr:\n            return old2\n\n    setAttributeNodeNS = setAttributeNode\n\n    def removeAttribute(self, name):\n        if self._attrsNS is None:\n            raise xml.dom.NotFoundErr()\n        try:\n            attr = self._attrs[name]\n        except KeyError:\n            raise xml.dom.NotFoundErr()\n        self.removeAttributeNode(attr)\n\n    def removeAttributeNS(self, namespaceURI, localName):\n        if self._attrsNS is None:\n            raise xml.dom.NotFoundErr()\n        try:\n            attr = self._attrsNS[(namespaceURI, localName)]\n        except KeyError:\n            raise xml.dom.NotFoundErr()\n        self.removeAttributeNode(attr)\n\n    def removeAttributeNode(self, node):\n        if node is None:\n            raise xml.dom.NotFoundErr()\n        try:\n            self._attrs[node.name]\n        except KeyError:\n            raise xml.dom.NotFoundErr()\n        _clear_id_cache(self)\n        node.unlink()\n        # Restore this since the node is still useful and otherwise\n        # unlinked\n        node.ownerDocument = self.ownerDocument\n\n    removeAttributeNodeNS = removeAttributeNode\n\n    def hasAttribute(self, name):\n        if self._attrs is None:\n            return False\n        return name in self._attrs\n\n    def hasAttributeNS(self, namespaceURI, localName):\n        if self._attrsNS is None:\n            return False\n        return (namespaceURI, localName) in self._attrsNS\n\n    def getElementsByTagName(self, name):\n        return _get_elements_by_tagName_helper(self, name, NodeList())\n\n    def getElementsByTagNameNS(self, namespaceURI, localName):\n        return _get_elements_by_tagName_ns_helper(\n            self, namespaceURI, localName, NodeList())\n\n    def __repr__(self):\n        return \"<DOM Element: %s at %#x>\" % (self.tagName, id(self))\n\n    def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n        # indent = current indentation\n        # addindent = indentation to add to higher levels\n        # newl = newline string\n        writer.write(indent+\"<\" + self.tagName)\n\n        attrs = self._get_attributes()\n        a_names = sorted(attrs.keys())\n\n        for a_name in a_names:\n            writer.write(\" %s=\\\"\" % a_name)\n            _write_data(writer, attrs[a_name].value)\n            writer.write(\"\\\"\")\n        if self.childNodes:\n            writer.write(\">\")\n            if (len(self.childNodes) == 1 and\n                self.childNodes[0].nodeType == Node.TEXT_NODE):\n                self.childNodes[0].writexml(writer, '', '', '')\n            else:\n                writer.write(newl)\n                for node in self.childNodes:\n                    node.writexml(writer, indent+addindent, addindent, newl)\n                writer.write(indent)\n            writer.write(\"</%s>%s\" % (self.tagName, newl))\n        else:\n            writer.write(\"/>%s\"%(newl))\n\n    def _get_attributes(self):\n        self._ensure_attributes()\n        return NamedNodeMap(self._attrs, self._attrsNS, self)\n\n    def hasAttributes(self):\n        if self._attrs:\n            return True\n        else:\n            return False\n\n    # DOM Level 3 attributes, based on the 22 Oct 2002 draft\n\n    def setIdAttribute(self, name):\n        idAttr = self.getAttributeNode(name)\n        self.setIdAttributeNode(idAttr)\n\n    def setIdAttributeNS(self, namespaceURI, localName):\n        idAttr = self.getAttributeNodeNS(namespaceURI, localName)\n        self.setIdAttributeNode(idAttr)\n\n    def setIdAttributeNode(self, idAttr):\n        if idAttr is None or not self.isSameNode(idAttr.ownerElement):\n            raise xml.dom.NotFoundErr()\n        if _get_containing_entref(self) is not None:\n            raise xml.dom.NoModificationAllowedErr()\n        if not idAttr._is_id:\n            idAttr._is_id = True\n            self._magic_id_nodes += 1\n            self.ownerDocument._magic_id_count += 1\n            _clear_id_cache(self)\n\ndefproperty(Element, \"attributes\",\n            doc=\"NamedNodeMap of attributes on the element.\")\ndefproperty(Element, \"localName\",\n            doc=\"Namespace-local name of this element.\")\n\n\ndef _set_attribute_node(element, attr):\n    _clear_id_cache(element)\n    element._ensure_attributes()\n    element._attrs[attr.name] = attr\n    element._attrsNS[(attr.namespaceURI, attr.localName)] = attr\n\n    # This creates a circular reference, but Element.unlink()\n    # breaks the cycle since the references to the attribute\n    # dictionaries are tossed.\n    attr.ownerElement = element\n\nclass Childless:\n    \"\"\"Mixin that makes childless-ness easy to implement and avoids\n    the complexity of the Node methods that deal with children.\n    \"\"\"\n    __slots__ = ()\n\n    attributes = None\n    childNodes = EmptyNodeList()\n    firstChild = None\n    lastChild = None\n\n    def _get_firstChild(self):\n        return None\n\n    def _get_lastChild(self):\n        return None\n\n    def appendChild(self, node):\n        raise xml.dom.HierarchyRequestErr(\n            self.nodeName + \" nodes cannot have children\")\n\n    def hasChildNodes(self):\n        return False\n\n    def insertBefore(self, newChild, refChild):\n        raise xml.dom.HierarchyRequestErr(\n            self.nodeName + \" nodes do not have children\")\n\n    def removeChild(self, oldChild):\n        raise xml.dom.NotFoundErr(\n            self.nodeName + \" nodes do not have children\")\n\n    def normalize(self):\n        # For childless nodes, normalize() has nothing to do.\n        pass\n\n    def replaceChild(self, newChild, oldChild):\n        raise xml.dom.HierarchyRequestErr(\n            self.nodeName + \" nodes do not have children\")\n\n\nclass ProcessingInstruction(Childless, Node):\n    nodeType = Node.PROCESSING_INSTRUCTION_NODE\n    __slots__ = ('target', 'data')\n\n    def __init__(self, target, data):\n        self.target = target\n        self.data = data\n\n    # nodeValue is an alias for data\n    def _get_nodeValue(self):\n        return self.data\n    def _set_nodeValue(self, value):\n        self.data = data\n    nodeValue = property(_get_nodeValue, _set_nodeValue)\n\n    # nodeName is an alias for target\n    def _get_nodeName(self):\n        return self.target\n    def _set_nodeName(self, value):\n        self.target = value\n    nodeName = property(_get_nodeName, _set_nodeName)\n\n    def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n        writer.write(\"%s<?%s %s?>%s\" % (indent,self.target, self.data, newl))\n\n\nclass CharacterData(Childless, Node):\n    __slots__=('_data', 'ownerDocument','parentNode', 'previousSibling', 'nextSibling')\n\n    def __init__(self):\n        self.ownerDocument = self.parentNode = None\n        self.previousSibling = self.nextSibling = None\n        self._data = ''\n        Node.__init__(self)\n\n    def _get_length(self):\n        return len(self.data)\n    __len__ = _get_length\n\n    def _get_data(self):\n        return self._data\n    def _set_data(self, data):\n        self._data = data\n\n    data = nodeValue = property(_get_data, _set_data)\n\n    def __repr__(self):\n        data = self.data\n        if len(data) > 10:\n            dotdotdot = \"...\"\n        else:\n            dotdotdot = \"\"\n        return '<DOM %s node \"%r%s\">' % (\n            self.__class__.__name__, data[0:10], dotdotdot)\n\n    def substringData(self, offset, count):\n        if offset < 0:\n            raise xml.dom.IndexSizeErr(\"offset cannot be negative\")\n        if offset >= len(self.data):\n            raise xml.dom.IndexSizeErr(\"offset cannot be beyond end of data\")\n        if count < 0:\n            raise xml.dom.IndexSizeErr(\"count cannot be negative\")\n        return self.data[offset:offset+count]\n\n    def appendData(self, arg):\n        self.data = self.data + arg\n\n    def insertData(self, offset, arg):\n        if offset < 0:\n            raise xml.dom.IndexSizeErr(\"offset cannot be negative\")\n        if offset >= len(self.data):\n            raise xml.dom.IndexSizeErr(\"offset cannot be beyond end of data\")\n        if arg:\n            self.data = \"%s%s%s\" % (\n                self.data[:offset], arg, self.data[offset:])\n\n    def deleteData(self, offset, count):\n        if offset < 0:\n            raise xml.dom.IndexSizeErr(\"offset cannot be negative\")\n        if offset >= len(self.data):\n            raise xml.dom.IndexSizeErr(\"offset cannot be beyond end of data\")\n        if count < 0:\n            raise xml.dom.IndexSizeErr(\"count cannot be negative\")\n        if count:\n            self.data = self.data[:offset] + self.data[offset+count:]\n\n    def replaceData(self, offset, count, arg):\n        if offset < 0:\n            raise xml.dom.IndexSizeErr(\"offset cannot be negative\")\n        if offset >= len(self.data):\n            raise xml.dom.IndexSizeErr(\"offset cannot be beyond end of data\")\n        if count < 0:\n            raise xml.dom.IndexSizeErr(\"count cannot be negative\")\n        if count:\n            self.data = \"%s%s%s\" % (\n                self.data[:offset], arg, self.data[offset+count:])\n\ndefproperty(CharacterData, \"length\", doc=\"Length of the string data.\")\n\n\nclass Text(CharacterData):\n    __slots__ = ()\n\n    nodeType = Node.TEXT_NODE\n    nodeName = \"#text\"\n    attributes = None\n\n    def splitText(self, offset):\n        if offset < 0 or offset > len(self.data):\n            raise xml.dom.IndexSizeErr(\"illegal offset value\")\n        newText = self.__class__()\n        newText.data = self.data[offset:]\n        newText.ownerDocument = self.ownerDocument\n        next = self.nextSibling\n        if self.parentNode and self in self.parentNode.childNodes:\n            if next is None:\n                self.parentNode.appendChild(newText)\n            else:\n                self.parentNode.insertBefore(newText, next)\n        self.data = self.data[:offset]\n        return newText\n\n    def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n        _write_data(writer, \"%s%s%s\" % (indent, self.data, newl))\n\n    # DOM Level 3 (WD 9 April 2002)\n\n    def _get_wholeText(self):\n        L = [self.data]\n        n = self.previousSibling\n        while n is not None:\n            if n.nodeType in (Node.TEXT_NODE, Node.CDATA_SECTION_NODE):\n                L.insert(0, n.data)\n                n = n.previousSibling\n            else:\n                break\n        n = self.nextSibling\n        while n is not None:\n            if n.nodeType in (Node.TEXT_NODE, Node.CDATA_SECTION_NODE):\n                L.append(n.data)\n                n = n.nextSibling\n            else:\n                break\n        return ''.join(L)\n\n    def replaceWholeText(self, content):\n        # XXX This needs to be seriously changed if minidom ever\n        # supports EntityReference nodes.\n        parent = self.parentNode\n        n = self.previousSibling\n        while n is not None:\n            if n.nodeType in (Node.TEXT_NODE, Node.CDATA_SECTION_NODE):\n                next = n.previousSibling\n                parent.removeChild(n)\n                n = next\n            else:\n                break\n        n = self.nextSibling\n        if not content:\n            parent.removeChild(self)\n        while n is not None:\n            if n.nodeType in (Node.TEXT_NODE, Node.CDATA_SECTION_NODE):\n                next = n.nextSibling\n                parent.removeChild(n)\n                n = next\n            else:\n                break\n        if content:\n            self.data = content\n            return self\n        else:\n            return None\n\n    def _get_isWhitespaceInElementContent(self):\n        if self.data.strip():\n            return False\n        elem = _get_containing_element(self)\n        if elem is None:\n            return False\n        info = self.ownerDocument._get_elem_info(elem)\n        if info is None:\n            return False\n        else:\n            return info.isElementContent()\n\ndefproperty(Text, \"isWhitespaceInElementContent\",\n            doc=\"True iff this text node contains only whitespace\"\n                \" and is in element content.\")\ndefproperty(Text, \"wholeText\",\n            doc=\"The text of all logically-adjacent text nodes.\")\n\n\ndef _get_containing_element(node):\n    c = node.parentNode\n    while c is not None:\n        if c.nodeType == Node.ELEMENT_NODE:\n            return c\n        c = c.parentNode\n    return None\n\ndef _get_containing_entref(node):\n    c = node.parentNode\n    while c is not None:\n        if c.nodeType == Node.ENTITY_REFERENCE_NODE:\n            return c\n        c = c.parentNode\n    return None\n\n\nclass Comment(CharacterData):\n    nodeType = Node.COMMENT_NODE\n    nodeName = \"#comment\"\n\n    def __init__(self, data):\n        CharacterData.__init__(self)\n        self._data = data\n\n    def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n        if \"--\" in self.data:\n            raise ValueError(\"'--' is not allowed in a comment node\")\n        writer.write(\"%s<!--%s-->%s\" % (indent, self.data, newl))\n\n\nclass CDATASection(Text):\n    __slots__ = ()\n\n    nodeType = Node.CDATA_SECTION_NODE\n    nodeName = \"#cdata-section\"\n\n    def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n        if self.data.find(\"]]>\") >= 0:\n            raise ValueError(\"']]>' not allowed in a CDATA section\")\n        writer.write(\"<![CDATA[%s]]>\" % self.data)\n\n\nclass ReadOnlySequentialNamedNodeMap(object):\n    __slots__ = '_seq',\n\n    def __init__(self, seq=()):\n        # seq should be a list or tuple\n        self._seq = seq\n\n    def __len__(self):\n        return len(self._seq)\n\n    def _get_length(self):\n        return len(self._seq)\n\n    def getNamedItem(self, name):\n        for n in self._seq:\n            if n.nodeName == name:\n                return n\n\n    def getNamedItemNS(self, namespaceURI, localName):\n        for n in self._seq:\n            if n.namespaceURI == namespaceURI and n.localName == localName:\n                return n\n\n    def __getitem__(self, name_or_tuple):\n        if isinstance(name_or_tuple, tuple):\n            node = self.getNamedItemNS(*name_or_tuple)\n        else:\n            node = self.getNamedItem(name_or_tuple)\n        if node is None:\n            raise KeyError(name_or_tuple)\n        return node\n\n    def item(self, index):\n        if index < 0:\n            return None\n        try:\n            return self._seq[index]\n        except IndexError:\n            return None\n\n    def removeNamedItem(self, name):\n        raise xml.dom.NoModificationAllowedErr(\n            \"NamedNodeMap instance is read-only\")\n\n    def removeNamedItemNS(self, namespaceURI, localName):\n        raise xml.dom.NoModificationAllowedErr(\n            \"NamedNodeMap instance is read-only\")\n\n    def setNamedItem(self, node):\n        raise xml.dom.NoModificationAllowedErr(\n            \"NamedNodeMap instance is read-only\")\n\n    def setNamedItemNS(self, node):\n        raise xml.dom.NoModificationAllowedErr(\n            \"NamedNodeMap instance is read-only\")\n\n    def __getstate__(self):\n        return [self._seq]\n\n    def __setstate__(self, state):\n        self._seq = state[0]\n\ndefproperty(ReadOnlySequentialNamedNodeMap, \"length\",\n            doc=\"Number of entries in the NamedNodeMap.\")\n\n\nclass Identified:\n    \"\"\"Mix-in class that supports the publicId and systemId attributes.\"\"\"\n\n    __slots__ = 'publicId', 'systemId'\n\n    def _identified_mixin_init(self, publicId, systemId):\n        self.publicId = publicId\n        self.systemId = systemId\n\n    def _get_publicId(self):\n        return self.publicId\n\n    def _get_systemId(self):\n        return self.systemId\n\nclass DocumentType(Identified, Childless, Node):\n    nodeType = Node.DOCUMENT_TYPE_NODE\n    nodeValue = None\n    name = None\n    publicId = None\n    systemId = None\n    internalSubset = None\n\n    def __init__(self, qualifiedName):\n        self.entities = ReadOnlySequentialNamedNodeMap()\n        self.notations = ReadOnlySequentialNamedNodeMap()\n        if qualifiedName:\n            prefix, localname = _nssplit(qualifiedName)\n            self.name = localname\n        self.nodeName = self.name\n\n    def _get_internalSubset(self):\n        return self.internalSubset\n\n    def cloneNode(self, deep):\n        if self.ownerDocument is None:\n            # it's ok\n            clone = DocumentType(None)\n            clone.name = self.name\n            clone.nodeName = self.name\n            operation = xml.dom.UserDataHandler.NODE_CLONED\n            if deep:\n                clone.entities._seq = []\n                clone.notations._seq = []\n                for n in self.notations._seq:\n                    notation = Notation(n.nodeName, n.publicId, n.systemId)\n                    clone.notations._seq.append(notation)\n                    n._call_user_data_handler(operation, n, notation)\n                for e in self.entities._seq:\n                    entity = Entity(e.nodeName, e.publicId, e.systemId,\n                                    e.notationName)\n                    entity.actualEncoding = e.actualEncoding\n                    entity.encoding = e.encoding\n                    entity.version = e.version\n                    clone.entities._seq.append(entity)\n                    e._call_user_data_handler(operation, n, entity)\n            self._call_user_data_handler(operation, self, clone)\n            return clone\n        else:\n            return None\n\n    def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n        writer.write(\"<!DOCTYPE \")\n        writer.write(self.name)\n        if self.publicId:\n            writer.write(\"%s  PUBLIC '%s'%s  '%s'\"\n                         % (newl, self.publicId, newl, self.systemId))\n        elif self.systemId:\n            writer.write(\"%s  SYSTEM '%s'\" % (newl, self.systemId))\n        if self.internalSubset is not None:\n            writer.write(\" [\")\n            writer.write(self.internalSubset)\n            writer.write(\"]\")\n        writer.write(\">\"+newl)\n\nclass Entity(Identified, Node):\n    attributes = None\n    nodeType = Node.ENTITY_NODE\n    nodeValue = None\n\n    actualEncoding = None\n    encoding = None\n    version = None\n\n    def __init__(self, name, publicId, systemId, notation):\n        self.nodeName = name\n        self.notationName = notation\n        self.childNodes = NodeList()\n        self._identified_mixin_init(publicId, systemId)\n\n    def _get_actualEncoding(self):\n        return self.actualEncoding\n\n    def _get_encoding(self):\n        return self.encoding\n\n    def _get_version(self):\n        return self.version\n\n    def appendChild(self, newChild):\n        raise xml.dom.HierarchyRequestErr(\n            \"cannot append children to an entity node\")\n\n    def insertBefore(self, newChild, refChild):\n        raise xml.dom.HierarchyRequestErr(\n            \"cannot insert children below an entity node\")\n\n    def removeChild(self, oldChild):\n        raise xml.dom.HierarchyRequestErr(\n            \"cannot remove children from an entity node\")\n\n    def replaceChild(self, newChild, oldChild):\n        raise xml.dom.HierarchyRequestErr(\n            \"cannot replace children of an entity node\")\n\nclass Notation(Identified, Childless, Node):\n    nodeType = Node.NOTATION_NODE\n    nodeValue = None\n\n    def __init__(self, name, publicId, systemId):\n        self.nodeName = name\n        self._identified_mixin_init(publicId, systemId)\n\n\nclass DOMImplementation(DOMImplementationLS):\n    _features = [(\"core\", \"1.0\"),\n                 (\"core\", \"2.0\"),\n                 (\"core\", None),\n                 (\"xml\", \"1.0\"),\n                 (\"xml\", \"2.0\"),\n                 (\"xml\", None),\n                 (\"ls-load\", \"3.0\"),\n                 (\"ls-load\", None),\n                 ]\n\n    def hasFeature(self, feature, version):\n        if version == \"\":\n            version = None\n        return (feature.lower(), version) in self._features\n\n    def createDocument(self, namespaceURI, qualifiedName, doctype):\n        if doctype and doctype.parentNode is not None:\n            raise xml.dom.WrongDocumentErr(\n                \"doctype object owned by another DOM tree\")\n        doc = self._create_document()\n\n        add_root_element = not (namespaceURI is None\n                                and qualifiedName is None\n                                and doctype is None)\n\n        if not qualifiedName and add_root_element:\n            # The spec is unclear what to raise here; SyntaxErr\n            # would be the other obvious candidate. Since Xerces raises\n            # InvalidCharacterErr, and since SyntaxErr is not listed\n            # for createDocument, that seems to be the better choice.\n            # XXX: need to check for illegal characters here and in\n            # createElement.\n\n            # DOM Level III clears this up when talking about the return value\n            # of this function.  If namespaceURI, qName and DocType are\n            # Null the document is returned without a document element\n            # Otherwise if doctype or namespaceURI are not None\n            # Then we go back to the above problem\n            raise xml.dom.InvalidCharacterErr(\"Element with no name\")\n\n        if add_root_element:\n            prefix, localname = _nssplit(qualifiedName)\n            if prefix == \"xml\" \\\n               and namespaceURI != \"http://www.w3.org/XML/1998/namespace\":\n                raise xml.dom.NamespaceErr(\"illegal use of 'xml' prefix\")\n            if prefix and not namespaceURI:\n                raise xml.dom.NamespaceErr(\n                    \"illegal use of prefix without namespaces\")\n            element = doc.createElementNS(namespaceURI, qualifiedName)\n            if doctype:\n                doc.appendChild(doctype)\n            doc.appendChild(element)\n\n        if doctype:\n            doctype.parentNode = doctype.ownerDocument = doc\n\n        doc.doctype = doctype\n        doc.implementation = self\n        return doc\n\n    def createDocumentType(self, qualifiedName, publicId, systemId):\n        doctype = DocumentType(qualifiedName)\n        doctype.publicId = publicId\n        doctype.systemId = systemId\n        return doctype\n\n    # DOM Level 3 (WD 9 April 2002)\n\n    def getInterface(self, feature):\n        if self.hasFeature(feature, None):\n            return self\n        else:\n            return None\n\n    # internal\n    def _create_document(self):\n        return Document()\n\nclass ElementInfo(object):\n    \"\"\"Object that represents content-model information for an element.\n\n    This implementation is not expected to be used in practice; DOM\n    builders should provide implementations which do the right thing\n    using information available to it.\n\n    \"\"\"\n\n    __slots__ = 'tagName',\n\n    def __init__(self, name):\n        self.tagName = name\n\n    def getAttributeType(self, aname):\n        return _no_type\n\n    def getAttributeTypeNS(self, namespaceURI, localName):\n        return _no_type\n\n    def isElementContent(self):\n        return False\n\n    def isEmpty(self):\n        \"\"\"Returns true iff this element is declared to have an EMPTY\n        content model.\"\"\"\n        return False\n\n    def isId(self, aname):\n        \"\"\"Returns true iff the named attribute is a DTD-style ID.\"\"\"\n        return False\n\n    def isIdNS(self, namespaceURI, localName):\n        \"\"\"Returns true iff the identified attribute is a DTD-style ID.\"\"\"\n        return False\n\n    def __getstate__(self):\n        return self.tagName\n\n    def __setstate__(self, state):\n        self.tagName = state\n\ndef _clear_id_cache(node):\n    if node.nodeType == Node.DOCUMENT_NODE:\n        node._id_cache.clear()\n        node._id_search_stack = None\n    elif _in_document(node):\n        node.ownerDocument._id_cache.clear()\n        node.ownerDocument._id_search_stack= None\n\nclass Document(Node, DocumentLS):\n    __slots__ = ('_elem_info', 'doctype',\n                 '_id_search_stack', 'childNodes', '_id_cache')\n    _child_node_types = (Node.ELEMENT_NODE, Node.PROCESSING_INSTRUCTION_NODE,\n                         Node.COMMENT_NODE, Node.DOCUMENT_TYPE_NODE)\n\n    implementation = DOMImplementation()\n    nodeType = Node.DOCUMENT_NODE\n    nodeName = \"#document\"\n    nodeValue = None\n    attributes = None\n    parentNode = None\n    previousSibling = nextSibling = None\n\n\n    # Document attributes from Level 3 (WD 9 April 2002)\n\n    actualEncoding = None\n    encoding = None\n    standalone = None\n    version = None\n    strictErrorChecking = False\n    errorHandler = None\n    documentURI = None\n\n    _magic_id_count = 0\n\n    def __init__(self):\n        self.doctype = None\n        self.childNodes = NodeList()\n        # mapping of (namespaceURI, localName) -> ElementInfo\n        #        and tagName -> ElementInfo\n        self._elem_info = {}\n        self._id_cache = {}\n        self._id_search_stack = None\n\n    def _get_elem_info(self, element):\n        if element.namespaceURI:\n            key = element.namespaceURI, element.localName\n        else:\n            key = element.tagName\n        return self._elem_info.get(key)\n\n    def _get_actualEncoding(self):\n        return self.actualEncoding\n\n    def _get_doctype(self):\n        return self.doctype\n\n    def _get_documentURI(self):\n        return self.documentURI\n\n    def _get_encoding(self):\n        return self.encoding\n\n    def _get_errorHandler(self):\n        return self.errorHandler\n\n    def _get_standalone(self):\n        return self.standalone\n\n    def _get_strictErrorChecking(self):\n        return self.strictErrorChecking\n\n    def _get_version(self):\n        return self.version\n\n    def appendChild(self, node):\n        if node.nodeType not in self._child_node_types:\n            raise xml.dom.HierarchyRequestErr(\n                \"%s cannot be child of %s\" % (repr(node), repr(self)))\n        if node.parentNode is not None:\n            # This needs to be done before the next test since this\n            # may *be* the document element, in which case it should\n            # end up re-ordered to the end.\n            node.parentNode.removeChild(node)\n\n        if node.nodeType == Node.ELEMENT_NODE \\\n           and self._get_documentElement():\n            raise xml.dom.HierarchyRequestErr(\n                \"two document elements disallowed\")\n        return Node.appendChild(self, node)\n\n    def removeChild(self, oldChild):\n        try:\n            self.childNodes.remove(oldChild)\n        except ValueError:\n            raise xml.dom.NotFoundErr()\n        oldChild.nextSibling = oldChild.previousSibling = None\n        oldChild.parentNode = None\n        if self.documentElement is oldChild:\n            self.documentElement = None\n\n        return oldChild\n\n    def _get_documentElement(self):\n        for node in self.childNodes:\n            if node.nodeType == Node.ELEMENT_NODE:\n                return node\n\n    def unlink(self):\n        if self.doctype is not None:\n            self.doctype.unlink()\n            self.doctype = None\n        Node.unlink(self)\n\n    def cloneNode(self, deep):\n        if not deep:\n            return None\n        clone = self.implementation.createDocument(None, None, None)\n        clone.encoding = self.encoding\n        clone.standalone = self.standalone\n        clone.version = self.version\n        for n in self.childNodes:\n            childclone = _clone_node(n, deep, clone)\n            assert childclone.ownerDocument.isSameNode(clone)\n            clone.childNodes.append(childclone)\n            if childclone.nodeType == Node.DOCUMENT_NODE:\n                assert clone.documentElement is None\n            elif childclone.nodeType == Node.DOCUMENT_TYPE_NODE:\n                assert clone.doctype is None\n                clone.doctype = childclone\n            childclone.parentNode = clone\n        self._call_user_data_handler(xml.dom.UserDataHandler.NODE_CLONED,\n                                     self, clone)\n        return clone\n\n    def createDocumentFragment(self):\n        d = DocumentFragment()\n        d.ownerDocument = self\n        return d\n\n    def createElement(self, tagName):\n        e = Element(tagName)\n        e.ownerDocument = self\n        return e\n\n    def createTextNode(self, data):\n        if not isinstance(data, str):\n            raise TypeError(\"node contents must be a string\")\n        t = Text()\n        t.data = data\n        t.ownerDocument = self\n        return t\n\n    def createCDATASection(self, data):\n        if not isinstance(data, str):\n            raise TypeError(\"node contents must be a string\")\n        c = CDATASection()\n        c.data = data\n        c.ownerDocument = self\n        return c\n\n    def createComment(self, data):\n        c = Comment(data)\n        c.ownerDocument = self\n        return c\n\n    def createProcessingInstruction(self, target, data):\n        p = ProcessingInstruction(target, data)\n        p.ownerDocument = self\n        return p\n\n    def createAttribute(self, qName):\n        a = Attr(qName)\n        a.ownerDocument = self\n        a.value = \"\"\n        return a\n\n    def createElementNS(self, namespaceURI, qualifiedName):\n        prefix, localName = _nssplit(qualifiedName)\n        e = Element(qualifiedName, namespaceURI, prefix)\n        e.ownerDocument = self\n        return e\n\n    def createAttributeNS(self, namespaceURI, qualifiedName):\n        prefix, localName = _nssplit(qualifiedName)\n        a = Attr(qualifiedName, namespaceURI, localName, prefix)\n        a.ownerDocument = self\n        a.value = \"\"\n        return a\n\n    # A couple of implementation-specific helpers to create node types\n    # not supported by the W3C DOM specs:\n\n    def _create_entity(self, name, publicId, systemId, notationName):\n        e = Entity(name, publicId, systemId, notationName)\n        e.ownerDocument = self\n        return e\n\n    def _create_notation(self, name, publicId, systemId):\n        n = Notation(name, publicId, systemId)\n        n.ownerDocument = self\n        return n\n\n    def getElementById(self, id):\n        if id in self._id_cache:\n            return self._id_cache[id]\n        if not (self._elem_info or self._magic_id_count):\n            return None\n\n        stack = self._id_search_stack\n        if stack is None:\n            # we never searched before, or the cache has been cleared\n            stack = [self.documentElement]\n            self._id_search_stack = stack\n        elif not stack:\n            # Previous search was completed and cache is still valid;\n            # no matching node.\n            return None\n\n        result = None\n        while stack:\n            node = stack.pop()\n            # add child elements to stack for continued searching\n            stack.extend([child for child in node.childNodes\n                          if child.nodeType in _nodeTypes_with_children])\n            # check this node\n            info = self._get_elem_info(node)\n            if info:\n                # We have to process all ID attributes before\n                # returning in order to get all the attributes set to\n                # be IDs using Element.setIdAttribute*().\n                for attr in node.attributes.values():\n                    if attr.namespaceURI:\n                        if info.isIdNS(attr.namespaceURI, attr.localName):\n                            self._id_cache[attr.value] = node\n                            if attr.value == id:\n                                result = node\n                            elif not node._magic_id_nodes:\n                                break\n                    elif info.isId(attr.name):\n                        self._id_cache[attr.value] = node\n                        if attr.value == id:\n                            result = node\n                        elif not node._magic_id_nodes:\n                            break\n                    elif attr._is_id:\n                        self._id_cache[attr.value] = node\n                        if attr.value == id:\n                            result = node\n                        elif node._magic_id_nodes == 1:\n                            break\n            elif node._magic_id_nodes:\n                for attr in node.attributes.values():\n                    if attr._is_id:\n                        self._id_cache[attr.value] = node\n                        if attr.value == id:\n                            result = node\n            if result is not None:\n                break\n        return result\n\n    def getElementsByTagName(self, name):\n        return _get_elements_by_tagName_helper(self, name, NodeList())\n\n    def getElementsByTagNameNS(self, namespaceURI, localName):\n        return _get_elements_by_tagName_ns_helper(\n            self, namespaceURI, localName, NodeList())\n\n    def isSupported(self, feature, version):\n        return self.implementation.hasFeature(feature, version)\n\n    def importNode(self, node, deep):\n        if node.nodeType == Node.DOCUMENT_NODE:\n            raise xml.dom.NotSupportedErr(\"cannot import document nodes\")\n        elif node.nodeType == Node.DOCUMENT_TYPE_NODE:\n            raise xml.dom.NotSupportedErr(\"cannot import document type nodes\")\n        return _clone_node(node, deep, self)\n\n    def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\", encoding=None):\n        if encoding is None:\n            writer.write('<?xml version=\"1.0\" ?>'+newl)\n        else:\n            writer.write('<?xml version=\"1.0\" encoding=\"%s\"?>%s' % (\n                encoding, newl))\n        for node in self.childNodes:\n            node.writexml(writer, indent, addindent, newl)\n\n    # DOM Level 3 (WD 9 April 2002)\n\n    def renameNode(self, n, namespaceURI, name):\n        if n.ownerDocument is not self:\n            raise xml.dom.WrongDocumentErr(\n                \"cannot rename nodes from other documents;\\n\"\n                \"expected %s,\\nfound %s\" % (self, n.ownerDocument))\n        if n.nodeType not in (Node.ELEMENT_NODE, Node.ATTRIBUTE_NODE):\n            raise xml.dom.NotSupportedErr(\n                \"renameNode() only applies to element and attribute nodes\")\n        if namespaceURI != EMPTY_NAMESPACE:\n            if ':' in name:\n                prefix, localName = name.split(':', 1)\n                if (  prefix == \"xmlns\"\n                      and namespaceURI != xml.dom.XMLNS_NAMESPACE):\n                    raise xml.dom.NamespaceErr(\n                        \"illegal use of 'xmlns' prefix\")\n            else:\n                if (  name == \"xmlns\"\n                      and namespaceURI != xml.dom.XMLNS_NAMESPACE\n                      and n.nodeType == Node.ATTRIBUTE_NODE):\n                    raise xml.dom.NamespaceErr(\n                        \"illegal use of the 'xmlns' attribute\")\n                prefix = None\n                localName = name\n        else:\n            prefix = None\n            localName = None\n        if n.nodeType == Node.ATTRIBUTE_NODE:\n            element = n.ownerElement\n            if element is not None:\n                is_id = n._is_id\n                element.removeAttributeNode(n)\n        else:\n            element = None\n        n.prefix = prefix\n        n._localName = localName\n        n.namespaceURI = namespaceURI\n        n.nodeName = name\n        if n.nodeType == Node.ELEMENT_NODE:\n            n.tagName = name\n        else:\n            # attribute node\n            n.name = name\n            if element is not None:\n                element.setAttributeNode(n)\n                if is_id:\n                    element.setIdAttributeNode(n)\n        # It's not clear from a semantic perspective whether we should\n        # call the user data handlers for the NODE_RENAMED event since\n        # we're re-using the existing node.  The draft spec has been\n        # interpreted as meaning \"no, don't call the handler unless a\n        # new node is created.\"\n        return n\n\ndefproperty(Document, \"documentElement\",\n            doc=\"Top-level element of this document.\")\n\n\ndef _clone_node(node, deep, newOwnerDocument):\n    \"\"\"\n    Clone a node and give it the new owner document.\n    Called by Node.cloneNode and Document.importNode\n    \"\"\"\n    if node.ownerDocument.isSameNode(newOwnerDocument):\n        operation = xml.dom.UserDataHandler.NODE_CLONED\n    else:\n        operation = xml.dom.UserDataHandler.NODE_IMPORTED\n    if node.nodeType == Node.ELEMENT_NODE:\n        clone = newOwnerDocument.createElementNS(node.namespaceURI,\n                                                 node.nodeName)\n        for attr in node.attributes.values():\n            clone.setAttributeNS(attr.namespaceURI, attr.nodeName, attr.value)\n            a = clone.getAttributeNodeNS(attr.namespaceURI, attr.localName)\n            a.specified = attr.specified\n\n        if deep:\n            for child in node.childNodes:\n                c = _clone_node(child, deep, newOwnerDocument)\n                clone.appendChild(c)\n\n    elif node.nodeType == Node.DOCUMENT_FRAGMENT_NODE:\n        clone = newOwnerDocument.createDocumentFragment()\n        if deep:\n            for child in node.childNodes:\n                c = _clone_node(child, deep, newOwnerDocument)\n                clone.appendChild(c)\n\n    elif node.nodeType == Node.TEXT_NODE:\n        clone = newOwnerDocument.createTextNode(node.data)\n    elif node.nodeType == Node.CDATA_SECTION_NODE:\n        clone = newOwnerDocument.createCDATASection(node.data)\n    elif node.nodeType == Node.PROCESSING_INSTRUCTION_NODE:\n        clone = newOwnerDocument.createProcessingInstruction(node.target,\n                                                             node.data)\n    elif node.nodeType == Node.COMMENT_NODE:\n        clone = newOwnerDocument.createComment(node.data)\n    elif node.nodeType == Node.ATTRIBUTE_NODE:\n        clone = newOwnerDocument.createAttributeNS(node.namespaceURI,\n                                                   node.nodeName)\n        clone.specified = True\n        clone.value = node.value\n    elif node.nodeType == Node.DOCUMENT_TYPE_NODE:\n        assert node.ownerDocument is not newOwnerDocument\n        operation = xml.dom.UserDataHandler.NODE_IMPORTED\n        clone = newOwnerDocument.implementation.createDocumentType(\n            node.name, node.publicId, node.systemId)\n        clone.ownerDocument = newOwnerDocument\n        if deep:\n            clone.entities._seq = []\n            clone.notations._seq = []\n            for n in node.notations._seq:\n                notation = Notation(n.nodeName, n.publicId, n.systemId)\n                notation.ownerDocument = newOwnerDocument\n                clone.notations._seq.append(notation)\n                if hasattr(n, '_call_user_data_handler'):\n                    n._call_user_data_handler(operation, n, notation)\n            for e in node.entities._seq:\n                entity = Entity(e.nodeName, e.publicId, e.systemId,\n                                e.notationName)\n                entity.actualEncoding = e.actualEncoding\n                entity.encoding = e.encoding\n                entity.version = e.version\n                entity.ownerDocument = newOwnerDocument\n                clone.entities._seq.append(entity)\n                if hasattr(e, '_call_user_data_handler'):\n                    e._call_user_data_handler(operation, n, entity)\n    else:\n        # Note the cloning of Document and DocumentType nodes is\n        # implementation specific.  minidom handles those cases\n        # directly in the cloneNode() methods.\n        raise xml.dom.NotSupportedErr(\"Cannot clone node %s\" % repr(node))\n\n    # Check for _call_user_data_handler() since this could conceivably\n    # used with other DOM implementations (one of the FourThought\n    # DOMs, perhaps?).\n    if hasattr(node, '_call_user_data_handler'):\n        node._call_user_data_handler(operation, node, clone)\n    return clone\n\n\ndef _nssplit(qualifiedName):\n    fields = qualifiedName.split(':', 1)\n    if len(fields) == 2:\n        return fields\n    else:\n        return (None, fields[0])\n\n\ndef _do_pulldom_parse(func, args, kwargs):\n    events = func(*args, **kwargs)\n    toktype, rootNode = events.getEvent()\n    events.expandNode(rootNode)\n    events.clear()\n    return rootNode\n\ndef parse(file, parser=None, bufsize=None):\n    \"\"\"Parse a file into a DOM by filename or file object.\"\"\"\n    if parser is None and not bufsize:\n        from xml.dom import expatbuilder\n        return expatbuilder.parse(file)\n    else:\n        from xml.dom import pulldom\n        return _do_pulldom_parse(pulldom.parse, (file,),\n            {'parser': parser, 'bufsize': bufsize})\n\ndef parseString(string, parser=None):\n    \"\"\"Parse a file into a DOM from a string.\"\"\"\n    if parser is None:\n        from xml.dom import expatbuilder\n        return expatbuilder.parseString(string)\n    else:\n        from xml.dom import pulldom\n        return _do_pulldom_parse(pulldom.parseString, (string,),\n                                 {'parser': parser})\n\ndef getDOMImplementation(features=None):\n    if features:\n        if isinstance(features, str):\n            features = domreg._parse_feature_string(features)\n        for f, v in features:\n            if not Document.implementation.hasFeature(f, v):\n                return None\n    return Document.implementation\n"], "modulefinder": [".js", "var $module=(function($B){\n\nvar _b_=$B.builtins\nvar _mod = {}\n\n$ModuleFinderDict = {__class__:$B.$type,__name__:'ModuleFinder'}\n$ModuleFinderDict.__mro__ = [$ModuleFinderDict,_b_.object.$dict]\n\n$ModuleFinderDict.run_script = function(self, pathname){\n    // pathname is the url of a Python script\n    var py_src = _b_.$open(pathname).read()\n    // transform into internal Brython tree structure\n    var root = $B.py2js(py_src)\n    // walk the tree to find occurences of imports\n    function walk(node){\n        var modules = []\n        var ctx = node.context\n        if(ctx && ctx.type=='node'){ctx = ctx.tree[0]}\n\n        if(ctx && ctx.type==\"import\"){\n            for(var i=0;i<ctx.tree.length;i++){\n                if(modules.indexOf(ctx.tree[i].name)==-1){\n                    modules.push(ctx.tree[i].name)\n                }\n            }\n        }else if(ctx && ctx.type==\"from\"){\n            if(modules.indexOf(ctx.module)==-1){\n                modules.push(ctx.module)\n            }\n        }\n        \n        for(var i=0;i<node.children.length;i++){\n            mods = walk(node.children[i])\n            for(var j=0;j<mods.length;j++){\n                if(modules.indexOf(mods[j])==-1){modules.push(mods[j])}\n            }\n        }\n        return modules\n    }\n    self.modules = walk(root)\n}\n\n_mod.ModuleFinder = function(){return {__class__:$ModuleFinderDict}\n}\n_mod.ModuleFinder.$dict = $ModuleFinderDict\n_mod.ModuleFinder.__class__ = $B.$factory\n$ModuleFinderDict.$factory = _mod.ModuleFinder\n\nreturn _mod\n})(__BRYTHON__)\n"], "unittest.test.support": [".py", "import unittest\n\n\nclass TestEquality(object):\n    \"\"\"Used as a mixin for TestCase\"\"\"\n\n    # Check for a valid __eq__ implementation\n    def test_eq(self):\n        for obj_1, obj_2 in self.eq_pairs:\n            self.assertEqual(obj_1, obj_2)\n            self.assertEqual(obj_2, obj_1)\n\n    # Check for a valid __ne__ implementation\n    def test_ne(self):\n        for obj_1, obj_2 in self.ne_pairs:\n            self.assertNotEqual(obj_1, obj_2)\n            self.assertNotEqual(obj_2, obj_1)\n\nclass TestHashing(object):\n    \"\"\"Used as a mixin for TestCase\"\"\"\n\n    # Check for a valid __hash__ implementation\n    def test_hash(self):\n        for obj_1, obj_2 in self.eq_pairs:\n            try:\n                if not hash(obj_1) == hash(obj_2):\n                    self.fail(\"%r and %r do not hash equal\" % (obj_1, obj_2))\n            except KeyboardInterrupt:\n                raise\n            except Exception as e:\n                self.fail(\"Problem hashing %r and %r: %s\" % (obj_1, obj_2, e))\n\n        for obj_1, obj_2 in self.ne_pairs:\n            try:\n                if hash(obj_1) == hash(obj_2):\n                    self.fail(\"%s and %s hash equal, but shouldn't\" %\n                              (obj_1, obj_2))\n            except KeyboardInterrupt:\n                raise\n            except Exception as e:\n                self.fail(\"Problem hashing %s and %s: %s\" % (obj_1, obj_2, e))\n\n\nclass LoggingResult(unittest.TestResult):\n    def __init__(self, log):\n        self._events = log\n        super().__init__()\n\n    def startTest(self, test):\n        self._events.append('startTest')\n        super().startTest(test)\n\n    def startTestRun(self):\n        self._events.append('startTestRun')\n        super(LoggingResult, self).startTestRun()\n\n    def stopTest(self, test):\n        self._events.append('stopTest')\n        super().stopTest(test)\n\n    def stopTestRun(self):\n        self._events.append('stopTestRun')\n        super(LoggingResult, self).stopTestRun()\n\n    def addFailure(self, *args):\n        self._events.append('addFailure')\n        super().addFailure(*args)\n\n    def addSuccess(self, *args):\n        self._events.append('addSuccess')\n        super(LoggingResult, self).addSuccess(*args)\n\n    def addError(self, *args):\n        self._events.append('addError')\n        super().addError(*args)\n\n    def addSkip(self, *args):\n        self._events.append('addSkip')\n        super(LoggingResult, self).addSkip(*args)\n\n    def addExpectedFailure(self, *args):\n        self._events.append('addExpectedFailure')\n        super(LoggingResult, self).addExpectedFailure(*args)\n\n    def addUnexpectedSuccess(self, *args):\n        self._events.append('addUnexpectedSuccess')\n        super(LoggingResult, self).addUnexpectedSuccess(*args)\n\n\nclass ResultWithNoStartTestRunStopTestRun(object):\n    \"\"\"An object honouring TestResult before startTestRun/stopTestRun.\"\"\"\n\n    def __init__(self):\n        self.failures = []\n        self.errors = []\n        self.testsRun = 0\n        self.skipped = []\n        self.expectedFailures = []\n        self.unexpectedSuccesses = []\n        self.shouldStop = False\n\n    def startTest(self, test):\n        pass\n\n    def stopTest(self, test):\n        pass\n\n    def addError(self, test):\n        pass\n\n    def addFailure(self, test):\n        pass\n\n    def addSuccess(self, test):\n        pass\n\n    def wasSuccessful(self):\n        return True\n"], "_jsre": [".js", "var $module=(function($B){\n\n    var _b_ = $B.builtins\n    var $s=[]\n    for(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\n    eval($s.join(';'))\n\n    var JSObject = $B.JSObject\n\n    var obj = {__class__:$module,\n        __str__: function(){return \"<module 're'>\"}\n    }\n    obj.A = obj.ASCII = 256\n    obj.I = obj.IGNORECASE = 2 // 'i'\n    obj.L = obj.LOCALE = 4\n    obj.M = obj.MULTILINE = 8 // 'm'\n    obj.S = obj.DOTALL = 16\n    obj.U = obj.UNICODE = 32\n    obj.X = obj.VERBOSE = 64\n    obj._is_valid = function(pattern) {\n        if ($B.$options.re=='pyre') return false  //force use of python's re module\n        if ($B.$options.re=='jsre') return true   //force use of brythons re module\n        // FIXME: Improve\n\n        if (!isinstance(pattern, str)) {\n           // this is probably a SRE_PATTERN, so return false, and let\n           // python's re module handle this.\n           return false\n        }\n        var is_valid = false;\n        try {\n            new RegExp(pattern);\n            is_valid = true;\n        }\n        catch(e) {}\n        if (!is_valid) return false  //if js won't parse the pattern return false\n\n        // using reference http://www.regular-expressions.info/\n        // to compare python re and javascript regex libraries\n\n        // look for things javascript does not support\n        // check for name capturing group\n        var mylist=['?P=', '?P<', '(?#', '(?<=', '(?<!', '(?(']\n        for(var i=0; i < mylist.length; i++) {\n           if (pattern.indexOf(mylist[i]) > -1) return false\n        }\n\n        var re_list=['\\{,\\d+\\}']\n        for(var i=0; i < re_list.length; i++) {\n           var _re=new RegExp(re_list[i])\n           if (_re.test(pattern)) return false\n        }\n\n        // it looks like the pattern has passed all our tests so lets assume\n        // javascript can handle this pattern.\n        return true\n    }\n    var $SRE_PatternDict = {\n        __class__:$B.$type,\n        __name__:'SRE_Pattern'\n    }\n    $SRE_PatternDict.__mro__ = [$SRE_PatternDict,object.$dict]\n    $SRE_PatternDict.findall = function(self,string){\n        return obj.findall(self.pattern,string,self.flags)\n    }\n    $SRE_PatternDict.finditer = function(self,string){\n        return obj.finditer(self.pattern,string,self.flags)\n    }\n    $SRE_PatternDict.match = function(self,string){\n        return obj.match(self.pattern,string,self.flags)\n    }\n    $SRE_PatternDict.search = function(self,string){\n        return obj.search(self.pattern,string,self.flags)\n    }\n    function normflags(flags) {\n        return ((flags & obj.I)? 'i' : '') + ((flags & obj.M)? 'm' : '');\n    }\n    obj.compile = function(pattern,flags){\n        return {\n            __class__:$SRE_PatternDict,\n            pattern:pattern,\n            flags:normflags(flags)\n        }\n    }\n    obj.escape = function(string){\n        // Escape all the characters in pattern except ASCII letters, numbers \n        // and '_'. This is useful if you want to match an arbitrary literal \n        // string that may have regular expression metacharacters in it.\n        var res = ''\n        var ok = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_'\n        for(var i=0;i<string.length;i++){\n            if(ok.search(string.charAt(i))>-1){res += string.charAt(i)}\n        }\n        return res\n    }\n    obj.findall = function(pattern,string,flags){\n        var $ns=$B.$MakeArgs('re.findall',arguments,['pattern','string'],[],'args','kw') ,\n            args = $ns['args'] ,\n            _flags = 0;\n        if(args.length>0){var flags=args[0]}\n        else{var _flags = getattr($ns['kw'], 'get')('flags',0)}\n        \n        var flags = normflags();\n        flags += 'gm'\n        var jsp = new RegExp(pattern,flags) ,\n            jsmatch = string.match(jsp);\n        if(jsmatch===null){return []}\n        return jsmatch\n    }\n    obj.finditer = function(pattern,string,flags){\n        var $ns=$B.$MakeArgs('re.finditer',arguments,['pattern','string'],[],'args','kw'),\n            args = $ns['args'],\n            _flags = 0;\n        if(args.length>0){var flags=args[0]}\n        else{var _flags = getattr($ns['kw'], 'get')('flags',0)}\n        \n        var flags = normflags();\n        flags += 'gm'\n        var jsp = new RegExp(pattern,flags),\n            jsmatch = string.match(jsp);\n        if(jsmatch===null){return []}\n        \n        var _list=[]\n        for (var j=0; j < jsmatch.length; j++) {\n            var mo = {}\n            mo._match=jsmatch[j]\n            mo.group = function(){\n               var res = []\n               for(var i=0;i<arguments.length;i++){\n                   if(jsmatch[arguments[i]]===undefined){res.push(None)}\n                   else{res.push(jsmatch[arguments[i]])}\n               }\n               if(arguments.length===1){return res[0]}\n               return tuple(res)\n            }\n            mo.groups = function(_default){\n               if(_default===undefined){_default=None}\n               var res = []\n               for(var i=1;i<jsmatch.length;i++){\n                  if(jsmatch[i]===undefined){res.push(_default)}\n                  else{res.push(jsmatch[i])}\n               }\n               return tuple(res)\n            }\n            mo.start = function(){return mo._match.index}\n            mo.end = function(){return mo._match.length-mo._match.index}\n            mo.string = string\n            _list.push(JSObject(mo))\n        }\n        return _list\n    }\n    obj.search = function(pattern,string){\n        var $ns=$B.$MakeArgs('re.search',arguments,['pattern','string'],[],'args','kw')\n        var args = $ns['args']\n        if(args.length>0){var flags=args[0]}\n        else{var flags = getattr($ns['kw'],'get')('flags','')}\n        flags = normflags(flags);\n        var jsp = new RegExp(pattern,flags)\n        var jsmatch = string.match(jsp)\n        if(jsmatch===null){return None}\n        var mo = new Object()\n        mo.group = function(){\n            var res = []\n            for(var i=0;i<arguments.length;i++){\n                if(jsmatch[arguments[i]]===undefined){res.push(None)}\n                else{res.push(jsmatch[arguments[i]])}\n            }\n            if(arguments.length===1){return res[0]}\n            return tuple(res)\n        }\n        mo.groups = function(_default){\n            if(_default===undefined){_default=None}\n            var res = []\n            for(var i=1;i<jsmatch.length;i++){\n                if(jsmatch[i]===undefined){res.push(_default)}\n                else{res.push(jsmatch[i])}\n            }\n            return tuple(res)\n        }\n        mo.start = function(){return jsmatch.index}\n        mo.end = function(){return jsmatch.length-jsmatch.index}\n        mo.string = string\n        return JSObject(mo)\n    }\n    obj.sub = function(pattern,repl,string){\n        var $ns=$B.$MakeArgs('re.search',arguments,['pattern','repl','string'],[],'args','kw')\n        for($var in $ns){eval(\"var \"+$var+\"=$ns[$var]\")}\n        var args = $ns['args']\n        var count = _b_.dict.$dict.get($ns['kw'],'count',0)\n        var flags = _b_.dict.$dict.get($ns['kw'],'flags','')\n        if(args.length>0){var count=args[0]}\n        if(args.length>1){var flags=args[1]}\n        flags = normflags(flags);\n        if(typeof repl===\"string\"){\n            // backreferences are \\1, \\2... in Python but $1,$2... in Javascript\n            repl = repl.replace(/\\\\(\\d+)/g,'$$$1')\n        }else if(typeof repl===\"function\"){\n            // the argument passed to the Python function is the match object\n            // the arguments passed to the Javascript function are :\n            // - the matched substring\n            // - the matched groups\n            // - the offset of the matched substring inside the string\n            // - the string being examined\n            var $repl1 = function(){\n                var mo = Object()\n                mo.string = arguments[arguments.length-1]\n                var start = arguments[arguments.length-2]\n                var end = start + arguments[0].length\n                mo.start = function(){return start}\n                mo.end = function(){return end}\n                groups = []\n                for(var i=1;i<arguments.length-2;i++){groups.push(arguments[i])}\n                mo.groups = function(_default){\n                    if(_default===undefined){_default=None}\n                    var res = []\n                    for(var i=0;i<groups.length;i++){\n                        if(groups[i]===undefined){res.push(_default)}\n                        else{res.push(groups[i])}\n                    }\n                    return res\n                }\n                return repl(JSObject(mo))\n            }\n        }\n        if(count==0){flags+='g'}\n        var jsp = new RegExp(pattern,flags)\n        if(typeof repl==='function'){return string.replace(jsp,$repl1)}\n        else{return string.replace(jsp,repl)}\n    }\n    obj.match = (function(search_func){\n        return function(){\n            // match is like search but pattern must start with ^\n            var pattern = arguments[0]\n            if(pattern.charAt(0)!=='^'){pattern = '^'+pattern}\n            var args = [pattern]\n            for(var i=1;i<arguments.length;i++){args.push(arguments[i])}\n            return search_func.apply(null,args)\n        }\n    })(obj.search)\n\n    return obj\n}\n)(__BRYTHON__)\n"], "posix": [".py", "\"\"\"This module provides access to operating system functionality that is\nstandardized by the C Standard and the POSIX standard (a thinly\ndisguised Unix interface).  Refer to the library manual and\ncorresponding Unix manual entries for more information on calls.\"\"\"\n\nimport datetime\n\nF_OK = 0\n\nO_APPEND = 8\n\nO_BINARY = 32768\n\nO_CREAT = 256\n\nO_EXCL = 1024\n\nO_NOINHERIT = 128\n\nO_RANDOM = 16\n\nO_RDONLY = 0\n\nO_RDWR = 2\n\nO_SEQUENTIAL = 32\n\nO_SHORT_LIVED = 4096\n\nO_TEMPORARY = 64\n\nO_TEXT = 16384\n\nO_TRUNC = 512\n\nO_WRONLY = 1\n\nP_DETACH = 4\n\nP_NOWAIT = 1\n\nP_NOWAITO = 3\n\nP_OVERLAY = 2\n\nP_WAIT = 0\n\nR_OK = 4\n\nTMP_MAX = 32767\n\nW_OK = 2\n\nX_OK = 1\n\nclass __loader__:\n    pass\n\ndef _exit(*args,**kw):\n    \"\"\"_exit(status)    \n    Exit to the system with specified status, without normal exit processing.\"\"\"\n    pass\n\ndef _getdiskusage(*args,**kw):\n    \"\"\"_getdiskusage(path) -> (total, free)    \n    Return disk usage statistics about the given path as (total, free) tuple.\"\"\"\n    pass\n\ndef _getfileinformation(*args,**kw):\n    pass\n\ndef _getfinalpathname(*args,**kw):\n    pass\n\ndef _getfullpathname(*args,**kw):\n    pass\n\n_have_functions = ['MS_WINDOWS']\n\ndef _isdir(*args,**kw):\n    \"\"\"Return true if the pathname refers to an existing directory.\"\"\"\n    pass\n\ndef abort(*args,**kw):\n    \"\"\"abort() -> does not return!    \n    Abort the interpreter immediately.  This 'dumps core' or otherwise fails\n    in the hardest way possible on the hosting operating system.\"\"\"\n    pass\n\ndef access(*args,**kw):\n    \"\"\"access(path, mode, *, dir_fd=None, effective_ids=False, follow_symlinks=True)    \n    Use the real uid/gid to test for access to a path.  Returns True if granted,\n    False otherwise.\n    \n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n    If effective_ids is True, access will use the effective uid/gid instead of\n      the real uid/gid.\n    If follow_symlinks is False, and the last element of the path is a symbolic\n      link, access will examine the symbolic link itself instead of the file the\n      link points to.\n    dir_fd, effective_ids, and follow_symlinks may not be implemented\n      on your platform.  If they are unavailable, using them will raise a\n      NotImplementedError.\n    \n    Note that most operations will use the effective uid/gid, therefore this\n      routine can be used in a suid/sgid environment to test if the invoking user\n      has the specified access to the path.\n    The mode argument can be F_OK to test existence, or the inclusive-OR\n      of R_OK, W_OK, and X_OK.\"\"\"\n    pass\n\ndef chdir(*args,**kw):\n    \"\"\"chdir(path)    \n    Change the current working directory to the specified path.\n    \n    path may always be specified as a string.\n    On some platforms, path may also be specified as an open file descriptor.\n      If this functionality is unavailable, using it raises an exception.\"\"\"\n    pass\n\ndef chmod(*args,**kw):\n    \"\"\"chmod(path, mode, *, dir_fd=None, follow_symlinks=True)    \n    Change the access permissions of a file.\n    \n    path may always be specified as a string.\n    On some platforms, path may also be specified as an open file descriptor.\n      If this functionality is unavailable, using it raises an exception.\n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n    If follow_symlinks is False, and the last element of the path is a symbolic\n      link, chmod will modify the symbolic link itself instead of the file the\n      link points to.\n    It is an error to use dir_fd or follow_symlinks when specifying path as\n      an open file descriptor.\n    dir_fd and follow_symlinks may not be implemented on your platform.\n      If they are unavailable, using them will raise a NotImplementedError.\"\"\"\n    pass\n\ndef close(*args,**kw):\n    \"\"\"close(fd)    \n    Close a file descriptor (for low level IO).\"\"\"\n    pass\n\ndef closerange(*args,**kw):\n    \"\"\"closerange(fd_low, fd_high)    \n    Closes all file descriptors in [fd_low, fd_high), ignoring errors.\"\"\"\n    pass\n\ndef device_encoding(*args,**kw):\n    \"\"\"device_encoding(fd) -> str    \n    Return a string describing the encoding of the device\n    if the output is a terminal; else return None.\"\"\"\n    pass\n\ndef dup(*args,**kw):\n    \"\"\"dup(fd) -> fd2    \n    Return a duplicate of a file descriptor.\"\"\"\n    pass\n\ndef dup2(*args,**kw):\n    \"\"\"dup2(old_fd, new_fd)    \n    Duplicate file descriptor.\"\"\"\n    pass\n\nenviron = {'PYTHONUSERBASE': ' '}\n\nerror = OSError\n\ndef execv(*args,**kw):\n    \"\"\"execv(path, args)    \n    Execute an executable path with arguments, replacing current process.\n    \n        path: path of executable file\n        args: tuple or list of strings\"\"\"\n    pass\n\ndef execve(*args,**kw):\n    \"\"\"execve(path, args, env)    \n    Execute a path with arguments and environment, replacing current process.\n    \n        path: path of executable file\n        args: tuple or list of arguments\n        env: dictionary of strings mapping to strings\n    \n    On some platforms, you may specify an open file descriptor for path;\n      execve will execute the program the file descriptor is open to.\n      If this functionality is unavailable, using it raises NotImplementedError.\"\"\"\n    pass\n\ndef fstat(*args,**kw):\n    \"\"\"fstat(fd) -> stat result    \n    Like stat(), but for an open file descriptor.\n    Equivalent to stat(fd=fd).\"\"\"\n    pass\n\ndef fsync(*args,**kw):\n    \"\"\"fsync(fildes)    \n    force write of file with filedescriptor to disk.\"\"\"\n    pass\n\ndef get_terminal_size(*args,**kw):\n    \"\"\"Return the size of the terminal window as (columns, lines).    \n    The optional argument fd (default standard output) specifies\n    which file descriptor should be queried.\n    \n    If the file descriptor is not connected to a terminal, an OSError\n    is thrown.\n    \n    This function will only be defined if an implementation is\n    available for this system.\n    \n    shutil.get_terminal_size is the high-level function which should \n    normally be used, os.get_terminal_size is the low-level implementation.\"\"\"\n    pass\n\ndef getcwd(*args,**kw):\n    \"\"\"getcwd() -> path    \n    Return a unicode string representing the current working directory.\"\"\"\n    return __BRYTHON__.brython_path # XXX fix me\n\ndef getcwdb(*args,**kw):\n    \"\"\"getcwdb() -> path    \n    Return a bytes string representing the current working directory.\"\"\"\n    pass\n\ndef getlogin(*args,**kw):\n    \"\"\"getlogin() -> string    \n    Return the actual login name.\"\"\"\n    pass\n\ndef getpid(*args,**kw):\n    \"\"\"getpid() -> pid    \n    Return the current process id\"\"\"\n    return 0\n\ndef getppid(*args,**kw):\n    \"\"\"getppid() -> ppid    \n    Return the parent's process id.  If the parent process has already exited,\n    Windows machines will still return its id; others systems will return the id\n    of the 'init' process (1).\"\"\"\n    pass\n\ndef isatty(*args,**kw):\n    \"\"\"isatty(fd) -> bool    \n    Return True if the file descriptor 'fd' is an open file descriptor\n    connected to the slave end of a terminal.\"\"\"\n    pass\n\ndef kill(*args,**kw):\n    \"\"\"kill(pid, sig)    \n    Kill a process with a signal.\"\"\"\n    pass\n\ndef link(*args,**kw):\n    \"\"\"link(src, dst, *, src_dir_fd=None, dst_dir_fd=None, follow_symlinks=True)    \n    Create a hard link to a file.\n    \n    If either src_dir_fd or dst_dir_fd is not None, it should be a file\n      descriptor open to a directory, and the respective path string (src or dst)\n      should be relative; the path will then be relative to that directory.\n    If follow_symlinks is False, and the last element of src is a symbolic\n      link, link will create a link to the symbolic link itself instead of the\n      file the link points to.\n    src_dir_fd, dst_dir_fd, and follow_symlinks may not be implemented on your\n      platform.  If they are unavailable, using them will raise a\n      NotImplementedError.\"\"\"\n    pass\n\ndef listdir(*args,**kw):\n    \"\"\"listdir(path='.') -> list_of_filenames    \n    Return a list containing the names of the files in the directory.\n    The list is in arbitrary order.  It does not include the special\n    entries '.' and '..' even if they are present in the directory.\n    \n    path can be specified as either str or bytes.  If path is bytes,\n      the filenames returned will also be bytes; in all other circumstances\n      the filenames returned will be str.\n    On some platforms, path may also be specified as an open file descriptor;\n      the file descriptor must refer to a directory.\n      If this functionality is unavailable, using it raises NotImplementedError.\"\"\"\n    pass\n\ndef lseek(*args,**kw):\n    \"\"\"lseek(fd, pos, how) -> newpos    \n    Set the current position of a file descriptor.\n    Return the new cursor position in bytes, starting from the beginning.\"\"\"\n    pass\n\ndef lstat(*args,**kw):\n    \"\"\"lstat(path, *, dir_fd=None) -> stat result    \n    Like stat(), but do not follow symbolic links.\n    Equivalent to stat(path, follow_symlinks=False).\"\"\"\n    return stat_result()\n\ndef mkdir(*args,**kw):\n    \"\"\"mkdir(path, mode=0o777, *, dir_fd=None)    \n    Create a directory.\n    \n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n    dir_fd may not be implemented on your platform.\n      If it is unavailable, using it will raise a NotImplementedError.\n    \n    The mode argument is ignored on Windows.\"\"\"\n    pass\n\ndef open(*args,**kw):\n    \"\"\"open(path, flags, mode=0o777, *, dir_fd=None)    \n    Open a file for low level IO.  Returns a file handle (integer).\n    \n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n    dir_fd may not be implemented on your platform.\n      If it is unavailable, using it will raise a NotImplementedError.\"\"\"\n    pass\n\ndef pipe(*args,**kw):\n    \"\"\"pipe() -> (read_end, write_end)    \n    Create a pipe.\"\"\"\n    pass\n\ndef putenv(*args,**kw):\n    \"\"\"putenv(key, value)    \n    Change or add an environment variable.\"\"\"\n    pass\n\ndef read(*args,**kw):\n    \"\"\"read(fd, buffersize) -> string    \n    Read a file descriptor.\"\"\"\n    pass\n\ndef readlink(*args,**kw):\n    \"\"\"readlink(path, *, dir_fd=None) -> path    \n    Return a string representing the path to which the symbolic link points.\n    \n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n    dir_fd may not be implemented on your platform.\n      If it is unavailable, using it will raise a NotImplementedError.\"\"\"\n    pass\n\ndef remove(*args,**kw):\n    \"\"\"remove(path, *, dir_fd=None)    \n    Remove a file (same as unlink()).\n    \n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n    dir_fd may not be implemented on your platform.\n      If it is unavailable, using it will raise a NotImplementedError.\"\"\"\n    pass\n\ndef rename(*args,**kw):\n    \"\"\"rename(src, dst, *, src_dir_fd=None, dst_dir_fd=None)    \n    Rename a file or directory.\n    \n    If either src_dir_fd or dst_dir_fd is not None, it should be a file\n      descriptor open to a directory, and the respective path string (src or dst)\n      should be relative; the path will then be relative to that directory.\n    src_dir_fd and dst_dir_fd, may not be implemented on your platform.\n      If they are unavailable, using them will raise a NotImplementedError.\"\"\"\n    pass\n\ndef replace(*args,**kw):\n    \"\"\"replace(src, dst, *, src_dir_fd=None, dst_dir_fd=None)    \n    Rename a file or directory, overwriting the destination.\n    \n    If either src_dir_fd or dst_dir_fd is not None, it should be a file\n      descriptor open to a directory, and the respective path string (src or dst)\n      should be relative; the path will then be relative to that directory.\n    src_dir_fd and dst_dir_fd, may not be implemented on your platform.\n      If they are unavailable, using them will raise a NotImplementedError.\"\"\"\n    pass\n\ndef rmdir(*args,**kw):\n    \"\"\"rmdir(path, *, dir_fd=None)    \n    Remove a directory.\n    \n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n    dir_fd may not be implemented on your platform.\n      If it is unavailable, using it will raise a NotImplementedError.\"\"\"\n    pass\n\ndef spawnv(*args,**kw):\n    \"\"\"spawnv(mode, path, args)    \n    Execute the program 'path' in a new process.\n    \n        mode: mode of process creation\n        path: path of executable file\n        args: tuple or list of strings\"\"\"\n    pass\n\ndef spawnve(*args,**kw):\n    \"\"\"spawnve(mode, path, args, env)    \n    Execute the program 'path' in a new process.\n    \n        mode: mode of process creation\n        path: path of executable file\n        args: tuple or list of arguments\n        env: dictionary of strings mapping to strings\"\"\"\n    pass\n\ndef startfile(*args,**kw):\n    \"\"\"startfile(filepath [, operation]) - Start a file with its associated    application.\n    \n    When \"operation\" is not specified or \"open\", this acts like\n    double-clicking the file in Explorer, or giving the file name as an\n    argument to the DOS \"start\" command: the file is opened with whatever\n    application (if any) its extension is associated.\n    When another \"operation\" is given, it specifies what should be done with\n    the file.  A typical operation is \"print\".\n    \n    startfile returns as soon as the associated application is launched.\n    There is no option to wait for the application to close, and no way\n    to retrieve the application's exit status.\n    \n    The filepath is relative to the current directory.  If you want to use\n    an absolute path, make sure the first character is not a slash (\"/\");\n    the underlying Win32 ShellExecute function doesn't work if it is.\"\"\"\n    pass\n\ndef stat(*args,**kw):\n    \"\"\"stat(path, *, dir_fd=None, follow_symlinks=True) -> stat result    \n    Perform a stat system call on the given path.\n    \n    path may be specified as either a string or as an open file descriptor.\n    \n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n      dir_fd may not be supported on your platform; if it is unavailable, using\n      it will raise a NotImplementedError.\n    If follow_symlinks is False, and the last element of the path is a symbolic\n      link, stat will examine the symbolic link itself instead of the file the\n      link points to.\n    It is an error to use dir_fd or follow_symlinks when specifying path as\n      an open file descriptor.\"\"\"\n    return stat_result()\n\ndef stat_float_times(*args,**kw):\n    \"\"\"stat_float_times([newval]) -> oldval    \n    Determine whether os.[lf]stat represents time stamps as float objects.\n    If newval is True, future calls to stat() return floats, if it is False,\n    future calls return ints. \n    If newval is omitted, return the current setting.\n    \"\"\"\n    pass\n\nclass stat_result:\n\n    def __init__(self):\n        \"\"\"st_mode - protection bits, \n        st_ino - inode number, \n        st_dev - device, \n        st_nlink - number of hard links, \n        st_uid - user id of owner, \n        st_gid - group id of owner, \n        st_size - size of file, in bytes, \n        st_atime - time of most recent access expressed in seconds, \n        st_mtime - time of most recent content modification expressed in \n            seconds, \n        st_ctime - platform dependent; time of most recent metadata change on \n            Unix, or the time of creation on Windows, expressed in seconds \n        st_atime_ns - time of most recent access expressed in nanoseconds as an\n             integer, \n        st_mtime_ns - time of most recent content modification expressed in \n            nanoseconds as an integer, \n        st_ctime_ns - platform dependent; time of most recent metadata change \n            on Unix, or the time of creation on Windows, expressed in \n            nanoseconds as an integer \"\"\"\n        # Brython : fake values\n        self.st_atime = datetime.datetime.now()\n        self.st_mtime = self.st_ctime = self.st_atime_ns = \\\n            self.st_mtime_ns = self.st_ctime_ns = self.st_atime\n        self.st_uid = self.st_gid = self.st_ino = -1\n        self.st_mode = 0\n        self.st_size = 1\n\nclass statvfs_result:\n    pass\n\ndef strerror(*args,**kw):\n    \"\"\"strerror(code) -> string    \n    Translate an error code to a message string.\"\"\"\n    pass\n\ndef symlink(*args,**kw):\n    \"\"\"symlink(src, dst, target_is_directory=False, *, dir_fd=None)    \n    Create a symbolic link pointing to src named dst.\n    \n    target_is_directory is required on Windows if the target is to be\n      interpreted as a directory.  (On Windows, symlink requires\n      Windows 6.0 or greater, and raises a NotImplementedError otherwise.)\n      target_is_directory is ignored on non-Windows platforms.\n    \n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n    dir_fd may not be implemented on your platform.\n      If it is unavailable, using it will raise a NotImplementedError.\"\"\"\n    pass\n\ndef system(*args,**kw):\n    \"\"\"system(command) -> exit_status    \n    Execute the command (a string) in a subshell.\"\"\"\n    pass\n\nclass terminal_size:\n    pass\n\ndef times(*args,**kw):\n    \"\"\"times() -> times_result    \n    Return an object containing floating point numbers indicating process\n    times.  The object behaves like a named tuple with these fields:\n      (utime, stime, cutime, cstime, elapsed_time)\"\"\"\n    pass\n\nclass times_result:\n    pass\n\ndef umask(*args,**kw):\n    \"\"\"umask(new_mask) -> old_mask    \n    Set the current numeric umask and return the previous umask.\"\"\"\n    pass\n\nclass uname_result:\n    pass\n\ndef unlink(*args,**kw):\n    \"\"\"unlink(path, *, dir_fd=None)    \n    Remove a file (same as remove()).\n    \n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n    dir_fd may not be implemented on your platform.\n      If it is unavailable, using it will raise a NotImplementedError.\"\"\"\n    pass\n\ndef urandom(n):\n    \"\"\"urandom(n) -> str    \n    Return n random bytes suitable for cryptographic use.\"\"\"\n    import __random\n    randbytes= [__random.randint(0,255) for i in range(n)]\n    return bytes(randbytes)\n\ndef utime(*args,**kw):\n    \"\"\"utime(path, times=None, *, ns=None, dir_fd=None, follow_symlinks=True)    Set the access and modified time of path.\n    \n    path may always be specified as a string.\n    On some platforms, path may also be specified as an open file descriptor.\n      If this functionality is unavailable, using it raises an exception.\n    \n    If times is not None, it must be a tuple (atime, mtime);\n        atime and mtime should be expressed as float seconds since the epoch.\n    If ns is not None, it must be a tuple (atime_ns, mtime_ns);\n        atime_ns and mtime_ns should be expressed as integer nanoseconds\n        since the epoch.\n    If both times and ns are None, utime uses the current time.\n    Specifying tuples for both times and ns is an error.\n    \n    If dir_fd is not None, it should be a file descriptor open to a directory,\n      and path should be relative; path will then be relative to that directory.\n    If follow_symlinks is False, and the last element of the path is a symbolic\n      link, utime will modify the symbolic link itself instead of the file the\n      link points to.\n    It is an error to use dir_fd or follow_symlinks when specifying path\n      as an open file descriptor.\n    dir_fd and follow_symlinks may not be available on your platform.\n      If they are unavailable, using them will raise a NotImplementedError.\"\"\"\n    pass\n\ndef waitpid(*args,**kw):\n    \"\"\"waitpid(pid, options) -> (pid, status << 8)    \n    Wait for completion of a given process.  options is ignored on Windows.\"\"\"\n    pass\n\ndef write(*args,**kw):\n    \"\"\"write(fd, string) -> byteswritten    \n    Write a string to a file descriptor.\"\"\"\n    pass\n\n## put WIFSIGNALED here. its needed by os module, and os module imports all\n## functions in this module\ndef WIFSIGNALED(a):\n    return False\n\ndef WTERMSIG(status):\n    return 0\n\ndef WIFSIGNALED(status):\n    \"Return True if the process exited due to a signal, otherwise return False\"\n    return False\n\ndef WIFEXITED(status):\n    return False\n\ndef WEXITSTATUS(status):\n    pass\n\ndef WNOHANG():\n    return (0,0)\n"], "encodings.aliases": [".py", "\"\"\" Encoding Aliases Support\n\n    This module is used by the encodings package search function to\n    map encodings names to module names.\n\n    Note that the search function normalizes the encoding names before\n    doing the lookup, so the mapping will have to map normalized\n    encoding names to module names.\n\n    Contents:\n\n        The following aliases dictionary contains mappings of all IANA\n        character set names for which the Python core library provides\n        codecs. In addition to these, a few Python specific codec\n        aliases have also been added.\n\n\"\"\"\naliases = {\n\n    # Please keep this list sorted alphabetically by value !\n\n    # ascii codec\n    '646'                : 'ascii',\n    'ansi_x3.4_1968'     : 'ascii',\n    'ansi_x3_4_1968'     : 'ascii', # some email headers use this non-standard name\n    'ansi_x3.4_1986'     : 'ascii',\n    'cp367'              : 'ascii',\n    'csascii'            : 'ascii',\n    'ibm367'             : 'ascii',\n    'iso646_us'          : 'ascii',\n    'iso_646.irv_1991'   : 'ascii',\n    'iso_ir_6'           : 'ascii',\n    'us'                 : 'ascii',\n    'us_ascii'           : 'ascii',\n\n    # base64_codec codec\n    'base64'             : 'base64_codec',\n    'base_64'            : 'base64_codec',\n\n    # big5 codec\n    'big5_tw'            : 'big5',\n    'csbig5'             : 'big5',\n\n    # big5hkscs codec\n    'big5_hkscs'         : 'big5hkscs',\n    'hkscs'              : 'big5hkscs',\n\n    # bz2_codec codec\n    'bz2'                : 'bz2_codec',\n\n    # cp037 codec\n    '037'                : 'cp037',\n    'csibm037'           : 'cp037',\n    'ebcdic_cp_ca'       : 'cp037',\n    'ebcdic_cp_nl'       : 'cp037',\n    'ebcdic_cp_us'       : 'cp037',\n    'ebcdic_cp_wt'       : 'cp037',\n    'ibm037'             : 'cp037',\n    'ibm039'             : 'cp037',\n\n    # cp1026 codec\n    '1026'               : 'cp1026',\n    'csibm1026'          : 'cp1026',\n    'ibm1026'            : 'cp1026',\n\n    # cp1125 codec\n    '1125'                : 'cp1125',\n    'ibm1125'             : 'cp1125',\n    'cp866u'              : 'cp1125',\n    'ruscii'              : 'cp1125',\n\n    # cp1140 codec\n    '1140'               : 'cp1140',\n    'ibm1140'            : 'cp1140',\n\n    # cp1250 codec\n    '1250'               : 'cp1250',\n    'windows_1250'       : 'cp1250',\n\n    # cp1251 codec\n    '1251'               : 'cp1251',\n    'windows_1251'       : 'cp1251',\n\n    # cp1252 codec\n    '1252'               : 'cp1252',\n    'windows_1252'       : 'cp1252',\n\n    # cp1253 codec\n    '1253'               : 'cp1253',\n    'windows_1253'       : 'cp1253',\n\n    # cp1254 codec\n    '1254'               : 'cp1254',\n    'windows_1254'       : 'cp1254',\n\n    # cp1255 codec\n    '1255'               : 'cp1255',\n    'windows_1255'       : 'cp1255',\n\n    # cp1256 codec\n    '1256'               : 'cp1256',\n    'windows_1256'       : 'cp1256',\n\n    # cp1257 codec\n    '1257'               : 'cp1257',\n    'windows_1257'       : 'cp1257',\n\n    # cp1258 codec\n    '1258'               : 'cp1258',\n    'windows_1258'       : 'cp1258',\n\n    # cp273 codec\n    '273'                : 'cp273',\n    'ibm273'             : 'cp273',\n    'csibm273'           : 'cp273',\n\n    # cp424 codec\n    '424'                : 'cp424',\n    'csibm424'           : 'cp424',\n    'ebcdic_cp_he'       : 'cp424',\n    'ibm424'             : 'cp424',\n\n    # cp437 codec\n    '437'                : 'cp437',\n    'cspc8codepage437'   : 'cp437',\n    'ibm437'             : 'cp437',\n\n    # cp500 codec\n    '500'                : 'cp500',\n    'csibm500'           : 'cp500',\n    'ebcdic_cp_be'       : 'cp500',\n    'ebcdic_cp_ch'       : 'cp500',\n    'ibm500'             : 'cp500',\n\n    # cp775 codec\n    '775'                : 'cp775',\n    'cspc775baltic'      : 'cp775',\n    'ibm775'             : 'cp775',\n\n    # cp850 codec\n    '850'                : 'cp850',\n    'cspc850multilingual' : 'cp850',\n    'ibm850'             : 'cp850',\n\n    # cp852 codec\n    '852'                : 'cp852',\n    'cspcp852'           : 'cp852',\n    'ibm852'             : 'cp852',\n\n    # cp855 codec\n    '855'                : 'cp855',\n    'csibm855'           : 'cp855',\n    'ibm855'             : 'cp855',\n\n    # cp857 codec\n    '857'                : 'cp857',\n    'csibm857'           : 'cp857',\n    'ibm857'             : 'cp857',\n\n    # cp858 codec\n    '858'                : 'cp858',\n    'csibm858'           : 'cp858',\n    'ibm858'             : 'cp858',\n\n    # cp860 codec\n    '860'                : 'cp860',\n    'csibm860'           : 'cp860',\n    'ibm860'             : 'cp860',\n\n    # cp861 codec\n    '861'                : 'cp861',\n    'cp_is'              : 'cp861',\n    'csibm861'           : 'cp861',\n    'ibm861'             : 'cp861',\n\n    # cp862 codec\n    '862'                : 'cp862',\n    'cspc862latinhebrew' : 'cp862',\n    'ibm862'             : 'cp862',\n\n    # cp863 codec\n    '863'                : 'cp863',\n    'csibm863'           : 'cp863',\n    'ibm863'             : 'cp863',\n\n    # cp864 codec\n    '864'                : 'cp864',\n    'csibm864'           : 'cp864',\n    'ibm864'             : 'cp864',\n\n    # cp865 codec\n    '865'                : 'cp865',\n    'csibm865'           : 'cp865',\n    'ibm865'             : 'cp865',\n\n    # cp866 codec\n    '866'                : 'cp866',\n    'csibm866'           : 'cp866',\n    'ibm866'             : 'cp866',\n\n    # cp869 codec\n    '869'                : 'cp869',\n    'cp_gr'              : 'cp869',\n    'csibm869'           : 'cp869',\n    'ibm869'             : 'cp869',\n\n    # cp932 codec\n    '932'                : 'cp932',\n    'ms932'              : 'cp932',\n    'mskanji'            : 'cp932',\n    'ms_kanji'           : 'cp932',\n\n    # cp949 codec\n    '949'                : 'cp949',\n    'ms949'              : 'cp949',\n    'uhc'                : 'cp949',\n\n    # cp950 codec\n    '950'                : 'cp950',\n    'ms950'              : 'cp950',\n\n    # euc_jis_2004 codec\n    'jisx0213'           : 'euc_jis_2004',\n    'eucjis2004'         : 'euc_jis_2004',\n    'euc_jis2004'        : 'euc_jis_2004',\n\n    # euc_jisx0213 codec\n    'eucjisx0213'        : 'euc_jisx0213',\n\n    # euc_jp codec\n    'eucjp'              : 'euc_jp',\n    'ujis'               : 'euc_jp',\n    'u_jis'              : 'euc_jp',\n\n    # euc_kr codec\n    'euckr'              : 'euc_kr',\n    'korean'             : 'euc_kr',\n    'ksc5601'            : 'euc_kr',\n    'ks_c_5601'          : 'euc_kr',\n    'ks_c_5601_1987'     : 'euc_kr',\n    'ksx1001'            : 'euc_kr',\n    'ks_x_1001'          : 'euc_kr',\n\n    # gb18030 codec\n    'gb18030_2000'       : 'gb18030',\n\n    # gb2312 codec\n    'chinese'            : 'gb2312',\n    'csiso58gb231280'    : 'gb2312',\n    'euc_cn'             : 'gb2312',\n    'euccn'              : 'gb2312',\n    'eucgb2312_cn'       : 'gb2312',\n    'gb2312_1980'        : 'gb2312',\n    'gb2312_80'          : 'gb2312',\n    'iso_ir_58'          : 'gb2312',\n\n    # gbk codec\n    '936'                : 'gbk',\n    'cp936'              : 'gbk',\n    'ms936'              : 'gbk',\n\n    # hex_codec codec\n    'hex'                : 'hex_codec',\n\n    # hp_roman8 codec\n    'roman8'             : 'hp_roman8',\n    'r8'                 : 'hp_roman8',\n    'csHPRoman8'         : 'hp_roman8',\n\n    # hz codec\n    'hzgb'               : 'hz',\n    'hz_gb'              : 'hz',\n    'hz_gb_2312'         : 'hz',\n\n    # iso2022_jp codec\n    'csiso2022jp'        : 'iso2022_jp',\n    'iso2022jp'          : 'iso2022_jp',\n    'iso_2022_jp'        : 'iso2022_jp',\n\n    # iso2022_jp_1 codec\n    'iso2022jp_1'        : 'iso2022_jp_1',\n    'iso_2022_jp_1'      : 'iso2022_jp_1',\n\n    # iso2022_jp_2 codec\n    'iso2022jp_2'        : 'iso2022_jp_2',\n    'iso_2022_jp_2'      : 'iso2022_jp_2',\n\n    # iso2022_jp_2004 codec\n    'iso_2022_jp_2004'   : 'iso2022_jp_2004',\n    'iso2022jp_2004'     : 'iso2022_jp_2004',\n\n    # iso2022_jp_3 codec\n    'iso2022jp_3'        : 'iso2022_jp_3',\n    'iso_2022_jp_3'      : 'iso2022_jp_3',\n\n    # iso2022_jp_ext codec\n    'iso2022jp_ext'      : 'iso2022_jp_ext',\n    'iso_2022_jp_ext'    : 'iso2022_jp_ext',\n\n    # iso2022_kr codec\n    'csiso2022kr'        : 'iso2022_kr',\n    'iso2022kr'          : 'iso2022_kr',\n    'iso_2022_kr'        : 'iso2022_kr',\n\n    # iso8859_10 codec\n    'csisolatin6'        : 'iso8859_10',\n    'iso_8859_10'        : 'iso8859_10',\n    'iso_8859_10_1992'   : 'iso8859_10',\n    'iso_ir_157'         : 'iso8859_10',\n    'l6'                 : 'iso8859_10',\n    'latin6'             : 'iso8859_10',\n\n    # iso8859_11 codec\n    'thai'               : 'iso8859_11',\n    'iso_8859_11'        : 'iso8859_11',\n    'iso_8859_11_2001'   : 'iso8859_11',\n\n    # iso8859_13 codec\n    'iso_8859_13'        : 'iso8859_13',\n    'l7'                 : 'iso8859_13',\n    'latin7'             : 'iso8859_13',\n\n    # iso8859_14 codec\n    'iso_8859_14'        : 'iso8859_14',\n    'iso_8859_14_1998'   : 'iso8859_14',\n    'iso_celtic'         : 'iso8859_14',\n    'iso_ir_199'         : 'iso8859_14',\n    'l8'                 : 'iso8859_14',\n    'latin8'             : 'iso8859_14',\n\n    # iso8859_15 codec\n    'iso_8859_15'        : 'iso8859_15',\n    'l9'                 : 'iso8859_15',\n    'latin9'             : 'iso8859_15',\n\n    # iso8859_16 codec\n    'iso_8859_16'        : 'iso8859_16',\n    'iso_8859_16_2001'   : 'iso8859_16',\n    'iso_ir_226'         : 'iso8859_16',\n    'l10'                : 'iso8859_16',\n    'latin10'            : 'iso8859_16',\n\n    # iso8859_2 codec\n    'csisolatin2'        : 'iso8859_2',\n    'iso_8859_2'         : 'iso8859_2',\n    'iso_8859_2_1987'    : 'iso8859_2',\n    'iso_ir_101'         : 'iso8859_2',\n    'l2'                 : 'iso8859_2',\n    'latin2'             : 'iso8859_2',\n\n    # iso8859_3 codec\n    'csisolatin3'        : 'iso8859_3',\n    'iso_8859_3'         : 'iso8859_3',\n    'iso_8859_3_1988'    : 'iso8859_3',\n    'iso_ir_109'         : 'iso8859_3',\n    'l3'                 : 'iso8859_3',\n    'latin3'             : 'iso8859_3',\n\n    # iso8859_4 codec\n    'csisolatin4'        : 'iso8859_4',\n    'iso_8859_4'         : 'iso8859_4',\n    'iso_8859_4_1988'    : 'iso8859_4',\n    'iso_ir_110'         : 'iso8859_4',\n    'l4'                 : 'iso8859_4',\n    'latin4'             : 'iso8859_4',\n\n    # iso8859_5 codec\n    'csisolatincyrillic' : 'iso8859_5',\n    'cyrillic'           : 'iso8859_5',\n    'iso_8859_5'         : 'iso8859_5',\n    'iso_8859_5_1988'    : 'iso8859_5',\n    'iso_ir_144'         : 'iso8859_5',\n\n    # iso8859_6 codec\n    'arabic'             : 'iso8859_6',\n    'asmo_708'           : 'iso8859_6',\n    'csisolatinarabic'   : 'iso8859_6',\n    'ecma_114'           : 'iso8859_6',\n    'iso_8859_6'         : 'iso8859_6',\n    'iso_8859_6_1987'    : 'iso8859_6',\n    'iso_ir_127'         : 'iso8859_6',\n\n    # iso8859_7 codec\n    'csisolatingreek'    : 'iso8859_7',\n    'ecma_118'           : 'iso8859_7',\n    'elot_928'           : 'iso8859_7',\n    'greek'              : 'iso8859_7',\n    'greek8'             : 'iso8859_7',\n    'iso_8859_7'         : 'iso8859_7',\n    'iso_8859_7_1987'    : 'iso8859_7',\n    'iso_ir_126'         : 'iso8859_7',\n\n    # iso8859_8 codec\n    'csisolatinhebrew'   : 'iso8859_8',\n    'hebrew'             : 'iso8859_8',\n    'iso_8859_8'         : 'iso8859_8',\n    'iso_8859_8_1988'    : 'iso8859_8',\n    'iso_ir_138'         : 'iso8859_8',\n\n    # iso8859_9 codec\n    'csisolatin5'        : 'iso8859_9',\n    'iso_8859_9'         : 'iso8859_9',\n    'iso_8859_9_1989'    : 'iso8859_9',\n    'iso_ir_148'         : 'iso8859_9',\n    'l5'                 : 'iso8859_9',\n    'latin5'             : 'iso8859_9',\n\n    # johab codec\n    'cp1361'             : 'johab',\n    'ms1361'             : 'johab',\n\n    # koi8_r codec\n    'cskoi8r'            : 'koi8_r',\n\n    # latin_1 codec\n    #\n    # Note that the latin_1 codec is implemented internally in C and a\n    # lot faster than the charmap codec iso8859_1 which uses the same\n    # encoding. This is why we discourage the use of the iso8859_1\n    # codec and alias it to latin_1 instead.\n    #\n    '8859'               : 'latin_1',\n    'cp819'              : 'latin_1',\n    'csisolatin1'        : 'latin_1',\n    'ibm819'             : 'latin_1',\n    'iso8859'            : 'latin_1',\n    'iso8859_1'          : 'latin_1',\n    'iso_8859_1'         : 'latin_1',\n    'iso_8859_1_1987'    : 'latin_1',\n    'iso_ir_100'         : 'latin_1',\n    'l1'                 : 'latin_1',\n    'latin'              : 'latin_1',\n    'latin1'             : 'latin_1',\n\n    # mac_cyrillic codec\n    'maccyrillic'        : 'mac_cyrillic',\n\n    # mac_greek codec\n    'macgreek'           : 'mac_greek',\n\n    # mac_iceland codec\n    'maciceland'         : 'mac_iceland',\n\n    # mac_latin2 codec\n    'maccentraleurope'   : 'mac_latin2',\n    'maclatin2'          : 'mac_latin2',\n\n    # mac_roman codec\n    'macintosh'          : 'mac_roman',\n    'macroman'           : 'mac_roman',\n\n    # mac_turkish codec\n    'macturkish'         : 'mac_turkish',\n\n    # mbcs codec\n    'dbcs'               : 'mbcs',\n\n    # ptcp154 codec\n    'csptcp154'          : 'ptcp154',\n    'pt154'              : 'ptcp154',\n    'cp154'              : 'ptcp154',\n    'cyrillic_asian'     : 'ptcp154',\n\n    # quopri_codec codec\n    'quopri'             : 'quopri_codec',\n    'quoted_printable'   : 'quopri_codec',\n    'quotedprintable'    : 'quopri_codec',\n\n    # rot_13 codec\n    'rot13'              : 'rot_13',\n\n    # shift_jis codec\n    'csshiftjis'         : 'shift_jis',\n    'shiftjis'           : 'shift_jis',\n    'sjis'               : 'shift_jis',\n    's_jis'              : 'shift_jis',\n\n    # shift_jis_2004 codec\n    'shiftjis2004'       : 'shift_jis_2004',\n    'sjis_2004'          : 'shift_jis_2004',\n    's_jis_2004'         : 'shift_jis_2004',\n\n    # shift_jisx0213 codec\n    'shiftjisx0213'      : 'shift_jisx0213',\n    'sjisx0213'          : 'shift_jisx0213',\n    's_jisx0213'         : 'shift_jisx0213',\n\n    # tactis codec\n    'tis260'             : 'tactis',\n\n    # tis_620 codec\n    'tis620'             : 'tis_620',\n    'tis_620_0'          : 'tis_620',\n    'tis_620_2529_0'     : 'tis_620',\n    'tis_620_2529_1'     : 'tis_620',\n    'iso_ir_166'         : 'tis_620',\n\n    # utf_16 codec\n    'u16'                : 'utf_16',\n    'utf16'              : 'utf_16',\n\n    # utf_16_be codec\n    'unicodebigunmarked' : 'utf_16_be',\n    'utf_16be'           : 'utf_16_be',\n\n    # utf_16_le codec\n    'unicodelittleunmarked' : 'utf_16_le',\n    'utf_16le'           : 'utf_16_le',\n\n    # utf_32 codec\n    'u32'                : 'utf_32',\n    'utf32'              : 'utf_32',\n\n    # utf_32_be codec\n    'utf_32be'           : 'utf_32_be',\n\n    # utf_32_le codec\n    'utf_32le'           : 'utf_32_le',\n\n    # utf_7 codec\n    'u7'                 : 'utf_7',\n    'utf7'               : 'utf_7',\n    'unicode_1_1_utf_7'  : 'utf_7',\n\n    # utf_8 codec\n    'u8'                 : 'utf_8',\n    'utf'                : 'utf_8',\n    'utf8'               : 'utf_8',\n    'utf8_ucs2'          : 'utf_8',\n    'utf8_ucs4'          : 'utf_8',\n\n    # uu_codec codec\n    'uu'                 : 'uu_codec',\n\n    # zlib_codec codec\n    'zip'                : 'zlib_codec',\n    'zlib'               : 'zlib_codec',\n\n    # temporary mac CJK aliases, will be replaced by proper codecs in 3.1\n    'x_mac_japanese'      : 'shift_jis',\n    'x_mac_korean'        : 'euc_kr',\n    'x_mac_simp_chinese'  : 'gb2312',\n    'x_mac_trad_chinese'  : 'big5',\n}\n"], "fnmatch": [".py", "\"\"\"Filename matching with shell patterns.\n\nfnmatch(FILENAME, PATTERN) matches according to the local convention.\nfnmatchcase(FILENAME, PATTERN) always takes case in account.\n\nThe functions operate by translating the pattern into a regular\nexpression.  They cache the compiled regular expressions for speed.\n\nThe function translate(PATTERN) returns a regular expression\ncorresponding to PATTERN.  (It does not compile it.)\n\"\"\"\nimport os\nimport posixpath\nimport re\nimport functools\n\n__all__ = [\"filter\", \"fnmatch\", \"fnmatchcase\", \"translate\"]\n\ndef fnmatch(name, pat):\n    \"\"\"Test whether FILENAME matches PATTERN.\n\n    Patterns are Unix shell style:\n\n    *       matches everything\n    ?       matches any single character\n    [seq]   matches any character in seq\n    [!seq]  matches any char not in seq\n\n    An initial period in FILENAME is not special.\n    Both FILENAME and PATTERN are first case-normalized\n    if the operating system requires it.\n    If you don't want this, use fnmatchcase(FILENAME, PATTERN).\n    \"\"\"\n    name = os.path.normcase(name)\n    pat = os.path.normcase(pat)\n    return fnmatchcase(name, pat)\n\n@functools.lru_cache(maxsize=256, typed=True)\ndef _compile_pattern(pat):\n    if isinstance(pat, bytes):\n        pat_str = str(pat, 'ISO-8859-1')\n        res_str = translate(pat_str)\n        res = bytes(res_str, 'ISO-8859-1')\n    else:\n        res = translate(pat)\n    return re.compile(res).match\n\ndef filter(names, pat):\n    \"\"\"Return the subset of the list NAMES that match PAT.\"\"\"\n    result = []\n    pat = os.path.normcase(pat)\n    match = _compile_pattern(pat)\n    if os.path is posixpath:\n        # normcase on posix is NOP. Optimize it away from the loop.\n        for name in names:\n            if match(name):\n                result.append(name)\n    else:\n        for name in names:\n            if match(os.path.normcase(name)):\n                result.append(name)\n    return result\n\ndef fnmatchcase(name, pat):\n    \"\"\"Test whether FILENAME matches PATTERN, including case.\n\n    This is a version of fnmatch() which doesn't case-normalize\n    its arguments.\n    \"\"\"\n    match = _compile_pattern(pat)\n    return match(name) is not None\n\n\ndef translate(pat):\n    \"\"\"Translate a shell PATTERN to a regular expression.\n\n    There is no way to quote meta-characters.\n    \"\"\"\n\n    i, n = 0, len(pat)\n    res = ''\n    while i < n:\n        c = pat[i]\n        i = i+1\n        if c == '*':\n            res = res + '.*'\n        elif c == '?':\n            res = res + '.'\n        elif c == '[':\n            j = i\n            if j < n and pat[j] == '!':\n                j = j+1\n            if j < n and pat[j] == ']':\n                j = j+1\n            while j < n and pat[j] != ']':\n                j = j+1\n            if j >= n:\n                res = res + '\\\\['\n            else:\n                stuff = pat[i:j].replace('\\\\','\\\\\\\\')\n                i = j+1\n                if stuff[0] == '!':\n                    stuff = '^' + stuff[1:]\n                elif stuff[0] == '^':\n                    stuff = '\\\\' + stuff\n                res = '%s[%s]' % (res, stuff)\n        else:\n            res = res + re.escape(c)\n    return res + '\\Z(?ms)'\n"], "sre_parse": [".py", "#\n# Secret Labs' Regular Expression Engine\n#\n# convert re-style regular expression to sre pattern\n#\n# Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\n#\n# See the sre.py file for information on usage and redistribution.\n#\n\n\"\"\"Internal support module for sre\"\"\"\n\n# XXX: show string offset and offending character for all errors\n\nimport sys\n\nfrom sre_constants import *\nfrom _sre import MAXREPEAT\n\nSPECIAL_CHARS = \".\\\\[{()*+?^$|\"\nREPEAT_CHARS = \"*+?{\"\n\nDIGITS = set(\"0123456789\")\n\nOCTDIGITS = set(\"01234567\")\nHEXDIGITS = set(\"0123456789abcdefABCDEF\")\n\nWHITESPACE = set(\" \\t\\n\\r\\v\\f\")\n\nESCAPES = {\n    r\"\\a\": (LITERAL, ord(\"\\a\")),\n    r\"\\b\": (LITERAL, ord(\"\\b\")),\n    r\"\\f\": (LITERAL, ord(\"\\f\")),\n    r\"\\n\": (LITERAL, ord(\"\\n\")),\n    r\"\\r\": (LITERAL, ord(\"\\r\")),\n    r\"\\t\": (LITERAL, ord(\"\\t\")),\n    r\"\\v\": (LITERAL, ord(\"\\v\")),\n    r\"\\\\\": (LITERAL, ord(\"\\\\\"))\n}\n\nCATEGORIES = {\n    r\"\\A\": (AT, AT_BEGINNING_STRING), # start of string\n    r\"\\b\": (AT, AT_BOUNDARY),\n    r\"\\B\": (AT, AT_NON_BOUNDARY),\n    r\"\\d\": (IN, [(CATEGORY, CATEGORY_DIGIT)]),\n    r\"\\D\": (IN, [(CATEGORY, CATEGORY_NOT_DIGIT)]),\n    r\"\\s\": (IN, [(CATEGORY, CATEGORY_SPACE)]),\n    r\"\\S\": (IN, [(CATEGORY, CATEGORY_NOT_SPACE)]),\n    r\"\\w\": (IN, [(CATEGORY, CATEGORY_WORD)]),\n    r\"\\W\": (IN, [(CATEGORY, CATEGORY_NOT_WORD)]),\n    r\"\\Z\": (AT, AT_END_STRING), # end of string\n}\n\nFLAGS = {\n    # standard flags\n    \"i\": SRE_FLAG_IGNORECASE,\n    \"L\": SRE_FLAG_LOCALE,\n    \"m\": SRE_FLAG_MULTILINE,\n    \"s\": SRE_FLAG_DOTALL,\n    \"x\": SRE_FLAG_VERBOSE,\n    # extensions\n    \"a\": SRE_FLAG_ASCII,\n    \"t\": SRE_FLAG_TEMPLATE,\n    \"u\": SRE_FLAG_UNICODE,\n}\n\nclass Pattern:\n    # master pattern object.  keeps track of global attributes\n    def __init__(self):\n        self.flags = 0\n        self.open = []\n        self.groups = 1\n        self.groupdict = {}\n    def opengroup(self, name=None):\n        gid = self.groups\n        self.groups = gid + 1\n        if name is not None:\n            ogid = self.groupdict.get(name, None)\n            if ogid is not None:\n                raise error(\"redefinition of group name %s as group %d; \"\n                            \"was group %d\" % (repr(name), gid,  ogid))\n            self.groupdict[name] = gid\n        self.open.append(gid)\n        return gid\n    def closegroup(self, gid):\n        self.open.remove(gid)\n    def checkgroup(self, gid):\n        return gid < self.groups and gid not in self.open\n\nclass SubPattern:\n    # a subpattern, in intermediate form\n    def __init__(self, pattern, data=None):\n        self.pattern = pattern\n        if data is None:\n            data = []\n        self.data = data\n        self.width = None\n    def __iter__(self):\n        return iter(self.data)\n\n    def dump(self, level=0):\n        nl = 1\n        seqtypes = (tuple, list)\n        for op, av in self.data:\n            print(level*\"  \" + op, end=' '); nl = 0\n            if op == \"in\":\n                # member sublanguage\n                print(); nl = 1\n                for op, a in av:\n                    print((level+1)*\"  \" + op, a)\n            elif op == \"branch\":\n                print(); nl = 1\n                i = 0\n                for a in av[1]:\n                    if i > 0:\n                        print(level*\"  \" + \"or\")\n                    a.dump(level+1); nl = 1\n                    i = i + 1\n            elif isinstance(av, seqtypes):\n                for a in av:\n                    if isinstance(a, SubPattern):\n                        if not nl: print()\n                        a.dump(level+1); nl = 1\n                    else:\n                        print(a, end=' ') ; nl = 0\n            else:\n                print(av, end=' ') ; nl = 0\n            if not nl: print()\n    def __repr__(self):\n        return repr(self.data)\n    def __len__(self):\n        return len(self.data)\n    def __delitem__(self, index):\n        del self.data[index]\n    def __getitem__(self, index):\n        if isinstance(index, slice):\n            return SubPattern(self.pattern, self.data[index])\n        return self.data[index]\n    def __setitem__(self, index, code):\n        self.data[index] = code\n    def insert(self, index, code):\n        self.data.insert(index, code)\n    def append(self, code):\n        self.data.append(code)\n    def getwidth(self):\n        # determine the width (min, max) for this subpattern\n        if self.width:\n            return self.width\n        lo = hi = 0\n        UNITCODES = (ANY, RANGE, IN, LITERAL, NOT_LITERAL, CATEGORY)\n        REPEATCODES = (MIN_REPEAT, MAX_REPEAT)\n        for op, av in self.data:\n            if op is BRANCH:\n                i = sys.maxsize\n                j = 0\n                for av in av[1]:\n                    l, h = av.getwidth()\n                    i = min(i, l)\n                    j = max(j, h)\n                lo = lo + i\n                hi = hi + j\n            elif op is CALL:\n                i, j = av.getwidth()\n                lo = lo + i\n                hi = hi + j\n            elif op is SUBPATTERN:\n                i, j = av[1].getwidth()\n                lo = lo + i\n                hi = hi + j\n            elif op in REPEATCODES:\n                i, j = av[2].getwidth()\n                lo = lo + int(i) * av[0]\n                hi = hi + int(j) * av[1]\n            elif op in UNITCODES:\n                lo = lo + 1\n                hi = hi + 1\n            elif op == SUCCESS:\n                break\n        self.width = int(min(lo, sys.maxsize)), int(min(hi, sys.maxsize))\n        return self.width\n\nclass Tokenizer:\n    def __init__(self, string):\n        self.istext = isinstance(string, str)\n        self.string = string\n        self.index = 0\n        self.__next()\n    def __next(self):\n        if self.index >= len(self.string):\n            self.next = None\n            return\n        char = self.string[self.index:self.index+1]\n        # Special case for the str8, since indexing returns a integer\n        # XXX This is only needed for test_bug_926075 in test_re.py\n        if char and not self.istext:\n            char = chr(char[0])\n        if char == \"\\\\\":\n            try:\n                c = self.string[self.index + 1]\n            except IndexError:\n                raise error(\"bogus escape (end of line)\")\n            if not self.istext:\n                c = chr(c)\n            char = char + c\n        self.index = self.index + len(char)\n        self.next = char\n    def match(self, char, skip=1):\n        if char == self.next:\n            if skip:\n                self.__next()\n            return 1\n        return 0\n    def get(self):\n        this = self.next\n        self.__next()\n        return this\n    def getwhile(self, n, charset):\n        result = ''\n        for _ in range(n):\n            c = self.next\n            if c not in charset:\n                break\n            result += c\n            self.__next()\n        return result\n    def tell(self):\n        return self.index, self.next\n    def seek(self, index):\n        self.index, self.next = index\n\ndef isident(char):\n    return \"a\" <= char <= \"z\" or \"A\" <= char <= \"Z\" or char == \"_\"\n\ndef isdigit(char):\n    return \"0\" <= char <= \"9\"\n\ndef isname(name):\n    # check that group name is a valid string\n    if not isident(name[0]):\n        return False\n    for char in name[1:]:\n        if not isident(char) and not isdigit(char):\n            return False\n    return True\n\ndef _class_escape(source, escape):\n    # handle escape code inside character class\n    code = ESCAPES.get(escape)\n    if code:\n        return code\n    code = CATEGORIES.get(escape)\n    if code and code[0] == IN:\n        return code\n    try:\n        c = escape[1:2]\n        if c == \"x\":\n            # hexadecimal escape (exactly two digits)\n            escape += source.getwhile(2, HEXDIGITS)\n            if len(escape) != 4:\n                raise ValueError\n            return LITERAL, int(escape[2:], 16) & 0xff\n        elif c == \"u\" and source.istext:\n            # unicode escape (exactly four digits)\n            escape += source.getwhile(4, HEXDIGITS)\n            if len(escape) != 6:\n                raise ValueError\n            return LITERAL, int(escape[2:], 16)\n        elif c == \"U\" and source.istext:\n            # unicode escape (exactly eight digits)\n            escape += source.getwhile(8, HEXDIGITS)\n            if len(escape) != 10:\n                raise ValueError\n            c = int(escape[2:], 16)\n            chr(c) # raise ValueError for invalid code\n            return LITERAL, c\n        elif c in OCTDIGITS:\n            # octal escape (up to three digits)\n            escape += source.getwhile(2, OCTDIGITS)\n            return LITERAL, int(escape[1:], 8) & 0xff\n        elif c in DIGITS:\n            raise ValueError\n        if len(escape) == 2:\n            return LITERAL, ord(escape[1])\n    except ValueError:\n        pass\n    raise error(\"bogus escape: %s\" % repr(escape))\n\ndef _escape(source, escape, state):\n    # handle escape code in expression\n    code = CATEGORIES.get(escape)\n    if code:\n        return code\n    code = ESCAPES.get(escape)\n    if code:\n        return code\n    try:\n        c = escape[1:2]\n        if c == \"x\":\n            # hexadecimal escape\n            escape += source.getwhile(2, HEXDIGITS)\n            if len(escape) != 4:\n                raise ValueError\n            return LITERAL, int(escape[2:], 16) & 0xff\n        elif c == \"u\" and source.istext:\n            # unicode escape (exactly four digits)\n            escape += source.getwhile(4, HEXDIGITS)\n            if len(escape) != 6:\n                raise ValueError\n            return LITERAL, int(escape[2:], 16)\n        elif c == \"U\" and source.istext:\n            # unicode escape (exactly eight digits)\n            escape += source.getwhile(8, HEXDIGITS)\n            if len(escape) != 10:\n                raise ValueError\n            c = int(escape[2:], 16)\n            chr(c) # raise ValueError for invalid code\n            return LITERAL, c\n        elif c == \"0\":\n            # octal escape\n            escape += source.getwhile(2, OCTDIGITS)\n            return LITERAL, int(escape[1:], 8) & 0xff\n        elif c in DIGITS:\n            # octal escape *or* decimal group reference (sigh)\n            if source.next in DIGITS:\n                escape = escape + source.get()\n                if (escape[1] in OCTDIGITS and escape[2] in OCTDIGITS and\n                    source.next in OCTDIGITS):\n                    # got three octal digits; this is an octal escape\n                    escape = escape + source.get()\n                    return LITERAL, int(escape[1:], 8) & 0xff\n            # not an octal escape, so this is a group reference\n            group = int(escape[1:])\n            if group < state.groups:\n                if not state.checkgroup(group):\n                    raise error(\"cannot refer to open group\")\n                return GROUPREF, group\n            raise ValueError\n        if len(escape) == 2:\n            return LITERAL, ord(escape[1])\n    except ValueError:\n        pass\n    raise error(\"bogus escape: %s\" % repr(escape))\n\ndef _parse_sub(source, state, nested=1):\n    # parse an alternation: a|b|c\n\n    items = []\n    itemsappend = items.append\n    sourcematch = source.match\n    while 1:\n        itemsappend(_parse(source, state))\n        if sourcematch(\"|\"):\n            continue\n        if not nested:\n            break\n        if not source.next or sourcematch(\")\", 0):\n            break\n        else:\n            raise error(\"pattern not properly closed\")\n\n    if len(items) == 1:\n        return items[0]\n\n    subpattern = SubPattern(state)\n    subpatternappend = subpattern.append\n\n    # check if all items share a common prefix\n    while 1:\n        prefix = None\n        for item in items:\n            if not item:\n                break\n            if prefix is None:\n                prefix = item[0]\n            elif item[0] != prefix:\n                break\n        else:\n            # all subitems start with a common \"prefix\".\n            # move it out of the branch\n            for item in items:\n                del item[0]\n            subpatternappend(prefix)\n            continue # check next one\n        break\n\n    # check if the branch can be replaced by a character set\n    for item in items:\n        if len(item) != 1 or item[0][0] != LITERAL:\n            break\n    else:\n        # we can store this as a character set instead of a\n        # branch (the compiler may optimize this even more)\n        set = []\n        setappend = set.append\n        for item in items:\n            setappend(item[0])\n        subpatternappend((IN, set))\n        return subpattern\n\n    subpattern.append((BRANCH, (None, items)))\n    return subpattern\n\ndef _parse_sub_cond(source, state, condgroup):\n    item_yes = _parse(source, state)\n    if source.match(\"|\"):\n        item_no = _parse(source, state)\n        if source.match(\"|\"):\n            raise error(\"conditional backref with more than two branches\")\n    else:\n        item_no = None\n    if source.next and not source.match(\")\", 0):\n        raise error(\"pattern not properly closed\")\n    subpattern = SubPattern(state)\n    subpattern.append((GROUPREF_EXISTS, (condgroup, item_yes, item_no)))\n    return subpattern\n\n_PATTERNENDERS = set(\"|)\")\n_ASSERTCHARS = set(\"=!<\")\n_LOOKBEHINDASSERTCHARS = set(\"=!\")\n_REPEATCODES = set([MIN_REPEAT, MAX_REPEAT])\n\ndef _parse(source, state):\n    # parse a simple pattern\n    subpattern = SubPattern(state)\n\n    # precompute constants into local variables\n    subpatternappend = subpattern.append\n    sourceget = source.get\n    sourcematch = source.match\n    _len = len\n    PATTERNENDERS = _PATTERNENDERS\n    ASSERTCHARS = _ASSERTCHARS\n    LOOKBEHINDASSERTCHARS = _LOOKBEHINDASSERTCHARS\n    REPEATCODES = _REPEATCODES\n\n    while 1:\n\n        if source.next in PATTERNENDERS:\n            break # end of subpattern\n        this = sourceget()\n        if this is None:\n            break # end of pattern\n\n        if state.flags & SRE_FLAG_VERBOSE:\n            # skip whitespace and comments\n            if this in WHITESPACE:\n                continue\n            if this == \"#\":\n                while 1:\n                    this = sourceget()\n                    if this in (None, \"\\n\"):\n                        break\n                continue\n\n        if this and this[0] not in SPECIAL_CHARS:\n            subpatternappend((LITERAL, ord(this)))\n\n        elif this == \"[\":\n            # character set\n            set = []\n            setappend = set.append\n##          if sourcematch(\":\"):\n##              pass # handle character classes\n            if sourcematch(\"^\"):\n                setappend((NEGATE, None))\n            # check remaining characters\n            start = set[:]\n            while 1:\n                this = sourceget()\n                if this == \"]\" and set != start:\n                    break\n                elif this and this[0] == \"\\\\\":\n                    code1 = _class_escape(source, this)\n                elif this:\n                    code1 = LITERAL, ord(this)\n                else:\n                    raise error(\"unexpected end of regular expression\")\n                if sourcematch(\"-\"):\n                    # potential range\n                    this = sourceget()\n                    if this == \"]\":\n                        if code1[0] is IN:\n                            code1 = code1[1][0]\n                        setappend(code1)\n                        setappend((LITERAL, ord(\"-\")))\n                        break\n                    elif this:\n                        if this[0] == \"\\\\\":\n                            code2 = _class_escape(source, this)\n                        else:\n                            code2 = LITERAL, ord(this)\n                        if code1[0] != LITERAL or code2[0] != LITERAL:\n                            raise error(\"bad character range\")\n                        lo = code1[1]\n                        hi = code2[1]\n                        if hi < lo:\n                            raise error(\"bad character range\")\n                        setappend((RANGE, (lo, hi)))\n                    else:\n                        raise error(\"unexpected end of regular expression\")\n                else:\n                    if code1[0] is IN:\n                        code1 = code1[1][0]\n                    setappend(code1)\n\n            # XXX: <fl> should move set optimization to compiler!\n            if _len(set)==1 and set[0][0] is LITERAL:\n                subpatternappend(set[0]) # optimization\n            elif _len(set)==2 and set[0][0] is NEGATE and set[1][0] is LITERAL:\n                subpatternappend((NOT_LITERAL, set[1][1])) # optimization\n            else:\n                # XXX: <fl> should add charmap optimization here\n                subpatternappend((IN, set))\n\n        elif this and this[0] in REPEAT_CHARS:\n            # repeat previous item\n            if this == \"?\":\n                min, max = 0, 1\n            elif this == \"*\":\n                min, max = 0, MAXREPEAT\n\n            elif this == \"+\":\n                min, max = 1, MAXREPEAT\n            elif this == \"{\":\n                if source.next == \"}\":\n                    subpatternappend((LITERAL, ord(this)))\n                    continue\n                here = source.tell()\n                min, max = 0, MAXREPEAT\n                lo = hi = \"\"\n                while source.next in DIGITS:\n                    lo = lo + source.get()\n                if sourcematch(\",\"):\n                    while source.next in DIGITS:\n                        hi = hi + sourceget()\n                else:\n                    hi = lo\n                if not sourcematch(\"}\"):\n                    subpatternappend((LITERAL, ord(this)))\n                    source.seek(here)\n                    continue\n                if lo:\n                    min = int(lo)\n                    if min >= MAXREPEAT:\n                        raise OverflowError(\"the repetition number is too large\")\n                if hi:\n                    max = int(hi)\n                    if max >= MAXREPEAT:\n                        raise OverflowError(\"the repetition number is too large\")\n                    if max < min:\n                        raise error(\"bad repeat interval\")\n            else:\n                raise error(\"not supported\")\n            # figure out which item to repeat\n            if subpattern:\n                item = subpattern[-1:]\n            else:\n                item = None\n            if not item or (_len(item) == 1 and item[0][0] == AT):\n                raise error(\"nothing to repeat\")\n            if item[0][0] in REPEATCODES:\n                raise error(\"multiple repeat\")\n            if sourcematch(\"?\"):\n                subpattern[-1] = (MIN_REPEAT, (min, max, item))\n            else:\n                subpattern[-1] = (MAX_REPEAT, (min, max, item))\n\n        elif this == \".\":\n            subpatternappend((ANY, None))\n\n        elif this == \"(\":\n            group = 1\n            name = None\n            condgroup = None\n            if sourcematch(\"?\"):\n                group = 0\n                # options\n                if sourcematch(\"P\"):\n                    # python extensions\n                    if sourcematch(\"<\"):\n                        # named group: skip forward to end of name\n                        name = \"\"\n                        while 1:\n                            char = sourceget()\n                            if char is None:\n                                raise error(\"unterminated name\")\n                            if char == \">\":\n                                break\n                            name = name + char\n                        group = 1\n                        if not name:\n                            raise error(\"missing group name\")\n                        if not isname(name):\n                            raise error(\"bad character in group name\")\n                    elif sourcematch(\"=\"):\n                        # named backreference\n                        name = \"\"\n                        while 1:\n                            char = sourceget()\n                            if char is None:\n                                raise error(\"unterminated name\")\n                            if char == \")\":\n                                break\n                            name = name + char\n                        if not name:\n                            raise error(\"missing group name\")\n                        if not isname(name):\n                            raise error(\"bad character in group name\")\n                        gid = state.groupdict.get(name)\n                        if gid is None:\n                            raise error(\"unknown group name\")\n                        subpatternappend((GROUPREF, gid))\n                        continue\n                    else:\n                        char = sourceget()\n                        if char is None:\n                            raise error(\"unexpected end of pattern\")\n                        raise error(\"unknown specifier: ?P%s\" % char)\n                elif sourcematch(\":\"):\n                    # non-capturing group\n                    group = 2\n                elif sourcematch(\"#\"):\n                    # comment\n                    while 1:\n                        if source.next is None or source.next == \")\":\n                            break\n                        sourceget()\n                    if not sourcematch(\")\"):\n                        raise error(\"unbalanced parenthesis\")\n                    continue\n                elif source.next in ASSERTCHARS:\n                    # lookahead assertions\n                    char = sourceget()\n                    dir = 1\n                    if char == \"<\":\n                        if source.next not in LOOKBEHINDASSERTCHARS:\n                            raise error(\"syntax error\")\n                        dir = -1 # lookbehind\n                        char = sourceget()\n                    p = _parse_sub(source, state)\n                    if not sourcematch(\")\"):\n                        raise error(\"unbalanced parenthesis\")\n                    if char == \"=\":\n                        subpatternappend((ASSERT, (dir, p)))\n                    else:\n                        subpatternappend((ASSERT_NOT, (dir, p)))\n                    continue\n                elif sourcematch(\"(\"):\n                    # conditional backreference group\n                    condname = \"\"\n                    while 1:\n                        char = sourceget()\n                        if char is None:\n                            raise error(\"unterminated name\")\n                        if char == \")\":\n                            break\n                        condname = condname + char\n                    group = 2\n                    if not condname:\n                        raise error(\"missing group name\")\n                    if isname(condname):\n                        condgroup = state.groupdict.get(condname)\n                        if condgroup is None:\n                            raise error(\"unknown group name\")\n                    else:\n                        try:\n                            condgroup = int(condname)\n                        except ValueError:\n                            raise error(\"bad character in group name\")\n                else:\n                    # flags\n                    if not source.next in FLAGS:\n                        raise error(\"unexpected end of pattern\")\n                    while source.next in FLAGS:\n                        state.flags = state.flags | FLAGS[sourceget()]\n            if group:\n                # parse group contents\n                if group == 2:\n                    # anonymous group\n                    group = None\n                else:\n                    group = state.opengroup(name)\n                if condgroup:\n                    p = _parse_sub_cond(source, state, condgroup)\n                else:\n                    p = _parse_sub(source, state)\n                if not sourcematch(\")\"):\n                    raise error(\"unbalanced parenthesis\")\n                if group is not None:\n                    state.closegroup(group)\n                subpatternappend((SUBPATTERN, (group, p)))\n            else:\n                while 1:\n                    char = sourceget()\n                    if char is None:\n                        raise error(\"unexpected end of pattern\")\n                    if char == \")\":\n                        break\n                    raise error(\"unknown extension\")\n\n        elif this == \"^\":\n            subpatternappend((AT, AT_BEGINNING))\n\n        elif this == \"$\":\n            subpattern.append((AT, AT_END))\n\n        elif this and this[0] == \"\\\\\":\n            code = _escape(source, this, state)\n            subpatternappend(code)\n\n        else:\n            raise error(\"parser error\")\n\n    return subpattern\n\ndef fix_flags(src, flags):\n    # Check and fix flags according to the type of pattern (str or bytes)\n    if isinstance(src, str):\n        if not flags & SRE_FLAG_ASCII:\n            flags |= SRE_FLAG_UNICODE\n        elif flags & SRE_FLAG_UNICODE:\n            raise ValueError(\"ASCII and UNICODE flags are incompatible\")\n    else:\n        if flags & SRE_FLAG_UNICODE:\n            raise ValueError(\"can't use UNICODE flag with a bytes pattern\")\n    return flags\n\ndef parse(str, flags=0, pattern=None):\n    # parse 're' pattern into list of (opcode, argument) tuples\n    source = Tokenizer(str)\n\n    if pattern is None:\n        pattern = Pattern()\n    pattern.flags = flags\n    pattern.str = str\n    p = _parse_sub(source, pattern, 0)\n    p.pattern.flags = fix_flags(str, p.pattern.flags)\n\n    tail = source.get()\n    if tail == \")\":\n        raise error(\"unbalanced parenthesis\")\n    elif tail:\n        raise error(\"bogus characters at end of regular expression\")\n\n    if flags & SRE_FLAG_DEBUG:\n        p.dump()\n\n    if not (flags & SRE_FLAG_VERBOSE) and p.pattern.flags & SRE_FLAG_VERBOSE:\n        # the VERBOSE flag was switched on inside the pattern.  to be\n        # on the safe side, we'll parse the whole thing again...\n        return parse(str, p.pattern.flags)\n\n    return p\n\ndef parse_template(source, pattern):\n    # parse 're' replacement string into list of literals and\n    # group references\n    s = Tokenizer(source)\n    sget = s.get\n    p = []\n    a = p.append\n    def literal(literal, p=p, pappend=a):\n        if p and p[-1][0] is LITERAL:\n            p[-1] = LITERAL, p[-1][1] + literal\n        else:\n            pappend((LITERAL, literal))\n    sep = source[:0]\n    if isinstance(sep, str):\n        makechar = chr\n    else:\n        makechar = chr\n    while 1:\n        this = sget()\n        if this is None:\n            break # end of replacement string\n        if this and this[0] == \"\\\\\":\n            # group\n            c = this[1:2]\n            if c == \"g\":\n                name = \"\"\n                if s.match(\"<\"):\n                    while 1:\n                        char = sget()\n                        if char is None:\n                            raise error(\"unterminated group name\")\n                        if char == \">\":\n                            break\n                        name = name + char\n                if not name:\n                    raise error(\"missing group name\")\n                try:\n                    index = int(name)\n                    if index < 0:\n                        raise error(\"negative group number\")\n                except ValueError:\n                    if not isname(name):\n                        raise error(\"bad character in group name\")\n                    try:\n                        index = pattern.groupindex[name]\n                    except KeyError:\n                        raise IndexError(\"unknown group name\")\n                a((MARK, index))\n            elif c == \"0\":\n                if s.next in OCTDIGITS:\n                    this = this + sget()\n                    if s.next in OCTDIGITS:\n                        this = this + sget()\n                literal(makechar(int(this[1:], 8) & 0xff))\n            elif c in DIGITS:\n                isoctal = False\n                if s.next in DIGITS:\n                    this = this + sget()\n                    if (c in OCTDIGITS and this[2] in OCTDIGITS and\n                        s.next in OCTDIGITS):\n                        this = this + sget()\n                        isoctal = True\n                        literal(makechar(int(this[1:], 8) & 0xff))\n                if not isoctal:\n                    a((MARK, int(this[1:])))\n            else:\n                try:\n                    this = makechar(ESCAPES[this][1])\n                except KeyError:\n                    pass\n                literal(this)\n        else:\n            literal(this)\n    # convert template to groups and literals lists\n    i = 0\n    groups = []\n    groupsappend = groups.append\n    literals = [None] * len(p)\n    if isinstance(source, str):\n        encode = lambda x: x\n    else:\n        # The tokenizer implicitly decodes bytes objects as latin-1, we must\n        # therefore re-encode the final representation.\n        encode = lambda x: x.encode('latin-1')\n    for c, s in p:\n        if c is MARK:\n            groupsappend((i, s))\n            # literal[i] is already None\n        else:\n            literals[i] = encode(s)\n        i = i + 1\n    return groups, literals\n\ndef expand_template(template, match):\n    g = match.group\n    sep = match.string[:0]\n    groups, literals = template\n    literals = literals[:]\n    try:\n        for index, group in groups:\n            literals[index] = s = g(group)\n            if s is None:\n                raise error(\"unmatched group\")\n    except IndexError:\n        raise error(\"invalid group reference\")\n    return sep.join(literals)\n\n\n"], "pickle": [".py", "from json import *"], "unittest.test.testmock": [".py", "import os\nimport sys\nimport unittest\n\n\nhere = os.path.dirname(__file__)\nloader = unittest.defaultTestLoader\n\ndef load_tests(*args):\n    suite = unittest.TestSuite()\n    for fn in os.listdir(here):\n        if fn.startswith(\"test\") and fn.endswith(\".py\"):\n            modname = \"unittest.test.testmock.\" + fn[:-3]\n            __import__(modname)\n            module = sys.modules[modname]\n            suite.addTest(loader.loadTestsFromModule(module))\n    return suite\n", 1], "browser": [".py", "from _browser import *\n\nfrom .local_storage import LocalStorage\nfrom .session_storage import SessionStorage\nfrom .object_storage import ObjectStorage\n", 1], "reprlib": [".py", "\"\"\"Redo the builtin repr() (representation) but with limits on most sizes.\"\"\"\n\n__all__ = [\"Repr\", \"repr\", \"recursive_repr\"]\n\nimport builtins\nfrom itertools import islice\ntry:\n    from _thread import get_ident\nexcept ImportError:\n    from _dummy_thread import get_ident\n\ndef recursive_repr(fillvalue='...'):\n    'Decorator to make a repr function return fillvalue for a recursive call'\n\n    def decorating_function(user_function):\n        repr_running = set()\n\n        def wrapper(self):\n            key = id(self), get_ident()\n            if key in repr_running:\n                return fillvalue\n            repr_running.add(key)\n            try:\n                result = user_function(self)\n            finally:\n                repr_running.discard(key)\n            return result\n\n        # Can't use functools.wraps() here because of bootstrap issues\n        wrapper.__module__ = getattr(user_function, '__module__')\n        wrapper.__doc__ = getattr(user_function, '__doc__')\n        wrapper.__name__ = getattr(user_function, '__name__')\n        wrapper.__annotations__ = getattr(user_function, '__annotations__', {})\n        return wrapper\n\n    return decorating_function\n\nclass Repr:\n\n    def __init__(self):\n        self.maxlevel = 6\n        self.maxtuple = 6\n        self.maxlist = 6\n        self.maxarray = 5\n        self.maxdict = 4\n        self.maxset = 6\n        self.maxfrozenset = 6\n        self.maxdeque = 6\n        self.maxstring = 30\n        self.maxlong = 40\n        self.maxother = 30\n\n    def repr(self, x):\n        return self.repr1(x, self.maxlevel)\n\n    def repr1(self, x, level):\n        typename = type(x).__name__\n        if ' ' in typename:\n            parts = typename.split()\n            typename = '_'.join(parts)\n        if hasattr(self, 'repr_' + typename):\n            return getattr(self, 'repr_' + typename)(x, level)\n        else:\n            return self.repr_instance(x, level)\n\n    def _repr_iterable(self, x, level, left, right, maxiter, trail=''):\n        n = len(x)\n        if level <= 0 and n:\n            s = '...'\n        else:\n            newlevel = level - 1\n            repr1 = self.repr1\n            pieces = [repr1(elem, newlevel) for elem in islice(x, maxiter)]\n            if n > maxiter:  pieces.append('...')\n            s = ', '.join(pieces)\n            if n == 1 and trail:  right = trail + right\n        return '%s%s%s' % (left, s, right)\n\n    def repr_tuple(self, x, level):\n        return self._repr_iterable(x, level, '(', ')', self.maxtuple, ',')\n\n    def repr_list(self, x, level):\n        return self._repr_iterable(x, level, '[', ']', self.maxlist)\n\n    def repr_array(self, x, level):\n        header = \"array('%s', [\" % x.typecode\n        return self._repr_iterable(x, level, header, '])', self.maxarray)\n\n    def repr_set(self, x, level):\n        x = _possibly_sorted(x)\n        return self._repr_iterable(x, level, 'set([', '])', self.maxset)\n\n    def repr_frozenset(self, x, level):\n        x = _possibly_sorted(x)\n        return self._repr_iterable(x, level, 'frozenset([', '])',\n                                   self.maxfrozenset)\n\n    def repr_deque(self, x, level):\n        return self._repr_iterable(x, level, 'deque([', '])', self.maxdeque)\n\n    def repr_dict(self, x, level):\n        n = len(x)\n        if n == 0: return '{}'\n        if level <= 0: return '{...}'\n        newlevel = level - 1\n        repr1 = self.repr1\n        pieces = []\n        for key in islice(_possibly_sorted(x), self.maxdict):\n            keyrepr = repr1(key, newlevel)\n            valrepr = repr1(x[key], newlevel)\n            pieces.append('%s: %s' % (keyrepr, valrepr))\n        if n > self.maxdict: pieces.append('...')\n        s = ', '.join(pieces)\n        return '{%s}' % (s,)\n\n    def repr_str(self, x, level):\n        s = builtins.repr(x[:self.maxstring])\n        if len(s) > self.maxstring:\n            i = max(0, (self.maxstring-3)//2)\n            j = max(0, self.maxstring-3-i)\n            s = builtins.repr(x[:i] + x[len(x)-j:])\n            s = s[:i] + '...' + s[len(s)-j:]\n        return s\n\n    def repr_int(self, x, level):\n        s = builtins.repr(x) # XXX Hope this isn't too slow...\n        if len(s) > self.maxlong:\n            i = max(0, (self.maxlong-3)//2)\n            j = max(0, self.maxlong-3-i)\n            s = s[:i] + '...' + s[len(s)-j:]\n        return s\n\n    def repr_instance(self, x, level):\n        try:\n            s = builtins.repr(x)\n            # Bugs in x.__repr__() can cause arbitrary\n            # exceptions -- then make up something\n        except Exception:\n            return '<%s instance at %x>' % (x.__class__.__name__, id(x))\n        if len(s) > self.maxother:\n            i = max(0, (self.maxother-3)//2)\n            j = max(0, self.maxother-3-i)\n            s = s[:i] + '...' + s[len(s)-j:]\n        return s\n\n\ndef _possibly_sorted(x):\n    # Since not all sequences of items can be sorted and comparison\n    # functions may raise arbitrary exceptions, return an unsorted\n    # sequence in that case.\n    try:\n        return sorted(x)\n    except Exception:\n        return list(x)\n\naRepr = Repr()\nrepr = aRepr.repr\n"], "browser.indexed_db": [".py", "class EventListener:\n  def __init__(self, events=[]):\n      self._events=events\n\n  def append(self, event):\n      self._events.append(event)\n\n  def fire(self, e):\n      for _event in self._events:\n          _event(e)\n\nclass IndexedDB:\n  def __init__(self):\n      if not __BRYTHON__.has_indexedDB:\n         raise NotImplementedError(\"Your browser doesn't support indexedDB\")\n         return\n\n      self._indexedDB=__BRYTHON__.indexedDB()\n      self._db=None\n      self._version=None\n\n  def _onsuccess(self, event):\n      self._db=event.target.result\n\n  def open(self, name, onsuccess, version=1.0, onerror=None, \n           onupgradeneeded=None):\n      self._version=version\n      _result=self._indexedDB.open(name, version)\n      _success=EventListener([self._onsuccess, onsuccess])\n      _result.onsuccess=_success.fire\n      _result.onupgradeneeded=onupgradeneeded\n\n      #if onerror is None:\n      def onerror(e):\n          print(\"onerror: %s:%s\" %  (e.type, e.target.result))\n\n      def onblocked(e):\n          print(\"blocked: %s:%s\" %  (e.type, e.result))\n\n      _result.onerror=onerror\n      _result.onblocked=onblocked\n\n  def transaction(self, entities, mode='read'):\n      return Transaction(self._db.transaction(entities, mode))\n\nclass Transaction:\n\n  def __init__(self, transaction):\n      self._transaction=transaction\n\n  def objectStore(self, name):\n      return ObjectStore(self._transaction.objectStore(name))\n\nclass ObjectStore:\n\n  def __init__(self, objectStore):\n      self._objectStore=objectStore\n      self._data=[]\n\n  def clear(self, onsuccess=None, onerror=None):\n      _result=self._objectStore.clear()\n\n      if onsuccess is not None:\n         _result.onsuccess=onsuccess\n\n      if onerror is not None:\n         _result.onerror=onerror\n\n  def _helper(self, func, object, onsuccess=None, onerror=None):\n      _result=func(object)\n\n      if onsuccess is not None:\n         _result.onsuccess=onsuccess\n\n      if onerror is not None:\n         _result.onerror=onerror\n\n  def put(self, obj, key=None, onsuccess=None, onerror=None):\n      _r = self._objectStore.put(obj, key)\n      _r.onsuccess = onsuccess\n      _r.onerror = onerror\n\n  def add(self, obj, key, onsuccess=None, onerror=None):\n      _r = self._objectStore.add(obj, key)\n      _r.onsuccess = onsuccess\n      _r.onerror = onerror\n      #self._helper(self._objectStore.add, object, onsuccess, onerror)\n\n  def delete(self, index, onsuccess=None, onerror=None): \n      self._helper(self._objectStore.delete, index, onsuccess, onerror)\n     \n  def query(self, *args):\n      self._data=[]\n      def onsuccess(event):\n          cursor=event.target.result\n          if cursor is not None:\n             self._data.append(cursor.value)\n             getattr(cursor,\"continue\")() # cursor.continue() is illegal\n\n      self._objectStore.openCursor(args).onsuccess=onsuccess\n\n  def fetchall(self):\n      yield self._data\n\n  def get(self, key, onsuccess=None, onerror=None):\n      self._helper(self._objectStore.get, key, onsuccess, onerror)\n"], "sre_compile": [".py", "#\n# Secret Labs' Regular Expression Engine\n#\n# convert template to internal format\n#\n# Copyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.\n#\n# See the sre.py file for information on usage and redistribution.\n#\n\n\"\"\"Internal support module for sre\"\"\"\n\n\nimport sys\nimport _sre\nimport sre_parse\nfrom sre_constants import *\nfrom _sre import MAXREPEAT\n\n\nassert _sre.MAGIC == MAGIC, \"SRE module mismatch\"\n\nif _sre.CODESIZE == 2:\n    MAXCODE = 65535\nelse:\n    MAXCODE = 0xFFFFFFFF\n\ndef _identityfunction(x):\n    return x\n\n\n_LITERAL_CODES = set([LITERAL, NOT_LITERAL])\n_REPEATING_CODES = set([REPEAT, MIN_REPEAT, MAX_REPEAT])\n_SUCCESS_CODES = set([SUCCESS, FAILURE])\n_ASSERT_CODES = set([ASSERT, ASSERT_NOT])\n\ndef _compile(code, pattern, flags):\n    # internal: compile a (sub)pattern\n    emit = code.append\n    _len = len\n    LITERAL_CODES = _LITERAL_CODES\n    REPEATING_CODES = _REPEATING_CODES\n    SUCCESS_CODES = _SUCCESS_CODES\n    ASSERT_CODES = _ASSERT_CODES\n    for op, av in pattern:\n        #print('sre_compile.py:_compile:42', op, av)\n        #print('sre_compile.py:_compile:42', code)\n        if op in LITERAL_CODES:\n            if flags & SRE_FLAG_IGNORECASE:\n                emit(OPCODES[OP_IGNORE[op]])\n                emit(_sre.getlower(av, flags))\n            else:\n                emit(OPCODES[op])\n                emit(av)\n        elif op is IN:\n            if flags & SRE_FLAG_IGNORECASE:\n                emit(OPCODES[OP_IGNORE[op]])\n                def fixup(literal, flags=flags):\n                    return _sre.getlower(literal, flags)\n            else:\n                emit(OPCODES[op])\n                fixup = _identityfunction\n            skip = _len(code); emit(0)\n            _compile_charset(av, flags, code, fixup)\n            code[skip] = _len(code) - skip\n        elif op is ANY:\n            if flags & SRE_FLAG_DOTALL:\n                emit(OPCODES[ANY_ALL])\n            else:\n                emit(OPCODES[ANY])\n        elif op in REPEATING_CODES:\n            if flags & SRE_FLAG_TEMPLATE:\n                raise error(\"internal: unsupported template operator\")\n                emit(OPCODES[REPEAT])\n                skip = _len(code); emit(0)\n                emit(av[0])\n                emit(av[1])\n                _compile(code, av[2], flags)\n                emit(OPCODES[SUCCESS])\n                code[skip] = _len(code) - skip\n            elif _simple(av) and op is not REPEAT:\n                if op is MAX_REPEAT:\n                    emit(OPCODES[REPEAT_ONE])\n                else:\n                    emit(OPCODES[MIN_REPEAT_ONE])\n                skip = _len(code); emit(0)\n                emit(av[0])\n                emit(av[1])\n                _compile(code, av[2], flags)\n                emit(OPCODES[SUCCESS])\n                code[skip] = _len(code) - skip\n            else:\n                emit(OPCODES[REPEAT])\n                skip = _len(code); emit(0)\n                emit(av[0])\n                emit(av[1])\n                _compile(code, av[2], flags)\n                code[skip] = _len(code) - skip\n                if op is MAX_REPEAT:\n                    emit(OPCODES[MAX_UNTIL])\n                else:\n                    emit(OPCODES[MIN_UNTIL])\n        elif op is SUBPATTERN:\n            if av[0]:\n                emit(OPCODES[MARK])\n                emit((av[0]-1)*2)\n            # _compile_info(code, av[1], flags)\n            _compile(code, av[1], flags)\n            if av[0]:\n                emit(OPCODES[MARK])\n                emit((av[0]-1)*2+1)\n        elif op in SUCCESS_CODES:\n            emit(OPCODES[op])\n        elif op in ASSERT_CODES:\n            emit(OPCODES[op])\n            skip = _len(code); emit(0)\n            if av[0] >= 0:\n                emit(0) # look ahead\n            else:\n                lo, hi = av[1].getwidth()\n                if lo != hi:\n                    raise error(\"look-behind requires fixed-width pattern\")\n                emit(lo) # look behind\n            _compile(code, av[1], flags)\n            emit(OPCODES[SUCCESS])\n            code[skip] = _len(code) - skip\n        elif op is CALL:\n            emit(OPCODES[op])\n            skip = _len(code); emit(0)\n            _compile(code, av, flags)\n            emit(OPCODES[SUCCESS])\n            code[skip] = _len(code) - skip\n        elif op is AT:\n            emit(OPCODES[op])\n            if flags & SRE_FLAG_MULTILINE:\n                av = AT_MULTILINE.get(av, av)\n            if flags & SRE_FLAG_LOCALE:\n                av = AT_LOCALE.get(av, av)\n            elif flags & SRE_FLAG_UNICODE:\n                av = AT_UNICODE.get(av, av)\n            emit(ATCODES[av])\n        elif op is BRANCH:\n            emit(OPCODES[op])\n            tail = []\n            tailappend = tail.append\n            for av in av[1]:\n                skip = _len(code); emit(0)\n                # _compile_info(code, av, flags)\n                _compile(code, av, flags)\n                emit(OPCODES[JUMP])\n                tailappend(_len(code)); emit(0)\n                code[skip] = _len(code) - skip\n            emit(0) # end of branch\n            for tail in tail:\n                code[tail] = _len(code) - tail\n        elif op is CATEGORY:\n            emit(OPCODES[op])\n            if flags & SRE_FLAG_LOCALE:\n                av = CH_LOCALE[av]\n            elif flags & SRE_FLAG_UNICODE:\n                av = CH_UNICODE[av]\n            emit(CHCODES[av])\n        elif op is GROUPREF:\n            if flags & SRE_FLAG_IGNORECASE:\n                emit(OPCODES[OP_IGNORE[op]])\n            else:\n                emit(OPCODES[op])\n            emit(av-1)\n        elif op is GROUPREF_EXISTS:\n            emit(OPCODES[op])\n            emit(av[0]-1)\n            skipyes = _len(code); emit(0)\n            _compile(code, av[1], flags)\n            if av[2]:\n                emit(OPCODES[JUMP])\n                skipno = _len(code); emit(0)\n                code[skipyes] = _len(code) - skipyes + 1\n                _compile(code, av[2], flags)\n                code[skipno] = _len(code) - skipno\n            else:\n                code[skipyes] = _len(code) - skipyes + 1\n        else:\n            raise ValueError(\"unsupported operand type\", op)\n\ndef _compile_charset(charset, flags, code, fixup=None):\n    # compile charset subprogram\n    emit = code.append\n    if fixup is None:\n        fixup = _identityfunction\n    for op, av in _optimize_charset(charset, fixup):\n        emit(OPCODES[op])\n        if op is NEGATE:\n            pass\n        elif op is LITERAL:\n            emit(fixup(av))\n        elif op is RANGE:\n            emit(fixup(av[0]))\n            emit(fixup(av[1]))\n        elif op is CHARSET:\n            code.extend(av)\n        elif op is BIGCHARSET:\n            code.extend(av)\n        elif op is CATEGORY:\n            if flags & SRE_FLAG_LOCALE:\n                emit(CHCODES[CH_LOCALE[av]])\n            elif flags & SRE_FLAG_UNICODE:\n                emit(CHCODES[CH_UNICODE[av]])\n            else:\n                emit(CHCODES[av])\n        else:\n            raise error(\"internal: unsupported set operator\")\n    emit(OPCODES[FAILURE])\n\n\ndef _optimize_charset(charset, fixup):\n    # internal: optimize character set\n    out = []\n    outappend = out.append\n    charmap = [0]*256\n    try:\n        for op, av in charset:\n            if op is NEGATE:\n                outappend((op, av))\n            elif op is LITERAL:\n                charmap[fixup(av)] = 1\n            elif op is RANGE:\n                for i in range(fixup(av[0]), fixup(av[1])+1):\n                    charmap[i] = 1\n            elif op is CATEGORY:\n                # XXX: could append to charmap tail\n                return charset # cannot compress\n    except IndexError:\n        # character set contains unicode characters\n        return _optimize_unicode(charset, fixup)\n    # compress character map\n    i = p = n = 0\n    runs = []\n    runsappend = runs.append\n    for c in charmap:\n        if c:\n            if n == 0:\n                p = i\n            n = n + 1\n        elif n:\n            runsappend((p, n))\n            n = 0\n        i = i + 1\n    if n:\n        runsappend((p, n))\n    if len(runs) <= 2:\n        # use literal/range\n        for p, n in runs:\n            if n == 1:\n                outappend((LITERAL, p))\n            else:\n                outappend((RANGE, (p, p+n-1)))\n        if len(out) < len(charset):\n            return out\n    else:\n        # use bitmap\n        data = _mk_bitmap(charmap)\n        outappend((CHARSET, data))\n        return out\n    return charset\n\ndef _mk_bitmap(bits):\n    data = []\n    dataappend = data.append\n    if _sre.CODESIZE == 2:\n        start = (1, 0)\n    else:\n        start = (1, 0)\n    m, v = start\n    for c in bits:\n        if c:\n            v = v + m\n        m = m + m\n        if m > MAXCODE:\n            dataappend(v)\n            m, v = start\n    return data\n\n# To represent a big charset, first a bitmap of all characters in the\n# set is constructed. Then, this bitmap is sliced into chunks of 256\n# characters, duplicate chunks are eliminated, and each chunk is\n# given a number. In the compiled expression, the charset is\n# represented by a 16-bit word sequence, consisting of one word for\n# the number of different chunks, a sequence of 256 bytes (128 words)\n# of chunk numbers indexed by their original chunk position, and a\n# sequence of chunks (16 words each).\n\n# Compression is normally good: in a typical charset, large ranges of\n# Unicode will be either completely excluded (e.g. if only cyrillic\n# letters are to be matched), or completely included (e.g. if large\n# subranges of Kanji match). These ranges will be represented by\n# chunks of all one-bits or all zero-bits.\n\n# Matching can be also done efficiently: the more significant byte of\n# the Unicode character is an index into the chunk number, and the\n# less significant byte is a bit index in the chunk (just like the\n# CHARSET matching).\n\n# In UCS-4 mode, the BIGCHARSET opcode still supports only subsets\n# of the basic multilingual plane; an efficient representation\n# for all of UTF-16 has not yet been developed. This means,\n# in particular, that negated charsets cannot be represented as\n# bigcharsets.\n\ndef _optimize_unicode(charset, fixup):\n    try:\n        import array\n    except ImportError:\n        return charset\n    charmap = [0]*65536\n    negate = 0\n    try:\n        for op, av in charset:\n            if op is NEGATE:\n                negate = 1\n            elif op is LITERAL:\n                charmap[fixup(av)] = 1\n            elif op is RANGE:\n                for i in range(fixup(av[0]), fixup(av[1])+1):\n                    charmap[i] = 1\n            elif op is CATEGORY:\n                # XXX: could expand category\n                return charset # cannot compress\n    except IndexError:\n        # non-BMP characters; XXX now they should work\n        return charset\n    if negate:\n        if sys.maxunicode != 65535:\n            # XXX: negation does not work with big charsets\n            # XXX2: now they should work, but removing this will make the\n            # charmap 17 times bigger\n            return charset\n        for i in range(65536):\n            charmap[i] = not charmap[i]\n    comps = {}\n    mapping = [0]*256\n    block = 0\n    data = []\n    for i in range(256):\n        chunk = tuple(charmap[i*256:(i+1)*256])\n        new = comps.setdefault(chunk, block)\n        mapping[i] = new\n        if new == block:\n            block = block + 1\n            data = data + _mk_bitmap(chunk)\n    header = [block]\n    if _sre.CODESIZE == 2:\n        code = 'H'\n    else:\n        code = 'I'\n    # Convert block indices to byte array of 256 bytes\n    mapping = array.array('b', mapping).tobytes()\n    # Convert byte array to word array\n    mapping = array.array(code, mapping)\n    assert mapping.itemsize == _sre.CODESIZE\n    assert len(mapping) * mapping.itemsize == 256\n    header = header + mapping.tolist()\n    data[0:0] = header\n    return [(BIGCHARSET, data)]\n\ndef _simple(av):\n    # check if av is a \"simple\" operator\n    lo, hi = av[2].getwidth()\n    if lo == 0 and hi == MAXREPEAT:\n        raise error(\"nothing to repeat\")\n    return lo == hi == 1 and av[2][0][0] != SUBPATTERN\n\ndef _compile_info(code, pattern, flags):\n    # internal: compile an info block.  in the current version,\n    # this contains min/max pattern width, and an optional literal\n    # prefix or a character map\n    lo, hi = pattern.getwidth()\n    #print('sre_compile.py:_compile_info:370', lo, hi)\n    if lo == 0:\n        return # not worth it\n    # look for a literal prefix\n    prefix = []\n    prefixappend = prefix.append\n    prefix_skip = 0\n    charset = [] # not used\n    charsetappend = charset.append\n    if not (flags & SRE_FLAG_IGNORECASE):\n        # look for literal prefix\n        for op, av in pattern.data:\n            #print('sre_compile.py:_code:381',op,av)\n            if op is LITERAL:\n                if len(prefix) == prefix_skip:\n                    prefix_skip = prefix_skip + 1\n                prefixappend(av)\n            elif op is SUBPATTERN and len(av[1]) == 1:\n                op, av = av[1][0]\n                if op is LITERAL:\n                    prefixappend(av)\n                else:\n                    break\n            else:\n                break\n        # if no prefix, look for charset prefix\n        if not prefix and pattern.data:\n            op, av = pattern.data[0]\n            if op is SUBPATTERN and av[1]:\n                op, av = av[1][0]\n                if op is LITERAL:\n                    charsetappend((op, av))\n                elif op is BRANCH:\n                    c = []\n                    cappend = c.append\n                    for p in av[1]:\n                        if not p:\n                            break\n                        op, av = p[0]\n                        if op is LITERAL:\n                            cappend((op, av))\n                        else:\n                            break\n                    else:\n                        charset = c\n            elif op is BRANCH:\n                c = []\n                cappend = c.append\n                for p in av[1]:\n                    if not p:\n                        break\n                    op, av = p[0]\n                    if op is LITERAL:\n                        cappend((op, av))\n                    else:\n                        break\n                else:\n                    charset = c\n            elif op is IN:\n                charset = av\n\n    #print('sre_compile.py:_code:430', code)\n##     if prefix:\n##         print \"*** PREFIX\", prefix, prefix_skip\n##     if charset:\n##         print \"*** CHARSET\", charset\n    # add an info block\n    emit = code.append\n    emit(OPCODES[INFO])\n    skip = len(code); emit(0)\n    # literal flag\n    mask = 0\n    if prefix:\n        mask = SRE_INFO_PREFIX\n        if len(prefix) == prefix_skip == len(pattern.data):\n            mask = mask + SRE_INFO_LITERAL\n    elif charset:\n        mask = mask + SRE_INFO_CHARSET\n    emit(mask)\n    # pattern length\n    if lo < MAXCODE:\n        emit(lo)\n    else:\n        emit(MAXCODE)\n        prefix = prefix[:MAXCODE]\n    if hi < MAXCODE:\n        emit(hi)\n    else:\n        emit(0)\n    # add literal prefix\n    #print('sre_compile.py:_code:457', code)\n    if prefix:\n        emit(len(prefix)) # length\n        emit(prefix_skip) # skip\n        code.extend(prefix)\n        # generate overlap table\n        table = [-1] + ([0]*len(prefix))\n        for i in range(len(prefix)):\n            table[i+1] = table[i]+1\n            while table[i+1] > 0 and prefix[i] != prefix[table[i+1]-1]:\n                table[i+1] = table[table[i+1]-1]+1\n        code.extend(table[1:]) # don't store first entry\n    elif charset:\n        _compile_charset(charset, flags, code)\n    code[skip] = len(code) - skip\n\ndef isstring(obj):\n    return isinstance(obj, (str, bytes))\n\ndef _code(p, flags):\n\n    flags = p.pattern.flags | flags\n    code = []\n\n    # compile info block\n    _compile_info(code, p, flags)\n\n    # compile the pattern\n    _compile(code, p.data, flags)\n\n    code.append(OPCODES[SUCCESS])\n\n    return code\n\ndef compile(p, flags=0):\n    # internal: convert pattern list to internal format\n\n    #print(\"sre_compile.py:compile:504:p\", p)\n    if isstring(p):\n        pattern = p\n        p = sre_parse.parse(p, flags)\n    else:\n        pattern = None\n\n    #print('sre_compile.py:498:p', p)\n    code = _code(p, flags)\n\n    #print('sre_compile.py:501:code', code)\n    # print code\n\n    # XXX: <fl> get rid of this limitation!\n    if p.pattern.groups > 100:\n        raise AssertionError(\n            \"sorry, but this version only supports 100 named groups\"\n            )\n\n    # map in either direction\n    groupindex = p.pattern.groupdict\n    indexgroup = [None] * p.pattern.groups\n    for k, i in groupindex.items():\n        indexgroup[i] = k\n\n    return _sre.compile(\n        pattern, flags | p.pattern.flags, code,\n        p.pattern.groups-1,\n        groupindex, indexgroup\n        )\n"], "xml.sax": [".py", "\"\"\"Simple API for XML (SAX) implementation for Python.\n\nThis module provides an implementation of the SAX 2 interface;\ninformation about the Java version of the interface can be found at\nhttp://www.megginson.com/SAX/.  The Python version of the interface is\ndocumented at <...>.\n\nThis package contains the following modules:\n\nhandler -- Base classes and constants which define the SAX 2 API for\n           the 'client-side' of SAX for Python.\n\nsaxutils -- Implementation of the convenience classes commonly used to\n            work with SAX.\n\nxmlreader -- Base classes and constants which define the SAX 2 API for\n             the parsers used with SAX for Python.\n\nexpatreader -- Driver that allows use of the Expat parser with SAX.\n\"\"\"\n\nfrom .xmlreader import InputSource\nfrom .handler import ContentHandler, ErrorHandler\nfrom ._exceptions import SAXException, SAXNotRecognizedException, \\\n                        SAXParseException, SAXNotSupportedException, \\\n                        SAXReaderNotAvailable\n\n\ndef parse(source, handler, errorHandler=ErrorHandler()):\n    parser = make_parser()\n    parser.setContentHandler(handler)\n    parser.setErrorHandler(errorHandler)\n    parser.parse(source)\n\ndef parseString(string, handler, errorHandler=ErrorHandler()):\n    from io import BytesIO\n\n    if errorHandler is None:\n        errorHandler = ErrorHandler()\n    parser = make_parser()\n    parser.setContentHandler(handler)\n    parser.setErrorHandler(errorHandler)\n\n    inpsrc = InputSource()\n    inpsrc.setByteStream(BytesIO(string))\n    parser.parse(inpsrc)\n\n# this is the parser list used by the make_parser function if no\n# alternatives are given as parameters to the function\n\ndefault_parser_list = [\"xml.sax.expatreader\"]\n\n# tell modulefinder that importing sax potentially imports expatreader\n_false = 0\nif _false:\n    import xml.sax.expatreader\n\nimport os, sys\n#if \"PY_SAX_PARSER\" in os.environ:\n#    default_parser_list = os.environ[\"PY_SAX_PARSER\"].split(\",\")\ndel os\n\n_key = \"python.xml.sax.parser\"\nif sys.platform[:4] == \"java\" and sys.registry.containsKey(_key):\n    default_parser_list = sys.registry.getProperty(_key).split(\",\")\n\n\ndef make_parser(parser_list = []):\n    \"\"\"Creates and returns a SAX parser.\n\n    Creates the first parser it is able to instantiate of the ones\n    given in the list created by doing parser_list +\n    default_parser_list.  The lists must contain the names of Python\n    modules containing both a SAX parser and a create_parser function.\"\"\"\n\n    for parser_name in parser_list + default_parser_list:\n        try:\n            return _create_parser(parser_name)\n        except ImportError as e:\n            import sys\n            if parser_name in sys.modules:\n                # The parser module was found, but importing it\n                # failed unexpectedly, pass this exception through\n                raise\n        except SAXReaderNotAvailable:\n            # The parser module detected that it won't work properly,\n            # so try the next one\n            pass\n\n    raise SAXReaderNotAvailable(\"No parsers found\", None)\n\n# --- Internal utility methods used by make_parser\n\nif sys.platform[ : 4] == \"java\":\n    def _create_parser(parser_name):\n        from org.python.core import imp\n        drv_module = imp.importName(parser_name, 0, globals())\n        return drv_module.create_parser()\n\nelse:\n    def _create_parser(parser_name):\n        drv_module = __import__(parser_name,{},{},['create_parser'])\n        return drv_module.create_parser()\n\ndel sys\n", 1], "_random": [".py", "import _os\nfrom os import urandom as _urandom\nclass Random:\n    \"\"\"Random number generator base class used by bound module functions.\n\n    Used to instantiate instances of Random to get generators that don't\n    share state.\n\n    Class Random can also be subclassed if you want to use a different basic\n    generator of your own devising: in that case, override the following\n    methods:  random(), seed(), getstate(), and setstate().\n    Optionally, implement a getrandbits() method so that randrange()\n    can cover arbitrarily large ranges.\n\n    \"\"\"\n    #random\n    #seed\n    #getstate\n    #setstate\n\n\n    VERSION = 3     # used by getstate/setstate\n\n    def __init__(self, x=None):\n        \"\"\"Initialize an instance.\n\n        Optional argument x controls seeding, as for Random.seed().\n        \"\"\"\n\n        self._state=x\n\n    def seed(self, a=None, version=2):\n        \"\"\"Initialize internal state from hashable object.\n\n        None or no argument seeds from current time or from an operating\n        system specific randomness source if available.\n\n        For version 2 (the default), all of the bits are used if *a* is a str,\n        bytes, or bytearray.  For version 1, the hash() of *a* is used instead.\n\n        If *a* is an int, all bits are used.\n\n        \"\"\"\n\n        self._state=a\n        self.gauss_next = None\n\n    def getstate(self):\n        \"\"\"Return internal state; can be passed to setstate() later.\"\"\"\n        return self._state\n\n    def setstate(self, state):\n        \"\"\"Restore internal state from object returned by getstate().\"\"\"\n        self._state=state\n\n    def random(self):\n        \"\"\"Get the next random number in the range [0.0, 1.0).\"\"\"\n        return _os.random()\n\n    def getrandbits(self, k):\n        \"\"\"getrandbits(k) -> x.  Generates a long int with k random bits.\"\"\"\n        if k <= 0:\n            raise ValueError('number of bits must be greater than zero')\n        if k != int(k):\n            raise TypeError('number of bits should be an integer')\n        numbytes = (k + 7) // 8                       # bits / 8 and rounded up\n        x = int.from_bytes(_urandom(numbytes), 'big')\n        return x >> (numbytes * 8 - k)                # trim excess bits\n"], "browser.timer": [".py", "from _timer import *"], "site": [".py", "import sys\n"], "unittest.test.test_result": [".py", "import io\nimport sys\nimport textwrap\n\nfrom test import support\n\nimport traceback\nimport unittest\n\n\nclass Test_TestResult(unittest.TestCase):\n    # Note: there are not separate tests for TestResult.wasSuccessful(),\n    # TestResult.errors, TestResult.failures, TestResult.testsRun or\n    # TestResult.shouldStop because these only have meaning in terms of\n    # other TestResult methods.\n    #\n    # Accordingly, tests for the aforenamed attributes are incorporated\n    # in with the tests for the defining methods.\n    ################################################################\n\n    def test_init(self):\n        result = unittest.TestResult()\n\n        self.assertTrue(result.wasSuccessful())\n        self.assertEqual(len(result.errors), 0)\n        self.assertEqual(len(result.failures), 0)\n        self.assertEqual(result.testsRun, 0)\n        self.assertEqual(result.shouldStop, False)\n        self.assertIsNone(result._stdout_buffer)\n        self.assertIsNone(result._stderr_buffer)\n\n    # \"This method can be called to signal that the set of tests being\n    # run should be aborted by setting the TestResult's shouldStop\n    # attribute to True.\"\n    def test_stop(self):\n        result = unittest.TestResult()\n\n        result.stop()\n\n        self.assertEqual(result.shouldStop, True)\n\n    # \"Called when the test case test is about to be run. The default\n    # implementation simply increments the instance's testsRun counter.\"\n    def test_startTest(self):\n        class Foo(unittest.TestCase):\n            def test_1(self):\n                pass\n\n        test = Foo('test_1')\n\n        result = unittest.TestResult()\n\n        result.startTest(test)\n\n        self.assertTrue(result.wasSuccessful())\n        self.assertEqual(len(result.errors), 0)\n        self.assertEqual(len(result.failures), 0)\n        self.assertEqual(result.testsRun, 1)\n        self.assertEqual(result.shouldStop, False)\n\n        result.stopTest(test)\n\n    # \"Called after the test case test has been executed, regardless of\n    # the outcome. The default implementation does nothing.\"\n    def test_stopTest(self):\n        class Foo(unittest.TestCase):\n            def test_1(self):\n                pass\n\n        test = Foo('test_1')\n\n        result = unittest.TestResult()\n\n        result.startTest(test)\n\n        self.assertTrue(result.wasSuccessful())\n        self.assertEqual(len(result.errors), 0)\n        self.assertEqual(len(result.failures), 0)\n        self.assertEqual(result.testsRun, 1)\n        self.assertEqual(result.shouldStop, False)\n\n        result.stopTest(test)\n\n        # Same tests as above; make sure nothing has changed\n        self.assertTrue(result.wasSuccessful())\n        self.assertEqual(len(result.errors), 0)\n        self.assertEqual(len(result.failures), 0)\n        self.assertEqual(result.testsRun, 1)\n        self.assertEqual(result.shouldStop, False)\n\n    # \"Called before and after tests are run. The default implementation does nothing.\"\n    def test_startTestRun_stopTestRun(self):\n        result = unittest.TestResult()\n        result.startTestRun()\n        result.stopTestRun()\n\n    # \"addSuccess(test)\"\n    # ...\n    # \"Called when the test case test succeeds\"\n    # ...\n    # \"wasSuccessful() - Returns True if all tests run so far have passed,\n    # otherwise returns False\"\n    # ...\n    # \"testsRun - The total number of tests run so far.\"\n    # ...\n    # \"errors - A list containing 2-tuples of TestCase instances and\n    # formatted tracebacks. Each tuple represents a test which raised an\n    # unexpected exception. Contains formatted\n    # tracebacks instead of sys.exc_info() results.\"\n    # ...\n    # \"failures - A list containing 2-tuples of TestCase instances and\n    # formatted tracebacks. Each tuple represents a test where a failure was\n    # explicitly signalled using the TestCase.fail*() or TestCase.assert*()\n    # methods. Contains formatted tracebacks instead\n    # of sys.exc_info() results.\"\n    def test_addSuccess(self):\n        class Foo(unittest.TestCase):\n            def test_1(self):\n                pass\n\n        test = Foo('test_1')\n\n        result = unittest.TestResult()\n\n        result.startTest(test)\n        result.addSuccess(test)\n        result.stopTest(test)\n\n        self.assertTrue(result.wasSuccessful())\n        self.assertEqual(len(result.errors), 0)\n        self.assertEqual(len(result.failures), 0)\n        self.assertEqual(result.testsRun, 1)\n        self.assertEqual(result.shouldStop, False)\n\n    # \"addFailure(test, err)\"\n    # ...\n    # \"Called when the test case test signals a failure. err is a tuple of\n    # the form returned by sys.exc_info(): (type, value, traceback)\"\n    # ...\n    # \"wasSuccessful() - Returns True if all tests run so far have passed,\n    # otherwise returns False\"\n    # ...\n    # \"testsRun - The total number of tests run so far.\"\n    # ...\n    # \"errors - A list containing 2-tuples of TestCase instances and\n    # formatted tracebacks. Each tuple represents a test which raised an\n    # unexpected exception. Contains formatted\n    # tracebacks instead of sys.exc_info() results.\"\n    # ...\n    # \"failures - A list containing 2-tuples of TestCase instances and\n    # formatted tracebacks. Each tuple represents a test where a failure was\n    # explicitly signalled using the TestCase.fail*() or TestCase.assert*()\n    # methods. Contains formatted tracebacks instead\n    # of sys.exc_info() results.\"\n    def test_addFailure(self):\n        class Foo(unittest.TestCase):\n            def test_1(self):\n                pass\n\n        test = Foo('test_1')\n        try:\n            test.fail(\"foo\")\n        except:\n            exc_info_tuple = sys.exc_info()\n\n        result = unittest.TestResult()\n\n        result.startTest(test)\n        result.addFailure(test, exc_info_tuple)\n        result.stopTest(test)\n\n        self.assertFalse(result.wasSuccessful())\n        self.assertEqual(len(result.errors), 0)\n        self.assertEqual(len(result.failures), 1)\n        self.assertEqual(result.testsRun, 1)\n        self.assertEqual(result.shouldStop, False)\n\n        test_case, formatted_exc = result.failures[0]\n        self.assertTrue(test_case is test)\n        self.assertIsInstance(formatted_exc, str)\n\n    # \"addError(test, err)\"\n    # ...\n    # \"Called when the test case test raises an unexpected exception err\n    # is a tuple of the form returned by sys.exc_info():\n    # (type, value, traceback)\"\n    # ...\n    # \"wasSuccessful() - Returns True if all tests run so far have passed,\n    # otherwise returns False\"\n    # ...\n    # \"testsRun - The total number of tests run so far.\"\n    # ...\n    # \"errors - A list containing 2-tuples of TestCase instances and\n    # formatted tracebacks. Each tuple represents a test which raised an\n    # unexpected exception. Contains formatted\n    # tracebacks instead of sys.exc_info() results.\"\n    # ...\n    # \"failures - A list containing 2-tuples of TestCase instances and\n    # formatted tracebacks. Each tuple represents a test where a failure was\n    # explicitly signalled using the TestCase.fail*() or TestCase.assert*()\n    # methods. Contains formatted tracebacks instead\n    # of sys.exc_info() results.\"\n    def test_addError(self):\n        class Foo(unittest.TestCase):\n            def test_1(self):\n                pass\n\n        test = Foo('test_1')\n        try:\n            raise TypeError()\n        except:\n            exc_info_tuple = sys.exc_info()\n\n        result = unittest.TestResult()\n\n        result.startTest(test)\n        result.addError(test, exc_info_tuple)\n        result.stopTest(test)\n\n        self.assertFalse(result.wasSuccessful())\n        self.assertEqual(len(result.errors), 1)\n        self.assertEqual(len(result.failures), 0)\n        self.assertEqual(result.testsRun, 1)\n        self.assertEqual(result.shouldStop, False)\n\n        test_case, formatted_exc = result.errors[0]\n        self.assertTrue(test_case is test)\n        self.assertIsInstance(formatted_exc, str)\n\n    def testGetDescriptionWithoutDocstring(self):\n        result = unittest.TextTestResult(None, True, 1)\n        self.assertEqual(\n                result.getDescription(self),\n                'testGetDescriptionWithoutDocstring (' + __name__ +\n                '.Test_TestResult)')\n\n    @unittest.skipIf(sys.flags.optimize >= 2,\n                     \"Docstrings are omitted with -O2 and above\")\n    def testGetDescriptionWithOneLineDocstring(self):\n        \"\"\"Tests getDescription() for a method with a docstring.\"\"\"\n        result = unittest.TextTestResult(None, True, 1)\n        self.assertEqual(\n                result.getDescription(self),\n               ('testGetDescriptionWithOneLineDocstring '\n                '(' + __name__ + '.Test_TestResult)\\n'\n                'Tests getDescription() for a method with a docstring.'))\n\n    @unittest.skipIf(sys.flags.optimize >= 2,\n                     \"Docstrings are omitted with -O2 and above\")\n    def testGetDescriptionWithMultiLineDocstring(self):\n        \"\"\"Tests getDescription() for a method with a longer docstring.\n        The second line of the docstring.\n        \"\"\"\n        result = unittest.TextTestResult(None, True, 1)\n        self.assertEqual(\n                result.getDescription(self),\n               ('testGetDescriptionWithMultiLineDocstring '\n                '(' + __name__ + '.Test_TestResult)\\n'\n                'Tests getDescription() for a method with a longer '\n                'docstring.'))\n\n    def testStackFrameTrimming(self):\n        class Frame(object):\n            class tb_frame(object):\n                f_globals = {}\n        result = unittest.TestResult()\n        self.assertFalse(result._is_relevant_tb_level(Frame))\n\n        Frame.tb_frame.f_globals['__unittest'] = True\n        self.assertTrue(result._is_relevant_tb_level(Frame))\n\n    def testFailFast(self):\n        result = unittest.TestResult()\n        result._exc_info_to_string = lambda *_: ''\n        result.failfast = True\n        result.addError(None, None)\n        self.assertTrue(result.shouldStop)\n\n        result = unittest.TestResult()\n        result._exc_info_to_string = lambda *_: ''\n        result.failfast = True\n        result.addFailure(None, None)\n        self.assertTrue(result.shouldStop)\n\n        result = unittest.TestResult()\n        result._exc_info_to_string = lambda *_: ''\n        result.failfast = True\n        result.addUnexpectedSuccess(None)\n        self.assertTrue(result.shouldStop)\n\n    def testFailFastSetByRunner(self):\n        runner = unittest.TextTestRunner(stream=io.StringIO(), failfast=True)\n        def test(result):\n            self.assertTrue(result.failfast)\n        result = runner.run(test)\n\n\nclassDict = dict(unittest.TestResult.__dict__)\nfor m in ('addSkip', 'addExpectedFailure', 'addUnexpectedSuccess',\n           '__init__'):\n    del classDict[m]\n\ndef __init__(self, stream=None, descriptions=None, verbosity=None):\n    self.failures = []\n    self.errors = []\n    self.testsRun = 0\n    self.shouldStop = False\n    self.buffer = False\n\nclassDict['__init__'] = __init__\nOldResult = type('OldResult', (object,), classDict)\n\nclass Test_OldTestResult(unittest.TestCase):\n\n    def assertOldResultWarning(self, test, failures):\n        with support.check_warnings((\"TestResult has no add.+ method,\",\n                                     RuntimeWarning)):\n            result = OldResult()\n            test.run(result)\n            self.assertEqual(len(result.failures), failures)\n\n    def testOldTestResult(self):\n        class Test(unittest.TestCase):\n            def testSkip(self):\n                self.skipTest('foobar')\n            @unittest.expectedFailure\n            def testExpectedFail(self):\n                raise TypeError\n            @unittest.expectedFailure\n            def testUnexpectedSuccess(self):\n                pass\n\n        for test_name, should_pass in (('testSkip', True),\n                                       ('testExpectedFail', True),\n                                       ('testUnexpectedSuccess', False)):\n            test = Test(test_name)\n            self.assertOldResultWarning(test, int(not should_pass))\n\n    def testOldTestTesultSetup(self):\n        class Test(unittest.TestCase):\n            def setUp(self):\n                self.skipTest('no reason')\n            def testFoo(self):\n                pass\n        self.assertOldResultWarning(Test('testFoo'), 0)\n\n    def testOldTestResultClass(self):\n        @unittest.skip('no reason')\n        class Test(unittest.TestCase):\n            def testFoo(self):\n                pass\n        self.assertOldResultWarning(Test('testFoo'), 0)\n\n    def testOldResultWithRunner(self):\n        class Test(unittest.TestCase):\n            def testFoo(self):\n                pass\n        runner = unittest.TextTestRunner(resultclass=OldResult,\n                                          stream=io.StringIO())\n        # This will raise an exception if TextTestRunner can't handle old\n        # test result objects\n        runner.run(Test('testFoo'))\n\n\nclass MockTraceback(object):\n    @staticmethod\n    def format_exception(*_):\n        return ['A traceback']\n\ndef restore_traceback():\n    unittest.result.traceback = traceback\n\n\nclass TestOutputBuffering(unittest.TestCase):\n\n    def setUp(self):\n        self._real_out = sys.stdout\n        self._real_err = sys.stderr\n\n    def tearDown(self):\n        sys.stdout = self._real_out\n        sys.stderr = self._real_err\n\n    def testBufferOutputOff(self):\n        real_out = self._real_out\n        real_err = self._real_err\n\n        result = unittest.TestResult()\n        self.assertFalse(result.buffer)\n\n        self.assertIs(real_out, sys.stdout)\n        self.assertIs(real_err, sys.stderr)\n\n        result.startTest(self)\n\n        self.assertIs(real_out, sys.stdout)\n        self.assertIs(real_err, sys.stderr)\n\n    def testBufferOutputStartTestAddSuccess(self):\n        real_out = self._real_out\n        real_err = self._real_err\n\n        result = unittest.TestResult()\n        self.assertFalse(result.buffer)\n\n        result.buffer = True\n\n        self.assertIs(real_out, sys.stdout)\n        self.assertIs(real_err, sys.stderr)\n\n        result.startTest(self)\n\n        self.assertIsNot(real_out, sys.stdout)\n        self.assertIsNot(real_err, sys.stderr)\n        self.assertIsInstance(sys.stdout, io.StringIO)\n        self.assertIsInstance(sys.stderr, io.StringIO)\n        self.assertIsNot(sys.stdout, sys.stderr)\n\n        out_stream = sys.stdout\n        err_stream = sys.stderr\n\n        result._original_stdout = io.StringIO()\n        result._original_stderr = io.StringIO()\n\n        print('foo')\n        print('bar', file=sys.stderr)\n\n        self.assertEqual(out_stream.getvalue(), 'foo\\n')\n        self.assertEqual(err_stream.getvalue(), 'bar\\n')\n\n        self.assertEqual(result._original_stdout.getvalue(), '')\n        self.assertEqual(result._original_stderr.getvalue(), '')\n\n        result.addSuccess(self)\n        result.stopTest(self)\n\n        self.assertIs(sys.stdout, result._original_stdout)\n        self.assertIs(sys.stderr, result._original_stderr)\n\n        self.assertEqual(result._original_stdout.getvalue(), '')\n        self.assertEqual(result._original_stderr.getvalue(), '')\n\n        self.assertEqual(out_stream.getvalue(), '')\n        self.assertEqual(err_stream.getvalue(), '')\n\n\n    def getStartedResult(self):\n        result = unittest.TestResult()\n        result.buffer = True\n        result.startTest(self)\n        return result\n\n    def testBufferOutputAddErrorOrFailure(self):\n        unittest.result.traceback = MockTraceback\n        self.addCleanup(restore_traceback)\n\n        for message_attr, add_attr, include_error in [\n            ('errors', 'addError', True),\n            ('failures', 'addFailure', False),\n            ('errors', 'addError', True),\n            ('failures', 'addFailure', False)\n        ]:\n            result = self.getStartedResult()\n            buffered_out = sys.stdout\n            buffered_err = sys.stderr\n            result._original_stdout = io.StringIO()\n            result._original_stderr = io.StringIO()\n\n            print('foo', file=sys.stdout)\n            if include_error:\n                print('bar', file=sys.stderr)\n\n\n            addFunction = getattr(result, add_attr)\n            addFunction(self, (None, None, None))\n            result.stopTest(self)\n\n            result_list = getattr(result, message_attr)\n            self.assertEqual(len(result_list), 1)\n\n            test, message = result_list[0]\n            expectedOutMessage = textwrap.dedent(\"\"\"\n                Stdout:\n                foo\n            \"\"\")\n            expectedErrMessage = ''\n            if include_error:\n                expectedErrMessage = textwrap.dedent(\"\"\"\n                Stderr:\n                bar\n            \"\"\")\n\n            expectedFullMessage = 'A traceback%s%s' % (expectedOutMessage, expectedErrMessage)\n\n            self.assertIs(test, self)\n            self.assertEqual(result._original_stdout.getvalue(), expectedOutMessage)\n            self.assertEqual(result._original_stderr.getvalue(), expectedErrMessage)\n            self.assertMultiLineEqual(message, expectedFullMessage)\n\n    def testBufferSetupClass(self):\n        result = unittest.TestResult()\n        result.buffer = True\n\n        class Foo(unittest.TestCase):\n            @classmethod\n            def setUpClass(cls):\n                1/0\n            def test_foo(self):\n                pass\n        suite = unittest.TestSuite([Foo('test_foo')])\n        suite(result)\n        self.assertEqual(len(result.errors), 1)\n\n    def testBufferTearDownClass(self):\n        result = unittest.TestResult()\n        result.buffer = True\n\n        class Foo(unittest.TestCase):\n            @classmethod\n            def tearDownClass(cls):\n                1/0\n            def test_foo(self):\n                pass\n        suite = unittest.TestSuite([Foo('test_foo')])\n        suite(result)\n        self.assertEqual(len(result.errors), 1)\n\n    def testBufferSetUpModule(self):\n        result = unittest.TestResult()\n        result.buffer = True\n\n        class Foo(unittest.TestCase):\n            def test_foo(self):\n                pass\n        class Module(object):\n            @staticmethod\n            def setUpModule():\n                1/0\n\n        Foo.__module__ = 'Module'\n        sys.modules['Module'] = Module\n        self.addCleanup(sys.modules.pop, 'Module')\n        suite = unittest.TestSuite([Foo('test_foo')])\n        suite(result)\n        self.assertEqual(len(result.errors), 1)\n\n    def testBufferTearDownModule(self):\n        result = unittest.TestResult()\n        result.buffer = True\n\n        class Foo(unittest.TestCase):\n            def test_foo(self):\n                pass\n        class Module(object):\n            @staticmethod\n            def tearDownModule():\n                1/0\n\n        Foo.__module__ = 'Module'\n        sys.modules['Module'] = Module\n        self.addCleanup(sys.modules.pop, 'Module')\n        suite = unittest.TestSuite([Foo('test_foo')])\n        suite(result)\n        self.assertEqual(len(result.errors), 1)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"], "test.regrtest": [".py", "#! /usr/bin/python3.3\n\n\"\"\"\nUsage:\n\npython -m test [options] [test_name1 [test_name2 ...]]\npython path/to/Lib/test/regrtest.py [options] [test_name1 [test_name2 ...]]\n\n\nIf no arguments or options are provided, finds all files matching\nthe pattern \"test_*\" in the Lib/test subdirectory and runs\nthem in alphabetical order (but see -M and -u, below, for exceptions).\n\nFor more rigorous testing, it is useful to use the following\ncommand line:\n\npython -E -Wd -m test [options] [test_name1 ...]\n\n\nOptions:\n\n-h/--help       -- print this text and exit\n--timeout TIMEOUT\n                -- dump the traceback and exit if a test takes more\n                   than TIMEOUT seconds; disabled if TIMEOUT is negative\n                   or equals to zero\n--wait          -- wait for user input, e.g., allow a debugger to be attached\n\nVerbosity\n\n-v/--verbose    -- run tests in verbose mode with output to stdout\n-w/--verbose2   -- re-run failed tests in verbose mode\n-W/--verbose3   -- display test output on failure\n-d/--debug      -- print traceback for failed tests\n-q/--quiet      -- no output unless one or more tests fail\n-o/--slow       -- print the slowest 10 tests\n   --header     -- print header with interpreter info\n\nSelecting tests\n\n-r/--randomize  -- randomize test execution order (see below)\n   --randseed   -- pass a random seed to reproduce a previous random run\n-f/--fromfile   -- read names of tests to run from a file (see below)\n-x/--exclude    -- arguments are tests to *exclude*\n-s/--single     -- single step through a set of tests (see below)\n-m/--match PAT  -- match test cases and methods with glob pattern PAT\n-G/--failfast   -- fail as soon as a test fails (only with -v or -W)\n-u/--use RES1,RES2,...\n                -- specify which special resource intensive tests to run\n-M/--memlimit LIMIT\n                -- run very large memory-consuming tests\n   --testdir DIR\n                -- execute test files in the specified directory (instead\n                   of the Python stdlib test suite)\n\nSpecial runs\n\n-l/--findleaks  -- if GC is available detect tests that leak memory\n-L/--runleaks   -- run the leaks(1) command just before exit\n-R/--huntrleaks RUNCOUNTS\n                -- search for reference leaks (needs debug build, v. slow)\n-j/--multiprocess PROCESSES\n                -- run PROCESSES processes at once\n-T/--coverage   -- turn on code coverage tracing using the trace module\n-D/--coverdir DIRECTORY\n                -- Directory where coverage files are put\n-N/--nocoverdir -- Put coverage files alongside modules\n-t/--threshold THRESHOLD\n                -- call gc.set_threshold(THRESHOLD)\n-n/--nowindows  -- suppress error message boxes on Windows\n-F/--forever    -- run the specified tests in a loop, until an error happens\n\n\nAdditional Option Details:\n\n-r randomizes test execution order. You can use --randseed=int to provide a\nint seed value for the randomizer; this is useful for reproducing troublesome\ntest orders.\n\n-s On the first invocation of regrtest using -s, the first test file found\nor the first test file given on the command line is run, and the name of\nthe next test is recorded in a file named pynexttest.  If run from the\nPython build directory, pynexttest is located in the 'build' subdirectory,\notherwise it is located in tempfile.gettempdir().  On subsequent runs,\nthe test in pynexttest is run, and the next test is written to pynexttest.\nWhen the last test has been run, pynexttest is deleted.  In this way it\nis possible to single step through the test files.  This is useful when\ndoing memory analysis on the Python interpreter, which process tends to\nconsume too many resources to run the full regression test non-stop.\n\n-S is used to continue running tests after an aborted run.  It will\nmaintain the order a standard run (ie, this assumes -r is not used).\nThis is useful after the tests have prematurely stopped for some external\nreason and you want to start running from where you left off rather\nthan starting from the beginning.\n\n-f reads the names of tests from the file given as f's argument, one\nor more test names per line.  Whitespace is ignored.  Blank lines and\nlines beginning with '#' are ignored.  This is especially useful for\nwhittling down failures involving interactions among tests.\n\n-L causes the leaks(1) command to be run just before exit if it exists.\nleaks(1) is available on Mac OS X and presumably on some other\nFreeBSD-derived systems.\n\n-R runs each test several times and examines sys.gettotalrefcount() to\nsee if the test appears to be leaking references.  The argument should\nbe of the form stab:run:fname where 'stab' is the number of times the\ntest is run to let gettotalrefcount settle down, 'run' is the number\nof times further it is run and 'fname' is the name of the file the\nreports are written to.  These parameters all have defaults (5, 4 and\n\"reflog.txt\" respectively), and the minimal invocation is '-R :'.\n\n-M runs tests that require an exorbitant amount of memory. These tests\ntypically try to ascertain containers keep working when containing more than\n2 billion objects, which only works on 64-bit systems. There are also some\ntests that try to exhaust the address space of the process, which only makes\nsense on 32-bit systems with at least 2Gb of memory. The passed-in memlimit,\nwhich is a string in the form of '2.5Gb', determines howmuch memory the\ntests will limit themselves to (but they may go slightly over.) The number\nshouldn't be more memory than the machine has (including swap memory). You\nshould also keep in mind that swap memory is generally much, much slower\nthan RAM, and setting memlimit to all available RAM or higher will heavily\ntax the machine. On the other hand, it is no use running these tests with a\nlimit of less than 2.5Gb, and many require more than 20Gb. Tests that expect\nto use more than memlimit memory will be skipped. The big-memory tests\ngenerally run very, very long.\n\n-u is used to specify which special resource intensive tests to run,\nsuch as those requiring large file support or network connectivity.\nThe argument is a comma-separated list of words indicating the\nresources to test.  Currently only the following are defined:\n\n    all -       Enable all special resources.\n\n    none -      Disable all special resources (this is the default).\n\n    audio -     Tests that use the audio device.  (There are known\n                cases of broken audio drivers that can crash Python or\n                even the Linux kernel.)\n\n    curses -    Tests that use curses and will modify the terminal's\n                state and output modes.\n\n    largefile - It is okay to run some test that may create huge\n                files.  These tests can take a long time and may\n                consume >2GB of disk space temporarily.\n\n    network -   It is okay to run tests that use external network\n                resource, e.g. testing SSL support for sockets.\n\n    decimal -   Test the decimal module against a large suite that\n                verifies compliance with standards.\n\n    cpu -       Used for certain CPU-heavy tests.\n\n    subprocess  Run all tests for the subprocess module.\n\n    urlfetch -  It is okay to download files required on testing.\n\n    gui -       Run tests that require a running GUI.\n\nTo enable all resources except one, use '-uall,-<resource>'.  For\nexample, to run all the tests except for the gui tests, give the\noption '-uall,-gui'.\n\"\"\"\n\n# We import importlib *ASAP* in order to test #15386\nimport importlib\n\nimport builtins\nimport faulthandler\nimport getopt\nimport io\nimport json\nimport logging\nimport os\nimport platform\nimport random\nimport re\nimport shutil\nimport signal\nimport sys\nimport sysconfig\nimport tempfile\nimport time\nimport traceback\nimport unittest\nimport warnings\nfrom inspect import isabstract\n\ntry:\n    import threading\nexcept ImportError:\n    threading = None\ntry:\n    import multiprocessing.process\nexcept ImportError:\n    multiprocessing = None\n\n\n# Some times __path__ and __file__ are not absolute (e.g. while running from\n# Lib/) and, if we change the CWD to run the tests in a temporary dir, some\n# imports might fail.  This affects only the modules imported before os.chdir().\n# These modules are searched first in sys.path[0] (so '' -- the CWD) and if\n# they are found in the CWD their __file__ and __path__ will be relative (this\n# happens before the chdir).  All the modules imported after the chdir, are\n# not found in the CWD, and since the other paths in sys.path[1:] are absolute\n# (site.py absolutize them), the __file__ and __path__ will be absolute too.\n# Therefore it is necessary to absolutize manually the __file__ and __path__ of\n# the packages to prevent later imports to fail when the CWD is different.\nfor module in sys.modules.values():\n    if hasattr(module, '__path__'):\n        module.__path__ = [os.path.abspath(path) for path in module.__path__]\n    if hasattr(module, '__file__'):\n        module.__file__ = os.path.abspath(module.__file__)\n\n\n# MacOSX (a.k.a. Darwin) has a default stack size that is too small\n# for deeply recursive regular expressions.  We see this as crashes in\n# the Python test suite when running test_re.py and test_sre.py.  The\n# fix is to set the stack limit to 2048.\n# This approach may also be useful for other Unixy platforms that\n# suffer from small default stack limits.\nif sys.platform == 'darwin':\n    try:\n        import resource\n    except ImportError:\n        pass\n    else:\n        soft, hard = resource.getrlimit(resource.RLIMIT_STACK)\n        newsoft = min(hard, max(soft, 1024*2048))\n        resource.setrlimit(resource.RLIMIT_STACK, (newsoft, hard))\n\n# Test result constants.\nPASSED = 1\nFAILED = 0\nENV_CHANGED = -1\nSKIPPED = -2\nRESOURCE_DENIED = -3\nINTERRUPTED = -4\nCHILD_ERROR = -5   # error in a child process\n\nfrom test import support\n\nRESOURCE_NAMES = ('audio', 'curses', 'largefile', 'network',\n                  'decimal', 'cpu', 'subprocess', 'urlfetch', 'gui')\n\nTEMPDIR = os.path.abspath(tempfile.gettempdir())\n\ndef usage(msg):\n    print(msg, file=sys.stderr)\n    print(\"Use --help for usage\", file=sys.stderr)\n    sys.exit(2)\n\n\ndef main(tests=None, testdir=None, verbose=0, quiet=False,\n         exclude=False, single=0, randomize=False, fromfile=None,\n         findleaks=False, use_resources=None, trace=False, coverdir='coverage',\n         runleaks=False, huntrleaks=False, verbose2=False, print_slow=False,\n         random_seed=None, use_mp=None, verbose3=False, forever=False,\n         header=False, failfast=False, match_tests=None):\n    \"\"\"Execute a test suite.\n\n    This also parses command-line options and modifies its behavior\n    accordingly.\n\n    tests -- a list of strings containing test names (optional)\n    testdir -- the directory in which to look for tests (optional)\n\n    Users other than the Python test suite will certainly want to\n    specify testdir; if it's omitted, the directory containing the\n    Python test suite is searched for.\n\n    If the tests argument is omitted, the tests listed on the\n    command-line will be used.  If that's empty, too, then all *.py\n    files beginning with test_ will be used.\n\n    The other default arguments (verbose, quiet, exclude,\n    single, randomize, findleaks, use_resources, trace, coverdir,\n    print_slow, and random_seed) allow programmers calling main()\n    directly to set the values that would normally be set by flags\n    on the command line.\n    \"\"\"\n\n    # Display the Python traceback on fatal errors (e.g. segfault)\n    faulthandler.enable(all_threads=True)\n\n    # Display the Python traceback on SIGALRM or SIGUSR1 signal\n    signals = []\n    if hasattr(signal, 'SIGALRM'):\n        signals.append(signal.SIGALRM)\n    if hasattr(signal, 'SIGUSR1'):\n        signals.append(signal.SIGUSR1)\n    for signum in signals:\n        faulthandler.register(signum, chain=True)\n\n    replace_stdout()\n\n    support.record_original_stdout(sys.stdout)\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], 'hvqxsoS:rf:lu:t:TD:NLR:FdwWM:nj:Gm:',\n            ['help', 'verbose', 'verbose2', 'verbose3', 'quiet',\n             'exclude', 'single', 'slow', 'randomize', 'fromfile=', 'findleaks',\n             'use=', 'threshold=', 'coverdir=', 'nocoverdir',\n             'runleaks', 'huntrleaks=', 'memlimit=', 'randseed=',\n             'multiprocess=', 'coverage', 'slaveargs=', 'forever', 'debug',\n             'start=', 'nowindows', 'header', 'testdir=', 'timeout=', 'wait',\n             'failfast', 'match=', 'next='])\n    except getopt.error as msg:\n        usage(msg)\n\n    # Defaults\n    if random_seed is None:\n        random_seed = random.randrange(10000000)\n    if use_resources is None:\n        use_resources = []\n    debug = False\n    start = None\n    timeout = None\n    for o, a in opts:\n        if o in ('-h', '--help'):\n            print(__doc__)\n            return\n        elif o in ('-v', '--verbose'):\n            verbose += 1\n        elif o in ('-w', '--verbose2'):\n            verbose2 = True\n        elif o in ('-d', '--debug'):\n            debug = True\n        elif o in ('-W', '--verbose3'):\n            verbose3 = True\n        elif o in ('-G', '--failfast'):\n            failfast = True\n        elif o in ('-q', '--quiet'):\n            quiet = True;\n            verbose = 0\n        elif o in ('-x', '--exclude'):\n            exclude = True\n        elif o in ('-S', '--start'):\n            start = a\n        elif o in ('-s', '--single'):\n            single = 1\n        elif o == '--next':\n            single = int(a)\n        elif o in ('-o', '--slow'):\n            print_slow = True\n        elif o in ('-r', '--randomize'):\n            randomize = True\n        elif o == '--randseed':\n            random_seed = int(a)\n        elif o in ('-f', '--fromfile'):\n            fromfile = a\n        elif o in ('-m', '--match'):\n            match_tests = a\n        elif o in ('-l', '--findleaks'):\n            findleaks = True\n        elif o in ('-L', '--runleaks'):\n            runleaks = True\n        elif o in ('-t', '--threshold'):\n            import gc\n            gc.set_threshold(int(a))\n        elif o in ('-T', '--coverage'):\n            trace = True\n        elif o in ('-D', '--coverdir'):\n            # CWD is replaced with a temporary dir before calling main(), so we\n            # need  join it with the saved CWD so it goes where the user expects.\n            coverdir = os.path.join(support.SAVEDCWD, a)\n        elif o in ('-N', '--nocoverdir'):\n            coverdir = None\n        elif o in ('-R', '--huntrleaks'):\n            huntrleaks = a.split(':')\n            if len(huntrleaks) not in (2, 3):\n                print(a, huntrleaks)\n                usage('-R takes 2 or 3 colon-separated arguments')\n            if not huntrleaks[0]:\n                huntrleaks[0] = 5\n            else:\n                huntrleaks[0] = int(huntrleaks[0])\n            if not huntrleaks[1]:\n                huntrleaks[1] = 4\n            else:\n                huntrleaks[1] = int(huntrleaks[1])\n            if len(huntrleaks) == 2 or not huntrleaks[2]:\n                huntrleaks[2:] = [\"reflog.txt\"]\n            # Avoid false positives due to various caches\n            # filling slowly with random data:\n            warm_caches()\n        elif o in ('-M', '--memlimit'):\n            support.set_memlimit(a)\n        elif o in ('-u', '--use'):\n            u = [x.lower() for x in a.split(',')]\n            for r in u:\n                if r == 'all':\n                    use_resources[:] = RESOURCE_NAMES\n                    continue\n                if r == 'none':\n                    del use_resources[:]\n                    continue\n                remove = False\n                if r[0] == '-':\n                    remove = True\n                    r = r[1:]\n                if r not in RESOURCE_NAMES:\n                    usage('Invalid -u/--use option: ' + a)\n                if remove:\n                    if r in use_resources:\n                        use_resources.remove(r)\n                elif r not in use_resources:\n                    use_resources.append(r)\n        elif o in ('-n', '--nowindows'):\n            import msvcrt\n            msvcrt.SetErrorMode(msvcrt.SEM_FAILCRITICALERRORS|\n                    msvcrt.SEM_NOALIGNMENTFAULTEXCEPT|\n                    msvcrt.SEM_NOGPFAULTERRORBOX|\n                    msvcrt.SEM_NOOPENFILEERRORBOX)\n            try:\n                msvcrt.CrtSetReportMode\n            except AttributeError:\n                # release build\n                pass\n            else:\n                for m in [msvcrt.CRT_WARN, msvcrt.CRT_ERROR, msvcrt.CRT_ASSERT]:\n                    msvcrt.CrtSetReportMode(m, msvcrt.CRTDBG_MODE_FILE)\n                    msvcrt.CrtSetReportFile(m, msvcrt.CRTDBG_FILE_STDERR)\n        elif o in ('-F', '--forever'):\n            forever = True\n        elif o in ('-j', '--multiprocess'):\n            use_mp = int(a)\n            if use_mp <= 0:\n                try:\n                    import multiprocessing\n                    # Use all cores + extras for tests that like to sleep\n                    use_mp = 2 + multiprocessing.cpu_count()\n                except (ImportError, NotImplementedError):\n                    use_mp = 3\n            if use_mp == 1:\n                use_mp = None\n        elif o == '--header':\n            header = True\n        elif o == '--slaveargs':\n            args, kwargs = json.loads(a)\n            try:\n                result = runtest(*args, **kwargs)\n            except KeyboardInterrupt:\n                result = INTERRUPTED, ''\n            except BaseException as e:\n                traceback.print_exc()\n                result = CHILD_ERROR, str(e)\n            sys.stdout.flush()\n            print()   # Force a newline (just in case)\n            print(json.dumps(result))\n            sys.exit(0)\n        elif o == '--testdir':\n            # CWD is replaced with a temporary dir before calling main(), so we\n            # join it with the saved CWD so it ends up where the user expects.\n            testdir = os.path.join(support.SAVEDCWD, a)\n        elif o == '--timeout':\n            if hasattr(faulthandler, 'dump_tracebacks_later'):\n                timeout = float(a)\n                if timeout <= 0:\n                    timeout = None\n            else:\n                print(\"Warning: The timeout option requires \"\n                      \"faulthandler.dump_tracebacks_later\")\n                timeout = None\n        elif o == '--wait':\n            input(\"Press any key to continue...\")\n        else:\n            print((\"No handler for option {}.  Please report this as a bug \"\n                   \"at http://bugs.python.org.\").format(o), file=sys.stderr)\n            sys.exit(1)\n    if single and fromfile:\n        usage(\"-s and -f don't go together!\")\n    if use_mp and trace:\n        usage(\"-T and -j don't go together!\")\n    if use_mp and findleaks:\n        usage(\"-l and -j don't go together!\")\n    if use_mp and support.max_memuse:\n        usage(\"-M and -j don't go together!\")\n    if failfast and not (verbose or verbose3):\n        usage(\"-G/--failfast needs either -v or -W\")\n\n    good = []\n    bad = []\n    skipped = []\n    resource_denieds = []\n    environment_changed = []\n    interrupted = False\n\n    if findleaks:\n        try:\n            import gc\n        except ImportError:\n            print('No GC available, disabling findleaks.')\n            findleaks = False\n        else:\n            # Uncomment the line below to report garbage that is not\n            # freeable by reference counting alone.  By default only\n            # garbage that is not collectable by the GC is reported.\n            #gc.set_debug(gc.DEBUG_SAVEALL)\n            found_garbage = []\n\n    if single:\n        filename = os.path.join(TEMPDIR, 'pynexttest')\n        try:\n            fp = open(filename, 'r')\n            next_test = fp.read().strip()\n            tests = [next_test]\n            fp.close()\n        except IOError:\n            pass\n\n    if fromfile:\n        tests = []\n        fp = open(os.path.join(support.SAVEDCWD, fromfile))\n        count_pat = re.compile(r'\\[\\s*\\d+/\\s*\\d+\\]')\n        for line in fp:\n            line = count_pat.sub('', line)\n            guts = line.split() # assuming no test has whitespace in its name\n            if guts and not guts[0].startswith('#'):\n                tests.extend(guts)\n        fp.close()\n\n    # Strip .py extensions.\n    removepy(args)\n    removepy(tests)\n\n    stdtests = STDTESTS[:]\n    nottests = NOTTESTS.copy()\n    if exclude:\n        for arg in args:\n            if arg in stdtests:\n                stdtests.remove(arg)\n            nottests.add(arg)\n        args = []\n\n    # For a partial run, we do not need to clutter the output.\n    if verbose or header or not (quiet or single != 1 or tests or args):\n        # Print basic platform information\n        print(\"==\", platform.python_implementation(), *sys.version.split())\n        print(\"==  \", platform.platform(aliased=True),\n                      \"%s-endian\" % sys.byteorder)\n        print(\"==  \", os.getcwd())\n        print(\"Testing with flags:\", sys.flags)\n\n    # if testdir is set, then we are not running the python tests suite, so\n    # don't add default tests to be executed or skipped (pass empty values)\n    if testdir:\n        alltests = findtests(testdir, list(), set())\n    else:\n        alltests = findtests(testdir, stdtests, nottests)\n\n    selected = tests or args or alltests\n    if single:\n        first_selected = selected[0]\n        index_selected = alltests.index(first_selected)\n        if index_selected + single > len(alltests):\n            single = len(alltests) - index_selected\n        selected = alltests[index_selected:index_selected+single]\n        try:\n            next_single_test = alltests[index_selected+single]\n        except IndexError:\n            next_single_test = None\n    # Remove all the selected tests that precede start if it's set.\n    if start:\n        try:\n            del selected[:selected.index(start)]\n        except ValueError:\n            print(\"Couldn't find starting test (%s), using all tests\" % start)\n    if randomize:\n        random.seed(random_seed)\n        print(\"Using random seed\", random_seed)\n        random.shuffle(selected)\n    if trace:\n        import trace, tempfile\n        tracer = trace.Trace(ignoredirs=[sys.base_prefix, sys.base_exec_prefix,\n                                         tempfile.gettempdir()],\n                             trace=False, count=True)\n\n    test_times = []\n    support.verbose = verbose      # Tell tests to be moderately quiet\n    support.use_resources = use_resources\n    save_modules = sys.modules.keys()\n\n    def accumulate_result(test, result):\n        ok, test_time = result\n        test_times.append((test_time, test))\n        if ok == PASSED:\n            good.append(test)\n        elif ok == FAILED:\n            bad.append(test)\n        elif ok == ENV_CHANGED:\n            environment_changed.append(test)\n        elif ok == SKIPPED:\n            skipped.append(test)\n        elif ok == RESOURCE_DENIED:\n            skipped.append(test)\n            resource_denieds.append(test)\n\n    if forever:\n        def test_forever(tests=list(selected)):\n            while True:\n                for test in tests:\n                    yield test\n                    if bad:\n                        return\n        tests = test_forever()\n        test_count = ''\n        test_count_width = 3\n    else:\n        tests = iter(selected)\n        test_count = '/{}'.format(len(selected))\n        test_count_width = len(test_count) - 1\n\n    if use_mp:\n        try:\n            from threading import Thread\n        except ImportError:\n            print(\"Multiprocess option requires thread support\")\n            sys.exit(2)\n        from queue import Queue\n        from subprocess import Popen, PIPE\n        debug_output_pat = re.compile(r\"\\[\\d+ refs\\]$\")\n        output = Queue()\n        pending = MultiprocessTests(tests)\n        opt_args = support.args_from_interpreter_flags()\n        base_cmd = [sys.executable] + opt_args + ['-m', 'test.regrtest']\n        def work():\n            # A worker thread.\n            try:\n                while True:\n                    try:\n                        test = next(pending)\n                    except StopIteration:\n                        output.put((None, None, None, None))\n                        return\n                    args_tuple = (\n                        (test, verbose, quiet),\n                        dict(huntrleaks=huntrleaks, use_resources=use_resources,\n                             debug=debug, output_on_failure=verbose3,\n                             timeout=timeout, failfast=failfast,\n                             match_tests=match_tests)\n                    )\n                    # -E is needed by some tests, e.g. test_import\n                    # Running the child from the same working directory ensures\n                    # that TEMPDIR for the child is the same when\n                    # sysconfig.is_python_build() is true. See issue 15300.\n                    popen = Popen(base_cmd + ['--slaveargs', json.dumps(args_tuple)],\n                                   stdout=PIPE, stderr=PIPE,\n                                   universal_newlines=True,\n                                   close_fds=(os.name != 'nt'),\n                                   cwd=support.SAVEDCWD)\n                    stdout, stderr = popen.communicate()\n                    retcode = popen.wait()\n                    # Strip last refcount output line if it exists, since it\n                    # comes from the shutdown of the interpreter in the subcommand.\n                    stderr = debug_output_pat.sub(\"\", stderr)\n                    stdout, _, result = stdout.strip().rpartition(\"\\n\")\n                    if retcode != 0:\n                        result = (CHILD_ERROR, \"Exit code %s\" % retcode)\n                        output.put((test, stdout.rstrip(), stderr.rstrip(), result))\n                        return\n                    if not result:\n                        output.put((None, None, None, None))\n                        return\n                    result = json.loads(result)\n                    output.put((test, stdout.rstrip(), stderr.rstrip(), result))\n            except BaseException:\n                output.put((None, None, None, None))\n                raise\n        workers = [Thread(target=work) for i in range(use_mp)]\n        for worker in workers:\n            worker.start()\n        finished = 0\n        test_index = 1\n        try:\n            while finished < use_mp:\n                test, stdout, stderr, result = output.get()\n                if test is None:\n                    finished += 1\n                    continue\n                accumulate_result(test, result)\n                if not quiet:\n                    fmt = \"[{1:{0}}{2}/{3}] {4}\" if bad else \"[{1:{0}}{2}] {4}\"\n                    print(fmt.format(\n                        test_count_width, test_index, test_count,\n                        len(bad), test))\n                if stdout:\n                    print(stdout)\n                if stderr:\n                    print(stderr, file=sys.stderr)\n                sys.stdout.flush()\n                sys.stderr.flush()\n                if result[0] == INTERRUPTED:\n                    raise KeyboardInterrupt\n                if result[0] == CHILD_ERROR:\n                    raise Exception(\"Child error on {}: {}\".format(test, result[1]))\n                test_index += 1\n        except KeyboardInterrupt:\n            interrupted = True\n            pending.interrupted = True\n        for worker in workers:\n            worker.join()\n    else:\n        for test_index, test in enumerate(tests, 1):\n            if not quiet:\n                fmt = \"[{1:{0}}{2}/{3}] {4}\" if bad else \"[{1:{0}}{2}] {4}\"\n                print(fmt.format(\n                    test_count_width, test_index, test_count, len(bad), test))\n                sys.stdout.flush()\n            if trace:\n                # If we're tracing code coverage, then we don't exit with status\n                # if on a false return value from main.\n                tracer.runctx('runtest(test, verbose, quiet, timeout=timeout)',\n                              globals=globals(), locals=vars())\n            else:\n                try:\n                    result = runtest(test, verbose, quiet, huntrleaks, debug,\n                                     output_on_failure=verbose3,\n                                     timeout=timeout, failfast=failfast,\n                                     match_tests=match_tests)\n                    accumulate_result(test, result)\n                except KeyboardInterrupt:\n                    interrupted = True\n                    break\n                except:\n                    raise\n            if findleaks:\n                gc.collect()\n                if gc.garbage:\n                    print(\"Warning: test created\", len(gc.garbage), end=' ')\n                    print(\"uncollectable object(s).\")\n                    # move the uncollectable objects somewhere so we don't see\n                    # them again\n                    found_garbage.extend(gc.garbage)\n                    del gc.garbage[:]\n            # Unload the newly imported modules (best effort finalization)\n            for module in sys.modules.keys():\n                if module not in save_modules and module.startswith(\"test.\"):\n                    support.unload(module)\n\n    if interrupted:\n        # print a newline after ^C\n        print()\n        print(\"Test suite interrupted by signal SIGINT.\")\n        omitted = set(selected) - set(good) - set(bad) - set(skipped)\n        print(count(len(omitted), \"test\"), \"omitted:\")\n        printlist(omitted)\n    if good and not quiet:\n        if not bad and not skipped and not interrupted and len(good) > 1:\n            print(\"All\", end=' ')\n        print(count(len(good), \"test\"), \"OK.\")\n    if print_slow:\n        test_times.sort(reverse=True)\n        print(\"10 slowest tests:\")\n        for time, test in test_times[:10]:\n            print(\"%s: %.1fs\" % (test, time))\n    if bad:\n        bad = sorted(set(bad) - set(environment_changed))\n        if bad:\n            print(count(len(bad), \"test\"), \"failed:\")\n            printlist(bad)\n    if environment_changed:\n        print(\"{} altered the execution environment:\".format(\n                 count(len(environment_changed), \"test\")))\n        printlist(environment_changed)\n    if skipped and not quiet:\n        print(count(len(skipped), \"test\"), \"skipped:\")\n        printlist(skipped)\n\n        e = _ExpectedSkips()\n        plat = sys.platform\n        if e.isvalid():\n            surprise = set(skipped) - e.getexpected() - set(resource_denieds)\n            if surprise:\n                print(count(len(surprise), \"skip\"), \\\n                      \"unexpected on\", plat + \":\")\n                printlist(surprise)\n            else:\n                print(\"Those skips are all expected on\", plat + \".\")\n        else:\n            print(\"Ask someone to teach regrtest.py about which tests are\")\n            print(\"expected to get skipped on\", plat + \".\")\n\n    if verbose2 and bad:\n        print(\"Re-running failed tests in verbose mode\")\n        for test in bad:\n            print(\"Re-running test %r in verbose mode\" % test)\n            sys.stdout.flush()\n            try:\n                verbose = True\n                ok = runtest(test, True, quiet, huntrleaks, debug, timeout=timeout)\n            except KeyboardInterrupt:\n                # print a newline separate from the ^C\n                print()\n                break\n            except:\n                raise\n\n    if single:\n        if next_single_test:\n            with open(filename, 'w') as fp:\n                fp.write(next_single_test + '\\n')\n        else:\n            os.unlink(filename)\n\n    if trace:\n        r = tracer.results()\n        r.write_results(show_missing=True, summary=True, coverdir=coverdir)\n\n    if runleaks:\n        os.system(\"leaks %d\" % os.getpid())\n\n    sys.exit(len(bad) > 0 or interrupted)\n\n\n# small set of tests to determine if we have a basically functioning interpreter\n# (i.e. if any of these fail, then anything else is likely to follow)\nSTDTESTS = [\n    'test_grammar',\n    'test_opcodes',\n    'test_dict',\n    'test_builtin',\n    'test_exceptions',\n    'test_types',\n    'test_unittest',\n    'test_doctest',\n    'test_doctest2',\n    'test_support'\n]\n\n# set of tests that we don't want to be executed when using regrtest\nNOTTESTS = set()\n\ndef findtests(testdir=None, stdtests=STDTESTS, nottests=NOTTESTS):\n    \"\"\"Return a list of all applicable test modules.\"\"\"\n    testdir = findtestdir(testdir)\n    names = os.listdir(testdir)\n    tests = []\n    others = set(stdtests) | nottests\n    for name in names:\n        mod, ext = os.path.splitext(name)\n        if mod[:5] == \"test_\" and ext in (\".py\", \"\") and mod not in others:\n            tests.append(mod)\n    return stdtests + sorted(tests)\n\n# We do not use a generator so multiple threads can call next().\nclass MultiprocessTests(object):\n\n    \"\"\"A thread-safe iterator over tests for multiprocess mode.\"\"\"\n\n    def __init__(self, tests):\n        self.interrupted = False\n        self.lock = threading.Lock()\n        self.tests = tests\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        with self.lock:\n            if self.interrupted:\n                raise StopIteration('tests interrupted')\n            return next(self.tests)\n\ndef replace_stdout():\n    \"\"\"Set stdout encoder error handler to backslashreplace (as stderr error\n    handler) to avoid UnicodeEncodeError when printing a traceback\"\"\"\n    import atexit\n\n    stdout = sys.stdout\n    sys.stdout = open(stdout.fileno(), 'w',\n        encoding=stdout.encoding,\n        errors=\"backslashreplace\",\n        closefd=False,\n        newline='\\n')\n\n    def restore_stdout():\n        sys.stdout.close()\n        sys.stdout = stdout\n    atexit.register(restore_stdout)\n\ndef runtest(test, verbose, quiet,\n            huntrleaks=False, debug=False, use_resources=None,\n            output_on_failure=False, failfast=False, match_tests=None,\n            timeout=None):\n    \"\"\"Run a single test.\n\n    test -- the name of the test\n    verbose -- if true, print more messages\n    quiet -- if true, don't print 'skipped' messages (probably redundant)\n    test_times -- a list of (time, test_name) pairs\n    huntrleaks -- run multiple times to test for leaks; requires a debug\n                  build; a triple corresponding to -R's three arguments\n    output_on_failure -- if true, display test output on failure\n    timeout -- dump the traceback and exit if a test takes more than\n               timeout seconds\n\n    Returns one of the test result constants:\n        INTERRUPTED      KeyboardInterrupt when run under -j\n        RESOURCE_DENIED  test skipped because resource denied\n        SKIPPED          test skipped for some other reason\n        ENV_CHANGED      test failed because it changed the execution environment\n        FAILED           test failed\n        PASSED           test passed\n    \"\"\"\n\n    if use_resources is not None:\n        support.use_resources = use_resources\n    use_timeout = (timeout is not None)\n    if use_timeout:\n        faulthandler.dump_tracebacks_later(timeout, exit=True)\n    try:\n        support.match_tests = match_tests\n        if failfast:\n            support.failfast = True\n        if output_on_failure:\n            support.verbose = True\n\n            # Reuse the same instance to all calls to runtest(). Some\n            # tests keep a reference to sys.stdout or sys.stderr\n            # (eg. test_argparse).\n            if runtest.stringio is None:\n                stream = io.StringIO()\n                runtest.stringio = stream\n            else:\n                stream = runtest.stringio\n                stream.seek(0)\n                stream.truncate()\n\n            orig_stdout = sys.stdout\n            orig_stderr = sys.stderr\n            try:\n                sys.stdout = stream\n                sys.stderr = stream\n                result = runtest_inner(test, verbose, quiet, huntrleaks,\n                                       debug, display_failure=False)\n                if result[0] == FAILED:\n                    output = stream.getvalue()\n                    orig_stderr.write(output)\n                    orig_stderr.flush()\n            finally:\n                sys.stdout = orig_stdout\n                sys.stderr = orig_stderr\n        else:\n            support.verbose = verbose  # Tell tests to be moderately quiet\n            result = runtest_inner(test, verbose, quiet, huntrleaks, debug,\n                                   display_failure=not verbose)\n        return result\n    finally:\n        if use_timeout:\n            faulthandler.cancel_dump_tracebacks_later()\n        cleanup_test_droppings(test, verbose)\nruntest.stringio = None\n\n# Unit tests are supposed to leave the execution environment unchanged\n# once they complete.  But sometimes tests have bugs, especially when\n# tests fail, and the changes to environment go on to mess up other\n# tests.  This can cause issues with buildbot stability, since tests\n# are run in random order and so problems may appear to come and go.\n# There are a few things we can save and restore to mitigate this, and\n# the following context manager handles this task.\n\nclass saved_test_environment:\n    \"\"\"Save bits of the test environment and restore them at block exit.\n\n        with saved_test_environment(testname, verbose, quiet):\n            #stuff\n\n    Unless quiet is True, a warning is printed to stderr if any of\n    the saved items was changed by the test.  The attribute 'changed'\n    is initially False, but is set to True if a change is detected.\n\n    If verbose is more than 1, the before and after state of changed\n    items is also printed.\n    \"\"\"\n\n    changed = False\n\n    def __init__(self, testname, verbose=0, quiet=False):\n        self.testname = testname\n        self.verbose = verbose\n        self.quiet = quiet\n\n    # To add things to save and restore, add a name XXX to the resources list\n    # and add corresponding get_XXX/restore_XXX functions.  get_XXX should\n    # return the value to be saved and compared against a second call to the\n    # get function when test execution completes.  restore_XXX should accept\n    # the saved value and restore the resource using it.  It will be called if\n    # and only if a change in the value is detected.\n    #\n    # Note: XXX will have any '.' replaced with '_' characters when determining\n    # the corresponding method names.\n\n    resources = ('sys.argv', 'cwd', 'sys.stdin', 'sys.stdout', 'sys.stderr',\n                 'os.environ', 'sys.path', 'sys.path_hooks', '__import__',\n                 'warnings.filters', 'asyncore.socket_map',\n                 'logging._handlers', 'logging._handlerList', 'sys.gettrace',\n                 'sys.warnoptions', 'threading._dangling',\n                 'multiprocessing.process._dangling',\n                 'sysconfig._CONFIG_VARS', 'sysconfig._INSTALL_SCHEMES',\n                 'support.TESTFN',\n                )\n\n    def get_sys_argv(self):\n        return id(sys.argv), sys.argv, sys.argv[:]\n    def restore_sys_argv(self, saved_argv):\n        sys.argv = saved_argv[1]\n        sys.argv[:] = saved_argv[2]\n\n    def get_cwd(self):\n        return os.getcwd()\n    def restore_cwd(self, saved_cwd):\n        os.chdir(saved_cwd)\n\n    def get_sys_stdout(self):\n        return sys.stdout\n    def restore_sys_stdout(self, saved_stdout):\n        sys.stdout = saved_stdout\n\n    def get_sys_stderr(self):\n        return sys.stderr\n    def restore_sys_stderr(self, saved_stderr):\n        sys.stderr = saved_stderr\n\n    def get_sys_stdin(self):\n        return sys.stdin\n    def restore_sys_stdin(self, saved_stdin):\n        sys.stdin = saved_stdin\n\n    def get_os_environ(self):\n        return id(os.environ), os.environ, dict(os.environ)\n    def restore_os_environ(self, saved_environ):\n        os.environ = saved_environ[1]\n        os.environ.clear()\n        os.environ.update(saved_environ[2])\n\n    def get_sys_path(self):\n        return id(sys.path), sys.path, sys.path[:]\n    def restore_sys_path(self, saved_path):\n        sys.path = saved_path[1]\n        sys.path[:] = saved_path[2]\n\n    def get_sys_path_hooks(self):\n        return id(sys.path_hooks), sys.path_hooks, sys.path_hooks[:]\n    def restore_sys_path_hooks(self, saved_hooks):\n        sys.path_hooks = saved_hooks[1]\n        sys.path_hooks[:] = saved_hooks[2]\n\n    def get_sys_gettrace(self):\n        return sys.gettrace()\n    def restore_sys_gettrace(self, trace_fxn):\n        sys.settrace(trace_fxn)\n\n    def get___import__(self):\n        return builtins.__import__\n    def restore___import__(self, import_):\n        builtins.__import__ = import_\n\n    def get_warnings_filters(self):\n        return id(warnings.filters), warnings.filters, warnings.filters[:]\n    def restore_warnings_filters(self, saved_filters):\n        warnings.filters = saved_filters[1]\n        warnings.filters[:] = saved_filters[2]\n\n    def get_asyncore_socket_map(self):\n        asyncore = sys.modules.get('asyncore')\n        # XXX Making a copy keeps objects alive until __exit__ gets called.\n        return asyncore and asyncore.socket_map.copy() or {}\n    def restore_asyncore_socket_map(self, saved_map):\n        asyncore = sys.modules.get('asyncore')\n        if asyncore is not None:\n            asyncore.close_all(ignore_all=True)\n            asyncore.socket_map.update(saved_map)\n\n    def get_shutil_archive_formats(self):\n        # we could call get_archives_formats() but that only returns the\n        # registry keys; we want to check the values too (the functions that\n        # are registered)\n        return shutil._ARCHIVE_FORMATS, shutil._ARCHIVE_FORMATS.copy()\n    def restore_shutil_archive_formats(self, saved):\n        shutil._ARCHIVE_FORMATS = saved[0]\n        shutil._ARCHIVE_FORMATS.clear()\n        shutil._ARCHIVE_FORMATS.update(saved[1])\n\n    def get_shutil_unpack_formats(self):\n        return shutil._UNPACK_FORMATS, shutil._UNPACK_FORMATS.copy()\n    def restore_shutil_unpack_formats(self, saved):\n        shutil._UNPACK_FORMATS = saved[0]\n        shutil._UNPACK_FORMATS.clear()\n        shutil._UNPACK_FORMATS.update(saved[1])\n\n    def get_logging__handlers(self):\n        # _handlers is a WeakValueDictionary\n        return id(logging._handlers), logging._handlers, logging._handlers.copy()\n    def restore_logging__handlers(self, saved_handlers):\n        # Can't easily revert the logging state\n        pass\n\n    def get_logging__handlerList(self):\n        # _handlerList is a list of weakrefs to handlers\n        return id(logging._handlerList), logging._handlerList, logging._handlerList[:]\n    def restore_logging__handlerList(self, saved_handlerList):\n        # Can't easily revert the logging state\n        pass\n\n    def get_sys_warnoptions(self):\n        return id(sys.warnoptions), sys.warnoptions, sys.warnoptions[:]\n    def restore_sys_warnoptions(self, saved_options):\n        sys.warnoptions = saved_options[1]\n        sys.warnoptions[:] = saved_options[2]\n\n    # Controlling dangling references to Thread objects can make it easier\n    # to track reference leaks.\n    def get_threading__dangling(self):\n        if not threading:\n            return None\n        # This copies the weakrefs without making any strong reference\n        return threading._dangling.copy()\n    def restore_threading__dangling(self, saved):\n        if not threading:\n            return\n        threading._dangling.clear()\n        threading._dangling.update(saved)\n\n    # Same for Process objects\n    def get_multiprocessing_process__dangling(self):\n        if not multiprocessing:\n            return None\n        # This copies the weakrefs without making any strong reference\n        return multiprocessing.process._dangling.copy()\n    def restore_multiprocessing_process__dangling(self, saved):\n        if not multiprocessing:\n            return\n        multiprocessing.process._dangling.clear()\n        multiprocessing.process._dangling.update(saved)\n\n    def get_sysconfig__CONFIG_VARS(self):\n        # make sure the dict is initialized\n        sysconfig.get_config_var('prefix')\n        return (id(sysconfig._CONFIG_VARS), sysconfig._CONFIG_VARS,\n                dict(sysconfig._CONFIG_VARS))\n    def restore_sysconfig__CONFIG_VARS(self, saved):\n        sysconfig._CONFIG_VARS = saved[1]\n        sysconfig._CONFIG_VARS.clear()\n        sysconfig._CONFIG_VARS.update(saved[2])\n\n    def get_sysconfig__INSTALL_SCHEMES(self):\n        return (id(sysconfig._INSTALL_SCHEMES), sysconfig._INSTALL_SCHEMES,\n                sysconfig._INSTALL_SCHEMES.copy())\n    def restore_sysconfig__INSTALL_SCHEMES(self, saved):\n        sysconfig._INSTALL_SCHEMES = saved[1]\n        sysconfig._INSTALL_SCHEMES.clear()\n        sysconfig._INSTALL_SCHEMES.update(saved[2])\n\n    def get_support_TESTFN(self):\n        if os.path.isfile(support.TESTFN):\n            result = 'f'\n        elif os.path.isdir(support.TESTFN):\n            result = 'd'\n        else:\n            result = None\n        return result\n    def restore_support_TESTFN(self, saved_value):\n        if saved_value is None:\n            if os.path.isfile(support.TESTFN):\n                os.unlink(support.TESTFN)\n            elif os.path.isdir(support.TESTFN):\n                shutil.rmtree(support.TESTFN)\n\n    def resource_info(self):\n        for name in self.resources:\n            method_suffix = name.replace('.', '_')\n            get_name = 'get_' + method_suffix\n            restore_name = 'restore_' + method_suffix\n            yield name, getattr(self, get_name), getattr(self, restore_name)\n\n    def __enter__(self):\n        self.saved_values = dict((name, get()) for name, get, restore\n                                                   in self.resource_info())\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        saved_values = self.saved_values\n        del self.saved_values\n        for name, get, restore in self.resource_info():\n            current = get()\n            original = saved_values.pop(name)\n            # Check for changes to the resource's value\n            if current != original:\n                self.changed = True\n                restore(original)\n                if not self.quiet:\n                    print(\"Warning -- {} was modified by {}\".format(\n                                                 name, self.testname),\n                                                 file=sys.stderr)\n                    if self.verbose > 1:\n                        print(\"  Before: {}\\n  After:  {} \".format(\n                                                  original, current),\n                                                  file=sys.stderr)\n        return False\n\n\ndef runtest_inner(test, verbose, quiet,\n                  huntrleaks=False, debug=False, display_failure=True):\n    support.unload(test)\n\n    test_time = 0.0\n    refleak = False  # True if the test leaked references.\n    try:\n        if test.startswith('test.'):\n            abstest = test\n        else:\n            # Always import it from the test package\n            abstest = 'test.' + test\n        with saved_test_environment(test, verbose, quiet) as environment:\n            start_time = time.time()\n            the_package = __import__(abstest, globals(), locals(), [])\n            the_module = getattr(the_package, test)\n            # If the test has a test_main, that will run the appropriate\n            # tests.  If not, use normal unittest test loading.\n            test_runner = getattr(the_module, \"test_main\", None)\n            if test_runner is None:\n                tests = unittest.TestLoader().loadTestsFromModule(the_module)\n                test_runner = lambda: support.run_unittest(tests)\n            test_runner()\n            if huntrleaks:\n                refleak = dash_R(the_module, test, test_runner,\n                    huntrleaks)\n            test_time = time.time() - start_time\n    except support.ResourceDenied as msg:\n        if not quiet:\n            print(test, \"skipped --\", msg)\n            sys.stdout.flush()\n        return RESOURCE_DENIED, test_time\n    except unittest.SkipTest as msg:\n        if not quiet:\n            print(test, \"skipped --\", msg)\n            sys.stdout.flush()\n        return SKIPPED, test_time\n    except KeyboardInterrupt:\n        raise\n    except support.TestFailed as msg:\n        if display_failure:\n            print(\"test\", test, \"failed --\", msg, file=sys.stderr)\n        else:\n            print(\"test\", test, \"failed\", file=sys.stderr)\n        sys.stderr.flush()\n        return FAILED, test_time\n    except:\n        msg = traceback.format_exc()\n        print(\"test\", test, \"crashed --\", msg, file=sys.stderr)\n        sys.stderr.flush()\n        return FAILED, test_time\n    else:\n        if refleak:\n            return FAILED, test_time\n        if environment.changed:\n            return ENV_CHANGED, test_time\n        return PASSED, test_time\n\ndef cleanup_test_droppings(testname, verbose):\n    import shutil\n    import stat\n    import gc\n\n    # First kill any dangling references to open files etc.\n    # This can also issue some ResourceWarnings which would otherwise get\n    # triggered during the following test run, and possibly produce failures.\n    gc.collect()\n\n    # Try to clean up junk commonly left behind.  While tests shouldn't leave\n    # any files or directories behind, when a test fails that can be tedious\n    # for it to arrange.  The consequences can be especially nasty on Windows,\n    # since if a test leaves a file open, it cannot be deleted by name (while\n    # there's nothing we can do about that here either, we can display the\n    # name of the offending test, which is a real help).\n    for name in (support.TESTFN,\n                 \"db_home\",\n                ):\n        if not os.path.exists(name):\n            continue\n\n        if os.path.isdir(name):\n            kind, nuker = \"directory\", shutil.rmtree\n        elif os.path.isfile(name):\n            kind, nuker = \"file\", os.unlink\n        else:\n            raise SystemError(\"os.path says %r exists but is neither \"\n                              \"directory nor file\" % name)\n\n        if verbose:\n            print(\"%r left behind %s %r\" % (testname, kind, name))\n        try:\n            # if we have chmod, fix possible permissions problems\n            # that might prevent cleanup\n            if (hasattr(os, 'chmod')):\n                os.chmod(name, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n            nuker(name)\n        except Exception as msg:\n            print((\"%r left behind %s %r and it couldn't be \"\n                \"removed: %s\" % (testname, kind, name, msg)), file=sys.stderr)\n\ndef dash_R(the_module, test, indirect_test, huntrleaks):\n    \"\"\"Run a test multiple times, looking for reference leaks.\n\n    Returns:\n        False if the test didn't leak references; True if we detected refleaks.\n    \"\"\"\n    # This code is hackish and inelegant, but it seems to do the job.\n    import copyreg\n    import collections.abc\n\n    if not hasattr(sys, 'gettotalrefcount'):\n        raise Exception(\"Tracking reference leaks requires a debug build \"\n                        \"of Python\")\n\n    # Save current values for dash_R_cleanup() to restore.\n    fs = warnings.filters[:]\n    ps = copyreg.dispatch_table.copy()\n    pic = sys.path_importer_cache.copy()\n    try:\n        import zipimport\n    except ImportError:\n        zdc = None # Run unmodified on platforms without zipimport support\n    else:\n        zdc = zipimport._zip_directory_cache.copy()\n    abcs = {}\n    for abc in [getattr(collections.abc, a) for a in collections.abc.__all__]:\n        if not isabstract(abc):\n            continue\n        for obj in abc.__subclasses__() + [abc]:\n            abcs[obj] = obj._abc_registry.copy()\n\n    if indirect_test:\n        def run_the_test():\n            indirect_test()\n    else:\n        def run_the_test():\n            del sys.modules[the_module.__name__]\n            exec('import ' + the_module.__name__)\n\n    deltas = []\n    nwarmup, ntracked, fname = huntrleaks\n    fname = os.path.join(support.SAVEDCWD, fname)\n    repcount = nwarmup + ntracked\n    print(\"beginning\", repcount, \"repetitions\", file=sys.stderr)\n    print((\"1234567890\"*(repcount//10 + 1))[:repcount], file=sys.stderr)\n    sys.stderr.flush()\n    dash_R_cleanup(fs, ps, pic, zdc, abcs)\n    for i in range(repcount):\n        rc_before = sys.gettotalrefcount()\n        run_the_test()\n        sys.stderr.write('.')\n        sys.stderr.flush()\n        dash_R_cleanup(fs, ps, pic, zdc, abcs)\n        rc_after = sys.gettotalrefcount()\n        if i >= nwarmup:\n            deltas.append(rc_after - rc_before)\n    print(file=sys.stderr)\n    if any(deltas):\n        msg = '%s leaked %s references, sum=%s' % (test, deltas, sum(deltas))\n        print(msg, file=sys.stderr)\n        sys.stderr.flush()\n        with open(fname, \"a\") as refrep:\n            print(msg, file=refrep)\n            refrep.flush()\n        return True\n    return False\n\ndef dash_R_cleanup(fs, ps, pic, zdc, abcs):\n    import gc, copyreg\n    import _strptime, linecache\n    import urllib.parse, urllib.request, mimetypes, doctest\n    import struct, filecmp, collections.abc\n    from distutils.dir_util import _path_created\n    from weakref import WeakSet\n\n    # Clear the warnings registry, so they can be displayed again\n    for mod in sys.modules.values():\n        if hasattr(mod, '__warningregistry__'):\n            del mod.__warningregistry__\n\n    # Restore some original values.\n    warnings.filters[:] = fs\n    copyreg.dispatch_table.clear()\n    copyreg.dispatch_table.update(ps)\n    sys.path_importer_cache.clear()\n    sys.path_importer_cache.update(pic)\n    try:\n        import zipimport\n    except ImportError:\n        pass # Run unmodified on platforms without zipimport support\n    else:\n        zipimport._zip_directory_cache.clear()\n        zipimport._zip_directory_cache.update(zdc)\n\n    # clear type cache\n    sys._clear_type_cache()\n\n    # Clear ABC registries, restoring previously saved ABC registries.\n    for abc in [getattr(collections.abc, a) for a in collections.abc.__all__]:\n        if not isabstract(abc):\n            continue\n        for obj in abc.__subclasses__() + [abc]:\n            obj._abc_registry = abcs.get(obj, WeakSet()).copy()\n            obj._abc_cache.clear()\n            obj._abc_negative_cache.clear()\n\n    # Flush standard output, so that buffered data is sent to the OS and\n    # associated Python objects are reclaimed.\n    for stream in (sys.stdout, sys.stderr, sys.__stdout__, sys.__stderr__):\n        if stream is not None:\n            stream.flush()\n\n    # Clear assorted module caches.\n    _path_created.clear()\n    re.purge()\n    _strptime._regex_cache.clear()\n    urllib.parse.clear_cache()\n    urllib.request.urlcleanup()\n    linecache.clearcache()\n    mimetypes._default_mime_types()\n    filecmp._cache.clear()\n    struct._clearcache()\n    doctest.master = None\n    try:\n        import ctypes\n    except ImportError:\n        # Don't worry about resetting the cache if ctypes is not supported\n        pass\n    else:\n        ctypes._reset_cache()\n\n    # Collect cyclic trash.\n    gc.collect()\n\ndef warm_caches():\n    # char cache\n    s = bytes(range(256))\n    for i in range(256):\n        s[i:i+1]\n    # unicode cache\n    x = [chr(i) for i in range(256)]\n    # int cache\n    x = list(range(-5, 257))\n\ndef findtestdir(path=None):\n    return path or os.path.dirname(__file__) or os.curdir\n\ndef removepy(names):\n    if not names:\n        return\n    for idx, name in enumerate(names):\n        basename, ext = os.path.splitext(name)\n        if ext == '.py':\n            names[idx] = basename\n\ndef count(n, word):\n    if n == 1:\n        return \"%d %s\" % (n, word)\n    else:\n        return \"%d %ss\" % (n, word)\n\ndef printlist(x, width=70, indent=4):\n    \"\"\"Print the elements of iterable x to stdout.\n\n    Optional arg width (default 70) is the maximum line length.\n    Optional arg indent (default 4) is the number of blanks with which to\n    begin each line.\n    \"\"\"\n\n    from textwrap import fill\n    blanks = ' ' * indent\n    # Print the sorted list: 'x' may be a '--random' list or a set()\n    print(fill(' '.join(str(elt) for elt in sorted(x)), width,\n               initial_indent=blanks, subsequent_indent=blanks))\n\n# Map sys.platform to a string containing the basenames of tests\n# expected to be skipped on that platform.\n#\n# Special cases:\n#     test_pep277\n#         The _ExpectedSkips constructor adds this to the set of expected\n#         skips if not os.path.supports_unicode_filenames.\n#     test_timeout\n#         Controlled by test_timeout.skip_expected.  Requires the network\n#         resource and a socket module.\n#\n# Tests that are expected to be skipped everywhere except on one platform\n# are also handled separately.\n\n_expectations = (\n    ('win32',\n        \"\"\"\n        test__locale\n        test_crypt\n        test_curses\n        test_dbm\n        test_devpoll\n        test_fcntl\n        test_fork1\n        test_epoll\n        test_dbm_gnu\n        test_dbm_ndbm\n        test_grp\n        test_ioctl\n        test_largefile\n        test_kqueue\n        test_openpty\n        test_ossaudiodev\n        test_pipes\n        test_poll\n        test_posix\n        test_pty\n        test_pwd\n        test_resource\n        test_signal\n        test_syslog\n        test_threadsignals\n        test_wait3\n        test_wait4\n        \"\"\"),\n    ('linux',\n        \"\"\"\n        test_curses\n        test_devpoll\n        test_largefile\n        test_kqueue\n        test_ossaudiodev\n        \"\"\"),\n    ('unixware',\n        \"\"\"\n        test_epoll\n        test_largefile\n        test_kqueue\n        test_minidom\n        test_openpty\n        test_pyexpat\n        test_sax\n        test_sundry\n        \"\"\"),\n    ('openunix',\n        \"\"\"\n        test_epoll\n        test_largefile\n        test_kqueue\n        test_minidom\n        test_openpty\n        test_pyexpat\n        test_sax\n        test_sundry\n        \"\"\"),\n    ('sco_sv',\n        \"\"\"\n        test_asynchat\n        test_fork1\n        test_epoll\n        test_gettext\n        test_largefile\n        test_locale\n        test_kqueue\n        test_minidom\n        test_openpty\n        test_pyexpat\n        test_queue\n        test_sax\n        test_sundry\n        test_thread\n        test_threaded_import\n        test_threadedtempfile\n        test_threading\n        \"\"\"),\n    ('darwin',\n        \"\"\"\n        test__locale\n        test_curses\n        test_devpoll\n        test_epoll\n        test_dbm_gnu\n        test_gdb\n        test_largefile\n        test_locale\n        test_minidom\n        test_ossaudiodev\n        test_poll\n        \"\"\"),\n    ('sunos',\n        \"\"\"\n        test_curses\n        test_dbm\n        test_epoll\n        test_kqueue\n        test_dbm_gnu\n        test_gzip\n        test_openpty\n        test_zipfile\n        test_zlib\n        \"\"\"),\n    ('hp-ux',\n        \"\"\"\n        test_curses\n        test_epoll\n        test_dbm_gnu\n        test_gzip\n        test_largefile\n        test_locale\n        test_kqueue\n        test_minidom\n        test_openpty\n        test_pyexpat\n        test_sax\n        test_zipfile\n        test_zlib\n        \"\"\"),\n    ('cygwin',\n        \"\"\"\n        test_curses\n        test_dbm\n        test_devpoll\n        test_epoll\n        test_ioctl\n        test_kqueue\n        test_largefile\n        test_locale\n        test_ossaudiodev\n        test_socketserver\n        \"\"\"),\n    ('os2emx',\n        \"\"\"\n        test_audioop\n        test_curses\n        test_epoll\n        test_kqueue\n        test_largefile\n        test_mmap\n        test_openpty\n        test_ossaudiodev\n        test_pty\n        test_resource\n        test_signal\n        \"\"\"),\n    ('freebsd',\n        \"\"\"\n        test_devpoll\n        test_epoll\n        test_dbm_gnu\n        test_locale\n        test_ossaudiodev\n        test_pep277\n        test_pty\n        test_socketserver\n        test_tcl\n        test_tk\n        test_ttk_guionly\n        test_ttk_textonly\n        test_timeout\n        test_urllibnet\n        test_multiprocessing\n        \"\"\"),\n    ('aix',\n        \"\"\"\n        test_bz2\n        test_epoll\n        test_dbm_gnu\n        test_gzip\n        test_kqueue\n        test_ossaudiodev\n        test_tcl\n        test_tk\n        test_ttk_guionly\n        test_ttk_textonly\n        test_zipimport\n        test_zlib\n        \"\"\"),\n    ('openbsd',\n        \"\"\"\n        test_ctypes\n        test_devpoll\n        test_epoll\n        test_dbm_gnu\n        test_locale\n        test_normalization\n        test_ossaudiodev\n        test_pep277\n        test_tcl\n        test_tk\n        test_ttk_guionly\n        test_ttk_textonly\n        test_multiprocessing\n        \"\"\"),\n    ('netbsd',\n        \"\"\"\n        test_ctypes\n        test_curses\n        test_devpoll\n        test_epoll\n        test_dbm_gnu\n        test_locale\n        test_ossaudiodev\n        test_pep277\n        test_tcl\n        test_tk\n        test_ttk_guionly\n        test_ttk_textonly\n        test_multiprocessing\n        \"\"\"),\n)\n\nclass _ExpectedSkips:\n    def __init__(self):\n        import os.path\n        from test import test_timeout\n\n        self.valid = False\n        expected = None\n        for item in _expectations:\n            if sys.platform.startswith(item[0]):\n                expected = item[1]\n                break\n        if expected is not None:\n            self.expected = set(expected.split())\n\n            # These are broken tests, for now skipped on every platform.\n            # XXX Fix these!\n            self.expected.add('test_nis')\n\n            # expected to be skipped on every platform, even Linux\n            if not os.path.supports_unicode_filenames:\n                self.expected.add('test_pep277')\n\n            # doctest, profile and cProfile tests fail when the codec for the\n            # fs encoding isn't built in because PyUnicode_Decode() adds two\n            # calls into Python.\n            encs = (\"utf-8\", \"latin-1\", \"ascii\", \"mbcs\", \"utf-16\", \"utf-32\")\n            if sys.getfilesystemencoding().lower() not in encs:\n                self.expected.add('test_profile')\n                self.expected.add('test_cProfile')\n                self.expected.add('test_doctest')\n\n            if test_timeout.skip_expected:\n                self.expected.add('test_timeout')\n\n            if sys.platform != \"win32\":\n                # test_sqlite is only reliable on Windows where the library\n                # is distributed with Python\n                WIN_ONLY = {\"test_unicode_file\", \"test_winreg\",\n                            \"test_winsound\", \"test_startfile\",\n                            \"test_sqlite\", \"test_msilib\"}\n                self.expected |= WIN_ONLY\n\n            if sys.platform != 'sunos5':\n                self.expected.add('test_nis')\n\n            if support.python_is_optimized():\n                self.expected.add(\"test_gdb\")\n\n            self.valid = True\n\n    def isvalid(self):\n        \"Return true iff _ExpectedSkips knows about the current platform.\"\n        return self.valid\n\n    def getexpected(self):\n        \"\"\"Return set of test names we expect to skip on current platform.\n\n        self.isvalid() must be true.\n        \"\"\"\n\n        assert self.isvalid()\n        return self.expected\n\ndef _make_temp_dir_for_build(TEMPDIR):\n    # When tests are run from the Python build directory, it is best practice\n    # to keep the test files in a subfolder.  It eases the cleanup of leftover\n    # files using command \"make distclean\".\n    if sysconfig.is_python_build():\n        TEMPDIR = os.path.join(sysconfig.get_config_var('srcdir'), 'build')\n        TEMPDIR = os.path.abspath(TEMPDIR)\n        try:\n            os.mkdir(TEMPDIR)\n        except FileExistsError:\n            pass\n\n    # Define a writable temp dir that will be used as cwd while running\n    # the tests. The name of the dir includes the pid to allow parallel\n    # testing (see the -j option).\n    TESTCWD = 'test_python_{}'.format(os.getpid())\n\n    TESTCWD = os.path.join(TEMPDIR, TESTCWD)\n    return TEMPDIR, TESTCWD\n\nif __name__ == '__main__':\n    # Remove regrtest.py's own directory from the module search path. Despite\n    # the elimination of implicit relative imports, this is still needed to\n    # ensure that submodules of the test package do not inappropriately appear\n    # as top-level modules even when people (or buildbots!) invoke regrtest.py\n    # directly instead of using the -m switch\n    mydir = os.path.abspath(os.path.normpath(os.path.dirname(sys.argv[0])))\n    i = len(sys.path)\n    while i >= 0:\n        i -= 1\n        if os.path.abspath(os.path.normpath(sys.path[i])) == mydir:\n            del sys.path[i]\n\n    # findtestdir() gets the dirname out of __file__, so we have to make it\n    # absolute before changing the working directory.\n    # For example __file__ may be relative when running trace or profile.\n    # See issue #9323.\n    __file__ = os.path.abspath(__file__)\n\n    # sanity check\n    assert __file__ == os.path.abspath(sys.argv[0])\n\n    TEMPDIR, TESTCWD = _make_temp_dir_for_build(TEMPDIR)\n\n    # Run the tests in a context manager that temporary changes the CWD to a\n    # temporary and writable directory. If it's not possible to create or\n    # change the CWD, the original CWD will be used. The original CWD is\n    # available from support.SAVEDCWD.\n    with support.temp_cwd(TESTCWD, quiet=True):\n        main()\n"], "contextlib": [".py", "\"\"\"Utilities for with-statement contexts.  See PEP 343.\"\"\"\n\nimport sys\nfrom collections import deque\nfrom functools import wraps\n\n__all__ = [\"contextmanager\", \"closing\", \"ContextDecorator\", \"ExitStack\"]\n\n\nclass ContextDecorator(object):\n    \"A base class or mixin that enables context managers to work as decorators.\"\n\n    def _recreate_cm(self):\n        \"\"\"Return a recreated instance of self.\n\n        Allows an otherwise one-shot context manager like\n        _GeneratorContextManager to support use as\n        a decorator via implicit recreation.\n\n        This is a private interface just for _GeneratorContextManager.\n        See issue #11647 for details.\n        \"\"\"\n        return self\n\n    def __call__(self, func):\n        @wraps(func)\n        def inner(*args, **kwds):\n            with self._recreate_cm():\n                return func(*args, **kwds)\n        return inner\n\n\nclass _GeneratorContextManager(ContextDecorator):\n    \"\"\"Helper for @contextmanager decorator.\"\"\"\n\n    def __init__(self, func, *args, **kwds):\n        self.gen = func(*args, **kwds)\n        self.func, self.args, self.kwds = func, args, kwds\n\n    def _recreate_cm(self):\n        # _GCM instances are one-shot context managers, so the\n        # CM must be recreated each time a decorated function is\n        # called\n        return self.__class__(self.func, *self.args, **self.kwds)\n\n    def __enter__(self):\n        try:\n            return next(self.gen)\n        except StopIteration:\n            raise RuntimeError(\"generator didn't yield\")\n\n    def __exit__(self, type, value, traceback):\n        if type is None:\n            try:\n                next(self.gen)\n            except StopIteration:\n                return\n            else:\n                raise RuntimeError(\"generator didn't stop\")\n        else:\n            if value is None:\n                # Need to force instantiation so we can reliably\n                # tell if we get the same exception back\n                value = type()\n            try:\n                self.gen.throw(type, value, traceback)\n                raise RuntimeError(\"generator didn't stop after throw()\")\n            except StopIteration as exc:\n                # Suppress the exception *unless* it's the same exception that\n                # was passed to throw().  This prevents a StopIteration\n                # raised inside the \"with\" statement from being suppressed\n                return exc is not value\n            except:\n                # only re-raise if it's *not* the exception that was\n                # passed to throw(), because __exit__() must not raise\n                # an exception unless __exit__() itself failed.  But throw()\n                # has to raise the exception to signal propagation, so this\n                # fixes the impedance mismatch between the throw() protocol\n                # and the __exit__() protocol.\n                #\n                if sys.exc_info()[1] is not value:\n                    raise\n\n\ndef contextmanager(func):\n    \"\"\"@contextmanager decorator.\n\n    Typical usage:\n\n        @contextmanager\n        def some_generator(<arguments>):\n            <setup>\n            try:\n                yield <value>\n            finally:\n                <cleanup>\n\n    This makes this:\n\n        with some_generator(<arguments>) as <variable>:\n            <body>\n\n    equivalent to this:\n\n        <setup>\n        try:\n            <variable> = <value>\n            <body>\n        finally:\n            <cleanup>\n\n    \"\"\"\n    @wraps(func)\n    def helper(*args, **kwds):\n        return _GeneratorContextManager(func, *args, **kwds)\n    return helper\n\n\nclass closing(object):\n    \"\"\"Context to automatically close something at the end of a block.\n\n    Code like this:\n\n        with closing(<module>.open(<arguments>)) as f:\n            <block>\n\n    is equivalent to this:\n\n        f = <module>.open(<arguments>)\n        try:\n            <block>\n        finally:\n            f.close()\n\n    \"\"\"\n    def __init__(self, thing):\n        self.thing = thing\n    def __enter__(self):\n        return self.thing\n    def __exit__(self, *exc_info):\n        self.thing.close()\n\n\n# Inspired by discussions on http://bugs.python.org/issue13585\nclass ExitStack(object):\n    \"\"\"Context manager for dynamic management of a stack of exit callbacks\n\n    For example:\n\n        with ExitStack() as stack:\n            files = [stack.enter_context(open(fname)) for fname in filenames]\n            # All opened files will automatically be closed at the end of\n            # the with statement, even if attempts to open files later\n            # in the list raise an exception\n\n    \"\"\"\n    def __init__(self):\n        self._exit_callbacks = deque()\n\n    def pop_all(self):\n        \"\"\"Preserve the context stack by transferring it to a new instance\"\"\"\n        new_stack = type(self)()\n        new_stack._exit_callbacks = self._exit_callbacks\n        self._exit_callbacks = deque()\n        return new_stack\n\n    def _push_cm_exit(self, cm, cm_exit):\n        \"\"\"Helper to correctly register callbacks to __exit__ methods\"\"\"\n        def _exit_wrapper(*exc_details):\n            return cm_exit(cm, *exc_details)\n        _exit_wrapper.__self__ = cm\n        self.push(_exit_wrapper)\n\n    def push(self, exit):\n        \"\"\"Registers a callback with the standard __exit__ method signature\n\n        Can suppress exceptions the same way __exit__ methods can.\n\n        Also accepts any object with an __exit__ method (registering a call\n        to the method instead of the object itself)\n        \"\"\"\n        # We use an unbound method rather than a bound method to follow\n        # the standard lookup behaviour for special methods\n        _cb_type = type(exit)\n        try:\n            exit_method = _cb_type.__exit__\n        except AttributeError:\n            # Not a context manager, so assume its a callable\n            self._exit_callbacks.append(exit)\n        else:\n            self._push_cm_exit(exit, exit_method)\n        return exit # Allow use as a decorator\n\n    def callback(self, callback, *args, **kwds):\n        \"\"\"Registers an arbitrary callback and arguments.\n\n        Cannot suppress exceptions.\n        \"\"\"\n        def _exit_wrapper(exc_type, exc, tb):\n            callback(*args, **kwds)\n        # We changed the signature, so using @wraps is not appropriate, but\n        # setting __wrapped__ may still help with introspection\n        _exit_wrapper.__wrapped__ = callback\n        self.push(_exit_wrapper)\n        return callback # Allow use as a decorator\n\n    def enter_context(self, cm):\n        \"\"\"Enters the supplied context manager\n\n        If successful, also pushes its __exit__ method as a callback and\n        returns the result of the __enter__ method.\n        \"\"\"\n        # We look up the special methods on the type to match the with statement\n        _cm_type = type(cm)\n        _exit = _cm_type.__exit__\n        result = _cm_type.__enter__(cm)\n        self._push_cm_exit(cm, _exit)\n        return result\n\n    def close(self):\n        \"\"\"Immediately unwind the context stack\"\"\"\n        self.__exit__(None, None, None)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc_details):\n        received_exc = exc_details[0] is not None\n\n        # We manipulate the exception state so it behaves as though\n        # we were actually nesting multiple with statements\n        frame_exc = sys.exc_info()[1]\n        def _fix_exception_context(new_exc, old_exc):\n            while 1:\n                exc_context = new_exc.__context__\n                if exc_context in (None, frame_exc):\n                    break\n                new_exc = exc_context\n            new_exc.__context__ = old_exc\n\n        # Callbacks are invoked in LIFO order to match the behaviour of\n        # nested context managers\n        suppressed_exc = False\n        pending_raise = False\n        while self._exit_callbacks:\n            cb = self._exit_callbacks.pop()\n            try:\n                if cb(*exc_details):\n                    suppressed_exc = True\n                    pending_raise = False\n                    exc_details = (None, None, None)\n            except:\n                new_exc_details = sys.exc_info()\n                # simulate the stack of exceptions by setting the context\n                _fix_exception_context(new_exc_details[1], exc_details[1])\n                pending_raise = True\n                exc_details = new_exc_details\n        if pending_raise:\n            try:\n                # bare \"raise exc_details[1]\" replaces our carefully\n                # set-up context\n                fixed_ctx = exc_details[1].__context__\n                raise exc_details[1]\n            except BaseException:\n                exc_details[1].__context__ = fixed_ctx\n                raise\n        return received_exc and suppressed_exc\n"], "numbers": [".py", "# Copyright 2007 Google, Inc. All Rights Reserved.\n# Licensed to PSF under a Contributor Agreement.\n\n\"\"\"Abstract Base Classes (ABCs) for numbers, according to PEP 3141.\n\nTODO: Fill out more detailed documentation on the operators.\"\"\"\n\nfrom abc import ABCMeta, abstractmethod\n\n__all__ = [\"Number\", \"Complex\", \"Real\", \"Rational\", \"Integral\"]\n\nclass Number(metaclass=ABCMeta):\n    \"\"\"All numbers inherit from this class.\n\n    If you just want to check if an argument x is a number, without\n    caring what kind, use isinstance(x, Number).\n    \"\"\"\n    __slots__ = ()\n\n    # Concrete numeric types must provide their own hash implementation\n    __hash__ = None\n\n\n## Notes on Decimal\n## ----------------\n## Decimal has all of the methods specified by the Real abc, but it should\n## not be registered as a Real because decimals do not interoperate with\n## binary floats (i.e.  Decimal('3.14') + 2.71828 is undefined).  But,\n## abstract reals are expected to interoperate (i.e. R1 + R2 should be\n## expected to work if R1 and R2 are both Reals).\n\nclass Complex(Number):\n    \"\"\"Complex defines the operations that work on the builtin complex type.\n\n    In short, those are: a conversion to complex, .real, .imag, +, -,\n    *, /, abs(), .conjugate, ==, and !=.\n\n    If it is given heterogenous arguments, and doesn't have special\n    knowledge about them, it should fall back to the builtin complex\n    type as described below.\n    \"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __complex__(self):\n        \"\"\"Return a builtin complex instance. Called for complex(self).\"\"\"\n\n    def __bool__(self):\n        \"\"\"True if self != 0. Called for bool(self).\"\"\"\n        return self != 0\n\n    @property\n    @abstractmethod\n    def real(self):\n        \"\"\"Retrieve the real component of this number.\n\n        This should subclass Real.\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    @abstractmethod\n    def imag(self):\n        \"\"\"Retrieve the imaginary component of this number.\n\n        This should subclass Real.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __add__(self, other):\n        \"\"\"self + other\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __radd__(self, other):\n        \"\"\"other + self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __neg__(self):\n        \"\"\"-self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __pos__(self):\n        \"\"\"+self\"\"\"\n        raise NotImplementedError\n\n    def __sub__(self, other):\n        \"\"\"self - other\"\"\"\n        return self + -other\n\n    def __rsub__(self, other):\n        \"\"\"other - self\"\"\"\n        return -self + other\n\n    @abstractmethod\n    def __mul__(self, other):\n        \"\"\"self * other\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __rmul__(self, other):\n        \"\"\"other * self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __truediv__(self, other):\n        \"\"\"self / other: Should promote to float when necessary.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __rtruediv__(self, other):\n        \"\"\"other / self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __pow__(self, exponent):\n        \"\"\"self**exponent; should promote to float or complex when necessary.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __rpow__(self, base):\n        \"\"\"base ** self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __abs__(self):\n        \"\"\"Returns the Real distance from 0. Called for abs(self).\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def conjugate(self):\n        \"\"\"(x+y*i).conjugate() returns (x-y*i).\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __eq__(self, other):\n        \"\"\"self == other\"\"\"\n        raise NotImplementedError\n\n    def __ne__(self, other):\n        \"\"\"self != other\"\"\"\n        # The default __ne__ doesn't negate __eq__ until 3.0.\n        return not (self == other)\n\nComplex.register(complex)\n\n\nclass Real(Complex):\n    \"\"\"To Complex, Real adds the operations that work on real numbers.\n\n    In short, those are: a conversion to float, trunc(), divmod,\n    %, <, <=, >, and >=.\n\n    Real also provides defaults for the derived operations.\n    \"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __float__(self):\n        \"\"\"Any Real can be converted to a native float object.\n\n        Called for float(self).\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __trunc__(self):\n        \"\"\"trunc(self): Truncates self to an Integral.\n\n        Returns an Integral i such that:\n          * i>0 iff self>0;\n          * abs(i) <= abs(self);\n          * for any Integral j satisfying the first two conditions,\n            abs(i) >= abs(j) [i.e. i has \"maximal\" abs among those].\n        i.e. \"truncate towards 0\".\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __floor__(self):\n        \"\"\"Finds the greatest Integral <= self.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __ceil__(self):\n        \"\"\"Finds the least Integral >= self.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __round__(self, ndigits=None):\n        \"\"\"Rounds self to ndigits decimal places, defaulting to 0.\n\n        If ndigits is omitted or None, returns an Integral, otherwise\n        returns a Real. Rounds half toward even.\n        \"\"\"\n        raise NotImplementedError\n\n    def __divmod__(self, other):\n        \"\"\"divmod(self, other): The pair (self // other, self % other).\n\n        Sometimes this can be computed faster than the pair of\n        operations.\n        \"\"\"\n        return (self // other, self % other)\n\n    def __rdivmod__(self, other):\n        \"\"\"divmod(other, self): The pair (self // other, self % other).\n\n        Sometimes this can be computed faster than the pair of\n        operations.\n        \"\"\"\n        return (other // self, other % self)\n\n    @abstractmethod\n    def __floordiv__(self, other):\n        \"\"\"self // other: The floor() of self/other.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __rfloordiv__(self, other):\n        \"\"\"other // self: The floor() of other/self.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __mod__(self, other):\n        \"\"\"self % other\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __rmod__(self, other):\n        \"\"\"other % self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __lt__(self, other):\n        \"\"\"self < other\n\n        < on Reals defines a total ordering, except perhaps for NaN.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __le__(self, other):\n        \"\"\"self <= other\"\"\"\n        raise NotImplementedError\n\n    # Concrete implementations of Complex abstract methods.\n    def __complex__(self):\n        \"\"\"complex(self) == complex(float(self), 0)\"\"\"\n        return complex(float(self))\n\n    @property\n    def real(self):\n        \"\"\"Real numbers are their real component.\"\"\"\n        return +self\n\n    @property\n    def imag(self):\n        \"\"\"Real numbers have no imaginary component.\"\"\"\n        return 0\n\n    def conjugate(self):\n        \"\"\"Conjugate is a no-op for Reals.\"\"\"\n        return +self\n\nReal.register(float)\n\n\nclass Rational(Real):\n    \"\"\".numerator and .denominator should be in lowest terms.\"\"\"\n\n    __slots__ = ()\n\n    @property\n    @abstractmethod\n    def numerator(self):\n        raise NotImplementedError\n\n    @property\n    @abstractmethod\n    def denominator(self):\n        raise NotImplementedError\n\n    # Concrete implementation of Real's conversion to float.\n    def __float__(self):\n        \"\"\"float(self) = self.numerator / self.denominator\n\n        It's important that this conversion use the integer's \"true\"\n        division rather than casting one side to float before dividing\n        so that ratios of huge integers convert without overflowing.\n\n        \"\"\"\n        return self.numerator / self.denominator\n\n\nclass Integral(Rational):\n    \"\"\"Integral adds a conversion to int and the bit-string operations.\"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __int__(self):\n        \"\"\"int(self)\"\"\"\n        raise NotImplementedError\n\n    def __index__(self):\n        \"\"\"Called whenever an index is needed, such as in slicing\"\"\"\n        return int(self)\n\n    @abstractmethod\n    def __pow__(self, exponent, modulus=None):\n        \"\"\"self ** exponent % modulus, but maybe faster.\n\n        Accept the modulus argument if you want to support the\n        3-argument version of pow(). Raise a TypeError if exponent < 0\n        or any argument isn't Integral. Otherwise, just implement the\n        2-argument version described in Complex.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __lshift__(self, other):\n        \"\"\"self << other\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __rlshift__(self, other):\n        \"\"\"other << self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __rshift__(self, other):\n        \"\"\"self >> other\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __rrshift__(self, other):\n        \"\"\"other >> self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __and__(self, other):\n        \"\"\"self & other\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __rand__(self, other):\n        \"\"\"other & self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __xor__(self, other):\n        \"\"\"self ^ other\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __rxor__(self, other):\n        \"\"\"other ^ self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __or__(self, other):\n        \"\"\"self | other\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __ror__(self, other):\n        \"\"\"other | self\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def __invert__(self):\n        \"\"\"~self\"\"\"\n        raise NotImplementedError\n\n    # Concrete implementations of Rational and Real abstract methods.\n    def __float__(self):\n        \"\"\"float(self) == float(int(self))\"\"\"\n        return float(int(self))\n\n    @property\n    def numerator(self):\n        \"\"\"Integers are their own numerators.\"\"\"\n        return +self\n\n    @property\n    def denominator(self):\n        \"\"\"Integers have a denominator of 1.\"\"\"\n        return 1\n\nIntegral.register(int)\n"], "io": [".py", "import builtins\n\nopen = builtins.open\n\n# for seek()\nSEEK_SET = 0\nSEEK_CUR = 1\nSEEK_END = 2\n\nr\"\"\"File-like objects that read from or write to a string buffer.\n\nThis implements (nearly) all stdio methods.\n\nf = StringIO()      # ready for writing\nf = StringIO(buf)   # ready for reading\nf.close()           # explicitly release resources held\nflag = f.isatty()   # always false\npos = f.tell()      # get current position\nf.seek(pos)         # set current position\nf.seek(pos, mode)   # mode 0: absolute; 1: relative; 2: relative to EOF\nbuf = f.read()      # read until EOF\nbuf = f.read(n)     # read up to n bytes\nbuf = f.readline()  # read until end of line ('\\n') or EOF\nlist = f.readlines()# list of f.readline() results until EOF\nf.truncate([size])  # truncate file at to at most size (default: current pos)\nf.write(buf)        # write at current position\nf.writelines(list)  # for line in list: f.write(line)\nf.getvalue()        # return whole file's contents as a string\n\nNotes:\n- Using a real file is often faster (but less convenient).\n- There's also a much faster implementation in C, called cStringIO, but\n  it's not subclassable.\n- fileno() is left unimplemented so that code which uses it triggers\n  an exception early.\n- Seeking far beyond EOF and then writing will insert real null\n  bytes that occupy space in the buffer.\n- There's a simple test set (see end of this file).\n\"\"\"\ntry:\n    from errno import EINVAL\nexcept ImportError:\n    EINVAL = 22\n\n__all__ = [\"StringIO\"]\n\ndef _complain_ifclosed(closed):\n    if closed:\n        raise ValueError(\"I/O operation on closed file\")\n\nclass StringIO:\n    \"\"\"class StringIO([buffer])\n\n    When a StringIO object is created, it can be initialized to an existing\n    string by passing the string to the constructor. If no string is given,\n    the StringIO will start empty.\n\n    The StringIO object can accept either Unicode or 8-bit strings, but\n    mixing the two may take some care. If both are used, 8-bit strings that\n    cannot be interpreted as 7-bit ASCII (that use the 8th bit) will cause\n    a UnicodeError to be raised when getvalue() is called.\n    \"\"\"\n    def __init__(self, buf = ''):\n        self.buf = buf\n        self.len = len(buf)\n        self.buflist = []\n        self.pos = 0\n        self.closed = False\n        self.softspace = 0\n\n    def __iter__(self):\n        return self\n\n    def next(self):\n        \"\"\"A file object is its own iterator, for example iter(f) returns f\n        (unless f is closed). When a file is used as an iterator, typically\n        in a for loop (for example, for line in f: print line), the next()\n        method is called repeatedly. This method returns the next input line,\n        or raises StopIteration when EOF is hit.\n        \"\"\"\n        _complain_ifclosed(self.closed)\n        r = self.readline()\n        if not r:\n            raise StopIteration\n        return r\n\n    def close(self):\n        \"\"\"Free the memory buffer.\n        \"\"\"\n        if not self.closed:\n            self.closed = True\n            del self.buf, self.pos\n\n    def isatty(self):\n        \"\"\"Returns False because StringIO objects are not connected to a\n        tty-like device.\n        \"\"\"\n        _complain_ifclosed(self.closed)\n        return False\n\n    def seek(self, pos, mode = 0):\n        \"\"\"Set the file's current position.\n\n        The mode argument is optional and defaults to 0 (absolute file\n        positioning); other values are 1 (seek relative to the current\n        position) and 2 (seek relative to the file's end).\n\n        There is no return value.\n        \"\"\"\n        _complain_ifclosed(self.closed)\n        if self.buflist:\n            self.buf += ''.join(self.buflist)\n            self.buflist = []\n        if mode == 1:\n            pos += self.pos\n        elif mode == 2:\n            pos += self.len\n        self.pos = max(0, pos)\n\n    def tell(self):\n        \"\"\"Return the file's current position.\"\"\"\n        _complain_ifclosed(self.closed)\n        return self.pos\n\n    def read(self, n = -1):\n        \"\"\"Read at most size bytes from the file\n        (less if the read hits EOF before obtaining size bytes).\n\n        If the size argument is negative or omitted, read all data until EOF\n        is reached. The bytes are returned as a string object. An empty\n        string is returned when EOF is encountered immediately.\n        \"\"\"\n        _complain_ifclosed(self.closed)\n        if self.buflist:\n            self.buf += ''.join(self.buflist)\n            self.buflist = []\n        if n is None or n < 0:\n            newpos = self.len\n        else:\n            newpos = min(self.pos+n, self.len)\n        r = self.buf[self.pos:newpos]\n        self.pos = newpos\n        return r\n\n    def readline(self, length=None):\n        r\"\"\"Read one entire line from the file.\n\n        A trailing newline character is kept in the string (but may be absent\n        when a file ends with an incomplete line). If the size argument is\n        present and non-negative, it is a maximum byte count (including the\n        trailing newline) and an incomplete line may be returned.\n\n        An empty string is returned only when EOF is encountered immediately.\n\n        Note: Unlike stdio's fgets(), the returned string contains null\n        characters ('\\0') if they occurred in the input.\n        \"\"\"\n        _complain_ifclosed(self.closed)\n        if self.buflist:\n            self.buf += ''.join(self.buflist)\n            self.buflist = []\n        i = self.buf.find('\\n', self.pos)\n        if i < 0:\n            newpos = self.len\n        else:\n            newpos = i+1\n        if length is not None and length >= 0:\n            if self.pos + length < newpos:\n                newpos = self.pos + length\n        r = self.buf[self.pos:newpos]\n        self.pos = newpos\n        return r\n\n    def readlines(self, sizehint = 0):\n        \"\"\"Read until EOF using readline() and return a list containing the\n        lines thus read.\n\n        If the optional sizehint argument is present, instead of reading up\n        to EOF, whole lines totalling approximately sizehint bytes (or more\n        to accommodate a final whole line).\n        \"\"\"\n        total = 0\n        lines = []\n        line = self.readline()\n        while line:\n            lines.append(line)\n            total += len(line)\n            if 0 < sizehint <= total:\n                break\n            line = self.readline()\n        return lines\n\n    def truncate(self, size=None):\n        \"\"\"Truncate the file's size.\n\n        If the optional size argument is present, the file is truncated to\n        (at most) that size. The size defaults to the current position.\n        The current file position is not changed unless the position\n        is beyond the new file size.\n\n        If the specified size exceeds the file's current size, the\n        file remains unchanged.\n        \"\"\"\n        _complain_ifclosed(self.closed)\n        if size is None:\n            size = self.pos\n        elif size < 0:\n            raise IOError(EINVAL, \"Negative size not allowed\")\n        elif size < self.pos:\n            self.pos = size\n        self.buf = self.getvalue()[:size]\n        self.len = size\n\n    def write(self, s):\n        \"\"\"Write a string to the file.\n\n        There is no return value.\n        \"\"\"\n        _complain_ifclosed(self.closed)\n        if not s: return\n        spos = self.pos\n        slen = self.len\n        if spos == slen:\n            self.buflist.append(s)\n            self.len = self.pos = spos + len(s)\n            return\n        if spos > slen:\n            self.buflist.append('\\0'*(spos - slen))\n            slen = spos\n        newpos = spos + len(s)\n        if spos < slen:\n            if self.buflist:\n                self.buf += ''.join(self.buflist)\n            self.buflist = [self.buf[:spos], s, self.buf[newpos:]]\n            self.buf = ''\n            if newpos > slen:\n                slen = newpos\n        else:\n            self.buflist.append(s)\n            slen = newpos\n        self.len = slen\n        self.pos = newpos\n\n    def writelines(self, iterable):\n        \"\"\"Write a sequence of strings to the file. The sequence can be any\n        iterable object producing strings, typically a list of strings. There\n        is no return value.\n\n        (The name is intended to match readlines(); writelines() does not add\n        line separators.)\n        \"\"\"\n        write = self.write\n        for line in iterable:\n            write(line)\n\n    def flush(self):\n        \"\"\"Flush the internal buffer\n        \"\"\"\n        _complain_ifclosed(self.closed)\n\n    def getvalue(self):\n        \"\"\"\n        Retrieve the entire contents of the \"file\" at any time before\n        the StringIO object's close() method is called.\n\n        The StringIO object can accept either Unicode or 8-bit strings,\n        but mixing the two may take some care. If both are used, 8-bit\n        strings that cannot be interpreted as 7-bit ASCII (that use the\n        8th bit) will cause a UnicodeError to be raised when getvalue()\n        is called.\n        \"\"\"\n        _complain_ifclosed(self.closed)\n        if self.buflist:\n            self.buf += ''.join(self.buflist)\n            self.buflist = []\n        return self.buf\n\n\nTextIOWrapper = StringIO\n\nclass RawIOBase:\n\n    def read(self,n=-1):\n        pass\n    def readall(self):\n        pass\n    def readinto(self,b):\n        pass\n    def write(self,b):\n        pass\n\nBufferedReader = RawIOBase\n\n#from _io import *\n"], "copyreg": [".py", "\"\"\"Helper to provide extensibility for pickle.\n\nThis is only useful to add pickle support for extension types defined in\nC, not for instances of user-defined classes.\n\"\"\"\n\n__all__ = [\"pickle\", \"constructor\",\n           \"add_extension\", \"remove_extension\", \"clear_extension_cache\"]\n\ndispatch_table = {}\n\ndef pickle(ob_type, pickle_function, constructor_ob=None):\n    if not callable(pickle_function):\n        raise TypeError(\"reduction functions must be callable\")\n    dispatch_table[ob_type] = pickle_function\n\n    # The constructor_ob function is a vestige of safe for unpickling.\n    # There is no reason for the caller to pass it anymore.\n    if constructor_ob is not None:\n        constructor(constructor_ob)\n\ndef constructor(object):\n    if not callable(object):\n        raise TypeError(\"constructors must be callable\")\n\n# Example: provide pickling support for complex numbers.\n\ntry:\n    complex\nexcept NameError:\n    pass\nelse:\n\n    def pickle_complex(c):\n        return complex, (c.real, c.imag)\n\n    pickle(complex, pickle_complex, complex)\n\n# Support for pickling new-style objects\n\ndef _reconstructor(cls, base, state):\n    if base is object:\n        obj = object.__new__(cls)\n    else:\n        obj = base.__new__(cls, state)\n        if base.__init__ != object.__init__:\n            base.__init__(obj, state)\n    return obj\n\n_HEAPTYPE = 1<<9\n\n# Python code for object.__reduce_ex__ for protocols 0 and 1\n\ndef _reduce_ex(self, proto):\n    assert proto < 2\n    for base in self.__class__.__mro__:\n        if hasattr(base, '__flags__') and not base.__flags__ & _HEAPTYPE:\n            break\n    else:\n        base = object # not really reachable\n    if base is object:\n        state = None\n    else:\n        if base is self.__class__:\n            raise TypeError(\"can't pickle %s objects\" % base.__name__)\n        state = base(self)\n    args = (self.__class__, base, state)\n    try:\n        getstate = self.__getstate__\n    except AttributeError:\n        if getattr(self, \"__slots__\", None):\n            raise TypeError(\"a class that defines __slots__ without \"\n                            \"defining __getstate__ cannot be pickled\")\n        try:\n            dict = self.__dict__\n        except AttributeError:\n            dict = None\n    else:\n        dict = getstate()\n    if dict:\n        return _reconstructor, args, dict\n    else:\n        return _reconstructor, args\n\n# Helper for __reduce_ex__ protocol 2\n\ndef __newobj__(cls, *args):\n    return cls.__new__(cls, *args)\n\ndef _slotnames(cls):\n    \"\"\"Return a list of slot names for a given class.\n\n    This needs to find slots defined by the class and its bases, so we\n    can't simply return the __slots__ attribute.  We must walk down\n    the Method Resolution Order and concatenate the __slots__ of each\n    class found there.  (This assumes classes don't modify their\n    __slots__ attribute to misrepresent their slots after the class is\n    defined.)\n    \"\"\"\n\n    # Get the value from a cache in the class if possible\n    names = cls.__dict__.get(\"__slotnames__\")\n    if names is not None:\n        return names\n\n    # Not cached -- calculate the value\n    names = []\n    if not hasattr(cls, \"__slots__\"):\n        # This class has no slots\n        pass\n    else:\n        # Slots found -- gather slot names from all base classes\n        for c in cls.__mro__:\n            if \"__slots__\" in c.__dict__:\n                slots = c.__dict__['__slots__']\n                # if class has a single slot, it can be given as a string\n                if isinstance(slots, str):\n                    slots = (slots,)\n                for name in slots:\n                    # special descriptors\n                    if name in (\"__dict__\", \"__weakref__\"):\n                        continue\n                    # mangled names\n                    elif name.startswith('__') and not name.endswith('__'):\n                        names.append('_%s%s' % (c.__name__, name))\n                    else:\n                        names.append(name)\n\n    # Cache the outcome in the class if at all possible\n    try:\n        cls.__slotnames__ = names\n    except:\n        pass # But don't die if we can't\n\n    return names\n\n# A registry of extension codes.  This is an ad-hoc compression\n# mechanism.  Whenever a global reference to <module>, <name> is about\n# to be pickled, the (<module>, <name>) tuple is looked up here to see\n# if it is a registered extension code for it.  Extension codes are\n# universal, so that the meaning of a pickle does not depend on\n# context.  (There are also some codes reserved for local use that\n# don't have this restriction.)  Codes are positive ints; 0 is\n# reserved.\n\n_extension_registry = {}                # key -> code\n_inverted_registry = {}                 # code -> key\n_extension_cache = {}                   # code -> object\n# Don't ever rebind those names:  pickling grabs a reference to them when\n# it's initialized, and won't see a rebinding.\n\ndef add_extension(module, name, code):\n    \"\"\"Register an extension code.\"\"\"\n    code = int(code)\n    if not 1 <= code <= 0x7fffffff:\n        raise ValueError(\"code out of range\")\n    key = (module, name)\n    if (_extension_registry.get(key) == code and\n        _inverted_registry.get(code) == key):\n        return # Redundant registrations are benign\n    if key in _extension_registry:\n        raise ValueError(\"key %s is already registered with code %s\" %\n                         (key, _extension_registry[key]))\n    if code in _inverted_registry:\n        raise ValueError(\"code %s is already in use for key %s\" %\n                         (code, _inverted_registry[code]))\n    _extension_registry[key] = code\n    _inverted_registry[code] = key\n\ndef remove_extension(module, name, code):\n    \"\"\"Unregister an extension code.  For testing only.\"\"\"\n    key = (module, name)\n    if (_extension_registry.get(key) != code or\n        _inverted_registry.get(code) != key):\n        raise ValueError(\"key %s is not registered with code %s\" %\n                         (key, code))\n    del _extension_registry[key]\n    del _inverted_registry[code]\n    if code in _extension_cache:\n        del _extension_cache[code]\n\ndef clear_extension_cache():\n    _extension_cache.clear()\n\n# Standard extension code assignments\n\n# Reserved ranges\n\n# First  Last Count  Purpose\n#     1   127   127  Reserved for Python standard library\n#   128   191    64  Reserved for Zope\n#   192   239    48  Reserved for 3rd parties\n#   240   255    16  Reserved for private use (will never be assigned)\n#   256   Inf   Inf  Reserved for future assignment\n\n# Extension codes are assigned by the Python Software Foundation.\n"], "pydoc_data.topics": [".py", "# -*- coding: utf-8 -*-\n# Autogenerated by Sphinx on Sat Mar 23 15:42:31 2013\ntopics = {'assert': '\\nThe ``assert`` statement\\n************************\\n\\nAssert statements are a convenient way to insert debugging assertions\\ninto a program:\\n\\n   assert_stmt ::= \"assert\" expression [\",\" expression]\\n\\nThe simple form, ``assert expression``, is equivalent to\\n\\n   if __debug__:\\n      if not expression: raise AssertionError\\n\\nThe extended form, ``assert expression1, expression2``, is equivalent\\nto\\n\\n   if __debug__:\\n      if not expression1: raise AssertionError(expression2)\\n\\nThese equivalences assume that ``__debug__`` and ``AssertionError``\\nrefer to the built-in variables with those names.  In the current\\nimplementation, the built-in variable ``__debug__`` is ``True`` under\\nnormal circumstances, ``False`` when optimization is requested\\n(command line option -O).  The current code generator emits no code\\nfor an assert statement when optimization is requested at compile\\ntime.  Note that it is unnecessary to include the source code for the\\nexpression that failed in the error message; it will be displayed as\\npart of the stack trace.\\n\\nAssignments to ``__debug__`` are illegal.  The value for the built-in\\nvariable is determined when the interpreter starts.\\n',\n 'assignment': '\\nAssignment statements\\n*********************\\n\\nAssignment statements are used to (re)bind names to values and to\\nmodify attributes or items of mutable objects:\\n\\n   assignment_stmt ::= (target_list \"=\")+ (expression_list | yield_expression)\\n   target_list     ::= target (\",\" target)* [\",\"]\\n   target          ::= identifier\\n              | \"(\" target_list \")\"\\n              | \"[\" target_list \"]\"\\n              | attributeref\\n              | subscription\\n              | slicing\\n              | \"*\" target\\n\\n(See section *Primaries* for the syntax definitions for the last three\\nsymbols.)\\n\\nAn assignment statement evaluates the expression list (remember that\\nthis can be a single expression or a comma-separated list, the latter\\nyielding a tuple) and assigns the single resulting object to each of\\nthe target lists, from left to right.\\n\\nAssignment is defined recursively depending on the form of the target\\n(list). When a target is part of a mutable object (an attribute\\nreference, subscription or slicing), the mutable object must\\nultimately perform the assignment and decide about its validity, and\\nmay raise an exception if the assignment is unacceptable.  The rules\\nobserved by various types and the exceptions raised are given with the\\ndefinition of the object types (see section *The standard type\\nhierarchy*).\\n\\nAssignment of an object to a target list, optionally enclosed in\\nparentheses or square brackets, is recursively defined as follows.\\n\\n* If the target list is a single target: The object is assigned to\\n  that target.\\n\\n* If the target list is a comma-separated list of targets: The object\\n  must be an iterable with the same number of items as there are\\n  targets in the target list, and the items are assigned, from left to\\n  right, to the corresponding targets.\\n\\n  * If the target list contains one target prefixed with an asterisk,\\n    called a \"starred\" target: The object must be a sequence with at\\n    least as many items as there are targets in the target list, minus\\n    one.  The first items of the sequence are assigned, from left to\\n    right, to the targets before the starred target.  The final items\\n    of the sequence are assigned to the targets after the starred\\n    target.  A list of the remaining items in the sequence is then\\n    assigned to the starred target (the list can be empty).\\n\\n  * Else: The object must be a sequence with the same number of items\\n    as there are targets in the target list, and the items are\\n    assigned, from left to right, to the corresponding targets.\\n\\nAssignment of an object to a single target is recursively defined as\\nfollows.\\n\\n* If the target is an identifier (name):\\n\\n  * If the name does not occur in a ``global`` or ``nonlocal``\\n    statement in the current code block: the name is bound to the\\n    object in the current local namespace.\\n\\n  * Otherwise: the name is bound to the object in the global namespace\\n    or the outer namespace determined by ``nonlocal``, respectively.\\n\\n  The name is rebound if it was already bound.  This may cause the\\n  reference count for the object previously bound to the name to reach\\n  zero, causing the object to be deallocated and its destructor (if it\\n  has one) to be called.\\n\\n* If the target is a target list enclosed in parentheses or in square\\n  brackets: The object must be an iterable with the same number of\\n  items as there are targets in the target list, and its items are\\n  assigned, from left to right, to the corresponding targets.\\n\\n* If the target is an attribute reference: The primary expression in\\n  the reference is evaluated.  It should yield an object with\\n  assignable attributes; if this is not the case, ``TypeError`` is\\n  raised.  That object is then asked to assign the assigned object to\\n  the given attribute; if it cannot perform the assignment, it raises\\n  an exception (usually but not necessarily ``AttributeError``).\\n\\n  Note: If the object is a class instance and the attribute reference\\n  occurs on both sides of the assignment operator, the RHS expression,\\n  ``a.x`` can access either an instance attribute or (if no instance\\n  attribute exists) a class attribute.  The LHS target ``a.x`` is\\n  always set as an instance attribute, creating it if necessary.\\n  Thus, the two occurrences of ``a.x`` do not necessarily refer to the\\n  same attribute: if the RHS expression refers to a class attribute,\\n  the LHS creates a new instance attribute as the target of the\\n  assignment:\\n\\n     class Cls:\\n         x = 3             # class variable\\n     inst = Cls()\\n     inst.x = inst.x + 1   # writes inst.x as 4 leaving Cls.x as 3\\n\\n  This description does not necessarily apply to descriptor\\n  attributes, such as properties created with ``property()``.\\n\\n* If the target is a subscription: The primary expression in the\\n  reference is evaluated.  It should yield either a mutable sequence\\n  object (such as a list) or a mapping object (such as a dictionary).\\n  Next, the subscript expression is evaluated.\\n\\n  If the primary is a mutable sequence object (such as a list), the\\n  subscript must yield an integer.  If it is negative, the sequence\\'s\\n  length is added to it.  The resulting value must be a nonnegative\\n  integer less than the sequence\\'s length, and the sequence is asked\\n  to assign the assigned object to its item with that index.  If the\\n  index is out of range, ``IndexError`` is raised (assignment to a\\n  subscripted sequence cannot add new items to a list).\\n\\n  If the primary is a mapping object (such as a dictionary), the\\n  subscript must have a type compatible with the mapping\\'s key type,\\n  and the mapping is then asked to create a key/datum pair which maps\\n  the subscript to the assigned object.  This can either replace an\\n  existing key/value pair with the same key value, or insert a new\\n  key/value pair (if no key with the same value existed).\\n\\n  For user-defined objects, the ``__setitem__()`` method is called\\n  with appropriate arguments.\\n\\n* If the target is a slicing: The primary expression in the reference\\n  is evaluated.  It should yield a mutable sequence object (such as a\\n  list).  The assigned object should be a sequence object of the same\\n  type.  Next, the lower and upper bound expressions are evaluated,\\n  insofar they are present; defaults are zero and the sequence\\'s\\n  length.  The bounds should evaluate to integers. If either bound is\\n  negative, the sequence\\'s length is added to it.  The resulting\\n  bounds are clipped to lie between zero and the sequence\\'s length,\\n  inclusive.  Finally, the sequence object is asked to replace the\\n  slice with the items of the assigned sequence.  The length of the\\n  slice may be different from the length of the assigned sequence,\\n  thus changing the length of the target sequence, if the object\\n  allows it.\\n\\n**CPython implementation detail:** In the current implementation, the\\nsyntax for targets is taken to be the same as for expressions, and\\ninvalid syntax is rejected during the code generation phase, causing\\nless detailed error messages.\\n\\nWARNING: Although the definition of assignment implies that overlaps\\nbetween the left-hand side and the right-hand side are \\'safe\\' (for\\nexample ``a, b = b, a`` swaps two variables), overlaps *within* the\\ncollection of assigned-to variables are not safe!  For instance, the\\nfollowing program prints ``[0, 2]``:\\n\\n   x = [0, 1]\\n   i = 0\\n   i, x[i] = 1, 2\\n   print(x)\\n\\nSee also:\\n\\n   **PEP 3132** - Extended Iterable Unpacking\\n      The specification for the ``*target`` feature.\\n\\n\\nAugmented assignment statements\\n===============================\\n\\nAugmented assignment is the combination, in a single statement, of a\\nbinary operation and an assignment statement:\\n\\n   augmented_assignment_stmt ::= augtarget augop (expression_list | yield_expression)\\n   augtarget                 ::= identifier | attributeref | subscription | slicing\\n   augop                     ::= \"+=\" | \"-=\" | \"*=\" | \"/=\" | \"//=\" | \"%=\" | \"**=\"\\n             | \">>=\" | \"<<=\" | \"&=\" | \"^=\" | \"|=\"\\n\\n(See section *Primaries* for the syntax definitions for the last three\\nsymbols.)\\n\\nAn augmented assignment evaluates the target (which, unlike normal\\nassignment statements, cannot be an unpacking) and the expression\\nlist, performs the binary operation specific to the type of assignment\\non the two operands, and assigns the result to the original target.\\nThe target is only evaluated once.\\n\\nAn augmented assignment expression like ``x += 1`` can be rewritten as\\n``x = x + 1`` to achieve a similar, but not exactly equal effect. In\\nthe augmented version, ``x`` is only evaluated once. Also, when\\npossible, the actual operation is performed *in-place*, meaning that\\nrather than creating a new object and assigning that to the target,\\nthe old object is modified instead.\\n\\nWith the exception of assigning to tuples and multiple targets in a\\nsingle statement, the assignment done by augmented assignment\\nstatements is handled the same way as normal assignments. Similarly,\\nwith the exception of the possible *in-place* behavior, the binary\\noperation performed by augmented assignment is the same as the normal\\nbinary operations.\\n\\nFor targets which are attribute references, the same *caveat about\\nclass and instance attributes* applies as for regular assignments.\\n',\n 'atom-identifiers': '\\nIdentifiers (Names)\\n*******************\\n\\nAn identifier occurring as an atom is a name.  See section\\n*Identifiers and keywords* for lexical definition and section *Naming\\nand binding* for documentation of naming and binding.\\n\\nWhen the name is bound to an object, evaluation of the atom yields\\nthat object. When a name is not bound, an attempt to evaluate it\\nraises a ``NameError`` exception.\\n\\n**Private name mangling:** When an identifier that textually occurs in\\na class definition begins with two or more underscore characters and\\ndoes not end in two or more underscores, it is considered a *private\\nname* of that class. Private names are transformed to a longer form\\nbefore code is generated for them.  The transformation inserts the\\nclass name in front of the name, with leading underscores removed, and\\na single underscore inserted in front of the class name.  For example,\\nthe identifier ``__spam`` occurring in a class named ``Ham`` will be\\ntransformed to ``_Ham__spam``.  This transformation is independent of\\nthe syntactical context in which the identifier is used.  If the\\ntransformed name is extremely long (longer than 255 characters),\\nimplementation defined truncation may happen.  If the class name\\nconsists only of underscores, no transformation is done.\\n',\n 'atom-literals': \"\\nLiterals\\n********\\n\\nPython supports string and bytes literals and various numeric\\nliterals:\\n\\n   literal ::= stringliteral | bytesliteral\\n               | integer | floatnumber | imagnumber\\n\\nEvaluation of a literal yields an object of the given type (string,\\nbytes, integer, floating point number, complex number) with the given\\nvalue.  The value may be approximated in the case of floating point\\nand imaginary (complex) literals.  See section *Literals* for details.\\n\\nAll literals correspond to immutable data types, and hence the\\nobject's identity is less important than its value.  Multiple\\nevaluations of literals with the same value (either the same\\noccurrence in the program text or a different occurrence) may obtain\\nthe same object or a different object with the same value.\\n\",\n 'attribute-access': '\\nCustomizing attribute access\\n****************************\\n\\nThe following methods can be defined to customize the meaning of\\nattribute access (use of, assignment to, or deletion of ``x.name``)\\nfor class instances.\\n\\nobject.__getattr__(self, name)\\n\\n   Called when an attribute lookup has not found the attribute in the\\n   usual places (i.e. it is not an instance attribute nor is it found\\n   in the class tree for ``self``).  ``name`` is the attribute name.\\n   This method should return the (computed) attribute value or raise\\n   an ``AttributeError`` exception.\\n\\n   Note that if the attribute is found through the normal mechanism,\\n   ``__getattr__()`` is not called.  (This is an intentional asymmetry\\n   between ``__getattr__()`` and ``__setattr__()``.) This is done both\\n   for efficiency reasons and because otherwise ``__getattr__()``\\n   would have no way to access other attributes of the instance.  Note\\n   that at least for instance variables, you can fake total control by\\n   not inserting any values in the instance attribute dictionary (but\\n   instead inserting them in another object).  See the\\n   ``__getattribute__()`` method below for a way to actually get total\\n   control over attribute access.\\n\\nobject.__getattribute__(self, name)\\n\\n   Called unconditionally to implement attribute accesses for\\n   instances of the class. If the class also defines\\n   ``__getattr__()``, the latter will not be called unless\\n   ``__getattribute__()`` either calls it explicitly or raises an\\n   ``AttributeError``. This method should return the (computed)\\n   attribute value or raise an ``AttributeError`` exception. In order\\n   to avoid infinite recursion in this method, its implementation\\n   should always call the base class method with the same name to\\n   access any attributes it needs, for example,\\n   ``object.__getattribute__(self, name)``.\\n\\n   Note: This method may still be bypassed when looking up special methods\\n     as the result of implicit invocation via language syntax or\\n     built-in functions. See *Special method lookup*.\\n\\nobject.__setattr__(self, name, value)\\n\\n   Called when an attribute assignment is attempted.  This is called\\n   instead of the normal mechanism (i.e. store the value in the\\n   instance dictionary). *name* is the attribute name, *value* is the\\n   value to be assigned to it.\\n\\n   If ``__setattr__()`` wants to assign to an instance attribute, it\\n   should call the base class method with the same name, for example,\\n   ``object.__setattr__(self, name, value)``.\\n\\nobject.__delattr__(self, name)\\n\\n   Like ``__setattr__()`` but for attribute deletion instead of\\n   assignment.  This should only be implemented if ``del obj.name`` is\\n   meaningful for the object.\\n\\nobject.__dir__(self)\\n\\n   Called when ``dir()`` is called on the object. A sequence must be\\n   returned. ``dir()`` converts the returned sequence to a list and\\n   sorts it.\\n\\n\\nImplementing Descriptors\\n========================\\n\\nThe following methods only apply when an instance of the class\\ncontaining the method (a so-called *descriptor* class) appears in an\\n*owner* class (the descriptor must be in either the owner\\'s class\\ndictionary or in the class dictionary for one of its parents).  In the\\nexamples below, \"the attribute\" refers to the attribute whose name is\\nthe key of the property in the owner class\\' ``__dict__``.\\n\\nobject.__get__(self, instance, owner)\\n\\n   Called to get the attribute of the owner class (class attribute\\n   access) or of an instance of that class (instance attribute\\n   access). *owner* is always the owner class, while *instance* is the\\n   instance that the attribute was accessed through, or ``None`` when\\n   the attribute is accessed through the *owner*.  This method should\\n   return the (computed) attribute value or raise an\\n   ``AttributeError`` exception.\\n\\nobject.__set__(self, instance, value)\\n\\n   Called to set the attribute on an instance *instance* of the owner\\n   class to a new value, *value*.\\n\\nobject.__delete__(self, instance)\\n\\n   Called to delete the attribute on an instance *instance* of the\\n   owner class.\\n\\n\\nInvoking Descriptors\\n====================\\n\\nIn general, a descriptor is an object attribute with \"binding\\nbehavior\", one whose attribute access has been overridden by methods\\nin the descriptor protocol:  ``__get__()``, ``__set__()``, and\\n``__delete__()``. If any of those methods are defined for an object,\\nit is said to be a descriptor.\\n\\nThe default behavior for attribute access is to get, set, or delete\\nthe attribute from an object\\'s dictionary. For instance, ``a.x`` has a\\nlookup chain starting with ``a.__dict__[\\'x\\']``, then\\n``type(a).__dict__[\\'x\\']``, and continuing through the base classes of\\n``type(a)`` excluding metaclasses.\\n\\nHowever, if the looked-up value is an object defining one of the\\ndescriptor methods, then Python may override the default behavior and\\ninvoke the descriptor method instead.  Where this occurs in the\\nprecedence chain depends on which descriptor methods were defined and\\nhow they were called.\\n\\nThe starting point for descriptor invocation is a binding, ``a.x``.\\nHow the arguments are assembled depends on ``a``:\\n\\nDirect Call\\n   The simplest and least common call is when user code directly\\n   invokes a descriptor method:    ``x.__get__(a)``.\\n\\nInstance Binding\\n   If binding to an object instance, ``a.x`` is transformed into the\\n   call: ``type(a).__dict__[\\'x\\'].__get__(a, type(a))``.\\n\\nClass Binding\\n   If binding to a class, ``A.x`` is transformed into the call:\\n   ``A.__dict__[\\'x\\'].__get__(None, A)``.\\n\\nSuper Binding\\n   If ``a`` is an instance of ``super``, then the binding ``super(B,\\n   obj).m()`` searches ``obj.__class__.__mro__`` for the base class\\n   ``A`` immediately preceding ``B`` and then invokes the descriptor\\n   with the call: ``A.__dict__[\\'m\\'].__get__(obj, obj.__class__)``.\\n\\nFor instance bindings, the precedence of descriptor invocation depends\\non the which descriptor methods are defined.  A descriptor can define\\nany combination of ``__get__()``, ``__set__()`` and ``__delete__()``.\\nIf it does not define ``__get__()``, then accessing the attribute will\\nreturn the descriptor object itself unless there is a value in the\\nobject\\'s instance dictionary.  If the descriptor defines ``__set__()``\\nand/or ``__delete__()``, it is a data descriptor; if it defines\\nneither, it is a non-data descriptor.  Normally, data descriptors\\ndefine both ``__get__()`` and ``__set__()``, while non-data\\ndescriptors have just the ``__get__()`` method.  Data descriptors with\\n``__set__()`` and ``__get__()`` defined always override a redefinition\\nin an instance dictionary.  In contrast, non-data descriptors can be\\noverridden by instances.\\n\\nPython methods (including ``staticmethod()`` and ``classmethod()``)\\nare implemented as non-data descriptors.  Accordingly, instances can\\nredefine and override methods.  This allows individual instances to\\nacquire behaviors that differ from other instances of the same class.\\n\\nThe ``property()`` function is implemented as a data descriptor.\\nAccordingly, instances cannot override the behavior of a property.\\n\\n\\n__slots__\\n=========\\n\\nBy default, instances of classes have a dictionary for attribute\\nstorage.  This wastes space for objects having very few instance\\nvariables.  The space consumption can become acute when creating large\\nnumbers of instances.\\n\\nThe default can be overridden by defining *__slots__* in a class\\ndefinition. The *__slots__* declaration takes a sequence of instance\\nvariables and reserves just enough space in each instance to hold a\\nvalue for each variable.  Space is saved because *__dict__* is not\\ncreated for each instance.\\n\\nobject.__slots__\\n\\n   This class variable can be assigned a string, iterable, or sequence\\n   of strings with variable names used by instances.  If defined in a\\n   class, *__slots__* reserves space for the declared variables and\\n   prevents the automatic creation of *__dict__* and *__weakref__* for\\n   each instance.\\n\\n\\nNotes on using *__slots__*\\n--------------------------\\n\\n* When inheriting from a class without *__slots__*, the *__dict__*\\n  attribute of that class will always be accessible, so a *__slots__*\\n  definition in the subclass is meaningless.\\n\\n* Without a *__dict__* variable, instances cannot be assigned new\\n  variables not listed in the *__slots__* definition.  Attempts to\\n  assign to an unlisted variable name raises ``AttributeError``. If\\n  dynamic assignment of new variables is desired, then add\\n  ``\\'__dict__\\'`` to the sequence of strings in the *__slots__*\\n  declaration.\\n\\n* Without a *__weakref__* variable for each instance, classes defining\\n  *__slots__* do not support weak references to its instances. If weak\\n  reference support is needed, then add ``\\'__weakref__\\'`` to the\\n  sequence of strings in the *__slots__* declaration.\\n\\n* *__slots__* are implemented at the class level by creating\\n  descriptors (*Implementing Descriptors*) for each variable name.  As\\n  a result, class attributes cannot be used to set default values for\\n  instance variables defined by *__slots__*; otherwise, the class\\n  attribute would overwrite the descriptor assignment.\\n\\n* The action of a *__slots__* declaration is limited to the class\\n  where it is defined.  As a result, subclasses will have a *__dict__*\\n  unless they also define *__slots__* (which must only contain names\\n  of any *additional* slots).\\n\\n* If a class defines a slot also defined in a base class, the instance\\n  variable defined by the base class slot is inaccessible (except by\\n  retrieving its descriptor directly from the base class). This\\n  renders the meaning of the program undefined.  In the future, a\\n  check may be added to prevent this.\\n\\n* Nonempty *__slots__* does not work for classes derived from\\n  \"variable-length\" built-in types such as ``int``, ``str`` and\\n  ``tuple``.\\n\\n* Any non-string iterable may be assigned to *__slots__*. Mappings may\\n  also be used; however, in the future, special meaning may be\\n  assigned to the values corresponding to each key.\\n\\n* *__class__* assignment works only if both classes have the same\\n  *__slots__*.\\n',\n 'attribute-references': '\\nAttribute references\\n********************\\n\\nAn attribute reference is a primary followed by a period and a name:\\n\\n   attributeref ::= primary \".\" identifier\\n\\nThe primary must evaluate to an object of a type that supports\\nattribute references, which most objects do.  This object is then\\nasked to produce the attribute whose name is the identifier (which can\\nbe customized by overriding the ``__getattr__()`` method).  If this\\nattribute is not available, the exception ``AttributeError`` is\\nraised.  Otherwise, the type and value of the object produced is\\ndetermined by the object.  Multiple evaluations of the same attribute\\nreference may yield different objects.\\n',\n 'augassign': '\\nAugmented assignment statements\\n*******************************\\n\\nAugmented assignment is the combination, in a single statement, of a\\nbinary operation and an assignment statement:\\n\\n   augmented_assignment_stmt ::= augtarget augop (expression_list | yield_expression)\\n   augtarget                 ::= identifier | attributeref | subscription | slicing\\n   augop                     ::= \"+=\" | \"-=\" | \"*=\" | \"/=\" | \"//=\" | \"%=\" | \"**=\"\\n             | \">>=\" | \"<<=\" | \"&=\" | \"^=\" | \"|=\"\\n\\n(See section *Primaries* for the syntax definitions for the last three\\nsymbols.)\\n\\nAn augmented assignment evaluates the target (which, unlike normal\\nassignment statements, cannot be an unpacking) and the expression\\nlist, performs the binary operation specific to the type of assignment\\non the two operands, and assigns the result to the original target.\\nThe target is only evaluated once.\\n\\nAn augmented assignment expression like ``x += 1`` can be rewritten as\\n``x = x + 1`` to achieve a similar, but not exactly equal effect. In\\nthe augmented version, ``x`` is only evaluated once. Also, when\\npossible, the actual operation is performed *in-place*, meaning that\\nrather than creating a new object and assigning that to the target,\\nthe old object is modified instead.\\n\\nWith the exception of assigning to tuples and multiple targets in a\\nsingle statement, the assignment done by augmented assignment\\nstatements is handled the same way as normal assignments. Similarly,\\nwith the exception of the possible *in-place* behavior, the binary\\noperation performed by augmented assignment is the same as the normal\\nbinary operations.\\n\\nFor targets which are attribute references, the same *caveat about\\nclass and instance attributes* applies as for regular assignments.\\n',\n 'binary': '\\nBinary arithmetic operations\\n****************************\\n\\nThe binary arithmetic operations have the conventional priority\\nlevels.  Note that some of these operations also apply to certain non-\\nnumeric types.  Apart from the power operator, there are only two\\nlevels, one for multiplicative operators and one for additive\\noperators:\\n\\n   m_expr ::= u_expr | m_expr \"*\" u_expr | m_expr \"//\" u_expr | m_expr \"/\" u_expr\\n              | m_expr \"%\" u_expr\\n   a_expr ::= m_expr | a_expr \"+\" m_expr | a_expr \"-\" m_expr\\n\\nThe ``*`` (multiplication) operator yields the product of its\\narguments.  The arguments must either both be numbers, or one argument\\nmust be an integer and the other must be a sequence. In the former\\ncase, the numbers are converted to a common type and then multiplied\\ntogether.  In the latter case, sequence repetition is performed; a\\nnegative repetition factor yields an empty sequence.\\n\\nThe ``/`` (division) and ``//`` (floor division) operators yield the\\nquotient of their arguments.  The numeric arguments are first\\nconverted to a common type. Integer division yields a float, while\\nfloor division of integers results in an integer; the result is that\\nof mathematical division with the \\'floor\\' function applied to the\\nresult.  Division by zero raises the ``ZeroDivisionError`` exception.\\n\\nThe ``%`` (modulo) operator yields the remainder from the division of\\nthe first argument by the second.  The numeric arguments are first\\nconverted to a common type.  A zero right argument raises the\\n``ZeroDivisionError`` exception.  The arguments may be floating point\\nnumbers, e.g., ``3.14%0.7`` equals ``0.34`` (since ``3.14`` equals\\n``4*0.7 + 0.34``.)  The modulo operator always yields a result with\\nthe same sign as its second operand (or zero); the absolute value of\\nthe result is strictly smaller than the absolute value of the second\\noperand [1].\\n\\nThe floor division and modulo operators are connected by the following\\nidentity: ``x == (x//y)*y + (x%y)``.  Floor division and modulo are\\nalso connected with the built-in function ``divmod()``: ``divmod(x, y)\\n== (x//y, x%y)``. [2].\\n\\nIn addition to performing the modulo operation on numbers, the ``%``\\noperator is also overloaded by string objects to perform old-style\\nstring formatting (also known as interpolation).  The syntax for\\nstring formatting is described in the Python Library Reference,\\nsection *printf-style String Formatting*.\\n\\nThe floor division operator, the modulo operator, and the ``divmod()``\\nfunction are not defined for complex numbers.  Instead, convert to a\\nfloating point number using the ``abs()`` function if appropriate.\\n\\nThe ``+`` (addition) operator yields the sum of its arguments.  The\\narguments must either both be numbers or both sequences of the same\\ntype.  In the former case, the numbers are converted to a common type\\nand then added together.  In the latter case, the sequences are\\nconcatenated.\\n\\nThe ``-`` (subtraction) operator yields the difference of its\\narguments.  The numeric arguments are first converted to a common\\ntype.\\n',\n 'bitwise': '\\nBinary bitwise operations\\n*************************\\n\\nEach of the three bitwise operations has a different priority level:\\n\\n   and_expr ::= shift_expr | and_expr \"&\" shift_expr\\n   xor_expr ::= and_expr | xor_expr \"^\" and_expr\\n   or_expr  ::= xor_expr | or_expr \"|\" xor_expr\\n\\nThe ``&`` operator yields the bitwise AND of its arguments, which must\\nbe integers.\\n\\nThe ``^`` operator yields the bitwise XOR (exclusive OR) of its\\narguments, which must be integers.\\n\\nThe ``|`` operator yields the bitwise (inclusive) OR of its arguments,\\nwhich must be integers.\\n',\n 'bltin-code-objects': '\\nCode Objects\\n************\\n\\nCode objects are used by the implementation to represent \"pseudo-\\ncompiled\" executable Python code such as a function body. They differ\\nfrom function objects because they don\\'t contain a reference to their\\nglobal execution environment.  Code objects are returned by the built-\\nin ``compile()`` function and can be extracted from function objects\\nthrough their ``__code__`` attribute. See also the ``code`` module.\\n\\nA code object can be executed or evaluated by passing it (instead of a\\nsource string) to the ``exec()`` or ``eval()``  built-in functions.\\n\\nSee *The standard type hierarchy* for more information.\\n',\n 'bltin-ellipsis-object': '\\nThe Ellipsis Object\\n*******************\\n\\nThis object is commonly used by slicing (see *Slicings*).  It supports\\nno special operations.  There is exactly one ellipsis object, named\\n``Ellipsis`` (a built-in name).  ``type(Ellipsis)()`` produces the\\n``Ellipsis`` singleton.\\n\\nIt is written as ``Ellipsis`` or ``...``.\\n',\n 'bltin-null-object': \"\\nThe Null Object\\n***************\\n\\nThis object is returned by functions that don't explicitly return a\\nvalue.  It supports no special operations.  There is exactly one null\\nobject, named ``None`` (a built-in name).  ``type(None)()`` produces\\nthe same singleton.\\n\\nIt is written as ``None``.\\n\",\n 'bltin-type-objects': \"\\nType Objects\\n************\\n\\nType objects represent the various object types.  An object's type is\\naccessed by the built-in function ``type()``.  There are no special\\noperations on types.  The standard module ``types`` defines names for\\nall standard built-in types.\\n\\nTypes are written like this: ``<class 'int'>``.\\n\",\n 'booleans': '\\nBoolean operations\\n******************\\n\\n   or_test  ::= and_test | or_test \"or\" and_test\\n   and_test ::= not_test | and_test \"and\" not_test\\n   not_test ::= comparison | \"not\" not_test\\n\\nIn the context of Boolean operations, and also when expressions are\\nused by control flow statements, the following values are interpreted\\nas false: ``False``, ``None``, numeric zero of all types, and empty\\nstrings and containers (including strings, tuples, lists,\\ndictionaries, sets and frozensets).  All other values are interpreted\\nas true.  User-defined objects can customize their truth value by\\nproviding a ``__bool__()`` method.\\n\\nThe operator ``not`` yields ``True`` if its argument is false,\\n``False`` otherwise.\\n\\nThe expression ``x and y`` first evaluates *x*; if *x* is false, its\\nvalue is returned; otherwise, *y* is evaluated and the resulting value\\nis returned.\\n\\nThe expression ``x or y`` first evaluates *x*; if *x* is true, its\\nvalue is returned; otherwise, *y* is evaluated and the resulting value\\nis returned.\\n\\n(Note that neither ``and`` nor ``or`` restrict the value and type they\\nreturn to ``False`` and ``True``, but rather return the last evaluated\\nargument.  This is sometimes useful, e.g., if ``s`` is a string that\\nshould be replaced by a default value if it is empty, the expression\\n``s or \\'foo\\'`` yields the desired value.  Because ``not`` has to\\ninvent a value anyway, it does not bother to return a value of the\\nsame type as its argument, so e.g., ``not \\'foo\\'`` yields ``False``,\\nnot ``\\'\\'``.)\\n',\n 'break': '\\nThe ``break`` statement\\n***********************\\n\\n   break_stmt ::= \"break\"\\n\\n``break`` may only occur syntactically nested in a ``for`` or\\n``while`` loop, but not nested in a function or class definition\\nwithin that loop.\\n\\nIt terminates the nearest enclosing loop, skipping the optional\\n``else`` clause if the loop has one.\\n\\nIf a ``for`` loop is terminated by ``break``, the loop control target\\nkeeps its current value.\\n\\nWhen ``break`` passes control out of a ``try`` statement with a\\n``finally`` clause, that ``finally`` clause is executed before really\\nleaving the loop.\\n',\n 'callable-types': '\\nEmulating callable objects\\n**************************\\n\\nobject.__call__(self[, args...])\\n\\n   Called when the instance is \"called\" as a function; if this method\\n   is defined, ``x(arg1, arg2, ...)`` is a shorthand for\\n   ``x.__call__(arg1, arg2, ...)``.\\n',\n 'calls': '\\nCalls\\n*****\\n\\nA call calls a callable object (e.g., a *function*) with a possibly\\nempty series of *arguments*:\\n\\n   call                 ::= primary \"(\" [argument_list [\",\"] | comprehension] \")\"\\n   argument_list        ::= positional_arguments [\",\" keyword_arguments]\\n                       [\",\" \"*\" expression] [\",\" keyword_arguments]\\n                       [\",\" \"**\" expression]\\n                     | keyword_arguments [\",\" \"*\" expression]\\n                       [\",\" keyword_arguments] [\",\" \"**\" expression]\\n                     | \"*\" expression [\",\" keyword_arguments] [\",\" \"**\" expression]\\n                     | \"**\" expression\\n   positional_arguments ::= expression (\",\" expression)*\\n   keyword_arguments    ::= keyword_item (\",\" keyword_item)*\\n   keyword_item         ::= identifier \"=\" expression\\n\\nA trailing comma may be present after the positional and keyword\\narguments but does not affect the semantics.\\n\\nThe primary must evaluate to a callable object (user-defined\\nfunctions, built-in functions, methods of built-in objects, class\\nobjects, methods of class instances, and all objects having a\\n``__call__()`` method are callable).  All argument expressions are\\nevaluated before the call is attempted.  Please refer to section\\n*Function definitions* for the syntax of formal *parameter* lists.\\n\\nIf keyword arguments are present, they are first converted to\\npositional arguments, as follows.  First, a list of unfilled slots is\\ncreated for the formal parameters.  If there are N positional\\narguments, they are placed in the first N slots.  Next, for each\\nkeyword argument, the identifier is used to determine the\\ncorresponding slot (if the identifier is the same as the first formal\\nparameter name, the first slot is used, and so on).  If the slot is\\nalready filled, a ``TypeError`` exception is raised. Otherwise, the\\nvalue of the argument is placed in the slot, filling it (even if the\\nexpression is ``None``, it fills the slot).  When all arguments have\\nbeen processed, the slots that are still unfilled are filled with the\\ncorresponding default value from the function definition.  (Default\\nvalues are calculated, once, when the function is defined; thus, a\\nmutable object such as a list or dictionary used as default value will\\nbe shared by all calls that don\\'t specify an argument value for the\\ncorresponding slot; this should usually be avoided.)  If there are any\\nunfilled slots for which no default value is specified, a\\n``TypeError`` exception is raised.  Otherwise, the list of filled\\nslots is used as the argument list for the call.\\n\\n**CPython implementation detail:** An implementation may provide\\nbuilt-in functions whose positional parameters do not have names, even\\nif they are \\'named\\' for the purpose of documentation, and which\\ntherefore cannot be supplied by keyword.  In CPython, this is the case\\nfor functions implemented in C that use ``PyArg_ParseTuple()`` to\\nparse their arguments.\\n\\nIf there are more positional arguments than there are formal parameter\\nslots, a ``TypeError`` exception is raised, unless a formal parameter\\nusing the syntax ``*identifier`` is present; in this case, that formal\\nparameter receives a tuple containing the excess positional arguments\\n(or an empty tuple if there were no excess positional arguments).\\n\\nIf any keyword argument does not correspond to a formal parameter\\nname, a ``TypeError`` exception is raised, unless a formal parameter\\nusing the syntax ``**identifier`` is present; in this case, that\\nformal parameter receives a dictionary containing the excess keyword\\narguments (using the keywords as keys and the argument values as\\ncorresponding values), or a (new) empty dictionary if there were no\\nexcess keyword arguments.\\n\\nIf the syntax ``*expression`` appears in the function call,\\n``expression`` must evaluate to an iterable.  Elements from this\\niterable are treated as if they were additional positional arguments;\\nif there are positional arguments *x1*, ..., *xN*, and ``expression``\\nevaluates to a sequence *y1*, ..., *yM*, this is equivalent to a call\\nwith M+N positional arguments *x1*, ..., *xN*, *y1*, ..., *yM*.\\n\\nA consequence of this is that although the ``*expression`` syntax may\\nappear *after* some keyword arguments, it is processed *before* the\\nkeyword arguments (and the ``**expression`` argument, if any -- see\\nbelow).  So:\\n\\n   >>> def f(a, b):\\n   ...  print(a, b)\\n   ...\\n   >>> f(b=1, *(2,))\\n   2 1\\n   >>> f(a=1, *(2,))\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 1, in ?\\n   TypeError: f() got multiple values for keyword argument \\'a\\'\\n   >>> f(1, *(2,))\\n   1 2\\n\\nIt is unusual for both keyword arguments and the ``*expression``\\nsyntax to be used in the same call, so in practice this confusion does\\nnot arise.\\n\\nIf the syntax ``**expression`` appears in the function call,\\n``expression`` must evaluate to a mapping, the contents of which are\\ntreated as additional keyword arguments.  In the case of a keyword\\nappearing in both ``expression`` and as an explicit keyword argument,\\na ``TypeError`` exception is raised.\\n\\nFormal parameters using the syntax ``*identifier`` or ``**identifier``\\ncannot be used as positional argument slots or as keyword argument\\nnames.\\n\\nA call always returns some value, possibly ``None``, unless it raises\\nan exception.  How this value is computed depends on the type of the\\ncallable object.\\n\\nIf it is---\\n\\na user-defined function:\\n   The code block for the function is executed, passing it the\\n   argument list.  The first thing the code block will do is bind the\\n   formal parameters to the arguments; this is described in section\\n   *Function definitions*.  When the code block executes a ``return``\\n   statement, this specifies the return value of the function call.\\n\\na built-in function or method:\\n   The result is up to the interpreter; see *Built-in Functions* for\\n   the descriptions of built-in functions and methods.\\n\\na class object:\\n   A new instance of that class is returned.\\n\\na class instance method:\\n   The corresponding user-defined function is called, with an argument\\n   list that is one longer than the argument list of the call: the\\n   instance becomes the first argument.\\n\\na class instance:\\n   The class must define a ``__call__()`` method; the effect is then\\n   the same as if that method was called.\\n',\n 'class': '\\nClass definitions\\n*****************\\n\\nA class definition defines a class object (see section *The standard\\ntype hierarchy*):\\n\\n   classdef    ::= [decorators] \"class\" classname [inheritance] \":\" suite\\n   inheritance ::= \"(\" [parameter_list] \")\"\\n   classname   ::= identifier\\n\\nA class definition is an executable statement.  The inheritance list\\nusually gives a list of base classes (see *Customizing class creation*\\nfor more advanced uses), so each item in the list should evaluate to a\\nclass object which allows subclassing.  Classes without an inheritance\\nlist inherit, by default, from the base class ``object``; hence,\\n\\n   class Foo:\\n       pass\\n\\nis equivalent to\\n\\n   class Foo(object):\\n       pass\\n\\nThe class\\'s suite is then executed in a new execution frame (see\\n*Naming and binding*), using a newly created local namespace and the\\noriginal global namespace. (Usually, the suite contains mostly\\nfunction definitions.)  When the class\\'s suite finishes execution, its\\nexecution frame is discarded but its local namespace is saved. [4] A\\nclass object is then created using the inheritance list for the base\\nclasses and the saved local namespace for the attribute dictionary.\\nThe class name is bound to this class object in the original local\\nnamespace.\\n\\nClass creation can be customized heavily using *metaclasses*.\\n\\nClasses can also be decorated: just like when decorating functions,\\n\\n   @f1(arg)\\n   @f2\\n   class Foo: pass\\n\\nis equivalent to\\n\\n   class Foo: pass\\n   Foo = f1(arg)(f2(Foo))\\n\\nThe evaluation rules for the decorator expressions are the same as for\\nfunction decorators.  The result must be a class object, which is then\\nbound to the class name.\\n\\n**Programmer\\'s note:** Variables defined in the class definition are\\nclass attributes; they are shared by instances.  Instance attributes\\ncan be set in a method with ``self.name = value``.  Both class and\\ninstance attributes are accessible through the notation\\n\"``self.name``\", and an instance attribute hides a class attribute\\nwith the same name when accessed in this way.  Class attributes can be\\nused as defaults for instance attributes, but using mutable values\\nthere can lead to unexpected results.  *Descriptors* can be used to\\ncreate instance variables with different implementation details.\\n\\nSee also:\\n\\n   **PEP 3115** - Metaclasses in Python 3 **PEP 3129** - Class\\n   Decorators\\n\\n-[ Footnotes ]-\\n\\n[1] The exception is propagated to the invocation stack unless there\\n    is a ``finally`` clause which happens to raise another exception.\\n    That new exception causes the old one to be lost.\\n\\n[2] Currently, control \"flows off the end\" except in the case of an\\n    exception or the execution of a ``return``, ``continue``, or\\n    ``break`` statement.\\n\\n[3] A string literal appearing as the first statement in the function\\n    body is transformed into the function\\'s ``__doc__`` attribute and\\n    therefore the function\\'s *docstring*.\\n\\n[4] A string literal appearing as the first statement in the class\\n    body is transformed into the namespace\\'s ``__doc__`` item and\\n    therefore the class\\'s *docstring*.\\n',\n 'comparisons': '\\nComparisons\\n***********\\n\\nUnlike C, all comparison operations in Python have the same priority,\\nwhich is lower than that of any arithmetic, shifting or bitwise\\noperation.  Also unlike C, expressions like ``a < b < c`` have the\\ninterpretation that is conventional in mathematics:\\n\\n   comparison    ::= or_expr ( comp_operator or_expr )*\\n   comp_operator ::= \"<\" | \">\" | \"==\" | \">=\" | \"<=\" | \"!=\"\\n                     | \"is\" [\"not\"] | [\"not\"] \"in\"\\n\\nComparisons yield boolean values: ``True`` or ``False``.\\n\\nComparisons can be chained arbitrarily, e.g., ``x < y <= z`` is\\nequivalent to ``x < y and y <= z``, except that ``y`` is evaluated\\nonly once (but in both cases ``z`` is not evaluated at all when ``x <\\ny`` is found to be false).\\n\\nFormally, if *a*, *b*, *c*, ..., *y*, *z* are expressions and *op1*,\\n*op2*, ..., *opN* are comparison operators, then ``a op1 b op2 c ... y\\nopN z`` is equivalent to ``a op1 b and b op2 c and ... y opN z``,\\nexcept that each expression is evaluated at most once.\\n\\nNote that ``a op1 b op2 c`` doesn\\'t imply any kind of comparison\\nbetween *a* and *c*, so that, e.g., ``x < y > z`` is perfectly legal\\n(though perhaps not pretty).\\n\\nThe operators ``<``, ``>``, ``==``, ``>=``, ``<=``, and ``!=`` compare\\nthe values of two objects.  The objects need not have the same type.\\nIf both are numbers, they are converted to a common type.  Otherwise,\\nthe ``==`` and ``!=`` operators *always* consider objects of different\\ntypes to be unequal, while the ``<``, ``>``, ``>=`` and ``<=``\\noperators raise a ``TypeError`` when comparing objects of different\\ntypes that do not implement these operators for the given pair of\\ntypes.  You can control comparison behavior of objects of non-built-in\\ntypes by defining rich comparison methods like ``__gt__()``, described\\nin section *Basic customization*.\\n\\nComparison of objects of the same type depends on the type:\\n\\n* Numbers are compared arithmetically.\\n\\n* The values ``float(\\'NaN\\')`` and ``Decimal(\\'NaN\\')`` are special. The\\n  are identical to themselves, ``x is x`` but are not equal to\\n  themselves, ``x != x``.  Additionally, comparing any value to a\\n  not-a-number value will return ``False``.  For example, both ``3 <\\n  float(\\'NaN\\')`` and ``float(\\'NaN\\') < 3`` will return ``False``.\\n\\n* Bytes objects are compared lexicographically using the numeric\\n  values of their elements.\\n\\n* Strings are compared lexicographically using the numeric equivalents\\n  (the result of the built-in function ``ord()``) of their characters.\\n  [3] String and bytes object can\\'t be compared!\\n\\n* Tuples and lists are compared lexicographically using comparison of\\n  corresponding elements.  This means that to compare equal, each\\n  element must compare equal and the two sequences must be of the same\\n  type and have the same length.\\n\\n  If not equal, the sequences are ordered the same as their first\\n  differing elements.  For example, ``[1,2,x] <= [1,2,y]`` has the\\n  same value as ``x <= y``.  If the corresponding element does not\\n  exist, the shorter sequence is ordered first (for example, ``[1,2] <\\n  [1,2,3]``).\\n\\n* Mappings (dictionaries) compare equal if and only if they have the\\n  same ``(key, value)`` pairs. Order comparisons ``(\\'<\\', \\'<=\\', \\'>=\\',\\n  \\'>\\')`` raise ``TypeError``.\\n\\n* Sets and frozensets define comparison operators to mean subset and\\n  superset tests.  Those relations do not define total orderings (the\\n  two sets ``{1,2}`` and {2,3} are not equal, nor subsets of one\\n  another, nor supersets of one another).  Accordingly, sets are not\\n  appropriate arguments for functions which depend on total ordering.\\n  For example, ``min()``, ``max()``, and ``sorted()`` produce\\n  undefined results given a list of sets as inputs.\\n\\n* Most other objects of built-in types compare unequal unless they are\\n  the same object; the choice whether one object is considered smaller\\n  or larger than another one is made arbitrarily but consistently\\n  within one execution of a program.\\n\\nComparison of objects of the differing types depends on whether either\\nof the types provide explicit support for the comparison.  Most\\nnumeric types can be compared with one another.  When cross-type\\ncomparison is not supported, the comparison method returns\\n``NotImplemented``.\\n\\nThe operators ``in`` and ``not in`` test for membership.  ``x in s``\\nevaluates to true if *x* is a member of *s*, and false otherwise.  ``x\\nnot in s`` returns the negation of ``x in s``.  All built-in sequences\\nand set types support this as well as dictionary, for which ``in``\\ntests whether a the dictionary has a given key. For container types\\nsuch as list, tuple, set, frozenset, dict, or collections.deque, the\\nexpression ``x in y`` is equivalent to ``any(x is e or x == e for e in\\ny)``.\\n\\nFor the string and bytes types, ``x in y`` is true if and only if *x*\\nis a substring of *y*.  An equivalent test is ``y.find(x) != -1``.\\nEmpty strings are always considered to be a substring of any other\\nstring, so ``\"\" in \"abc\"`` will return ``True``.\\n\\nFor user-defined classes which define the ``__contains__()`` method,\\n``x in y`` is true if and only if ``y.__contains__(x)`` is true.\\n\\nFor user-defined classes which do not define ``__contains__()`` but do\\ndefine ``__iter__()``, ``x in y`` is true if some value ``z`` with ``x\\n== z`` is produced while iterating over ``y``.  If an exception is\\nraised during the iteration, it is as if ``in`` raised that exception.\\n\\nLastly, the old-style iteration protocol is tried: if a class defines\\n``__getitem__()``, ``x in y`` is true if and only if there is a non-\\nnegative integer index *i* such that ``x == y[i]``, and all lower\\ninteger indices do not raise ``IndexError`` exception.  (If any other\\nexception is raised, it is as if ``in`` raised that exception).\\n\\nThe operator ``not in`` is defined to have the inverse true value of\\n``in``.\\n\\nThe operators ``is`` and ``is not`` test for object identity: ``x is\\ny`` is true if and only if *x* and *y* are the same object.  ``x is\\nnot y`` yields the inverse truth value. [4]\\n',\n 'compound': '\\nCompound statements\\n*******************\\n\\nCompound statements contain (groups of) other statements; they affect\\nor control the execution of those other statements in some way.  In\\ngeneral, compound statements span multiple lines, although in simple\\nincarnations a whole compound statement may be contained in one line.\\n\\nThe ``if``, ``while`` and ``for`` statements implement traditional\\ncontrol flow constructs.  ``try`` specifies exception handlers and/or\\ncleanup code for a group of statements, while the ``with`` statement\\nallows the execution of initialization and finalization code around a\\nblock of code.  Function and class definitions are also syntactically\\ncompound statements.\\n\\nCompound statements consist of one or more \\'clauses.\\'  A clause\\nconsists of a header and a \\'suite.\\'  The clause headers of a\\nparticular compound statement are all at the same indentation level.\\nEach clause header begins with a uniquely identifying keyword and ends\\nwith a colon.  A suite is a group of statements controlled by a\\nclause.  A suite can be one or more semicolon-separated simple\\nstatements on the same line as the header, following the header\\'s\\ncolon, or it can be one or more indented statements on subsequent\\nlines.  Only the latter form of suite can contain nested compound\\nstatements; the following is illegal, mostly because it wouldn\\'t be\\nclear to which ``if`` clause a following ``else`` clause would belong:\\n\\n   if test1: if test2: print(x)\\n\\nAlso note that the semicolon binds tighter than the colon in this\\ncontext, so that in the following example, either all or none of the\\n``print()`` calls are executed:\\n\\n   if x < y < z: print(x); print(y); print(z)\\n\\nSummarizing:\\n\\n   compound_stmt ::= if_stmt\\n                     | while_stmt\\n                     | for_stmt\\n                     | try_stmt\\n                     | with_stmt\\n                     | funcdef\\n                     | classdef\\n   suite         ::= stmt_list NEWLINE | NEWLINE INDENT statement+ DEDENT\\n   statement     ::= stmt_list NEWLINE | compound_stmt\\n   stmt_list     ::= simple_stmt (\";\" simple_stmt)* [\";\"]\\n\\nNote that statements always end in a ``NEWLINE`` possibly followed by\\na ``DEDENT``.  Also note that optional continuation clauses always\\nbegin with a keyword that cannot start a statement, thus there are no\\nambiguities (the \\'dangling ``else``\\' problem is solved in Python by\\nrequiring nested ``if`` statements to be indented).\\n\\nThe formatting of the grammar rules in the following sections places\\neach clause on a separate line for clarity.\\n\\n\\nThe ``if`` statement\\n====================\\n\\nThe ``if`` statement is used for conditional execution:\\n\\n   if_stmt ::= \"if\" expression \":\" suite\\n               ( \"elif\" expression \":\" suite )*\\n               [\"else\" \":\" suite]\\n\\nIt selects exactly one of the suites by evaluating the expressions one\\nby one until one is found to be true (see section *Boolean operations*\\nfor the definition of true and false); then that suite is executed\\n(and no other part of the ``if`` statement is executed or evaluated).\\nIf all expressions are false, the suite of the ``else`` clause, if\\npresent, is executed.\\n\\n\\nThe ``while`` statement\\n=======================\\n\\nThe ``while`` statement is used for repeated execution as long as an\\nexpression is true:\\n\\n   while_stmt ::= \"while\" expression \":\" suite\\n                  [\"else\" \":\" suite]\\n\\nThis repeatedly tests the expression and, if it is true, executes the\\nfirst suite; if the expression is false (which may be the first time\\nit is tested) the suite of the ``else`` clause, if present, is\\nexecuted and the loop terminates.\\n\\nA ``break`` statement executed in the first suite terminates the loop\\nwithout executing the ``else`` clause\\'s suite.  A ``continue``\\nstatement executed in the first suite skips the rest of the suite and\\ngoes back to testing the expression.\\n\\n\\nThe ``for`` statement\\n=====================\\n\\nThe ``for`` statement is used to iterate over the elements of a\\nsequence (such as a string, tuple or list) or other iterable object:\\n\\n   for_stmt ::= \"for\" target_list \"in\" expression_list \":\" suite\\n                [\"else\" \":\" suite]\\n\\nThe expression list is evaluated once; it should yield an iterable\\nobject.  An iterator is created for the result of the\\n``expression_list``.  The suite is then executed once for each item\\nprovided by the iterator, in the order of ascending indices.  Each\\nitem in turn is assigned to the target list using the standard rules\\nfor assignments (see *Assignment statements*), and then the suite is\\nexecuted.  When the items are exhausted (which is immediately when the\\nsequence is empty or an iterator raises a ``StopIteration``\\nexception), the suite in the ``else`` clause, if present, is executed,\\nand the loop terminates.\\n\\nA ``break`` statement executed in the first suite terminates the loop\\nwithout executing the ``else`` clause\\'s suite.  A ``continue``\\nstatement executed in the first suite skips the rest of the suite and\\ncontinues with the next item, or with the ``else`` clause if there was\\nno next item.\\n\\nThe suite may assign to the variable(s) in the target list; this does\\nnot affect the next item assigned to it.\\n\\nNames in the target list are not deleted when the loop is finished,\\nbut if the sequence is empty, it will not have been assigned to at all\\nby the loop.  Hint: the built-in function ``range()`` returns an\\niterator of integers suitable to emulate the effect of Pascal\\'s ``for\\ni := a to b do``; e.g., ``list(range(3))`` returns the list ``[0, 1,\\n2]``.\\n\\nNote: There is a subtlety when the sequence is being modified by the loop\\n  (this can only occur for mutable sequences, i.e. lists).  An\\n  internal counter is used to keep track of which item is used next,\\n  and this is incremented on each iteration.  When this counter has\\n  reached the length of the sequence the loop terminates.  This means\\n  that if the suite deletes the current (or a previous) item from the\\n  sequence, the next item will be skipped (since it gets the index of\\n  the current item which has already been treated).  Likewise, if the\\n  suite inserts an item in the sequence before the current item, the\\n  current item will be treated again the next time through the loop.\\n  This can lead to nasty bugs that can be avoided by making a\\n  temporary copy using a slice of the whole sequence, e.g.,\\n\\n     for x in a[:]:\\n         if x < 0: a.remove(x)\\n\\n\\nThe ``try`` statement\\n=====================\\n\\nThe ``try`` statement specifies exception handlers and/or cleanup code\\nfor a group of statements:\\n\\n   try_stmt  ::= try1_stmt | try2_stmt\\n   try1_stmt ::= \"try\" \":\" suite\\n                 (\"except\" [expression [\"as\" target]] \":\" suite)+\\n                 [\"else\" \":\" suite]\\n                 [\"finally\" \":\" suite]\\n   try2_stmt ::= \"try\" \":\" suite\\n                 \"finally\" \":\" suite\\n\\nThe ``except`` clause(s) specify one or more exception handlers. When\\nno exception occurs in the ``try`` clause, no exception handler is\\nexecuted. When an exception occurs in the ``try`` suite, a search for\\nan exception handler is started.  This search inspects the except\\nclauses in turn until one is found that matches the exception.  An\\nexpression-less except clause, if present, must be last; it matches\\nany exception.  For an except clause with an expression, that\\nexpression is evaluated, and the clause matches the exception if the\\nresulting object is \"compatible\" with the exception.  An object is\\ncompatible with an exception if it is the class or a base class of the\\nexception object or a tuple containing an item compatible with the\\nexception.\\n\\nIf no except clause matches the exception, the search for an exception\\nhandler continues in the surrounding code and on the invocation stack.\\n[1]\\n\\nIf the evaluation of an expression in the header of an except clause\\nraises an exception, the original search for a handler is canceled and\\na search starts for the new exception in the surrounding code and on\\nthe call stack (it is treated as if the entire ``try`` statement\\nraised the exception).\\n\\nWhen a matching except clause is found, the exception is assigned to\\nthe target specified after the ``as`` keyword in that except clause,\\nif present, and the except clause\\'s suite is executed.  All except\\nclauses must have an executable block.  When the end of this block is\\nreached, execution continues normally after the entire try statement.\\n(This means that if two nested handlers exist for the same exception,\\nand the exception occurs in the try clause of the inner handler, the\\nouter handler will not handle the exception.)\\n\\nWhen an exception has been assigned using ``as target``, it is cleared\\nat the end of the except clause.  This is as if\\n\\n   except E as N:\\n       foo\\n\\nwas translated to\\n\\n   except E as N:\\n       try:\\n           foo\\n       finally:\\n           del N\\n\\nThis means the exception must be assigned to a different name to be\\nable to refer to it after the except clause.  Exceptions are cleared\\nbecause with the traceback attached to them, they form a reference\\ncycle with the stack frame, keeping all locals in that frame alive\\nuntil the next garbage collection occurs.\\n\\nBefore an except clause\\'s suite is executed, details about the\\nexception are stored in the ``sys`` module and can be access via\\n``sys.exc_info()``. ``sys.exc_info()`` returns a 3-tuple consisting of\\nthe exception class, the exception instance and a traceback object\\n(see section *The standard type hierarchy*) identifying the point in\\nthe program where the exception occurred.  ``sys.exc_info()`` values\\nare restored to their previous values (before the call) when returning\\nfrom a function that handled an exception.\\n\\nThe optional ``else`` clause is executed if and when control flows off\\nthe end of the ``try`` clause. [2] Exceptions in the ``else`` clause\\nare not handled by the preceding ``except`` clauses.\\n\\nIf ``finally`` is present, it specifies a \\'cleanup\\' handler.  The\\n``try`` clause is executed, including any ``except`` and ``else``\\nclauses.  If an exception occurs in any of the clauses and is not\\nhandled, the exception is temporarily saved. The ``finally`` clause is\\nexecuted.  If there is a saved exception it is re-raised at the end of\\nthe ``finally`` clause.  If the ``finally`` clause raises another\\nexception, the saved exception is set as the context of the new\\nexception. If the ``finally`` clause executes a ``return`` or\\n``break`` statement, the saved exception is discarded:\\n\\n   def f():\\n       try:\\n           1/0\\n       finally:\\n           return 42\\n\\n   >>> f()\\n   42\\n\\nThe exception information is not available to the program during\\nexecution of the ``finally`` clause.\\n\\nWhen a ``return``, ``break`` or ``continue`` statement is executed in\\nthe ``try`` suite of a ``try``...``finally`` statement, the\\n``finally`` clause is also executed \\'on the way out.\\' A ``continue``\\nstatement is illegal in the ``finally`` clause. (The reason is a\\nproblem with the current implementation --- this restriction may be\\nlifted in the future).\\n\\nAdditional information on exceptions can be found in section\\n*Exceptions*, and information on using the ``raise`` statement to\\ngenerate exceptions may be found in section *The raise statement*.\\n\\n\\nThe ``with`` statement\\n======================\\n\\nThe ``with`` statement is used to wrap the execution of a block with\\nmethods defined by a context manager (see section *With Statement\\nContext Managers*). This allows common\\n``try``...``except``...``finally`` usage patterns to be encapsulated\\nfor convenient reuse.\\n\\n   with_stmt ::= \"with\" with_item (\",\" with_item)* \":\" suite\\n   with_item ::= expression [\"as\" target]\\n\\nThe execution of the ``with`` statement with one \"item\" proceeds as\\nfollows:\\n\\n1. The context expression (the expression given in the ``with_item``)\\n   is evaluated to obtain a context manager.\\n\\n2. The context manager\\'s ``__exit__()`` is loaded for later use.\\n\\n3. The context manager\\'s ``__enter__()`` method is invoked.\\n\\n4. If a target was included in the ``with`` statement, the return\\n   value from ``__enter__()`` is assigned to it.\\n\\n   Note: The ``with`` statement guarantees that if the ``__enter__()``\\n     method returns without an error, then ``__exit__()`` will always\\n     be called. Thus, if an error occurs during the assignment to the\\n     target list, it will be treated the same as an error occurring\\n     within the suite would be. See step 6 below.\\n\\n5. The suite is executed.\\n\\n6. The context manager\\'s ``__exit__()`` method is invoked.  If an\\n   exception caused the suite to be exited, its type, value, and\\n   traceback are passed as arguments to ``__exit__()``. Otherwise,\\n   three ``None`` arguments are supplied.\\n\\n   If the suite was exited due to an exception, and the return value\\n   from the ``__exit__()`` method was false, the exception is\\n   reraised.  If the return value was true, the exception is\\n   suppressed, and execution continues with the statement following\\n   the ``with`` statement.\\n\\n   If the suite was exited for any reason other than an exception, the\\n   return value from ``__exit__()`` is ignored, and execution proceeds\\n   at the normal location for the kind of exit that was taken.\\n\\nWith more than one item, the context managers are processed as if\\nmultiple ``with`` statements were nested:\\n\\n   with A() as a, B() as b:\\n       suite\\n\\nis equivalent to\\n\\n   with A() as a:\\n       with B() as b:\\n           suite\\n\\nChanged in version 3.1: Support for multiple context expressions.\\n\\nSee also:\\n\\n   **PEP 0343** - The \"with\" statement\\n      The specification, background, and examples for the Python\\n      ``with`` statement.\\n\\n\\nFunction definitions\\n====================\\n\\nA function definition defines a user-defined function object (see\\nsection *The standard type hierarchy*):\\n\\n   funcdef        ::= [decorators] \"def\" funcname \"(\" [parameter_list] \")\" [\"->\" expression] \":\" suite\\n   decorators     ::= decorator+\\n   decorator      ::= \"@\" dotted_name [\"(\" [parameter_list [\",\"]] \")\"] NEWLINE\\n   dotted_name    ::= identifier (\".\" identifier)*\\n   parameter_list ::= (defparameter \",\")*\\n                      ( \"*\" [parameter] (\",\" defparameter)* [\",\" \"**\" parameter]\\n                      | \"**\" parameter\\n                      | defparameter [\",\"] )\\n   parameter      ::= identifier [\":\" expression]\\n   defparameter   ::= parameter [\"=\" expression]\\n   funcname       ::= identifier\\n\\nA function definition is an executable statement.  Its execution binds\\nthe function name in the current local namespace to a function object\\n(a wrapper around the executable code for the function).  This\\nfunction object contains a reference to the current global namespace\\nas the global namespace to be used when the function is called.\\n\\nThe function definition does not execute the function body; this gets\\nexecuted only when the function is called. [3]\\n\\nA function definition may be wrapped by one or more *decorator*\\nexpressions. Decorator expressions are evaluated when the function is\\ndefined, in the scope that contains the function definition.  The\\nresult must be a callable, which is invoked with the function object\\nas the only argument. The returned value is bound to the function name\\ninstead of the function object.  Multiple decorators are applied in\\nnested fashion. For example, the following code\\n\\n   @f1(arg)\\n   @f2\\n   def func(): pass\\n\\nis equivalent to\\n\\n   def func(): pass\\n   func = f1(arg)(f2(func))\\n\\nWhen one or more *parameters* have the form *parameter* ``=``\\n*expression*, the function is said to have \"default parameter values.\"\\nFor a parameter with a default value, the corresponding *argument* may\\nbe omitted from a call, in which case the parameter\\'s default value is\\nsubstituted.  If a parameter has a default value, all following\\nparameters up until the \"``*``\" must also have a default value ---\\nthis is a syntactic restriction that is not expressed by the grammar.\\n\\n**Default parameter values are evaluated when the function definition\\nis executed.** This means that the expression is evaluated once, when\\nthe function is defined, and that the same \"pre-computed\" value is\\nused for each call.  This is especially important to understand when a\\ndefault parameter is a mutable object, such as a list or a dictionary:\\nif the function modifies the object (e.g. by appending an item to a\\nlist), the default value is in effect modified. This is generally not\\nwhat was intended.  A way around this is to use ``None`` as the\\ndefault, and explicitly test for it in the body of the function, e.g.:\\n\\n   def whats_on_the_telly(penguin=None):\\n       if penguin is None:\\n           penguin = []\\n       penguin.append(\"property of the zoo\")\\n       return penguin\\n\\nFunction call semantics are described in more detail in section\\n*Calls*. A function call always assigns values to all parameters\\nmentioned in the parameter list, either from position arguments, from\\nkeyword arguments, or from default values.  If the form\\n\"``*identifier``\" is present, it is initialized to a tuple receiving\\nany excess positional parameters, defaulting to the empty tuple.  If\\nthe form \"``**identifier``\" is present, it is initialized to a new\\ndictionary receiving any excess keyword arguments, defaulting to a new\\nempty dictionary. Parameters after \"``*``\" or \"``*identifier``\" are\\nkeyword-only parameters and may only be passed used keyword arguments.\\n\\nParameters may have annotations of the form \"``: expression``\"\\nfollowing the parameter name.  Any parameter may have an annotation\\neven those of the form ``*identifier`` or ``**identifier``.  Functions\\nmay have \"return\" annotation of the form \"``-> expression``\" after the\\nparameter list.  These annotations can be any valid Python expression\\nand are evaluated when the function definition is executed.\\nAnnotations may be evaluated in a different order than they appear in\\nthe source code.  The presence of annotations does not change the\\nsemantics of a function.  The annotation values are available as\\nvalues of a dictionary keyed by the parameters\\' names in the\\n``__annotations__`` attribute of the function object.\\n\\nIt is also possible to create anonymous functions (functions not bound\\nto a name), for immediate use in expressions.  This uses lambda forms,\\ndescribed in section *Lambdas*.  Note that the lambda form is merely a\\nshorthand for a simplified function definition; a function defined in\\na \"``def``\" statement can be passed around or assigned to another name\\njust like a function defined by a lambda form.  The \"``def``\" form is\\nactually more powerful since it allows the execution of multiple\\nstatements and annotations.\\n\\n**Programmer\\'s note:** Functions are first-class objects.  A \"``def``\"\\nform executed inside a function definition defines a local function\\nthat can be returned or passed around.  Free variables used in the\\nnested function can access the local variables of the function\\ncontaining the def.  See section *Naming and binding* for details.\\n\\nSee also:\\n\\n   **PEP 3107** - Function Annotations\\n      The original specification for function annotations.\\n\\n\\nClass definitions\\n=================\\n\\nA class definition defines a class object (see section *The standard\\ntype hierarchy*):\\n\\n   classdef    ::= [decorators] \"class\" classname [inheritance] \":\" suite\\n   inheritance ::= \"(\" [parameter_list] \")\"\\n   classname   ::= identifier\\n\\nA class definition is an executable statement.  The inheritance list\\nusually gives a list of base classes (see *Customizing class creation*\\nfor more advanced uses), so each item in the list should evaluate to a\\nclass object which allows subclassing.  Classes without an inheritance\\nlist inherit, by default, from the base class ``object``; hence,\\n\\n   class Foo:\\n       pass\\n\\nis equivalent to\\n\\n   class Foo(object):\\n       pass\\n\\nThe class\\'s suite is then executed in a new execution frame (see\\n*Naming and binding*), using a newly created local namespace and the\\noriginal global namespace. (Usually, the suite contains mostly\\nfunction definitions.)  When the class\\'s suite finishes execution, its\\nexecution frame is discarded but its local namespace is saved. [4] A\\nclass object is then created using the inheritance list for the base\\nclasses and the saved local namespace for the attribute dictionary.\\nThe class name is bound to this class object in the original local\\nnamespace.\\n\\nClass creation can be customized heavily using *metaclasses*.\\n\\nClasses can also be decorated: just like when decorating functions,\\n\\n   @f1(arg)\\n   @f2\\n   class Foo: pass\\n\\nis equivalent to\\n\\n   class Foo: pass\\n   Foo = f1(arg)(f2(Foo))\\n\\nThe evaluation rules for the decorator expressions are the same as for\\nfunction decorators.  The result must be a class object, which is then\\nbound to the class name.\\n\\n**Programmer\\'s note:** Variables defined in the class definition are\\nclass attributes; they are shared by instances.  Instance attributes\\ncan be set in a method with ``self.name = value``.  Both class and\\ninstance attributes are accessible through the notation\\n\"``self.name``\", and an instance attribute hides a class attribute\\nwith the same name when accessed in this way.  Class attributes can be\\nused as defaults for instance attributes, but using mutable values\\nthere can lead to unexpected results.  *Descriptors* can be used to\\ncreate instance variables with different implementation details.\\n\\nSee also:\\n\\n   **PEP 3115** - Metaclasses in Python 3 **PEP 3129** - Class\\n   Decorators\\n\\n-[ Footnotes ]-\\n\\n[1] The exception is propagated to the invocation stack unless there\\n    is a ``finally`` clause which happens to raise another exception.\\n    That new exception causes the old one to be lost.\\n\\n[2] Currently, control \"flows off the end\" except in the case of an\\n    exception or the execution of a ``return``, ``continue``, or\\n    ``break`` statement.\\n\\n[3] A string literal appearing as the first statement in the function\\n    body is transformed into the function\\'s ``__doc__`` attribute and\\n    therefore the function\\'s *docstring*.\\n\\n[4] A string literal appearing as the first statement in the class\\n    body is transformed into the namespace\\'s ``__doc__`` item and\\n    therefore the class\\'s *docstring*.\\n',\n 'context-managers': '\\nWith Statement Context Managers\\n*******************************\\n\\nA *context manager* is an object that defines the runtime context to\\nbe established when executing a ``with`` statement. The context\\nmanager handles the entry into, and the exit from, the desired runtime\\ncontext for the execution of the block of code.  Context managers are\\nnormally invoked using the ``with`` statement (described in section\\n*The with statement*), but can also be used by directly invoking their\\nmethods.\\n\\nTypical uses of context managers include saving and restoring various\\nkinds of global state, locking and unlocking resources, closing opened\\nfiles, etc.\\n\\nFor more information on context managers, see *Context Manager Types*.\\n\\nobject.__enter__(self)\\n\\n   Enter the runtime context related to this object. The ``with``\\n   statement will bind this method\\'s return value to the target(s)\\n   specified in the ``as`` clause of the statement, if any.\\n\\nobject.__exit__(self, exc_type, exc_value, traceback)\\n\\n   Exit the runtime context related to this object. The parameters\\n   describe the exception that caused the context to be exited. If the\\n   context was exited without an exception, all three arguments will\\n   be ``None``.\\n\\n   If an exception is supplied, and the method wishes to suppress the\\n   exception (i.e., prevent it from being propagated), it should\\n   return a true value. Otherwise, the exception will be processed\\n   normally upon exit from this method.\\n\\n   Note that ``__exit__()`` methods should not reraise the passed-in\\n   exception; this is the caller\\'s responsibility.\\n\\nSee also:\\n\\n   **PEP 0343** - The \"with\" statement\\n      The specification, background, and examples for the Python\\n      ``with`` statement.\\n',\n 'continue': '\\nThe ``continue`` statement\\n**************************\\n\\n   continue_stmt ::= \"continue\"\\n\\n``continue`` may only occur syntactically nested in a ``for`` or\\n``while`` loop, but not nested in a function or class definition or\\n``finally`` clause within that loop.  It continues with the next cycle\\nof the nearest enclosing loop.\\n\\nWhen ``continue`` passes control out of a ``try`` statement with a\\n``finally`` clause, that ``finally`` clause is executed before really\\nstarting the next loop cycle.\\n',\n 'conversions': '\\nArithmetic conversions\\n**********************\\n\\nWhen a description of an arithmetic operator below uses the phrase\\n\"the numeric arguments are converted to a common type,\" this means\\nthat the operator implementation for built-in types works that way:\\n\\n* If either argument is a complex number, the other is converted to\\n  complex;\\n\\n* otherwise, if either argument is a floating point number, the other\\n  is converted to floating point;\\n\\n* otherwise, both must be integers and no conversion is necessary.\\n\\nSome additional rules apply for certain operators (e.g., a string left\\nargument to the \\'%\\' operator).  Extensions must define their own\\nconversion behavior.\\n',\n 'customization': '\\nBasic customization\\n*******************\\n\\nobject.__new__(cls[, ...])\\n\\n   Called to create a new instance of class *cls*.  ``__new__()`` is a\\n   static method (special-cased so you need not declare it as such)\\n   that takes the class of which an instance was requested as its\\n   first argument.  The remaining arguments are those passed to the\\n   object constructor expression (the call to the class).  The return\\n   value of ``__new__()`` should be the new object instance (usually\\n   an instance of *cls*).\\n\\n   Typical implementations create a new instance of the class by\\n   invoking the superclass\\'s ``__new__()`` method using\\n   ``super(currentclass, cls).__new__(cls[, ...])`` with appropriate\\n   arguments and then modifying the newly-created instance as\\n   necessary before returning it.\\n\\n   If ``__new__()`` returns an instance of *cls*, then the new\\n   instance\\'s ``__init__()`` method will be invoked like\\n   ``__init__(self[, ...])``, where *self* is the new instance and the\\n   remaining arguments are the same as were passed to ``__new__()``.\\n\\n   If ``__new__()`` does not return an instance of *cls*, then the new\\n   instance\\'s ``__init__()`` method will not be invoked.\\n\\n   ``__new__()`` is intended mainly to allow subclasses of immutable\\n   types (like int, str, or tuple) to customize instance creation.  It\\n   is also commonly overridden in custom metaclasses in order to\\n   customize class creation.\\n\\nobject.__init__(self[, ...])\\n\\n   Called when the instance is created.  The arguments are those\\n   passed to the class constructor expression.  If a base class has an\\n   ``__init__()`` method, the derived class\\'s ``__init__()`` method,\\n   if any, must explicitly call it to ensure proper initialization of\\n   the base class part of the instance; for example:\\n   ``BaseClass.__init__(self, [args...])``.  As a special constraint\\n   on constructors, no value may be returned; doing so will cause a\\n   ``TypeError`` to be raised at runtime.\\n\\nobject.__del__(self)\\n\\n   Called when the instance is about to be destroyed.  This is also\\n   called a destructor.  If a base class has a ``__del__()`` method,\\n   the derived class\\'s ``__del__()`` method, if any, must explicitly\\n   call it to ensure proper deletion of the base class part of the\\n   instance.  Note that it is possible (though not recommended!) for\\n   the ``__del__()`` method to postpone destruction of the instance by\\n   creating a new reference to it.  It may then be called at a later\\n   time when this new reference is deleted.  It is not guaranteed that\\n   ``__del__()`` methods are called for objects that still exist when\\n   the interpreter exits.\\n\\n   Note: ``del x`` doesn\\'t directly call ``x.__del__()`` --- the former\\n     decrements the reference count for ``x`` by one, and the latter\\n     is only called when ``x``\\'s reference count reaches zero.  Some\\n     common situations that may prevent the reference count of an\\n     object from going to zero include: circular references between\\n     objects (e.g., a doubly-linked list or a tree data structure with\\n     parent and child pointers); a reference to the object on the\\n     stack frame of a function that caught an exception (the traceback\\n     stored in ``sys.exc_info()[2]`` keeps the stack frame alive); or\\n     a reference to the object on the stack frame that raised an\\n     unhandled exception in interactive mode (the traceback stored in\\n     ``sys.last_traceback`` keeps the stack frame alive).  The first\\n     situation can only be remedied by explicitly breaking the cycles;\\n     the latter two situations can be resolved by storing ``None`` in\\n     ``sys.last_traceback``. Circular references which are garbage are\\n     detected when the option cycle detector is enabled (it\\'s on by\\n     default), but can only be cleaned up if there are no Python-\\n     level ``__del__()`` methods involved. Refer to the documentation\\n     for the ``gc`` module for more information about how\\n     ``__del__()`` methods are handled by the cycle detector,\\n     particularly the description of the ``garbage`` value.\\n\\n   Warning: Due to the precarious circumstances under which ``__del__()``\\n     methods are invoked, exceptions that occur during their execution\\n     are ignored, and a warning is printed to ``sys.stderr`` instead.\\n     Also, when ``__del__()`` is invoked in response to a module being\\n     deleted (e.g., when execution of the program is done), other\\n     globals referenced by the ``__del__()`` method may already have\\n     been deleted or in the process of being torn down (e.g. the\\n     import machinery shutting down).  For this reason, ``__del__()``\\n     methods should do the absolute minimum needed to maintain\\n     external invariants.  Starting with version 1.5, Python\\n     guarantees that globals whose name begins with a single\\n     underscore are deleted from their module before other globals are\\n     deleted; if no other references to such globals exist, this may\\n     help in assuring that imported modules are still available at the\\n     time when the ``__del__()`` method is called.\\n\\nobject.__repr__(self)\\n\\n   Called by the ``repr()`` built-in function to compute the\\n   \"official\" string representation of an object.  If at all possible,\\n   this should look like a valid Python expression that could be used\\n   to recreate an object with the same value (given an appropriate\\n   environment).  If this is not possible, a string of the form\\n   ``<...some useful description...>`` should be returned. The return\\n   value must be a string object. If a class defines ``__repr__()``\\n   but not ``__str__()``, then ``__repr__()`` is also used when an\\n   \"informal\" string representation of instances of that class is\\n   required.\\n\\n   This is typically used for debugging, so it is important that the\\n   representation is information-rich and unambiguous.\\n\\nobject.__str__(self)\\n\\n   Called by ``str(object)`` and the built-in functions ``format()``\\n   and ``print()`` to compute the \"informal\" or nicely printable\\n   string representation of an object.  The return value must be a\\n   *string* object.\\n\\n   This method differs from ``object.__repr__()`` in that there is no\\n   expectation that ``__str__()`` return a valid Python expression: a\\n   more convenient or concise representation can be used.\\n\\n   The default implementation defined by the built-in type ``object``\\n   calls ``object.__repr__()``.\\n\\nobject.__bytes__(self)\\n\\n   Called by ``bytes()`` to compute a byte-string representation of an\\n   object. This should return a ``bytes`` object.\\n\\nobject.__format__(self, format_spec)\\n\\n   Called by the ``format()`` built-in function (and by extension, the\\n   ``str.format()`` method of class ``str``) to produce a \"formatted\"\\n   string representation of an object. The ``format_spec`` argument is\\n   a string that contains a description of the formatting options\\n   desired. The interpretation of the ``format_spec`` argument is up\\n   to the type implementing ``__format__()``, however most classes\\n   will either delegate formatting to one of the built-in types, or\\n   use a similar formatting option syntax.\\n\\n   See *Format Specification Mini-Language* for a description of the\\n   standard formatting syntax.\\n\\n   The return value must be a string object.\\n\\nobject.__lt__(self, other)\\nobject.__le__(self, other)\\nobject.__eq__(self, other)\\nobject.__ne__(self, other)\\nobject.__gt__(self, other)\\nobject.__ge__(self, other)\\n\\n   These are the so-called \"rich comparison\" methods. The\\n   correspondence between operator symbols and method names is as\\n   follows: ``x<y`` calls ``x.__lt__(y)``, ``x<=y`` calls\\n   ``x.__le__(y)``, ``x==y`` calls ``x.__eq__(y)``, ``x!=y`` calls\\n   ``x.__ne__(y)``, ``x>y`` calls ``x.__gt__(y)``, and ``x>=y`` calls\\n   ``x.__ge__(y)``.\\n\\n   A rich comparison method may return the singleton\\n   ``NotImplemented`` if it does not implement the operation for a\\n   given pair of arguments. By convention, ``False`` and ``True`` are\\n   returned for a successful comparison. However, these methods can\\n   return any value, so if the comparison operator is used in a\\n   Boolean context (e.g., in the condition of an ``if`` statement),\\n   Python will call ``bool()`` on the value to determine if the result\\n   is true or false.\\n\\n   There are no implied relationships among the comparison operators.\\n   The truth of ``x==y`` does not imply that ``x!=y`` is false.\\n   Accordingly, when defining ``__eq__()``, one should also define\\n   ``__ne__()`` so that the operators will behave as expected.  See\\n   the paragraph on ``__hash__()`` for some important notes on\\n   creating *hashable* objects which support custom comparison\\n   operations and are usable as dictionary keys.\\n\\n   There are no swapped-argument versions of these methods (to be used\\n   when the left argument does not support the operation but the right\\n   argument does); rather, ``__lt__()`` and ``__gt__()`` are each\\n   other\\'s reflection, ``__le__()`` and ``__ge__()`` are each other\\'s\\n   reflection, and ``__eq__()`` and ``__ne__()`` are their own\\n   reflection.\\n\\n   Arguments to rich comparison methods are never coerced.\\n\\n   To automatically generate ordering operations from a single root\\n   operation, see ``functools.total_ordering()``.\\n\\nobject.__hash__(self)\\n\\n   Called by built-in function ``hash()`` and for operations on\\n   members of hashed collections including ``set``, ``frozenset``, and\\n   ``dict``.  ``__hash__()`` should return an integer.  The only\\n   required property is that objects which compare equal have the same\\n   hash value; it is advised to somehow mix together (e.g. using\\n   exclusive or) the hash values for the components of the object that\\n   also play a part in comparison of objects.\\n\\n   If a class does not define an ``__eq__()`` method it should not\\n   define a ``__hash__()`` operation either; if it defines\\n   ``__eq__()`` but not ``__hash__()``, its instances will not be\\n   usable as items in hashable collections.  If a class defines\\n   mutable objects and implements an ``__eq__()`` method, it should\\n   not implement ``__hash__()``, since the implementation of hashable\\n   collections requires that a key\\'s hash value is immutable (if the\\n   object\\'s hash value changes, it will be in the wrong hash bucket).\\n\\n   User-defined classes have ``__eq__()`` and ``__hash__()`` methods\\n   by default; with them, all objects compare unequal (except with\\n   themselves) and ``x.__hash__()`` returns an appropriate value such\\n   that ``x == y`` implies both that ``x is y`` and ``hash(x) ==\\n   hash(y)``.\\n\\n   A class that overrides ``__eq__()`` and does not define\\n   ``__hash__()`` will have its ``__hash__()`` implicitly set to\\n   ``None``.  When the ``__hash__()`` method of a class is ``None``,\\n   instances of the class will raise an appropriate ``TypeError`` when\\n   a program attempts to retrieve their hash value, and will also be\\n   correctly identified as unhashable when checking ``isinstance(obj,\\n   collections.Hashable``).\\n\\n   If a class that overrides ``__eq__()`` needs to retain the\\n   implementation of ``__hash__()`` from a parent class, the\\n   interpreter must be told this explicitly by setting ``__hash__ =\\n   <ParentClass>.__hash__``.\\n\\n   If a class that does not override ``__eq__()`` wishes to suppress\\n   hash support, it should include ``__hash__ = None`` in the class\\n   definition. A class which defines its own ``__hash__()`` that\\n   explicitly raises a ``TypeError`` would be incorrectly identified\\n   as hashable by an ``isinstance(obj, collections.Hashable)`` call.\\n\\n   Note: By default, the ``__hash__()`` values of str, bytes and datetime\\n     objects are \"salted\" with an unpredictable random value.\\n     Although they remain constant within an individual Python\\n     process, they are not predictable between repeated invocations of\\n     Python.This is intended to provide protection against a denial-\\n     of-service caused by carefully-chosen inputs that exploit the\\n     worst case performance of a dict insertion, O(n^2) complexity.\\n     See http://www.ocert.org/advisories/ocert-2011-003.html for\\n     details.Changing hash values affects the iteration order of\\n     dicts, sets and other mappings.  Python has never made guarantees\\n     about this ordering (and it typically varies between 32-bit and\\n     64-bit builds).See also ``PYTHONHASHSEED``.\\n\\n   Changed in version 3.3: Hash randomization is enabled by default.\\n\\nobject.__bool__(self)\\n\\n   Called to implement truth value testing and the built-in operation\\n   ``bool()``; should return ``False`` or ``True``.  When this method\\n   is not defined, ``__len__()`` is called, if it is defined, and the\\n   object is considered true if its result is nonzero.  If a class\\n   defines neither ``__len__()`` nor ``__bool__()``, all its instances\\n   are considered true.\\n',\n 'debugger': '\\n``pdb`` --- The Python Debugger\\n*******************************\\n\\nThe module ``pdb`` defines an interactive source code debugger for\\nPython programs.  It supports setting (conditional) breakpoints and\\nsingle stepping at the source line level, inspection of stack frames,\\nsource code listing, and evaluation of arbitrary Python code in the\\ncontext of any stack frame.  It also supports post-mortem debugging\\nand can be called under program control.\\n\\nThe debugger is extensible -- it is actually defined as the class\\n``Pdb``. This is currently undocumented but easily understood by\\nreading the source.  The extension interface uses the modules ``bdb``\\nand ``cmd``.\\n\\nThe debugger\\'s prompt is ``(Pdb)``. Typical usage to run a program\\nunder control of the debugger is:\\n\\n   >>> import pdb\\n   >>> import mymodule\\n   >>> pdb.run(\\'mymodule.test()\\')\\n   > <string>(0)?()\\n   (Pdb) continue\\n   > <string>(1)?()\\n   (Pdb) continue\\n   NameError: \\'spam\\'\\n   > <string>(1)?()\\n   (Pdb)\\n\\nChanged in version 3.3: Tab-completion via the ``readline`` module is\\navailable for commands and command arguments, e.g. the current global\\nand local names are offered as arguments of the ``print`` command.\\n\\n``pdb.py`` can also be invoked as a script to debug other scripts.\\nFor example:\\n\\n   python3 -m pdb myscript.py\\n\\nWhen invoked as a script, pdb will automatically enter post-mortem\\ndebugging if the program being debugged exits abnormally.  After post-\\nmortem debugging (or after normal exit of the program), pdb will\\nrestart the program.  Automatic restarting preserves pdb\\'s state (such\\nas breakpoints) and in most cases is more useful than quitting the\\ndebugger upon program\\'s exit.\\n\\nNew in version 3.2: ``pdb.py`` now accepts a ``-c`` option that\\nexecutes commands as if given in a ``.pdbrc`` file, see *Debugger\\nCommands*.\\n\\nThe typical usage to break into the debugger from a running program is\\nto insert\\n\\n   import pdb; pdb.set_trace()\\n\\nat the location you want to break into the debugger.  You can then\\nstep through the code following this statement, and continue running\\nwithout the debugger using the ``continue`` command.\\n\\nThe typical usage to inspect a crashed program is:\\n\\n   >>> import pdb\\n   >>> import mymodule\\n   >>> mymodule.test()\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 1, in ?\\n     File \"./mymodule.py\", line 4, in test\\n       test2()\\n     File \"./mymodule.py\", line 3, in test2\\n       print(spam)\\n   NameError: spam\\n   >>> pdb.pm()\\n   > ./mymodule.py(3)test2()\\n   -> print(spam)\\n   (Pdb)\\n\\nThe module defines the following functions; each enters the debugger\\nin a slightly different way:\\n\\npdb.run(statement, globals=None, locals=None)\\n\\n   Execute the *statement* (given as a string or a code object) under\\n   debugger control.  The debugger prompt appears before any code is\\n   executed; you can set breakpoints and type ``continue``, or you can\\n   step through the statement using ``step`` or ``next`` (all these\\n   commands are explained below).  The optional *globals* and *locals*\\n   arguments specify the environment in which the code is executed; by\\n   default the dictionary of the module ``__main__`` is used.  (See\\n   the explanation of the built-in ``exec()`` or ``eval()``\\n   functions.)\\n\\npdb.runeval(expression, globals=None, locals=None)\\n\\n   Evaluate the *expression* (given as a string or a code object)\\n   under debugger control.  When ``runeval()`` returns, it returns the\\n   value of the expression.  Otherwise this function is similar to\\n   ``run()``.\\n\\npdb.runcall(function, *args, **kwds)\\n\\n   Call the *function* (a function or method object, not a string)\\n   with the given arguments.  When ``runcall()`` returns, it returns\\n   whatever the function call returned.  The debugger prompt appears\\n   as soon as the function is entered.\\n\\npdb.set_trace()\\n\\n   Enter the debugger at the calling stack frame.  This is useful to\\n   hard-code a breakpoint at a given point in a program, even if the\\n   code is not otherwise being debugged (e.g. when an assertion\\n   fails).\\n\\npdb.post_mortem(traceback=None)\\n\\n   Enter post-mortem debugging of the given *traceback* object.  If no\\n   *traceback* is given, it uses the one of the exception that is\\n   currently being handled (an exception must be being handled if the\\n   default is to be used).\\n\\npdb.pm()\\n\\n   Enter post-mortem debugging of the traceback found in\\n   ``sys.last_traceback``.\\n\\nThe ``run*`` functions and ``set_trace()`` are aliases for\\ninstantiating the ``Pdb`` class and calling the method of the same\\nname.  If you want to access further features, you have to do this\\nyourself:\\n\\nclass class pdb.Pdb(completekey=\\'tab\\', stdin=None, stdout=None, skip=None, nosigint=False)\\n\\n   ``Pdb`` is the debugger class.\\n\\n   The *completekey*, *stdin* and *stdout* arguments are passed to the\\n   underlying ``cmd.Cmd`` class; see the description there.\\n\\n   The *skip* argument, if given, must be an iterable of glob-style\\n   module name patterns.  The debugger will not step into frames that\\n   originate in a module that matches one of these patterns. [1]\\n\\n   By default, Pdb sets a handler for the SIGINT signal (which is sent\\n   when the user presses Ctrl-C on the console) when you give a\\n   ``continue`` command. This allows you to break into the debugger\\n   again by pressing Ctrl-C.  If you want Pdb not to touch the SIGINT\\n   handler, set *nosigint* tot true.\\n\\n   Example call to enable tracing with *skip*:\\n\\n      import pdb; pdb.Pdb(skip=[\\'django.*\\']).set_trace()\\n\\n   New in version 3.1: The *skip* argument.\\n\\n   New in version 3.2: The *nosigint* argument.  Previously, a SIGINT\\n   handler was never set by Pdb.\\n\\n   run(statement, globals=None, locals=None)\\n   runeval(expression, globals=None, locals=None)\\n   runcall(function, *args, **kwds)\\n   set_trace()\\n\\n      See the documentation for the functions explained above.\\n\\n\\nDebugger Commands\\n=================\\n\\nThe commands recognized by the debugger are listed below.  Most\\ncommands can be abbreviated to one or two letters as indicated; e.g.\\n``h(elp)`` means that either ``h`` or ``help`` can be used to enter\\nthe help command (but not ``he`` or ``hel``, nor ``H`` or ``Help`` or\\n``HELP``).  Arguments to commands must be separated by whitespace\\n(spaces or tabs).  Optional arguments are enclosed in square brackets\\n(``[]``) in the command syntax; the square brackets must not be typed.\\nAlternatives in the command syntax are separated by a vertical bar\\n(``|``).\\n\\nEntering a blank line repeats the last command entered.  Exception: if\\nthe last command was a ``list`` command, the next 11 lines are listed.\\n\\nCommands that the debugger doesn\\'t recognize are assumed to be Python\\nstatements and are executed in the context of the program being\\ndebugged.  Python statements can also be prefixed with an exclamation\\npoint (``!``).  This is a powerful way to inspect the program being\\ndebugged; it is even possible to change a variable or call a function.\\nWhen an exception occurs in such a statement, the exception name is\\nprinted but the debugger\\'s state is not changed.\\n\\nThe debugger supports *aliases*.  Aliases can have parameters which\\nallows one a certain level of adaptability to the context under\\nexamination.\\n\\nMultiple commands may be entered on a single line, separated by\\n``;;``.  (A single ``;`` is not used as it is the separator for\\nmultiple commands in a line that is passed to the Python parser.)  No\\nintelligence is applied to separating the commands; the input is split\\nat the first ``;;`` pair, even if it is in the middle of a quoted\\nstring.\\n\\nIf a file ``.pdbrc`` exists in the user\\'s home directory or in the\\ncurrent directory, it is read in and executed as if it had been typed\\nat the debugger prompt.  This is particularly useful for aliases.  If\\nboth files exist, the one in the home directory is read first and\\naliases defined there can be overridden by the local file.\\n\\nChanged in version 3.2: ``.pdbrc`` can now contain commands that\\ncontinue debugging, such as ``continue`` or ``next``.  Previously,\\nthese commands had no effect.\\n\\nh(elp) [command]\\n\\n   Without argument, print the list of available commands.  With a\\n   *command* as argument, print help about that command.  ``help pdb``\\n   displays the full documentation (the docstring of the ``pdb``\\n   module).  Since the *command* argument must be an identifier,\\n   ``help exec`` must be entered to get help on the ``!`` command.\\n\\nw(here)\\n\\n   Print a stack trace, with the most recent frame at the bottom.  An\\n   arrow indicates the current frame, which determines the context of\\n   most commands.\\n\\nd(own) [count]\\n\\n   Move the current frame *count* (default one) levels down in the\\n   stack trace (to a newer frame).\\n\\nu(p) [count]\\n\\n   Move the current frame *count* (default one) levels up in the stack\\n   trace (to an older frame).\\n\\nb(reak) [([filename:]lineno | function) [, condition]]\\n\\n   With a *lineno* argument, set a break there in the current file.\\n   With a *function* argument, set a break at the first executable\\n   statement within that function.  The line number may be prefixed\\n   with a filename and a colon, to specify a breakpoint in another\\n   file (probably one that hasn\\'t been loaded yet).  The file is\\n   searched on ``sys.path``.  Note that each breakpoint is assigned a\\n   number to which all the other breakpoint commands refer.\\n\\n   If a second argument is present, it is an expression which must\\n   evaluate to true before the breakpoint is honored.\\n\\n   Without argument, list all breaks, including for each breakpoint,\\n   the number of times that breakpoint has been hit, the current\\n   ignore count, and the associated condition if any.\\n\\ntbreak [([filename:]lineno | function) [, condition]]\\n\\n   Temporary breakpoint, which is removed automatically when it is\\n   first hit. The arguments are the same as for ``break``.\\n\\ncl(ear) [filename:lineno | bpnumber [bpnumber ...]]\\n\\n   With a *filename:lineno* argument, clear all the breakpoints at\\n   this line. With a space separated list of breakpoint numbers, clear\\n   those breakpoints. Without argument, clear all breaks (but first\\n   ask confirmation).\\n\\ndisable [bpnumber [bpnumber ...]]\\n\\n   Disable the breakpoints given as a space separated list of\\n   breakpoint numbers.  Disabling a breakpoint means it cannot cause\\n   the program to stop execution, but unlike clearing a breakpoint, it\\n   remains in the list of breakpoints and can be (re-)enabled.\\n\\nenable [bpnumber [bpnumber ...]]\\n\\n   Enable the breakpoints specified.\\n\\nignore bpnumber [count]\\n\\n   Set the ignore count for the given breakpoint number.  If count is\\n   omitted, the ignore count is set to 0.  A breakpoint becomes active\\n   when the ignore count is zero.  When non-zero, the count is\\n   decremented each time the breakpoint is reached and the breakpoint\\n   is not disabled and any associated condition evaluates to true.\\n\\ncondition bpnumber [condition]\\n\\n   Set a new *condition* for the breakpoint, an expression which must\\n   evaluate to true before the breakpoint is honored.  If *condition*\\n   is absent, any existing condition is removed; i.e., the breakpoint\\n   is made unconditional.\\n\\ncommands [bpnumber]\\n\\n   Specify a list of commands for breakpoint number *bpnumber*.  The\\n   commands themselves appear on the following lines.  Type a line\\n   containing just ``end`` to terminate the commands. An example:\\n\\n      (Pdb) commands 1\\n      (com) print some_variable\\n      (com) end\\n      (Pdb)\\n\\n   To remove all commands from a breakpoint, type commands and follow\\n   it immediately with ``end``; that is, give no commands.\\n\\n   With no *bpnumber* argument, commands refers to the last breakpoint\\n   set.\\n\\n   You can use breakpoint commands to start your program up again.\\n   Simply use the continue command, or step, or any other command that\\n   resumes execution.\\n\\n   Specifying any command resuming execution (currently continue,\\n   step, next, return, jump, quit and their abbreviations) terminates\\n   the command list (as if that command was immediately followed by\\n   end). This is because any time you resume execution (even with a\\n   simple next or step), you may encounter another breakpoint--which\\n   could have its own command list, leading to ambiguities about which\\n   list to execute.\\n\\n   If you use the \\'silent\\' command in the command list, the usual\\n   message about stopping at a breakpoint is not printed.  This may be\\n   desirable for breakpoints that are to print a specific message and\\n   then continue.  If none of the other commands print anything, you\\n   see no sign that the breakpoint was reached.\\n\\ns(tep)\\n\\n   Execute the current line, stop at the first possible occasion\\n   (either in a function that is called or on the next line in the\\n   current function).\\n\\nn(ext)\\n\\n   Continue execution until the next line in the current function is\\n   reached or it returns.  (The difference between ``next`` and\\n   ``step`` is that ``step`` stops inside a called function, while\\n   ``next`` executes called functions at (nearly) full speed, only\\n   stopping at the next line in the current function.)\\n\\nunt(il) [lineno]\\n\\n   Without argument, continue execution until the line with a number\\n   greater than the current one is reached.\\n\\n   With a line number, continue execution until a line with a number\\n   greater or equal to that is reached.  In both cases, also stop when\\n   the current frame returns.\\n\\n   Changed in version 3.2: Allow giving an explicit line number.\\n\\nr(eturn)\\n\\n   Continue execution until the current function returns.\\n\\nc(ont(inue))\\n\\n   Continue execution, only stop when a breakpoint is encountered.\\n\\nj(ump) lineno\\n\\n   Set the next line that will be executed.  Only available in the\\n   bottom-most frame.  This lets you jump back and execute code again,\\n   or jump forward to skip code that you don\\'t want to run.\\n\\n   It should be noted that not all jumps are allowed -- for instance\\n   it is not possible to jump into the middle of a ``for`` loop or out\\n   of a ``finally`` clause.\\n\\nl(ist) [first[, last]]\\n\\n   List source code for the current file.  Without arguments, list 11\\n   lines around the current line or continue the previous listing.\\n   With ``.`` as argument, list 11 lines around the current line.\\n   With one argument, list 11 lines around at that line.  With two\\n   arguments, list the given range; if the second argument is less\\n   than the first, it is interpreted as a count.\\n\\n   The current line in the current frame is indicated by ``->``.  If\\n   an exception is being debugged, the line where the exception was\\n   originally raised or propagated is indicated by ``>>``, if it\\n   differs from the current line.\\n\\n   New in version 3.2: The ``>>`` marker.\\n\\nll | longlist\\n\\n   List all source code for the current function or frame.\\n   Interesting lines are marked as for ``list``.\\n\\n   New in version 3.2.\\n\\na(rgs)\\n\\n   Print the argument list of the current function.\\n\\np(rint) expression\\n\\n   Evaluate the *expression* in the current context and print its\\n   value.\\n\\npp expression\\n\\n   Like the ``print`` command, except the value of the expression is\\n   pretty-printed using the ``pprint`` module.\\n\\nwhatis expression\\n\\n   Print the type of the *expression*.\\n\\nsource expression\\n\\n   Try to get source code for the given object and display it.\\n\\n   New in version 3.2.\\n\\ndisplay [expression]\\n\\n   Display the value of the expression if it changed, each time\\n   execution stops in the current frame.\\n\\n   Without expression, list all display expressions for the current\\n   frame.\\n\\n   New in version 3.2.\\n\\nundisplay [expression]\\n\\n   Do not display the expression any more in the current frame.\\n   Without expression, clear all display expressions for the current\\n   frame.\\n\\n   New in version 3.2.\\n\\ninteract\\n\\n   Start an interative interpreter (using the ``code`` module) whose\\n   global namespace contains all the (global and local) names found in\\n   the current scope.\\n\\n   New in version 3.2.\\n\\nalias [name [command]]\\n\\n   Create an alias called *name* that executes *command*.  The command\\n   must *not* be enclosed in quotes.  Replaceable parameters can be\\n   indicated by ``%1``, ``%2``, and so on, while ``%*`` is replaced by\\n   all the parameters. If no command is given, the current alias for\\n   *name* is shown. If no arguments are given, all aliases are listed.\\n\\n   Aliases may be nested and can contain anything that can be legally\\n   typed at the pdb prompt.  Note that internal pdb commands *can* be\\n   overridden by aliases.  Such a command is then hidden until the\\n   alias is removed.  Aliasing is recursively applied to the first\\n   word of the command line; all other words in the line are left\\n   alone.\\n\\n   As an example, here are two useful aliases (especially when placed\\n   in the ``.pdbrc`` file):\\n\\n      # Print instance variables (usage \"pi classInst\")\\n      alias pi for k in %1.__dict__.keys(): print(\"%1.\",k,\"=\",%1.__dict__[k])\\n      # Print instance variables in self\\n      alias ps pi self\\n\\nunalias name\\n\\n   Delete the specified alias.\\n\\n! statement\\n\\n   Execute the (one-line) *statement* in the context of the current\\n   stack frame. The exclamation point can be omitted unless the first\\n   word of the statement resembles a debugger command.  To set a\\n   global variable, you can prefix the assignment command with a\\n   ``global`` statement on the same line, e.g.:\\n\\n      (Pdb) global list_options; list_options = [\\'-l\\']\\n      (Pdb)\\n\\nrun [args ...]\\nrestart [args ...]\\n\\n   Restart the debugged Python program.  If an argument is supplied,\\n   it is split with ``shlex`` and the result is used as the new\\n   ``sys.argv``. History, breakpoints, actions and debugger options\\n   are preserved. ``restart`` is an alias for ``run``.\\n\\nq(uit)\\n\\n   Quit from the debugger.  The program being executed is aborted.\\n\\n-[ Footnotes ]-\\n\\n[1] Whether a frame is considered to originate in a certain module is\\n    determined by the ``__name__`` in the frame globals.\\n',\n 'del': '\\nThe ``del`` statement\\n*********************\\n\\n   del_stmt ::= \"del\" target_list\\n\\nDeletion is recursively defined very similar to the way assignment is\\ndefined. Rather than spelling it out in full details, here are some\\nhints.\\n\\nDeletion of a target list recursively deletes each target, from left\\nto right.\\n\\nDeletion of a name removes the binding of that name from the local or\\nglobal namespace, depending on whether the name occurs in a ``global``\\nstatement in the same code block.  If the name is unbound, a\\n``NameError`` exception will be raised.\\n\\nDeletion of attribute references, subscriptions and slicings is passed\\nto the primary object involved; deletion of a slicing is in general\\nequivalent to assignment of an empty slice of the right type (but even\\nthis is determined by the sliced object).\\n\\nChanged in version 3.2: Previously it was illegal to delete a name\\nfrom the local namespace if it occurs as a free variable in a nested\\nblock.\\n',\n 'dict': '\\nDictionary displays\\n*******************\\n\\nA dictionary display is a possibly empty series of key/datum pairs\\nenclosed in curly braces:\\n\\n   dict_display       ::= \"{\" [key_datum_list | dict_comprehension] \"}\"\\n   key_datum_list     ::= key_datum (\",\" key_datum)* [\",\"]\\n   key_datum          ::= expression \":\" expression\\n   dict_comprehension ::= expression \":\" expression comp_for\\n\\nA dictionary display yields a new dictionary object.\\n\\nIf a comma-separated sequence of key/datum pairs is given, they are\\nevaluated from left to right to define the entries of the dictionary:\\neach key object is used as a key into the dictionary to store the\\ncorresponding datum.  This means that you can specify the same key\\nmultiple times in the key/datum list, and the final dictionary\\'s value\\nfor that key will be the last one given.\\n\\nA dict comprehension, in contrast to list and set comprehensions,\\nneeds two expressions separated with a colon followed by the usual\\n\"for\" and \"if\" clauses. When the comprehension is run, the resulting\\nkey and value elements are inserted in the new dictionary in the order\\nthey are produced.\\n\\nRestrictions on the types of the key values are listed earlier in\\nsection *The standard type hierarchy*.  (To summarize, the key type\\nshould be *hashable*, which excludes all mutable objects.)  Clashes\\nbetween duplicate keys are not detected; the last datum (textually\\nrightmost in the display) stored for a given key value prevails.\\n',\n 'dynamic-features': '\\nInteraction with dynamic features\\n*********************************\\n\\nThere are several cases where Python statements are illegal when used\\nin conjunction with nested scopes that contain free variables.\\n\\nIf a variable is referenced in an enclosing scope, it is illegal to\\ndelete the name.  An error will be reported at compile time.\\n\\nIf the wild card form of import --- ``import *`` --- is used in a\\nfunction and the function contains or is a nested block with free\\nvariables, the compiler will raise a ``SyntaxError``.\\n\\nThe ``eval()`` and ``exec()`` functions do not have access to the full\\nenvironment for resolving names.  Names may be resolved in the local\\nand global namespaces of the caller.  Free variables are not resolved\\nin the nearest enclosing namespace, but in the global namespace.  [1]\\nThe ``exec()`` and ``eval()`` functions have optional arguments to\\noverride the global and local namespace.  If only one namespace is\\nspecified, it is used for both.\\n',\n 'else': '\\nThe ``if`` statement\\n********************\\n\\nThe ``if`` statement is used for conditional execution:\\n\\n   if_stmt ::= \"if\" expression \":\" suite\\n               ( \"elif\" expression \":\" suite )*\\n               [\"else\" \":\" suite]\\n\\nIt selects exactly one of the suites by evaluating the expressions one\\nby one until one is found to be true (see section *Boolean operations*\\nfor the definition of true and false); then that suite is executed\\n(and no other part of the ``if`` statement is executed or evaluated).\\nIf all expressions are false, the suite of the ``else`` clause, if\\npresent, is executed.\\n',\n 'exceptions': '\\nExceptions\\n**********\\n\\nExceptions are a means of breaking out of the normal flow of control\\nof a code block in order to handle errors or other exceptional\\nconditions.  An exception is *raised* at the point where the error is\\ndetected; it may be *handled* by the surrounding code block or by any\\ncode block that directly or indirectly invoked the code block where\\nthe error occurred.\\n\\nThe Python interpreter raises an exception when it detects a run-time\\nerror (such as division by zero).  A Python program can also\\nexplicitly raise an exception with the ``raise`` statement. Exception\\nhandlers are specified with the ``try`` ... ``except`` statement.  The\\n``finally`` clause of such a statement can be used to specify cleanup\\ncode which does not handle the exception, but is executed whether an\\nexception occurred or not in the preceding code.\\n\\nPython uses the \"termination\" model of error handling: an exception\\nhandler can find out what happened and continue execution at an outer\\nlevel, but it cannot repair the cause of the error and retry the\\nfailing operation (except by re-entering the offending piece of code\\nfrom the top).\\n\\nWhen an exception is not handled at all, the interpreter terminates\\nexecution of the program, or returns to its interactive main loop.  In\\neither case, it prints a stack backtrace, except when the exception is\\n``SystemExit``.\\n\\nExceptions are identified by class instances.  The ``except`` clause\\nis selected depending on the class of the instance: it must reference\\nthe class of the instance or a base class thereof.  The instance can\\nbe received by the handler and can carry additional information about\\nthe exceptional condition.\\n\\nNote: Exception messages are not part of the Python API.  Their contents\\n  may change from one version of Python to the next without warning\\n  and should not be relied on by code which will run under multiple\\n  versions of the interpreter.\\n\\nSee also the description of the ``try`` statement in section *The try\\nstatement* and ``raise`` statement in section *The raise statement*.\\n\\n-[ Footnotes ]-\\n\\n[1] This limitation occurs because the code that is executed by these\\n    operations is not available at the time the module is compiled.\\n',\n 'execmodel': '\\nExecution model\\n***************\\n\\n\\nNaming and binding\\n==================\\n\\n*Names* refer to objects.  Names are introduced by name binding\\noperations. Each occurrence of a name in the program text refers to\\nthe *binding* of that name established in the innermost function block\\ncontaining the use.\\n\\nA *block* is a piece of Python program text that is executed as a\\nunit. The following are blocks: a module, a function body, and a class\\ndefinition. Each command typed interactively is a block.  A script\\nfile (a file given as standard input to the interpreter or specified\\non the interpreter command line the first argument) is a code block.\\nA script command (a command specified on the interpreter command line\\nwith the \\'**-c**\\' option) is a code block.  The string argument passed\\nto the built-in functions ``eval()`` and ``exec()`` is a code block.\\n\\nA code block is executed in an *execution frame*.  A frame contains\\nsome administrative information (used for debugging) and determines\\nwhere and how execution continues after the code block\\'s execution has\\ncompleted.\\n\\nA *scope* defines the visibility of a name within a block.  If a local\\nvariable is defined in a block, its scope includes that block.  If the\\ndefinition occurs in a function block, the scope extends to any blocks\\ncontained within the defining one, unless a contained block introduces\\na different binding for the name.  The scope of names defined in a\\nclass block is limited to the class block; it does not extend to the\\ncode blocks of methods -- this includes comprehensions and generator\\nexpressions since they are implemented using a function scope.  This\\nmeans that the following will fail:\\n\\n   class A:\\n       a = 42\\n       b = list(a + i for i in range(10))\\n\\nWhen a name is used in a code block, it is resolved using the nearest\\nenclosing scope.  The set of all such scopes visible to a code block\\nis called the block\\'s *environment*.\\n\\nIf a name is bound in a block, it is a local variable of that block,\\nunless declared as ``nonlocal``.  If a name is bound at the module\\nlevel, it is a global variable.  (The variables of the module code\\nblock are local and global.)  If a variable is used in a code block\\nbut not defined there, it is a *free variable*.\\n\\nWhen a name is not found at all, a ``NameError`` exception is raised.\\nIf the name refers to a local variable that has not been bound, a\\n``UnboundLocalError`` exception is raised.  ``UnboundLocalError`` is a\\nsubclass of ``NameError``.\\n\\nThe following constructs bind names: formal parameters to functions,\\n``import`` statements, class and function definitions (these bind the\\nclass or function name in the defining block), and targets that are\\nidentifiers if occurring in an assignment, ``for`` loop header, or\\nafter ``as`` in a ``with`` statement or ``except`` clause. The\\n``import`` statement of the form ``from ... import *`` binds all names\\ndefined in the imported module, except those beginning with an\\nunderscore.  This form may only be used at the module level.\\n\\nA target occurring in a ``del`` statement is also considered bound for\\nthis purpose (though the actual semantics are to unbind the name).\\n\\nEach assignment or import statement occurs within a block defined by a\\nclass or function definition or at the module level (the top-level\\ncode block).\\n\\nIf a name binding operation occurs anywhere within a code block, all\\nuses of the name within the block are treated as references to the\\ncurrent block.  This can lead to errors when a name is used within a\\nblock before it is bound.  This rule is subtle.  Python lacks\\ndeclarations and allows name binding operations to occur anywhere\\nwithin a code block.  The local variables of a code block can be\\ndetermined by scanning the entire text of the block for name binding\\noperations.\\n\\nIf the ``global`` statement occurs within a block, all uses of the\\nname specified in the statement refer to the binding of that name in\\nthe top-level namespace.  Names are resolved in the top-level\\nnamespace by searching the global namespace, i.e. the namespace of the\\nmodule containing the code block, and the builtins namespace, the\\nnamespace of the module ``builtins``.  The global namespace is\\nsearched first.  If the name is not found there, the builtins\\nnamespace is searched.  The global statement must precede all uses of\\nthe name.\\n\\nThe builtins namespace associated with the execution of a code block\\nis actually found by looking up the name ``__builtins__`` in its\\nglobal namespace; this should be a dictionary or a module (in the\\nlatter case the module\\'s dictionary is used).  By default, when in the\\n``__main__`` module, ``__builtins__`` is the built-in module\\n``builtins``; when in any other module, ``__builtins__`` is an alias\\nfor the dictionary of the ``builtins`` module itself.\\n``__builtins__`` can be set to a user-created dictionary to create a\\nweak form of restricted execution.\\n\\n**CPython implementation detail:** Users should not touch\\n``__builtins__``; it is strictly an implementation detail.  Users\\nwanting to override values in the builtins namespace should ``import``\\nthe ``builtins`` module and modify its attributes appropriately.\\n\\nThe namespace for a module is automatically created the first time a\\nmodule is imported.  The main module for a script is always called\\n``__main__``.\\n\\nThe ``global`` statement has the same scope as a name binding\\noperation in the same block.  If the nearest enclosing scope for a\\nfree variable contains a global statement, the free variable is\\ntreated as a global.\\n\\nA class definition is an executable statement that may use and define\\nnames. These references follow the normal rules for name resolution.\\nThe namespace of the class definition becomes the attribute dictionary\\nof the class.  Names defined at the class scope are not visible in\\nmethods.\\n\\n\\nInteraction with dynamic features\\n---------------------------------\\n\\nThere are several cases where Python statements are illegal when used\\nin conjunction with nested scopes that contain free variables.\\n\\nIf a variable is referenced in an enclosing scope, it is illegal to\\ndelete the name.  An error will be reported at compile time.\\n\\nIf the wild card form of import --- ``import *`` --- is used in a\\nfunction and the function contains or is a nested block with free\\nvariables, the compiler will raise a ``SyntaxError``.\\n\\nThe ``eval()`` and ``exec()`` functions do not have access to the full\\nenvironment for resolving names.  Names may be resolved in the local\\nand global namespaces of the caller.  Free variables are not resolved\\nin the nearest enclosing namespace, but in the global namespace.  [1]\\nThe ``exec()`` and ``eval()`` functions have optional arguments to\\noverride the global and local namespace.  If only one namespace is\\nspecified, it is used for both.\\n\\n\\nExceptions\\n==========\\n\\nExceptions are a means of breaking out of the normal flow of control\\nof a code block in order to handle errors or other exceptional\\nconditions.  An exception is *raised* at the point where the error is\\ndetected; it may be *handled* by the surrounding code block or by any\\ncode block that directly or indirectly invoked the code block where\\nthe error occurred.\\n\\nThe Python interpreter raises an exception when it detects a run-time\\nerror (such as division by zero).  A Python program can also\\nexplicitly raise an exception with the ``raise`` statement. Exception\\nhandlers are specified with the ``try`` ... ``except`` statement.  The\\n``finally`` clause of such a statement can be used to specify cleanup\\ncode which does not handle the exception, but is executed whether an\\nexception occurred or not in the preceding code.\\n\\nPython uses the \"termination\" model of error handling: an exception\\nhandler can find out what happened and continue execution at an outer\\nlevel, but it cannot repair the cause of the error and retry the\\nfailing operation (except by re-entering the offending piece of code\\nfrom the top).\\n\\nWhen an exception is not handled at all, the interpreter terminates\\nexecution of the program, or returns to its interactive main loop.  In\\neither case, it prints a stack backtrace, except when the exception is\\n``SystemExit``.\\n\\nExceptions are identified by class instances.  The ``except`` clause\\nis selected depending on the class of the instance: it must reference\\nthe class of the instance or a base class thereof.  The instance can\\nbe received by the handler and can carry additional information about\\nthe exceptional condition.\\n\\nNote: Exception messages are not part of the Python API.  Their contents\\n  may change from one version of Python to the next without warning\\n  and should not be relied on by code which will run under multiple\\n  versions of the interpreter.\\n\\nSee also the description of the ``try`` statement in section *The try\\nstatement* and ``raise`` statement in section *The raise statement*.\\n\\n-[ Footnotes ]-\\n\\n[1] This limitation occurs because the code that is executed by these\\n    operations is not available at the time the module is compiled.\\n',\n 'exprlists': '\\nExpression lists\\n****************\\n\\n   expression_list ::= expression ( \",\" expression )* [\",\"]\\n\\nAn expression list containing at least one comma yields a tuple.  The\\nlength of the tuple is the number of expressions in the list.  The\\nexpressions are evaluated from left to right.\\n\\nThe trailing comma is required only to create a single tuple (a.k.a. a\\n*singleton*); it is optional in all other cases.  A single expression\\nwithout a trailing comma doesn\\'t create a tuple, but rather yields the\\nvalue of that expression. (To create an empty tuple, use an empty pair\\nof parentheses: ``()``.)\\n',\n 'floating': '\\nFloating point literals\\n***********************\\n\\nFloating point literals are described by the following lexical\\ndefinitions:\\n\\n   floatnumber   ::= pointfloat | exponentfloat\\n   pointfloat    ::= [intpart] fraction | intpart \".\"\\n   exponentfloat ::= (intpart | pointfloat) exponent\\n   intpart       ::= digit+\\n   fraction      ::= \".\" digit+\\n   exponent      ::= (\"e\" | \"E\") [\"+\" | \"-\"] digit+\\n\\nNote that the integer and exponent parts are always interpreted using\\nradix 10. For example, ``077e010`` is legal, and denotes the same\\nnumber as ``77e10``. The allowed range of floating point literals is\\nimplementation-dependent. Some examples of floating point literals:\\n\\n   3.14    10.    .001    1e100    3.14e-10    0e0\\n\\nNote that numeric literals do not include a sign; a phrase like ``-1``\\nis actually an expression composed of the unary operator ``-`` and the\\nliteral ``1``.\\n',\n 'for': '\\nThe ``for`` statement\\n*********************\\n\\nThe ``for`` statement is used to iterate over the elements of a\\nsequence (such as a string, tuple or list) or other iterable object:\\n\\n   for_stmt ::= \"for\" target_list \"in\" expression_list \":\" suite\\n                [\"else\" \":\" suite]\\n\\nThe expression list is evaluated once; it should yield an iterable\\nobject.  An iterator is created for the result of the\\n``expression_list``.  The suite is then executed once for each item\\nprovided by the iterator, in the order of ascending indices.  Each\\nitem in turn is assigned to the target list using the standard rules\\nfor assignments (see *Assignment statements*), and then the suite is\\nexecuted.  When the items are exhausted (which is immediately when the\\nsequence is empty or an iterator raises a ``StopIteration``\\nexception), the suite in the ``else`` clause, if present, is executed,\\nand the loop terminates.\\n\\nA ``break`` statement executed in the first suite terminates the loop\\nwithout executing the ``else`` clause\\'s suite.  A ``continue``\\nstatement executed in the first suite skips the rest of the suite and\\ncontinues with the next item, or with the ``else`` clause if there was\\nno next item.\\n\\nThe suite may assign to the variable(s) in the target list; this does\\nnot affect the next item assigned to it.\\n\\nNames in the target list are not deleted when the loop is finished,\\nbut if the sequence is empty, it will not have been assigned to at all\\nby the loop.  Hint: the built-in function ``range()`` returns an\\niterator of integers suitable to emulate the effect of Pascal\\'s ``for\\ni := a to b do``; e.g., ``list(range(3))`` returns the list ``[0, 1,\\n2]``.\\n\\nNote: There is a subtlety when the sequence is being modified by the loop\\n  (this can only occur for mutable sequences, i.e. lists).  An\\n  internal counter is used to keep track of which item is used next,\\n  and this is incremented on each iteration.  When this counter has\\n  reached the length of the sequence the loop terminates.  This means\\n  that if the suite deletes the current (or a previous) item from the\\n  sequence, the next item will be skipped (since it gets the index of\\n  the current item which has already been treated).  Likewise, if the\\n  suite inserts an item in the sequence before the current item, the\\n  current item will be treated again the next time through the loop.\\n  This can lead to nasty bugs that can be avoided by making a\\n  temporary copy using a slice of the whole sequence, e.g.,\\n\\n     for x in a[:]:\\n         if x < 0: a.remove(x)\\n',\n 'formatstrings': '\\nFormat String Syntax\\n********************\\n\\nThe ``str.format()`` method and the ``Formatter`` class share the same\\nsyntax for format strings (although in the case of ``Formatter``,\\nsubclasses can define their own format string syntax).\\n\\nFormat strings contain \"replacement fields\" surrounded by curly braces\\n``{}``. Anything that is not contained in braces is considered literal\\ntext, which is copied unchanged to the output.  If you need to include\\na brace character in the literal text, it can be escaped by doubling:\\n``{{`` and ``}}``.\\n\\nThe grammar for a replacement field is as follows:\\n\\n      replacement_field ::= \"{\" [field_name] [\"!\" conversion] [\":\" format_spec] \"}\"\\n      field_name        ::= arg_name (\".\" attribute_name | \"[\" element_index \"]\")*\\n      arg_name          ::= [identifier | integer]\\n      attribute_name    ::= identifier\\n      element_index     ::= integer | index_string\\n      index_string      ::= <any source character except \"]\"> +\\n      conversion        ::= \"r\" | \"s\" | \"a\"\\n      format_spec       ::= <described in the next section>\\n\\nIn less formal terms, the replacement field can start with a\\n*field_name* that specifies the object whose value is to be formatted\\nand inserted into the output instead of the replacement field. The\\n*field_name* is optionally followed by a  *conversion* field, which is\\npreceded by an exclamation point ``\\'!\\'``, and a *format_spec*, which\\nis preceded by a colon ``\\':\\'``.  These specify a non-default format\\nfor the replacement value.\\n\\nSee also the *Format Specification Mini-Language* section.\\n\\nThe *field_name* itself begins with an *arg_name* that is either a\\nnumber or a keyword.  If it\\'s a number, it refers to a positional\\nargument, and if it\\'s a keyword, it refers to a named keyword\\nargument.  If the numerical arg_names in a format string are 0, 1, 2,\\n... in sequence, they can all be omitted (not just some) and the\\nnumbers 0, 1, 2, ... will be automatically inserted in that order.\\nBecause *arg_name* is not quote-delimited, it is not possible to\\nspecify arbitrary dictionary keys (e.g., the strings ``\\'10\\'`` or\\n``\\':-]\\'``) within a format string. The *arg_name* can be followed by\\nany number of index or attribute expressions. An expression of the\\nform ``\\'.name\\'`` selects the named attribute using ``getattr()``,\\nwhile an expression of the form ``\\'[index]\\'`` does an index lookup\\nusing ``__getitem__()``.\\n\\nChanged in version 3.1: The positional argument specifiers can be\\nomitted, so ``\\'{} {}\\'`` is equivalent to ``\\'{0} {1}\\'``.\\n\\nSome simple format string examples:\\n\\n   \"First, thou shalt count to {0}\" # References first positional argument\\n   \"Bring me a {}\"                  # Implicitly references the first positional argument\\n   \"From {} to {}\"                  # Same as \"From {0} to {1}\"\\n   \"My quest is {name}\"             # References keyword argument \\'name\\'\\n   \"Weight in tons {0.weight}\"      # \\'weight\\' attribute of first positional arg\\n   \"Units destroyed: {players[0]}\"  # First element of keyword argument \\'players\\'.\\n\\nThe *conversion* field causes a type coercion before formatting.\\nNormally, the job of formatting a value is done by the\\n``__format__()`` method of the value itself.  However, in some cases\\nit is desirable to force a type to be formatted as a string,\\noverriding its own definition of formatting.  By converting the value\\nto a string before calling ``__format__()``, the normal formatting\\nlogic is bypassed.\\n\\nThree conversion flags are currently supported: ``\\'!s\\'`` which calls\\n``str()`` on the value, ``\\'!r\\'`` which calls ``repr()`` and ``\\'!a\\'``\\nwhich calls ``ascii()``.\\n\\nSome examples:\\n\\n   \"Harold\\'s a clever {0!s}\"        # Calls str() on the argument first\\n   \"Bring out the holy {name!r}\"    # Calls repr() on the argument first\\n   \"More {!a}\"                      # Calls ascii() on the argument first\\n\\nThe *format_spec* field contains a specification of how the value\\nshould be presented, including such details as field width, alignment,\\npadding, decimal precision and so on.  Each value type can define its\\nown \"formatting mini-language\" or interpretation of the *format_spec*.\\n\\nMost built-in types support a common formatting mini-language, which\\nis described in the next section.\\n\\nA *format_spec* field can also include nested replacement fields\\nwithin it. These nested replacement fields can contain only a field\\nname; conversion flags and format specifications are not allowed.  The\\nreplacement fields within the format_spec are substituted before the\\n*format_spec* string is interpreted. This allows the formatting of a\\nvalue to be dynamically specified.\\n\\nSee the *Format examples* section for some examples.\\n\\n\\nFormat Specification Mini-Language\\n==================================\\n\\n\"Format specifications\" are used within replacement fields contained\\nwithin a format string to define how individual values are presented\\n(see *Format String Syntax*).  They can also be passed directly to the\\nbuilt-in ``format()`` function.  Each formattable type may define how\\nthe format specification is to be interpreted.\\n\\nMost built-in types implement the following options for format\\nspecifications, although some of the formatting options are only\\nsupported by the numeric types.\\n\\nA general convention is that an empty format string (``\"\"``) produces\\nthe same result as if you had called ``str()`` on the value. A non-\\nempty format string typically modifies the result.\\n\\nThe general form of a *standard format specifier* is:\\n\\n   format_spec ::= [[fill]align][sign][#][0][width][,][.precision][type]\\n   fill        ::= <a character other than \\'{\\' or \\'}\\'>\\n   align       ::= \"<\" | \">\" | \"=\" | \"^\"\\n   sign        ::= \"+\" | \"-\" | \" \"\\n   width       ::= integer\\n   precision   ::= integer\\n   type        ::= \"b\" | \"c\" | \"d\" | \"e\" | \"E\" | \"f\" | \"F\" | \"g\" | \"G\" | \"n\" | \"o\" | \"s\" | \"x\" | \"X\" | \"%\"\\n\\nThe *fill* character can be any character other than \\'{\\' or \\'}\\'.  The\\npresence of a fill character is signaled by the character following\\nit, which must be one of the alignment options.  If the second\\ncharacter of *format_spec* is not a valid alignment option, then it is\\nassumed that both the fill character and the alignment option are\\nabsent.\\n\\nThe meaning of the various alignment options is as follows:\\n\\n   +-----------+------------------------------------------------------------+\\n   | Option    | Meaning                                                    |\\n   +===========+============================================================+\\n   | ``\\'<\\'``   | Forces the field to be left-aligned within the available   |\\n   |           | space (this is the default for most objects).              |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'>\\'``   | Forces the field to be right-aligned within the available  |\\n   |           | space (this is the default for numbers).                   |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'=\\'``   | Forces the padding to be placed after the sign (if any)    |\\n   |           | but before the digits.  This is used for printing fields   |\\n   |           | in the form \\'+000000120\\'. This alignment option is only    |\\n   |           | valid for numeric types.                                   |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'^\\'``   | Forces the field to be centered within the available       |\\n   |           | space.                                                     |\\n   +-----------+------------------------------------------------------------+\\n\\nNote that unless a minimum field width is defined, the field width\\nwill always be the same size as the data to fill it, so that the\\nalignment option has no meaning in this case.\\n\\nThe *sign* option is only valid for number types, and can be one of\\nthe following:\\n\\n   +-----------+------------------------------------------------------------+\\n   | Option    | Meaning                                                    |\\n   +===========+============================================================+\\n   | ``\\'+\\'``   | indicates that a sign should be used for both positive as  |\\n   |           | well as negative numbers.                                  |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'-\\'``   | indicates that a sign should be used only for negative     |\\n   |           | numbers (this is the default behavior).                    |\\n   +-----------+------------------------------------------------------------+\\n   | space     | indicates that a leading space should be used on positive  |\\n   |           | numbers, and a minus sign on negative numbers.             |\\n   +-----------+------------------------------------------------------------+\\n\\nThe ``\\'#\\'`` option causes the \"alternate form\" to be used for the\\nconversion.  The alternate form is defined differently for different\\ntypes.  This option is only valid for integer, float, complex and\\nDecimal types. For integers, when binary, octal, or hexadecimal output\\nis used, this option adds the prefix respective ``\\'0b\\'``, ``\\'0o\\'``, or\\n``\\'0x\\'`` to the output value. For floats, complex and Decimal the\\nalternate form causes the result of the conversion to always contain a\\ndecimal-point character, even if no digits follow it. Normally, a\\ndecimal-point character appears in the result of these conversions\\nonly if a digit follows it. In addition, for ``\\'g\\'`` and ``\\'G\\'``\\nconversions, trailing zeros are not removed from the result.\\n\\nThe ``\\',\\'`` option signals the use of a comma for a thousands\\nseparator. For a locale aware separator, use the ``\\'n\\'`` integer\\npresentation type instead.\\n\\nChanged in version 3.1: Added the ``\\',\\'`` option (see also **PEP\\n378**).\\n\\n*width* is a decimal integer defining the minimum field width.  If not\\nspecified, then the field width will be determined by the content.\\n\\nPreceding the *width* field by a zero (``\\'0\\'``) character enables\\nsign-aware zero-padding for numeric types.  This is equivalent to a\\n*fill* character of ``\\'0\\'`` with an *alignment* type of ``\\'=\\'``.\\n\\nThe *precision* is a decimal number indicating how many digits should\\nbe displayed after the decimal point for a floating point value\\nformatted with ``\\'f\\'`` and ``\\'F\\'``, or before and after the decimal\\npoint for a floating point value formatted with ``\\'g\\'`` or ``\\'G\\'``.\\nFor non-number types the field indicates the maximum field size - in\\nother words, how many characters will be used from the field content.\\nThe *precision* is not allowed for integer values.\\n\\nFinally, the *type* determines how the data should be presented.\\n\\nThe available string presentation types are:\\n\\n   +-----------+------------------------------------------------------------+\\n   | Type      | Meaning                                                    |\\n   +===========+============================================================+\\n   | ``\\'s\\'``   | String format. This is the default type for strings and    |\\n   |           | may be omitted.                                            |\\n   +-----------+------------------------------------------------------------+\\n   | None      | The same as ``\\'s\\'``.                                       |\\n   +-----------+------------------------------------------------------------+\\n\\nThe available integer presentation types are:\\n\\n   +-----------+------------------------------------------------------------+\\n   | Type      | Meaning                                                    |\\n   +===========+============================================================+\\n   | ``\\'b\\'``   | Binary format. Outputs the number in base 2.               |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'c\\'``   | Character. Converts the integer to the corresponding       |\\n   |           | unicode character before printing.                         |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'d\\'``   | Decimal Integer. Outputs the number in base 10.            |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'o\\'``   | Octal format. Outputs the number in base 8.                |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'x\\'``   | Hex format. Outputs the number in base 16, using lower-    |\\n   |           | case letters for the digits above 9.                       |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'X\\'``   | Hex format. Outputs the number in base 16, using upper-    |\\n   |           | case letters for the digits above 9.                       |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'n\\'``   | Number. This is the same as ``\\'d\\'``, except that it uses   |\\n   |           | the current locale setting to insert the appropriate       |\\n   |           | number separator characters.                               |\\n   +-----------+------------------------------------------------------------+\\n   | None      | The same as ``\\'d\\'``.                                       |\\n   +-----------+------------------------------------------------------------+\\n\\nIn addition to the above presentation types, integers can be formatted\\nwith the floating point presentation types listed below (except\\n``\\'n\\'`` and None). When doing so, ``float()`` is used to convert the\\ninteger to a floating point number before formatting.\\n\\nThe available presentation types for floating point and decimal values\\nare:\\n\\n   +-----------+------------------------------------------------------------+\\n   | Type      | Meaning                                                    |\\n   +===========+============================================================+\\n   | ``\\'e\\'``   | Exponent notation. Prints the number in scientific         |\\n   |           | notation using the letter \\'e\\' to indicate the exponent.    |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'E\\'``   | Exponent notation. Same as ``\\'e\\'`` except it uses an upper |\\n   |           | case \\'E\\' as the separator character.                       |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'f\\'``   | Fixed point. Displays the number as a fixed-point number.  |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'F\\'``   | Fixed point. Same as ``\\'f\\'``, but converts ``nan`` to      |\\n   |           | ``NAN`` and ``inf`` to ``INF``.                            |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'g\\'``   | General format.  For a given precision ``p >= 1``, this    |\\n   |           | rounds the number to ``p`` significant digits and then     |\\n   |           | formats the result in either fixed-point format or in      |\\n   |           | scientific notation, depending on its magnitude.  The      |\\n   |           | precise rules are as follows: suppose that the result      |\\n   |           | formatted with presentation type ``\\'e\\'`` and precision     |\\n   |           | ``p-1`` would have exponent ``exp``.  Then if ``-4 <= exp  |\\n   |           | < p``, the number is formatted with presentation type      |\\n   |           | ``\\'f\\'`` and precision ``p-1-exp``. Otherwise, the number   |\\n   |           | is formatted with presentation type ``\\'e\\'`` and precision  |\\n   |           | ``p-1``. In both cases insignificant trailing zeros are    |\\n   |           | removed from the significand, and the decimal point is     |\\n   |           | also removed if there are no remaining digits following    |\\n   |           | it.  Positive and negative infinity, positive and negative |\\n   |           | zero, and nans, are formatted as ``inf``, ``-inf``, ``0``, |\\n   |           | ``-0`` and ``nan`` respectively, regardless of the         |\\n   |           | precision.  A precision of ``0`` is treated as equivalent  |\\n   |           | to a precision of ``1``.                                   |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'G\\'``   | General format. Same as ``\\'g\\'`` except switches to ``\\'E\\'`` |\\n   |           | if the number gets too large. The representations of       |\\n   |           | infinity and NaN are uppercased, too.                      |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'n\\'``   | Number. This is the same as ``\\'g\\'``, except that it uses   |\\n   |           | the current locale setting to insert the appropriate       |\\n   |           | number separator characters.                               |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'%\\'``   | Percentage. Multiplies the number by 100 and displays in   |\\n   |           | fixed (``\\'f\\'``) format, followed by a percent sign.        |\\n   +-----------+------------------------------------------------------------+\\n   | None      | Similar to ``\\'g\\'``, except with at least one digit past    |\\n   |           | the decimal point and a default precision of 12. This is   |\\n   |           | intended to match ``str()``, except you can add the other  |\\n   |           | format modifiers.                                          |\\n   +-----------+------------------------------------------------------------+\\n\\n\\nFormat examples\\n===============\\n\\nThis section contains examples of the new format syntax and comparison\\nwith the old ``%``-formatting.\\n\\nIn most of the cases the syntax is similar to the old\\n``%``-formatting, with the addition of the ``{}`` and with ``:`` used\\ninstead of ``%``. For example, ``\\'%03.2f\\'`` can be translated to\\n``\\'{:03.2f}\\'``.\\n\\nThe new format syntax also supports new and different options, shown\\nin the follow examples.\\n\\nAccessing arguments by position:\\n\\n   >>> \\'{0}, {1}, {2}\\'.format(\\'a\\', \\'b\\', \\'c\\')\\n   \\'a, b, c\\'\\n   >>> \\'{}, {}, {}\\'.format(\\'a\\', \\'b\\', \\'c\\')  # 3.1+ only\\n   \\'a, b, c\\'\\n   >>> \\'{2}, {1}, {0}\\'.format(\\'a\\', \\'b\\', \\'c\\')\\n   \\'c, b, a\\'\\n   >>> \\'{2}, {1}, {0}\\'.format(*\\'abc\\')      # unpacking argument sequence\\n   \\'c, b, a\\'\\n   >>> \\'{0}{1}{0}\\'.format(\\'abra\\', \\'cad\\')   # arguments\\' indices can be repeated\\n   \\'abracadabra\\'\\n\\nAccessing arguments by name:\\n\\n   >>> \\'Coordinates: {latitude}, {longitude}\\'.format(latitude=\\'37.24N\\', longitude=\\'-115.81W\\')\\n   \\'Coordinates: 37.24N, -115.81W\\'\\n   >>> coord = {\\'latitude\\': \\'37.24N\\', \\'longitude\\': \\'-115.81W\\'}\\n   >>> \\'Coordinates: {latitude}, {longitude}\\'.format(**coord)\\n   \\'Coordinates: 37.24N, -115.81W\\'\\n\\nAccessing arguments\\' attributes:\\n\\n   >>> c = 3-5j\\n   >>> (\\'The complex number {0} is formed from the real part {0.real} \\'\\n   ...  \\'and the imaginary part {0.imag}.\\').format(c)\\n   \\'The complex number (3-5j) is formed from the real part 3.0 and the imaginary part -5.0.\\'\\n   >>> class Point:\\n   ...     def __init__(self, x, y):\\n   ...         self.x, self.y = x, y\\n   ...     def __str__(self):\\n   ...         return \\'Point({self.x}, {self.y})\\'.format(self=self)\\n   ...\\n   >>> str(Point(4, 2))\\n   \\'Point(4, 2)\\'\\n\\nAccessing arguments\\' items:\\n\\n   >>> coord = (3, 5)\\n   >>> \\'X: {0[0]};  Y: {0[1]}\\'.format(coord)\\n   \\'X: 3;  Y: 5\\'\\n\\nReplacing ``%s`` and ``%r``:\\n\\n   >>> \"repr() shows quotes: {!r}; str() doesn\\'t: {!s}\".format(\\'test1\\', \\'test2\\')\\n   \"repr() shows quotes: \\'test1\\'; str() doesn\\'t: test2\"\\n\\nAligning the text and specifying a width:\\n\\n   >>> \\'{:<30}\\'.format(\\'left aligned\\')\\n   \\'left aligned                  \\'\\n   >>> \\'{:>30}\\'.format(\\'right aligned\\')\\n   \\'                 right aligned\\'\\n   >>> \\'{:^30}\\'.format(\\'centered\\')\\n   \\'           centered           \\'\\n   >>> \\'{:*^30}\\'.format(\\'centered\\')  # use \\'*\\' as a fill char\\n   \\'***********centered***********\\'\\n\\nReplacing ``%+f``, ``%-f``, and ``% f`` and specifying a sign:\\n\\n   >>> \\'{:+f}; {:+f}\\'.format(3.14, -3.14)  # show it always\\n   \\'+3.140000; -3.140000\\'\\n   >>> \\'{: f}; {: f}\\'.format(3.14, -3.14)  # show a space for positive numbers\\n   \\' 3.140000; -3.140000\\'\\n   >>> \\'{:-f}; {:-f}\\'.format(3.14, -3.14)  # show only the minus -- same as \\'{:f}; {:f}\\'\\n   \\'3.140000; -3.140000\\'\\n\\nReplacing ``%x`` and ``%o`` and converting the value to different\\nbases:\\n\\n   >>> # format also supports binary numbers\\n   >>> \"int: {0:d};  hex: {0:x};  oct: {0:o};  bin: {0:b}\".format(42)\\n   \\'int: 42;  hex: 2a;  oct: 52;  bin: 101010\\'\\n   >>> # with 0x, 0o, or 0b as prefix:\\n   >>> \"int: {0:d};  hex: {0:#x};  oct: {0:#o};  bin: {0:#b}\".format(42)\\n   \\'int: 42;  hex: 0x2a;  oct: 0o52;  bin: 0b101010\\'\\n\\nUsing the comma as a thousands separator:\\n\\n   >>> \\'{:,}\\'.format(1234567890)\\n   \\'1,234,567,890\\'\\n\\nExpressing a percentage:\\n\\n   >>> points = 19\\n   >>> total = 22\\n   >>> \\'Correct answers: {:.2%}\\'.format(points/total)\\n   \\'Correct answers: 86.36%\\'\\n\\nUsing type-specific formatting:\\n\\n   >>> import datetime\\n   >>> d = datetime.datetime(2010, 7, 4, 12, 15, 58)\\n   >>> \\'{:%Y-%m-%d %H:%M:%S}\\'.format(d)\\n   \\'2010-07-04 12:15:58\\'\\n\\nNesting arguments and more complex examples:\\n\\n   >>> for align, text in zip(\\'<^>\\', [\\'left\\', \\'center\\', \\'right\\']):\\n   ...     \\'{0:{fill}{align}16}\\'.format(text, fill=align, align=align)\\n   ...\\n   \\'left<<<<<<<<<<<<\\'\\n   \\'^^^^^center^^^^^\\'\\n   \\'>>>>>>>>>>>right\\'\\n   >>>\\n   >>> octets = [192, 168, 0, 1]\\n   >>> \\'{:02X}{:02X}{:02X}{:02X}\\'.format(*octets)\\n   \\'C0A80001\\'\\n   >>> int(_, 16)\\n   3232235521\\n   >>>\\n   >>> width = 5\\n   >>> for num in range(5,12): #doctest: +NORMALIZE_WHITESPACE\\n   ...     for base in \\'dXob\\':\\n   ...         print(\\'{0:{width}{base}}\\'.format(num, base=base, width=width), end=\\' \\')\\n   ...     print()\\n   ...\\n       5     5     5   101\\n       6     6     6   110\\n       7     7     7   111\\n       8     8    10  1000\\n       9     9    11  1001\\n      10     A    12  1010\\n      11     B    13  1011\\n',\n 'function': '\\nFunction definitions\\n********************\\n\\nA function definition defines a user-defined function object (see\\nsection *The standard type hierarchy*):\\n\\n   funcdef        ::= [decorators] \"def\" funcname \"(\" [parameter_list] \")\" [\"->\" expression] \":\" suite\\n   decorators     ::= decorator+\\n   decorator      ::= \"@\" dotted_name [\"(\" [parameter_list [\",\"]] \")\"] NEWLINE\\n   dotted_name    ::= identifier (\".\" identifier)*\\n   parameter_list ::= (defparameter \",\")*\\n                      ( \"*\" [parameter] (\",\" defparameter)* [\",\" \"**\" parameter]\\n                      | \"**\" parameter\\n                      | defparameter [\",\"] )\\n   parameter      ::= identifier [\":\" expression]\\n   defparameter   ::= parameter [\"=\" expression]\\n   funcname       ::= identifier\\n\\nA function definition is an executable statement.  Its execution binds\\nthe function name in the current local namespace to a function object\\n(a wrapper around the executable code for the function).  This\\nfunction object contains a reference to the current global namespace\\nas the global namespace to be used when the function is called.\\n\\nThe function definition does not execute the function body; this gets\\nexecuted only when the function is called. [3]\\n\\nA function definition may be wrapped by one or more *decorator*\\nexpressions. Decorator expressions are evaluated when the function is\\ndefined, in the scope that contains the function definition.  The\\nresult must be a callable, which is invoked with the function object\\nas the only argument. The returned value is bound to the function name\\ninstead of the function object.  Multiple decorators are applied in\\nnested fashion. For example, the following code\\n\\n   @f1(arg)\\n   @f2\\n   def func(): pass\\n\\nis equivalent to\\n\\n   def func(): pass\\n   func = f1(arg)(f2(func))\\n\\nWhen one or more *parameters* have the form *parameter* ``=``\\n*expression*, the function is said to have \"default parameter values.\"\\nFor a parameter with a default value, the corresponding *argument* may\\nbe omitted from a call, in which case the parameter\\'s default value is\\nsubstituted.  If a parameter has a default value, all following\\nparameters up until the \"``*``\" must also have a default value ---\\nthis is a syntactic restriction that is not expressed by the grammar.\\n\\n**Default parameter values are evaluated when the function definition\\nis executed.** This means that the expression is evaluated once, when\\nthe function is defined, and that the same \"pre-computed\" value is\\nused for each call.  This is especially important to understand when a\\ndefault parameter is a mutable object, such as a list or a dictionary:\\nif the function modifies the object (e.g. by appending an item to a\\nlist), the default value is in effect modified. This is generally not\\nwhat was intended.  A way around this is to use ``None`` as the\\ndefault, and explicitly test for it in the body of the function, e.g.:\\n\\n   def whats_on_the_telly(penguin=None):\\n       if penguin is None:\\n           penguin = []\\n       penguin.append(\"property of the zoo\")\\n       return penguin\\n\\nFunction call semantics are described in more detail in section\\n*Calls*. A function call always assigns values to all parameters\\nmentioned in the parameter list, either from position arguments, from\\nkeyword arguments, or from default values.  If the form\\n\"``*identifier``\" is present, it is initialized to a tuple receiving\\nany excess positional parameters, defaulting to the empty tuple.  If\\nthe form \"``**identifier``\" is present, it is initialized to a new\\ndictionary receiving any excess keyword arguments, defaulting to a new\\nempty dictionary. Parameters after \"``*``\" or \"``*identifier``\" are\\nkeyword-only parameters and may only be passed used keyword arguments.\\n\\nParameters may have annotations of the form \"``: expression``\"\\nfollowing the parameter name.  Any parameter may have an annotation\\neven those of the form ``*identifier`` or ``**identifier``.  Functions\\nmay have \"return\" annotation of the form \"``-> expression``\" after the\\nparameter list.  These annotations can be any valid Python expression\\nand are evaluated when the function definition is executed.\\nAnnotations may be evaluated in a different order than they appear in\\nthe source code.  The presence of annotations does not change the\\nsemantics of a function.  The annotation values are available as\\nvalues of a dictionary keyed by the parameters\\' names in the\\n``__annotations__`` attribute of the function object.\\n\\nIt is also possible to create anonymous functions (functions not bound\\nto a name), for immediate use in expressions.  This uses lambda forms,\\ndescribed in section *Lambdas*.  Note that the lambda form is merely a\\nshorthand for a simplified function definition; a function defined in\\na \"``def``\" statement can be passed around or assigned to another name\\njust like a function defined by a lambda form.  The \"``def``\" form is\\nactually more powerful since it allows the execution of multiple\\nstatements and annotations.\\n\\n**Programmer\\'s note:** Functions are first-class objects.  A \"``def``\"\\nform executed inside a function definition defines a local function\\nthat can be returned or passed around.  Free variables used in the\\nnested function can access the local variables of the function\\ncontaining the def.  See section *Naming and binding* for details.\\n\\nSee also:\\n\\n   **PEP 3107** - Function Annotations\\n      The original specification for function annotations.\\n',\n 'global': '\\nThe ``global`` statement\\n************************\\n\\n   global_stmt ::= \"global\" identifier (\",\" identifier)*\\n\\nThe ``global`` statement is a declaration which holds for the entire\\ncurrent code block.  It means that the listed identifiers are to be\\ninterpreted as globals.  It would be impossible to assign to a global\\nvariable without ``global``, although free variables may refer to\\nglobals without being declared global.\\n\\nNames listed in a ``global`` statement must not be used in the same\\ncode block textually preceding that ``global`` statement.\\n\\nNames listed in a ``global`` statement must not be defined as formal\\nparameters or in a ``for`` loop control target, ``class`` definition,\\nfunction definition, or ``import`` statement.\\n\\n**CPython implementation detail:** The current implementation does not\\nenforce the latter two restrictions, but programs should not abuse\\nthis freedom, as future implementations may enforce them or silently\\nchange the meaning of the program.\\n\\n**Programmer\\'s note:** the ``global`` is a directive to the parser.\\nIt applies only to code parsed at the same time as the ``global``\\nstatement. In particular, a ``global`` statement contained in a string\\nor code object supplied to the built-in ``exec()`` function does not\\naffect the code block *containing* the function call, and code\\ncontained in such a string is unaffected by ``global`` statements in\\nthe code containing the function call.  The same applies to the\\n``eval()`` and ``compile()`` functions.\\n',\n 'id-classes': '\\nReserved classes of identifiers\\n*******************************\\n\\nCertain classes of identifiers (besides keywords) have special\\nmeanings.  These classes are identified by the patterns of leading and\\ntrailing underscore characters:\\n\\n``_*``\\n   Not imported by ``from module import *``.  The special identifier\\n   ``_`` is used in the interactive interpreter to store the result of\\n   the last evaluation; it is stored in the ``builtins`` module.  When\\n   not in interactive mode, ``_`` has no special meaning and is not\\n   defined. See section *The import statement*.\\n\\n   Note: The name ``_`` is often used in conjunction with\\n     internationalization; refer to the documentation for the\\n     ``gettext`` module for more information on this convention.\\n\\n``__*__``\\n   System-defined names. These names are defined by the interpreter\\n   and its implementation (including the standard library).  Current\\n   system names are discussed in the *Special method names* section\\n   and elsewhere.  More will likely be defined in future versions of\\n   Python.  *Any* use of ``__*__`` names, in any context, that does\\n   not follow explicitly documented use, is subject to breakage\\n   without warning.\\n\\n``__*``\\n   Class-private names.  Names in this category, when used within the\\n   context of a class definition, are re-written to use a mangled form\\n   to help avoid name clashes between \"private\" attributes of base and\\n   derived classes. See section *Identifiers (Names)*.\\n',\n 'identifiers': '\\nIdentifiers and keywords\\n************************\\n\\nIdentifiers (also referred to as *names*) are described by the\\nfollowing lexical definitions.\\n\\nThe syntax of identifiers in Python is based on the Unicode standard\\nannex UAX-31, with elaboration and changes as defined below; see also\\n**PEP 3131** for further details.\\n\\nWithin the ASCII range (U+0001..U+007F), the valid characters for\\nidentifiers are the same as in Python 2.x: the uppercase and lowercase\\nletters ``A`` through ``Z``, the underscore ``_`` and, except for the\\nfirst character, the digits ``0`` through ``9``.\\n\\nPython 3.0 introduces additional characters from outside the ASCII\\nrange (see **PEP 3131**).  For these characters, the classification\\nuses the version of the Unicode Character Database as included in the\\n``unicodedata`` module.\\n\\nIdentifiers are unlimited in length.  Case is significant.\\n\\n   identifier   ::= xid_start xid_continue*\\n   id_start     ::= <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property>\\n   id_continue  ::= <all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property>\\n   xid_start    ::= <all characters in id_start whose NFKC normalization is in \"id_start xid_continue*\">\\n   xid_continue ::= <all characters in id_continue whose NFKC normalization is in \"id_continue*\">\\n\\nThe Unicode category codes mentioned above stand for:\\n\\n* *Lu* - uppercase letters\\n\\n* *Ll* - lowercase letters\\n\\n* *Lt* - titlecase letters\\n\\n* *Lm* - modifier letters\\n\\n* *Lo* - other letters\\n\\n* *Nl* - letter numbers\\n\\n* *Mn* - nonspacing marks\\n\\n* *Mc* - spacing combining marks\\n\\n* *Nd* - decimal numbers\\n\\n* *Pc* - connector punctuations\\n\\n* *Other_ID_Start* - explicit list of characters in PropList.txt to\\n  support backwards compatibility\\n\\n* *Other_ID_Continue* - likewise\\n\\nAll identifiers are converted into the normal form NFKC while parsing;\\ncomparison of identifiers is based on NFKC.\\n\\nA non-normative HTML file listing all valid identifier characters for\\nUnicode 4.1 can be found at http://www.dcl.hpi.uni-\\npotsdam.de/home/loewis/table-3131.html.\\n\\n\\nKeywords\\n========\\n\\nThe following identifiers are used as reserved words, or *keywords* of\\nthe language, and cannot be used as ordinary identifiers.  They must\\nbe spelled exactly as written here:\\n\\n   False      class      finally    is         return\\n   None       continue   for        lambda     try\\n   True       def        from       nonlocal   while\\n   and        del        global     not        with\\n   as         elif       if         or         yield\\n   assert     else       import     pass\\n   break      except     in         raise\\n\\n\\nReserved classes of identifiers\\n===============================\\n\\nCertain classes of identifiers (besides keywords) have special\\nmeanings.  These classes are identified by the patterns of leading and\\ntrailing underscore characters:\\n\\n``_*``\\n   Not imported by ``from module import *``.  The special identifier\\n   ``_`` is used in the interactive interpreter to store the result of\\n   the last evaluation; it is stored in the ``builtins`` module.  When\\n   not in interactive mode, ``_`` has no special meaning and is not\\n   defined. See section *The import statement*.\\n\\n   Note: The name ``_`` is often used in conjunction with\\n     internationalization; refer to the documentation for the\\n     ``gettext`` module for more information on this convention.\\n\\n``__*__``\\n   System-defined names. These names are defined by the interpreter\\n   and its implementation (including the standard library).  Current\\n   system names are discussed in the *Special method names* section\\n   and elsewhere.  More will likely be defined in future versions of\\n   Python.  *Any* use of ``__*__`` names, in any context, that does\\n   not follow explicitly documented use, is subject to breakage\\n   without warning.\\n\\n``__*``\\n   Class-private names.  Names in this category, when used within the\\n   context of a class definition, are re-written to use a mangled form\\n   to help avoid name clashes between \"private\" attributes of base and\\n   derived classes. See section *Identifiers (Names)*.\\n',\n 'if': '\\nThe ``if`` statement\\n********************\\n\\nThe ``if`` statement is used for conditional execution:\\n\\n   if_stmt ::= \"if\" expression \":\" suite\\n               ( \"elif\" expression \":\" suite )*\\n               [\"else\" \":\" suite]\\n\\nIt selects exactly one of the suites by evaluating the expressions one\\nby one until one is found to be true (see section *Boolean operations*\\nfor the definition of true and false); then that suite is executed\\n(and no other part of the ``if`` statement is executed or evaluated).\\nIf all expressions are false, the suite of the ``else`` clause, if\\npresent, is executed.\\n',\n 'imaginary': '\\nImaginary literals\\n******************\\n\\nImaginary literals are described by the following lexical definitions:\\n\\n   imagnumber ::= (floatnumber | intpart) (\"j\" | \"J\")\\n\\nAn imaginary literal yields a complex number with a real part of 0.0.\\nComplex numbers are represented as a pair of floating point numbers\\nand have the same restrictions on their range.  To create a complex\\nnumber with a nonzero real part, add a floating point number to it,\\ne.g., ``(3+4j)``.  Some examples of imaginary literals:\\n\\n   3.14j   10.j    10j     .001j   1e100j  3.14e-10j\\n',\n 'import': '\\nThe ``import`` statement\\n************************\\n\\n   import_stmt     ::= \"import\" module [\"as\" name] ( \",\" module [\"as\" name] )*\\n                   | \"from\" relative_module \"import\" identifier [\"as\" name]\\n                   ( \",\" identifier [\"as\" name] )*\\n                   | \"from\" relative_module \"import\" \"(\" identifier [\"as\" name]\\n                   ( \",\" identifier [\"as\" name] )* [\",\"] \")\"\\n                   | \"from\" module \"import\" \"*\"\\n   module          ::= (identifier \".\")* identifier\\n   relative_module ::= \".\"* module | \".\"+\\n   name            ::= identifier\\n\\nThe basic import statement (no ``from`` clause) is executed in two\\nsteps:\\n\\n1. find a module, loading and initializing it if necessary\\n\\n2. define a name or names in the local namespace for the scope where\\n   the ``import`` statement occurs.\\n\\nWhen the statement contains multiple clauses (separated by commas) the\\ntwo steps are carried out separately for each clause, just as though\\nthe clauses had been separated out into individiual import statements.\\n\\nThe details of the first step, finding and loading modules is\\ndescribed in greater detail in the section on the *import system*,\\nwhich also describes the various types of packages and modules that\\ncan be imported, as well as all the hooks that can be used to\\ncustomize the import system. Note that failures in this step may\\nindicate either that the module could not be located, *or* that an\\nerror occurred while initializing the module, which includes execution\\nof the module\\'s code.\\n\\nIf the requested module is retrieved successfully, it will be made\\navailable in the local namespace in one of three ways:\\n\\n* If the module name is followed by ``as``, then the name following\\n  ``as`` is bound directly to the imported module.\\n\\n* If no other name is specified, and the module being imported is a\\n  top level module, the module\\'s name is bound in the local namespace\\n  as a reference to the imported module\\n\\n* If the module being imported is *not* a top level module, then the\\n  name of the top level package that contains the module is bound in\\n  the local namespace as a reference to the top level package. The\\n  imported module must be accessed using its full qualified name\\n  rather than directly\\n\\nThe ``from`` form uses a slightly more complex process:\\n\\n1. find the module specified in the ``from`` clause loading and\\n   initializing it if necessary;\\n\\n2. for each of the identifiers specified in the ``import`` clauses:\\n\\n   1. check if the imported module has an attribute by that name\\n\\n   2. if not, attempt to import a submodule with that name and then\\n      check the imported module again for that attribute\\n\\n   3. if the attribute is not found, ``ImportError`` is raised.\\n\\n   4. otherwise, a reference to that value is bound in the local\\n      namespace, using the name in the ``as`` clause if it is present,\\n      otherwise using the attribute name\\n\\nExamples:\\n\\n   import foo                 # foo imported and bound locally\\n   import foo.bar.baz         # foo.bar.baz imported, foo bound locally\\n   import foo.bar.baz as fbb  # foo.bar.baz imported and bound as fbb\\n   from foo.bar import baz    # foo.bar.baz imported and bound as baz\\n   from foo import attr       # foo imported and foo.attr bound as attr\\n\\nIf the list of identifiers is replaced by a star (``\\'*\\'``), all public\\nnames defined in the module are bound in the local namespace for the\\nscope where the ``import`` statement occurs.\\n\\nThe *public names* defined by a module are determined by checking the\\nmodule\\'s namespace for a variable named ``__all__``; if defined, it\\nmust be a sequence of strings which are names defined or imported by\\nthat module.  The names given in ``__all__`` are all considered public\\nand are required to exist.  If ``__all__`` is not defined, the set of\\npublic names includes all names found in the module\\'s namespace which\\ndo not begin with an underscore character (``\\'_\\'``).  ``__all__``\\nshould contain the entire public API. It is intended to avoid\\naccidentally exporting items that are not part of the API (such as\\nlibrary modules which were imported and used within the module).\\n\\nThe ``from`` form with ``*`` may only occur in a module scope.\\nAttempting to use it in class or function definitions will raise a\\n``SyntaxError``.\\n\\nThe *public names* defined by a module are determined by checking the\\nmodule\\'s namespace for a variable named ``__all__``; if defined, it\\nmust be a sequence of strings which are names defined or imported by\\nthat module.  The names given in ``__all__`` are all considered public\\nand are required to exist.  If ``__all__`` is not defined, the set of\\npublic names includes all names found in the module\\'s namespace which\\ndo not begin with an underscore character (``\\'_\\'``).  ``__all__``\\nshould contain the entire public API. It is intended to avoid\\naccidentally exporting items that are not part of the API (such as\\nlibrary modules which were imported and used within the module).\\n\\nThe ``from`` form with ``*`` may only occur in a module scope.  The\\nwild card form of import --- ``import *`` --- is only allowed at the\\nmodule level. Attempting to use it in class or function definitions\\nwill raise a ``SyntaxError``.\\n\\nWhen specifying what module to import you do not have to specify the\\nabsolute name of the module. When a module or package is contained\\nwithin another package it is possible to make a relative import within\\nthe same top package without having to mention the package name. By\\nusing leading dots in the specified module or package after ``from``\\nyou can specify how high to traverse up the current package hierarchy\\nwithout specifying exact names. One leading dot means the current\\npackage where the module making the import exists. Two dots means up\\none package level. Three dots is up two levels, etc. So if you execute\\n``from . import mod`` from a module in the ``pkg`` package then you\\nwill end up importing ``pkg.mod``. If you execute ``from ..subpkg2\\nimport mod`` from within ``pkg.subpkg1`` you will import\\n``pkg.subpkg2.mod``. The specification for relative imports is\\ncontained within **PEP 328**.\\n\\n``importlib.import_module()`` is provided to support applications that\\ndetermine which modules need to be loaded dynamically.\\n\\n\\nFuture statements\\n=================\\n\\nA *future statement* is a directive to the compiler that a particular\\nmodule should be compiled using syntax or semantics that will be\\navailable in a specified future release of Python.  The future\\nstatement is intended to ease migration to future versions of Python\\nthat introduce incompatible changes to the language.  It allows use of\\nthe new features on a per-module basis before the release in which the\\nfeature becomes standard.\\n\\n   future_statement ::= \"from\" \"__future__\" \"import\" feature [\"as\" name]\\n                        (\",\" feature [\"as\" name])*\\n                        | \"from\" \"__future__\" \"import\" \"(\" feature [\"as\" name]\\n                        (\",\" feature [\"as\" name])* [\",\"] \")\"\\n   feature          ::= identifier\\n   name             ::= identifier\\n\\nA future statement must appear near the top of the module.  The only\\nlines that can appear before a future statement are:\\n\\n* the module docstring (if any),\\n\\n* comments,\\n\\n* blank lines, and\\n\\n* other future statements.\\n\\nThe features recognized by Python 3.0 are ``absolute_import``,\\n``division``, ``generators``, ``unicode_literals``,\\n``print_function``, ``nested_scopes`` and ``with_statement``.  They\\nare all redundant because they are always enabled, and only kept for\\nbackwards compatibility.\\n\\nA future statement is recognized and treated specially at compile\\ntime: Changes to the semantics of core constructs are often\\nimplemented by generating different code.  It may even be the case\\nthat a new feature introduces new incompatible syntax (such as a new\\nreserved word), in which case the compiler may need to parse the\\nmodule differently.  Such decisions cannot be pushed off until\\nruntime.\\n\\nFor any given release, the compiler knows which feature names have\\nbeen defined, and raises a compile-time error if a future statement\\ncontains a feature not known to it.\\n\\nThe direct runtime semantics are the same as for any import statement:\\nthere is a standard module ``__future__``, described later, and it\\nwill be imported in the usual way at the time the future statement is\\nexecuted.\\n\\nThe interesting runtime semantics depend on the specific feature\\nenabled by the future statement.\\n\\nNote that there is nothing special about the statement:\\n\\n   import __future__ [as name]\\n\\nThat is not a future statement; it\\'s an ordinary import statement with\\nno special semantics or syntax restrictions.\\n\\nCode compiled by calls to the built-in functions ``exec()`` and\\n``compile()`` that occur in a module ``M`` containing a future\\nstatement will, by default, use the new syntax or semantics associated\\nwith the future statement.  This can be controlled by optional\\narguments to ``compile()`` --- see the documentation of that function\\nfor details.\\n\\nA future statement typed at an interactive interpreter prompt will\\ntake effect for the rest of the interpreter session.  If an\\ninterpreter is started with the *-i* option, is passed a script name\\nto execute, and the script includes a future statement, it will be in\\neffect in the interactive session started after the script is\\nexecuted.\\n\\nSee also:\\n\\n   **PEP 236** - Back to the __future__\\n      The original proposal for the __future__ mechanism.\\n',\n 'in': '\\nComparisons\\n***********\\n\\nUnlike C, all comparison operations in Python have the same priority,\\nwhich is lower than that of any arithmetic, shifting or bitwise\\noperation.  Also unlike C, expressions like ``a < b < c`` have the\\ninterpretation that is conventional in mathematics:\\n\\n   comparison    ::= or_expr ( comp_operator or_expr )*\\n   comp_operator ::= \"<\" | \">\" | \"==\" | \">=\" | \"<=\" | \"!=\"\\n                     | \"is\" [\"not\"] | [\"not\"] \"in\"\\n\\nComparisons yield boolean values: ``True`` or ``False``.\\n\\nComparisons can be chained arbitrarily, e.g., ``x < y <= z`` is\\nequivalent to ``x < y and y <= z``, except that ``y`` is evaluated\\nonly once (but in both cases ``z`` is not evaluated at all when ``x <\\ny`` is found to be false).\\n\\nFormally, if *a*, *b*, *c*, ..., *y*, *z* are expressions and *op1*,\\n*op2*, ..., *opN* are comparison operators, then ``a op1 b op2 c ... y\\nopN z`` is equivalent to ``a op1 b and b op2 c and ... y opN z``,\\nexcept that each expression is evaluated at most once.\\n\\nNote that ``a op1 b op2 c`` doesn\\'t imply any kind of comparison\\nbetween *a* and *c*, so that, e.g., ``x < y > z`` is perfectly legal\\n(though perhaps not pretty).\\n\\nThe operators ``<``, ``>``, ``==``, ``>=``, ``<=``, and ``!=`` compare\\nthe values of two objects.  The objects need not have the same type.\\nIf both are numbers, they are converted to a common type.  Otherwise,\\nthe ``==`` and ``!=`` operators *always* consider objects of different\\ntypes to be unequal, while the ``<``, ``>``, ``>=`` and ``<=``\\noperators raise a ``TypeError`` when comparing objects of different\\ntypes that do not implement these operators for the given pair of\\ntypes.  You can control comparison behavior of objects of non-built-in\\ntypes by defining rich comparison methods like ``__gt__()``, described\\nin section *Basic customization*.\\n\\nComparison of objects of the same type depends on the type:\\n\\n* Numbers are compared arithmetically.\\n\\n* The values ``float(\\'NaN\\')`` and ``Decimal(\\'NaN\\')`` are special. The\\n  are identical to themselves, ``x is x`` but are not equal to\\n  themselves, ``x != x``.  Additionally, comparing any value to a\\n  not-a-number value will return ``False``.  For example, both ``3 <\\n  float(\\'NaN\\')`` and ``float(\\'NaN\\') < 3`` will return ``False``.\\n\\n* Bytes objects are compared lexicographically using the numeric\\n  values of their elements.\\n\\n* Strings are compared lexicographically using the numeric equivalents\\n  (the result of the built-in function ``ord()``) of their characters.\\n  [3] String and bytes object can\\'t be compared!\\n\\n* Tuples and lists are compared lexicographically using comparison of\\n  corresponding elements.  This means that to compare equal, each\\n  element must compare equal and the two sequences must be of the same\\n  type and have the same length.\\n\\n  If not equal, the sequences are ordered the same as their first\\n  differing elements.  For example, ``[1,2,x] <= [1,2,y]`` has the\\n  same value as ``x <= y``.  If the corresponding element does not\\n  exist, the shorter sequence is ordered first (for example, ``[1,2] <\\n  [1,2,3]``).\\n\\n* Mappings (dictionaries) compare equal if and only if they have the\\n  same ``(key, value)`` pairs. Order comparisons ``(\\'<\\', \\'<=\\', \\'>=\\',\\n  \\'>\\')`` raise ``TypeError``.\\n\\n* Sets and frozensets define comparison operators to mean subset and\\n  superset tests.  Those relations do not define total orderings (the\\n  two sets ``{1,2}`` and {2,3} are not equal, nor subsets of one\\n  another, nor supersets of one another).  Accordingly, sets are not\\n  appropriate arguments for functions which depend on total ordering.\\n  For example, ``min()``, ``max()``, and ``sorted()`` produce\\n  undefined results given a list of sets as inputs.\\n\\n* Most other objects of built-in types compare unequal unless they are\\n  the same object; the choice whether one object is considered smaller\\n  or larger than another one is made arbitrarily but consistently\\n  within one execution of a program.\\n\\nComparison of objects of the differing types depends on whether either\\nof the types provide explicit support for the comparison.  Most\\nnumeric types can be compared with one another.  When cross-type\\ncomparison is not supported, the comparison method returns\\n``NotImplemented``.\\n\\nThe operators ``in`` and ``not in`` test for membership.  ``x in s``\\nevaluates to true if *x* is a member of *s*, and false otherwise.  ``x\\nnot in s`` returns the negation of ``x in s``.  All built-in sequences\\nand set types support this as well as dictionary, for which ``in``\\ntests whether a the dictionary has a given key. For container types\\nsuch as list, tuple, set, frozenset, dict, or collections.deque, the\\nexpression ``x in y`` is equivalent to ``any(x is e or x == e for e in\\ny)``.\\n\\nFor the string and bytes types, ``x in y`` is true if and only if *x*\\nis a substring of *y*.  An equivalent test is ``y.find(x) != -1``.\\nEmpty strings are always considered to be a substring of any other\\nstring, so ``\"\" in \"abc\"`` will return ``True``.\\n\\nFor user-defined classes which define the ``__contains__()`` method,\\n``x in y`` is true if and only if ``y.__contains__(x)`` is true.\\n\\nFor user-defined classes which do not define ``__contains__()`` but do\\ndefine ``__iter__()``, ``x in y`` is true if some value ``z`` with ``x\\n== z`` is produced while iterating over ``y``.  If an exception is\\nraised during the iteration, it is as if ``in`` raised that exception.\\n\\nLastly, the old-style iteration protocol is tried: if a class defines\\n``__getitem__()``, ``x in y`` is true if and only if there is a non-\\nnegative integer index *i* such that ``x == y[i]``, and all lower\\ninteger indices do not raise ``IndexError`` exception.  (If any other\\nexception is raised, it is as if ``in`` raised that exception).\\n\\nThe operator ``not in`` is defined to have the inverse true value of\\n``in``.\\n\\nThe operators ``is`` and ``is not`` test for object identity: ``x is\\ny`` is true if and only if *x* and *y* are the same object.  ``x is\\nnot y`` yields the inverse truth value. [4]\\n',\n 'integers': '\\nInteger literals\\n****************\\n\\nInteger literals are described by the following lexical definitions:\\n\\n   integer        ::= decimalinteger | octinteger | hexinteger | bininteger\\n   decimalinteger ::= nonzerodigit digit* | \"0\"+\\n   nonzerodigit   ::= \"1\"...\"9\"\\n   digit          ::= \"0\"...\"9\"\\n   octinteger     ::= \"0\" (\"o\" | \"O\") octdigit+\\n   hexinteger     ::= \"0\" (\"x\" | \"X\") hexdigit+\\n   bininteger     ::= \"0\" (\"b\" | \"B\") bindigit+\\n   octdigit       ::= \"0\"...\"7\"\\n   hexdigit       ::= digit | \"a\"...\"f\" | \"A\"...\"F\"\\n   bindigit       ::= \"0\" | \"1\"\\n\\nThere is no limit for the length of integer literals apart from what\\ncan be stored in available memory.\\n\\nNote that leading zeros in a non-zero decimal number are not allowed.\\nThis is for disambiguation with C-style octal literals, which Python\\nused before version 3.0.\\n\\nSome examples of integer literals:\\n\\n   7     2147483647                        0o177    0b100110111\\n   3     79228162514264337593543950336     0o377    0x100000000\\n         79228162514264337593543950336              0xdeadbeef\\n',\n 'lambda': '\\nLambdas\\n*******\\n\\n   lambda_form        ::= \"lambda\" [parameter_list]: expression\\n   lambda_form_nocond ::= \"lambda\" [parameter_list]: expression_nocond\\n\\nLambda forms (lambda expressions) have the same syntactic position as\\nexpressions.  They are a shorthand to create anonymous functions; the\\nexpression ``lambda arguments: expression`` yields a function object.\\nThe unnamed object behaves like a function object defined with\\n\\n   def <lambda>(arguments):\\n       return expression\\n\\nSee section *Function definitions* for the syntax of parameter lists.\\nNote that functions created with lambda forms cannot contain\\nstatements or annotations.\\n',\n 'lists': '\\nList displays\\n*************\\n\\nA list display is a possibly empty series of expressions enclosed in\\nsquare brackets:\\n\\n   list_display ::= \"[\" [expression_list | comprehension] \"]\"\\n\\nA list display yields a new list object, the contents being specified\\nby either a list of expressions or a comprehension.  When a comma-\\nseparated list of expressions is supplied, its elements are evaluated\\nfrom left to right and placed into the list object in that order.\\nWhen a comprehension is supplied, the list is constructed from the\\nelements resulting from the comprehension.\\n',\n 'naming': \"\\nNaming and binding\\n******************\\n\\n*Names* refer to objects.  Names are introduced by name binding\\noperations. Each occurrence of a name in the program text refers to\\nthe *binding* of that name established in the innermost function block\\ncontaining the use.\\n\\nA *block* is a piece of Python program text that is executed as a\\nunit. The following are blocks: a module, a function body, and a class\\ndefinition. Each command typed interactively is a block.  A script\\nfile (a file given as standard input to the interpreter or specified\\non the interpreter command line the first argument) is a code block.\\nA script command (a command specified on the interpreter command line\\nwith the '**-c**' option) is a code block.  The string argument passed\\nto the built-in functions ``eval()`` and ``exec()`` is a code block.\\n\\nA code block is executed in an *execution frame*.  A frame contains\\nsome administrative information (used for debugging) and determines\\nwhere and how execution continues after the code block's execution has\\ncompleted.\\n\\nA *scope* defines the visibility of a name within a block.  If a local\\nvariable is defined in a block, its scope includes that block.  If the\\ndefinition occurs in a function block, the scope extends to any blocks\\ncontained within the defining one, unless a contained block introduces\\na different binding for the name.  The scope of names defined in a\\nclass block is limited to the class block; it does not extend to the\\ncode blocks of methods -- this includes comprehensions and generator\\nexpressions since they are implemented using a function scope.  This\\nmeans that the following will fail:\\n\\n   class A:\\n       a = 42\\n       b = list(a + i for i in range(10))\\n\\nWhen a name is used in a code block, it is resolved using the nearest\\nenclosing scope.  The set of all such scopes visible to a code block\\nis called the block's *environment*.\\n\\nIf a name is bound in a block, it is a local variable of that block,\\nunless declared as ``nonlocal``.  If a name is bound at the module\\nlevel, it is a global variable.  (The variables of the module code\\nblock are local and global.)  If a variable is used in a code block\\nbut not defined there, it is a *free variable*.\\n\\nWhen a name is not found at all, a ``NameError`` exception is raised.\\nIf the name refers to a local variable that has not been bound, a\\n``UnboundLocalError`` exception is raised.  ``UnboundLocalError`` is a\\nsubclass of ``NameError``.\\n\\nThe following constructs bind names: formal parameters to functions,\\n``import`` statements, class and function definitions (these bind the\\nclass or function name in the defining block), and targets that are\\nidentifiers if occurring in an assignment, ``for`` loop header, or\\nafter ``as`` in a ``with`` statement or ``except`` clause. The\\n``import`` statement of the form ``from ... import *`` binds all names\\ndefined in the imported module, except those beginning with an\\nunderscore.  This form may only be used at the module level.\\n\\nA target occurring in a ``del`` statement is also considered bound for\\nthis purpose (though the actual semantics are to unbind the name).\\n\\nEach assignment or import statement occurs within a block defined by a\\nclass or function definition or at the module level (the top-level\\ncode block).\\n\\nIf a name binding operation occurs anywhere within a code block, all\\nuses of the name within the block are treated as references to the\\ncurrent block.  This can lead to errors when a name is used within a\\nblock before it is bound.  This rule is subtle.  Python lacks\\ndeclarations and allows name binding operations to occur anywhere\\nwithin a code block.  The local variables of a code block can be\\ndetermined by scanning the entire text of the block for name binding\\noperations.\\n\\nIf the ``global`` statement occurs within a block, all uses of the\\nname specified in the statement refer to the binding of that name in\\nthe top-level namespace.  Names are resolved in the top-level\\nnamespace by searching the global namespace, i.e. the namespace of the\\nmodule containing the code block, and the builtins namespace, the\\nnamespace of the module ``builtins``.  The global namespace is\\nsearched first.  If the name is not found there, the builtins\\nnamespace is searched.  The global statement must precede all uses of\\nthe name.\\n\\nThe builtins namespace associated with the execution of a code block\\nis actually found by looking up the name ``__builtins__`` in its\\nglobal namespace; this should be a dictionary or a module (in the\\nlatter case the module's dictionary is used).  By default, when in the\\n``__main__`` module, ``__builtins__`` is the built-in module\\n``builtins``; when in any other module, ``__builtins__`` is an alias\\nfor the dictionary of the ``builtins`` module itself.\\n``__builtins__`` can be set to a user-created dictionary to create a\\nweak form of restricted execution.\\n\\n**CPython implementation detail:** Users should not touch\\n``__builtins__``; it is strictly an implementation detail.  Users\\nwanting to override values in the builtins namespace should ``import``\\nthe ``builtins`` module and modify its attributes appropriately.\\n\\nThe namespace for a module is automatically created the first time a\\nmodule is imported.  The main module for a script is always called\\n``__main__``.\\n\\nThe ``global`` statement has the same scope as a name binding\\noperation in the same block.  If the nearest enclosing scope for a\\nfree variable contains a global statement, the free variable is\\ntreated as a global.\\n\\nA class definition is an executable statement that may use and define\\nnames. These references follow the normal rules for name resolution.\\nThe namespace of the class definition becomes the attribute dictionary\\nof the class.  Names defined at the class scope are not visible in\\nmethods.\\n\\n\\nInteraction with dynamic features\\n=================================\\n\\nThere are several cases where Python statements are illegal when used\\nin conjunction with nested scopes that contain free variables.\\n\\nIf a variable is referenced in an enclosing scope, it is illegal to\\ndelete the name.  An error will be reported at compile time.\\n\\nIf the wild card form of import --- ``import *`` --- is used in a\\nfunction and the function contains or is a nested block with free\\nvariables, the compiler will raise a ``SyntaxError``.\\n\\nThe ``eval()`` and ``exec()`` functions do not have access to the full\\nenvironment for resolving names.  Names may be resolved in the local\\nand global namespaces of the caller.  Free variables are not resolved\\nin the nearest enclosing namespace, but in the global namespace.  [1]\\nThe ``exec()`` and ``eval()`` functions have optional arguments to\\noverride the global and local namespace.  If only one namespace is\\nspecified, it is used for both.\\n\",\n 'nonlocal': '\\nThe ``nonlocal`` statement\\n**************************\\n\\n   nonlocal_stmt ::= \"nonlocal\" identifier (\",\" identifier)*\\n\\nThe ``nonlocal`` statement causes the listed identifiers to refer to\\npreviously bound variables in the nearest enclosing scope.  This is\\nimportant because the default behavior for binding is to search the\\nlocal namespace first.  The statement allows encapsulated code to\\nrebind variables outside of the local scope besides the global\\n(module) scope.\\n\\nNames listed in a ``nonlocal`` statement, unlike to those listed in a\\n``global`` statement, must refer to pre-existing bindings in an\\nenclosing scope (the scope in which a new binding should be created\\ncannot be determined unambiguously).\\n\\nNames listed in a ``nonlocal`` statement must not collide with pre-\\nexisting bindings in the local scope.\\n\\nSee also:\\n\\n   **PEP 3104** - Access to Names in Outer Scopes\\n      The specification for the ``nonlocal`` statement.\\n',\n 'numbers': \"\\nNumeric literals\\n****************\\n\\nThere are three types of numeric literals: integers, floating point\\nnumbers, and imaginary numbers.  There are no complex literals\\n(complex numbers can be formed by adding a real number and an\\nimaginary number).\\n\\nNote that numeric literals do not include a sign; a phrase like ``-1``\\nis actually an expression composed of the unary operator '``-``' and\\nthe literal ``1``.\\n\",\n 'numeric-types': \"\\nEmulating numeric types\\n***********************\\n\\nThe following methods can be defined to emulate numeric objects.\\nMethods corresponding to operations that are not supported by the\\nparticular kind of number implemented (e.g., bitwise operations for\\nnon-integral numbers) should be left undefined.\\n\\nobject.__add__(self, other)\\nobject.__sub__(self, other)\\nobject.__mul__(self, other)\\nobject.__truediv__(self, other)\\nobject.__floordiv__(self, other)\\nobject.__mod__(self, other)\\nobject.__divmod__(self, other)\\nobject.__pow__(self, other[, modulo])\\nobject.__lshift__(self, other)\\nobject.__rshift__(self, other)\\nobject.__and__(self, other)\\nobject.__xor__(self, other)\\nobject.__or__(self, other)\\n\\n   These methods are called to implement the binary arithmetic\\n   operations (``+``, ``-``, ``*``, ``/``, ``//``, ``%``,\\n   ``divmod()``, ``pow()``, ``**``, ``<<``, ``>>``, ``&``, ``^``,\\n   ``|``).  For instance, to evaluate the expression ``x + y``, where\\n   *x* is an instance of a class that has an ``__add__()`` method,\\n   ``x.__add__(y)`` is called.  The ``__divmod__()`` method should be\\n   the equivalent to using ``__floordiv__()`` and ``__mod__()``; it\\n   should not be related to ``__truediv__()``.  Note that\\n   ``__pow__()`` should be defined to accept an optional third\\n   argument if the ternary version of the built-in ``pow()`` function\\n   is to be supported.\\n\\n   If one of those methods does not support the operation with the\\n   supplied arguments, it should return ``NotImplemented``.\\n\\nobject.__radd__(self, other)\\nobject.__rsub__(self, other)\\nobject.__rmul__(self, other)\\nobject.__rtruediv__(self, other)\\nobject.__rfloordiv__(self, other)\\nobject.__rmod__(self, other)\\nobject.__rdivmod__(self, other)\\nobject.__rpow__(self, other)\\nobject.__rlshift__(self, other)\\nobject.__rrshift__(self, other)\\nobject.__rand__(self, other)\\nobject.__rxor__(self, other)\\nobject.__ror__(self, other)\\n\\n   These methods are called to implement the binary arithmetic\\n   operations (``+``, ``-``, ``*``, ``/``, ``//``, ``%``,\\n   ``divmod()``, ``pow()``, ``**``, ``<<``, ``>>``, ``&``, ``^``,\\n   ``|``) with reflected (swapped) operands. These functions are only\\n   called if the left operand does not support the corresponding\\n   operation and the operands are of different types. [2]  For\\n   instance, to evaluate the expression ``x - y``, where *y* is an\\n   instance of a class that has an ``__rsub__()`` method,\\n   ``y.__rsub__(x)`` is called if ``x.__sub__(y)`` returns\\n   *NotImplemented*.\\n\\n   Note that ternary ``pow()`` will not try calling ``__rpow__()``\\n   (the coercion rules would become too complicated).\\n\\n   Note: If the right operand's type is a subclass of the left operand's\\n     type and that subclass provides the reflected method for the\\n     operation, this method will be called before the left operand's\\n     non-reflected method.  This behavior allows subclasses to\\n     override their ancestors' operations.\\n\\nobject.__iadd__(self, other)\\nobject.__isub__(self, other)\\nobject.__imul__(self, other)\\nobject.__itruediv__(self, other)\\nobject.__ifloordiv__(self, other)\\nobject.__imod__(self, other)\\nobject.__ipow__(self, other[, modulo])\\nobject.__ilshift__(self, other)\\nobject.__irshift__(self, other)\\nobject.__iand__(self, other)\\nobject.__ixor__(self, other)\\nobject.__ior__(self, other)\\n\\n   These methods are called to implement the augmented arithmetic\\n   assignments (``+=``, ``-=``, ``*=``, ``/=``, ``//=``, ``%=``,\\n   ``**=``, ``<<=``, ``>>=``, ``&=``, ``^=``, ``|=``).  These methods\\n   should attempt to do the operation in-place (modifying *self*) and\\n   return the result (which could be, but does not have to be,\\n   *self*).  If a specific method is not defined, the augmented\\n   assignment falls back to the normal methods.  For instance, to\\n   execute the statement ``x += y``, where *x* is an instance of a\\n   class that has an ``__iadd__()`` method, ``x.__iadd__(y)`` is\\n   called.  If *x* is an instance of a class that does not define a\\n   ``__iadd__()`` method, ``x.__add__(y)`` and ``y.__radd__(x)`` are\\n   considered, as with the evaluation of ``x + y``.\\n\\nobject.__neg__(self)\\nobject.__pos__(self)\\nobject.__abs__(self)\\nobject.__invert__(self)\\n\\n   Called to implement the unary arithmetic operations (``-``, ``+``,\\n   ``abs()`` and ``~``).\\n\\nobject.__complex__(self)\\nobject.__int__(self)\\nobject.__float__(self)\\nobject.__round__(self[, n])\\n\\n   Called to implement the built-in functions ``complex()``,\\n   ``int()``, ``float()`` and ``round()``.  Should return a value of\\n   the appropriate type.\\n\\nobject.__index__(self)\\n\\n   Called to implement ``operator.index()``.  Also called whenever\\n   Python needs an integer object (such as in slicing, or in the\\n   built-in ``bin()``, ``hex()`` and ``oct()`` functions). Must return\\n   an integer.\\n\",\n 'objects': '\\nObjects, values and types\\n*************************\\n\\n*Objects* are Python\\'s abstraction for data.  All data in a Python\\nprogram is represented by objects or by relations between objects. (In\\na sense, and in conformance to Von Neumann\\'s model of a \"stored\\nprogram computer,\" code is also represented by objects.)\\n\\nEvery object has an identity, a type and a value.  An object\\'s\\n*identity* never changes once it has been created; you may think of it\\nas the object\\'s address in memory.  The \\'``is``\\' operator compares the\\nidentity of two objects; the ``id()`` function returns an integer\\nrepresenting its identity.\\n\\n**CPython implementation detail:** For CPython, ``id(x)`` is the\\nmemory address where ``x`` is stored.\\n\\nAn object\\'s type determines the operations that the object supports\\n(e.g., \"does it have a length?\") and also defines the possible values\\nfor objects of that type.  The ``type()`` function returns an object\\'s\\ntype (which is an object itself).  Like its identity, an object\\'s\\n*type* is also unchangeable. [1]\\n\\nThe *value* of some objects can change.  Objects whose value can\\nchange are said to be *mutable*; objects whose value is unchangeable\\nonce they are created are called *immutable*. (The value of an\\nimmutable container object that contains a reference to a mutable\\nobject can change when the latter\\'s value is changed; however the\\ncontainer is still considered immutable, because the collection of\\nobjects it contains cannot be changed.  So, immutability is not\\nstrictly the same as having an unchangeable value, it is more subtle.)\\nAn object\\'s mutability is determined by its type; for instance,\\nnumbers, strings and tuples are immutable, while dictionaries and\\nlists are mutable.\\n\\nObjects are never explicitly destroyed; however, when they become\\nunreachable they may be garbage-collected.  An implementation is\\nallowed to postpone garbage collection or omit it altogether --- it is\\na matter of implementation quality how garbage collection is\\nimplemented, as long as no objects are collected that are still\\nreachable.\\n\\n**CPython implementation detail:** CPython currently uses a reference-\\ncounting scheme with (optional) delayed detection of cyclically linked\\ngarbage, which collects most objects as soon as they become\\nunreachable, but is not guaranteed to collect garbage containing\\ncircular references.  See the documentation of the ``gc`` module for\\ninformation on controlling the collection of cyclic garbage. Other\\nimplementations act differently and CPython may change. Do not depend\\non immediate finalization of objects when they become unreachable (ex:\\nalways close files).\\n\\nNote that the use of the implementation\\'s tracing or debugging\\nfacilities may keep objects alive that would normally be collectable.\\nAlso note that catching an exception with a \\'``try``...``except``\\'\\nstatement may keep objects alive.\\n\\nSome objects contain references to \"external\" resources such as open\\nfiles or windows.  It is understood that these resources are freed\\nwhen the object is garbage-collected, but since garbage collection is\\nnot guaranteed to happen, such objects also provide an explicit way to\\nrelease the external resource, usually a ``close()`` method. Programs\\nare strongly recommended to explicitly close such objects.  The\\n\\'``try``...``finally``\\' statement and the \\'``with``\\' statement provide\\nconvenient ways to do this.\\n\\nSome objects contain references to other objects; these are called\\n*containers*. Examples of containers are tuples, lists and\\ndictionaries.  The references are part of a container\\'s value.  In\\nmost cases, when we talk about the value of a container, we imply the\\nvalues, not the identities of the contained objects; however, when we\\ntalk about the mutability of a container, only the identities of the\\nimmediately contained objects are implied.  So, if an immutable\\ncontainer (like a tuple) contains a reference to a mutable object, its\\nvalue changes if that mutable object is changed.\\n\\nTypes affect almost all aspects of object behavior.  Even the\\nimportance of object identity is affected in some sense: for immutable\\ntypes, operations that compute new values may actually return a\\nreference to any existing object with the same type and value, while\\nfor mutable objects this is not allowed.  E.g., after ``a = 1; b =\\n1``, ``a`` and ``b`` may or may not refer to the same object with the\\nvalue one, depending on the implementation, but after ``c = []; d =\\n[]``, ``c`` and ``d`` are guaranteed to refer to two different,\\nunique, newly created empty lists. (Note that ``c = d = []`` assigns\\nthe same object to both ``c`` and ``d``.)\\n',\n 'operator-summary': '\\nOperator precedence\\n*******************\\n\\nThe following table summarizes the operator precedences in Python,\\nfrom lowest precedence (least binding) to highest precedence (most\\nbinding).  Operators in the same box have the same precedence.  Unless\\nthe syntax is explicitly given, operators are binary.  Operators in\\nthe same box group left to right (except for comparisons, including\\ntests, which all have the same precedence and chain from left to right\\n--- see section *Comparisons* --- and exponentiation, which groups\\nfrom right to left).\\n\\n+-------------------------------------------------+---------------------------------------+\\n| Operator                                        | Description                           |\\n+=================================================+=======================================+\\n| ``lambda``                                      | Lambda expression                     |\\n+-------------------------------------------------+---------------------------------------+\\n| ``if`` -- ``else``                              | Conditional expression                |\\n+-------------------------------------------------+---------------------------------------+\\n| ``or``                                          | Boolean OR                            |\\n+-------------------------------------------------+---------------------------------------+\\n| ``and``                                         | Boolean AND                           |\\n+-------------------------------------------------+---------------------------------------+\\n| ``not`` ``x``                                   | Boolean NOT                           |\\n+-------------------------------------------------+---------------------------------------+\\n| ``in``, ``not in``, ``is``, ``is not``, ``<``,  | Comparisons, including membership     |\\n| ``<=``, ``>``, ``>=``, ``!=``, ``==``           | tests and identity tests,             |\\n+-------------------------------------------------+---------------------------------------+\\n| ``|``                                           | Bitwise OR                            |\\n+-------------------------------------------------+---------------------------------------+\\n| ``^``                                           | Bitwise XOR                           |\\n+-------------------------------------------------+---------------------------------------+\\n| ``&``                                           | Bitwise AND                           |\\n+-------------------------------------------------+---------------------------------------+\\n| ``<<``, ``>>``                                  | Shifts                                |\\n+-------------------------------------------------+---------------------------------------+\\n| ``+``, ``-``                                    | Addition and subtraction              |\\n+-------------------------------------------------+---------------------------------------+\\n| ``*``, ``/``, ``//``, ``%``                     | Multiplication, division, remainder   |\\n|                                                 | [5]                                   |\\n+-------------------------------------------------+---------------------------------------+\\n| ``+x``, ``-x``, ``~x``                          | Positive, negative, bitwise NOT       |\\n+-------------------------------------------------+---------------------------------------+\\n| ``**``                                          | Exponentiation [6]                    |\\n+-------------------------------------------------+---------------------------------------+\\n| ``x[index]``, ``x[index:index]``,               | Subscription, slicing, call,          |\\n| ``x(arguments...)``, ``x.attribute``            | attribute reference                   |\\n+-------------------------------------------------+---------------------------------------+\\n| ``(expressions...)``, ``[expressions...]``,     | Binding or tuple display, list        |\\n| ``{key: value...}``, ``{expressions...}``       | display, dictionary display, set      |\\n|                                                 | display                               |\\n+-------------------------------------------------+---------------------------------------+\\n\\n-[ Footnotes ]-\\n\\n[1] While ``abs(x%y) < abs(y)`` is true mathematically, for floats it\\n    may not be true numerically due to roundoff.  For example, and\\n    assuming a platform on which a Python float is an IEEE 754 double-\\n    precision number, in order that ``-1e-100 % 1e100`` have the same\\n    sign as ``1e100``, the computed result is ``-1e-100 + 1e100``,\\n    which is numerically exactly equal to ``1e100``.  The function\\n    ``math.fmod()`` returns a result whose sign matches the sign of\\n    the first argument instead, and so returns ``-1e-100`` in this\\n    case. Which approach is more appropriate depends on the\\n    application.\\n\\n[2] If x is very close to an exact integer multiple of y, it\\'s\\n    possible for ``x//y`` to be one larger than ``(x-x%y)//y`` due to\\n    rounding.  In such cases, Python returns the latter result, in\\n    order to preserve that ``divmod(x,y)[0] * y + x % y`` be very\\n    close to ``x``.\\n\\n[3] While comparisons between strings make sense at the byte level,\\n    they may be counter-intuitive to users.  For example, the strings\\n    ``\"\\\\u00C7\"`` and ``\"\\\\u0327\\\\u0043\"`` compare differently, even\\n    though they both represent the same unicode character (LATIN\\n    CAPITAL LETTER C WITH CEDILLA).  To compare strings in a human\\n    recognizable way, compare using ``unicodedata.normalize()``.\\n\\n[4] Due to automatic garbage-collection, free lists, and the dynamic\\n    nature of descriptors, you may notice seemingly unusual behaviour\\n    in certain uses of the ``is`` operator, like those involving\\n    comparisons between instance methods, or constants.  Check their\\n    documentation for more info.\\n\\n[5] The ``%`` operator is also used for string formatting; the same\\n    precedence applies.\\n\\n[6] The power operator ``**`` binds less tightly than an arithmetic or\\n    bitwise unary operator on its right, that is, ``2**-1`` is\\n    ``0.5``.\\n',\n 'pass': '\\nThe ``pass`` statement\\n**********************\\n\\n   pass_stmt ::= \"pass\"\\n\\n``pass`` is a null operation --- when it is executed, nothing happens.\\nIt is useful as a placeholder when a statement is required\\nsyntactically, but no code needs to be executed, for example:\\n\\n   def f(arg): pass    # a function that does nothing (yet)\\n\\n   class C: pass       # a class with no methods (yet)\\n',\n 'power': '\\nThe power operator\\n******************\\n\\nThe power operator binds more tightly than unary operators on its\\nleft; it binds less tightly than unary operators on its right.  The\\nsyntax is:\\n\\n   power ::= primary [\"**\" u_expr]\\n\\nThus, in an unparenthesized sequence of power and unary operators, the\\noperators are evaluated from right to left (this does not constrain\\nthe evaluation order for the operands): ``-1**2`` results in ``-1``.\\n\\nThe power operator has the same semantics as the built-in ``pow()``\\nfunction, when called with two arguments: it yields its left argument\\nraised to the power of its right argument.  The numeric arguments are\\nfirst converted to a common type, and the result is of that type.\\n\\nFor int operands, the result has the same type as the operands unless\\nthe second argument is negative; in that case, all arguments are\\nconverted to float and a float result is delivered. For example,\\n``10**2`` returns ``100``, but ``10**-2`` returns ``0.01``.\\n\\nRaising ``0.0`` to a negative power results in a\\n``ZeroDivisionError``. Raising a negative number to a fractional power\\nresults in a ``complex`` number. (In earlier versions it raised a\\n``ValueError``.)\\n',\n 'raise': '\\nThe ``raise`` statement\\n***********************\\n\\n   raise_stmt ::= \"raise\" [expression [\"from\" expression]]\\n\\nIf no expressions are present, ``raise`` re-raises the last exception\\nthat was active in the current scope.  If no exception is active in\\nthe current scope, a ``RuntimeError`` exception is raised indicating\\nthat this is an error.\\n\\nOtherwise, ``raise`` evaluates the first expression as the exception\\nobject.  It must be either a subclass or an instance of\\n``BaseException``. If it is a class, the exception instance will be\\nobtained when needed by instantiating the class with no arguments.\\n\\nThe *type* of the exception is the exception instance\\'s class, the\\n*value* is the instance itself.\\n\\nA traceback object is normally created automatically when an exception\\nis raised and attached to it as the ``__traceback__`` attribute, which\\nis writable. You can create an exception and set your own traceback in\\none step using the ``with_traceback()`` exception method (which\\nreturns the same exception instance, with its traceback set to its\\nargument), like so:\\n\\n   raise Exception(\"foo occurred\").with_traceback(tracebackobj)\\n\\nThe ``from`` clause is used for exception chaining: if given, the\\nsecond *expression* must be another exception class or instance, which\\nwill then be attached to the raised exception as the ``__cause__``\\nattribute (which is writable).  If the raised exception is not\\nhandled, both exceptions will be printed:\\n\\n   >>> try:\\n   ...     print(1 / 0)\\n   ... except Exception as exc:\\n   ...     raise RuntimeError(\"Something bad happened\") from exc\\n   ...\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 2, in <module>\\n   ZeroDivisionError: int division or modulo by zero\\n\\n   The above exception was the direct cause of the following exception:\\n\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 4, in <module>\\n   RuntimeError: Something bad happened\\n\\nA similar mechanism works implicitly if an exception is raised inside\\nan exception handler: the previous exception is then attached as the\\nnew exception\\'s ``__context__`` attribute:\\n\\n   >>> try:\\n   ...     print(1 / 0)\\n   ... except:\\n   ...     raise RuntimeError(\"Something bad happened\")\\n   ...\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 2, in <module>\\n   ZeroDivisionError: int division or modulo by zero\\n\\n   During handling of the above exception, another exception occurred:\\n\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 4, in <module>\\n   RuntimeError: Something bad happened\\n\\nAdditional information on exceptions can be found in section\\n*Exceptions*, and information about handling exceptions is in section\\n*The try statement*.\\n',\n 'return': '\\nThe ``return`` statement\\n************************\\n\\n   return_stmt ::= \"return\" [expression_list]\\n\\n``return`` may only occur syntactically nested in a function\\ndefinition, not within a nested class definition.\\n\\nIf an expression list is present, it is evaluated, else ``None`` is\\nsubstituted.\\n\\n``return`` leaves the current function call with the expression list\\n(or ``None``) as return value.\\n\\nWhen ``return`` passes control out of a ``try`` statement with a\\n``finally`` clause, that ``finally`` clause is executed before really\\nleaving the function.\\n\\nIn a generator function, the ``return`` statement indicates that the\\ngenerator is done and will cause ``StopIteration`` to be raised. The\\nreturned value (if any) is used as an argument to construct\\n``StopIteration`` and becomes the ``StopIteration.value`` attribute.\\n',\n 'sequence-types': \"\\nEmulating container types\\n*************************\\n\\nThe following methods can be defined to implement container objects.\\nContainers usually are sequences (such as lists or tuples) or mappings\\n(like dictionaries), but can represent other containers as well.  The\\nfirst set of methods is used either to emulate a sequence or to\\nemulate a mapping; the difference is that for a sequence, the\\nallowable keys should be the integers *k* for which ``0 <= k < N``\\nwhere *N* is the length of the sequence, or slice objects, which\\ndefine a range of items.  It is also recommended that mappings provide\\nthe methods ``keys()``, ``values()``, ``items()``, ``get()``,\\n``clear()``, ``setdefault()``, ``pop()``, ``popitem()``, ``copy()``,\\nand ``update()`` behaving similar to those for Python's standard\\ndictionary objects.  The ``collections`` module provides a\\n``MutableMapping`` abstract base class to help create those methods\\nfrom a base set of ``__getitem__()``, ``__setitem__()``,\\n``__delitem__()``, and ``keys()``. Mutable sequences should provide\\nmethods ``append()``, ``count()``, ``index()``, ``extend()``,\\n``insert()``, ``pop()``, ``remove()``, ``reverse()`` and ``sort()``,\\nlike Python standard list objects.  Finally, sequence types should\\nimplement addition (meaning concatenation) and multiplication (meaning\\nrepetition) by defining the methods ``__add__()``, ``__radd__()``,\\n``__iadd__()``, ``__mul__()``, ``__rmul__()`` and ``__imul__()``\\ndescribed below; they should not define other numerical operators.  It\\nis recommended that both mappings and sequences implement the\\n``__contains__()`` method to allow efficient use of the ``in``\\noperator; for mappings, ``in`` should search the mapping's keys; for\\nsequences, it should search through the values.  It is further\\nrecommended that both mappings and sequences implement the\\n``__iter__()`` method to allow efficient iteration through the\\ncontainer; for mappings, ``__iter__()`` should be the same as\\n``keys()``; for sequences, it should iterate through the values.\\n\\nobject.__len__(self)\\n\\n   Called to implement the built-in function ``len()``.  Should return\\n   the length of the object, an integer ``>=`` 0.  Also, an object\\n   that doesn't define a ``__bool__()`` method and whose ``__len__()``\\n   method returns zero is considered to be false in a Boolean context.\\n\\nNote: Slicing is done exclusively with the following three methods.  A\\n  call like\\n\\n     a[1:2] = b\\n\\n  is translated to\\n\\n     a[slice(1, 2, None)] = b\\n\\n  and so forth.  Missing slice items are always filled in with\\n  ``None``.\\n\\nobject.__getitem__(self, key)\\n\\n   Called to implement evaluation of ``self[key]``. For sequence\\n   types, the accepted keys should be integers and slice objects.\\n   Note that the special interpretation of negative indexes (if the\\n   class wishes to emulate a sequence type) is up to the\\n   ``__getitem__()`` method. If *key* is of an inappropriate type,\\n   ``TypeError`` may be raised; if of a value outside the set of\\n   indexes for the sequence (after any special interpretation of\\n   negative values), ``IndexError`` should be raised. For mapping\\n   types, if *key* is missing (not in the container), ``KeyError``\\n   should be raised.\\n\\n   Note: ``for`` loops expect that an ``IndexError`` will be raised for\\n     illegal indexes to allow proper detection of the end of the\\n     sequence.\\n\\nobject.__setitem__(self, key, value)\\n\\n   Called to implement assignment to ``self[key]``.  Same note as for\\n   ``__getitem__()``.  This should only be implemented for mappings if\\n   the objects support changes to the values for keys, or if new keys\\n   can be added, or for sequences if elements can be replaced.  The\\n   same exceptions should be raised for improper *key* values as for\\n   the ``__getitem__()`` method.\\n\\nobject.__delitem__(self, key)\\n\\n   Called to implement deletion of ``self[key]``.  Same note as for\\n   ``__getitem__()``.  This should only be implemented for mappings if\\n   the objects support removal of keys, or for sequences if elements\\n   can be removed from the sequence.  The same exceptions should be\\n   raised for improper *key* values as for the ``__getitem__()``\\n   method.\\n\\nobject.__iter__(self)\\n\\n   This method is called when an iterator is required for a container.\\n   This method should return a new iterator object that can iterate\\n   over all the objects in the container.  For mappings, it should\\n   iterate over the keys of the container, and should also be made\\n   available as the method ``keys()``.\\n\\n   Iterator objects also need to implement this method; they are\\n   required to return themselves.  For more information on iterator\\n   objects, see *Iterator Types*.\\n\\nobject.__reversed__(self)\\n\\n   Called (if present) by the ``reversed()`` built-in to implement\\n   reverse iteration.  It should return a new iterator object that\\n   iterates over all the objects in the container in reverse order.\\n\\n   If the ``__reversed__()`` method is not provided, the\\n   ``reversed()`` built-in will fall back to using the sequence\\n   protocol (``__len__()`` and ``__getitem__()``).  Objects that\\n   support the sequence protocol should only provide\\n   ``__reversed__()`` if they can provide an implementation that is\\n   more efficient than the one provided by ``reversed()``.\\n\\nThe membership test operators (``in`` and ``not in``) are normally\\nimplemented as an iteration through a sequence.  However, container\\nobjects can supply the following special method with a more efficient\\nimplementation, which also does not require the object be a sequence.\\n\\nobject.__contains__(self, item)\\n\\n   Called to implement membership test operators.  Should return true\\n   if *item* is in *self*, false otherwise.  For mapping objects, this\\n   should consider the keys of the mapping rather than the values or\\n   the key-item pairs.\\n\\n   For objects that don't define ``__contains__()``, the membership\\n   test first tries iteration via ``__iter__()``, then the old\\n   sequence iteration protocol via ``__getitem__()``, see *this\\n   section in the language reference*.\\n\",\n 'shifting': '\\nShifting operations\\n*******************\\n\\nThe shifting operations have lower priority than the arithmetic\\noperations:\\n\\n   shift_expr ::= a_expr | shift_expr ( \"<<\" | \">>\" ) a_expr\\n\\nThese operators accept integers as arguments.  They shift the first\\nargument to the left or right by the number of bits given by the\\nsecond argument.\\n\\nA right shift by *n* bits is defined as division by ``pow(2,n)``.  A\\nleft shift by *n* bits is defined as multiplication with ``pow(2,n)``.\\n\\nNote: In the current implementation, the right-hand operand is required to\\n  be at most ``sys.maxsize``.  If the right-hand operand is larger\\n  than ``sys.maxsize`` an ``OverflowError`` exception is raised.\\n',\n 'slicings': '\\nSlicings\\n********\\n\\nA slicing selects a range of items in a sequence object (e.g., a\\nstring, tuple or list).  Slicings may be used as expressions or as\\ntargets in assignment or ``del`` statements.  The syntax for a\\nslicing:\\n\\n   slicing      ::= primary \"[\" slice_list \"]\"\\n   slice_list   ::= slice_item (\",\" slice_item)* [\",\"]\\n   slice_item   ::= expression | proper_slice\\n   proper_slice ::= [lower_bound] \":\" [upper_bound] [ \":\" [stride] ]\\n   lower_bound  ::= expression\\n   upper_bound  ::= expression\\n   stride       ::= expression\\n\\nThere is ambiguity in the formal syntax here: anything that looks like\\nan expression list also looks like a slice list, so any subscription\\ncan be interpreted as a slicing.  Rather than further complicating the\\nsyntax, this is disambiguated by defining that in this case the\\ninterpretation as a subscription takes priority over the\\ninterpretation as a slicing (this is the case if the slice list\\ncontains no proper slice).\\n\\nThe semantics for a slicing are as follows.  The primary must evaluate\\nto a mapping object, and it is indexed (using the same\\n``__getitem__()`` method as normal subscription) with a key that is\\nconstructed from the slice list, as follows.  If the slice list\\ncontains at least one comma, the key is a tuple containing the\\nconversion of the slice items; otherwise, the conversion of the lone\\nslice item is the key.  The conversion of a slice item that is an\\nexpression is that expression.  The conversion of a proper slice is a\\nslice object (see section *The standard type hierarchy*) whose\\n``start``, ``stop`` and ``step`` attributes are the values of the\\nexpressions given as lower bound, upper bound and stride,\\nrespectively, substituting ``None`` for missing expressions.\\n',\n 'specialattrs': '\\nSpecial Attributes\\n******************\\n\\nThe implementation adds a few special read-only attributes to several\\nobject types, where they are relevant.  Some of these are not reported\\nby the ``dir()`` built-in function.\\n\\nobject.__dict__\\n\\n   A dictionary or other mapping object used to store an object\\'s\\n   (writable) attributes.\\n\\ninstance.__class__\\n\\n   The class to which a class instance belongs.\\n\\nclass.__bases__\\n\\n   The tuple of base classes of a class object.\\n\\nclass.__name__\\n\\n   The name of the class or type.\\n\\nclass.__qualname__\\n\\n   The *qualified name* of the class or type.\\n\\n   New in version 3.3.\\n\\nclass.__mro__\\n\\n   This attribute is a tuple of classes that are considered when\\n   looking for base classes during method resolution.\\n\\nclass.mro()\\n\\n   This method can be overridden by a metaclass to customize the\\n   method resolution order for its instances.  It is called at class\\n   instantiation, and its result is stored in ``__mro__``.\\n\\nclass.__subclasses__()\\n\\n   Each class keeps a list of weak references to its immediate\\n   subclasses.  This method returns a list of all those references\\n   still alive. Example:\\n\\n      >>> int.__subclasses__()\\n      [<class \\'bool\\'>]\\n\\n-[ Footnotes ]-\\n\\n[1] Additional information on these special methods may be found in\\n    the Python Reference Manual (*Basic customization*).\\n\\n[2] As a consequence, the list ``[1, 2]`` is considered equal to\\n    ``[1.0, 2.0]``, and similarly for tuples.\\n\\n[3] They must have since the parser can\\'t tell the type of the\\n    operands.\\n\\n[4] Cased characters are those with general category property being\\n    one of \"Lu\" (Letter, uppercase), \"Ll\" (Letter, lowercase), or \"Lt\"\\n    (Letter, titlecase).\\n\\n[5] To format only a tuple you should therefore provide a singleton\\n    tuple whose only element is the tuple to be formatted.\\n',\n 'specialnames': '\\nSpecial method names\\n********************\\n\\nA class can implement certain operations that are invoked by special\\nsyntax (such as arithmetic operations or subscripting and slicing) by\\ndefining methods with special names. This is Python\\'s approach to\\n*operator overloading*, allowing classes to define their own behavior\\nwith respect to language operators.  For instance, if a class defines\\na method named ``__getitem__()``, and ``x`` is an instance of this\\nclass, then ``x[i]`` is roughly equivalent to ``type(x).__getitem__(x,\\ni)``.  Except where mentioned, attempts to execute an operation raise\\nan exception when no appropriate method is defined (typically\\n``AttributeError`` or ``TypeError``).\\n\\nWhen implementing a class that emulates any built-in type, it is\\nimportant that the emulation only be implemented to the degree that it\\nmakes sense for the object being modelled.  For example, some\\nsequences may work well with retrieval of individual elements, but\\nextracting a slice may not make sense.  (One example of this is the\\n``NodeList`` interface in the W3C\\'s Document Object Model.)\\n\\n\\nBasic customization\\n===================\\n\\nobject.__new__(cls[, ...])\\n\\n   Called to create a new instance of class *cls*.  ``__new__()`` is a\\n   static method (special-cased so you need not declare it as such)\\n   that takes the class of which an instance was requested as its\\n   first argument.  The remaining arguments are those passed to the\\n   object constructor expression (the call to the class).  The return\\n   value of ``__new__()`` should be the new object instance (usually\\n   an instance of *cls*).\\n\\n   Typical implementations create a new instance of the class by\\n   invoking the superclass\\'s ``__new__()`` method using\\n   ``super(currentclass, cls).__new__(cls[, ...])`` with appropriate\\n   arguments and then modifying the newly-created instance as\\n   necessary before returning it.\\n\\n   If ``__new__()`` returns an instance of *cls*, then the new\\n   instance\\'s ``__init__()`` method will be invoked like\\n   ``__init__(self[, ...])``, where *self* is the new instance and the\\n   remaining arguments are the same as were passed to ``__new__()``.\\n\\n   If ``__new__()`` does not return an instance of *cls*, then the new\\n   instance\\'s ``__init__()`` method will not be invoked.\\n\\n   ``__new__()`` is intended mainly to allow subclasses of immutable\\n   types (like int, str, or tuple) to customize instance creation.  It\\n   is also commonly overridden in custom metaclasses in order to\\n   customize class creation.\\n\\nobject.__init__(self[, ...])\\n\\n   Called when the instance is created.  The arguments are those\\n   passed to the class constructor expression.  If a base class has an\\n   ``__init__()`` method, the derived class\\'s ``__init__()`` method,\\n   if any, must explicitly call it to ensure proper initialization of\\n   the base class part of the instance; for example:\\n   ``BaseClass.__init__(self, [args...])``.  As a special constraint\\n   on constructors, no value may be returned; doing so will cause a\\n   ``TypeError`` to be raised at runtime.\\n\\nobject.__del__(self)\\n\\n   Called when the instance is about to be destroyed.  This is also\\n   called a destructor.  If a base class has a ``__del__()`` method,\\n   the derived class\\'s ``__del__()`` method, if any, must explicitly\\n   call it to ensure proper deletion of the base class part of the\\n   instance.  Note that it is possible (though not recommended!) for\\n   the ``__del__()`` method to postpone destruction of the instance by\\n   creating a new reference to it.  It may then be called at a later\\n   time when this new reference is deleted.  It is not guaranteed that\\n   ``__del__()`` methods are called for objects that still exist when\\n   the interpreter exits.\\n\\n   Note: ``del x`` doesn\\'t directly call ``x.__del__()`` --- the former\\n     decrements the reference count for ``x`` by one, and the latter\\n     is only called when ``x``\\'s reference count reaches zero.  Some\\n     common situations that may prevent the reference count of an\\n     object from going to zero include: circular references between\\n     objects (e.g., a doubly-linked list or a tree data structure with\\n     parent and child pointers); a reference to the object on the\\n     stack frame of a function that caught an exception (the traceback\\n     stored in ``sys.exc_info()[2]`` keeps the stack frame alive); or\\n     a reference to the object on the stack frame that raised an\\n     unhandled exception in interactive mode (the traceback stored in\\n     ``sys.last_traceback`` keeps the stack frame alive).  The first\\n     situation can only be remedied by explicitly breaking the cycles;\\n     the latter two situations can be resolved by storing ``None`` in\\n     ``sys.last_traceback``. Circular references which are garbage are\\n     detected when the option cycle detector is enabled (it\\'s on by\\n     default), but can only be cleaned up if there are no Python-\\n     level ``__del__()`` methods involved. Refer to the documentation\\n     for the ``gc`` module for more information about how\\n     ``__del__()`` methods are handled by the cycle detector,\\n     particularly the description of the ``garbage`` value.\\n\\n   Warning: Due to the precarious circumstances under which ``__del__()``\\n     methods are invoked, exceptions that occur during their execution\\n     are ignored, and a warning is printed to ``sys.stderr`` instead.\\n     Also, when ``__del__()`` is invoked in response to a module being\\n     deleted (e.g., when execution of the program is done), other\\n     globals referenced by the ``__del__()`` method may already have\\n     been deleted or in the process of being torn down (e.g. the\\n     import machinery shutting down).  For this reason, ``__del__()``\\n     methods should do the absolute minimum needed to maintain\\n     external invariants.  Starting with version 1.5, Python\\n     guarantees that globals whose name begins with a single\\n     underscore are deleted from their module before other globals are\\n     deleted; if no other references to such globals exist, this may\\n     help in assuring that imported modules are still available at the\\n     time when the ``__del__()`` method is called.\\n\\nobject.__repr__(self)\\n\\n   Called by the ``repr()`` built-in function to compute the\\n   \"official\" string representation of an object.  If at all possible,\\n   this should look like a valid Python expression that could be used\\n   to recreate an object with the same value (given an appropriate\\n   environment).  If this is not possible, a string of the form\\n   ``<...some useful description...>`` should be returned. The return\\n   value must be a string object. If a class defines ``__repr__()``\\n   but not ``__str__()``, then ``__repr__()`` is also used when an\\n   \"informal\" string representation of instances of that class is\\n   required.\\n\\n   This is typically used for debugging, so it is important that the\\n   representation is information-rich and unambiguous.\\n\\nobject.__str__(self)\\n\\n   Called by ``str(object)`` and the built-in functions ``format()``\\n   and ``print()`` to compute the \"informal\" or nicely printable\\n   string representation of an object.  The return value must be a\\n   *string* object.\\n\\n   This method differs from ``object.__repr__()`` in that there is no\\n   expectation that ``__str__()`` return a valid Python expression: a\\n   more convenient or concise representation can be used.\\n\\n   The default implementation defined by the built-in type ``object``\\n   calls ``object.__repr__()``.\\n\\nobject.__bytes__(self)\\n\\n   Called by ``bytes()`` to compute a byte-string representation of an\\n   object. This should return a ``bytes`` object.\\n\\nobject.__format__(self, format_spec)\\n\\n   Called by the ``format()`` built-in function (and by extension, the\\n   ``str.format()`` method of class ``str``) to produce a \"formatted\"\\n   string representation of an object. The ``format_spec`` argument is\\n   a string that contains a description of the formatting options\\n   desired. The interpretation of the ``format_spec`` argument is up\\n   to the type implementing ``__format__()``, however most classes\\n   will either delegate formatting to one of the built-in types, or\\n   use a similar formatting option syntax.\\n\\n   See *Format Specification Mini-Language* for a description of the\\n   standard formatting syntax.\\n\\n   The return value must be a string object.\\n\\nobject.__lt__(self, other)\\nobject.__le__(self, other)\\nobject.__eq__(self, other)\\nobject.__ne__(self, other)\\nobject.__gt__(self, other)\\nobject.__ge__(self, other)\\n\\n   These are the so-called \"rich comparison\" methods. The\\n   correspondence between operator symbols and method names is as\\n   follows: ``x<y`` calls ``x.__lt__(y)``, ``x<=y`` calls\\n   ``x.__le__(y)``, ``x==y`` calls ``x.__eq__(y)``, ``x!=y`` calls\\n   ``x.__ne__(y)``, ``x>y`` calls ``x.__gt__(y)``, and ``x>=y`` calls\\n   ``x.__ge__(y)``.\\n\\n   A rich comparison method may return the singleton\\n   ``NotImplemented`` if it does not implement the operation for a\\n   given pair of arguments. By convention, ``False`` and ``True`` are\\n   returned for a successful comparison. However, these methods can\\n   return any value, so if the comparison operator is used in a\\n   Boolean context (e.g., in the condition of an ``if`` statement),\\n   Python will call ``bool()`` on the value to determine if the result\\n   is true or false.\\n\\n   There are no implied relationships among the comparison operators.\\n   The truth of ``x==y`` does not imply that ``x!=y`` is false.\\n   Accordingly, when defining ``__eq__()``, one should also define\\n   ``__ne__()`` so that the operators will behave as expected.  See\\n   the paragraph on ``__hash__()`` for some important notes on\\n   creating *hashable* objects which support custom comparison\\n   operations and are usable as dictionary keys.\\n\\n   There are no swapped-argument versions of these methods (to be used\\n   when the left argument does not support the operation but the right\\n   argument does); rather, ``__lt__()`` and ``__gt__()`` are each\\n   other\\'s reflection, ``__le__()`` and ``__ge__()`` are each other\\'s\\n   reflection, and ``__eq__()`` and ``__ne__()`` are their own\\n   reflection.\\n\\n   Arguments to rich comparison methods are never coerced.\\n\\n   To automatically generate ordering operations from a single root\\n   operation, see ``functools.total_ordering()``.\\n\\nobject.__hash__(self)\\n\\n   Called by built-in function ``hash()`` and for operations on\\n   members of hashed collections including ``set``, ``frozenset``, and\\n   ``dict``.  ``__hash__()`` should return an integer.  The only\\n   required property is that objects which compare equal have the same\\n   hash value; it is advised to somehow mix together (e.g. using\\n   exclusive or) the hash values for the components of the object that\\n   also play a part in comparison of objects.\\n\\n   If a class does not define an ``__eq__()`` method it should not\\n   define a ``__hash__()`` operation either; if it defines\\n   ``__eq__()`` but not ``__hash__()``, its instances will not be\\n   usable as items in hashable collections.  If a class defines\\n   mutable objects and implements an ``__eq__()`` method, it should\\n   not implement ``__hash__()``, since the implementation of hashable\\n   collections requires that a key\\'s hash value is immutable (if the\\n   object\\'s hash value changes, it will be in the wrong hash bucket).\\n\\n   User-defined classes have ``__eq__()`` and ``__hash__()`` methods\\n   by default; with them, all objects compare unequal (except with\\n   themselves) and ``x.__hash__()`` returns an appropriate value such\\n   that ``x == y`` implies both that ``x is y`` and ``hash(x) ==\\n   hash(y)``.\\n\\n   A class that overrides ``__eq__()`` and does not define\\n   ``__hash__()`` will have its ``__hash__()`` implicitly set to\\n   ``None``.  When the ``__hash__()`` method of a class is ``None``,\\n   instances of the class will raise an appropriate ``TypeError`` when\\n   a program attempts to retrieve their hash value, and will also be\\n   correctly identified as unhashable when checking ``isinstance(obj,\\n   collections.Hashable``).\\n\\n   If a class that overrides ``__eq__()`` needs to retain the\\n   implementation of ``__hash__()`` from a parent class, the\\n   interpreter must be told this explicitly by setting ``__hash__ =\\n   <ParentClass>.__hash__``.\\n\\n   If a class that does not override ``__eq__()`` wishes to suppress\\n   hash support, it should include ``__hash__ = None`` in the class\\n   definition. A class which defines its own ``__hash__()`` that\\n   explicitly raises a ``TypeError`` would be incorrectly identified\\n   as hashable by an ``isinstance(obj, collections.Hashable)`` call.\\n\\n   Note: By default, the ``__hash__()`` values of str, bytes and datetime\\n     objects are \"salted\" with an unpredictable random value.\\n     Although they remain constant within an individual Python\\n     process, they are not predictable between repeated invocations of\\n     Python.This is intended to provide protection against a denial-\\n     of-service caused by carefully-chosen inputs that exploit the\\n     worst case performance of a dict insertion, O(n^2) complexity.\\n     See http://www.ocert.org/advisories/ocert-2011-003.html for\\n     details.Changing hash values affects the iteration order of\\n     dicts, sets and other mappings.  Python has never made guarantees\\n     about this ordering (and it typically varies between 32-bit and\\n     64-bit builds).See also ``PYTHONHASHSEED``.\\n\\n   Changed in version 3.3: Hash randomization is enabled by default.\\n\\nobject.__bool__(self)\\n\\n   Called to implement truth value testing and the built-in operation\\n   ``bool()``; should return ``False`` or ``True``.  When this method\\n   is not defined, ``__len__()`` is called, if it is defined, and the\\n   object is considered true if its result is nonzero.  If a class\\n   defines neither ``__len__()`` nor ``__bool__()``, all its instances\\n   are considered true.\\n\\n\\nCustomizing attribute access\\n============================\\n\\nThe following methods can be defined to customize the meaning of\\nattribute access (use of, assignment to, or deletion of ``x.name``)\\nfor class instances.\\n\\nobject.__getattr__(self, name)\\n\\n   Called when an attribute lookup has not found the attribute in the\\n   usual places (i.e. it is not an instance attribute nor is it found\\n   in the class tree for ``self``).  ``name`` is the attribute name.\\n   This method should return the (computed) attribute value or raise\\n   an ``AttributeError`` exception.\\n\\n   Note that if the attribute is found through the normal mechanism,\\n   ``__getattr__()`` is not called.  (This is an intentional asymmetry\\n   between ``__getattr__()`` and ``__setattr__()``.) This is done both\\n   for efficiency reasons and because otherwise ``__getattr__()``\\n   would have no way to access other attributes of the instance.  Note\\n   that at least for instance variables, you can fake total control by\\n   not inserting any values in the instance attribute dictionary (but\\n   instead inserting them in another object).  See the\\n   ``__getattribute__()`` method below for a way to actually get total\\n   control over attribute access.\\n\\nobject.__getattribute__(self, name)\\n\\n   Called unconditionally to implement attribute accesses for\\n   instances of the class. If the class also defines\\n   ``__getattr__()``, the latter will not be called unless\\n   ``__getattribute__()`` either calls it explicitly or raises an\\n   ``AttributeError``. This method should return the (computed)\\n   attribute value or raise an ``AttributeError`` exception. In order\\n   to avoid infinite recursion in this method, its implementation\\n   should always call the base class method with the same name to\\n   access any attributes it needs, for example,\\n   ``object.__getattribute__(self, name)``.\\n\\n   Note: This method may still be bypassed when looking up special methods\\n     as the result of implicit invocation via language syntax or\\n     built-in functions. See *Special method lookup*.\\n\\nobject.__setattr__(self, name, value)\\n\\n   Called when an attribute assignment is attempted.  This is called\\n   instead of the normal mechanism (i.e. store the value in the\\n   instance dictionary). *name* is the attribute name, *value* is the\\n   value to be assigned to it.\\n\\n   If ``__setattr__()`` wants to assign to an instance attribute, it\\n   should call the base class method with the same name, for example,\\n   ``object.__setattr__(self, name, value)``.\\n\\nobject.__delattr__(self, name)\\n\\n   Like ``__setattr__()`` but for attribute deletion instead of\\n   assignment.  This should only be implemented if ``del obj.name`` is\\n   meaningful for the object.\\n\\nobject.__dir__(self)\\n\\n   Called when ``dir()`` is called on the object. A sequence must be\\n   returned. ``dir()`` converts the returned sequence to a list and\\n   sorts it.\\n\\n\\nImplementing Descriptors\\n------------------------\\n\\nThe following methods only apply when an instance of the class\\ncontaining the method (a so-called *descriptor* class) appears in an\\n*owner* class (the descriptor must be in either the owner\\'s class\\ndictionary or in the class dictionary for one of its parents).  In the\\nexamples below, \"the attribute\" refers to the attribute whose name is\\nthe key of the property in the owner class\\' ``__dict__``.\\n\\nobject.__get__(self, instance, owner)\\n\\n   Called to get the attribute of the owner class (class attribute\\n   access) or of an instance of that class (instance attribute\\n   access). *owner* is always the owner class, while *instance* is the\\n   instance that the attribute was accessed through, or ``None`` when\\n   the attribute is accessed through the *owner*.  This method should\\n   return the (computed) attribute value or raise an\\n   ``AttributeError`` exception.\\n\\nobject.__set__(self, instance, value)\\n\\n   Called to set the attribute on an instance *instance* of the owner\\n   class to a new value, *value*.\\n\\nobject.__delete__(self, instance)\\n\\n   Called to delete the attribute on an instance *instance* of the\\n   owner class.\\n\\n\\nInvoking Descriptors\\n--------------------\\n\\nIn general, a descriptor is an object attribute with \"binding\\nbehavior\", one whose attribute access has been overridden by methods\\nin the descriptor protocol:  ``__get__()``, ``__set__()``, and\\n``__delete__()``. If any of those methods are defined for an object,\\nit is said to be a descriptor.\\n\\nThe default behavior for attribute access is to get, set, or delete\\nthe attribute from an object\\'s dictionary. For instance, ``a.x`` has a\\nlookup chain starting with ``a.__dict__[\\'x\\']``, then\\n``type(a).__dict__[\\'x\\']``, and continuing through the base classes of\\n``type(a)`` excluding metaclasses.\\n\\nHowever, if the looked-up value is an object defining one of the\\ndescriptor methods, then Python may override the default behavior and\\ninvoke the descriptor method instead.  Where this occurs in the\\nprecedence chain depends on which descriptor methods were defined and\\nhow they were called.\\n\\nThe starting point for descriptor invocation is a binding, ``a.x``.\\nHow the arguments are assembled depends on ``a``:\\n\\nDirect Call\\n   The simplest and least common call is when user code directly\\n   invokes a descriptor method:    ``x.__get__(a)``.\\n\\nInstance Binding\\n   If binding to an object instance, ``a.x`` is transformed into the\\n   call: ``type(a).__dict__[\\'x\\'].__get__(a, type(a))``.\\n\\nClass Binding\\n   If binding to a class, ``A.x`` is transformed into the call:\\n   ``A.__dict__[\\'x\\'].__get__(None, A)``.\\n\\nSuper Binding\\n   If ``a`` is an instance of ``super``, then the binding ``super(B,\\n   obj).m()`` searches ``obj.__class__.__mro__`` for the base class\\n   ``A`` immediately preceding ``B`` and then invokes the descriptor\\n   with the call: ``A.__dict__[\\'m\\'].__get__(obj, obj.__class__)``.\\n\\nFor instance bindings, the precedence of descriptor invocation depends\\non the which descriptor methods are defined.  A descriptor can define\\nany combination of ``__get__()``, ``__set__()`` and ``__delete__()``.\\nIf it does not define ``__get__()``, then accessing the attribute will\\nreturn the descriptor object itself unless there is a value in the\\nobject\\'s instance dictionary.  If the descriptor defines ``__set__()``\\nand/or ``__delete__()``, it is a data descriptor; if it defines\\nneither, it is a non-data descriptor.  Normally, data descriptors\\ndefine both ``__get__()`` and ``__set__()``, while non-data\\ndescriptors have just the ``__get__()`` method.  Data descriptors with\\n``__set__()`` and ``__get__()`` defined always override a redefinition\\nin an instance dictionary.  In contrast, non-data descriptors can be\\noverridden by instances.\\n\\nPython methods (including ``staticmethod()`` and ``classmethod()``)\\nare implemented as non-data descriptors.  Accordingly, instances can\\nredefine and override methods.  This allows individual instances to\\nacquire behaviors that differ from other instances of the same class.\\n\\nThe ``property()`` function is implemented as a data descriptor.\\nAccordingly, instances cannot override the behavior of a property.\\n\\n\\n__slots__\\n---------\\n\\nBy default, instances of classes have a dictionary for attribute\\nstorage.  This wastes space for objects having very few instance\\nvariables.  The space consumption can become acute when creating large\\nnumbers of instances.\\n\\nThe default can be overridden by defining *__slots__* in a class\\ndefinition. The *__slots__* declaration takes a sequence of instance\\nvariables and reserves just enough space in each instance to hold a\\nvalue for each variable.  Space is saved because *__dict__* is not\\ncreated for each instance.\\n\\nobject.__slots__\\n\\n   This class variable can be assigned a string, iterable, or sequence\\n   of strings with variable names used by instances.  If defined in a\\n   class, *__slots__* reserves space for the declared variables and\\n   prevents the automatic creation of *__dict__* and *__weakref__* for\\n   each instance.\\n\\n\\nNotes on using *__slots__*\\n~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\n* When inheriting from a class without *__slots__*, the *__dict__*\\n  attribute of that class will always be accessible, so a *__slots__*\\n  definition in the subclass is meaningless.\\n\\n* Without a *__dict__* variable, instances cannot be assigned new\\n  variables not listed in the *__slots__* definition.  Attempts to\\n  assign to an unlisted variable name raises ``AttributeError``. If\\n  dynamic assignment of new variables is desired, then add\\n  ``\\'__dict__\\'`` to the sequence of strings in the *__slots__*\\n  declaration.\\n\\n* Without a *__weakref__* variable for each instance, classes defining\\n  *__slots__* do not support weak references to its instances. If weak\\n  reference support is needed, then add ``\\'__weakref__\\'`` to the\\n  sequence of strings in the *__slots__* declaration.\\n\\n* *__slots__* are implemented at the class level by creating\\n  descriptors (*Implementing Descriptors*) for each variable name.  As\\n  a result, class attributes cannot be used to set default values for\\n  instance variables defined by *__slots__*; otherwise, the class\\n  attribute would overwrite the descriptor assignment.\\n\\n* The action of a *__slots__* declaration is limited to the class\\n  where it is defined.  As a result, subclasses will have a *__dict__*\\n  unless they also define *__slots__* (which must only contain names\\n  of any *additional* slots).\\n\\n* If a class defines a slot also defined in a base class, the instance\\n  variable defined by the base class slot is inaccessible (except by\\n  retrieving its descriptor directly from the base class). This\\n  renders the meaning of the program undefined.  In the future, a\\n  check may be added to prevent this.\\n\\n* Nonempty *__slots__* does not work for classes derived from\\n  \"variable-length\" built-in types such as ``int``, ``str`` and\\n  ``tuple``.\\n\\n* Any non-string iterable may be assigned to *__slots__*. Mappings may\\n  also be used; however, in the future, special meaning may be\\n  assigned to the values corresponding to each key.\\n\\n* *__class__* assignment works only if both classes have the same\\n  *__slots__*.\\n\\n\\nCustomizing class creation\\n==========================\\n\\nBy default, classes are constructed using ``type()``. The class body\\nis executed in a new namespace and the class name is bound locally to\\nthe result of ``type(name, bases, namespace)``.\\n\\nThe class creation process can be customised by passing the\\n``metaclass`` keyword argument in the class definition line, or by\\ninheriting from an existing class that included such an argument. In\\nthe following example, both ``MyClass`` and ``MySubclass`` are\\ninstances of ``Meta``:\\n\\n   class Meta(type):\\n       pass\\n\\n   class MyClass(metaclass=Meta):\\n       pass\\n\\n   class MySubclass(MyClass):\\n       pass\\n\\nAny other keyword arguments that are specified in the class definition\\nare passed through to all metaclass operations described below.\\n\\nWhen a class definition is executed, the following steps occur:\\n\\n* the appropriate metaclass is determined\\n\\n* the class namespace is prepared\\n\\n* the class body is executed\\n\\n* the class object is created\\n\\n\\nDetermining the appropriate metaclass\\n-------------------------------------\\n\\nThe appropriate metaclass for a class definition is determined as\\nfollows:\\n\\n* if no bases and no explicit metaclass are given, then ``type()`` is\\n  used\\n\\n* if an explicit metaclass is given and it is *not* an instance of\\n  ``type()``, then it is used directly as the metaclass\\n\\n* if an instance of ``type()`` is given as the explicit metaclass, or\\n  bases are defined, then the most derived metaclass is used\\n\\nThe most derived metaclass is selected from the explicitly specified\\nmetaclass (if any) and the metaclasses (i.e. ``type(cls)``) of all\\nspecified base classes. The most derived metaclass is one which is a\\nsubtype of *all* of these candidate metaclasses. If none of the\\ncandidate metaclasses meets that criterion, then the class definition\\nwill fail with ``TypeError``.\\n\\n\\nPreparing the class namespace\\n-----------------------------\\n\\nOnce the appropriate metaclass has been identified, then the class\\nnamespace is prepared. If the metaclass has a ``__prepare__``\\nattribute, it is called as ``namespace = metaclass.__prepare__(name,\\nbases, **kwds)`` (where the additional keyword arguments, if any, come\\nfrom the class definition).\\n\\nIf the metaclass has no ``__prepare__`` attribute, then the class\\nnamespace is initialised as an empty ``dict()`` instance.\\n\\nSee also:\\n\\n   **PEP 3115** - Metaclasses in Python 3000\\n      Introduced the ``__prepare__`` namespace hook\\n\\n\\nExecuting the class body\\n------------------------\\n\\nThe class body is executed (approximately) as ``exec(body, globals(),\\nnamespace)``. The key difference from a normal call to ``exec()`` is\\nthat lexical scoping allows the class body (including any methods) to\\nreference names from the current and outer scopes when the class\\ndefinition occurs inside a function.\\n\\nHowever, even when the class definition occurs inside the function,\\nmethods defined inside the class still cannot see names defined at the\\nclass scope. Class variables must be accessed through the first\\nparameter of instance or class methods, and cannot be accessed at all\\nfrom static methods.\\n\\n\\nCreating the class object\\n-------------------------\\n\\nOnce the class namespace has been populated by executing the class\\nbody, the class object is created by calling ``metaclass(name, bases,\\nnamespace, **kwds)`` (the additional keywords passed here are the same\\nas those passed to ``__prepare__``).\\n\\nThis class object is the one that will be referenced by the zero-\\nargument form of ``super()``. ``__class__`` is an implicit closure\\nreference created by the compiler if any methods in a class body refer\\nto either ``__class__`` or ``super``. This allows the zero argument\\nform of ``super()`` to correctly identify the class being defined\\nbased on lexical scoping, while the class or instance that was used to\\nmake the current call is identified based on the first argument passed\\nto the method.\\n\\nAfter the class object is created, it is passed to the class\\ndecorators included in the class definition (if any) and the resulting\\nobject is bound in the local namespace as the defined class.\\n\\nSee also:\\n\\n   **PEP 3135** - New super\\n      Describes the implicit ``__class__`` closure reference\\n\\n\\nMetaclass example\\n-----------------\\n\\nThe potential uses for metaclasses are boundless. Some ideas that have\\nbeen explored include logging, interface checking, automatic\\ndelegation, automatic property creation, proxies, frameworks, and\\nautomatic resource locking/synchronization.\\n\\nHere is an example of a metaclass that uses an\\n``collections.OrderedDict`` to remember the order that class members\\nwere defined:\\n\\n   class OrderedClass(type):\\n\\n        @classmethod\\n        def __prepare__(metacls, name, bases, **kwds):\\n           return collections.OrderedDict()\\n\\n        def __new__(cls, name, bases, namespace, **kwds):\\n           result = type.__new__(cls, name, bases, dict(namespace))\\n           result.members = tuple(namespace)\\n           return result\\n\\n   class A(metaclass=OrderedClass):\\n       def one(self): pass\\n       def two(self): pass\\n       def three(self): pass\\n       def four(self): pass\\n\\n   >>> A.members\\n   (\\'__module__\\', \\'one\\', \\'two\\', \\'three\\', \\'four\\')\\n\\nWhen the class definition for *A* gets executed, the process begins\\nwith calling the metaclass\\'s ``__prepare__()`` method which returns an\\nempty ``collections.OrderedDict``.  That mapping records the methods\\nand attributes of *A* as they are defined within the body of the class\\nstatement. Once those definitions are executed, the ordered dictionary\\nis fully populated and the metaclass\\'s ``__new__()`` method gets\\ninvoked.  That method builds the new type and it saves the ordered\\ndictionary keys in an attribute called ``members``.\\n\\n\\nCustomizing instance and subclass checks\\n========================================\\n\\nThe following methods are used to override the default behavior of the\\n``isinstance()`` and ``issubclass()`` built-in functions.\\n\\nIn particular, the metaclass ``abc.ABCMeta`` implements these methods\\nin order to allow the addition of Abstract Base Classes (ABCs) as\\n\"virtual base classes\" to any class or type (including built-in\\ntypes), including other ABCs.\\n\\nclass.__instancecheck__(self, instance)\\n\\n   Return true if *instance* should be considered a (direct or\\n   indirect) instance of *class*. If defined, called to implement\\n   ``isinstance(instance, class)``.\\n\\nclass.__subclasscheck__(self, subclass)\\n\\n   Return true if *subclass* should be considered a (direct or\\n   indirect) subclass of *class*.  If defined, called to implement\\n   ``issubclass(subclass, class)``.\\n\\nNote that these methods are looked up on the type (metaclass) of a\\nclass.  They cannot be defined as class methods in the actual class.\\nThis is consistent with the lookup of special methods that are called\\non instances, only in this case the instance is itself a class.\\n\\nSee also:\\n\\n   **PEP 3119** - Introducing Abstract Base Classes\\n      Includes the specification for customizing ``isinstance()`` and\\n      ``issubclass()`` behavior through ``__instancecheck__()`` and\\n      ``__subclasscheck__()``, with motivation for this functionality\\n      in the context of adding Abstract Base Classes (see the ``abc``\\n      module) to the language.\\n\\n\\nEmulating callable objects\\n==========================\\n\\nobject.__call__(self[, args...])\\n\\n   Called when the instance is \"called\" as a function; if this method\\n   is defined, ``x(arg1, arg2, ...)`` is a shorthand for\\n   ``x.__call__(arg1, arg2, ...)``.\\n\\n\\nEmulating container types\\n=========================\\n\\nThe following methods can be defined to implement container objects.\\nContainers usually are sequences (such as lists or tuples) or mappings\\n(like dictionaries), but can represent other containers as well.  The\\nfirst set of methods is used either to emulate a sequence or to\\nemulate a mapping; the difference is that for a sequence, the\\nallowable keys should be the integers *k* for which ``0 <= k < N``\\nwhere *N* is the length of the sequence, or slice objects, which\\ndefine a range of items.  It is also recommended that mappings provide\\nthe methods ``keys()``, ``values()``, ``items()``, ``get()``,\\n``clear()``, ``setdefault()``, ``pop()``, ``popitem()``, ``copy()``,\\nand ``update()`` behaving similar to those for Python\\'s standard\\ndictionary objects.  The ``collections`` module provides a\\n``MutableMapping`` abstract base class to help create those methods\\nfrom a base set of ``__getitem__()``, ``__setitem__()``,\\n``__delitem__()``, and ``keys()``. Mutable sequences should provide\\nmethods ``append()``, ``count()``, ``index()``, ``extend()``,\\n``insert()``, ``pop()``, ``remove()``, ``reverse()`` and ``sort()``,\\nlike Python standard list objects.  Finally, sequence types should\\nimplement addition (meaning concatenation) and multiplication (meaning\\nrepetition) by defining the methods ``__add__()``, ``__radd__()``,\\n``__iadd__()``, ``__mul__()``, ``__rmul__()`` and ``__imul__()``\\ndescribed below; they should not define other numerical operators.  It\\nis recommended that both mappings and sequences implement the\\n``__contains__()`` method to allow efficient use of the ``in``\\noperator; for mappings, ``in`` should search the mapping\\'s keys; for\\nsequences, it should search through the values.  It is further\\nrecommended that both mappings and sequences implement the\\n``__iter__()`` method to allow efficient iteration through the\\ncontainer; for mappings, ``__iter__()`` should be the same as\\n``keys()``; for sequences, it should iterate through the values.\\n\\nobject.__len__(self)\\n\\n   Called to implement the built-in function ``len()``.  Should return\\n   the length of the object, an integer ``>=`` 0.  Also, an object\\n   that doesn\\'t define a ``__bool__()`` method and whose ``__len__()``\\n   method returns zero is considered to be false in a Boolean context.\\n\\nNote: Slicing is done exclusively with the following three methods.  A\\n  call like\\n\\n     a[1:2] = b\\n\\n  is translated to\\n\\n     a[slice(1, 2, None)] = b\\n\\n  and so forth.  Missing slice items are always filled in with\\n  ``None``.\\n\\nobject.__getitem__(self, key)\\n\\n   Called to implement evaluation of ``self[key]``. For sequence\\n   types, the accepted keys should be integers and slice objects.\\n   Note that the special interpretation of negative indexes (if the\\n   class wishes to emulate a sequence type) is up to the\\n   ``__getitem__()`` method. If *key* is of an inappropriate type,\\n   ``TypeError`` may be raised; if of a value outside the set of\\n   indexes for the sequence (after any special interpretation of\\n   negative values), ``IndexError`` should be raised. For mapping\\n   types, if *key* is missing (not in the container), ``KeyError``\\n   should be raised.\\n\\n   Note: ``for`` loops expect that an ``IndexError`` will be raised for\\n     illegal indexes to allow proper detection of the end of the\\n     sequence.\\n\\nobject.__setitem__(self, key, value)\\n\\n   Called to implement assignment to ``self[key]``.  Same note as for\\n   ``__getitem__()``.  This should only be implemented for mappings if\\n   the objects support changes to the values for keys, or if new keys\\n   can be added, or for sequences if elements can be replaced.  The\\n   same exceptions should be raised for improper *key* values as for\\n   the ``__getitem__()`` method.\\n\\nobject.__delitem__(self, key)\\n\\n   Called to implement deletion of ``self[key]``.  Same note as for\\n   ``__getitem__()``.  This should only be implemented for mappings if\\n   the objects support removal of keys, or for sequences if elements\\n   can be removed from the sequence.  The same exceptions should be\\n   raised for improper *key* values as for the ``__getitem__()``\\n   method.\\n\\nobject.__iter__(self)\\n\\n   This method is called when an iterator is required for a container.\\n   This method should return a new iterator object that can iterate\\n   over all the objects in the container.  For mappings, it should\\n   iterate over the keys of the container, and should also be made\\n   available as the method ``keys()``.\\n\\n   Iterator objects also need to implement this method; they are\\n   required to return themselves.  For more information on iterator\\n   objects, see *Iterator Types*.\\n\\nobject.__reversed__(self)\\n\\n   Called (if present) by the ``reversed()`` built-in to implement\\n   reverse iteration.  It should return a new iterator object that\\n   iterates over all the objects in the container in reverse order.\\n\\n   If the ``__reversed__()`` method is not provided, the\\n   ``reversed()`` built-in will fall back to using the sequence\\n   protocol (``__len__()`` and ``__getitem__()``).  Objects that\\n   support the sequence protocol should only provide\\n   ``__reversed__()`` if they can provide an implementation that is\\n   more efficient than the one provided by ``reversed()``.\\n\\nThe membership test operators (``in`` and ``not in``) are normally\\nimplemented as an iteration through a sequence.  However, container\\nobjects can supply the following special method with a more efficient\\nimplementation, which also does not require the object be a sequence.\\n\\nobject.__contains__(self, item)\\n\\n   Called to implement membership test operators.  Should return true\\n   if *item* is in *self*, false otherwise.  For mapping objects, this\\n   should consider the keys of the mapping rather than the values or\\n   the key-item pairs.\\n\\n   For objects that don\\'t define ``__contains__()``, the membership\\n   test first tries iteration via ``__iter__()``, then the old\\n   sequence iteration protocol via ``__getitem__()``, see *this\\n   section in the language reference*.\\n\\n\\nEmulating numeric types\\n=======================\\n\\nThe following methods can be defined to emulate numeric objects.\\nMethods corresponding to operations that are not supported by the\\nparticular kind of number implemented (e.g., bitwise operations for\\nnon-integral numbers) should be left undefined.\\n\\nobject.__add__(self, other)\\nobject.__sub__(self, other)\\nobject.__mul__(self, other)\\nobject.__truediv__(self, other)\\nobject.__floordiv__(self, other)\\nobject.__mod__(self, other)\\nobject.__divmod__(self, other)\\nobject.__pow__(self, other[, modulo])\\nobject.__lshift__(self, other)\\nobject.__rshift__(self, other)\\nobject.__and__(self, other)\\nobject.__xor__(self, other)\\nobject.__or__(self, other)\\n\\n   These methods are called to implement the binary arithmetic\\n   operations (``+``, ``-``, ``*``, ``/``, ``//``, ``%``,\\n   ``divmod()``, ``pow()``, ``**``, ``<<``, ``>>``, ``&``, ``^``,\\n   ``|``).  For instance, to evaluate the expression ``x + y``, where\\n   *x* is an instance of a class that has an ``__add__()`` method,\\n   ``x.__add__(y)`` is called.  The ``__divmod__()`` method should be\\n   the equivalent to using ``__floordiv__()`` and ``__mod__()``; it\\n   should not be related to ``__truediv__()``.  Note that\\n   ``__pow__()`` should be defined to accept an optional third\\n   argument if the ternary version of the built-in ``pow()`` function\\n   is to be supported.\\n\\n   If one of those methods does not support the operation with the\\n   supplied arguments, it should return ``NotImplemented``.\\n\\nobject.__radd__(self, other)\\nobject.__rsub__(self, other)\\nobject.__rmul__(self, other)\\nobject.__rtruediv__(self, other)\\nobject.__rfloordiv__(self, other)\\nobject.__rmod__(self, other)\\nobject.__rdivmod__(self, other)\\nobject.__rpow__(self, other)\\nobject.__rlshift__(self, other)\\nobject.__rrshift__(self, other)\\nobject.__rand__(self, other)\\nobject.__rxor__(self, other)\\nobject.__ror__(self, other)\\n\\n   These methods are called to implement the binary arithmetic\\n   operations (``+``, ``-``, ``*``, ``/``, ``//``, ``%``,\\n   ``divmod()``, ``pow()``, ``**``, ``<<``, ``>>``, ``&``, ``^``,\\n   ``|``) with reflected (swapped) operands. These functions are only\\n   called if the left operand does not support the corresponding\\n   operation and the operands are of different types. [2]  For\\n   instance, to evaluate the expression ``x - y``, where *y* is an\\n   instance of a class that has an ``__rsub__()`` method,\\n   ``y.__rsub__(x)`` is called if ``x.__sub__(y)`` returns\\n   *NotImplemented*.\\n\\n   Note that ternary ``pow()`` will not try calling ``__rpow__()``\\n   (the coercion rules would become too complicated).\\n\\n   Note: If the right operand\\'s type is a subclass of the left operand\\'s\\n     type and that subclass provides the reflected method for the\\n     operation, this method will be called before the left operand\\'s\\n     non-reflected method.  This behavior allows subclasses to\\n     override their ancestors\\' operations.\\n\\nobject.__iadd__(self, other)\\nobject.__isub__(self, other)\\nobject.__imul__(self, other)\\nobject.__itruediv__(self, other)\\nobject.__ifloordiv__(self, other)\\nobject.__imod__(self, other)\\nobject.__ipow__(self, other[, modulo])\\nobject.__ilshift__(self, other)\\nobject.__irshift__(self, other)\\nobject.__iand__(self, other)\\nobject.__ixor__(self, other)\\nobject.__ior__(self, other)\\n\\n   These methods are called to implement the augmented arithmetic\\n   assignments (``+=``, ``-=``, ``*=``, ``/=``, ``//=``, ``%=``,\\n   ``**=``, ``<<=``, ``>>=``, ``&=``, ``^=``, ``|=``).  These methods\\n   should attempt to do the operation in-place (modifying *self*) and\\n   return the result (which could be, but does not have to be,\\n   *self*).  If a specific method is not defined, the augmented\\n   assignment falls back to the normal methods.  For instance, to\\n   execute the statement ``x += y``, where *x* is an instance of a\\n   class that has an ``__iadd__()`` method, ``x.__iadd__(y)`` is\\n   called.  If *x* is an instance of a class that does not define a\\n   ``__iadd__()`` method, ``x.__add__(y)`` and ``y.__radd__(x)`` are\\n   considered, as with the evaluation of ``x + y``.\\n\\nobject.__neg__(self)\\nobject.__pos__(self)\\nobject.__abs__(self)\\nobject.__invert__(self)\\n\\n   Called to implement the unary arithmetic operations (``-``, ``+``,\\n   ``abs()`` and ``~``).\\n\\nobject.__complex__(self)\\nobject.__int__(self)\\nobject.__float__(self)\\nobject.__round__(self[, n])\\n\\n   Called to implement the built-in functions ``complex()``,\\n   ``int()``, ``float()`` and ``round()``.  Should return a value of\\n   the appropriate type.\\n\\nobject.__index__(self)\\n\\n   Called to implement ``operator.index()``.  Also called whenever\\n   Python needs an integer object (such as in slicing, or in the\\n   built-in ``bin()``, ``hex()`` and ``oct()`` functions). Must return\\n   an integer.\\n\\n\\nWith Statement Context Managers\\n===============================\\n\\nA *context manager* is an object that defines the runtime context to\\nbe established when executing a ``with`` statement. The context\\nmanager handles the entry into, and the exit from, the desired runtime\\ncontext for the execution of the block of code.  Context managers are\\nnormally invoked using the ``with`` statement (described in section\\n*The with statement*), but can also be used by directly invoking their\\nmethods.\\n\\nTypical uses of context managers include saving and restoring various\\nkinds of global state, locking and unlocking resources, closing opened\\nfiles, etc.\\n\\nFor more information on context managers, see *Context Manager Types*.\\n\\nobject.__enter__(self)\\n\\n   Enter the runtime context related to this object. The ``with``\\n   statement will bind this method\\'s return value to the target(s)\\n   specified in the ``as`` clause of the statement, if any.\\n\\nobject.__exit__(self, exc_type, exc_value, traceback)\\n\\n   Exit the runtime context related to this object. The parameters\\n   describe the exception that caused the context to be exited. If the\\n   context was exited without an exception, all three arguments will\\n   be ``None``.\\n\\n   If an exception is supplied, and the method wishes to suppress the\\n   exception (i.e., prevent it from being propagated), it should\\n   return a true value. Otherwise, the exception will be processed\\n   normally upon exit from this method.\\n\\n   Note that ``__exit__()`` methods should not reraise the passed-in\\n   exception; this is the caller\\'s responsibility.\\n\\nSee also:\\n\\n   **PEP 0343** - The \"with\" statement\\n      The specification, background, and examples for the Python\\n      ``with`` statement.\\n\\n\\nSpecial method lookup\\n=====================\\n\\nFor custom classes, implicit invocations of special methods are only\\nguaranteed to work correctly if defined on an object\\'s type, not in\\nthe object\\'s instance dictionary.  That behaviour is the reason why\\nthe following code raises an exception:\\n\\n   >>> class C:\\n   ...     pass\\n   ...\\n   >>> c = C()\\n   >>> c.__len__ = lambda: 5\\n   >>> len(c)\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 1, in <module>\\n   TypeError: object of type \\'C\\' has no len()\\n\\nThe rationale behind this behaviour lies with a number of special\\nmethods such as ``__hash__()`` and ``__repr__()`` that are implemented\\nby all objects, including type objects. If the implicit lookup of\\nthese methods used the conventional lookup process, they would fail\\nwhen invoked on the type object itself:\\n\\n   >>> 1 .__hash__() == hash(1)\\n   True\\n   >>> int.__hash__() == hash(int)\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 1, in <module>\\n   TypeError: descriptor \\'__hash__\\' of \\'int\\' object needs an argument\\n\\nIncorrectly attempting to invoke an unbound method of a class in this\\nway is sometimes referred to as \\'metaclass confusion\\', and is avoided\\nby bypassing the instance when looking up special methods:\\n\\n   >>> type(1).__hash__(1) == hash(1)\\n   True\\n   >>> type(int).__hash__(int) == hash(int)\\n   True\\n\\nIn addition to bypassing any instance attributes in the interest of\\ncorrectness, implicit special method lookup generally also bypasses\\nthe ``__getattribute__()`` method even of the object\\'s metaclass:\\n\\n   >>> class Meta(type):\\n   ...    def __getattribute__(*args):\\n   ...       print(\"Metaclass getattribute invoked\")\\n   ...       return type.__getattribute__(*args)\\n   ...\\n   >>> class C(object, metaclass=Meta):\\n   ...     def __len__(self):\\n   ...         return 10\\n   ...     def __getattribute__(*args):\\n   ...         print(\"Class getattribute invoked\")\\n   ...         return object.__getattribute__(*args)\\n   ...\\n   >>> c = C()\\n   >>> c.__len__()                 # Explicit lookup via instance\\n   Class getattribute invoked\\n   10\\n   >>> type(c).__len__(c)          # Explicit lookup via type\\n   Metaclass getattribute invoked\\n   10\\n   >>> len(c)                      # Implicit lookup\\n   10\\n\\nBypassing the ``__getattribute__()`` machinery in this fashion\\nprovides significant scope for speed optimisations within the\\ninterpreter, at the cost of some flexibility in the handling of\\nspecial methods (the special method *must* be set on the class object\\nitself in order to be consistently invoked by the interpreter).\\n\\n-[ Footnotes ]-\\n\\n[1] It *is* possible in some cases to change an object\\'s type, under\\n    certain controlled conditions. It generally isn\\'t a good idea\\n    though, since it can lead to some very strange behaviour if it is\\n    handled incorrectly.\\n\\n[2] For operands of the same type, it is assumed that if the non-\\n    reflected method (such as ``__add__()``) fails the operation is\\n    not supported, which is why the reflected method is not called.\\n',\n 'string-methods': '\\nString Methods\\n**************\\n\\nStrings implement all of the *common* sequence operations, along with\\nthe additional methods described below.\\n\\nStrings also support two styles of string formatting, one providing a\\nlarge degree of flexibility and customization (see ``str.format()``,\\n*Format String Syntax* and *String Formatting*) and the other based on\\nC ``printf`` style formatting that handles a narrower range of types\\nand is slightly harder to use correctly, but is often faster for the\\ncases it can handle (*printf-style String Formatting*).\\n\\nThe *Text Processing Services* section of the standard library covers\\na number of other modules that provide various text related utilities\\n(including regular expression support in the ``re`` module).\\n\\nstr.capitalize()\\n\\n   Return a copy of the string with its first character capitalized\\n   and the rest lowercased.\\n\\nstr.casefold()\\n\\n   Return a casefolded copy of the string. Casefolded strings may be\\n   used for caseless matching.\\n\\n   Casefolding is similar to lowercasing but more aggressive because\\n   it is intended to remove all case distinctions in a string. For\\n   example, the German lowercase letter ``\\'\\xc3\\x9f\\'`` is equivalent to\\n   ``\"ss\"``. Since it is already lowercase, ``lower()`` would do\\n   nothing to ``\\'\\xc3\\x9f\\'``; ``casefold()`` converts it to ``\"ss\"``.\\n\\n   The casefolding algorithm is described in section 3.13 of the\\n   Unicode Standard.\\n\\n   New in version 3.3.\\n\\nstr.center(width[, fillchar])\\n\\n   Return centered in a string of length *width*. Padding is done\\n   using the specified *fillchar* (default is a space).\\n\\nstr.count(sub[, start[, end]])\\n\\n   Return the number of non-overlapping occurrences of substring *sub*\\n   in the range [*start*, *end*].  Optional arguments *start* and\\n   *end* are interpreted as in slice notation.\\n\\nstr.encode(encoding=\"utf-8\", errors=\"strict\")\\n\\n   Return an encoded version of the string as a bytes object. Default\\n   encoding is ``\\'utf-8\\'``. *errors* may be given to set a different\\n   error handling scheme. The default for *errors* is ``\\'strict\\'``,\\n   meaning that encoding errors raise a ``UnicodeError``. Other\\n   possible values are ``\\'ignore\\'``, ``\\'replace\\'``,\\n   ``\\'xmlcharrefreplace\\'``, ``\\'backslashreplace\\'`` and any other name\\n   registered via ``codecs.register_error()``, see section *Codec Base\\n   Classes*. For a list of possible encodings, see section *Standard\\n   Encodings*.\\n\\n   Changed in version 3.1: Support for keyword arguments added.\\n\\nstr.endswith(suffix[, start[, end]])\\n\\n   Return ``True`` if the string ends with the specified *suffix*,\\n   otherwise return ``False``.  *suffix* can also be a tuple of\\n   suffixes to look for.  With optional *start*, test beginning at\\n   that position.  With optional *end*, stop comparing at that\\n   position.\\n\\nstr.expandtabs([tabsize])\\n\\n   Return a copy of the string where all tab characters are replaced\\n   by zero or more spaces, depending on the current column and the\\n   given tab size.  The column number is reset to zero after each\\n   newline occurring in the string. If *tabsize* is not given, a tab\\n   size of ``8`` characters is assumed.  This doesn\\'t understand other\\n   non-printing characters or escape sequences.\\n\\nstr.find(sub[, start[, end]])\\n\\n   Return the lowest index in the string where substring *sub* is\\n   found, such that *sub* is contained in the slice ``s[start:end]``.\\n   Optional arguments *start* and *end* are interpreted as in slice\\n   notation.  Return ``-1`` if *sub* is not found.\\n\\n   Note: The ``find()`` method should be used only if you need to know the\\n     position of *sub*.  To check if *sub* is a substring or not, use\\n     the ``in`` operator:\\n\\n        >>> \\'Py\\' in \\'Python\\'\\n        True\\n\\nstr.format(*args, **kwargs)\\n\\n   Perform a string formatting operation.  The string on which this\\n   method is called can contain literal text or replacement fields\\n   delimited by braces ``{}``.  Each replacement field contains either\\n   the numeric index of a positional argument, or the name of a\\n   keyword argument.  Returns a copy of the string where each\\n   replacement field is replaced with the string value of the\\n   corresponding argument.\\n\\n   >>> \"The sum of 1 + 2 is {0}\".format(1+2)\\n   \\'The sum of 1 + 2 is 3\\'\\n\\n   See *Format String Syntax* for a description of the various\\n   formatting options that can be specified in format strings.\\n\\nstr.format_map(mapping)\\n\\n   Similar to ``str.format(**mapping)``, except that ``mapping`` is\\n   used directly and not copied to a ``dict`` .  This is useful if for\\n   example ``mapping`` is a dict subclass:\\n\\n   >>> class Default(dict):\\n   ...     def __missing__(self, key):\\n   ...         return key\\n   ...\\n   >>> \\'{name} was born in {country}\\'.format_map(Default(name=\\'Guido\\'))\\n   \\'Guido was born in country\\'\\n\\n   New in version 3.2.\\n\\nstr.index(sub[, start[, end]])\\n\\n   Like ``find()``, but raise ``ValueError`` when the substring is not\\n   found.\\n\\nstr.isalnum()\\n\\n   Return true if all characters in the string are alphanumeric and\\n   there is at least one character, false otherwise.  A character\\n   ``c`` is alphanumeric if one of the following returns ``True``:\\n   ``c.isalpha()``, ``c.isdecimal()``, ``c.isdigit()``, or\\n   ``c.isnumeric()``.\\n\\nstr.isalpha()\\n\\n   Return true if all characters in the string are alphabetic and\\n   there is at least one character, false otherwise.  Alphabetic\\n   characters are those characters defined in the Unicode character\\n   database as \"Letter\", i.e., those with general category property\\n   being one of \"Lm\", \"Lt\", \"Lu\", \"Ll\", or \"Lo\".  Note that this is\\n   different from the \"Alphabetic\" property defined in the Unicode\\n   Standard.\\n\\nstr.isdecimal()\\n\\n   Return true if all characters in the string are decimal characters\\n   and there is at least one character, false otherwise. Decimal\\n   characters are those from general category \"Nd\". This category\\n   includes digit characters, and all characters that can be used to\\n   form decimal-radix numbers, e.g. U+0660, ARABIC-INDIC DIGIT ZERO.\\n\\nstr.isdigit()\\n\\n   Return true if all characters in the string are digits and there is\\n   at least one character, false otherwise.  Digits include decimal\\n   characters and digits that need special handling, such as the\\n   compatibility superscript digits.  Formally, a digit is a character\\n   that has the property value Numeric_Type=Digit or\\n   Numeric_Type=Decimal.\\n\\nstr.isidentifier()\\n\\n   Return true if the string is a valid identifier according to the\\n   language definition, section *Identifiers and keywords*.\\n\\nstr.islower()\\n\\n   Return true if all cased characters [4] in the string are lowercase\\n   and there is at least one cased character, false otherwise.\\n\\nstr.isnumeric()\\n\\n   Return true if all characters in the string are numeric characters,\\n   and there is at least one character, false otherwise. Numeric\\n   characters include digit characters, and all characters that have\\n   the Unicode numeric value property, e.g. U+2155, VULGAR FRACTION\\n   ONE FIFTH.  Formally, numeric characters are those with the\\n   property value Numeric_Type=Digit, Numeric_Type=Decimal or\\n   Numeric_Type=Numeric.\\n\\nstr.isprintable()\\n\\n   Return true if all characters in the string are printable or the\\n   string is empty, false otherwise.  Nonprintable characters are\\n   those characters defined in the Unicode character database as\\n   \"Other\" or \"Separator\", excepting the ASCII space (0x20) which is\\n   considered printable.  (Note that printable characters in this\\n   context are those which should not be escaped when ``repr()`` is\\n   invoked on a string.  It has no bearing on the handling of strings\\n   written to ``sys.stdout`` or ``sys.stderr``.)\\n\\nstr.isspace()\\n\\n   Return true if there are only whitespace characters in the string\\n   and there is at least one character, false otherwise.  Whitespace\\n   characters  are those characters defined in the Unicode character\\n   database as \"Other\" or \"Separator\" and those with bidirectional\\n   property being one of \"WS\", \"B\", or \"S\".\\n\\nstr.istitle()\\n\\n   Return true if the string is a titlecased string and there is at\\n   least one character, for example uppercase characters may only\\n   follow uncased characters and lowercase characters only cased ones.\\n   Return false otherwise.\\n\\nstr.isupper()\\n\\n   Return true if all cased characters [4] in the string are uppercase\\n   and there is at least one cased character, false otherwise.\\n\\nstr.join(iterable)\\n\\n   Return a string which is the concatenation of the strings in the\\n   *iterable* *iterable*.  A ``TypeError`` will be raised if there are\\n   any non-string values in *iterable*, including ``bytes`` objects.\\n   The separator between elements is the string providing this method.\\n\\nstr.ljust(width[, fillchar])\\n\\n   Return the string left justified in a string of length *width*.\\n   Padding is done using the specified *fillchar* (default is a\\n   space).  The original string is returned if *width* is less than or\\n   equal to ``len(s)``.\\n\\nstr.lower()\\n\\n   Return a copy of the string with all the cased characters [4]\\n   converted to lowercase.\\n\\n   The lowercasing algorithm used is described in section 3.13 of the\\n   Unicode Standard.\\n\\nstr.lstrip([chars])\\n\\n   Return a copy of the string with leading characters removed.  The\\n   *chars* argument is a string specifying the set of characters to be\\n   removed.  If omitted or ``None``, the *chars* argument defaults to\\n   removing whitespace.  The *chars* argument is not a prefix; rather,\\n   all combinations of its values are stripped:\\n\\n   >>> \\'   spacious   \\'.lstrip()\\n   \\'spacious   \\'\\n   >>> \\'www.example.com\\'.lstrip(\\'cmowz.\\')\\n   \\'example.com\\'\\n\\nstatic str.maketrans(x[, y[, z]])\\n\\n   This static method returns a translation table usable for\\n   ``str.translate()``.\\n\\n   If there is only one argument, it must be a dictionary mapping\\n   Unicode ordinals (integers) or characters (strings of length 1) to\\n   Unicode ordinals, strings (of arbitrary lengths) or None.\\n   Character keys will then be converted to ordinals.\\n\\n   If there are two arguments, they must be strings of equal length,\\n   and in the resulting dictionary, each character in x will be mapped\\n   to the character at the same position in y.  If there is a third\\n   argument, it must be a string, whose characters will be mapped to\\n   None in the result.\\n\\nstr.partition(sep)\\n\\n   Split the string at the first occurrence of *sep*, and return a\\n   3-tuple containing the part before the separator, the separator\\n   itself, and the part after the separator.  If the separator is not\\n   found, return a 3-tuple containing the string itself, followed by\\n   two empty strings.\\n\\nstr.replace(old, new[, count])\\n\\n   Return a copy of the string with all occurrences of substring *old*\\n   replaced by *new*.  If the optional argument *count* is given, only\\n   the first *count* occurrences are replaced.\\n\\nstr.rfind(sub[, start[, end]])\\n\\n   Return the highest index in the string where substring *sub* is\\n   found, such that *sub* is contained within ``s[start:end]``.\\n   Optional arguments *start* and *end* are interpreted as in slice\\n   notation.  Return ``-1`` on failure.\\n\\nstr.rindex(sub[, start[, end]])\\n\\n   Like ``rfind()`` but raises ``ValueError`` when the substring *sub*\\n   is not found.\\n\\nstr.rjust(width[, fillchar])\\n\\n   Return the string right justified in a string of length *width*.\\n   Padding is done using the specified *fillchar* (default is a\\n   space). The original string is returned if *width* is less than or\\n   equal to ``len(s)``.\\n\\nstr.rpartition(sep)\\n\\n   Split the string at the last occurrence of *sep*, and return a\\n   3-tuple containing the part before the separator, the separator\\n   itself, and the part after the separator.  If the separator is not\\n   found, return a 3-tuple containing two empty strings, followed by\\n   the string itself.\\n\\nstr.rsplit(sep=None, maxsplit=-1)\\n\\n   Return a list of the words in the string, using *sep* as the\\n   delimiter string. If *maxsplit* is given, at most *maxsplit* splits\\n   are done, the *rightmost* ones.  If *sep* is not specified or\\n   ``None``, any whitespace string is a separator.  Except for\\n   splitting from the right, ``rsplit()`` behaves like ``split()``\\n   which is described in detail below.\\n\\nstr.rstrip([chars])\\n\\n   Return a copy of the string with trailing characters removed.  The\\n   *chars* argument is a string specifying the set of characters to be\\n   removed.  If omitted or ``None``, the *chars* argument defaults to\\n   removing whitespace.  The *chars* argument is not a suffix; rather,\\n   all combinations of its values are stripped:\\n\\n   >>> \\'   spacious   \\'.rstrip()\\n   \\'   spacious\\'\\n   >>> \\'mississippi\\'.rstrip(\\'ipz\\')\\n   \\'mississ\\'\\n\\nstr.split(sep=None, maxsplit=-1)\\n\\n   Return a list of the words in the string, using *sep* as the\\n   delimiter string.  If *maxsplit* is given, at most *maxsplit*\\n   splits are done (thus, the list will have at most ``maxsplit+1``\\n   elements).  If *maxsplit* is not specified or ``-1``, then there is\\n   no limit on the number of splits (all possible splits are made).\\n\\n   If *sep* is given, consecutive delimiters are not grouped together\\n   and are deemed to delimit empty strings (for example,\\n   ``\\'1,,2\\'.split(\\',\\')`` returns ``[\\'1\\', \\'\\', \\'2\\']``).  The *sep*\\n   argument may consist of multiple characters (for example,\\n   ``\\'1<>2<>3\\'.split(\\'<>\\')`` returns ``[\\'1\\', \\'2\\', \\'3\\']``). Splitting\\n   an empty string with a specified separator returns ``[\\'\\']``.\\n\\n   If *sep* is not specified or is ``None``, a different splitting\\n   algorithm is applied: runs of consecutive whitespace are regarded\\n   as a single separator, and the result will contain no empty strings\\n   at the start or end if the string has leading or trailing\\n   whitespace.  Consequently, splitting an empty string or a string\\n   consisting of just whitespace with a ``None`` separator returns\\n   ``[]``.\\n\\n   For example, ``\\' 1  2   3  \\'.split()`` returns ``[\\'1\\', \\'2\\', \\'3\\']``,\\n   and ``\\'  1  2   3  \\'.split(None, 1)`` returns ``[\\'1\\', \\'2   3  \\']``.\\n\\nstr.splitlines([keepends])\\n\\n   Return a list of the lines in the string, breaking at line\\n   boundaries. This method uses the *universal newlines* approach to\\n   splitting lines. Line breaks are not included in the resulting list\\n   unless *keepends* is given and true.\\n\\n   For example, ``\\'ab c\\\\n\\\\nde fg\\\\rkl\\\\r\\\\n\\'.splitlines()`` returns\\n   ``[\\'ab c\\', \\'\\', \\'de fg\\', \\'kl\\']``, while the same call with\\n   ``splitlines(True)`` returns ``[\\'ab c\\\\n\\', \\'\\\\n\\', \\'de fg\\\\r\\',\\n   \\'kl\\\\r\\\\n\\']``.\\n\\n   Unlike ``split()`` when a delimiter string *sep* is given, this\\n   method returns an empty list for the empty string, and a terminal\\n   line break does not result in an extra line.\\n\\nstr.startswith(prefix[, start[, end]])\\n\\n   Return ``True`` if string starts with the *prefix*, otherwise\\n   return ``False``. *prefix* can also be a tuple of prefixes to look\\n   for.  With optional *start*, test string beginning at that\\n   position.  With optional *end*, stop comparing string at that\\n   position.\\n\\nstr.strip([chars])\\n\\n   Return a copy of the string with the leading and trailing\\n   characters removed. The *chars* argument is a string specifying the\\n   set of characters to be removed. If omitted or ``None``, the\\n   *chars* argument defaults to removing whitespace. The *chars*\\n   argument is not a prefix or suffix; rather, all combinations of its\\n   values are stripped:\\n\\n   >>> \\'   spacious   \\'.strip()\\n   \\'spacious\\'\\n   >>> \\'www.example.com\\'.strip(\\'cmowz.\\')\\n   \\'example\\'\\n\\nstr.swapcase()\\n\\n   Return a copy of the string with uppercase characters converted to\\n   lowercase and vice versa. Note that it is not necessarily true that\\n   ``s.swapcase().swapcase() == s``.\\n\\nstr.title()\\n\\n   Return a titlecased version of the string where words start with an\\n   uppercase character and the remaining characters are lowercase.\\n\\n   The algorithm uses a simple language-independent definition of a\\n   word as groups of consecutive letters.  The definition works in\\n   many contexts but it means that apostrophes in contractions and\\n   possessives form word boundaries, which may not be the desired\\n   result:\\n\\n      >>> \"they\\'re bill\\'s friends from the UK\".title()\\n      \"They\\'Re Bill\\'S Friends From The Uk\"\\n\\n   A workaround for apostrophes can be constructed using regular\\n   expressions:\\n\\n      >>> import re\\n      >>> def titlecase(s):\\n      ...     return re.sub(r\"[A-Za-z]+(\\'[A-Za-z]+)?\",\\n      ...                   lambda mo: mo.group(0)[0].upper() +\\n      ...                              mo.group(0)[1:].lower(),\\n      ...                   s)\\n      ...\\n      >>> titlecase(\"they\\'re bill\\'s friends.\")\\n      \"They\\'re Bill\\'s Friends.\"\\n\\nstr.translate(map)\\n\\n   Return a copy of the *s* where all characters have been mapped\\n   through the *map* which must be a dictionary of Unicode ordinals\\n   (integers) to Unicode ordinals, strings or ``None``.  Unmapped\\n   characters are left untouched. Characters mapped to ``None`` are\\n   deleted.\\n\\n   You can use ``str.maketrans()`` to create a translation map from\\n   character-to-character mappings in different formats.\\n\\n   Note: An even more flexible approach is to create a custom character\\n     mapping codec using the ``codecs`` module (see\\n     ``encodings.cp1251`` for an example).\\n\\nstr.upper()\\n\\n   Return a copy of the string with all the cased characters [4]\\n   converted to uppercase.  Note that ``str.upper().isupper()`` might\\n   be ``False`` if ``s`` contains uncased characters or if the Unicode\\n   category of the resulting character(s) is not \"Lu\" (Letter,\\n   uppercase), but e.g. \"Lt\" (Letter, titlecase).\\n\\n   The uppercasing algorithm used is described in section 3.13 of the\\n   Unicode Standard.\\n\\nstr.zfill(width)\\n\\n   Return the numeric string left filled with zeros in a string of\\n   length *width*.  A sign prefix is handled correctly.  The original\\n   string is returned if *width* is less than or equal to ``len(s)``.\\n',\n 'strings': '\\nString and Bytes literals\\n*************************\\n\\nString literals are described by the following lexical definitions:\\n\\n   stringliteral   ::= [stringprefix](shortstring | longstring)\\n   stringprefix    ::= \"r\" | \"u\" | \"R\" | \"U\"\\n   shortstring     ::= \"\\'\" shortstringitem* \"\\'\" | \\'\"\\' shortstringitem* \\'\"\\'\\n   longstring      ::= \"\\'\\'\\'\" longstringitem* \"\\'\\'\\'\" | \\'\"\"\"\\' longstringitem* \\'\"\"\"\\'\\n   shortstringitem ::= shortstringchar | stringescapeseq\\n   longstringitem  ::= longstringchar | stringescapeseq\\n   shortstringchar ::= <any source character except \"\\\\\" or newline or the quote>\\n   longstringchar  ::= <any source character except \"\\\\\">\\n   stringescapeseq ::= \"\\\\\" <any source character>\\n\\n   bytesliteral   ::= bytesprefix(shortbytes | longbytes)\\n   bytesprefix    ::= \"b\" | \"B\" | \"br\" | \"Br\" | \"bR\" | \"BR\" | \"rb\" | \"rB\" | \"Rb\" | \"RB\"\\n   shortbytes     ::= \"\\'\" shortbytesitem* \"\\'\" | \\'\"\\' shortbytesitem* \\'\"\\'\\n   longbytes      ::= \"\\'\\'\\'\" longbytesitem* \"\\'\\'\\'\" | \\'\"\"\"\\' longbytesitem* \\'\"\"\"\\'\\n   shortbytesitem ::= shortbyteschar | bytesescapeseq\\n   longbytesitem  ::= longbyteschar | bytesescapeseq\\n   shortbyteschar ::= <any ASCII character except \"\\\\\" or newline or the quote>\\n   longbyteschar  ::= <any ASCII character except \"\\\\\">\\n   bytesescapeseq ::= \"\\\\\" <any ASCII character>\\n\\nOne syntactic restriction not indicated by these productions is that\\nwhitespace is not allowed between the ``stringprefix`` or\\n``bytesprefix`` and the rest of the literal. The source character set\\nis defined by the encoding declaration; it is UTF-8 if no encoding\\ndeclaration is given in the source file; see section *Encoding\\ndeclarations*.\\n\\nIn plain English: Both types of literals can be enclosed in matching\\nsingle quotes (``\\'``) or double quotes (``\"``).  They can also be\\nenclosed in matching groups of three single or double quotes (these\\nare generally referred to as *triple-quoted strings*).  The backslash\\n(``\\\\``) character is used to escape characters that otherwise have a\\nspecial meaning, such as newline, backslash itself, or the quote\\ncharacter.\\n\\nBytes literals are always prefixed with ``\\'b\\'`` or ``\\'B\\'``; they\\nproduce an instance of the ``bytes`` type instead of the ``str`` type.\\nThey may only contain ASCII characters; bytes with a numeric value of\\n128 or greater must be expressed with escapes.\\n\\nAs of Python 3.3 it is possible again to prefix unicode strings with a\\n``u`` prefix to simplify maintenance of dual 2.x and 3.x codebases.\\n\\nBoth string and bytes literals may optionally be prefixed with a\\nletter ``\\'r\\'`` or ``\\'R\\'``; such strings are called *raw strings* and\\ntreat backslashes as literal characters.  As a result, in string\\nliterals, ``\\'\\\\U\\'`` and ``\\'\\\\u\\'`` escapes in raw strings are not treated\\nspecially. Given that Python 2.x\\'s raw unicode literals behave\\ndifferently than Python 3.x\\'s the ``\\'ur\\'`` syntax is not supported.\\n\\n   New in version 3.3: The ``\\'rb\\'`` prefix of raw bytes literals has\\n   been added as a synonym of ``\\'br\\'``.\\n\\n   New in version 3.3: Support for the unicode legacy literal\\n   (``u\\'value\\'``) was reintroduced to simplify the maintenance of dual\\n   Python 2.x and 3.x codebases. See **PEP 414** for more information.\\n\\nIn triple-quoted strings, unescaped newlines and quotes are allowed\\n(and are retained), except that three unescaped quotes in a row\\nterminate the string.  (A \"quote\" is the character used to open the\\nstring, i.e. either ``\\'`` or ``\"``.)\\n\\nUnless an ``\\'r\\'`` or ``\\'R\\'`` prefix is present, escape sequences in\\nstrings are interpreted according to rules similar to those used by\\nStandard C.  The recognized escape sequences are:\\n\\n+-------------------+-----------------------------------+---------+\\n| Escape Sequence   | Meaning                           | Notes   |\\n+===================+===================================+=========+\\n| ``\\\\newline``      | Backslash and newline ignored     |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\\\\\``            | Backslash (``\\\\``)                 |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\\\'``            | Single quote (``\\'``)              |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\\"``            | Double quote (``\"``)              |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\a``            | ASCII Bell (BEL)                  |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\b``            | ASCII Backspace (BS)              |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\f``            | ASCII Formfeed (FF)               |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\n``            | ASCII Linefeed (LF)               |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\r``            | ASCII Carriage Return (CR)        |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\t``            | ASCII Horizontal Tab (TAB)        |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\v``            | ASCII Vertical Tab (VT)           |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\ooo``          | Character with octal value *ooo*  | (1,3)   |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\xhh``          | Character with hex value *hh*     | (2,3)   |\\n+-------------------+-----------------------------------+---------+\\n\\nEscape sequences only recognized in string literals are:\\n\\n+-------------------+-----------------------------------+---------+\\n| Escape Sequence   | Meaning                           | Notes   |\\n+===================+===================================+=========+\\n| ``\\\\N{name}``      | Character named *name* in the     | (4)     |\\n|                   | Unicode database                  |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\uxxxx``        | Character with 16-bit hex value   | (5)     |\\n|                   | *xxxx*                            |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\Uxxxxxxxx``    | Character with 32-bit hex value   | (6)     |\\n|                   | *xxxxxxxx*                        |         |\\n+-------------------+-----------------------------------+---------+\\n\\nNotes:\\n\\n1. As in Standard C, up to three octal digits are accepted.\\n\\n2. Unlike in Standard C, exactly two hex digits are required.\\n\\n3. In a bytes literal, hexadecimal and octal escapes denote the byte\\n   with the given value. In a string literal, these escapes denote a\\n   Unicode character with the given value.\\n\\n4. Changed in version 3.3: Support for name aliases [1] has been\\n   added.\\n\\n5. Individual code units which form parts of a surrogate pair can be\\n   encoded using this escape sequence.  Exactly four hex digits are\\n   required.\\n\\n6. Any Unicode character can be encoded this way.  Exactly eight hex\\n   digits are required.\\n\\nUnlike Standard C, all unrecognized escape sequences are left in the\\nstring unchanged, i.e., *the backslash is left in the string*.  (This\\nbehavior is useful when debugging: if an escape sequence is mistyped,\\nthe resulting output is more easily recognized as broken.)  It is also\\nimportant to note that the escape sequences only recognized in string\\nliterals fall into the category of unrecognized escapes for bytes\\nliterals.\\n\\nEven in a raw string, string quotes can be escaped with a backslash,\\nbut the backslash remains in the string; for example, ``r\"\\\\\"\"`` is a\\nvalid string literal consisting of two characters: a backslash and a\\ndouble quote; ``r\"\\\\\"`` is not a valid string literal (even a raw\\nstring cannot end in an odd number of backslashes).  Specifically, *a\\nraw string cannot end in a single backslash* (since the backslash\\nwould escape the following quote character).  Note also that a single\\nbackslash followed by a newline is interpreted as those two characters\\nas part of the string, *not* as a line continuation.\\n',\n 'subscriptions': '\\nSubscriptions\\n*************\\n\\nA subscription selects an item of a sequence (string, tuple or list)\\nor mapping (dictionary) object:\\n\\n   subscription ::= primary \"[\" expression_list \"]\"\\n\\nThe primary must evaluate to an object that supports subscription,\\ne.g. a list or dictionary.  User-defined objects can support\\nsubscription by defining a ``__getitem__()`` method.\\n\\nFor built-in objects, there are two types of objects that support\\nsubscription:\\n\\nIf the primary is a mapping, the expression list must evaluate to an\\nobject whose value is one of the keys of the mapping, and the\\nsubscription selects the value in the mapping that corresponds to that\\nkey.  (The expression list is a tuple except if it has exactly one\\nitem.)\\n\\nIf the primary is a sequence, the expression (list) must evaluate to\\nan integer or a slice (as discussed in the following section).\\n\\nThe formal syntax makes no special provision for negative indices in\\nsequences; however, built-in sequences all provide a ``__getitem__()``\\nmethod that interprets negative indices by adding the length of the\\nsequence to the index (so that ``x[-1]`` selects the last item of\\n``x``).  The resulting value must be a nonnegative integer less than\\nthe number of items in the sequence, and the subscription selects the\\nitem whose index is that value (counting from zero). Since the support\\nfor negative indices and slicing occurs in the object\\'s\\n``__getitem__()`` method, subclasses overriding this method will need\\nto explicitly add that support.\\n\\nA string\\'s items are characters.  A character is not a separate data\\ntype but a string of exactly one character.\\n',\n 'truth': \"\\nTruth Value Testing\\n*******************\\n\\nAny object can be tested for truth value, for use in an ``if`` or\\n``while`` condition or as operand of the Boolean operations below. The\\nfollowing values are considered false:\\n\\n* ``None``\\n\\n* ``False``\\n\\n* zero of any numeric type, for example, ``0``, ``0.0``, ``0j``.\\n\\n* any empty sequence, for example, ``''``, ``()``, ``[]``.\\n\\n* any empty mapping, for example, ``{}``.\\n\\n* instances of user-defined classes, if the class defines a\\n  ``__bool__()`` or ``__len__()`` method, when that method returns the\\n  integer zero or ``bool`` value ``False``. [1]\\n\\nAll other values are considered true --- so objects of many types are\\nalways true.\\n\\nOperations and built-in functions that have a Boolean result always\\nreturn ``0`` or ``False`` for false and ``1`` or ``True`` for true,\\nunless otherwise stated. (Important exception: the Boolean operations\\n``or`` and ``and`` always return one of their operands.)\\n\",\n 'try': '\\nThe ``try`` statement\\n*********************\\n\\nThe ``try`` statement specifies exception handlers and/or cleanup code\\nfor a group of statements:\\n\\n   try_stmt  ::= try1_stmt | try2_stmt\\n   try1_stmt ::= \"try\" \":\" suite\\n                 (\"except\" [expression [\"as\" target]] \":\" suite)+\\n                 [\"else\" \":\" suite]\\n                 [\"finally\" \":\" suite]\\n   try2_stmt ::= \"try\" \":\" suite\\n                 \"finally\" \":\" suite\\n\\nThe ``except`` clause(s) specify one or more exception handlers. When\\nno exception occurs in the ``try`` clause, no exception handler is\\nexecuted. When an exception occurs in the ``try`` suite, a search for\\nan exception handler is started.  This search inspects the except\\nclauses in turn until one is found that matches the exception.  An\\nexpression-less except clause, if present, must be last; it matches\\nany exception.  For an except clause with an expression, that\\nexpression is evaluated, and the clause matches the exception if the\\nresulting object is \"compatible\" with the exception.  An object is\\ncompatible with an exception if it is the class or a base class of the\\nexception object or a tuple containing an item compatible with the\\nexception.\\n\\nIf no except clause matches the exception, the search for an exception\\nhandler continues in the surrounding code and on the invocation stack.\\n[1]\\n\\nIf the evaluation of an expression in the header of an except clause\\nraises an exception, the original search for a handler is canceled and\\na search starts for the new exception in the surrounding code and on\\nthe call stack (it is treated as if the entire ``try`` statement\\nraised the exception).\\n\\nWhen a matching except clause is found, the exception is assigned to\\nthe target specified after the ``as`` keyword in that except clause,\\nif present, and the except clause\\'s suite is executed.  All except\\nclauses must have an executable block.  When the end of this block is\\nreached, execution continues normally after the entire try statement.\\n(This means that if two nested handlers exist for the same exception,\\nand the exception occurs in the try clause of the inner handler, the\\nouter handler will not handle the exception.)\\n\\nWhen an exception has been assigned using ``as target``, it is cleared\\nat the end of the except clause.  This is as if\\n\\n   except E as N:\\n       foo\\n\\nwas translated to\\n\\n   except E as N:\\n       try:\\n           foo\\n       finally:\\n           del N\\n\\nThis means the exception must be assigned to a different name to be\\nable to refer to it after the except clause.  Exceptions are cleared\\nbecause with the traceback attached to them, they form a reference\\ncycle with the stack frame, keeping all locals in that frame alive\\nuntil the next garbage collection occurs.\\n\\nBefore an except clause\\'s suite is executed, details about the\\nexception are stored in the ``sys`` module and can be access via\\n``sys.exc_info()``. ``sys.exc_info()`` returns a 3-tuple consisting of\\nthe exception class, the exception instance and a traceback object\\n(see section *The standard type hierarchy*) identifying the point in\\nthe program where the exception occurred.  ``sys.exc_info()`` values\\nare restored to their previous values (before the call) when returning\\nfrom a function that handled an exception.\\n\\nThe optional ``else`` clause is executed if and when control flows off\\nthe end of the ``try`` clause. [2] Exceptions in the ``else`` clause\\nare not handled by the preceding ``except`` clauses.\\n\\nIf ``finally`` is present, it specifies a \\'cleanup\\' handler.  The\\n``try`` clause is executed, including any ``except`` and ``else``\\nclauses.  If an exception occurs in any of the clauses and is not\\nhandled, the exception is temporarily saved. The ``finally`` clause is\\nexecuted.  If there is a saved exception it is re-raised at the end of\\nthe ``finally`` clause.  If the ``finally`` clause raises another\\nexception, the saved exception is set as the context of the new\\nexception. If the ``finally`` clause executes a ``return`` or\\n``break`` statement, the saved exception is discarded:\\n\\n   def f():\\n       try:\\n           1/0\\n       finally:\\n           return 42\\n\\n   >>> f()\\n   42\\n\\nThe exception information is not available to the program during\\nexecution of the ``finally`` clause.\\n\\nWhen a ``return``, ``break`` or ``continue`` statement is executed in\\nthe ``try`` suite of a ``try``...``finally`` statement, the\\n``finally`` clause is also executed \\'on the way out.\\' A ``continue``\\nstatement is illegal in the ``finally`` clause. (The reason is a\\nproblem with the current implementation --- this restriction may be\\nlifted in the future).\\n\\nAdditional information on exceptions can be found in section\\n*Exceptions*, and information on using the ``raise`` statement to\\ngenerate exceptions may be found in section *The raise statement*.\\n',\n 'types': '\\nThe standard type hierarchy\\n***************************\\n\\nBelow is a list of the types that are built into Python.  Extension\\nmodules (written in C, Java, or other languages, depending on the\\nimplementation) can define additional types.  Future versions of\\nPython may add types to the type hierarchy (e.g., rational numbers,\\nefficiently stored arrays of integers, etc.), although such additions\\nwill often be provided via the standard library instead.\\n\\nSome of the type descriptions below contain a paragraph listing\\n\\'special attributes.\\'  These are attributes that provide access to the\\nimplementation and are not intended for general use.  Their definition\\nmay change in the future.\\n\\nNone\\n   This type has a single value.  There is a single object with this\\n   value. This object is accessed through the built-in name ``None``.\\n   It is used to signify the absence of a value in many situations,\\n   e.g., it is returned from functions that don\\'t explicitly return\\n   anything. Its truth value is false.\\n\\nNotImplemented\\n   This type has a single value.  There is a single object with this\\n   value. This object is accessed through the built-in name\\n   ``NotImplemented``. Numeric methods and rich comparison methods may\\n   return this value if they do not implement the operation for the\\n   operands provided.  (The interpreter will then try the reflected\\n   operation, or some other fallback, depending on the operator.)  Its\\n   truth value is true.\\n\\nEllipsis\\n   This type has a single value.  There is a single object with this\\n   value. This object is accessed through the literal ``...`` or the\\n   built-in name ``Ellipsis``.  Its truth value is true.\\n\\n``numbers.Number``\\n   These are created by numeric literals and returned as results by\\n   arithmetic operators and arithmetic built-in functions.  Numeric\\n   objects are immutable; once created their value never changes.\\n   Python numbers are of course strongly related to mathematical\\n   numbers, but subject to the limitations of numerical representation\\n   in computers.\\n\\n   Python distinguishes between integers, floating point numbers, and\\n   complex numbers:\\n\\n   ``numbers.Integral``\\n      These represent elements from the mathematical set of integers\\n      (positive and negative).\\n\\n      There are two types of integers:\\n\\n      Integers (``int``)\\n\\n         These represent numbers in an unlimited range, subject to\\n         available (virtual) memory only.  For the purpose of shift\\n         and mask operations, a binary representation is assumed, and\\n         negative numbers are represented in a variant of 2\\'s\\n         complement which gives the illusion of an infinite string of\\n         sign bits extending to the left.\\n\\n      Booleans (``bool``)\\n         These represent the truth values False and True.  The two\\n         objects representing the values False and True are the only\\n         Boolean objects. The Boolean type is a subtype of the integer\\n         type, and Boolean values behave like the values 0 and 1,\\n         respectively, in almost all contexts, the exception being\\n         that when converted to a string, the strings ``\"False\"`` or\\n         ``\"True\"`` are returned, respectively.\\n\\n      The rules for integer representation are intended to give the\\n      most meaningful interpretation of shift and mask operations\\n      involving negative integers.\\n\\n   ``numbers.Real`` (``float``)\\n      These represent machine-level double precision floating point\\n      numbers. You are at the mercy of the underlying machine\\n      architecture (and C or Java implementation) for the accepted\\n      range and handling of overflow. Python does not support single-\\n      precision floating point numbers; the savings in processor and\\n      memory usage that are usually the reason for using these is\\n      dwarfed by the overhead of using objects in Python, so there is\\n      no reason to complicate the language with two kinds of floating\\n      point numbers.\\n\\n   ``numbers.Complex`` (``complex``)\\n      These represent complex numbers as a pair of machine-level\\n      double precision floating point numbers.  The same caveats apply\\n      as for floating point numbers. The real and imaginary parts of a\\n      complex number ``z`` can be retrieved through the read-only\\n      attributes ``z.real`` and ``z.imag``.\\n\\nSequences\\n   These represent finite ordered sets indexed by non-negative\\n   numbers. The built-in function ``len()`` returns the number of\\n   items of a sequence. When the length of a sequence is *n*, the\\n   index set contains the numbers 0, 1, ..., *n*-1.  Item *i* of\\n   sequence *a* is selected by ``a[i]``.\\n\\n   Sequences also support slicing: ``a[i:j]`` selects all items with\\n   index *k* such that *i* ``<=`` *k* ``<`` *j*.  When used as an\\n   expression, a slice is a sequence of the same type.  This implies\\n   that the index set is renumbered so that it starts at 0.\\n\\n   Some sequences also support \"extended slicing\" with a third \"step\"\\n   parameter: ``a[i:j:k]`` selects all items of *a* with index *x*\\n   where ``x = i + n*k``, *n* ``>=`` ``0`` and *i* ``<=`` *x* ``<``\\n   *j*.\\n\\n   Sequences are distinguished according to their mutability:\\n\\n   Immutable sequences\\n      An object of an immutable sequence type cannot change once it is\\n      created.  (If the object contains references to other objects,\\n      these other objects may be mutable and may be changed; however,\\n      the collection of objects directly referenced by an immutable\\n      object cannot change.)\\n\\n      The following types are immutable sequences:\\n\\n      Strings\\n         A string is a sequence of values that represent Unicode\\n         codepoints. All the codepoints in range ``U+0000 - U+10FFFF``\\n         can be represented in a string.  Python doesn\\'t have a\\n         ``chr`` type, and every character in the string is\\n         represented as a string object with length ``1``.  The built-\\n         in function ``ord()`` converts a character to its codepoint\\n         (as an integer); ``chr()`` converts an integer in range ``0 -\\n         10FFFF`` to the corresponding character. ``str.encode()`` can\\n         be used to convert a ``str`` to ``bytes`` using the given\\n         encoding, and ``bytes.decode()`` can be used to achieve the\\n         opposite.\\n\\n      Tuples\\n         The items of a tuple are arbitrary Python objects. Tuples of\\n         two or more items are formed by comma-separated lists of\\n         expressions.  A tuple of one item (a \\'singleton\\') can be\\n         formed by affixing a comma to an expression (an expression by\\n         itself does not create a tuple, since parentheses must be\\n         usable for grouping of expressions).  An empty tuple can be\\n         formed by an empty pair of parentheses.\\n\\n      Bytes\\n         A bytes object is an immutable array.  The items are 8-bit\\n         bytes, represented by integers in the range 0 <= x < 256.\\n         Bytes literals (like ``b\\'abc\\'``) and the built-in function\\n         ``bytes()`` can be used to construct bytes objects.  Also,\\n         bytes objects can be decoded to strings via the ``decode()``\\n         method.\\n\\n   Mutable sequences\\n      Mutable sequences can be changed after they are created.  The\\n      subscription and slicing notations can be used as the target of\\n      assignment and ``del`` (delete) statements.\\n\\n      There are currently two intrinsic mutable sequence types:\\n\\n      Lists\\n         The items of a list are arbitrary Python objects.  Lists are\\n         formed by placing a comma-separated list of expressions in\\n         square brackets. (Note that there are no special cases needed\\n         to form lists of length 0 or 1.)\\n\\n      Byte Arrays\\n         A bytearray object is a mutable array. They are created by\\n         the built-in ``bytearray()`` constructor.  Aside from being\\n         mutable (and hence unhashable), byte arrays otherwise provide\\n         the same interface and functionality as immutable bytes\\n         objects.\\n\\n      The extension module ``array`` provides an additional example of\\n      a mutable sequence type, as does the ``collections`` module.\\n\\nSet types\\n   These represent unordered, finite sets of unique, immutable\\n   objects. As such, they cannot be indexed by any subscript. However,\\n   they can be iterated over, and the built-in function ``len()``\\n   returns the number of items in a set. Common uses for sets are fast\\n   membership testing, removing duplicates from a sequence, and\\n   computing mathematical operations such as intersection, union,\\n   difference, and symmetric difference.\\n\\n   For set elements, the same immutability rules apply as for\\n   dictionary keys. Note that numeric types obey the normal rules for\\n   numeric comparison: if two numbers compare equal (e.g., ``1`` and\\n   ``1.0``), only one of them can be contained in a set.\\n\\n   There are currently two intrinsic set types:\\n\\n   Sets\\n      These represent a mutable set. They are created by the built-in\\n      ``set()`` constructor and can be modified afterwards by several\\n      methods, such as ``add()``.\\n\\n   Frozen sets\\n      These represent an immutable set.  They are created by the\\n      built-in ``frozenset()`` constructor.  As a frozenset is\\n      immutable and *hashable*, it can be used again as an element of\\n      another set, or as a dictionary key.\\n\\nMappings\\n   These represent finite sets of objects indexed by arbitrary index\\n   sets. The subscript notation ``a[k]`` selects the item indexed by\\n   ``k`` from the mapping ``a``; this can be used in expressions and\\n   as the target of assignments or ``del`` statements. The built-in\\n   function ``len()`` returns the number of items in a mapping.\\n\\n   There is currently a single intrinsic mapping type:\\n\\n   Dictionaries\\n      These represent finite sets of objects indexed by nearly\\n      arbitrary values.  The only types of values not acceptable as\\n      keys are values containing lists or dictionaries or other\\n      mutable types that are compared by value rather than by object\\n      identity, the reason being that the efficient implementation of\\n      dictionaries requires a key\\'s hash value to remain constant.\\n      Numeric types used for keys obey the normal rules for numeric\\n      comparison: if two numbers compare equal (e.g., ``1`` and\\n      ``1.0``) then they can be used interchangeably to index the same\\n      dictionary entry.\\n\\n      Dictionaries are mutable; they can be created by the ``{...}``\\n      notation (see section *Dictionary displays*).\\n\\n      The extension modules ``dbm.ndbm`` and ``dbm.gnu`` provide\\n      additional examples of mapping types, as does the\\n      ``collections`` module.\\n\\nCallable types\\n   These are the types to which the function call operation (see\\n   section *Calls*) can be applied:\\n\\n   User-defined functions\\n      A user-defined function object is created by a function\\n      definition (see section *Function definitions*).  It should be\\n      called with an argument list containing the same number of items\\n      as the function\\'s formal parameter list.\\n\\n      Special attributes:\\n\\n      +---------------------------+---------------------------------+-------------+\\n      | Attribute                 | Meaning                         |             |\\n      +===========================+=================================+=============+\\n      | ``__doc__``               | The function\\'s documentation    | Writable    |\\n      |                           | string, or ``None`` if          |             |\\n      |                           | unavailable                     |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__name__``              | The function\\'s name             | Writable    |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__qualname__``          | The function\\'s *qualified name* | Writable    |\\n      |                           | New in version 3.3.             |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__module__``            | The name of the module the      | Writable    |\\n      |                           | function was defined in, or     |             |\\n      |                           | ``None`` if unavailable.        |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__defaults__``          | A tuple containing default      | Writable    |\\n      |                           | argument values for those       |             |\\n      |                           | arguments that have defaults,   |             |\\n      |                           | or ``None`` if no arguments     |             |\\n      |                           | have a default value            |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__code__``              | The code object representing    | Writable    |\\n      |                           | the compiled function body.     |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__globals__``           | A reference to the dictionary   | Read-only   |\\n      |                           | that holds the function\\'s       |             |\\n      |                           | global variables --- the global |             |\\n      |                           | namespace of the module in      |             |\\n      |                           | which the function was defined. |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__dict__``              | The namespace supporting        | Writable    |\\n      |                           | arbitrary function attributes.  |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__closure__``           | ``None`` or a tuple of cells    | Read-only   |\\n      |                           | that contain bindings for the   |             |\\n      |                           | function\\'s free variables.      |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__annotations__``       | A dict containing annotations   | Writable    |\\n      |                           | of parameters.  The keys of the |             |\\n      |                           | dict are the parameter names,   |             |\\n      |                           | or ``\\'return\\'`` for the return  |             |\\n      |                           | annotation, if provided.        |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__kwdefaults__``        | A dict containing defaults for  | Writable    |\\n      |                           | keyword-only parameters.        |             |\\n      +---------------------------+---------------------------------+-------------+\\n\\n      Most of the attributes labelled \"Writable\" check the type of the\\n      assigned value.\\n\\n      Function objects also support getting and setting arbitrary\\n      attributes, which can be used, for example, to attach metadata\\n      to functions.  Regular attribute dot-notation is used to get and\\n      set such attributes. *Note that the current implementation only\\n      supports function attributes on user-defined functions. Function\\n      attributes on built-in functions may be supported in the\\n      future.*\\n\\n      Additional information about a function\\'s definition can be\\n      retrieved from its code object; see the description of internal\\n      types below.\\n\\n   Instance methods\\n      An instance method object combines a class, a class instance and\\n      any callable object (normally a user-defined function).\\n\\n      Special read-only attributes: ``__self__`` is the class instance\\n      object, ``__func__`` is the function object; ``__doc__`` is the\\n      method\\'s documentation (same as ``__func__.__doc__``);\\n      ``__name__`` is the method name (same as ``__func__.__name__``);\\n      ``__module__`` is the name of the module the method was defined\\n      in, or ``None`` if unavailable.\\n\\n      Methods also support accessing (but not setting) the arbitrary\\n      function attributes on the underlying function object.\\n\\n      User-defined method objects may be created when getting an\\n      attribute of a class (perhaps via an instance of that class), if\\n      that attribute is a user-defined function object or a class\\n      method object.\\n\\n      When an instance method object is created by retrieving a user-\\n      defined function object from a class via one of its instances,\\n      its ``__self__`` attribute is the instance, and the method\\n      object is said to be bound.  The new method\\'s ``__func__``\\n      attribute is the original function object.\\n\\n      When a user-defined method object is created by retrieving\\n      another method object from a class or instance, the behaviour is\\n      the same as for a function object, except that the ``__func__``\\n      attribute of the new instance is not the original method object\\n      but its ``__func__`` attribute.\\n\\n      When an instance method object is created by retrieving a class\\n      method object from a class or instance, its ``__self__``\\n      attribute is the class itself, and its ``__func__`` attribute is\\n      the function object underlying the class method.\\n\\n      When an instance method object is called, the underlying\\n      function (``__func__``) is called, inserting the class instance\\n      (``__self__``) in front of the argument list.  For instance,\\n      when ``C`` is a class which contains a definition for a function\\n      ``f()``, and ``x`` is an instance of ``C``, calling ``x.f(1)``\\n      is equivalent to calling ``C.f(x, 1)``.\\n\\n      When an instance method object is derived from a class method\\n      object, the \"class instance\" stored in ``__self__`` will\\n      actually be the class itself, so that calling either ``x.f(1)``\\n      or ``C.f(1)`` is equivalent to calling ``f(C,1)`` where ``f`` is\\n      the underlying function.\\n\\n      Note that the transformation from function object to instance\\n      method object happens each time the attribute is retrieved from\\n      the instance.  In some cases, a fruitful optimization is to\\n      assign the attribute to a local variable and call that local\\n      variable. Also notice that this transformation only happens for\\n      user-defined functions; other callable objects (and all non-\\n      callable objects) are retrieved without transformation.  It is\\n      also important to note that user-defined functions which are\\n      attributes of a class instance are not converted to bound\\n      methods; this *only* happens when the function is an attribute\\n      of the class.\\n\\n   Generator functions\\n      A function or method which uses the ``yield`` statement (see\\n      section *The yield statement*) is called a *generator function*.\\n      Such a function, when called, always returns an iterator object\\n      which can be used to execute the body of the function:  calling\\n      the iterator\\'s ``iterator__next__()`` method will cause the\\n      function to execute until it provides a value using the\\n      ``yield`` statement.  When the function executes a ``return``\\n      statement or falls off the end, a ``StopIteration`` exception is\\n      raised and the iterator will have reached the end of the set of\\n      values to be returned.\\n\\n   Built-in functions\\n      A built-in function object is a wrapper around a C function.\\n      Examples of built-in functions are ``len()`` and ``math.sin()``\\n      (``math`` is a standard built-in module). The number and type of\\n      the arguments are determined by the C function. Special read-\\n      only attributes: ``__doc__`` is the function\\'s documentation\\n      string, or ``None`` if unavailable; ``__name__`` is the\\n      function\\'s name; ``__self__`` is set to ``None`` (but see the\\n      next item); ``__module__`` is the name of the module the\\n      function was defined in or ``None`` if unavailable.\\n\\n   Built-in methods\\n      This is really a different disguise of a built-in function, this\\n      time containing an object passed to the C function as an\\n      implicit extra argument.  An example of a built-in method is\\n      ``alist.append()``, assuming *alist* is a list object. In this\\n      case, the special read-only attribute ``__self__`` is set to the\\n      object denoted by *alist*.\\n\\n   Classes\\n      Classes are callable.  These objects normally act as factories\\n      for new instances of themselves, but variations are possible for\\n      class types that override ``__new__()``.  The arguments of the\\n      call are passed to ``__new__()`` and, in the typical case, to\\n      ``__init__()`` to initialize the new instance.\\n\\n   Class Instances\\n      Instances of arbitrary classes can be made callable by defining\\n      a ``__call__()`` method in their class.\\n\\nModules\\n   Modules are a basic organizational unit of Python code, and are\\n   created by the *import system* as invoked either by the ``import``\\n   statement (see ``import``), or by calling functions such as\\n   ``importlib.import_module()`` and built-in ``__import__()``.  A\\n   module object has a namespace implemented by a dictionary object\\n   (this is the dictionary referenced by the ``__globals__`` attribute\\n   of functions defined in the module).  Attribute references are\\n   translated to lookups in this dictionary, e.g., ``m.x`` is\\n   equivalent to ``m.__dict__[\"x\"]``. A module object does not contain\\n   the code object used to initialize the module (since it isn\\'t\\n   needed once the initialization is done).\\n\\n   Attribute assignment updates the module\\'s namespace dictionary,\\n   e.g., ``m.x = 1`` is equivalent to ``m.__dict__[\"x\"] = 1``.\\n\\n   Special read-only attribute: ``__dict__`` is the module\\'s namespace\\n   as a dictionary object.\\n\\n   **CPython implementation detail:** Because of the way CPython\\n   clears module dictionaries, the module dictionary will be cleared\\n   when the module falls out of scope even if the dictionary still has\\n   live references.  To avoid this, copy the dictionary or keep the\\n   module around while using its dictionary directly.\\n\\n   Predefined (writable) attributes: ``__name__`` is the module\\'s\\n   name; ``__doc__`` is the module\\'s documentation string, or ``None``\\n   if unavailable; ``__file__`` is the pathname of the file from which\\n   the module was loaded, if it was loaded from a file. The\\n   ``__file__`` attribute may be missing for certain types of modules,\\n   such as C modules that are statically linked into the interpreter;\\n   for extension modules loaded dynamically from a shared library, it\\n   is the pathname of the shared library file.\\n\\nCustom classes\\n   Custom class types are typically created by class definitions (see\\n   section *Class definitions*).  A class has a namespace implemented\\n   by a dictionary object. Class attribute references are translated\\n   to lookups in this dictionary, e.g., ``C.x`` is translated to\\n   ``C.__dict__[\"x\"]`` (although there are a number of hooks which\\n   allow for other means of locating attributes). When the attribute\\n   name is not found there, the attribute search continues in the base\\n   classes. This search of the base classes uses the C3 method\\n   resolution order which behaves correctly even in the presence of\\n   \\'diamond\\' inheritance structures where there are multiple\\n   inheritance paths leading back to a common ancestor. Additional\\n   details on the C3 MRO used by Python can be found in the\\n   documentation accompanying the 2.3 release at\\n   http://www.python.org/download/releases/2.3/mro/.\\n\\n   When a class attribute reference (for class ``C``, say) would yield\\n   a class method object, it is transformed into an instance method\\n   object whose ``__self__`` attributes is ``C``.  When it would yield\\n   a static method object, it is transformed into the object wrapped\\n   by the static method object. See section *Implementing Descriptors*\\n   for another way in which attributes retrieved from a class may\\n   differ from those actually contained in its ``__dict__``.\\n\\n   Class attribute assignments update the class\\'s dictionary, never\\n   the dictionary of a base class.\\n\\n   A class object can be called (see above) to yield a class instance\\n   (see below).\\n\\n   Special attributes: ``__name__`` is the class name; ``__module__``\\n   is the module name in which the class was defined; ``__dict__`` is\\n   the dictionary containing the class\\'s namespace; ``__bases__`` is a\\n   tuple (possibly empty or a singleton) containing the base classes,\\n   in the order of their occurrence in the base class list;\\n   ``__doc__`` is the class\\'s documentation string, or None if\\n   undefined.\\n\\nClass instances\\n   A class instance is created by calling a class object (see above).\\n   A class instance has a namespace implemented as a dictionary which\\n   is the first place in which attribute references are searched.\\n   When an attribute is not found there, and the instance\\'s class has\\n   an attribute by that name, the search continues with the class\\n   attributes.  If a class attribute is found that is a user-defined\\n   function object, it is transformed into an instance method object\\n   whose ``__self__`` attribute is the instance.  Static method and\\n   class method objects are also transformed; see above under\\n   \"Classes\".  See section *Implementing Descriptors* for another way\\n   in which attributes of a class retrieved via its instances may\\n   differ from the objects actually stored in the class\\'s\\n   ``__dict__``.  If no class attribute is found, and the object\\'s\\n   class has a ``__getattr__()`` method, that is called to satisfy the\\n   lookup.\\n\\n   Attribute assignments and deletions update the instance\\'s\\n   dictionary, never a class\\'s dictionary.  If the class has a\\n   ``__setattr__()`` or ``__delattr__()`` method, this is called\\n   instead of updating the instance dictionary directly.\\n\\n   Class instances can pretend to be numbers, sequences, or mappings\\n   if they have methods with certain special names.  See section\\n   *Special method names*.\\n\\n   Special attributes: ``__dict__`` is the attribute dictionary;\\n   ``__class__`` is the instance\\'s class.\\n\\nI/O objects (also known as file objects)\\n   A *file object* represents an open file.  Various shortcuts are\\n   available to create file objects: the ``open()`` built-in function,\\n   and also ``os.popen()``, ``os.fdopen()``, and the ``makefile()``\\n   method of socket objects (and perhaps by other functions or methods\\n   provided by extension modules).\\n\\n   The objects ``sys.stdin``, ``sys.stdout`` and ``sys.stderr`` are\\n   initialized to file objects corresponding to the interpreter\\'s\\n   standard input, output and error streams; they are all open in text\\n   mode and therefore follow the interface defined by the\\n   ``io.TextIOBase`` abstract class.\\n\\nInternal types\\n   A few types used internally by the interpreter are exposed to the\\n   user. Their definitions may change with future versions of the\\n   interpreter, but they are mentioned here for completeness.\\n\\n   Code objects\\n      Code objects represent *byte-compiled* executable Python code,\\n      or *bytecode*. The difference between a code object and a\\n      function object is that the function object contains an explicit\\n      reference to the function\\'s globals (the module in which it was\\n      defined), while a code object contains no context; also the\\n      default argument values are stored in the function object, not\\n      in the code object (because they represent values calculated at\\n      run-time).  Unlike function objects, code objects are immutable\\n      and contain no references (directly or indirectly) to mutable\\n      objects.\\n\\n      Special read-only attributes: ``co_name`` gives the function\\n      name; ``co_argcount`` is the number of positional arguments\\n      (including arguments with default values); ``co_nlocals`` is the\\n      number of local variables used by the function (including\\n      arguments); ``co_varnames`` is a tuple containing the names of\\n      the local variables (starting with the argument names);\\n      ``co_cellvars`` is a tuple containing the names of local\\n      variables that are referenced by nested functions;\\n      ``co_freevars`` is a tuple containing the names of free\\n      variables; ``co_code`` is a string representing the sequence of\\n      bytecode instructions; ``co_consts`` is a tuple containing the\\n      literals used by the bytecode; ``co_names`` is a tuple\\n      containing the names used by the bytecode; ``co_filename`` is\\n      the filename from which the code was compiled;\\n      ``co_firstlineno`` is the first line number of the function;\\n      ``co_lnotab`` is a string encoding the mapping from bytecode\\n      offsets to line numbers (for details see the source code of the\\n      interpreter); ``co_stacksize`` is the required stack size\\n      (including local variables); ``co_flags`` is an integer encoding\\n      a number of flags for the interpreter.\\n\\n      The following flag bits are defined for ``co_flags``: bit\\n      ``0x04`` is set if the function uses the ``*arguments`` syntax\\n      to accept an arbitrary number of positional arguments; bit\\n      ``0x08`` is set if the function uses the ``**keywords`` syntax\\n      to accept arbitrary keyword arguments; bit ``0x20`` is set if\\n      the function is a generator.\\n\\n      Future feature declarations (``from __future__ import\\n      division``) also use bits in ``co_flags`` to indicate whether a\\n      code object was compiled with a particular feature enabled: bit\\n      ``0x2000`` is set if the function was compiled with future\\n      division enabled; bits ``0x10`` and ``0x1000`` were used in\\n      earlier versions of Python.\\n\\n      Other bits in ``co_flags`` are reserved for internal use.\\n\\n      If a code object represents a function, the first item in\\n      ``co_consts`` is the documentation string of the function, or\\n      ``None`` if undefined.\\n\\n   Frame objects\\n      Frame objects represent execution frames.  They may occur in\\n      traceback objects (see below).\\n\\n      Special read-only attributes: ``f_back`` is to the previous\\n      stack frame (towards the caller), or ``None`` if this is the\\n      bottom stack frame; ``f_code`` is the code object being executed\\n      in this frame; ``f_locals`` is the dictionary used to look up\\n      local variables; ``f_globals`` is used for global variables;\\n      ``f_builtins`` is used for built-in (intrinsic) names;\\n      ``f_lasti`` gives the precise instruction (this is an index into\\n      the bytecode string of the code object).\\n\\n      Special writable attributes: ``f_trace``, if not ``None``, is a\\n      function called at the start of each source code line (this is\\n      used by the debugger); ``f_lineno`` is the current line number\\n      of the frame --- writing to this from within a trace function\\n      jumps to the given line (only for the bottom-most frame).  A\\n      debugger can implement a Jump command (aka Set Next Statement)\\n      by writing to f_lineno.\\n\\n   Traceback objects\\n      Traceback objects represent a stack trace of an exception.  A\\n      traceback object is created when an exception occurs.  When the\\n      search for an exception handler unwinds the execution stack, at\\n      each unwound level a traceback object is inserted in front of\\n      the current traceback.  When an exception handler is entered,\\n      the stack trace is made available to the program. (See section\\n      *The try statement*.) It is accessible as the third item of the\\n      tuple returned by ``sys.exc_info()``. When the program contains\\n      no suitable handler, the stack trace is written (nicely\\n      formatted) to the standard error stream; if the interpreter is\\n      interactive, it is also made available to the user as\\n      ``sys.last_traceback``.\\n\\n      Special read-only attributes: ``tb_next`` is the next level in\\n      the stack trace (towards the frame where the exception\\n      occurred), or ``None`` if there is no next level; ``tb_frame``\\n      points to the execution frame of the current level;\\n      ``tb_lineno`` gives the line number where the exception\\n      occurred; ``tb_lasti`` indicates the precise instruction.  The\\n      line number and last instruction in the traceback may differ\\n      from the line number of its frame object if the exception\\n      occurred in a ``try`` statement with no matching except clause\\n      or with a finally clause.\\n\\n   Slice objects\\n      Slice objects are used to represent slices for ``__getitem__()``\\n      methods.  They are also created by the built-in ``slice()``\\n      function.\\n\\n      Special read-only attributes: ``start`` is the lower bound;\\n      ``stop`` is the upper bound; ``step`` is the step value; each is\\n      ``None`` if omitted. These attributes can have any type.\\n\\n      Slice objects support one method:\\n\\n      slice.indices(self, length)\\n\\n         This method takes a single integer argument *length* and\\n         computes information about the slice that the slice object\\n         would describe if applied to a sequence of *length* items.\\n         It returns a tuple of three integers; respectively these are\\n         the *start* and *stop* indices and the *step* or stride\\n         length of the slice. Missing or out-of-bounds indices are\\n         handled in a manner consistent with regular slices.\\n\\n   Static method objects\\n      Static method objects provide a way of defeating the\\n      transformation of function objects to method objects described\\n      above. A static method object is a wrapper around any other\\n      object, usually a user-defined method object. When a static\\n      method object is retrieved from a class or a class instance, the\\n      object actually returned is the wrapped object, which is not\\n      subject to any further transformation. Static method objects are\\n      not themselves callable, although the objects they wrap usually\\n      are. Static method objects are created by the built-in\\n      ``staticmethod()`` constructor.\\n\\n   Class method objects\\n      A class method object, like a static method object, is a wrapper\\n      around another object that alters the way in which that object\\n      is retrieved from classes and class instances. The behaviour of\\n      class method objects upon such retrieval is described above,\\n      under \"User-defined methods\". Class method objects are created\\n      by the built-in ``classmethod()`` constructor.\\n',\n 'typesfunctions': '\\nFunctions\\n*********\\n\\nFunction objects are created by function definitions.  The only\\noperation on a function object is to call it: ``func(argument-list)``.\\n\\nThere are really two flavors of function objects: built-in functions\\nand user-defined functions.  Both support the same operation (to call\\nthe function), but the implementation is different, hence the\\ndifferent object types.\\n\\nSee *Function definitions* for more information.\\n',\n 'typesmapping': '\\nMapping Types --- ``dict``\\n**************************\\n\\nA *mapping* object maps *hashable* values to arbitrary objects.\\nMappings are mutable objects.  There is currently only one standard\\nmapping type, the *dictionary*.  (For other containers see the built-\\nin ``list``, ``set``, and ``tuple`` classes, and the ``collections``\\nmodule.)\\n\\nA dictionary\\'s keys are *almost* arbitrary values.  Values that are\\nnot *hashable*, that is, values containing lists, dictionaries or\\nother mutable types (that are compared by value rather than by object\\nidentity) may not be used as keys.  Numeric types used for keys obey\\nthe normal rules for numeric comparison: if two numbers compare equal\\n(such as ``1`` and ``1.0``) then they can be used interchangeably to\\nindex the same dictionary entry.  (Note however, that since computers\\nstore floating-point numbers as approximations it is usually unwise to\\nuse them as dictionary keys.)\\n\\nDictionaries can be created by placing a comma-separated list of\\n``key: value`` pairs within braces, for example: ``{\\'jack\\': 4098,\\n\\'sjoerd\\': 4127}`` or ``{4098: \\'jack\\', 4127: \\'sjoerd\\'}``, or by the\\n``dict`` constructor.\\n\\nclass class dict(**kwarg)\\nclass class dict(mapping, **kwarg)\\nclass class dict(iterable, **kwarg)\\n\\n   Return a new dictionary initialized from an optional positional\\n   argument and a possibly empty set of keyword arguments.\\n\\n   If no positional argument is given, an empty dictionary is created.\\n   If a positional argument is given and it is a mapping object, a\\n   dictionary is created with the same key-value pairs as the mapping\\n   object.  Otherwise, the positional argument must be an *iterator*\\n   object.  Each item in the iterable must itself be an iterator with\\n   exactly two objects.  The first object of each item becomes a key\\n   in the new dictionary, and the second object the corresponding\\n   value.  If a key occurs more than once, the last value for that key\\n   becomes the corresponding value in the new dictionary.\\n\\n   If keyword arguments are given, the keyword arguments and their\\n   values are added to the dictionary created from the positional\\n   argument.  If a key being added is already present, the value from\\n   the keyword argument replaces the value from the positional\\n   argument.\\n\\n   To illustrate, the following examples all return a dictionary equal\\n   to ``{\"one\": 1, \"two\": 2, \"three\": 3}``:\\n\\n      >>> a = dict(one=1, two=2, three=3)\\n      >>> b = {\\'one\\': 1, \\'two\\': 2, \\'three\\': 3}\\n      >>> c = dict(zip([\\'one\\', \\'two\\', \\'three\\'], [1, 2, 3]))\\n      >>> d = dict([(\\'two\\', 2), (\\'one\\', 1), (\\'three\\', 3)])\\n      >>> e = dict({\\'three\\': 3, \\'one\\': 1, \\'two\\': 2})\\n      >>> a == b == c == d == e\\n      True\\n\\n   Providing keyword arguments as in the first example only works for\\n   keys that are valid Python identifiers.  Otherwise, any valid keys\\n   can be used.\\n\\n   These are the operations that dictionaries support (and therefore,\\n   custom mapping types should support too):\\n\\n   len(d)\\n\\n      Return the number of items in the dictionary *d*.\\n\\n   d[key]\\n\\n      Return the item of *d* with key *key*.  Raises a ``KeyError`` if\\n      *key* is not in the map.\\n\\n      If a subclass of dict defines a method ``__missing__()``, if the\\n      key *key* is not present, the ``d[key]`` operation calls that\\n      method with the key *key* as argument.  The ``d[key]`` operation\\n      then returns or raises whatever is returned or raised by the\\n      ``__missing__(key)`` call if the key is not present. No other\\n      operations or methods invoke ``__missing__()``. If\\n      ``__missing__()`` is not defined, ``KeyError`` is raised.\\n      ``__missing__()`` must be a method; it cannot be an instance\\n      variable:\\n\\n         >>> class Counter(dict):\\n         ...     def __missing__(self, key):\\n         ...         return 0\\n         >>> c = Counter()\\n         >>> c[\\'red\\']\\n         0\\n         >>> c[\\'red\\'] += 1\\n         >>> c[\\'red\\']\\n         1\\n\\n      See ``collections.Counter`` for a complete implementation\\n      including other methods helpful for accumulating and managing\\n      tallies.\\n\\n   d[key] = value\\n\\n      Set ``d[key]`` to *value*.\\n\\n   del d[key]\\n\\n      Remove ``d[key]`` from *d*.  Raises a ``KeyError`` if *key* is\\n      not in the map.\\n\\n   key in d\\n\\n      Return ``True`` if *d* has a key *key*, else ``False``.\\n\\n   key not in d\\n\\n      Equivalent to ``not key in d``.\\n\\n   iter(d)\\n\\n      Return an iterator over the keys of the dictionary.  This is a\\n      shortcut for ``iter(d.keys())``.\\n\\n   clear()\\n\\n      Remove all items from the dictionary.\\n\\n   copy()\\n\\n      Return a shallow copy of the dictionary.\\n\\n   classmethod fromkeys(seq[, value])\\n\\n      Create a new dictionary with keys from *seq* and values set to\\n      *value*.\\n\\n      ``fromkeys()`` is a class method that returns a new dictionary.\\n      *value* defaults to ``None``.\\n\\n   get(key[, default])\\n\\n      Return the value for *key* if *key* is in the dictionary, else\\n      *default*. If *default* is not given, it defaults to ``None``,\\n      so that this method never raises a ``KeyError``.\\n\\n   items()\\n\\n      Return a new view of the dictionary\\'s items (``(key, value)``\\n      pairs). See the *documentation of view objects*.\\n\\n   keys()\\n\\n      Return a new view of the dictionary\\'s keys.  See the\\n      *documentation of view objects*.\\n\\n   pop(key[, default])\\n\\n      If *key* is in the dictionary, remove it and return its value,\\n      else return *default*.  If *default* is not given and *key* is\\n      not in the dictionary, a ``KeyError`` is raised.\\n\\n   popitem()\\n\\n      Remove and return an arbitrary ``(key, value)`` pair from the\\n      dictionary.\\n\\n      ``popitem()`` is useful to destructively iterate over a\\n      dictionary, as often used in set algorithms.  If the dictionary\\n      is empty, calling ``popitem()`` raises a ``KeyError``.\\n\\n   setdefault(key[, default])\\n\\n      If *key* is in the dictionary, return its value.  If not, insert\\n      *key* with a value of *default* and return *default*.  *default*\\n      defaults to ``None``.\\n\\n   update([other])\\n\\n      Update the dictionary with the key/value pairs from *other*,\\n      overwriting existing keys.  Return ``None``.\\n\\n      ``update()`` accepts either another dictionary object or an\\n      iterable of key/value pairs (as tuples or other iterables of\\n      length two).  If keyword arguments are specified, the dictionary\\n      is then updated with those key/value pairs: ``d.update(red=1,\\n      blue=2)``.\\n\\n   values()\\n\\n      Return a new view of the dictionary\\'s values.  See the\\n      *documentation of view objects*.\\n\\nSee also:\\n\\n   ``types.MappingProxyType`` can be used to create a read-only view\\n   of a ``dict``.\\n\\n\\nDictionary view objects\\n=======================\\n\\nThe objects returned by ``dict.keys()``, ``dict.values()`` and\\n``dict.items()`` are *view objects*.  They provide a dynamic view on\\nthe dictionary\\'s entries, which means that when the dictionary\\nchanges, the view reflects these changes.\\n\\nDictionary views can be iterated over to yield their respective data,\\nand support membership tests:\\n\\nlen(dictview)\\n\\n   Return the number of entries in the dictionary.\\n\\niter(dictview)\\n\\n   Return an iterator over the keys, values or items (represented as\\n   tuples of ``(key, value)``) in the dictionary.\\n\\n   Keys and values are iterated over in an arbitrary order which is\\n   non-random, varies across Python implementations, and depends on\\n   the dictionary\\'s history of insertions and deletions. If keys,\\n   values and items views are iterated over with no intervening\\n   modifications to the dictionary, the order of items will directly\\n   correspond.  This allows the creation of ``(value, key)`` pairs\\n   using ``zip()``: ``pairs = zip(d.values(), d.keys())``.  Another\\n   way to create the same list is ``pairs = [(v, k) for (k, v) in\\n   d.items()]``.\\n\\n   Iterating views while adding or deleting entries in the dictionary\\n   may raise a ``RuntimeError`` or fail to iterate over all entries.\\n\\nx in dictview\\n\\n   Return ``True`` if *x* is in the underlying dictionary\\'s keys,\\n   values or items (in the latter case, *x* should be a ``(key,\\n   value)`` tuple).\\n\\nKeys views are set-like since their entries are unique and hashable.\\nIf all values are hashable, so that ``(key, value)`` pairs are unique\\nand hashable, then the items view is also set-like.  (Values views are\\nnot treated as set-like since the entries are generally not unique.)\\nFor set-like views, all of the operations defined for the abstract\\nbase class ``collections.abc.Set`` are available (for example, ``==``,\\n``<``, or ``^``).\\n\\nAn example of dictionary view usage:\\n\\n   >>> dishes = {\\'eggs\\': 2, \\'sausage\\': 1, \\'bacon\\': 1, \\'spam\\': 500}\\n   >>> keys = dishes.keys()\\n   >>> values = dishes.values()\\n\\n   >>> # iteration\\n   >>> n = 0\\n   >>> for val in values:\\n   ...     n += val\\n   >>> print(n)\\n   504\\n\\n   >>> # keys and values are iterated over in the same order\\n   >>> list(keys)\\n   [\\'eggs\\', \\'bacon\\', \\'sausage\\', \\'spam\\']\\n   >>> list(values)\\n   [2, 1, 1, 500]\\n\\n   >>> # view objects are dynamic and reflect dict changes\\n   >>> del dishes[\\'eggs\\']\\n   >>> del dishes[\\'sausage\\']\\n   >>> list(keys)\\n   [\\'spam\\', \\'bacon\\']\\n\\n   >>> # set operations\\n   >>> keys & {\\'eggs\\', \\'bacon\\', \\'salad\\'}\\n   {\\'bacon\\'}\\n   >>> keys ^ {\\'sausage\\', \\'juice\\'}\\n   {\\'juice\\', \\'sausage\\', \\'bacon\\', \\'spam\\'}\\n',\n 'typesmethods': '\\nMethods\\n*******\\n\\nMethods are functions that are called using the attribute notation.\\nThere are two flavors: built-in methods (such as ``append()`` on\\nlists) and class instance methods.  Built-in methods are described\\nwith the types that support them.\\n\\nIf you access a method (a function defined in a class namespace)\\nthrough an instance, you get a special object: a *bound method* (also\\ncalled *instance method*) object. When called, it will add the\\n``self`` argument to the argument list.  Bound methods have two\\nspecial read-only attributes: ``m.__self__`` is the object on which\\nthe method operates, and ``m.__func__`` is the function implementing\\nthe method.  Calling ``m(arg-1, arg-2, ..., arg-n)`` is completely\\nequivalent to calling ``m.__func__(m.__self__, arg-1, arg-2, ...,\\narg-n)``.\\n\\nLike function objects, bound method objects support getting arbitrary\\nattributes.  However, since method attributes are actually stored on\\nthe underlying function object (``meth.__func__``), setting method\\nattributes on bound methods is disallowed.  Attempting to set an\\nattribute on a method results in an ``AttributeError`` being raised.\\nIn order to set a method attribute, you need to explicitly set it on\\nthe underlying function object:\\n\\n   >>> class C:\\n   ...     def method(self):\\n   ...         pass\\n   ...\\n   >>> c = C()\\n   >>> c.method.whoami = \\'my name is method\\'  # can\\'t set on the method\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 1, in <module>\\n   AttributeError: \\'method\\' object has no attribute \\'whoami\\'\\n   >>> c.method.__func__.whoami = \\'my name is method\\'\\n   >>> c.method.whoami\\n   \\'my name is method\\'\\n\\nSee *The standard type hierarchy* for more information.\\n',\n 'typesmodules': \"\\nModules\\n*******\\n\\nThe only special operation on a module is attribute access:\\n``m.name``, where *m* is a module and *name* accesses a name defined\\nin *m*'s symbol table. Module attributes can be assigned to.  (Note\\nthat the ``import`` statement is not, strictly speaking, an operation\\non a module object; ``import foo`` does not require a module object\\nnamed *foo* to exist, rather it requires an (external) *definition*\\nfor a module named *foo* somewhere.)\\n\\nA special attribute of every module is ``__dict__``. This is the\\ndictionary containing the module's symbol table. Modifying this\\ndictionary will actually change the module's symbol table, but direct\\nassignment to the ``__dict__`` attribute is not possible (you can\\nwrite ``m.__dict__['a'] = 1``, which defines ``m.a`` to be ``1``, but\\nyou can't write ``m.__dict__ = {}``).  Modifying ``__dict__`` directly\\nis not recommended.\\n\\nModules built into the interpreter are written like this: ``<module\\n'sys' (built-in)>``.  If loaded from a file, they are written as\\n``<module 'os' from '/usr/local/lib/pythonX.Y/os.pyc'>``.\\n\",\n 'typesseq': '\\nSequence Types --- ``list``, ``tuple``, ``range``\\n*************************************************\\n\\nThere are three basic sequence types: lists, tuples, and range\\nobjects. Additional sequence types tailored for processing of *binary\\ndata* and *text strings* are described in dedicated sections.\\n\\n\\nCommon Sequence Operations\\n==========================\\n\\nThe operations in the following table are supported by most sequence\\ntypes, both mutable and immutable. The ``collections.abc.Sequence``\\nABC is provided to make it easier to correctly implement these\\noperations on custom sequence types.\\n\\nThis table lists the sequence operations sorted in ascending priority\\n(operations in the same box have the same priority).  In the table,\\n*s* and *t* are sequences of the same type, *n*, *i*, *j* and *k* are\\nintegers and *x* is an arbitrary object that meets any type and value\\nrestrictions imposed by *s*.\\n\\nThe ``in`` and ``not in`` operations have the same priorities as the\\ncomparison operations. The ``+`` (concatenation) and ``*``\\n(repetition) operations have the same priority as the corresponding\\nnumeric operations.\\n\\n+----------------------------+----------------------------------+------------+\\n| Operation                  | Result                           | Notes      |\\n+============================+==================================+============+\\n| ``x in s``                 | ``True`` if an item of *s* is    | (1)        |\\n|                            | equal to *x*, else ``False``     |            |\\n+----------------------------+----------------------------------+------------+\\n| ``x not in s``             | ``False`` if an item of *s* is   | (1)        |\\n|                            | equal to *x*, else ``True``      |            |\\n+----------------------------+----------------------------------+------------+\\n| ``s + t``                  | the concatenation of *s* and *t* | (6)(7)     |\\n+----------------------------+----------------------------------+------------+\\n| ``s * n`` or ``n * s``     | *n* shallow copies of *s*        | (2)(7)     |\\n|                            | concatenated                     |            |\\n+----------------------------+----------------------------------+------------+\\n| ``s[i]``                   | *i*th item of *s*, origin 0      | (3)        |\\n+----------------------------+----------------------------------+------------+\\n| ``s[i:j]``                 | slice of *s* from *i* to *j*     | (3)(4)     |\\n+----------------------------+----------------------------------+------------+\\n| ``s[i:j:k]``               | slice of *s* from *i* to *j*     | (3)(5)     |\\n|                            | with step *k*                    |            |\\n+----------------------------+----------------------------------+------------+\\n| ``len(s)``                 | length of *s*                    |            |\\n+----------------------------+----------------------------------+------------+\\n| ``min(s)``                 | smallest item of *s*             |            |\\n+----------------------------+----------------------------------+------------+\\n| ``max(s)``                 | largest item of *s*              |            |\\n+----------------------------+----------------------------------+------------+\\n| ``s.index(x[, i[, j]])``   | index of the first occurence of  | (8)        |\\n|                            | *x* in *s* (at or after index    |            |\\n|                            | *i* and before index *j*)        |            |\\n+----------------------------+----------------------------------+------------+\\n| ``s.count(x)``             | total number of occurences of    |            |\\n|                            | *x* in *s*                       |            |\\n+----------------------------+----------------------------------+------------+\\n\\nSequences of the same type also support comparisons.  In particular,\\ntuples and lists are compared lexicographically by comparing\\ncorresponding elements. This means that to compare equal, every\\nelement must compare equal and the two sequences must be of the same\\ntype and have the same length.  (For full details see *Comparisons* in\\nthe language reference.)\\n\\nNotes:\\n\\n1. While the ``in`` and ``not in`` operations are used only for simple\\n   containment testing in the general case, some specialised sequences\\n   (such as ``str``, ``bytes`` and ``bytearray``) also use them for\\n   subsequence testing:\\n\\n      >>> \"gg\" in \"eggs\"\\n      True\\n\\n2. Values of *n* less than ``0`` are treated as ``0`` (which yields an\\n   empty sequence of the same type as *s*).  Note also that the copies\\n   are shallow; nested structures are not copied.  This often haunts\\n   new Python programmers; consider:\\n\\n      >>> lists = [[]] * 3\\n      >>> lists\\n      [[], [], []]\\n      >>> lists[0].append(3)\\n      >>> lists\\n      [[3], [3], [3]]\\n\\n   What has happened is that ``[[]]`` is a one-element list containing\\n   an empty list, so all three elements of ``[[]] * 3`` are (pointers\\n   to) this single empty list.  Modifying any of the elements of\\n   ``lists`` modifies this single list. You can create a list of\\n   different lists this way:\\n\\n      >>> lists = [[] for i in range(3)]\\n      >>> lists[0].append(3)\\n      >>> lists[1].append(5)\\n      >>> lists[2].append(7)\\n      >>> lists\\n      [[3], [5], [7]]\\n\\n3. If *i* or *j* is negative, the index is relative to the end of the\\n   string: ``len(s) + i`` or ``len(s) + j`` is substituted.  But note\\n   that ``-0`` is still ``0``.\\n\\n4. The slice of *s* from *i* to *j* is defined as the sequence of\\n   items with index *k* such that ``i <= k < j``.  If *i* or *j* is\\n   greater than ``len(s)``, use ``len(s)``.  If *i* is omitted or\\n   ``None``, use ``0``.  If *j* is omitted or ``None``, use\\n   ``len(s)``.  If *i* is greater than or equal to *j*, the slice is\\n   empty.\\n\\n5. The slice of *s* from *i* to *j* with step *k* is defined as the\\n   sequence of items with index  ``x = i + n*k`` such that ``0 <= n <\\n   (j-i)/k``.  In other words, the indices are ``i``, ``i+k``,\\n   ``i+2*k``, ``i+3*k`` and so on, stopping when *j* is reached (but\\n   never including *j*).  If *i* or *j* is greater than ``len(s)``,\\n   use ``len(s)``.  If *i* or *j* are omitted or ``None``, they become\\n   \"end\" values (which end depends on the sign of *k*).  Note, *k*\\n   cannot be zero. If *k* is ``None``, it is treated like ``1``.\\n\\n6. Concatenating immutable sequences always results in a new object.\\n   This means that building up a sequence by repeated concatenation\\n   will have a quadratic runtime cost in the total sequence length.\\n   To get a linear runtime cost, you must switch to one of the\\n   alternatives below:\\n\\n   * if concatenating ``str`` objects, you can build a list and use\\n     ``str.join()`` at the end or else write to a ``io.StringIO``\\n     instance and retrieve its value when complete\\n\\n   * if concatenating ``bytes`` objects, you can similarly use\\n     ``bytes.join()`` or ``io.BytesIO``, or you can do in-place\\n     concatenation with a ``bytearray`` object.  ``bytearray`` objects\\n     are mutable and have an efficient overallocation mechanism\\n\\n   * if concatenating ``tuple`` objects, extend a ``list`` instead\\n\\n   * for other types, investigate the relevant class documentation\\n\\n7. Some sequence types (such as ``range``) only support item sequences\\n   that follow specific patterns, and hence don\\'t support sequence\\n   concatenation or repetition.\\n\\n8. ``index`` raises ``ValueError`` when *x* is not found in *s*. When\\n   supported, the additional arguments to the index method allow\\n   efficient searching of subsections of the sequence. Passing the\\n   extra arguments is roughly equivalent to using ``s[i:j].index(x)``,\\n   only without copying any data and with the returned index being\\n   relative to the start of the sequence rather than the start of the\\n   slice.\\n\\n\\nImmutable Sequence Types\\n========================\\n\\nThe only operation that immutable sequence types generally implement\\nthat is not also implemented by mutable sequence types is support for\\nthe ``hash()`` built-in.\\n\\nThis support allows immutable sequences, such as ``tuple`` instances,\\nto be used as ``dict`` keys and stored in ``set`` and ``frozenset``\\ninstances.\\n\\nAttempting to hash an immutable sequence that contains unhashable\\nvalues will result in ``TypeError``.\\n\\n\\nMutable Sequence Types\\n======================\\n\\nThe operations in the following table are defined on mutable sequence\\ntypes. The ``collections.abc.MutableSequence`` ABC is provided to make\\nit easier to correctly implement these operations on custom sequence\\ntypes.\\n\\nIn the table *s* is an instance of a mutable sequence type, *t* is any\\niterable object and *x* is an arbitrary object that meets any type and\\nvalue restrictions imposed by *s* (for example, ``bytearray`` only\\naccepts integers that meet the value restriction ``0 <= x <= 255``).\\n\\n+--------------------------------+----------------------------------+-----------------------+\\n| Operation                      | Result                           | Notes                 |\\n+================================+==================================+=======================+\\n| ``s[i] = x``                   | item *i* of *s* is replaced by   |                       |\\n|                                | *x*                              |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s[i:j] = t``                 | slice of *s* from *i* to *j* is  |                       |\\n|                                | replaced by the contents of the  |                       |\\n|                                | iterable *t*                     |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``del s[i:j]``                 | same as ``s[i:j] = []``          |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s[i:j:k] = t``               | the elements of ``s[i:j:k]`` are | (1)                   |\\n|                                | replaced by those of *t*         |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``del s[i:j:k]``               | removes the elements of          |                       |\\n|                                | ``s[i:j:k]`` from the list       |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.append(x)``                | appends *x* to the end of the    |                       |\\n|                                | sequence (same as                |                       |\\n|                                | ``s[len(s):len(s)] = [x]``)      |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.clear()``                  | removes all items from ``s``     | (5)                   |\\n|                                | (same as ``del s[:]``)           |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.copy()``                   | creates a shallow copy of ``s``  | (5)                   |\\n|                                | (same as ``s[:]``)               |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.extend(t)``                | extends *s* with the contents of |                       |\\n|                                | *t* (same as ``s[len(s):len(s)]  |                       |\\n|                                | = t``)                           |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.insert(i, x)``             | inserts *x* into *s* at the      |                       |\\n|                                | index given by *i* (same as      |                       |\\n|                                | ``s[i:i] = [x]``)                |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.pop([i])``                 | retrieves the item at *i* and    | (2)                   |\\n|                                | also removes it from *s*         |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.remove(x)``                | remove the first item from *s*   | (3)                   |\\n|                                | where ``s[i] == x``              |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.reverse()``                | reverses the items of *s* in     | (4)                   |\\n|                                | place                            |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n\\nNotes:\\n\\n1. *t* must have the same length as the slice it is replacing.\\n\\n2. The optional argument *i* defaults to ``-1``, so that by default\\n   the last item is removed and returned.\\n\\n3. ``remove`` raises ``ValueError`` when *x* is not found in *s*.\\n\\n4. The ``reverse()`` method modifies the sequence in place for economy\\n   of space when reversing a large sequence.  To remind users that it\\n   operates by side effect, it does not return the reversed sequence.\\n\\n5. ``clear()`` and ``copy()`` are included for consistency with the\\n   interfaces of mutable containers that don\\'t support slicing\\n   operations (such as ``dict`` and ``set``)\\n\\n   New in version 3.3: ``clear()`` and ``copy()`` methods.\\n\\n\\nLists\\n=====\\n\\nLists are mutable sequences, typically used to store collections of\\nhomogeneous items (where the precise degree of similarity will vary by\\napplication).\\n\\nclass class list([iterable])\\n\\n   Lists may be constructed in several ways:\\n\\n   * Using a pair of square brackets to denote the empty list: ``[]``\\n\\n   * Using square brackets, separating items with commas: ``[a]``,\\n     ``[a, b, c]``\\n\\n   * Using a list comprehension: ``[x for x in iterable]``\\n\\n   * Using the type constructor: ``list()`` or ``list(iterable)``\\n\\n   The constructor builds a list whose items are the same and in the\\n   same order as *iterable*\\'s items.  *iterable* may be either a\\n   sequence, a container that supports iteration, or an iterator\\n   object.  If *iterable* is already a list, a copy is made and\\n   returned, similar to ``iterable[:]``. For example, ``list(\\'abc\\')``\\n   returns ``[\\'a\\', \\'b\\', \\'c\\']`` and ``list( (1, 2, 3) )`` returns ``[1,\\n   2, 3]``. If no argument is given, the constructor creates a new\\n   empty list, ``[]``.\\n\\n   Many other operations also produce lists, including the\\n   ``sorted()`` built-in.\\n\\n   Lists implement all of the *common* and *mutable* sequence\\n   operations. Lists also provide the following additional method:\\n\\n   sort(*, key=None, reverse=None)\\n\\n      This method sorts the list in place, using only ``<``\\n      comparisons between items. Exceptions are not suppressed - if\\n      any comparison operations fail, the entire sort operation will\\n      fail (and the list will likely be left in a partially modified\\n      state).\\n\\n      *key* specifies a function of one argument that is used to\\n      extract a comparison key from each list element (for example,\\n      ``key=str.lower``). The key corresponding to each item in the\\n      list is calculated once and then used for the entire sorting\\n      process. The default value of ``None`` means that list items are\\n      sorted directly without calculating a separate key value.\\n\\n      The ``functools.cmp_to_key()`` utility is available to convert a\\n      2.x style *cmp* function to a *key* function.\\n\\n      *reverse* is a boolean value.  If set to ``True``, then the list\\n      elements are sorted as if each comparison were reversed.\\n\\n      This method modifies the sequence in place for economy of space\\n      when sorting a large sequence.  To remind users that it operates\\n      by side effect, it does not return the sorted sequence (use\\n      ``sorted()`` to explicitly request a new sorted list instance).\\n\\n      The ``sort()`` method is guaranteed to be stable.  A sort is\\n      stable if it guarantees not to change the relative order of\\n      elements that compare equal --- this is helpful for sorting in\\n      multiple passes (for example, sort by department, then by salary\\n      grade).\\n\\n      **CPython implementation detail:** While a list is being sorted,\\n      the effect of attempting to mutate, or even inspect, the list is\\n      undefined.  The C implementation of Python makes the list appear\\n      empty for the duration, and raises ``ValueError`` if it can\\n      detect that the list has been mutated during a sort.\\n\\n\\nTuples\\n======\\n\\nTuples are immutable sequences, typically used to store collections of\\nheterogeneous data (such as the 2-tuples produced by the\\n``enumerate()`` built-in). Tuples are also used for cases where an\\nimmutable sequence of homogeneous data is needed (such as allowing\\nstorage in a ``set`` or ``dict`` instance).\\n\\nclass class tuple([iterable])\\n\\n   Tuples may be constructed in a number of ways:\\n\\n   * Using a pair of parentheses to denote the empty tuple: ``()``\\n\\n   * Using a trailing comma for a singleton tuple: ``a,`` or ``(a,)``\\n\\n   * Separating items with commas: ``a, b, c`` or ``(a, b, c)``\\n\\n   * Using the ``tuple()`` built-in: ``tuple()`` or\\n     ``tuple(iterable)``\\n\\n   The constructor builds a tuple whose items are the same and in the\\n   same order as *iterable*\\'s items.  *iterable* may be either a\\n   sequence, a container that supports iteration, or an iterator\\n   object.  If *iterable* is already a tuple, it is returned\\n   unchanged. For example, ``tuple(\\'abc\\')`` returns ``(\\'a\\', \\'b\\',\\n   \\'c\\')`` and ``tuple( [1, 2, 3] )`` returns ``(1, 2, 3)``. If no\\n   argument is given, the constructor creates a new empty tuple,\\n   ``()``.\\n\\n   Note that it is actually the comma which makes a tuple, not the\\n   parentheses. The parentheses are optional, except in the empty\\n   tuple case, or when they are needed to avoid syntactic ambiguity.\\n   For example, ``f(a, b, c)`` is a function call with three\\n   arguments, while ``f((a, b, c))`` is a function call with a 3-tuple\\n   as the sole argument.\\n\\n   Tuples implement all of the *common* sequence operations.\\n\\nFor heterogeneous collections of data where access by name is clearer\\nthan access by index, ``collections.namedtuple()`` may be a more\\nappropriate choice than a simple tuple object.\\n\\n\\nRanges\\n======\\n\\nThe ``range`` type represents an immutable sequence of numbers and is\\ncommonly used for looping a specific number of times in ``for`` loops.\\n\\nclass class range(stop)\\nclass class range(start, stop[, step])\\n\\n   The arguments to the range constructor must be integers (either\\n   built-in ``int`` or any object that implements the ``__index__``\\n   special method).  If the *step* argument is omitted, it defaults to\\n   ``1``. If the *start* argument is omitted, it defaults to ``0``. If\\n   *step* is zero, ``ValueError`` is raised.\\n\\n   For a positive *step*, the contents of a range ``r`` are determined\\n   by the formula ``r[i] = start + step*i`` where ``i >= 0`` and\\n   ``r[i] < stop``.\\n\\n   For a negative *step*, the contents of the range are still\\n   determined by the formula ``r[i] = start + step*i``, but the\\n   constraints are ``i >= 0`` and ``r[i] > stop``.\\n\\n   A range object will be empty if ``r[0]`` does not meet the value\\n   constraint. Ranges do support negative indices, but these are\\n   interpreted as indexing from the end of the sequence determined by\\n   the positive indices.\\n\\n   Ranges containing absolute values larger than ``sys.maxsize`` are\\n   permitted but some features (such as ``len()``) may raise\\n   ``OverflowError``.\\n\\n   Range examples:\\n\\n      >>> list(range(10))\\n      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\\n      >>> list(range(1, 11))\\n      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\\n      >>> list(range(0, 30, 5))\\n      [0, 5, 10, 15, 20, 25]\\n      >>> list(range(0, 10, 3))\\n      [0, 3, 6, 9]\\n      >>> list(range(0, -10, -1))\\n      [0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\\n      >>> list(range(0))\\n      []\\n      >>> list(range(1, 0))\\n      []\\n\\n   Ranges implement all of the *common* sequence operations except\\n   concatenation and repetition (due to the fact that range objects\\n   can only represent sequences that follow a strict pattern and\\n   repetition and concatenation will usually violate that pattern).\\n\\nThe advantage of the ``range`` type over a regular ``list`` or\\n``tuple`` is that a ``range`` object will always take the same (small)\\namount of memory, no matter the size of the range it represents (as it\\nonly stores the ``start``, ``stop`` and ``step`` values, calculating\\nindividual items and subranges as needed).\\n\\nRange objects implement the ``collections.Sequence`` ABC, and provide\\nfeatures such as containment tests, element index lookup, slicing and\\nsupport for negative indices (see *Sequence Types --- list, tuple,\\nrange*):\\n\\n>>> r = range(0, 20, 2)\\n>>> r\\nrange(0, 20, 2)\\n>>> 11 in r\\nFalse\\n>>> 10 in r\\nTrue\\n>>> r.index(10)\\n5\\n>>> r[5]\\n10\\n>>> r[:5]\\nrange(0, 10, 2)\\n>>> r[-1]\\n18\\n\\nTesting range objects for equality with ``==`` and ``!=`` compares\\nthem as sequences.  That is, two range objects are considered equal if\\nthey represent the same sequence of values.  (Note that two range\\nobjects that compare equal might have different ``start``, ``stop``\\nand ``step`` attributes, for example ``range(0) == range(2, 1, 3)`` or\\n``range(0, 3, 2) == range(0, 4, 2)``.)\\n\\nChanged in version 3.2: Implement the Sequence ABC. Support slicing\\nand negative indices. Test ``int`` objects for membership in constant\\ntime instead of iterating through all items.\\n\\nChanged in version 3.3: Define \\'==\\' and \\'!=\\' to compare range objects\\nbased on the sequence of values they define (instead of comparing\\nbased on object identity).\\n\\nNew in version 3.3: The ``start``, ``stop`` and ``step`` attributes.\\n',\n 'typesseq-mutable': \"\\nMutable Sequence Types\\n**********************\\n\\nThe operations in the following table are defined on mutable sequence\\ntypes. The ``collections.abc.MutableSequence`` ABC is provided to make\\nit easier to correctly implement these operations on custom sequence\\ntypes.\\n\\nIn the table *s* is an instance of a mutable sequence type, *t* is any\\niterable object and *x* is an arbitrary object that meets any type and\\nvalue restrictions imposed by *s* (for example, ``bytearray`` only\\naccepts integers that meet the value restriction ``0 <= x <= 255``).\\n\\n+--------------------------------+----------------------------------+-----------------------+\\n| Operation                      | Result                           | Notes                 |\\n+================================+==================================+=======================+\\n| ``s[i] = x``                   | item *i* of *s* is replaced by   |                       |\\n|                                | *x*                              |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s[i:j] = t``                 | slice of *s* from *i* to *j* is  |                       |\\n|                                | replaced by the contents of the  |                       |\\n|                                | iterable *t*                     |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``del s[i:j]``                 | same as ``s[i:j] = []``          |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s[i:j:k] = t``               | the elements of ``s[i:j:k]`` are | (1)                   |\\n|                                | replaced by those of *t*         |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``del s[i:j:k]``               | removes the elements of          |                       |\\n|                                | ``s[i:j:k]`` from the list       |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.append(x)``                | appends *x* to the end of the    |                       |\\n|                                | sequence (same as                |                       |\\n|                                | ``s[len(s):len(s)] = [x]``)      |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.clear()``                  | removes all items from ``s``     | (5)                   |\\n|                                | (same as ``del s[:]``)           |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.copy()``                   | creates a shallow copy of ``s``  | (5)                   |\\n|                                | (same as ``s[:]``)               |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.extend(t)``                | extends *s* with the contents of |                       |\\n|                                | *t* (same as ``s[len(s):len(s)]  |                       |\\n|                                | = t``)                           |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.insert(i, x)``             | inserts *x* into *s* at the      |                       |\\n|                                | index given by *i* (same as      |                       |\\n|                                | ``s[i:i] = [x]``)                |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.pop([i])``                 | retrieves the item at *i* and    | (2)                   |\\n|                                | also removes it from *s*         |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.remove(x)``                | remove the first item from *s*   | (3)                   |\\n|                                | where ``s[i] == x``              |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.reverse()``                | reverses the items of *s* in     | (4)                   |\\n|                                | place                            |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n\\nNotes:\\n\\n1. *t* must have the same length as the slice it is replacing.\\n\\n2. The optional argument *i* defaults to ``-1``, so that by default\\n   the last item is removed and returned.\\n\\n3. ``remove`` raises ``ValueError`` when *x* is not found in *s*.\\n\\n4. The ``reverse()`` method modifies the sequence in place for economy\\n   of space when reversing a large sequence.  To remind users that it\\n   operates by side effect, it does not return the reversed sequence.\\n\\n5. ``clear()`` and ``copy()`` are included for consistency with the\\n   interfaces of mutable containers that don't support slicing\\n   operations (such as ``dict`` and ``set``)\\n\\n   New in version 3.3: ``clear()`` and ``copy()`` methods.\\n\",\n 'unary': '\\nUnary arithmetic and bitwise operations\\n***************************************\\n\\nAll unary arithmetic and bitwise operations have the same priority:\\n\\n   u_expr ::= power | \"-\" u_expr | \"+\" u_expr | \"~\" u_expr\\n\\nThe unary ``-`` (minus) operator yields the negation of its numeric\\nargument.\\n\\nThe unary ``+`` (plus) operator yields its numeric argument unchanged.\\n\\nThe unary ``~`` (invert) operator yields the bitwise inversion of its\\ninteger argument.  The bitwise inversion of ``x`` is defined as\\n``-(x+1)``.  It only applies to integral numbers.\\n\\nIn all three cases, if the argument does not have the proper type, a\\n``TypeError`` exception is raised.\\n',\n 'while': '\\nThe ``while`` statement\\n***********************\\n\\nThe ``while`` statement is used for repeated execution as long as an\\nexpression is true:\\n\\n   while_stmt ::= \"while\" expression \":\" suite\\n                  [\"else\" \":\" suite]\\n\\nThis repeatedly tests the expression and, if it is true, executes the\\nfirst suite; if the expression is false (which may be the first time\\nit is tested) the suite of the ``else`` clause, if present, is\\nexecuted and the loop terminates.\\n\\nA ``break`` statement executed in the first suite terminates the loop\\nwithout executing the ``else`` clause\\'s suite.  A ``continue``\\nstatement executed in the first suite skips the rest of the suite and\\ngoes back to testing the expression.\\n',\n 'with': '\\nThe ``with`` statement\\n**********************\\n\\nThe ``with`` statement is used to wrap the execution of a block with\\nmethods defined by a context manager (see section *With Statement\\nContext Managers*). This allows common\\n``try``...``except``...``finally`` usage patterns to be encapsulated\\nfor convenient reuse.\\n\\n   with_stmt ::= \"with\" with_item (\",\" with_item)* \":\" suite\\n   with_item ::= expression [\"as\" target]\\n\\nThe execution of the ``with`` statement with one \"item\" proceeds as\\nfollows:\\n\\n1. The context expression (the expression given in the ``with_item``)\\n   is evaluated to obtain a context manager.\\n\\n2. The context manager\\'s ``__exit__()`` is loaded for later use.\\n\\n3. The context manager\\'s ``__enter__()`` method is invoked.\\n\\n4. If a target was included in the ``with`` statement, the return\\n   value from ``__enter__()`` is assigned to it.\\n\\n   Note: The ``with`` statement guarantees that if the ``__enter__()``\\n     method returns without an error, then ``__exit__()`` will always\\n     be called. Thus, if an error occurs during the assignment to the\\n     target list, it will be treated the same as an error occurring\\n     within the suite would be. See step 6 below.\\n\\n5. The suite is executed.\\n\\n6. The context manager\\'s ``__exit__()`` method is invoked.  If an\\n   exception caused the suite to be exited, its type, value, and\\n   traceback are passed as arguments to ``__exit__()``. Otherwise,\\n   three ``None`` arguments are supplied.\\n\\n   If the suite was exited due to an exception, and the return value\\n   from the ``__exit__()`` method was false, the exception is\\n   reraised.  If the return value was true, the exception is\\n   suppressed, and execution continues with the statement following\\n   the ``with`` statement.\\n\\n   If the suite was exited for any reason other than an exception, the\\n   return value from ``__exit__()`` is ignored, and execution proceeds\\n   at the normal location for the kind of exit that was taken.\\n\\nWith more than one item, the context managers are processed as if\\nmultiple ``with`` statements were nested:\\n\\n   with A() as a, B() as b:\\n       suite\\n\\nis equivalent to\\n\\n   with A() as a:\\n       with B() as b:\\n           suite\\n\\nChanged in version 3.1: Support for multiple context expressions.\\n\\nSee also:\\n\\n   **PEP 0343** - The \"with\" statement\\n      The specification, background, and examples for the Python\\n      ``with`` statement.\\n',\n 'yield': '\\nThe ``yield`` statement\\n***********************\\n\\n   yield_stmt ::= yield_expression\\n\\nThe ``yield`` statement is only used when defining a generator\\nfunction, and is only used in the body of the generator function.\\nUsing a ``yield`` statement in a function definition is sufficient to\\ncause that definition to create a generator function instead of a\\nnormal function.\\n\\nWhen a generator function is called, it returns an iterator known as a\\ngenerator iterator, or more commonly, a generator.  The body of the\\ngenerator function is executed by calling the ``next()`` function on\\nthe generator repeatedly until it raises an exception.\\n\\nWhen a ``yield`` statement is executed, the state of the generator is\\nfrozen and the value of ``expression_list`` is returned to\\n``next()``\\'s caller.  By \"frozen\" we mean that all local state is\\nretained, including the current bindings of local variables, the\\ninstruction pointer, and the internal evaluation stack: enough\\ninformation is saved so that the next time ``next()`` is invoked, the\\nfunction can proceed exactly as if the ``yield`` statement were just\\nanother external call.\\n\\nThe ``yield`` statement is allowed in the ``try`` clause of a ``try``\\n...  ``finally`` construct.  If the generator is not resumed before it\\nis finalized (by reaching a zero reference count or by being garbage\\ncollected), the generator-iterator\\'s ``close()`` method will be\\ncalled, allowing any pending ``finally`` clauses to execute.\\n\\nWhen ``yield from <expr>`` is used, it treats the supplied expression\\nas a subiterator, producing values from it until the underlying\\niterator is exhausted.\\n\\n   Changed in version 3.3: Added ``yield from <expr>`` to delegate\\n   control flow to a subiterator\\n\\nFor full details of ``yield`` semantics, refer to the *Yield\\nexpressions* section.\\n\\nSee also:\\n\\n   **PEP 0255** - Simple Generators\\n      The proposal for adding generators and the ``yield`` statement\\n      to Python.\\n\\n   **PEP 0342** - Coroutines via Enhanced Generators\\n      The proposal to enhance the API and syntax of generators, making\\n      them usable as simple coroutines.\\n\\n   **PEP 0380** - Syntax for Delegating to a Subgenerator\\n      The proposal to introduce the ``yield_from`` syntax, making\\n      delegation to sub-generators easy.\\n'}\n"], "shutil": [".py", "\"\"\"Utility functions for copying and archiving files and directory trees.\n\nXXX The functions here don't copy the resource fork or other metadata on Mac.\n\n\"\"\"\n\nimport os\nimport sys\nimport stat\nfrom os.path import abspath\nimport fnmatch\nimport collections\nimport errno\nimport tarfile\n\ntry:\n    import bz2\n    del bz2\n    _BZ2_SUPPORTED = True\nexcept ImportError:\n    _BZ2_SUPPORTED = False\n\ntry:\n    from pwd import getpwnam\nexcept ImportError:\n    getpwnam = None\n\ntry:\n    from grp import getgrnam\nexcept ImportError:\n    getgrnam = None\n\n__all__ = [\"copyfileobj\", \"copyfile\", \"copymode\", \"copystat\", \"copy\", \"copy2\",\n           \"copytree\", \"move\", \"rmtree\", \"Error\", \"SpecialFileError\",\n           \"ExecError\", \"make_archive\", \"get_archive_formats\",\n           \"register_archive_format\", \"unregister_archive_format\",\n           \"get_unpack_formats\", \"register_unpack_format\",\n           \"unregister_unpack_format\", \"unpack_archive\",\n           \"ignore_patterns\", \"chown\", \"which\"]\n           # disk_usage is added later, if available on the platform\n\nclass Error(EnvironmentError):\n    pass\n\nclass SpecialFileError(EnvironmentError):\n    \"\"\"Raised when trying to do a kind of operation (e.g. copying) which is\n    not supported on a special file (e.g. a named pipe)\"\"\"\n\nclass ExecError(EnvironmentError):\n    \"\"\"Raised when a command could not be executed\"\"\"\n\nclass ReadError(EnvironmentError):\n    \"\"\"Raised when an archive cannot be read\"\"\"\n\nclass RegistryError(Exception):\n    \"\"\"Raised when a registry operation with the archiving\n    and unpacking registeries fails\"\"\"\n\n\ntry:\n    WindowsError\nexcept NameError:\n    WindowsError = None\n\ndef copyfileobj(fsrc, fdst, length=16*1024):\n    \"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\n    while 1:\n        buf = fsrc.read(length)\n        if not buf:\n            break\n        fdst.write(buf)\n\ndef _samefile(src, dst):\n    # Macintosh, Unix.\n    if hasattr(os.path, 'samefile'):\n        try:\n            return os.path.samefile(src, dst)\n        except OSError:\n            return False\n\n    # All other platforms: check for same pathname.\n    return (os.path.normcase(os.path.abspath(src)) ==\n            os.path.normcase(os.path.abspath(dst)))\n\ndef copyfile(src, dst, *, follow_symlinks=True):\n    \"\"\"Copy data from src to dst.\n\n    If follow_symlinks is not set and src is a symbolic link, a new\n    symlink will be created instead of copying the file it points to.\n\n    \"\"\"\n    if _samefile(src, dst):\n        raise Error(\"`%s` and `%s` are the same file\" % (src, dst))\n\n    for fn in [src, dst]:\n        try:\n            st = os.stat(fn)\n        except OSError:\n            # File most likely does not exist\n            pass\n        else:\n            # XXX What about other special files? (sockets, devices...)\n            if stat.S_ISFIFO(st.st_mode):\n                raise SpecialFileError(\"`%s` is a named pipe\" % fn)\n\n    if not follow_symlinks and os.path.islink(src):\n        os.symlink(os.readlink(src), dst)\n    else:\n        with open(src, 'rb') as fsrc:\n            with open(dst, 'wb') as fdst:\n                copyfileobj(fsrc, fdst)\n    return dst\n\ndef copymode(src, dst, *, follow_symlinks=True):\n    \"\"\"Copy mode bits from src to dst.\n\n    If follow_symlinks is not set, symlinks aren't followed if and only\n    if both `src` and `dst` are symlinks.  If `lchmod` isn't available\n    (e.g. Linux) this method does nothing.\n\n    \"\"\"\n    if not follow_symlinks and os.path.islink(src) and os.path.islink(dst):\n        if hasattr(os, 'lchmod'):\n            stat_func, chmod_func = os.lstat, os.lchmod\n        else:\n            return\n    elif hasattr(os, 'chmod'):\n        stat_func, chmod_func = os.stat, os.chmod\n    else:\n        return\n\n    st = stat_func(src)\n    chmod_func(dst, stat.S_IMODE(st.st_mode))\n\nif hasattr(os, 'listxattr'):\n    def _copyxattr(src, dst, *, follow_symlinks=True):\n        \"\"\"Copy extended filesystem attributes from `src` to `dst`.\n\n        Overwrite existing attributes.\n\n        If `follow_symlinks` is false, symlinks won't be followed.\n\n        \"\"\"\n\n        try:\n            names = os.listxattr(src, follow_symlinks=follow_symlinks)\n        except OSError as e:\n            if e.errno not in (errno.ENOTSUP, errno.ENODATA):\n                raise\n            return\n        for name in names:\n            try:\n                value = os.getxattr(src, name, follow_symlinks=follow_symlinks)\n                os.setxattr(dst, name, value, follow_symlinks=follow_symlinks)\n            except OSError as e:\n                if e.errno not in (errno.EPERM, errno.ENOTSUP, errno.ENODATA):\n                    raise\nelse:\n    def _copyxattr(*args, **kwargs):\n        pass\n\ndef copystat(src, dst, *, follow_symlinks=True):\n    \"\"\"Copy all stat info (mode bits, atime, mtime, flags) from src to dst.\n\n    If the optional flag `follow_symlinks` is not set, symlinks aren't followed if and\n    only if both `src` and `dst` are symlinks.\n\n    \"\"\"\n    def _nop(*args, ns=None, follow_symlinks=None):\n        pass\n\n    # follow symlinks (aka don't not follow symlinks)\n    follow = follow_symlinks or not (os.path.islink(src) and os.path.islink(dst))\n    if follow:\n        # use the real function if it exists\n        def lookup(name):\n            return getattr(os, name, _nop)\n    else:\n        # use the real function only if it exists\n        # *and* it supports follow_symlinks\n        def lookup(name):\n            fn = getattr(os, name, _nop)\n            if fn in os.supports_follow_symlinks:\n                return fn\n            return _nop\n\n    st = lookup(\"stat\")(src, follow_symlinks=follow)\n    mode = stat.S_IMODE(st.st_mode)\n    lookup(\"utime\")(dst, ns=(st.st_atime_ns, st.st_mtime_ns),\n        follow_symlinks=follow)\n    try:\n        lookup(\"chmod\")(dst, mode, follow_symlinks=follow)\n    except NotImplementedError:\n        # if we got a NotImplementedError, it's because\n        #   * follow_symlinks=False,\n        #   * lchown() is unavailable, and\n        #   * either\n        #       * fchownat() is unavailable or\n        #       * fchownat() doesn't implement AT_SYMLINK_NOFOLLOW.\n        #         (it returned ENOSUP.)\n        # therefore we're out of options--we simply cannot chown the\n        # symlink.  give up, suppress the error.\n        # (which is what shutil always did in this circumstance.)\n        pass\n    if hasattr(st, 'st_flags'):\n        try:\n            lookup(\"chflags\")(dst, st.st_flags, follow_symlinks=follow)\n        except OSError as why:\n            for err in 'EOPNOTSUPP', 'ENOTSUP':\n                if hasattr(errno, err) and why.errno == getattr(errno, err):\n                    break\n            else:\n                raise\n    _copyxattr(src, dst, follow_symlinks=follow)\n\ndef copy(src, dst, *, follow_symlinks=True):\n    \"\"\"Copy data and mode bits (\"cp src dst\"). Return the file's destination.\n\n    The destination may be a directory.\n\n    If follow_symlinks is false, symlinks won't be followed. This\n    resembles GNU's \"cp -P src dst\".\n\n    \"\"\"\n    if os.path.isdir(dst):\n        dst = os.path.join(dst, os.path.basename(src))\n    copyfile(src, dst, follow_symlinks=follow_symlinks)\n    copymode(src, dst, follow_symlinks=follow_symlinks)\n    return dst\n\ndef copy2(src, dst, *, follow_symlinks=True):\n    \"\"\"Copy data and all stat info (\"cp -p src dst\"). Return the file's\n    destination.\"\n\n    The destination may be a directory.\n\n    If follow_symlinks is false, symlinks won't be followed. This\n    resembles GNU's \"cp -P src dst\".\n\n    \"\"\"\n    if os.path.isdir(dst):\n        dst = os.path.join(dst, os.path.basename(src))\n    copyfile(src, dst, follow_symlinks=follow_symlinks)\n    copystat(src, dst, follow_symlinks=follow_symlinks)\n    return dst\n\ndef ignore_patterns(*patterns):\n    \"\"\"Function that can be used as copytree() ignore parameter.\n\n    Patterns is a sequence of glob-style patterns\n    that are used to exclude files\"\"\"\n    def _ignore_patterns(path, names):\n        ignored_names = []\n        for pattern in patterns:\n            ignored_names.extend(fnmatch.filter(names, pattern))\n        return set(ignored_names)\n    return _ignore_patterns\n\ndef copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2,\n             ignore_dangling_symlinks=False):\n    \"\"\"Recursively copy a directory tree.\n\n    The destination directory must not already exist.\n    If exception(s) occur, an Error is raised with a list of reasons.\n\n    If the optional symlinks flag is true, symbolic links in the\n    source tree result in symbolic links in the destination tree; if\n    it is false, the contents of the files pointed to by symbolic\n    links are copied. If the file pointed by the symlink doesn't\n    exist, an exception will be added in the list of errors raised in\n    an Error exception at the end of the copy process.\n\n    You can set the optional ignore_dangling_symlinks flag to true if you\n    want to silence this exception. Notice that this has no effect on\n    platforms that don't support os.symlink.\n\n    The optional ignore argument is a callable. If given, it\n    is called with the `src` parameter, which is the directory\n    being visited by copytree(), and `names` which is the list of\n    `src` contents, as returned by os.listdir():\n\n        callable(src, names) -> ignored_names\n\n    Since copytree() is called recursively, the callable will be\n    called once for each directory that is copied. It returns a\n    list of names relative to the `src` directory that should\n    not be copied.\n\n    The optional copy_function argument is a callable that will be used\n    to copy each file. It will be called with the source path and the\n    destination path as arguments. By default, copy2() is used, but any\n    function that supports the same signature (like copy()) can be used.\n\n    \"\"\"\n    names = os.listdir(src)\n    if ignore is not None:\n        ignored_names = ignore(src, names)\n    else:\n        ignored_names = set()\n\n    os.makedirs(dst)\n    errors = []\n    for name in names:\n        if name in ignored_names:\n            continue\n        srcname = os.path.join(src, name)\n        dstname = os.path.join(dst, name)\n        try:\n            if os.path.islink(srcname):\n                linkto = os.readlink(srcname)\n                if symlinks:\n                    # We can't just leave it to `copy_function` because legacy\n                    # code with a custom `copy_function` may rely on copytree\n                    # doing the right thing.\n                    os.symlink(linkto, dstname)\n                    copystat(srcname, dstname, follow_symlinks=not symlinks)\n                else:\n                    # ignore dangling symlink if the flag is on\n                    if not os.path.exists(linkto) and ignore_dangling_symlinks:\n                        continue\n                    # otherwise let the copy occurs. copy2 will raise an error\n                    copy_function(srcname, dstname)\n            elif os.path.isdir(srcname):\n                copytree(srcname, dstname, symlinks, ignore, copy_function)\n            else:\n                # Will raise a SpecialFileError for unsupported file types\n                copy_function(srcname, dstname)\n        # catch the Error from the recursive copytree so that we can\n        # continue with other files\n        except Error as err:\n            errors.extend(err.args[0])\n        except EnvironmentError as why:\n            errors.append((srcname, dstname, str(why)))\n    try:\n        copystat(src, dst)\n    except OSError as why:\n        if WindowsError is not None and isinstance(why, WindowsError):\n            # Copying file access times may fail on Windows\n            pass\n        else:\n            errors.append((src, dst, str(why)))\n    if errors:\n        raise Error(errors)\n    return dst\n\n# version vulnerable to race conditions\ndef _rmtree_unsafe(path, onerror):\n    try:\n        if os.path.islink(path):\n            # symlinks to directories are forbidden, see bug #1669\n            raise OSError(\"Cannot call rmtree on a symbolic link\")\n    except OSError:\n        onerror(os.path.islink, path, sys.exc_info())\n        # can't continue even if onerror hook returns\n        return\n    names = []\n    try:\n        names = os.listdir(path)\n    except os.error:\n        onerror(os.listdir, path, sys.exc_info())\n    for name in names:\n        fullname = os.path.join(path, name)\n        try:\n            mode = os.lstat(fullname).st_mode\n        except os.error:\n            mode = 0\n        if stat.S_ISDIR(mode):\n            _rmtree_unsafe(fullname, onerror)\n        else:\n            try:\n                os.unlink(fullname)\n            except os.error:\n                onerror(os.unlink, fullname, sys.exc_info())\n    try:\n        os.rmdir(path)\n    except os.error:\n        onerror(os.rmdir, path, sys.exc_info())\n\n# Version using fd-based APIs to protect against races\ndef _rmtree_safe_fd(topfd, path, onerror):\n    names = []\n    try:\n        names = os.listdir(topfd)\n    except OSError as err:\n        err.filename = path\n        onerror(os.listdir, path, sys.exc_info())\n    for name in names:\n        fullname = os.path.join(path, name)\n        try:\n            orig_st = os.stat(name, dir_fd=topfd, follow_symlinks=False)\n            mode = orig_st.st_mode\n        except OSError:\n            mode = 0\n        if stat.S_ISDIR(mode):\n            try:\n                dirfd = os.open(name, os.O_RDONLY, dir_fd=topfd)\n            except OSError:\n                onerror(os.open, fullname, sys.exc_info())\n            else:\n                try:\n                    if os.path.samestat(orig_st, os.fstat(dirfd)):\n                        _rmtree_safe_fd(dirfd, fullname, onerror)\n                        try:\n                            os.rmdir(name, dir_fd=topfd)\n                        except OSError:\n                            onerror(os.rmdir, fullname, sys.exc_info())\n                    else:\n                        try:\n                            # This can only happen if someone replaces\n                            # a directory with a symlink after the call to\n                            # stat.S_ISDIR above.\n                            raise OSError(\"Cannot call rmtree on a symbolic \"\n                                          \"link\")\n                        except OSError:\n                            onerror(os.path.islink, fullname, sys.exc_info())\n                finally:\n                    os.close(dirfd)\n        else:\n            try:\n                os.unlink(name, dir_fd=topfd)\n            except OSError:\n                onerror(os.unlink, fullname, sys.exc_info())\n\n_use_fd_functions = ({os.open, os.stat, os.unlink, os.rmdir} <=\n                     os.supports_dir_fd and\n                     os.listdir in os.supports_fd and\n                     os.stat in os.supports_follow_symlinks)\n\ndef rmtree(path, ignore_errors=False, onerror=None):\n    \"\"\"Recursively delete a directory tree.\n\n    If ignore_errors is set, errors are ignored; otherwise, if onerror\n    is set, it is called to handle the error with arguments (func,\n    path, exc_info) where func is platform and implementation dependent;\n    path is the argument to that function that caused it to fail; and\n    exc_info is a tuple returned by sys.exc_info().  If ignore_errors\n    is false and onerror is None, an exception is raised.\n\n    \"\"\"\n    if ignore_errors:\n        def onerror(*args):\n            pass\n    elif onerror is None:\n        def onerror(*args):\n            raise\n    if _use_fd_functions:\n        # While the unsafe rmtree works fine on bytes, the fd based does not.\n        if isinstance(path, bytes):\n            path = os.fsdecode(path)\n        # Note: To guard against symlink races, we use the standard\n        # lstat()/open()/fstat() trick.\n        try:\n            orig_st = os.lstat(path)\n        except Exception:\n            onerror(os.lstat, path, sys.exc_info())\n            return\n        try:\n            fd = os.open(path, os.O_RDONLY)\n        except Exception:\n            onerror(os.lstat, path, sys.exc_info())\n            return\n        try:\n            if os.path.samestat(orig_st, os.fstat(fd)):\n                _rmtree_safe_fd(fd, path, onerror)\n                try:\n                    os.rmdir(path)\n                except os.error:\n                    onerror(os.rmdir, path, sys.exc_info())\n            else:\n                try:\n                    # symlinks to directories are forbidden, see bug #1669\n                    raise OSError(\"Cannot call rmtree on a symbolic link\")\n                except OSError:\n                    onerror(os.path.islink, path, sys.exc_info())\n        finally:\n            os.close(fd)\n    else:\n        return _rmtree_unsafe(path, onerror)\n\n# Allow introspection of whether or not the hardening against symlink\n# attacks is supported on the current platform\nrmtree.avoids_symlink_attacks = _use_fd_functions\n\ndef _basename(path):\n    # A basename() variant which first strips the trailing slash, if present.\n    # Thus we always get the last component of the path, even for directories.\n    return os.path.basename(path.rstrip(os.path.sep))\n\ndef move(src, dst):\n    \"\"\"Recursively move a file or directory to another location. This is\n    similar to the Unix \"mv\" command. Return the file or directory's\n    destination.\n\n    If the destination is a directory or a symlink to a directory, the source\n    is moved inside the directory. The destination path must not already\n    exist.\n\n    If the destination already exists but is not a directory, it may be\n    overwritten depending on os.rename() semantics.\n\n    If the destination is on our current filesystem, then rename() is used.\n    Otherwise, src is copied to the destination and then removed. Symlinks are\n    recreated under the new name if os.rename() fails because of cross\n    filesystem renames.\n\n    A lot more could be done here...  A look at a mv.c shows a lot of\n    the issues this implementation glosses over.\n\n    \"\"\"\n    real_dst = dst\n    if os.path.isdir(dst):\n        if _samefile(src, dst):\n            # We might be on a case insensitive filesystem,\n            # perform the rename anyway.\n            os.rename(src, dst)\n            return\n\n        real_dst = os.path.join(dst, _basename(src))\n        if os.path.exists(real_dst):\n            raise Error(\"Destination path '%s' already exists\" % real_dst)\n    try:\n        os.rename(src, real_dst)\n    except OSError:\n        if os.path.islink(src):\n            linkto = os.readlink(src)\n            os.symlink(linkto, real_dst)\n            os.unlink(src)\n        elif os.path.isdir(src):\n            if _destinsrc(src, dst):\n                raise Error(\"Cannot move a directory '%s' into itself '%s'.\" % (src, dst))\n            copytree(src, real_dst, symlinks=True)\n            rmtree(src)\n        else:\n            copy2(src, real_dst)\n            os.unlink(src)\n    return real_dst\n\ndef _destinsrc(src, dst):\n    src = abspath(src)\n    dst = abspath(dst)\n    if not src.endswith(os.path.sep):\n        src += os.path.sep\n    if not dst.endswith(os.path.sep):\n        dst += os.path.sep\n    return dst.startswith(src)\n\ndef _get_gid(name):\n    \"\"\"Returns a gid, given a group name.\"\"\"\n    if getgrnam is None or name is None:\n        return None\n    try:\n        result = getgrnam(name)\n    except KeyError:\n        result = None\n    if result is not None:\n        return result[2]\n    return None\n\ndef _get_uid(name):\n    \"\"\"Returns an uid, given a user name.\"\"\"\n    if getpwnam is None or name is None:\n        return None\n    try:\n        result = getpwnam(name)\n    except KeyError:\n        result = None\n    if result is not None:\n        return result[2]\n    return None\n\ndef _make_tarball(base_name, base_dir, compress=\"gzip\", verbose=0, dry_run=0,\n                  owner=None, group=None, logger=None):\n    \"\"\"Create a (possibly compressed) tar file from all the files under\n    'base_dir'.\n\n    'compress' must be \"gzip\" (the default), \"bzip2\", or None.\n\n    'owner' and 'group' can be used to define an owner and a group for the\n    archive that is being built. If not provided, the current owner and group\n    will be used.\n\n    The output tar file will be named 'base_name' +  \".tar\", possibly plus\n    the appropriate compression extension (\".gz\", or \".bz2\").\n\n    Returns the output filename.\n    \"\"\"\n    tar_compression = {'gzip': 'gz', None: ''}\n    compress_ext = {'gzip': '.gz'}\n\n    if _BZ2_SUPPORTED:\n        tar_compression['bzip2'] = 'bz2'\n        compress_ext['bzip2'] = '.bz2'\n\n    # flags for compression program, each element of list will be an argument\n    if compress is not None and compress not in compress_ext:\n        raise ValueError(\"bad value for 'compress', or compression format not \"\n                         \"supported : {0}\".format(compress))\n\n    archive_name = base_name + '.tar' + compress_ext.get(compress, '')\n    archive_dir = os.path.dirname(archive_name)\n\n    if not os.path.exists(archive_dir):\n        if logger is not None:\n            logger.info(\"creating %s\", archive_dir)\n        if not dry_run:\n            os.makedirs(archive_dir)\n\n    # creating the tarball\n    if logger is not None:\n        logger.info('Creating tar archive')\n\n    uid = _get_uid(owner)\n    gid = _get_gid(group)\n\n    def _set_uid_gid(tarinfo):\n        if gid is not None:\n            tarinfo.gid = gid\n            tarinfo.gname = group\n        if uid is not None:\n            tarinfo.uid = uid\n            tarinfo.uname = owner\n        return tarinfo\n\n    if not dry_run:\n        tar = tarfile.open(archive_name, 'w|%s' % tar_compression[compress])\n        try:\n            tar.add(base_dir, filter=_set_uid_gid)\n        finally:\n            tar.close()\n\n    return archive_name\n\ndef _call_external_zip(base_dir, zip_filename, verbose=False, dry_run=False):\n    # XXX see if we want to keep an external call here\n    if verbose:\n        zipoptions = \"-r\"\n    else:\n        zipoptions = \"-rq\"\n    from distutils.errors import DistutilsExecError\n    from distutils.spawn import spawn\n    try:\n        spawn([\"zip\", zipoptions, zip_filename, base_dir], dry_run=dry_run)\n    except DistutilsExecError:\n        # XXX really should distinguish between \"couldn't find\n        # external 'zip' command\" and \"zip failed\".\n        raise ExecError(\"unable to create zip file '%s': \"\n            \"could neither import the 'zipfile' module nor \"\n            \"find a standalone zip utility\") % zip_filename\n\ndef _make_zipfile(base_name, base_dir, verbose=0, dry_run=0, logger=None):\n    \"\"\"Create a zip file from all the files under 'base_dir'.\n\n    The output zip file will be named 'base_name' + \".zip\".  Uses either the\n    \"zipfile\" Python module (if available) or the InfoZIP \"zip\" utility\n    (if installed and found on the default search path).  If neither tool is\n    available, raises ExecError.  Returns the name of the output zip\n    file.\n    \"\"\"\n    zip_filename = base_name + \".zip\"\n    archive_dir = os.path.dirname(base_name)\n\n    if not os.path.exists(archive_dir):\n        if logger is not None:\n            logger.info(\"creating %s\", archive_dir)\n        if not dry_run:\n            os.makedirs(archive_dir)\n\n    # If zipfile module is not available, try spawning an external 'zip'\n    # command.\n    try:\n        import zipfile\n    except ImportError:\n        zipfile = None\n\n    if zipfile is None:\n        _call_external_zip(base_dir, zip_filename, verbose, dry_run)\n    else:\n        if logger is not None:\n            logger.info(\"creating '%s' and adding '%s' to it\",\n                        zip_filename, base_dir)\n\n        if not dry_run:\n            zip = zipfile.ZipFile(zip_filename, \"w\",\n                                  compression=zipfile.ZIP_DEFLATED)\n\n            for dirpath, dirnames, filenames in os.walk(base_dir):\n                for name in filenames:\n                    path = os.path.normpath(os.path.join(dirpath, name))\n                    if os.path.isfile(path):\n                        zip.write(path, path)\n                        if logger is not None:\n                            logger.info(\"adding '%s'\", path)\n            zip.close()\n\n    return zip_filename\n\n_ARCHIVE_FORMATS = {\n    'gztar': (_make_tarball, [('compress', 'gzip')], \"gzip'ed tar-file\"),\n    'tar':   (_make_tarball, [('compress', None)], \"uncompressed tar file\"),\n    'zip':   (_make_zipfile, [], \"ZIP file\")\n    }\n\nif _BZ2_SUPPORTED:\n    _ARCHIVE_FORMATS['bztar'] = (_make_tarball, [('compress', 'bzip2')],\n                                \"bzip2'ed tar-file\")\n\ndef get_archive_formats():\n    \"\"\"Returns a list of supported formats for archiving and unarchiving.\n\n    Each element of the returned sequence is a tuple (name, description)\n    \"\"\"\n    formats = [(name, registry[2]) for name, registry in\n               _ARCHIVE_FORMATS.items()]\n    formats.sort()\n    return formats\n\ndef register_archive_format(name, function, extra_args=None, description=''):\n    \"\"\"Registers an archive format.\n\n    name is the name of the format. function is the callable that will be\n    used to create archives. If provided, extra_args is a sequence of\n    (name, value) tuples that will be passed as arguments to the callable.\n    description can be provided to describe the format, and will be returned\n    by the get_archive_formats() function.\n    \"\"\"\n    if extra_args is None:\n        extra_args = []\n    if not callable(function):\n        raise TypeError('The %s object is not callable' % function)\n    if not isinstance(extra_args, (tuple, list)):\n        raise TypeError('extra_args needs to be a sequence')\n    for element in extra_args:\n        if not isinstance(element, (tuple, list)) or len(element) !=2:\n            raise TypeError('extra_args elements are : (arg_name, value)')\n\n    _ARCHIVE_FORMATS[name] = (function, extra_args, description)\n\ndef unregister_archive_format(name):\n    del _ARCHIVE_FORMATS[name]\n\ndef make_archive(base_name, format, root_dir=None, base_dir=None, verbose=0,\n                 dry_run=0, owner=None, group=None, logger=None):\n    \"\"\"Create an archive file (eg. zip or tar).\n\n    'base_name' is the name of the file to create, minus any format-specific\n    extension; 'format' is the archive format: one of \"zip\", \"tar\", \"bztar\"\n    or \"gztar\".\n\n    'root_dir' is a directory that will be the root directory of the\n    archive; ie. we typically chdir into 'root_dir' before creating the\n    archive.  'base_dir' is the directory where we start archiving from;\n    ie. 'base_dir' will be the common prefix of all files and\n    directories in the archive.  'root_dir' and 'base_dir' both default\n    to the current directory.  Returns the name of the archive file.\n\n    'owner' and 'group' are used when creating a tar archive. By default,\n    uses the current owner and group.\n    \"\"\"\n    save_cwd = os.getcwd()\n    if root_dir is not None:\n        if logger is not None:\n            logger.debug(\"changing into '%s'\", root_dir)\n        base_name = os.path.abspath(base_name)\n        if not dry_run:\n            os.chdir(root_dir)\n\n    if base_dir is None:\n        base_dir = os.curdir\n\n    kwargs = {'dry_run': dry_run, 'logger': logger}\n\n    try:\n        format_info = _ARCHIVE_FORMATS[format]\n    except KeyError:\n        raise ValueError(\"unknown archive format '%s'\" % format)\n\n    func = format_info[0]\n    for arg, val in format_info[1]:\n        kwargs[arg] = val\n\n    if format != 'zip':\n        kwargs['owner'] = owner\n        kwargs['group'] = group\n\n    try:\n        filename = func(base_name, base_dir, **kwargs)\n    finally:\n        if root_dir is not None:\n            if logger is not None:\n                logger.debug(\"changing back to '%s'\", save_cwd)\n            os.chdir(save_cwd)\n\n    return filename\n\n\ndef get_unpack_formats():\n    \"\"\"Returns a list of supported formats for unpacking.\n\n    Each element of the returned sequence is a tuple\n    (name, extensions, description)\n    \"\"\"\n    formats = [(name, info[0], info[3]) for name, info in\n               _UNPACK_FORMATS.items()]\n    formats.sort()\n    return formats\n\ndef _check_unpack_options(extensions, function, extra_args):\n    \"\"\"Checks what gets registered as an unpacker.\"\"\"\n    # first make sure no other unpacker is registered for this extension\n    existing_extensions = {}\n    for name, info in _UNPACK_FORMATS.items():\n        for ext in info[0]:\n            existing_extensions[ext] = name\n\n    for extension in extensions:\n        if extension in existing_extensions:\n            msg = '%s is already registered for \"%s\"'\n            raise RegistryError(msg % (extension,\n                                       existing_extensions[extension]))\n\n    if not callable(function):\n        raise TypeError('The registered function must be a callable')\n\n\ndef register_unpack_format(name, extensions, function, extra_args=None,\n                           description=''):\n    \"\"\"Registers an unpack format.\n\n    `name` is the name of the format. `extensions` is a list of extensions\n    corresponding to the format.\n\n    `function` is the callable that will be\n    used to unpack archives. The callable will receive archives to unpack.\n    If it's unable to handle an archive, it needs to raise a ReadError\n    exception.\n\n    If provided, `extra_args` is a sequence of\n    (name, value) tuples that will be passed as arguments to the callable.\n    description can be provided to describe the format, and will be returned\n    by the get_unpack_formats() function.\n    \"\"\"\n    if extra_args is None:\n        extra_args = []\n    _check_unpack_options(extensions, function, extra_args)\n    _UNPACK_FORMATS[name] = extensions, function, extra_args, description\n\ndef unregister_unpack_format(name):\n    \"\"\"Removes the pack format from the registery.\"\"\"\n    del _UNPACK_FORMATS[name]\n\ndef _ensure_directory(path):\n    \"\"\"Ensure that the parent directory of `path` exists\"\"\"\n    dirname = os.path.dirname(path)\n    if not os.path.isdir(dirname):\n        os.makedirs(dirname)\n\ndef _unpack_zipfile(filename, extract_dir):\n    \"\"\"Unpack zip `filename` to `extract_dir`\n    \"\"\"\n    try:\n        import zipfile\n    except ImportError:\n        raise ReadError('zlib not supported, cannot unpack this archive.')\n\n    if not zipfile.is_zipfile(filename):\n        raise ReadError(\"%s is not a zip file\" % filename)\n\n    zip = zipfile.ZipFile(filename)\n    try:\n        for info in zip.infolist():\n            name = info.filename\n\n            # don't extract absolute paths or ones with .. in them\n            if name.startswith('/') or '..' in name:\n                continue\n\n            target = os.path.join(extract_dir, *name.split('/'))\n            if not target:\n                continue\n\n            _ensure_directory(target)\n            if not name.endswith('/'):\n                # file\n                data = zip.read(info.filename)\n                f = open(target, 'wb')\n                try:\n                    f.write(data)\n                finally:\n                    f.close()\n                    del data\n    finally:\n        zip.close()\n\ndef _unpack_tarfile(filename, extract_dir):\n    \"\"\"Unpack tar/tar.gz/tar.bz2 `filename` to `extract_dir`\n    \"\"\"\n    try:\n        tarobj = tarfile.open(filename)\n    except tarfile.TarError:\n        raise ReadError(\n            \"%s is not a compressed or uncompressed tar file\" % filename)\n    try:\n        tarobj.extractall(extract_dir)\n    finally:\n        tarobj.close()\n\n_UNPACK_FORMATS = {\n    'gztar': (['.tar.gz', '.tgz'], _unpack_tarfile, [], \"gzip'ed tar-file\"),\n    'tar':   (['.tar'], _unpack_tarfile, [], \"uncompressed tar file\"),\n    'zip':   (['.zip'], _unpack_zipfile, [], \"ZIP file\")\n    }\n\nif _BZ2_SUPPORTED:\n    _UNPACK_FORMATS['bztar'] = (['.bz2'], _unpack_tarfile, [],\n                                \"bzip2'ed tar-file\")\n\ndef _find_unpack_format(filename):\n    for name, info in _UNPACK_FORMATS.items():\n        for extension in info[0]:\n            if filename.endswith(extension):\n                return name\n    return None\n\ndef unpack_archive(filename, extract_dir=None, format=None):\n    \"\"\"Unpack an archive.\n\n    `filename` is the name of the archive.\n\n    `extract_dir` is the name of the target directory, where the archive\n    is unpacked. If not provided, the current working directory is used.\n\n    `format` is the archive format: one of \"zip\", \"tar\", or \"gztar\". Or any\n    other registered format. If not provided, unpack_archive will use the\n    filename extension and see if an unpacker was registered for that\n    extension.\n\n    In case none is found, a ValueError is raised.\n    \"\"\"\n    if extract_dir is None:\n        extract_dir = os.getcwd()\n\n    if format is not None:\n        try:\n            format_info = _UNPACK_FORMATS[format]\n        except KeyError:\n            raise ValueError(\"Unknown unpack format '{0}'\".format(format))\n\n        func = format_info[1]\n        func(filename, extract_dir, **dict(format_info[2]))\n    else:\n        # we need to look at the registered unpackers supported extensions\n        format = _find_unpack_format(filename)\n        if format is None:\n            raise ReadError(\"Unknown archive format '{0}'\".format(filename))\n\n        func = _UNPACK_FORMATS[format][1]\n        kwargs = dict(_UNPACK_FORMATS[format][2])\n        func(filename, extract_dir, **kwargs)\n\n\nif hasattr(os, 'statvfs'):\n\n    __all__.append('disk_usage')\n    _ntuple_diskusage = collections.namedtuple('usage', 'total used free')\n\n    def disk_usage(path):\n        \"\"\"Return disk usage statistics about the given path.\n\n        Returned value is a named tuple with attributes 'total', 'used' and\n        'free', which are the amount of total, used and free space, in bytes.\n        \"\"\"\n        st = os.statvfs(path)\n        free = st.f_bavail * st.f_frsize\n        total = st.f_blocks * st.f_frsize\n        used = (st.f_blocks - st.f_bfree) * st.f_frsize\n        return _ntuple_diskusage(total, used, free)\n\nelif os.name == 'nt':\n\n    import nt\n    __all__.append('disk_usage')\n    _ntuple_diskusage = collections.namedtuple('usage', 'total used free')\n\n    def disk_usage(path):\n        \"\"\"Return disk usage statistics about the given path.\n\n        Returned values is a named tuple with attributes 'total', 'used' and\n        'free', which are the amount of total, used and free space, in bytes.\n        \"\"\"\n        total, free = nt._getdiskusage(path)\n        used = total - free\n        return _ntuple_diskusage(total, used, free)\n\n\ndef chown(path, user=None, group=None):\n    \"\"\"Change owner user and group of the given path.\n\n    user and group can be the uid/gid or the user/group names, and in that case,\n    they are converted to their respective uid/gid.\n    \"\"\"\n\n    if user is None and group is None:\n        raise ValueError(\"user and/or group must be set\")\n\n    _user = user\n    _group = group\n\n    # -1 means don't change it\n    if user is None:\n        _user = -1\n    # user can either be an int (the uid) or a string (the system username)\n    elif isinstance(user, str):\n        _user = _get_uid(user)\n        if _user is None:\n            raise LookupError(\"no such user: {!r}\".format(user))\n\n    if group is None:\n        _group = -1\n    elif not isinstance(group, int):\n        _group = _get_gid(group)\n        if _group is None:\n            raise LookupError(\"no such group: {!r}\".format(group))\n\n    os.chown(path, _user, _group)\n\ndef get_terminal_size(fallback=(80, 24)):\n    \"\"\"Get the size of the terminal window.\n\n    For each of the two dimensions, the environment variable, COLUMNS\n    and LINES respectively, is checked. If the variable is defined and\n    the value is a positive integer, it is used.\n\n    When COLUMNS or LINES is not defined, which is the common case,\n    the terminal connected to sys.__stdout__ is queried\n    by invoking os.get_terminal_size.\n\n    If the terminal size cannot be successfully queried, either because\n    the system doesn't support querying, or because we are not\n    connected to a terminal, the value given in fallback parameter\n    is used. Fallback defaults to (80, 24) which is the default\n    size used by many terminal emulators.\n\n    The value returned is a named tuple of type os.terminal_size.\n    \"\"\"\n    # columns, lines are the working values\n    try:\n        columns = int(os.environ['COLUMNS'])\n    except (KeyError, ValueError):\n        columns = 0\n\n    try:\n        lines = int(os.environ['LINES'])\n    except (KeyError, ValueError):\n        lines = 0\n\n    # only query if necessary\n    if columns <= 0 or lines <= 0:\n        try:\n            size = os.get_terminal_size(sys.__stdout__.fileno())\n        except (NameError, OSError):\n            size = os.terminal_size(fallback)\n        if columns <= 0:\n            columns = size.columns\n        if lines <= 0:\n            lines = size.lines\n\n    return os.terminal_size((columns, lines))\n\ndef which(cmd, mode=os.F_OK | os.X_OK, path=None):\n    \"\"\"Given a command, mode, and a PATH string, return the path which\n    conforms to the given mode on the PATH, or None if there is no such\n    file.\n\n    `mode` defaults to os.F_OK | os.X_OK. `path` defaults to the result\n    of os.environ.get(\"PATH\"), or can be overridden with a custom search\n    path.\n\n    \"\"\"\n    # Check that a given file can be accessed with the correct mode.\n    # Additionally check that `file` is not a directory, as on Windows\n    # directories pass the os.access check.\n    def _access_check(fn, mode):\n        return (os.path.exists(fn) and os.access(fn, mode)\n                and not os.path.isdir(fn))\n\n    # If we're given a path with a directory part, look it up directly rather\n    # than referring to PATH directories. This includes checking relative to the\n    # current directory, e.g. ./script\n    if os.path.dirname(cmd):\n        if _access_check(cmd, mode):\n            return cmd\n        return None\n\n    if path is None:\n        path = os.environ.get(\"PATH\", os.defpath)\n    if not path:\n        return None\n    path = path.split(os.pathsep)\n\n    if sys.platform == \"win32\":\n        # The current directory takes precedence on Windows.\n        if not os.curdir in path:\n            path.insert(0, os.curdir)\n\n        # PATHEXT is necessary to check on Windows.\n        pathext = os.environ.get(\"PATHEXT\", \"\").split(os.pathsep)\n        # See if the given file matches any of the expected path extensions.\n        # This will allow us to short circuit when given \"python.exe\".\n        # If it does match, only test that one, otherwise we have to try\n        # others.\n        if any(cmd.lower().endswith(ext.lower()) for ext in pathext):\n            files = [cmd]\n        else:\n            files = [cmd + ext for ext in pathext]\n    else:\n        # On other platforms you don't have things like PATHEXT to tell you\n        # what file suffixes are executable, so just pass on cmd as-is.\n        files = [cmd]\n\n    seen = set()\n    for dir in path:\n        normdir = os.path.normcase(dir)\n        if not normdir in seen:\n            seen.add(normdir)\n            for thefile in files:\n                name = os.path.join(dir, thefile)\n                if _access_check(name, mode):\n                    return name\n    return None\n"], "unittest.test.test_break": [".py", "import gc\nimport io\nimport os\nimport sys\nimport signal\nimport weakref\n\nimport unittest\n\n\n@unittest.skipUnless(hasattr(os, 'kill'), \"Test requires os.kill\")\n@unittest.skipIf(sys.platform ==\"win32\", \"Test cannot run on Windows\")\n@unittest.skipIf(sys.platform == 'freebsd6', \"Test kills regrtest on freebsd6 \"\n    \"if threads have been used\")\nclass TestBreak(unittest.TestCase):\n\n    def setUp(self):\n        self._default_handler = signal.getsignal(signal.SIGINT)\n\n    def tearDown(self):\n        signal.signal(signal.SIGINT, self._default_handler)\n        unittest.signals._results = weakref.WeakKeyDictionary()\n        unittest.signals._interrupt_handler = None\n\n\n    def testInstallHandler(self):\n        default_handler = signal.getsignal(signal.SIGINT)\n        unittest.installHandler()\n        self.assertNotEqual(signal.getsignal(signal.SIGINT), default_handler)\n\n        try:\n            pid = os.getpid()\n            os.kill(pid, signal.SIGINT)\n        except KeyboardInterrupt:\n            self.fail(\"KeyboardInterrupt not handled\")\n\n        self.assertTrue(unittest.signals._interrupt_handler.called)\n\n    def testRegisterResult(self):\n        result = unittest.TestResult()\n        unittest.registerResult(result)\n\n        for ref in unittest.signals._results:\n            if ref is result:\n                break\n            elif ref is not result:\n                self.fail(\"odd object in result set\")\n        else:\n            self.fail(\"result not found\")\n\n\n    def testInterruptCaught(self):\n        default_handler = signal.getsignal(signal.SIGINT)\n\n        result = unittest.TestResult()\n        unittest.installHandler()\n        unittest.registerResult(result)\n\n        self.assertNotEqual(signal.getsignal(signal.SIGINT), default_handler)\n\n        def test(result):\n            pid = os.getpid()\n            os.kill(pid, signal.SIGINT)\n            result.breakCaught = True\n            self.assertTrue(result.shouldStop)\n\n        try:\n            test(result)\n        except KeyboardInterrupt:\n            self.fail(\"KeyboardInterrupt not handled\")\n        self.assertTrue(result.breakCaught)\n\n\n    def testSecondInterrupt(self):\n        result = unittest.TestResult()\n        unittest.installHandler()\n        unittest.registerResult(result)\n\n        def test(result):\n            pid = os.getpid()\n            os.kill(pid, signal.SIGINT)\n            result.breakCaught = True\n            self.assertTrue(result.shouldStop)\n            os.kill(pid, signal.SIGINT)\n            self.fail(\"Second KeyboardInterrupt not raised\")\n\n        try:\n            test(result)\n        except KeyboardInterrupt:\n            pass\n        else:\n            self.fail(\"Second KeyboardInterrupt not raised\")\n        self.assertTrue(result.breakCaught)\n\n\n    def testTwoResults(self):\n        unittest.installHandler()\n\n        result = unittest.TestResult()\n        unittest.registerResult(result)\n        new_handler = signal.getsignal(signal.SIGINT)\n\n        result2 = unittest.TestResult()\n        unittest.registerResult(result2)\n        self.assertEqual(signal.getsignal(signal.SIGINT), new_handler)\n\n        result3 = unittest.TestResult()\n\n        def test(result):\n            pid = os.getpid()\n            os.kill(pid, signal.SIGINT)\n\n        try:\n            test(result)\n        except KeyboardInterrupt:\n            self.fail(\"KeyboardInterrupt not handled\")\n\n        self.assertTrue(result.shouldStop)\n        self.assertTrue(result2.shouldStop)\n        self.assertFalse(result3.shouldStop)\n\n\n    def testHandlerReplacedButCalled(self):\n        # If our handler has been replaced (is no longer installed) but is\n        # called by the *new* handler, then it isn't safe to delay the\n        # SIGINT and we should immediately delegate to the default handler\n        unittest.installHandler()\n\n        handler = signal.getsignal(signal.SIGINT)\n        def new_handler(frame, signum):\n            handler(frame, signum)\n        signal.signal(signal.SIGINT, new_handler)\n\n        try:\n            pid = os.getpid()\n            os.kill(pid, signal.SIGINT)\n        except KeyboardInterrupt:\n            pass\n        else:\n            self.fail(\"replaced but delegated handler doesn't raise interrupt\")\n\n    def testRunner(self):\n        # Creating a TextTestRunner with the appropriate argument should\n        # register the TextTestResult it creates\n        runner = unittest.TextTestRunner(stream=io.StringIO())\n\n        result = runner.run(unittest.TestSuite())\n        self.assertIn(result, unittest.signals._results)\n\n    def testWeakReferences(self):\n        # Calling registerResult on a result should not keep it alive\n        result = unittest.TestResult()\n        unittest.registerResult(result)\n\n        ref = weakref.ref(result)\n        del result\n\n        # For non-reference counting implementations\n        gc.collect();gc.collect()\n        self.assertIsNone(ref())\n\n\n    def testRemoveResult(self):\n        result = unittest.TestResult()\n        unittest.registerResult(result)\n\n        unittest.installHandler()\n        self.assertTrue(unittest.removeResult(result))\n\n        # Should this raise an error instead?\n        self.assertFalse(unittest.removeResult(unittest.TestResult()))\n\n        try:\n            pid = os.getpid()\n            os.kill(pid, signal.SIGINT)\n        except KeyboardInterrupt:\n            pass\n\n        self.assertFalse(result.shouldStop)\n\n    def testMainInstallsHandler(self):\n        failfast = object()\n        test = object()\n        verbosity = object()\n        result = object()\n        default_handler = signal.getsignal(signal.SIGINT)\n\n        class FakeRunner(object):\n            initArgs = []\n            runArgs = []\n            def __init__(self, *args, **kwargs):\n                self.initArgs.append((args, kwargs))\n            def run(self, test):\n                self.runArgs.append(test)\n                return result\n\n        class Program(unittest.TestProgram):\n            def __init__(self, catchbreak):\n                self.exit = False\n                self.verbosity = verbosity\n                self.failfast = failfast\n                self.catchbreak = catchbreak\n                self.testRunner = FakeRunner\n                self.test = test\n                self.result = None\n\n        p = Program(False)\n        p.runTests()\n\n        self.assertEqual(FakeRunner.initArgs, [((), {'buffer': None,\n                                                     'verbosity': verbosity,\n                                                     'failfast': failfast,\n                                                     'warnings': None})])\n        self.assertEqual(FakeRunner.runArgs, [test])\n        self.assertEqual(p.result, result)\n\n        self.assertEqual(signal.getsignal(signal.SIGINT), default_handler)\n\n        FakeRunner.initArgs = []\n        FakeRunner.runArgs = []\n        p = Program(True)\n        p.runTests()\n\n        self.assertEqual(FakeRunner.initArgs, [((), {'buffer': None,\n                                                     'verbosity': verbosity,\n                                                     'failfast': failfast,\n                                                     'warnings': None})])\n        self.assertEqual(FakeRunner.runArgs, [test])\n        self.assertEqual(p.result, result)\n\n        self.assertNotEqual(signal.getsignal(signal.SIGINT), default_handler)\n\n    def testRemoveHandler(self):\n        default_handler = signal.getsignal(signal.SIGINT)\n        unittest.installHandler()\n        unittest.removeHandler()\n        self.assertEqual(signal.getsignal(signal.SIGINT), default_handler)\n\n        # check that calling removeHandler multiple times has no ill-effect\n        unittest.removeHandler()\n        self.assertEqual(signal.getsignal(signal.SIGINT), default_handler)\n\n    def testRemoveHandlerAsDecorator(self):\n        default_handler = signal.getsignal(signal.SIGINT)\n        unittest.installHandler()\n\n        @unittest.removeHandler\n        def test():\n            self.assertEqual(signal.getsignal(signal.SIGINT), default_handler)\n\n        test()\n        self.assertNotEqual(signal.getsignal(signal.SIGINT), default_handler)\n"], "configparser": [".py", "\"\"\"Configuration file parser.\n\nA configuration file consists of sections, lead by a \"[section]\" header,\nand followed by \"name: value\" entries, with continuations and such in\nthe style of RFC 822.\n\nIntrinsic defaults can be specified by passing them into the\nConfigParser constructor as a dictionary.\n\nclass:\n\nConfigParser -- responsible for parsing a list of\n                    configuration files, and managing the parsed database.\n\n    methods:\n\n    __init__(defaults=None, dict_type=_default_dict, allow_no_value=False,\n             delimiters=('=', ':'), comment_prefixes=('#', ';'),\n             inline_comment_prefixes=None, strict=True,\n             empty_lines_in_values=True):\n        Create the parser. When `defaults' is given, it is initialized into the\n        dictionary or intrinsic defaults. The keys must be strings, the values\n        must be appropriate for %()s string interpolation.\n\n        When `dict_type' is given, it will be used to create the dictionary\n        objects for the list of sections, for the options within a section, and\n        for the default values.\n\n        When `delimiters' is given, it will be used as the set of substrings\n        that divide keys from values.\n\n        When `comment_prefixes' is given, it will be used as the set of\n        substrings that prefix comments in empty lines. Comments can be\n        indented.\n\n        When `inline_comment_prefixes' is given, it will be used as the set of\n        substrings that prefix comments in non-empty lines.\n\n        When `strict` is True, the parser won't allow for any section or option\n        duplicates while reading from a single source (file, string or\n        dictionary). Default is True.\n\n        When `empty_lines_in_values' is False (default: True), each empty line\n        marks the end of an option. Otherwise, internal empty lines of\n        a multiline option are kept as part of the value.\n\n        When `allow_no_value' is True (default: False), options without\n        values are accepted; the value presented for these is None.\n\n    sections()\n        Return all the configuration section names, sans DEFAULT.\n\n    has_section(section)\n        Return whether the given section exists.\n\n    has_option(section, option)\n        Return whether the given option exists in the given section.\n\n    options(section)\n        Return list of configuration options for the named section.\n\n    read(filenames, encoding=None)\n        Read and parse the list of named configuration files, given by\n        name.  A single filename is also allowed.  Non-existing files\n        are ignored.  Return list of successfully read files.\n\n    read_file(f, filename=None)\n        Read and parse one configuration file, given as a file object.\n        The filename defaults to f.name; it is only used in error\n        messages (if f has no `name' attribute, the string `<???>' is used).\n\n    read_string(string)\n        Read configuration from a given string.\n\n    read_dict(dictionary)\n        Read configuration from a dictionary. Keys are section names,\n        values are dictionaries with keys and values that should be present\n        in the section. If the used dictionary type preserves order, sections\n        and their keys will be added in order. Values are automatically\n        converted to strings.\n\n    get(section, option, raw=False, vars=None, fallback=_UNSET)\n        Return a string value for the named option.  All % interpolations are\n        expanded in the return values, based on the defaults passed into the\n        constructor and the DEFAULT section.  Additional substitutions may be\n        provided using the `vars' argument, which must be a dictionary whose\n        contents override any pre-existing defaults. If `option' is a key in\n        `vars', the value from `vars' is used.\n\n    getint(section, options, raw=False, vars=None, fallback=_UNSET)\n        Like get(), but convert value to an integer.\n\n    getfloat(section, options, raw=False, vars=None, fallback=_UNSET)\n        Like get(), but convert value to a float.\n\n    getboolean(section, options, raw=False, vars=None, fallback=_UNSET)\n        Like get(), but convert value to a boolean (currently case\n        insensitively defined as 0, false, no, off for False, and 1, true,\n        yes, on for True).  Returns False or True.\n\n    items(section=_UNSET, raw=False, vars=None)\n        If section is given, return a list of tuples with (name, value) for\n        each option in the section. Otherwise, return a list of tuples with\n        (section_name, section_proxy) for each section, including DEFAULTSECT.\n\n    remove_section(section)\n        Remove the given file section and all its options.\n\n    remove_option(section, option)\n        Remove the given option from the given section.\n\n    set(section, option, value)\n        Set the given option.\n\n    write(fp, space_around_delimiters=True)\n        Write the configuration state in .ini format. If\n        `space_around_delimiters' is True (the default), delimiters\n        between keys and values are surrounded by spaces.\n\"\"\"\n\nfrom collections.abc import MutableMapping\nfrom collections import OrderedDict as _default_dict, ChainMap as _ChainMap\nimport functools\nimport io\nimport itertools\nimport re\nimport sys\nimport warnings\n\n__all__ = [\"NoSectionError\", \"DuplicateOptionError\", \"DuplicateSectionError\",\n           \"NoOptionError\", \"InterpolationError\", \"InterpolationDepthError\",\n           \"InterpolationSyntaxError\", \"ParsingError\",\n           \"MissingSectionHeaderError\",\n           \"ConfigParser\", \"SafeConfigParser\", \"RawConfigParser\",\n           \"DEFAULTSECT\", \"MAX_INTERPOLATION_DEPTH\"]\n\nDEFAULTSECT = \"DEFAULT\"\n\nMAX_INTERPOLATION_DEPTH = 10\n\n\n\n# exception classes\nclass Error(Exception):\n    \"\"\"Base class for ConfigParser exceptions.\"\"\"\n\n    def _get_message(self):\n        \"\"\"Getter for 'message'; needed only to override deprecation in\n        BaseException.\n        \"\"\"\n        return self.__message\n\n    def _set_message(self, value):\n        \"\"\"Setter for 'message'; needed only to override deprecation in\n        BaseException.\n        \"\"\"\n        self.__message = value\n\n    # BaseException.message has been deprecated since Python 2.6.  To prevent\n    # DeprecationWarning from popping up over this pre-existing attribute, use\n    # a new property that takes lookup precedence.\n    message = property(_get_message, _set_message)\n\n    def __init__(self, msg=''):\n        self.message = msg\n        Exception.__init__(self, msg)\n\n    def __repr__(self):\n        return self.message\n\n    __str__ = __repr__\n\n\nclass NoSectionError(Error):\n    \"\"\"Raised when no section matches a requested option.\"\"\"\n\n    def __init__(self, section):\n        Error.__init__(self, 'No section: %r' % (section,))\n        self.section = section\n        self.args = (section, )\n\n\nclass DuplicateSectionError(Error):\n    \"\"\"Raised when a section is repeated in an input source.\n\n    Possible repetitions that raise this exception are: multiple creation\n    using the API or in strict parsers when a section is found more than once\n    in a single input file, string or dictionary.\n    \"\"\"\n\n    def __init__(self, section, source=None, lineno=None):\n        msg = [repr(section), \" already exists\"]\n        if source is not None:\n            message = [\"While reading from \", source]\n            if lineno is not None:\n                message.append(\" [line {0:2d}]\".format(lineno))\n            message.append(\": section \")\n            message.extend(msg)\n            msg = message\n        else:\n            msg.insert(0, \"Section \")\n        Error.__init__(self, \"\".join(msg))\n        self.section = section\n        self.source = source\n        self.lineno = lineno\n        self.args = (section, source, lineno)\n\n\nclass DuplicateOptionError(Error):\n    \"\"\"Raised by strict parsers when an option is repeated in an input source.\n\n    Current implementation raises this exception only when an option is found\n    more than once in a single file, string or dictionary.\n    \"\"\"\n\n    def __init__(self, section, option, source=None, lineno=None):\n        msg = [repr(option), \" in section \", repr(section),\n               \" already exists\"]\n        if source is not None:\n            message = [\"While reading from \", source]\n            if lineno is not None:\n                message.append(\" [line {0:2d}]\".format(lineno))\n            message.append(\": option \")\n            message.extend(msg)\n            msg = message\n        else:\n            msg.insert(0, \"Option \")\n        Error.__init__(self, \"\".join(msg))\n        self.section = section\n        self.option = option\n        self.source = source\n        self.lineno = lineno\n        self.args = (section, option, source, lineno)\n\n\nclass NoOptionError(Error):\n    \"\"\"A requested option was not found.\"\"\"\n\n    def __init__(self, option, section):\n        Error.__init__(self, \"No option %r in section: %r\" %\n                       (option, section))\n        self.option = option\n        self.section = section\n        self.args = (option, section)\n\n\nclass InterpolationError(Error):\n    \"\"\"Base class for interpolation-related exceptions.\"\"\"\n\n    def __init__(self, option, section, msg):\n        Error.__init__(self, msg)\n        self.option = option\n        self.section = section\n        self.args = (option, section, msg)\n\n\nclass InterpolationMissingOptionError(InterpolationError):\n    \"\"\"A string substitution required a setting which was not available.\"\"\"\n\n    def __init__(self, option, section, rawval, reference):\n        msg = (\"Bad value substitution:\\n\"\n               \"\\tsection: [%s]\\n\"\n               \"\\toption : %s\\n\"\n               \"\\tkey    : %s\\n\"\n               \"\\trawval : %s\\n\"\n               % (section, option, reference, rawval))\n        InterpolationError.__init__(self, option, section, msg)\n        self.reference = reference\n        self.args = (option, section, rawval, reference)\n\n\nclass InterpolationSyntaxError(InterpolationError):\n    \"\"\"Raised when the source text contains invalid syntax.\n\n    Current implementation raises this exception when the source text into\n    which substitutions are made does not conform to the required syntax.\n    \"\"\"\n\n\nclass InterpolationDepthError(InterpolationError):\n    \"\"\"Raised when substitutions are nested too deeply.\"\"\"\n\n    def __init__(self, option, section, rawval):\n        msg = (\"Value interpolation too deeply recursive:\\n\"\n               \"\\tsection: [%s]\\n\"\n               \"\\toption : %s\\n\"\n               \"\\trawval : %s\\n\"\n               % (section, option, rawval))\n        InterpolationError.__init__(self, option, section, msg)\n        self.args = (option, section, rawval)\n\n\nclass ParsingError(Error):\n    \"\"\"Raised when a configuration file does not follow legal syntax.\"\"\"\n\n    def __init__(self, source=None, filename=None):\n        # Exactly one of `source'/`filename' arguments has to be given.\n        # `filename' kept for compatibility.\n        if filename and source:\n            raise ValueError(\"Cannot specify both `filename' and `source'. \"\n                             \"Use `source'.\")\n        elif not filename and not source:\n            raise ValueError(\"Required argument `source' not given.\")\n        elif filename:\n            source = filename\n        Error.__init__(self, 'Source contains parsing errors: %s' % source)\n        self.source = source\n        self.errors = []\n        self.args = (source, )\n\n    @property\n    def filename(self):\n        \"\"\"Deprecated, use `source'.\"\"\"\n        warnings.warn(\n            \"The 'filename' attribute will be removed in future versions.  \"\n            \"Use 'source' instead.\",\n            DeprecationWarning, stacklevel=2\n        )\n        return self.source\n\n    @filename.setter\n    def filename(self, value):\n        \"\"\"Deprecated, user `source'.\"\"\"\n        warnings.warn(\n            \"The 'filename' attribute will be removed in future versions.  \"\n            \"Use 'source' instead.\",\n            DeprecationWarning, stacklevel=2\n        )\n        self.source = value\n\n    def append(self, lineno, line):\n        self.errors.append((lineno, line))\n        self.message += '\\n\\t[line %2d]: %s' % (lineno, line)\n\n\nclass MissingSectionHeaderError(ParsingError):\n    \"\"\"Raised when a key-value pair is found before any section header.\"\"\"\n\n    def __init__(self, filename, lineno, line):\n        Error.__init__(\n            self,\n            'File contains no section headers.\\nfile: %s, line: %d\\n%r' %\n            (filename, lineno, line))\n        self.source = filename\n        self.lineno = lineno\n        self.line = line\n        self.args = (filename, lineno, line)\n\n\n# Used in parser getters to indicate the default behaviour when a specific\n# option is not found it to raise an exception. Created to enable `None' as\n# a valid fallback value.\n_UNSET = object()\n\n\nclass Interpolation:\n    \"\"\"Dummy interpolation that passes the value through with no changes.\"\"\"\n\n    def before_get(self, parser, section, option, value, defaults):\n        return value\n\n    def before_set(self, parser, section, option, value):\n        return value\n\n    def before_read(self, parser, section, option, value):\n        return value\n\n    def before_write(self, parser, section, option, value):\n        return value\n\n\nclass BasicInterpolation(Interpolation):\n    \"\"\"Interpolation as implemented in the classic ConfigParser.\n\n    The option values can contain format strings which refer to other values in\n    the same section, or values in the special default section.\n\n    For example:\n\n        something: %(dir)s/whatever\n\n    would resolve the \"%(dir)s\" to the value of dir.  All reference\n    expansions are done late, on demand. If a user needs to use a bare % in\n    a configuration file, she can escape it by writing %%. Other % usage\n    is considered a user error and raises `InterpolationSyntaxError'.\"\"\"\n\n    _KEYCRE = re.compile(r\"%\\(([^)]+)\\)s\")\n\n    def before_get(self, parser, section, option, value, defaults):\n        L = []\n        self._interpolate_some(parser, option, L, value, section, defaults, 1)\n        return ''.join(L)\n\n    def before_set(self, parser, section, option, value):\n        tmp_value = value.replace('%%', '') # escaped percent signs\n        tmp_value = self._KEYCRE.sub('', tmp_value) # valid syntax\n        if '%' in tmp_value:\n            raise ValueError(\"invalid interpolation syntax in %r at \"\n                             \"position %d\" % (value, tmp_value.find('%')))\n        return value\n\n    def _interpolate_some(self, parser, option, accum, rest, section, map,\n                          depth):\n        if depth > MAX_INTERPOLATION_DEPTH:\n            raise InterpolationDepthError(option, section, rest)\n        while rest:\n            p = rest.find(\"%\")\n            if p < 0:\n                accum.append(rest)\n                return\n            if p > 0:\n                accum.append(rest[:p])\n                rest = rest[p:]\n            # p is no longer used\n            c = rest[1:2]\n            if c == \"%\":\n                accum.append(\"%\")\n                rest = rest[2:]\n            elif c == \"(\":\n                m = self._KEYCRE.match(rest)\n                if m is None:\n                    raise InterpolationSyntaxError(option, section,\n                        \"bad interpolation variable reference %r\" % rest)\n                var = parser.optionxform(m.group(1))\n                rest = rest[m.end():]\n                try:\n                    v = map[var]\n                except KeyError:\n                    raise InterpolationMissingOptionError(\n                        option, section, rest, var)\n                if \"%\" in v:\n                    self._interpolate_some(parser, option, accum, v,\n                                           section, map, depth + 1)\n                else:\n                    accum.append(v)\n            else:\n                raise InterpolationSyntaxError(\n                    option, section,\n                    \"'%%' must be followed by '%%' or '(', \"\n                    \"found: %r\" % (rest,))\n\n\nclass ExtendedInterpolation(Interpolation):\n    \"\"\"Advanced variant of interpolation, supports the syntax used by\n    `zc.buildout'. Enables interpolation between sections.\"\"\"\n\n    _KEYCRE = re.compile(r\"\\$\\{([^}]+)\\}\")\n\n    def before_get(self, parser, section, option, value, defaults):\n        L = []\n        self._interpolate_some(parser, option, L, value, section, defaults, 1)\n        return ''.join(L)\n\n    def before_set(self, parser, section, option, value):\n        tmp_value = value.replace('$$', '') # escaped dollar signs\n        tmp_value = self._KEYCRE.sub('', tmp_value) # valid syntax\n        if '$' in tmp_value:\n            raise ValueError(\"invalid interpolation syntax in %r at \"\n                             \"position %d\" % (value, tmp_value.find('%')))\n        return value\n\n    def _interpolate_some(self, parser, option, accum, rest, section, map,\n                          depth):\n        if depth > MAX_INTERPOLATION_DEPTH:\n            raise InterpolationDepthError(option, section, rest)\n        while rest:\n            p = rest.find(\"$\")\n            if p < 0:\n                accum.append(rest)\n                return\n            if p > 0:\n                accum.append(rest[:p])\n                rest = rest[p:]\n            # p is no longer used\n            c = rest[1:2]\n            if c == \"$\":\n                accum.append(\"$\")\n                rest = rest[2:]\n            elif c == \"{\":\n                m = self._KEYCRE.match(rest)\n                if m is None:\n                    raise InterpolationSyntaxError(option, section,\n                        \"bad interpolation variable reference %r\" % rest)\n                path = m.group(1).split(':')\n                rest = rest[m.end():]\n                sect = section\n                opt = option\n                try:\n                    if len(path) == 1:\n                        opt = parser.optionxform(path[0])\n                        v = map[opt]\n                    elif len(path) == 2:\n                        sect = path[0]\n                        opt = parser.optionxform(path[1])\n                        v = parser.get(sect, opt, raw=True)\n                    else:\n                        raise InterpolationSyntaxError(\n                            option, section,\n                            \"More than one ':' found: %r\" % (rest,))\n                except (KeyError, NoSectionError, NoOptionError):\n                    raise InterpolationMissingOptionError(\n                        option, section, rest, \":\".join(path))\n                if \"$\" in v:\n                    self._interpolate_some(parser, opt, accum, v, sect,\n                                           dict(parser.items(sect, raw=True)),\n                                           depth + 1)\n                else:\n                    accum.append(v)\n            else:\n                raise InterpolationSyntaxError(\n                    option, section,\n                    \"'$' must be followed by '$' or '{', \"\n                    \"found: %r\" % (rest,))\n\n\nclass LegacyInterpolation(Interpolation):\n    \"\"\"Deprecated interpolation used in old versions of ConfigParser.\n    Use BasicInterpolation or ExtendedInterpolation instead.\"\"\"\n\n    _KEYCRE = re.compile(r\"%\\(([^)]*)\\)s|.\")\n\n    def before_get(self, parser, section, option, value, vars):\n        rawval = value\n        depth = MAX_INTERPOLATION_DEPTH\n        while depth:                    # Loop through this until it's done\n            depth -= 1\n            if value and \"%(\" in value:\n                replace = functools.partial(self._interpolation_replace,\n                                            parser=parser)\n                value = self._KEYCRE.sub(replace, value)\n                try:\n                    value = value % vars\n                except KeyError as e:\n                    raise InterpolationMissingOptionError(\n                        option, section, rawval, e.args[0])\n            else:\n                break\n        if value and \"%(\" in value:\n            raise InterpolationDepthError(option, section, rawval)\n        return value\n\n    def before_set(self, parser, section, option, value):\n        return value\n\n    @staticmethod\n    def _interpolation_replace(match, parser):\n        s = match.group(1)\n        if s is None:\n            return match.group()\n        else:\n            return \"%%(%s)s\" % parser.optionxform(s)\n\n\nclass RawConfigParser(MutableMapping):\n    \"\"\"ConfigParser that does not do interpolation.\"\"\"\n\n    # Regular expressions for parsing section headers and options\n    _SECT_TMPL = r\"\"\"\n        \\[                                 # [\n        (?P<header>[^]]+)                  # very permissive!\n        \\]                                 # ]\n        \"\"\"\n    _OPT_TMPL = r\"\"\"\n        (?P<option>.*?)                    # very permissive!\n        \\s*(?P<vi>{delim})\\s*              # any number of space/tab,\n                                           # followed by any of the\n                                           # allowed delimiters,\n                                           # followed by any space/tab\n        (?P<value>.*)$                     # everything up to eol\n        \"\"\"\n    _OPT_NV_TMPL = r\"\"\"\n        (?P<option>.*?)                    # very permissive!\n        \\s*(?:                             # any number of space/tab,\n        (?P<vi>{delim})\\s*                 # optionally followed by\n                                           # any of the allowed\n                                           # delimiters, followed by any\n                                           # space/tab\n        (?P<value>.*))?$                   # everything up to eol\n        \"\"\"\n    # Interpolation algorithm to be used if the user does not specify another\n    _DEFAULT_INTERPOLATION = Interpolation()\n    # Compiled regular expression for matching sections\n    SECTCRE = re.compile(_SECT_TMPL, re.VERBOSE)\n    # Compiled regular expression for matching options with typical separators\n    OPTCRE = re.compile(_OPT_TMPL.format(delim=\"=|:\"), re.VERBOSE)\n    # Compiled regular expression for matching options with optional values\n    # delimited using typical separators\n    OPTCRE_NV = re.compile(_OPT_NV_TMPL.format(delim=\"=|:\"), re.VERBOSE)\n    # Compiled regular expression for matching leading whitespace in a line\n    NONSPACECRE = re.compile(r\"\\S\")\n    # Possible boolean values in the configuration.\n    BOOLEAN_STATES = {'1': True, 'yes': True, 'true': True, 'on': True,\n                      '0': False, 'no': False, 'false': False, 'off': False}\n\n    def __init__(self, defaults=None, dict_type=_default_dict,\n                 allow_no_value=False, *, delimiters=('=', ':'),\n                 comment_prefixes=('#', ';'), inline_comment_prefixes=None,\n                 strict=True, empty_lines_in_values=True,\n                 default_section=DEFAULTSECT,\n                 interpolation=_UNSET):\n\n        self._dict = dict_type\n        self._sections = self._dict()\n        self._defaults = self._dict()\n        self._proxies = self._dict()\n        self._proxies[default_section] = SectionProxy(self, default_section)\n        if defaults:\n            for key, value in defaults.items():\n                self._defaults[self.optionxform(key)] = value\n        self._delimiters = tuple(delimiters)\n        if delimiters == ('=', ':'):\n            self._optcre = self.OPTCRE_NV if allow_no_value else self.OPTCRE\n        else:\n            d = \"|\".join(re.escape(d) for d in delimiters)\n            if allow_no_value:\n                self._optcre = re.compile(self._OPT_NV_TMPL.format(delim=d),\n                                          re.VERBOSE)\n            else:\n                self._optcre = re.compile(self._OPT_TMPL.format(delim=d),\n                                          re.VERBOSE)\n        self._comment_prefixes = tuple(comment_prefixes or ())\n        self._inline_comment_prefixes = tuple(inline_comment_prefixes or ())\n        self._strict = strict\n        self._allow_no_value = allow_no_value\n        self._empty_lines_in_values = empty_lines_in_values\n        self.default_section=default_section\n        self._interpolation = interpolation\n        if self._interpolation is _UNSET:\n            self._interpolation = self._DEFAULT_INTERPOLATION\n        if self._interpolation is None:\n            self._interpolation = Interpolation()\n\n    def defaults(self):\n        return self._defaults\n\n    def sections(self):\n        \"\"\"Return a list of section names, excluding [DEFAULT]\"\"\"\n        # self._sections will never have [DEFAULT] in it\n        return list(self._sections.keys())\n\n    def add_section(self, section):\n        \"\"\"Create a new section in the configuration.\n\n        Raise DuplicateSectionError if a section by the specified name\n        already exists. Raise ValueError if name is DEFAULT.\n        \"\"\"\n        if section == self.default_section:\n            raise ValueError('Invalid section name: %r' % section)\n\n        if section in self._sections:\n            raise DuplicateSectionError(section)\n        self._sections[section] = self._dict()\n        self._proxies[section] = SectionProxy(self, section)\n\n    def has_section(self, section):\n        \"\"\"Indicate whether the named section is present in the configuration.\n\n        The DEFAULT section is not acknowledged.\n        \"\"\"\n        return section in self._sections\n\n    def options(self, section):\n        \"\"\"Return a list of option names for the given section name.\"\"\"\n        try:\n            opts = self._sections[section].copy()\n        except KeyError:\n            raise NoSectionError(section)\n        opts.update(self._defaults)\n        return list(opts.keys())\n\n    def read(self, filenames, encoding=None):\n        \"\"\"Read and parse a filename or a list of filenames.\n\n        Files that cannot be opened are silently ignored; this is\n        designed so that you can specify a list of potential\n        configuration file locations (e.g. current directory, user's\n        home directory, systemwide directory), and all existing\n        configuration files in the list will be read.  A single\n        filename may also be given.\n\n        Return list of successfully read files.\n        \"\"\"\n        if isinstance(filenames, str):\n            filenames = [filenames]\n        read_ok = []\n        for filename in filenames:\n            try:\n                with open(filename, encoding=encoding) as fp:\n                    self._read(fp, filename)\n            except IOError:\n                continue\n            read_ok.append(filename)\n        return read_ok\n\n    def read_file(self, f, source=None):\n        \"\"\"Like read() but the argument must be a file-like object.\n\n        The `f' argument must be iterable, returning one line at a time.\n        Optional second argument is the `source' specifying the name of the\n        file being read. If not given, it is taken from f.name. If `f' has no\n        `name' attribute, `<???>' is used.\n        \"\"\"\n        if source is None:\n            try:\n                source = f.name\n            except AttributeError:\n                source = '<???>'\n        self._read(f, source)\n\n    def read_string(self, string, source='<string>'):\n        \"\"\"Read configuration from a given string.\"\"\"\n        sfile = io.StringIO(string)\n        self.read_file(sfile, source)\n\n    def read_dict(self, dictionary, source='<dict>'):\n        \"\"\"Read configuration from a dictionary.\n\n        Keys are section names, values are dictionaries with keys and values\n        that should be present in the section. If the used dictionary type\n        preserves order, sections and their keys will be added in order.\n\n        All types held in the dictionary are converted to strings during\n        reading, including section names, option names and keys.\n\n        Optional second argument is the `source' specifying the name of the\n        dictionary being read.\n        \"\"\"\n        elements_added = set()\n        for section, keys in dictionary.items():\n            section = str(section)\n            try:\n                self.add_section(section)\n            except (DuplicateSectionError, ValueError):\n                if self._strict and section in elements_added:\n                    raise\n            elements_added.add(section)\n            for key, value in keys.items():\n                key = self.optionxform(str(key))\n                if value is not None:\n                    value = str(value)\n                if self._strict and (section, key) in elements_added:\n                    raise DuplicateOptionError(section, key, source)\n                elements_added.add((section, key))\n                self.set(section, key, value)\n\n    def readfp(self, fp, filename=None):\n        \"\"\"Deprecated, use read_file instead.\"\"\"\n        warnings.warn(\n            \"This method will be removed in future versions.  \"\n            \"Use 'parser.read_file()' instead.\",\n            DeprecationWarning, stacklevel=2\n        )\n        self.read_file(fp, source=filename)\n\n    def get(self, section, option, *, raw=False, vars=None, fallback=_UNSET):\n        \"\"\"Get an option value for a given section.\n\n        If `vars' is provided, it must be a dictionary. The option is looked up\n        in `vars' (if provided), `section', and in `DEFAULTSECT' in that order.\n        If the key is not found and `fallback' is provided, it is used as\n        a fallback value. `None' can be provided as a `fallback' value.\n\n        If interpolation is enabled and the optional argument `raw' is False,\n        all interpolations are expanded in the return values.\n\n        Arguments `raw', `vars', and `fallback' are keyword only.\n\n        The section DEFAULT is special.\n        \"\"\"\n        try:\n            d = self._unify_values(section, vars)\n        except NoSectionError:\n            if fallback is _UNSET:\n                raise\n            else:\n                return fallback\n        option = self.optionxform(option)\n        try:\n            value = d[option]\n        except KeyError:\n            if fallback is _UNSET:\n                raise NoOptionError(option, section)\n            else:\n                return fallback\n\n        if raw or value is None:\n            return value\n        else:\n            return self._interpolation.before_get(self, section, option, value,\n                                                  d)\n\n    def _get(self, section, conv, option, **kwargs):\n        return conv(self.get(section, option, **kwargs))\n\n    def getint(self, section, option, *, raw=False, vars=None,\n               fallback=_UNSET):\n        try:\n            return self._get(section, int, option, raw=raw, vars=vars)\n        except (NoSectionError, NoOptionError):\n            if fallback is _UNSET:\n                raise\n            else:\n                return fallback\n\n    def getfloat(self, section, option, *, raw=False, vars=None,\n                 fallback=_UNSET):\n        try:\n            return self._get(section, float, option, raw=raw, vars=vars)\n        except (NoSectionError, NoOptionError):\n            if fallback is _UNSET:\n                raise\n            else:\n                return fallback\n\n    def getboolean(self, section, option, *, raw=False, vars=None,\n                   fallback=_UNSET):\n        try:\n            return self._get(section, self._convert_to_boolean, option,\n                             raw=raw, vars=vars)\n        except (NoSectionError, NoOptionError):\n            if fallback is _UNSET:\n                raise\n            else:\n                return fallback\n\n    def items(self, section=_UNSET, raw=False, vars=None):\n        \"\"\"Return a list of (name, value) tuples for each option in a section.\n\n        All % interpolations are expanded in the return values, based on the\n        defaults passed into the constructor, unless the optional argument\n        `raw' is true.  Additional substitutions may be provided using the\n        `vars' argument, which must be a dictionary whose contents overrides\n        any pre-existing defaults.\n\n        The section DEFAULT is special.\n        \"\"\"\n        if section is _UNSET:\n            return super().items()\n        d = self._defaults.copy()\n        try:\n            d.update(self._sections[section])\n        except KeyError:\n            if section != self.default_section:\n                raise NoSectionError(section)\n        # Update with the entry specific variables\n        if vars:\n            for key, value in vars.items():\n                d[self.optionxform(key)] = value\n        value_getter = lambda option: self._interpolation.before_get(self,\n            section, option, d[option], d)\n        if raw:\n            value_getter = lambda option: d[option]\n        return [(option, value_getter(option)) for option in d.keys()]\n\n    def popitem(self):\n        \"\"\"Remove a section from the parser and return it as\n        a (section_name, section_proxy) tuple. If no section is present, raise\n        KeyError.\n\n        The section DEFAULT is never returned because it cannot be removed.\n        \"\"\"\n        for key in self.sections():\n            value = self[key]\n            del self[key]\n            return key, value\n        raise KeyError\n\n    def optionxform(self, optionstr):\n        return optionstr.lower()\n\n    def has_option(self, section, option):\n        \"\"\"Check for the existence of a given option in a given section.\n        If the specified `section' is None or an empty string, DEFAULT is\n        assumed. If the specified `section' does not exist, returns False.\"\"\"\n        if not section or section == self.default_section:\n            option = self.optionxform(option)\n            return option in self._defaults\n        elif section not in self._sections:\n            return False\n        else:\n            option = self.optionxform(option)\n            return (option in self._sections[section]\n                    or option in self._defaults)\n\n    def set(self, section, option, value=None):\n        \"\"\"Set an option.\"\"\"\n        if value:\n            value = self._interpolation.before_set(self, section, option,\n                                                   value)\n        if not section or section == self.default_section:\n            sectdict = self._defaults\n        else:\n            try:\n                sectdict = self._sections[section]\n            except KeyError:\n                raise NoSectionError(section)\n        sectdict[self.optionxform(option)] = value\n\n    def write(self, fp, space_around_delimiters=True):\n        \"\"\"Write an .ini-format representation of the configuration state.\n\n        If `space_around_delimiters' is True (the default), delimiters\n        between keys and values are surrounded by spaces.\n        \"\"\"\n        if space_around_delimiters:\n            d = \" {} \".format(self._delimiters[0])\n        else:\n            d = self._delimiters[0]\n        if self._defaults:\n            self._write_section(fp, self.default_section,\n                                    self._defaults.items(), d)\n        for section in self._sections:\n            self._write_section(fp, section,\n                                self._sections[section].items(), d)\n\n    def _write_section(self, fp, section_name, section_items, delimiter):\n        \"\"\"Write a single section to the specified `fp'.\"\"\"\n        fp.write(\"[{}]\\n\".format(section_name))\n        for key, value in section_items:\n            value = self._interpolation.before_write(self, section_name, key,\n                                                     value)\n            if value is not None or not self._allow_no_value:\n                value = delimiter + str(value).replace('\\n', '\\n\\t')\n            else:\n                value = \"\"\n            fp.write(\"{}{}\\n\".format(key, value))\n        fp.write(\"\\n\")\n\n    def remove_option(self, section, option):\n        \"\"\"Remove an option.\"\"\"\n        if not section or section == self.default_section:\n            sectdict = self._defaults\n        else:\n            try:\n                sectdict = self._sections[section]\n            except KeyError:\n                raise NoSectionError(section)\n        option = self.optionxform(option)\n        existed = option in sectdict\n        if existed:\n            del sectdict[option]\n        return existed\n\n    def remove_section(self, section):\n        \"\"\"Remove a file section.\"\"\"\n        existed = section in self._sections\n        if existed:\n            del self._sections[section]\n            del self._proxies[section]\n        return existed\n\n    def __getitem__(self, key):\n        if key != self.default_section and not self.has_section(key):\n            raise KeyError(key)\n        return self._proxies[key]\n\n    def __setitem__(self, key, value):\n        # To conform with the mapping protocol, overwrites existing values in\n        # the section.\n\n        # XXX this is not atomic if read_dict fails at any point. Then again,\n        # no update method in configparser is atomic in this implementation.\n        if key == self.default_section:\n            self._defaults.clear()\n        elif key in self._sections:\n            self._sections[key].clear()\n        self.read_dict({key: value})\n\n    def __delitem__(self, key):\n        if key == self.default_section:\n            raise ValueError(\"Cannot remove the default section.\")\n        if not self.has_section(key):\n            raise KeyError(key)\n        self.remove_section(key)\n\n    def __contains__(self, key):\n        return key == self.default_section or self.has_section(key)\n\n    def __len__(self):\n        return len(self._sections) + 1 # the default section\n\n    def __iter__(self):\n        # XXX does it break when underlying container state changed?\n        return itertools.chain((self.default_section,), self._sections.keys())\n\n    def _read(self, fp, fpname):\n        \"\"\"Parse a sectioned configuration file.\n\n        Each section in a configuration file contains a header, indicated by\n        a name in square brackets (`[]'), plus key/value options, indicated by\n        `name' and `value' delimited with a specific substring (`=' or `:' by\n        default).\n\n        Values can span multiple lines, as long as they are indented deeper\n        than the first line of the value. Depending on the parser's mode, blank\n        lines may be treated as parts of multiline values or ignored.\n\n        Configuration files may include comments, prefixed by specific\n        characters (`#' and `;' by default). Comments may appear on their own\n        in an otherwise empty line or may be entered in lines holding values or\n        section names.\n        \"\"\"\n        elements_added = set()\n        cursect = None                        # None, or a dictionary\n        sectname = None\n        optname = None\n        lineno = 0\n        indent_level = 0\n        e = None                              # None, or an exception\n        for lineno, line in enumerate(fp, start=1):\n            comment_start = sys.maxsize\n            # strip inline comments\n            inline_prefixes = {p: -1 for p in self._inline_comment_prefixes}\n            while comment_start == sys.maxsize and inline_prefixes:\n                next_prefixes = {}\n                for prefix, index in inline_prefixes.items():\n                    index = line.find(prefix, index+1)\n                    if index == -1:\n                        continue\n                    next_prefixes[prefix] = index\n                    if index == 0 or (index > 0 and line[index-1].isspace()):\n                        comment_start = min(comment_start, index)\n                inline_prefixes = next_prefixes\n            # strip full line comments\n            for prefix in self._comment_prefixes:\n                if line.strip().startswith(prefix):\n                    comment_start = 0\n                    break\n            if comment_start == sys.maxsize:\n                comment_start = None\n            value = line[:comment_start].strip()\n            if not value:\n                if self._empty_lines_in_values:\n                    # add empty line to the value, but only if there was no\n                    # comment on the line\n                    if (comment_start is None and\n                        cursect is not None and\n                        optname and\n                        cursect[optname] is not None):\n                        cursect[optname].append('') # newlines added at join\n                else:\n                    # empty line marks end of value\n                    indent_level = sys.maxsize\n                continue\n            # continuation line?\n            first_nonspace = self.NONSPACECRE.search(line)\n            cur_indent_level = first_nonspace.start() if first_nonspace else 0\n            if (cursect is not None and optname and\n                cur_indent_level > indent_level):\n                cursect[optname].append(value)\n            # a section header or option header?\n            else:\n                indent_level = cur_indent_level\n                # is it a section header?\n                mo = self.SECTCRE.match(value)\n                if mo:\n                    sectname = mo.group('header')\n                    if sectname in self._sections:\n                        if self._strict and sectname in elements_added:\n                            raise DuplicateSectionError(sectname, fpname,\n                                                        lineno)\n                        cursect = self._sections[sectname]\n                        elements_added.add(sectname)\n                    elif sectname == self.default_section:\n                        cursect = self._defaults\n                    else:\n                        cursect = self._dict()\n                        self._sections[sectname] = cursect\n                        self._proxies[sectname] = SectionProxy(self, sectname)\n                        elements_added.add(sectname)\n                    # So sections can't start with a continuation line\n                    optname = None\n                # no section header in the file?\n                elif cursect is None:\n                    raise MissingSectionHeaderError(fpname, lineno, line)\n                # an option line?\n                else:\n                    mo = self._optcre.match(value)\n                    if mo:\n                        optname, vi, optval = mo.group('option', 'vi', 'value')\n                        if not optname:\n                            e = self._handle_error(e, fpname, lineno, line)\n                        optname = self.optionxform(optname.rstrip())\n                        if (self._strict and\n                            (sectname, optname) in elements_added):\n                            raise DuplicateOptionError(sectname, optname,\n                                                       fpname, lineno)\n                        elements_added.add((sectname, optname))\n                        # This check is fine because the OPTCRE cannot\n                        # match if it would set optval to None\n                        if optval is not None:\n                            optval = optval.strip()\n                            cursect[optname] = [optval]\n                        else:\n                            # valueless option handling\n                            cursect[optname] = None\n                    else:\n                        # a non-fatal parsing error occurred. set up the\n                        # exception but keep going. the exception will be\n                        # raised at the end of the file and will contain a\n                        # list of all bogus lines\n                        e = self._handle_error(e, fpname, lineno, line)\n        # if any parsing errors occurred, raise an exception\n        if e:\n            raise e\n        self._join_multiline_values()\n\n    def _join_multiline_values(self):\n        defaults = self.default_section, self._defaults\n        all_sections = itertools.chain((defaults,),\n                                       self._sections.items())\n        for section, options in all_sections:\n            for name, val in options.items():\n                if isinstance(val, list):\n                    val = '\\n'.join(val).rstrip()\n                options[name] = self._interpolation.before_read(self,\n                                                                section,\n                                                                name, val)\n\n    def _handle_error(self, exc, fpname, lineno, line):\n        if not exc:\n            exc = ParsingError(fpname)\n        exc.append(lineno, repr(line))\n        return exc\n\n    def _unify_values(self, section, vars):\n        \"\"\"Create a sequence of lookups with 'vars' taking priority over\n        the 'section' which takes priority over the DEFAULTSECT.\n\n        \"\"\"\n        sectiondict = {}\n        try:\n            sectiondict = self._sections[section]\n        except KeyError:\n            if section != self.default_section:\n                raise NoSectionError(section)\n        # Update with the entry specific variables\n        vardict = {}\n        if vars:\n            for key, value in vars.items():\n                if value is not None:\n                    value = str(value)\n                vardict[self.optionxform(key)] = value\n        return _ChainMap(vardict, sectiondict, self._defaults)\n\n    def _convert_to_boolean(self, value):\n        \"\"\"Return a boolean value translating from other types if necessary.\n        \"\"\"\n        if value.lower() not in self.BOOLEAN_STATES:\n            raise ValueError('Not a boolean: %s' % value)\n        return self.BOOLEAN_STATES[value.lower()]\n\n    def _validate_value_types(self, *, section=\"\", option=\"\", value=\"\"):\n        \"\"\"Raises a TypeError for non-string values.\n\n        The only legal non-string value if we allow valueless\n        options is None, so we need to check if the value is a\n        string if:\n        - we do not allow valueless options, or\n        - we allow valueless options but the value is not None\n\n        For compatibility reasons this method is not used in classic set()\n        for RawConfigParsers. It is invoked in every case for mapping protocol\n        access and in ConfigParser.set().\n        \"\"\"\n        if not isinstance(section, str):\n            raise TypeError(\"section names must be strings\")\n        if not isinstance(option, str):\n            raise TypeError(\"option keys must be strings\")\n        if not self._allow_no_value or value:\n            if not isinstance(value, str):\n                raise TypeError(\"option values must be strings\")\n\n\nclass ConfigParser(RawConfigParser):\n    \"\"\"ConfigParser implementing interpolation.\"\"\"\n\n    _DEFAULT_INTERPOLATION = BasicInterpolation()\n\n    def set(self, section, option, value=None):\n        \"\"\"Set an option.  Extends RawConfigParser.set by validating type and\n        interpolation syntax on the value.\"\"\"\n        self._validate_value_types(option=option, value=value)\n        super().set(section, option, value)\n\n    def add_section(self, section):\n        \"\"\"Create a new section in the configuration.  Extends\n        RawConfigParser.add_section by validating if the section name is\n        a string.\"\"\"\n        self._validate_value_types(section=section)\n        super().add_section(section)\n\n\nclass SafeConfigParser(ConfigParser):\n    \"\"\"ConfigParser alias for backwards compatibility purposes.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        warnings.warn(\n            \"The SafeConfigParser class has been renamed to ConfigParser \"\n            \"in Python 3.2. This alias will be removed in future versions.\"\n            \" Use ConfigParser directly instead.\",\n            DeprecationWarning, stacklevel=2\n        )\n\n\nclass SectionProxy(MutableMapping):\n    \"\"\"A proxy for a single section from a parser.\"\"\"\n\n    def __init__(self, parser, name):\n        \"\"\"Creates a view on a section of the specified `name` in `parser`.\"\"\"\n        self._parser = parser\n        self._name = name\n\n    def __repr__(self):\n        return '<Section: {}>'.format(self._name)\n\n    def __getitem__(self, key):\n        if not self._parser.has_option(self._name, key):\n            raise KeyError(key)\n        return self._parser.get(self._name, key)\n\n    def __setitem__(self, key, value):\n        self._parser._validate_value_types(option=key, value=value)\n        return self._parser.set(self._name, key, value)\n\n    def __delitem__(self, key):\n        if not (self._parser.has_option(self._name, key) and\n                self._parser.remove_option(self._name, key)):\n            raise KeyError(key)\n\n    def __contains__(self, key):\n        return self._parser.has_option(self._name, key)\n\n    def __len__(self):\n        return len(self._options())\n\n    def __iter__(self):\n        return self._options().__iter__()\n\n    def _options(self):\n        if self._name != self._parser.default_section:\n            return self._parser.options(self._name)\n        else:\n            return self._parser.defaults()\n\n    def get(self, option, fallback=None, *, raw=False, vars=None):\n        return self._parser.get(self._name, option, raw=raw, vars=vars,\n                                fallback=fallback)\n\n    def getint(self, option, fallback=None, *, raw=False, vars=None):\n        return self._parser.getint(self._name, option, raw=raw, vars=vars,\n                                   fallback=fallback)\n\n    def getfloat(self, option, fallback=None, *, raw=False, vars=None):\n        return self._parser.getfloat(self._name, option, raw=raw, vars=vars,\n                                     fallback=fallback)\n\n    def getboolean(self, option, fallback=None, *, raw=False, vars=None):\n        return self._parser.getboolean(self._name, option, raw=raw, vars=vars,\n                                       fallback=fallback)\n\n    @property\n    def parser(self):\n        # The parser object of the proxy is read-only.\n        return self._parser\n\n    @property\n    def name(self):\n        # The name of the section on a proxy is read-only.\n        return self._name\n"], "weakref": [".py", "\"\"\"Weak reference support for Python.\n\nThis module is an implementation of PEP 205:\n\nhttp://www.python.org/dev/peps/pep-0205/\n\"\"\"\n\n# Naming convention: Variables named \"wr\" are weak reference objects;\n# they are called this instead of \"ref\" to avoid name collisions with\n# the module-global ref() function imported from _weakref.\n\nfrom _weakref import (\n     getweakrefcount,\n     getweakrefs,\n     ref,\n     proxy,\n     CallableProxyType,\n     ProxyType,\n     ReferenceType)\n\nfrom _weakrefset import WeakSet, _IterationGuard\n\nimport collections  # Import after _weakref to avoid circular import.\n\nProxyTypes = (ProxyType, CallableProxyType)\n\n__all__ = [\"ref\", \"proxy\", \"getweakrefcount\", \"getweakrefs\",\n           \"WeakKeyDictionary\", \"ReferenceType\", \"ProxyType\",\n           \"CallableProxyType\", \"ProxyTypes\", \"WeakValueDictionary\",\n           \"WeakSet\"]\n\n\nclass WeakValueDictionary(collections.MutableMapping):\n    \"\"\"Mapping class that references values weakly.\n\n    Entries in the dictionary will be discarded when no strong\n    reference to the value exists anymore\n    \"\"\"\n    # We inherit the constructor without worrying about the input\n    # dictionary; since it uses our .update() method, we get the right\n    # checks (if the other dictionary is a WeakValueDictionary,\n    # objects are unwrapped on the way out, and we always wrap on the\n    # way in).\n\n    def __init__(self, *args, **kw):\n        def remove(wr, selfref=ref(self)):\n            self = selfref()\n            if self is not None:\n                if self._iterating:\n                    self._pending_removals.append(wr.key)\n                else:\n                    del self.data[wr.key]\n        self._remove = remove\n        # A list of keys to be removed\n        self._pending_removals = []\n        self._iterating = set()\n        self.data = d = {}\n        self.update(*args, **kw)\n\n    def _commit_removals(self):\n        l = self._pending_removals\n        d = self.data\n        # We shouldn't encounter any KeyError, because this method should\n        # always be called *before* mutating the dict.\n        while l:\n            del d[l.pop()]\n\n    def __getitem__(self, key):\n        o = self.data[key]()\n        if o is None:\n            raise KeyError(key)\n        else:\n            return o\n\n    def __delitem__(self, key):\n        if self._pending_removals:\n            self._commit_removals()\n        del self.data[key]\n\n    def __len__(self):\n        return len(self.data) - len(self._pending_removals)\n\n    def __contains__(self, key):\n        try:\n            o = self.data[key]()\n        except KeyError:\n            return False\n        return o is not None\n\n    def __repr__(self):\n        return \"<WeakValueDictionary at %s>\" % id(self)\n\n    def __setitem__(self, key, value):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data[key] = KeyedRef(value, self._remove, key)\n\n    def copy(self):\n        new = WeakValueDictionary()\n        for key, wr in self.data.items():\n            o = wr()\n            if o is not None:\n                new[key] = o\n        return new\n\n    __copy__ = copy\n\n    def __deepcopy__(self, memo):\n        from copy import deepcopy\n        new = self.__class__()\n        for key, wr in self.data.items():\n            o = wr()\n            if o is not None:\n                new[deepcopy(key, memo)] = o\n        return new\n\n    def get(self, key, default=None):\n        try:\n            wr = self.data[key]\n        except KeyError:\n            return default\n        else:\n            o = wr()\n            if o is None:\n                # This should only happen\n                return default\n            else:\n                return o\n\n    def items(self):\n        with _IterationGuard(self):\n            for k, wr in self.data.items():\n                v = wr()\n                if v is not None:\n                    yield k, v\n\n    def keys(self):\n        with _IterationGuard(self):\n            for k, wr in self.data.items():\n                if wr() is not None:\n                    yield k\n\n    __iter__ = keys\n\n    def itervaluerefs(self):\n        \"\"\"Return an iterator that yields the weak references to the values.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the values around longer than needed.\n\n        \"\"\"\n        with _IterationGuard(self):\n            for wr in self.data.values():\n                yield wr\n\n    def values(self):\n        with _IterationGuard(self):\n            for wr in self.data.values():\n                obj = wr()\n                if obj is not None:\n                    yield obj\n\n    def popitem(self):\n        if self._pending_removals:\n            self._commit_removals()\n        while True:\n            key, wr = self.data.popitem()\n            o = wr()\n            if o is not None:\n                return key, o\n\n    def pop(self, key, *args):\n        if self._pending_removals:\n            self._commit_removals()\n        try:\n            o = self.data.pop(key)()\n        except KeyError:\n            if args:\n                return args[0]\n            raise\n        if o is None:\n            raise KeyError(key)\n        else:\n            return o\n\n    def setdefault(self, key, default=None):\n        try:\n            wr = self.data[key]\n        except KeyError:\n            if self._pending_removals:\n                self._commit_removals()\n            self.data[key] = KeyedRef(default, self._remove, key)\n            return default\n        else:\n            return wr()\n\n    def update(self, dict=None, **kwargs):\n        if self._pending_removals:\n            self._commit_removals()\n        d = self.data\n        if dict is not None:\n            if not hasattr(dict, \"items\"):\n                dict = type({})(dict)\n            for key, o in dict.items():\n                d[key] = KeyedRef(o, self._remove, key)\n        if len(kwargs):\n            self.update(kwargs)\n\n    def valuerefs(self):\n        \"\"\"Return a list of weak references to the values.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the values around longer than needed.\n\n        \"\"\"\n        return list(self.data.values())\n\n\nclass KeyedRef(ref):\n    \"\"\"Specialized reference that includes a key corresponding to the value.\n\n    This is used in the WeakValueDictionary to avoid having to create\n    a function object for each key stored in the mapping.  A shared\n    callback object can use the 'key' attribute of a KeyedRef instead\n    of getting a reference to the key from an enclosing scope.\n\n    \"\"\"\n\n    __slots__ = \"key\",\n\n    def __new__(type, ob, callback, key):\n        self = ref.__new__(type, ob, callback)\n        self.key = key\n        return self\n\n    def __init__(self, ob, callback, key):\n        super().__init__(ob, callback)\n\n\nclass WeakKeyDictionary(collections.MutableMapping):\n    \"\"\" Mapping class that references keys weakly.\n\n    Entries in the dictionary will be discarded when there is no\n    longer a strong reference to the key. This can be used to\n    associate additional data with an object owned by other parts of\n    an application without adding attributes to those objects. This\n    can be especially useful with objects that override attribute\n    accesses.\n    \"\"\"\n\n    def __init__(self, dict=None):\n        self.data = {}\n        def remove(k, selfref=ref(self)):\n            self = selfref()\n            if self is not None:\n                if self._iterating:\n                    self._pending_removals.append(k)\n                else:\n                    del self.data[k]\n        self._remove = remove\n        # A list of dead weakrefs (keys to be removed)\n        self._pending_removals = []\n        self._iterating = set()\n        if dict is not None:\n            self.update(dict)\n\n    def _commit_removals(self):\n        # NOTE: We don't need to call this method before mutating the dict,\n        # because a dead weakref never compares equal to a live weakref,\n        # even if they happened to refer to equal objects.\n        # However, it means keys may already have been removed.\n        l = self._pending_removals\n        d = self.data\n        while l:\n            try:\n                del d[l.pop()]\n            except KeyError:\n                pass\n\n    def __delitem__(self, key):\n        del self.data[ref(key)]\n\n    def __getitem__(self, key):\n        return self.data[ref(key)]\n\n    def __len__(self):\n        return len(self.data) - len(self._pending_removals)\n\n    def __repr__(self):\n        return \"<WeakKeyDictionary at %s>\" % id(self)\n\n    def __setitem__(self, key, value):\n        self.data[ref(key, self._remove)] = value\n\n    def copy(self):\n        new = WeakKeyDictionary()\n        for key, value in self.data.items():\n            o = key()\n            if o is not None:\n                new[o] = value\n        return new\n\n    __copy__ = copy\n\n    def __deepcopy__(self, memo):\n        from copy import deepcopy\n        new = self.__class__()\n        for key, value in self.data.items():\n            o = key()\n            if o is not None:\n                new[o] = deepcopy(value, memo)\n        return new\n\n    def get(self, key, default=None):\n        return self.data.get(ref(key),default)\n\n    def __contains__(self, key):\n        try:\n            wr = ref(key)\n        except TypeError:\n            return False\n        return wr in self.data\n\n    def items(self):\n        with _IterationGuard(self):\n            for wr, value in self.data.items():\n                key = wr()\n                if key is not None:\n                    yield key, value\n\n    def keys(self):\n        with _IterationGuard(self):\n            for wr in self.data:\n                obj = wr()\n                if obj is not None:\n                    yield obj\n\n    __iter__ = keys\n\n    def values(self):\n        with _IterationGuard(self):\n            for wr, value in self.data.items():\n                if wr() is not None:\n                    yield value\n\n    def keyrefs(self):\n        \"\"\"Return a list of weak references to the keys.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the keys around longer than needed.\n\n        \"\"\"\n        return list(self.data)\n\n    def popitem(self):\n        while True:\n            key, value = self.data.popitem()\n            o = key()\n            if o is not None:\n                return o, value\n\n    def pop(self, key, *args):\n        return self.data.pop(ref(key), *args)\n\n    def setdefault(self, key, default=None):\n        return self.data.setdefault(ref(key, self._remove),default)\n\n    def update(self, dict=None, **kwargs):\n        d = self.data\n        if dict is not None:\n            if not hasattr(dict, \"items\"):\n                dict = type({})(dict)\n            for key, value in dict.items():\n                d[ref(key, self._remove)] = value\n        if len(kwargs):\n            self.update(kwargs)\n"], "unittest.result": [".py", "\"\"\"Test result object\"\"\"\n\nimport io\nimport sys\nimport traceback\n\nfrom . import util\nfrom functools import wraps\n\n__unittest = True\n\ndef failfast(method):\n    @wraps(method)\n    def inner(self, *args, **kw):\n        if getattr(self, 'failfast', False):\n            self.stop()\n        return method(self, *args, **kw)\n    return inner\n\nSTDOUT_LINE = '\\nStdout:\\n%s'\nSTDERR_LINE = '\\nStderr:\\n%s'\n\n\nclass TestResult(object):\n    \"\"\"Holder for test result information.\n\n    Test results are automatically managed by the TestCase and TestSuite\n    classes, and do not need to be explicitly manipulated by writers of tests.\n\n    Each instance holds the total number of tests run, and collections of\n    failures and errors that occurred among those test runs. The collections\n    contain tuples of (testcase, exceptioninfo), where exceptioninfo is the\n    formatted traceback of the error that occurred.\n    \"\"\"\n    _previousTestClass = None\n    _testRunEntered = False\n    _moduleSetUpFailed = False\n    def __init__(self, stream=None, descriptions=None, verbosity=None):\n        self.failfast = False\n        self.failures = []\n        self.errors = []\n        self.testsRun = 0\n        self.skipped = []\n        self.expectedFailures = []\n        self.unexpectedSuccesses = []\n        self.shouldStop = False\n        self.buffer = False\n        self._stdout_buffer = None\n        self._stderr_buffer = None\n        self._original_stdout = sys.stdout\n        self._original_stderr = sys.stderr\n        self._mirrorOutput = False\n\n    def printErrors(self):\n        \"Called by TestRunner after test run\"\n        #fixme brython\n        pass\n\n    def startTest(self, test):\n        \"Called when the given test is about to be run\"\n        self.testsRun += 1\n        self._mirrorOutput = False\n        self._setupStdout()\n\n    def _setupStdout(self):\n        if self.buffer:\n            if self._stderr_buffer is None:\n                self._stderr_buffer = io.StringIO()\n                self._stdout_buffer = io.StringIO()\n            sys.stdout = self._stdout_buffer\n            sys.stderr = self._stderr_buffer\n\n    def startTestRun(self):\n        \"\"\"Called once before any tests are executed.\n\n        See startTest for a method called before each test.\n        \"\"\"\n\n    def stopTest(self, test):\n        \"\"\"Called when the given test has been run\"\"\"\n        self._restoreStdout()\n        self._mirrorOutput = False\n\n    def _restoreStdout(self):\n        if self.buffer:\n            if self._mirrorOutput:\n                output = sys.stdout.getvalue()\n                error = sys.stderr.getvalue()\n                if output:\n                    if not output.endswith('\\n'):\n                        output += '\\n'\n                    self._original_stdout.write(STDOUT_LINE % output)\n                if error:\n                    if not error.endswith('\\n'):\n                        error += '\\n'\n                    self._original_stderr.write(STDERR_LINE % error)\n\n            sys.stdout = self._original_stdout\n            sys.stderr = self._original_stderr\n            self._stdout_buffer.seek(0)\n            self._stdout_buffer.truncate()\n            self._stderr_buffer.seek(0)\n            self._stderr_buffer.truncate()\n\n    def stopTestRun(self):\n        \"\"\"Called once after all tests are executed.\n\n        See stopTest for a method called after each test.\n        \"\"\"\n\n    @failfast\n    def addError(self, test, err):\n        \"\"\"Called when an error has occurred. 'err' is a tuple of values as\n        returned by sys.exc_info().\n        \"\"\"\n        self.errors.append((test, self._exc_info_to_string(err, test)))\n        self._mirrorOutput = True\n\n    @failfast\n    def addFailure(self, test, err):\n        \"\"\"Called when an error has occurred. 'err' is a tuple of values as\n        returned by sys.exc_info().\"\"\"\n        self.failures.append((test, self._exc_info_to_string(err, test)))\n        self._mirrorOutput = True\n\n    def addSuccess(self, test):\n        \"Called when a test has completed successfully\"\n        pass\n\n    def addSkip(self, test, reason):\n        \"\"\"Called when a test is skipped.\"\"\"\n        self.skipped.append((test, reason))\n\n    def addExpectedFailure(self, test, err):\n        \"\"\"Called when an expected failure/error occured.\"\"\"\n        self.expectedFailures.append(\n            (test, self._exc_info_to_string(err, test)))\n\n    @failfast\n    def addUnexpectedSuccess(self, test):\n        \"\"\"Called when a test was expected to fail, but succeed.\"\"\"\n        self.unexpectedSuccesses.append(test)\n\n    def wasSuccessful(self):\n        \"Tells whether or not this result was a success\"\n        return len(self.failures) == len(self.errors) == 0\n\n    def stop(self):\n        \"Indicates that the tests should be aborted\"\n        self.shouldStop = True\n\n    def _exc_info_to_string(self, err, test):\n        \"\"\"Converts a sys.exc_info()-style tuple of values into a string.\"\"\"\n        exctype, value, tb = err\n        # Skip test runner traceback levels\n        while tb and self._is_relevant_tb_level(tb):\n            tb = tb.tb_next\n\n        if exctype is test.failureException:\n            # Skip assert*() traceback levels\n            length = self._count_relevant_tb_levels(tb)\n            msgLines = traceback.format_exception(exctype, value, tb, length)\n        else:\n            msgLines = traceback.format_exception(exctype, value, tb)\n\n        if self.buffer:\n            output = sys.stdout.getvalue()\n            error = sys.stderr.getvalue()\n            if output:\n                if not output.endswith('\\n'):\n                    output += '\\n'\n                msgLines.append(STDOUT_LINE % output)\n            if error:\n                if not error.endswith('\\n'):\n                    error += '\\n'\n                msgLines.append(STDERR_LINE % error)\n        return ''.join(msgLines)\n\n\n    def _is_relevant_tb_level(self, tb):\n        #fix me brython\n        #return '__unittest' in tb.tb_frame.f_globals\n        return True  #for now, lets just return False\n\n    def _count_relevant_tb_levels(self, tb):\n        length = 0\n        while tb and not self._is_relevant_tb_level(tb):\n            length += 1\n            tb = tb.tb_next\n        return length\n\n    def __repr__(self):\n        return (\"<%s run=%i errors=%i failures=%i>\" %\n               (util.strclass(self.__class__), self.testsRun, len(self.errors),\n                len(self.failures)))\n"], "xml.etree.ElementPath": [".py", "#\n# ElementTree\n# $Id: ElementPath.py 3375 2008-02-13 08:05:08Z fredrik $\n#\n# limited xpath support for element trees\n#\n# history:\n# 2003-05-23 fl   created\n# 2003-05-28 fl   added support for // etc\n# 2003-08-27 fl   fixed parsing of periods in element names\n# 2007-09-10 fl   new selection engine\n# 2007-09-12 fl   fixed parent selector\n# 2007-09-13 fl   added iterfind; changed findall to return a list\n# 2007-11-30 fl   added namespaces support\n# 2009-10-30 fl   added child element value filter\n#\n# Copyright (c) 2003-2009 by Fredrik Lundh.  All rights reserved.\n#\n# fredrik@pythonware.com\n# http://www.pythonware.com\n#\n# --------------------------------------------------------------------\n# The ElementTree toolkit is\n#\n# Copyright (c) 1999-2009 by Fredrik Lundh\n#\n# By obtaining, using, and/or copying this software and/or its\n# associated documentation, you agree that you have read, understood,\n# and will comply with the following terms and conditions:\n#\n# Permission to use, copy, modify, and distribute this software and\n# its associated documentation for any purpose and without fee is\n# hereby granted, provided that the above copyright notice appears in\n# all copies, and that both that copyright notice and this permission\n# notice appear in supporting documentation, and that the name of\n# Secret Labs AB or the author not be used in advertising or publicity\n# pertaining to distribution of the software without specific, written\n# prior permission.\n#\n# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD\n# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-\n# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR\n# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY\n# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,\n# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE\n# OF THIS SOFTWARE.\n# --------------------------------------------------------------------\n\n# Licensed to PSF under a Contributor Agreement.\n# See http://www.python.org/psf/license for licensing details.\n\n##\n# Implementation module for XPath support.  There's usually no reason\n# to import this module directly; the <b>ElementTree</b> does this for\n# you, if needed.\n##\n\nimport re\n\nxpath_tokenizer_re = re.compile(\n    \"(\"\n    \"'[^']*'|\\\"[^\\\"]*\\\"|\"\n    \"::|\"\n    \"//?|\"\n    \"\\.\\.|\"\n    \"\\(\\)|\"\n    \"[/.*:\\[\\]\\(\\)@=])|\"\n    \"((?:\\{[^}]+\\})?[^/\\[\\]\\(\\)@=\\s]+)|\"\n    \"\\s+\"\n    )\n\ndef xpath_tokenizer(pattern, namespaces=None):\n    for token in xpath_tokenizer_re.findall(pattern):\n        tag = token[1]\n        if tag and tag[0] != \"{\" and \":\" in tag:\n            try:\n                prefix, uri = tag.split(\":\", 1)\n                if not namespaces:\n                    raise KeyError\n                yield token[0], \"{%s}%s\" % (namespaces[prefix], uri)\n            except KeyError:\n                raise SyntaxError(\"prefix %r not found in prefix map\" % prefix)\n        else:\n            yield token\n\ndef get_parent_map(context):\n    parent_map = context.parent_map\n    if parent_map is None:\n        context.parent_map = parent_map = {}\n        for p in context.root.iter():\n            for e in p:\n                parent_map[e] = p\n    return parent_map\n\ndef prepare_child(next, token):\n    tag = token[1]\n    def select(context, result):\n        for elem in result:\n            for e in elem:\n                if e.tag == tag:\n                    yield e\n    return select\n\ndef prepare_star(next, token):\n    def select(context, result):\n        for elem in result:\n            for e in elem:\n                yield e\n    return select\n\ndef prepare_self(next, token):\n    def select(context, result):\n        for elem in result:\n            yield elem\n    return select\n\ndef prepare_descendant(next, token):\n    token = next()\n    if token[0] == \"*\":\n        tag = \"*\"\n    elif not token[0]:\n        tag = token[1]\n    else:\n        raise SyntaxError(\"invalid descendant\")\n    def select(context, result):\n        for elem in result:\n            for e in elem.iter(tag):\n                if e is not elem:\n                    yield e\n    return select\n\ndef prepare_parent(next, token):\n    def select(context, result):\n        # FIXME: raise error if .. is applied at toplevel?\n        parent_map = get_parent_map(context)\n        result_map = {}\n        for elem in result:\n            if elem in parent_map:\n                parent = parent_map[elem]\n                if parent not in result_map:\n                    result_map[parent] = None\n                    yield parent\n    return select\n\ndef prepare_predicate(next, token):\n    # FIXME: replace with real parser!!! refs:\n    # http://effbot.org/zone/simple-iterator-parser.htm\n    # http://javascript.crockford.com/tdop/tdop.html\n    signature = []\n    predicate = []\n    while 1:\n        token = next()\n        if token[0] == \"]\":\n            break\n        if token[0] and token[0][:1] in \"'\\\"\":\n            token = \"'\", token[0][1:-1]\n        signature.append(token[0] or \"-\")\n        predicate.append(token[1])\n    signature = \"\".join(signature)\n    # use signature to determine predicate type\n    if signature == \"@-\":\n        # [@attribute] predicate\n        key = predicate[1]\n        def select(context, result):\n            for elem in result:\n                if elem.get(key) is not None:\n                    yield elem\n        return select\n    if signature == \"@-='\":\n        # [@attribute='value']\n        key = predicate[1]\n        value = predicate[-1]\n        def select(context, result):\n            for elem in result:\n                if elem.get(key) == value:\n                    yield elem\n        return select\n    if signature == \"-\" and not re.match(\"\\d+$\", predicate[0]):\n        # [tag]\n        tag = predicate[0]\n        def select(context, result):\n            for elem in result:\n                if elem.find(tag) is not None:\n                    yield elem\n        return select\n    if signature == \"-='\" and not re.match(\"\\d+$\", predicate[0]):\n        # [tag='value']\n        tag = predicate[0]\n        value = predicate[-1]\n        def select(context, result):\n            for elem in result:\n                for e in elem.findall(tag):\n                    if \"\".join(e.itertext()) == value:\n                        yield elem\n                        break\n        return select\n    if signature == \"-\" or signature == \"-()\" or signature == \"-()-\":\n        # [index] or [last()] or [last()-index]\n        if signature == \"-\":\n            index = int(predicate[0]) - 1\n        else:\n            if predicate[0] != \"last\":\n                raise SyntaxError(\"unsupported function\")\n            if signature == \"-()-\":\n                try:\n                    index = int(predicate[2]) - 1\n                except ValueError:\n                    raise SyntaxError(\"unsupported expression\")\n            else:\n                index = -1\n        def select(context, result):\n            parent_map = get_parent_map(context)\n            for elem in result:\n                try:\n                    parent = parent_map[elem]\n                    # FIXME: what if the selector is \"*\" ?\n                    elems = list(parent.findall(elem.tag))\n                    if elems[index] is elem:\n                        yield elem\n                except (IndexError, KeyError):\n                    pass\n        return select\n    raise SyntaxError(\"invalid predicate\")\n\nops = {\n    \"\": prepare_child,\n    \"*\": prepare_star,\n    \".\": prepare_self,\n    \"..\": prepare_parent,\n    \"//\": prepare_descendant,\n    \"[\": prepare_predicate,\n    }\n\n_cache = {}\n\nclass _SelectorContext:\n    parent_map = None\n    def __init__(self, root):\n        self.root = root\n\n# --------------------------------------------------------------------\n\n##\n# Generate all matching objects.\n\ndef iterfind(elem, path, namespaces=None):\n    # compile selector pattern\n    if path[-1:] == \"/\":\n        path = path + \"*\" # implicit all (FIXME: keep this?)\n    try:\n        selector = _cache[path]\n    except KeyError:\n        if len(_cache) > 100:\n            _cache.clear()\n        if path[:1] == \"/\":\n            raise SyntaxError(\"cannot use absolute path on element\")\n        next = iter(xpath_tokenizer(path, namespaces)).__next__\n        token = next()\n        selector = []\n        while 1:\n            try:\n                selector.append(ops[token[0]](next, token))\n            except StopIteration:\n                raise SyntaxError(\"invalid path\")\n            try:\n                token = next()\n                if token[0] == \"/\":\n                    token = next()\n            except StopIteration:\n                break\n        _cache[path] = selector\n    # execute selector pattern\n    result = [elem]\n    context = _SelectorContext(elem)\n    for select in selector:\n        result = select(context, result)\n    return result\n\n##\n# Find first matching object.\n\ndef find(elem, path, namespaces=None):\n    try:\n        return next(iterfind(elem, path, namespaces))\n    except StopIteration:\n        return None\n\n##\n# Find all matching objects.\n\ndef findall(elem, path, namespaces=None):\n    return list(iterfind(elem, path, namespaces))\n\n##\n# Find text for first matching object.\n\ndef findtext(elem, path, default=None, namespaces=None):\n    try:\n        elem = next(iterfind(elem, path, namespaces))\n        return elem.text or \"\"\n    except StopIteration:\n        return default\n"], "_weakrefset": [".py", "# Access WeakSet through the weakref module.\n# This code is separated-out because it is needed\n# by abc.py to load everything else at startup.\n\nfrom _weakref import ref\n\n__all__ = ['WeakSet']\n\n\nclass _IterationGuard:\n    # This context manager registers itself in the current iterators of the\n    # weak container, such as to delay all removals until the context manager\n    # exits.\n    # This technique should be relatively thread-safe (since sets are).\n\n    def __init__(self, weakcontainer):\n        # Don't create cycles\n        self.weakcontainer = ref(weakcontainer)\n\n    def __enter__(self):\n        w = self.weakcontainer()\n        if w is not None:\n            w._iterating.add(self)\n        return self\n\n    def __exit__(self, e, t, b):\n        w = self.weakcontainer()\n        if w is not None:\n            s = w._iterating\n            s.remove(self)\n            if not s:\n                w._commit_removals()\n\n\nclass WeakSet:\n    def __init__(self, data=None):\n        self.data = set()\n        def _remove(item, selfref=ref(self)):\n            self = selfref()\n            if self is not None:\n                if self._iterating:\n                    self._pending_removals.append(item)\n                else:\n                    self.data.discard(item)\n        self._remove = _remove\n        # A list of keys to be removed\n        self._pending_removals = []\n        self._iterating = set()\n        if data is not None:\n            self.update(data)\n\n    def _commit_removals(self):\n        l = self._pending_removals\n        discard = self.data.discard\n        while l:\n            discard(l.pop())\n\n    def __iter__(self):\n        with _IterationGuard(self):\n            for itemref in self.data:\n                item = itemref()\n                if item is not None:\n                    yield item\n\n    def __len__(self):\n        return len(self.data) - len(self._pending_removals)\n\n    def __contains__(self, item):\n        try:\n            wr = ref(item)\n        except TypeError:\n            return False\n        return wr in self.data\n\n    def __reduce__(self):\n        return (self.__class__, (list(self),),\n                getattr(self, '__dict__', None))\n\n    def add(self, item):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.add(ref(item, self._remove))\n\n    def clear(self):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.clear()\n\n    def copy(self):\n        return self.__class__(self)\n\n    def pop(self):\n        if self._pending_removals:\n            self._commit_removals()\n        while True:\n            try:\n                itemref = self.data.pop()\n            except KeyError:\n                raise KeyError('pop from empty WeakSet')\n            item = itemref()\n            if item is not None:\n                return item\n\n    def remove(self, item):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.remove(ref(item))\n\n    def discard(self, item):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.discard(ref(item))\n\n    def update(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        for element in other:\n            self.add(element)\n\n    def __ior__(self, other):\n        self.update(other)\n        return self\n\n    def difference(self, other):\n        newset = self.copy()\n        newset.difference_update(other)\n        return newset\n    __sub__ = difference\n\n    def difference_update(self, other):\n        self.__isub__(other)\n    def __isub__(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        if self is other:\n            self.data.clear()\n        else:\n            self.data.difference_update(ref(item) for item in other)\n        return self\n\n    def intersection(self, other):\n        return self.__class__(item for item in other if item in self)\n    __and__ = intersection\n\n    def intersection_update(self, other):\n        self.__iand__(other)\n    def __iand__(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.intersection_update(ref(item) for item in other)\n        return self\n\n    def issubset(self, other):\n        return self.data.issubset(ref(item) for item in other)\n    __le__ = issubset\n\n    def __lt__(self, other):\n        return self.data < set(ref(item) for item in other)\n\n    def issuperset(self, other):\n        return self.data.issuperset(ref(item) for item in other)\n    __ge__ = issuperset\n\n    def __gt__(self, other):\n        return self.data > set(ref(item) for item in other)\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return self.data == set(ref(item) for item in other)\n\n    def symmetric_difference(self, other):\n        newset = self.copy()\n        newset.symmetric_difference_update(other)\n        return newset\n    __xor__ = symmetric_difference\n\n    def symmetric_difference_update(self, other):\n        self.__ixor__(other)\n    def __ixor__(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        if self is other:\n            self.data.clear()\n        else:\n            self.data.symmetric_difference_update(ref(item, self._remove) for item in other)\n        return self\n\n    def union(self, other):\n        return self.__class__(e for s in (self, other) for e in s)\n    __or__ = union\n\n    def isdisjoint(self, other):\n        return len(self.intersection(other)) == 0\n"], "_timer": [".js", "var $module = (function($B){\n\n    var _b_=$B.builtins\n    \n    function wrap(func){\n        // Transforms a function f into another function that prints a\n        // traceback in case of exception\n        return function(){\n            try{return func.apply(null,arguments)}\n            catch(err){\n                var exc = $B.exception(err)\n                var w = _b_.getattr($B.stderr,'write')\n                w(exc.info)\n                w('\\n'+exc.__name__)\n                if(exc.message){w(': '+exc.message)}\n                w('\\n')\n            }\n        }\n    }\n    \n    return {\n\n        __name__ : 'timer',\n    \n        clear_interval : function(int_id){window.clearInterval(int_id)},\n        \n        clear_timeout : function(timeout_id){window.clearTimeout(timeout_id)},\n    \n        set_interval : function(func,interval){\n            return _b_.int(window.setInterval(wrap(func),interval))\n        },\n        set_timeout : function(func,interval){\n            return _b_.int(window.setTimeout(wrap(func),interval))\n        },\n        request_animation_frame: function(func){\n            return _b_.int(window.requestAnimationFrame(func))\n        },\n        cancel_animation_frame: function(int_id){\n            window.cancelAnimationFrame(int_id)\n        }\n    }\n\n})(__BRYTHON__)\n"], "importlib._bootstrap": [".py", "\"\"\"Core implementation of import.\n\nThis module is NOT meant to be directly imported! It has been designed such\nthat it can be bootstrapped into Python as the implementation of import. As\nsuch it requires the injection of specific modules and attributes in order to\nwork. One should use importlib as the public-facing version of this module.\n\n\"\"\"\n#\n# IMPORTANT: Whenever making changes to this module, be sure to run\n# a top-level make in order to get the frozen version of the module\n# update. Not doing so, will result in the Makefile to fail for\n# all others who don't have a ./python around to freeze the module\n# in the early stages of compilation.\n#\n\n# See importlib._setup() for what is injected into the global namespace.\n\n# When editing this code be aware that code executed at import time CANNOT\n# reference any injected objects! This includes not only global code but also\n# anything specified at the class level.\n\n# XXX Make sure all public names have no single leading underscore and all\n#     others do.\n\n\n# Bootstrap-related code ######################################################\n\n_CASE_INSENSITIVE_PLATFORMS = 'win', 'cygwin', 'darwin'\n\n\ndef _make_relax_case():\n    if sys.platform.startswith(_CASE_INSENSITIVE_PLATFORMS):\n        def _relax_case():\n            \"\"\"True if filenames must be checked case-insensitively.\"\"\"\n            return b'PYTHONCASEOK' in _os.environ\n    else:\n        def _relax_case():\n            \"\"\"True if filenames must be checked case-insensitively.\"\"\"\n            return False\n    return _relax_case\n\n\n# TODO: Expose from marshal\ndef _w_long(x):\n    \"\"\"Convert a 32-bit integer to little-endian.\n\n    XXX Temporary until marshal's long functions are exposed.\n\n    \"\"\"\n    x = int(x)\n    int_bytes = []\n    int_bytes.append(x & 0xFF)\n    int_bytes.append((x >> 8) & 0xFF)\n    int_bytes.append((x >> 16) & 0xFF)\n    int_bytes.append((x >> 24) & 0xFF)\n    return bytearray(int_bytes)\n\n\n# TODO: Expose from marshal\ndef _r_long(int_bytes):\n    \"\"\"Convert 4 bytes in little-endian to an integer.\n\n    XXX Temporary until marshal's long function are exposed.\n\n    \"\"\"\n    x = int_bytes[0]\n    x |= int_bytes[1] << 8\n    x |= int_bytes[2] << 16\n    x |= int_bytes[3] << 24\n    return x\n\n\ndef _path_join(*path_parts):\n    \"\"\"Replacement for os.path.join().\"\"\"\n    new_parts = []\n    for part in path_parts:\n        if not part:\n            continue\n        new_parts.append(part)\n        if part[-1] not in path_separators:\n            new_parts.append(path_sep)\n    return ''.join(new_parts[:-1])  # Drop superfluous path separator.\n\n\ndef _path_split(path):\n    \"\"\"Replacement for os.path.split().\"\"\"\n    for x in reversed(path):\n        if x in path_separators:\n            sep = x\n            break\n    else:\n        sep = path_sep\n    front, _, tail = path.rpartition(sep)\n    return front, tail\n\n\ndef _path_is_mode_type(path, mode):\n    \"\"\"Test whether the path is the specified mode type.\"\"\"\n    try:\n        stat_info = _os.stat(path)\n    except OSError:\n        return False\n    return (stat_info.st_mode & 0o170000) == mode\n\n\n# XXX Could also expose Modules/getpath.c:isfile()\ndef _path_isfile(path):\n    \"\"\"Replacement for os.path.isfile.\"\"\"\n    return _path_is_mode_type(path, 0o100000)\n\n\n# XXX Could also expose Modules/getpath.c:isdir()\ndef _path_isdir(path):\n    \"\"\"Replacement for os.path.isdir.\"\"\"\n    if not path:\n        path = _os.getcwd()\n    return _path_is_mode_type(path, 0o040000)\n\n\ndef _write_atomic(path, data, mode=0o666):\n    \"\"\"Best-effort function to write data to a path atomically.\n    Be prepared to handle a FileExistsError if concurrent writing of the\n    temporary file is attempted.\"\"\"\n    # id() is used to generate a pseudo-random filename.\n    path_tmp = '{}.{}'.format(path, id(path))\n    fd = _os.open(path_tmp,\n                  _os.O_EXCL | _os.O_CREAT | _os.O_WRONLY, mode & 0o666)\n    try:\n        # We first write data to a temporary file, and then use os.replace() to\n        # perform an atomic rename.\n        with _io.FileIO(fd, 'wb') as file:\n            file.write(data)\n        _os.replace(path_tmp, path)\n    except OSError:\n        try:\n            _os.unlink(path_tmp)\n        except OSError:\n            pass\n        raise\n\n\ndef _wrap(new, old):\n    \"\"\"Simple substitute for functools.update_wrapper.\"\"\"\n    for replace in ['__module__', '__name__', '__qualname__', '__doc__']:\n        if hasattr(old, replace):\n            setattr(new, replace, getattr(old, replace))\n    new.__dict__.update(old.__dict__)\n\n\n_code_type = type(_wrap.__code__)\n\n\ndef new_module(name):\n    \"\"\"Create a new module.\n\n    The module is not entered into sys.modules.\n\n    \"\"\"\n    return type(_io)(name)\n\n\n# Module-level locking ########################################################\n\n# A dict mapping module names to weakrefs of _ModuleLock instances\n_module_locks = {}\n# A dict mapping thread ids to _ModuleLock instances\n_blocking_on = {}\n\n\nclass _DeadlockError(RuntimeError):\n    pass\n\n\nclass _ModuleLock:\n    \"\"\"A recursive lock implementation which is able to detect deadlocks\n    (e.g. thread 1 trying to take locks A then B, and thread 2 trying to\n    take locks B then A).\n    \"\"\"\n\n    def __init__(self, name):\n        self.lock = _thread.allocate_lock()\n        self.wakeup = _thread.allocate_lock()\n        self.name = name\n        self.owner = None\n        self.count = 0\n        self.waiters = 0\n\n    def has_deadlock(self):\n        # Deadlock avoidance for concurrent circular imports.\n        me = _thread.get_ident()\n        tid = self.owner\n        while True:\n            lock = _blocking_on.get(tid)\n            if lock is None:\n                return False\n            tid = lock.owner\n            if tid == me:\n                return True\n\n    def acquire(self):\n        \"\"\"\n        Acquire the module lock.  If a potential deadlock is detected,\n        a _DeadlockError is raised.\n        Otherwise, the lock is always acquired and True is returned.\n        \"\"\"\n        tid = _thread.get_ident()\n        _blocking_on[tid] = self\n        try:\n            while True:\n                with self.lock:\n                    if self.count == 0 or self.owner == tid:\n                        self.owner = tid\n                        self.count += 1\n                        return True\n                    if self.has_deadlock():\n                        raise _DeadlockError(\"deadlock detected by %r\" % self)\n                    if self.wakeup.acquire(False):\n                        self.waiters += 1\n                # Wait for a release() call\n                self.wakeup.acquire()\n                self.wakeup.release()\n        finally:\n            del _blocking_on[tid]\n\n    def release(self):\n        tid = _thread.get_ident()\n        with self.lock:\n            if self.owner != tid:\n                raise RuntimeError(\"cannot release un-acquired lock\")\n            assert self.count > 0\n            self.count -= 1\n            if self.count == 0:\n                self.owner = None\n                if self.waiters:\n                    self.waiters -= 1\n                    self.wakeup.release()\n\n    def __repr__(self):\n        return \"_ModuleLock(%r) at %d\" % (self.name, id(self))\n\n\nclass _DummyModuleLock:\n    \"\"\"A simple _ModuleLock equivalent for Python builds without\n    multi-threading support.\"\"\"\n\n    def __init__(self, name):\n        self.name = name\n        self.count = 0\n\n    def acquire(self):\n        self.count += 1\n        return True\n\n    def release(self):\n        if self.count == 0:\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        self.count -= 1\n\n    def __repr__(self):\n        return \"_DummyModuleLock(%r) at %d\" % (self.name, id(self))\n\n\n# The following two functions are for consumption by Python/import.c.\n\ndef _get_module_lock(name):\n    \"\"\"Get or create the module lock for a given module name.\n\n    Should only be called with the import lock taken.\"\"\"\n    lock = None\n    try:\n        lock = _module_locks[name]()\n    except KeyError:\n        pass\n    if lock is None:\n        if _thread is None:\n            lock = _DummyModuleLock(name)\n        else:\n            lock = _ModuleLock(name)\n        def cb(_):\n            del _module_locks[name]\n        _module_locks[name] = _weakref.ref(lock, cb)\n    return lock\n\ndef _lock_unlock_module(name):\n    \"\"\"Release the global import lock, and acquires then release the\n    module lock for a given module name.\n    This is used to ensure a module is completely initialized, in the\n    event it is being imported by another thread.\n\n    Should only be called with the import lock taken.\"\"\"\n    lock = _get_module_lock(name)\n    _imp.release_lock()\n    try:\n        lock.acquire()\n    except _DeadlockError:\n        # Concurrent circular import, we'll accept a partially initialized\n        # module object.\n        pass\n    else:\n        lock.release()\n\n# Frame stripping magic ###############################################\n\ndef _call_with_frames_removed(f, *args, **kwds):\n    \"\"\"remove_importlib_frames in import.c will always remove sequences\n    of importlib frames that end with a call to this function\n\n    Use it instead of a normal call in places where including the importlib\n    frames introduces unwanted noise into the traceback (e.g. when executing\n    module code)\n    \"\"\"\n    return f(*args, **kwds)\n\n\n# Finder/loader utility code ###############################################\n\n\"\"\"Magic word to reject .pyc files generated by other Python versions.\nIt should change for each incompatible change to the bytecode.\n\nThe value of CR and LF is incorporated so if you ever read or write\na .pyc file in text mode the magic number will be wrong; also, the\nApple MPW compiler swaps their values, botching string constants.\n\nThe magic numbers must be spaced apart at least 2 values, as the\n-U interpeter flag will cause MAGIC+1 being used. They have been\nodd numbers for some time now.\n\nThere were a variety of old schemes for setting the magic number.\nThe current working scheme is to increment the previous value by\n10.\n\nStarting with the adoption of PEP 3147 in Python 3.2, every bump in magic\nnumber also includes a new \"magic tag\", i.e. a human readable string used\nto represent the magic number in __pycache__ directories.  When you change\nthe magic number, you must also set a new unique magic tag.  Generally this\ncan be named after the Python major version of the magic number bump, but\nit can really be anything, as long as it's different than anything else\nthat's come before.  The tags are included in the following table, starting\nwith Python 3.2a0.\n\nKnown values:\n Python 1.5:   20121\n Python 1.5.1: 20121\n    Python 1.5.2: 20121\n    Python 1.6:   50428\n    Python 2.0:   50823\n    Python 2.0.1: 50823\n    Python 2.1:   60202\n    Python 2.1.1: 60202\n    Python 2.1.2: 60202\n    Python 2.2:   60717\n    Python 2.3a0: 62011\n    Python 2.3a0: 62021\n    Python 2.3a0: 62011 (!)\n    Python 2.4a0: 62041\n    Python 2.4a3: 62051\n    Python 2.4b1: 62061\n    Python 2.5a0: 62071\n    Python 2.5a0: 62081 (ast-branch)\n    Python 2.5a0: 62091 (with)\n    Python 2.5a0: 62092 (changed WITH_CLEANUP opcode)\n    Python 2.5b3: 62101 (fix wrong code: for x, in ...)\n    Python 2.5b3: 62111 (fix wrong code: x += yield)\n    Python 2.5c1: 62121 (fix wrong lnotab with for loops and\n                         storing constants that should have been removed)\n    Python 2.5c2: 62131 (fix wrong code: for x, in ... in listcomp/genexp)\n    Python 2.6a0: 62151 (peephole optimizations and STORE_MAP opcode)\n    Python 2.6a1: 62161 (WITH_CLEANUP optimization)\n    Python 3000:   3000\n                   3010 (removed UNARY_CONVERT)\n                   3020 (added BUILD_SET)\n                   3030 (added keyword-only parameters)\n                   3040 (added signature annotations)\n                   3050 (print becomes a function)\n                   3060 (PEP 3115 metaclass syntax)\n                   3061 (string literals become unicode)\n                   3071 (PEP 3109 raise changes)\n                   3081 (PEP 3137 make __file__ and __name__ unicode)\n                   3091 (kill str8 interning)\n                   3101 (merge from 2.6a0, see 62151)\n                   3103 (__file__ points to source file)\n    Python 3.0a4: 3111 (WITH_CLEANUP optimization).\n    Python 3.0a5: 3131 (lexical exception stacking, including POP_EXCEPT)\n    Python 3.1a0: 3141 (optimize list, set and dict comprehensions:\n            change LIST_APPEND and SET_ADD, add MAP_ADD)\n    Python 3.1a0: 3151 (optimize conditional branches:\n            introduce POP_JUMP_IF_FALSE and POP_JUMP_IF_TRUE)\n    Python 3.2a0: 3160 (add SETUP_WITH)\n                  tag: cpython-32\n    Python 3.2a1: 3170 (add DUP_TOP_TWO, remove DUP_TOPX and ROT_FOUR)\n                  tag: cpython-32\n    Python 3.2a2  3180 (add DELETE_DEREF)\n    Python 3.3a0  3190 __class__ super closure changed\n    Python 3.3a0  3200 (__qualname__ added)\n                     3210 (added size modulo 2**32 to the pyc header)\n    Python 3.3a1  3220 (changed PEP 380 implementation)\n    Python 3.3a4  3230 (revert changes to implicit __class__ closure)\n\nMAGIC must change whenever the bytecode emitted by the compiler may no\nlonger be understood by older implementations of the eval loop (usually\ndue to the addition of new opcodes).\n\n\"\"\"\n_RAW_MAGIC_NUMBER = 3230 | ord('\\r') << 16 | ord('\\n') << 24\n_MAGIC_BYTES = bytes(_RAW_MAGIC_NUMBER >> n & 0xff for n in range(0, 25, 8))\n\n_PYCACHE = '__pycache__'\n\nSOURCE_SUFFIXES = ['.py']  # _setup() adds .pyw as needed.\n\nDEBUG_BYTECODE_SUFFIXES = ['.pyc']\nOPTIMIZED_BYTECODE_SUFFIXES = ['.pyo']\n\ndef cache_from_source(path, debug_override=None):\n    \"\"\"Given the path to a .py file, return the path to its .pyc/.pyo file.\n\n    The .py file does not need to exist; this simply returns the path to the\n    .pyc/.pyo file calculated as if the .py file were imported.  The extension\n    will be .pyc unless sys.flags.optimize is non-zero, then it will be .pyo.\n\n    If debug_override is not None, then it must be a boolean and is used in\n    place of sys.flags.optimize.\n\n    If sys.implementation.cache_tag is None then NotImplementedError is raised.\n\n    \"\"\"\n    debug = not sys.flags.optimize if debug_override is None else debug_override\n    if debug:\n        suffixes = DEBUG_BYTECODE_SUFFIXES\n    else:\n        suffixes = OPTIMIZED_BYTECODE_SUFFIXES\n    head, tail = _path_split(path)\n    base_filename, sep, _ = tail.partition('.')\n    tag = sys.implementation.cache_tag\n    if tag is None:\n        raise NotImplementedError('sys.implementation.cache_tag is None')\n    filename = ''.join([base_filename, sep, tag, suffixes[0]])\n    return _path_join(head, _PYCACHE, filename)\n\n\ndef source_from_cache(path):\n    \"\"\"Given the path to a .pyc./.pyo file, return the path to its .py file.\n\n    The .pyc/.pyo file does not need to exist; this simply returns the path to\n    the .py file calculated to correspond to the .pyc/.pyo file.  If path does\n    not conform to PEP 3147 format, ValueError will be raised. If\n    sys.implementation.cache_tag is None then NotImplementedError is raised.\n\n    \"\"\"\n    if sys.implementation.cache_tag is None:\n        raise NotImplementedError('sys.implementation.cache_tag is None')\n    head, pycache_filename = _path_split(path)\n    head, pycache = _path_split(head)\n    if pycache != _PYCACHE:\n        raise ValueError('{} not bottom-level directory in '\n                         '{!r}'.format(_PYCACHE, path))\n    if pycache_filename.count('.') != 2:\n        raise ValueError('expected only 2 dots in '\n                         '{!r}'.format(pycache_filename))\n    base_filename = pycache_filename.partition('.')[0]\n    return _path_join(head, base_filename + SOURCE_SUFFIXES[0])\n\n\ndef _get_sourcefile(bytecode_path):\n    \"\"\"Convert a bytecode file path to a source path (if possible).\n\n    This function exists purely for backwards-compatibility for\n    PyImport_ExecCodeModuleWithFilenames() in the C API.\n\n    \"\"\"\n    if len(bytecode_path) == 0:\n        return None\n    rest, _, extension = bytecode_path.rpartition('.')\n    if not rest or extension.lower()[-3:-1] != 'py':\n        return bytecode_path\n    try:\n        source_path = source_from_cache(bytecode_path)\n    except (NotImplementedError, ValueError):\n        source_path = bytecode_path[:-1]\n    return source_path if _path_isfile(source_path) else bytecode_path\n\n\ndef _verbose_message(message, *args, verbosity=1):\n    \"\"\"Print the message to stderr if -v/PYTHONVERBOSE is turned on.\"\"\"\n    if sys.flags.verbose >= verbosity:\n        if not message.startswith(('#', 'import ')):\n            message = '# ' + message\n        print(message.format(*args), file=sys.stderr)\n\n\ndef set_package(fxn):\n    \"\"\"Set __package__ on the returned module.\"\"\"\n    def set_package_wrapper(*args, **kwargs):\n        module = fxn(*args, **kwargs)\n        if getattr(module, '__package__', None) is None:\n            module.__package__ = module.__name__\n            if not hasattr(module, '__path__'):\n                module.__package__ = module.__package__.rpartition('.')[0]\n        return module\n    _wrap(set_package_wrapper, fxn)\n    return set_package_wrapper\n\n\ndef set_loader(fxn):\n    \"\"\"Set __loader__ on the returned module.\"\"\"\n    def set_loader_wrapper(self, *args, **kwargs):\n        module = fxn(self, *args, **kwargs)\n        if not hasattr(module, '__loader__'):\n            module.__loader__ = self\n        return module\n    _wrap(set_loader_wrapper, fxn)\n    return set_loader_wrapper\n\n\ndef module_for_loader(fxn):\n    \"\"\"Decorator to handle selecting the proper module for loaders.\n\n    The decorated function is passed the module to use instead of the module\n    name. The module passed in to the function is either from sys.modules if\n    it already exists or is a new module. If the module is new, then __name__\n    is set the first argument to the method, __loader__ is set to self, and\n    __package__ is set accordingly (if self.is_package() is defined) will be set\n    before it is passed to the decorated function (if self.is_package() does\n    not work for the module it will be set post-load).\n\n    If an exception is raised and the decorator created the module it is\n    subsequently removed from sys.modules.\n\n    The decorator assumes that the decorated function takes the module name as\n    the second argument.\n\n    \"\"\"\n    def module_for_loader_wrapper(self, fullname, *args, **kwargs):\n        module = sys.modules.get(fullname)\n        is_reload = module is not None\n        if not is_reload:\n            # This must be done before open() is called as the 'io' module\n            # implicitly imports 'locale' and would otherwise trigger an\n            # infinite loop.\n            module = new_module(fullname)\n            # This must be done before putting the module in sys.modules\n            # (otherwise an optimization shortcut in import.c becomes wrong)\n            module.__initializing__ = True\n            sys.modules[fullname] = module\n            module.__loader__ = self\n            try:\n                is_package = self.is_package(fullname)\n            except (ImportError, AttributeError):\n                pass\n            else:\n                if is_package:\n                    module.__package__ = fullname\n                else:\n                    module.__package__ = fullname.rpartition('.')[0]\n        else:\n            module.__initializing__ = True\n        try:\n            # If __package__ was not set above, __import__() will do it later.\n            return fxn(self, module, *args, **kwargs)\n        except:\n            if not is_reload:\n                del sys.modules[fullname]\n            raise\n        finally:\n            module.__initializing__ = False\n    _wrap(module_for_loader_wrapper, fxn)\n    return module_for_loader_wrapper\n\n\ndef _check_name(method):\n    \"\"\"Decorator to verify that the module being requested matches the one the\n    loader can handle.\n\n    The first argument (self) must define _name which the second argument is\n    compared against. If the comparison fails then ImportError is raised.\n\n    \"\"\"\n    def _check_name_wrapper(self, name=None, *args, **kwargs):\n        if name is None:\n            name = self.name\n        elif self.name != name:\n            raise ImportError(\"loader cannot handle %s\" % name, name=name)\n        return method(self, name, *args, **kwargs)\n    _wrap(_check_name_wrapper, method)\n    return _check_name_wrapper\n\n\ndef _requires_builtin(fxn):\n    \"\"\"Decorator to verify the named module is built-in.\"\"\"\n    def _requires_builtin_wrapper(self, fullname):\n        if fullname not in sys.builtin_module_names:\n            raise ImportError(\"{} is not a built-in module\".format(fullname),\n                              name=fullname)\n        return fxn(self, fullname)\n    _wrap(_requires_builtin_wrapper, fxn)\n    return _requires_builtin_wrapper\n\n\ndef _requires_frozen(fxn):\n    \"\"\"Decorator to verify the named module is frozen.\"\"\"\n    def _requires_frozen_wrapper(self, fullname):\n        if not _imp.is_frozen(fullname):\n            raise ImportError(\"{} is not a frozen module\".format(fullname),\n                              name=fullname)\n        return fxn(self, fullname)\n    _wrap(_requires_frozen_wrapper, fxn)\n    return _requires_frozen_wrapper\n\n\ndef _find_module_shim(self, fullname):\n    \"\"\"Try to find a loader for the specified module by delegating to\n    self.find_loader().\"\"\"\n    # Call find_loader(). If it returns a string (indicating this\n    # is a namespace package portion), generate a warning and\n    # return None.\n    loader, portions = self.find_loader(fullname)\n    if loader is None and len(portions):\n        msg = \"Not importing directory {}: missing __init__\"\n        _warnings.warn(msg.format(portions[0]), ImportWarning)\n    return loader\n\n\n\n\n# Loaders #####################################################################\n\nclass BuiltinImporter:\n\n    \"\"\"Meta path import for built-in modules.\n\n    All methods are either class or static methods to avoid the need to\n    instantiate the class.\n\n    \"\"\"\n\n    @classmethod\n    def module_repr(cls, module):\n        return \"<module '{}' (built-in)>\".format(module.__name__)\n\n    @classmethod\n    def find_module(cls, fullname, path=None):\n        \"\"\"Find the built-in module.\n\n        If 'path' is ever specified then the search is considered a failure.\n\n        \"\"\"\n        if path is not None:\n            return None\n        return cls if _imp.is_builtin(fullname) else None\n\n    @classmethod\n    @set_package\n    @set_loader\n    @_requires_builtin\n    def load_module(cls, fullname):\n        \"\"\"Load a built-in module.\"\"\"\n        is_reload = fullname in sys.modules\n        try:\n            return _call_with_frames_removed(_imp.init_builtin, fullname)\n        except:\n            if not is_reload and fullname in sys.modules:\n                del sys.modules[fullname]\n            raise\n\n    @classmethod\n    @_requires_builtin\n    def get_code(cls, fullname):\n        \"\"\"Return None as built-in modules do not have code objects.\"\"\"\n        return None\n\n    @classmethod\n    @_requires_builtin\n    def get_source(cls, fullname):\n        \"\"\"Return None as built-in modules do not have source code.\"\"\"\n        return None\n\n    @classmethod\n    @_requires_builtin\n    def is_package(cls, fullname):\n        \"\"\"Return False as built-in modules are never packages.\"\"\"\n        return False\n\n\nclass FrozenImporter:\n\n    \"\"\"Meta path import for frozen modules.\n\n    All methods are either class or static methods to avoid the need to\n    instantiate the class.\n\n    \"\"\"\n\n    @classmethod\n    def module_repr(cls, m):\n        return \"<module '{}' (frozen)>\".format(m.__name__)\n\n    @classmethod\n    def find_module(cls, fullname, path=None):\n        \"\"\"Find a frozen module.\"\"\"\n        return cls if _imp.is_frozen(fullname) else None\n\n    @classmethod\n    @set_package\n    @set_loader\n    @_requires_frozen\n    def load_module(cls, fullname):\n        \"\"\"Load a frozen module.\"\"\"\n        is_reload = fullname in sys.modules\n        try:\n            m = _call_with_frames_removed(_imp.init_frozen, fullname)\n            # Let our own module_repr() method produce a suitable repr.\n            del m.__file__\n            return m\n        except:\n            if not is_reload and fullname in sys.modules:\n                del sys.modules[fullname]\n            raise\n\n    @classmethod\n    @_requires_frozen\n    def get_code(cls, fullname):\n        \"\"\"Return the code object for the frozen module.\"\"\"\n        return _imp.get_frozen_object(fullname)\n\n    @classmethod\n    @_requires_frozen\n    def get_source(cls, fullname):\n        \"\"\"Return None as frozen modules do not have source code.\"\"\"\n        return None\n\n    @classmethod\n    @_requires_frozen\n    def is_package(cls, fullname):\n        \"\"\"Return True if the frozen module is a package.\"\"\"\n        return _imp.is_frozen_package(fullname)\n\n\nclass WindowsRegistryFinder:\n\n    \"\"\"Meta path finder for modules declared in the Windows registry.\n    \"\"\"\n\n    REGISTRY_KEY = (\n        \"Software\\\\Python\\\\PythonCore\\\\{sys_version}\"\n        \"\\\\Modules\\\\{fullname}\")\n    REGISTRY_KEY_DEBUG = (\n        \"Software\\\\Python\\\\PythonCore\\\\{sys_version}\"\n        \"\\\\Modules\\\\{fullname}\\\\Debug\")\n    DEBUG_BUILD = False  # Changed in _setup()\n\n    @classmethod\n    def _open_registry(cls, key):\n        try:\n            return _winreg.OpenKey(_winreg.HKEY_CURRENT_USER, key)\n        except WindowsError:\n            return _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE, key)\n\n    @classmethod\n    def _search_registry(cls, fullname):\n        if cls.DEBUG_BUILD:\n            registry_key = cls.REGISTRY_KEY_DEBUG\n        else:\n            registry_key = cls.REGISTRY_KEY\n        key = registry_key.format(fullname=fullname,\n                                  sys_version=sys.version[:3])\n        try:\n            with cls._open_registry(key) as hkey:\n                filepath = _winreg.QueryValue(hkey, \"\")\n        except WindowsError:\n            return None\n        return filepath\n\n    @classmethod\n    def find_module(cls, fullname, path=None):\n        \"\"\"Find module named in the registry.\"\"\"\n        filepath = cls._search_registry(fullname)\n        if filepath is None:\n            return None\n        try:\n            _os.stat(filepath)\n        except OSError:\n            return None\n        for loader, suffixes in _get_supported_file_loaders():\n            if filepath.endswith(tuple(suffixes)):\n                return loader(fullname, filepath)\n\n\nclass _LoaderBasics:\n\n    \"\"\"Base class of common code needed by both SourceLoader and\n    SourcelessFileLoader.\"\"\"\n\n    def is_package(self, fullname):\n        \"\"\"Concrete implementation of InspectLoader.is_package by checking if\n        the path returned by get_filename has a filename of '__init__.py'.\"\"\"\n        filename = _path_split(self.get_filename(fullname))[1]\n        filename_base = filename.rsplit('.', 1)[0]\n        tail_name = fullname.rpartition('.')[2]\n        return filename_base == '__init__' and tail_name != '__init__'\n\n    def _bytes_from_bytecode(self, fullname, data, bytecode_path, source_stats):\n        \"\"\"Return the marshalled bytes from bytecode, verifying the magic\n        number, timestamp and source size along the way.\n\n        If source_stats is None then skip the timestamp check.\n\n        \"\"\"\n        magic = data[:4]\n        raw_timestamp = data[4:8]\n        raw_size = data[8:12]\n        if magic != _MAGIC_BYTES:\n            msg = 'bad magic number in {!r}: {!r}'.format(fullname, magic)\n            _verbose_message(msg)\n            raise ImportError(msg, name=fullname, path=bytecode_path)\n        elif len(raw_timestamp) != 4:\n            message = 'bad timestamp in {}'.format(fullname)\n            _verbose_message(message)\n            raise EOFError(message)\n        elif len(raw_size) != 4:\n            message = 'bad size in {}'.format(fullname)\n            _verbose_message(message)\n            raise EOFError(message)\n        if source_stats is not None:\n            try:\n                source_mtime = int(source_stats['mtime'])\n            except KeyError:\n                pass\n            else:\n                if _r_long(raw_timestamp) != source_mtime:\n                    message = 'bytecode is stale for {}'.format(fullname)\n                    _verbose_message(message)\n                    raise ImportError(message, name=fullname,\n                                      path=bytecode_path)\n            try:\n                source_size = source_stats['size'] & 0xFFFFFFFF\n            except KeyError:\n                pass\n            else:\n                if _r_long(raw_size) != source_size:\n                    raise ImportError(\n                        \"bytecode is stale for {}\".format(fullname),\n                        name=fullname, path=bytecode_path)\n        # Can't return the code object as errors from marshal loading need to\n        # propagate even when source is available.\n        return data[12:]\n\n    @module_for_loader\n    def _load_module(self, module, *, sourceless=False):\n        \"\"\"Helper for load_module able to handle either source or sourceless\n        loading.\"\"\"\n        name = module.__name__\n        code_object = self.get_code(name)\n        module.__file__ = self.get_filename(name)\n        if not sourceless:\n            try:\n                module.__cached__ = cache_from_source(module.__file__)\n            except NotImplementedError:\n                module.__cached__ = module.__file__\n        else:\n            module.__cached__ = module.__file__\n        module.__package__ = name\n        if self.is_package(name):\n            module.__path__ = [_path_split(module.__file__)[0]]\n        else:\n            module.__package__ = module.__package__.rpartition('.')[0]\n        module.__loader__ = self\n        _call_with_frames_removed(exec, code_object, module.__dict__)\n        return module\n\n\nclass SourceLoader(_LoaderBasics):\n\n    def path_mtime(self, path):\n        \"\"\"Optional method that returns the modification time (an int) for the\n        specified path, where path is a str.\n        \"\"\"\n        raise NotImplementedError\n\n    def path_stats(self, path):\n        \"\"\"Optional method returning a metadata dict for the specified path\n        to by the path (str).\n        Possible keys:\n        - 'mtime' (mandatory) is the numeric timestamp of last source\n          code modification;\n        - 'size' (optional) is the size in bytes of the source code.\n\n        Implementing this method allows the loader to read bytecode files.\n        \"\"\"\n        return {'mtime': self.path_mtime(path)}\n\n    def _cache_bytecode(self, source_path, cache_path, data):\n        \"\"\"Optional method which writes data (bytes) to a file path (a str).\n\n        Implementing this method allows for the writing of bytecode files.\n\n        The source path is needed in order to correctly transfer permissions\n        \"\"\"\n        # For backwards compatibility, we delegate to set_data()\n        return self.set_data(cache_path, data)\n\n    def set_data(self, path, data):\n        \"\"\"Optional method which writes data (bytes) to a file path (a str).\n\n        Implementing this method allows for the writing of bytecode files.\n\n        \"\"\"\n        raise NotImplementedError\n\n\n    def get_source(self, fullname):\n        \"\"\"Concrete implementation of InspectLoader.get_source.\"\"\"\n        import tokenize\n        path = self.get_filename(fullname)\n        try:\n            source_bytes = self.get_data(path)\n        except IOError as exc:\n            raise ImportError(\"source not available through get_data()\",\n                              name=fullname) from exc\n        readsource = _io.BytesIO(source_bytes).readline\n        try:\n            encoding = tokenize.detect_encoding(readsource)\n        except SyntaxError as exc:\n            raise ImportError(\"Failed to detect encoding\",\n                              name=fullname) from exc\n        newline_decoder = _io.IncrementalNewlineDecoder(None, True)\n        try:\n            return newline_decoder.decode(source_bytes.decode(encoding[0]))\n        except UnicodeDecodeError as exc:\n            raise ImportError(\"Failed to decode source file\",\n                              name=fullname) from exc\n\n    def get_code(self, fullname):\n        \"\"\"Concrete implementation of InspectLoader.get_code.\n\n        Reading of bytecode requires path_stats to be implemented. To write\n        bytecode, set_data must also be implemented.\n\n        \"\"\"\n        source_path = self.get_filename(fullname)\n        source_mtime = None\n        try:\n            bytecode_path = cache_from_source(source_path)\n        except NotImplementedError:\n            bytecode_path = None\n        else:\n            try:\n                st = self.path_stats(source_path)\n            except NotImplementedError:\n                pass\n            else:\n                source_mtime = int(st['mtime'])\n                try:\n                    data = self.get_data(bytecode_path)\n                except IOError:\n                    pass\n                else:\n                    try:\n                        bytes_data = self._bytes_from_bytecode(fullname, data,\n                                                               bytecode_path,\n                                                               st)\n                    except (ImportError, EOFError):\n                        pass\n                    else:\n                        _verbose_message('{} matches {}', bytecode_path,\n                                        source_path)\n                        found = marshal.loads(bytes_data)\n                        if isinstance(found, _code_type):\n                            _imp._fix_co_filename(found, source_path)\n                            _verbose_message('code object from {}',\n                                            bytecode_path)\n                            return found\n                        else:\n                            msg = \"Non-code object in {}\"\n                            raise ImportError(msg.format(bytecode_path),\n                                              name=fullname, path=bytecode_path)\n        source_bytes = self.get_data(source_path)\n        code_object = _call_with_frames_removed(compile,\n                          source_bytes, source_path, 'exec',\n                          dont_inherit=True)\n        _verbose_message('code object from {}', source_path)\n        if (not sys.dont_write_bytecode and bytecode_path is not None and\n            source_mtime is not None):\n            data = bytearray(_MAGIC_BYTES)\n            data.extend(_w_long(source_mtime))\n            data.extend(_w_long(len(source_bytes)))\n            data.extend(marshal.dumps(code_object))\n            try:\n                self._cache_bytecode(source_path, bytecode_path, data)\n                _verbose_message('wrote {!r}', bytecode_path)\n            except NotImplementedError:\n                pass\n        return code_object\n\n    def load_module(self, fullname):\n        \"\"\"Concrete implementation of Loader.load_module.\n\n        Requires ExecutionLoader.get_filename and ResourceLoader.get_data to be\n        implemented to load source code. Use of bytecode is dictated by whether\n        get_code uses/writes bytecode.\n\n        \"\"\"\n        return self._load_module(fullname)\n\n\nclass FileLoader:\n\n    \"\"\"Base file loader class which implements the loader protocol methods that\n    require file system usage.\"\"\"\n\n    def __init__(self, fullname, path):\n        \"\"\"Cache the module name and the path to the file found by the\n        finder.\"\"\"\n        self.name = fullname\n        self.path = path\n\n    @_check_name\n    def load_module(self, fullname):\n        \"\"\"Load a module from a file.\"\"\"\n        # Issue #14857: Avoid the zero-argument form so the implementation\n        # of that form can be updated without breaking the frozen module\n        return super(FileLoader, self).load_module(fullname)\n\n    @_check_name\n    def get_filename(self, fullname):\n        \"\"\"Return the path to the source file as found by the finder.\"\"\"\n        return self.path\n\n    def get_data(self, path):\n        \"\"\"Return the data from path as raw bytes.\"\"\"\n        with _io.FileIO(path, 'r') as file:\n            return file.read()\n\n\nclass SourceFileLoader(FileLoader, SourceLoader):\n\n    \"\"\"Concrete implementation of SourceLoader using the file system.\"\"\"\n\n    def path_stats(self, path):\n        \"\"\"Return the metadata for the path.\"\"\"\n        st = _os.stat(path)\n        return {'mtime': st.st_mtime, 'size': st.st_size}\n\n    def _cache_bytecode(self, source_path, bytecode_path, data):\n        # Adapt between the two APIs\n        try:\n            mode = _os.stat(source_path).st_mode\n        except OSError:\n            mode = 0o666\n        # We always ensure write access so we can update cached files\n        # later even when the source files are read-only on Windows (#6074)\n        mode |= 0o200\n        return self.set_data(bytecode_path, data, _mode=mode)\n\n    def set_data(self, path, data, *, _mode=0o666):\n        \"\"\"Write bytes data to a file.\"\"\"\n        parent, filename = _path_split(path)\n        path_parts = []\n        # Figure out what directories are missing.\n        while parent and not _path_isdir(parent):\n            parent, part = _path_split(parent)\n            path_parts.append(part)\n        # Create needed directories.\n        for part in reversed(path_parts):\n            parent = _path_join(parent, part)\n            try:\n                _os.mkdir(parent)\n            except FileExistsError:\n                # Probably another Python process already created the dir.\n                continue\n            except OSError as exc:\n                # Could be a permission error, read-only filesystem: just forget\n                # about writing the data.\n                _verbose_message('could not create {!r}: {!r}', parent, exc)\n                return\n        try:\n            _write_atomic(path, data, _mode)\n            _verbose_message('created {!r}', path)\n        except OSError as exc:\n            # Same as above: just don't write the bytecode.\n            _verbose_message('could not create {!r}: {!r}', path, exc)\n\n\nclass SourcelessFileLoader(FileLoader, _LoaderBasics):\n\n    \"\"\"Loader which handles sourceless file imports.\"\"\"\n\n    def load_module(self, fullname):\n        return self._load_module(fullname, sourceless=True)\n\n    def get_code(self, fullname):\n        path = self.get_filename(fullname)\n        data = self.get_data(path)\n        bytes_data = self._bytes_from_bytecode(fullname, data, path, None)\n        found = marshal.loads(bytes_data)\n        if isinstance(found, _code_type):\n            _verbose_message('code object from {!r}', path)\n            return found\n        else:\n            raise ImportError(\"Non-code object in {}\".format(path),\n                              name=fullname, path=path)\n\n    def get_source(self, fullname):\n        \"\"\"Return None as there is no source code.\"\"\"\n        return None\n\n\n# Filled in by _setup().\nEXTENSION_SUFFIXES = []\n\n\nclass ExtensionFileLoader:\n\n    \"\"\"Loader for extension modules.\n\n    The constructor is designed to work with FileFinder.\n\n    \"\"\"\n\n    def __init__(self, name, path):\n        self.name = name\n        self.path = path\n\n    @_check_name\n    @set_package\n    @set_loader\n    def load_module(self, fullname):\n        \"\"\"Load an extension module.\"\"\"\n        is_reload = fullname in sys.modules\n        try:\n            module = _call_with_frames_removed(_imp.load_dynamic,\n                                               fullname, self.path)\n            _verbose_message('extension module loaded from {!r}', self.path)\n            if self.is_package(fullname) and not hasattr(module, '__path__'):\n                module.__path__ = [_path_split(self.path)[0]]\n            return module\n        except:\n            if not is_reload and fullname in sys.modules:\n                del sys.modules[fullname]\n            raise\n\n    def is_package(self, fullname):\n        \"\"\"Return True if the extension module is a package.\"\"\"\n        file_name = _path_split(self.path)[1]\n        return any(file_name == '__init__' + suffix\n                   for suffix in EXTENSION_SUFFIXES)\n\n    def get_code(self, fullname):\n        \"\"\"Return None as an extension module cannot create a code object.\"\"\"\n        return None\n\n    def get_source(self, fullname):\n        \"\"\"Return None as extension modules have no source code.\"\"\"\n        return None\n\n\nclass _NamespacePath:\n    \"\"\"Represents a namespace package's path.  It uses the module name\n    to find its parent module, and from there it looks up the parent's\n    __path__.  When this changes, the module's own path is recomputed,\n    using path_finder.  For top-level modules, the parent module's path\n    is sys.path.\"\"\"\n\n    def __init__(self, name, path, path_finder):\n        self._name = name\n        self._path = path\n        self._last_parent_path = tuple(self._get_parent_path())\n        self._path_finder = path_finder\n\n    def _find_parent_path_names(self):\n        \"\"\"Returns a tuple of (parent-module-name, parent-path-attr-name)\"\"\"\n        parent, dot, me = self._name.rpartition('.')\n        if dot == '':\n            # This is a top-level module. sys.path contains the parent path.\n            return 'sys', 'path'\n        # Not a top-level module. parent-module.__path__ contains the\n        #  parent path.\n        return parent, '__path__'\n\n    def _get_parent_path(self):\n        parent_module_name, path_attr_name = self._find_parent_path_names()\n        return getattr(sys.modules[parent_module_name], path_attr_name)\n\n    def _recalculate(self):\n        # If the parent's path has changed, recalculate _path\n        parent_path = tuple(self._get_parent_path()) # Make a copy\n        if parent_path != self._last_parent_path:\n            loader, new_path = self._path_finder(self._name, parent_path)\n            # Note that no changes are made if a loader is returned, but we\n            #  do remember the new parent path\n            if loader is None:\n                self._path = new_path\n            self._last_parent_path = parent_path     # Save the copy\n        return self._path\n\n    def __iter__(self):\n        return iter(self._recalculate())\n\n    def __len__(self):\n        return len(self._recalculate())\n\n    def __repr__(self):\n        return \"_NamespacePath({!r})\".format(self._path)\n\n    def __contains__(self, item):\n        return item in self._recalculate()\n\n    def append(self, item):\n        self._path.append(item)\n\n\nclass NamespaceLoader:\n    def __init__(self, name, path, path_finder):\n        self._path = _NamespacePath(name, path, path_finder)\n\n    @classmethod\n    def module_repr(cls, module):\n        return \"<module '{}' (namespace)>\".format(module.__name__)\n\n    @module_for_loader\n    def load_module(self, module):\n        \"\"\"Load a namespace module.\"\"\"\n        _verbose_message('namespace module loaded with path {!r}', self._path)\n        module.__path__ = self._path\n        return module\n\n\n# Finders #####################################################################\n\nclass PathFinder:\n\n    \"\"\"Meta path finder for sys.path and package __path__ attributes.\"\"\"\n\n    @classmethod\n    def invalidate_caches(cls):\n        \"\"\"Call the invalidate_caches() method on all path entry finders\n        stored in sys.path_importer_caches (where implemented).\"\"\"\n        for finder in sys.path_importer_cache.values():\n            if hasattr(finder, 'invalidate_caches'):\n                finder.invalidate_caches()\n\n    @classmethod\n    def _path_hooks(cls, path):\n        \"\"\"Search sequence of hooks for a finder for 'path'.\n\n        If 'hooks' is false then use sys.path_hooks.\n\n        \"\"\"\n        if not sys.path_hooks:\n            _warnings.warn('sys.path_hooks is empty', ImportWarning)\n        for hook in sys.path_hooks:\n            try:\n                return hook(path)\n            except ImportError:\n                continue\n        else:\n            return None\n\n    @classmethod\n    def _path_importer_cache(cls, path):\n        \"\"\"Get the finder for the path entry from sys.path_importer_cache.\n\n        If the path entry is not in the cache, find the appropriate finder\n        and cache it. If no finder is available, store None.\n\n        \"\"\"\n        if path == '':\n            path = '.'\n        try:\n            finder = sys.path_importer_cache[path]\n        except KeyError:\n            finder = cls._path_hooks(path)\n            sys.path_importer_cache[path] = finder\n        return finder\n\n    @classmethod\n    def _get_loader(cls, fullname, path):\n        \"\"\"Find the loader or namespace_path for this module/package name.\"\"\"\n        # If this ends up being a namespace package, namespace_path is\n        #  the list of paths that will become its __path__\n        namespace_path = []\n        for entry in path:\n            if not isinstance(entry, (str, bytes)):\n                continue\n            finder = cls._path_importer_cache(entry)\n            if finder is not None:\n                if hasattr(finder, 'find_loader'):\n                    loader, portions = finder.find_loader(fullname)\n                else:\n                    loader = finder.find_module(fullname)\n                    portions = []\n                if loader is not None:\n                    # We found a loader: return it immediately.\n                    return loader, namespace_path\n                # This is possibly part of a namespace package.\n                #  Remember these path entries (if any) for when we\n                #  create a namespace package, and continue iterating\n                #  on path.\n                namespace_path.extend(portions)\n        else:\n            return None, namespace_path\n\n    @classmethod\n    def find_module(cls, fullname, path=None):\n        \"\"\"Find the module on sys.path or 'path' based on sys.path_hooks and\n        sys.path_importer_cache.\"\"\"\n        if path is None:\n            path = sys.path\n        loader, namespace_path = cls._get_loader(fullname, path)\n        if loader is not None:\n            return loader\n        else:\n            if namespace_path:\n                # We found at least one namespace path.  Return a\n                #  loader which can create the namespace package.\n                return NamespaceLoader(fullname, namespace_path, cls._get_loader)\n            else:\n                return None\n\n\nclass FileFinder:\n\n    \"\"\"File-based finder.\n\n    Interactions with the file system are cached for performance, being\n    refreshed when the directory the finder is handling has been modified.\n\n    \"\"\"\n\n    def __init__(self, path, *loader_details):\n        \"\"\"Initialize with the path to search on and a variable number of\n        2-tuples containing the loader and the file suffixes the loader\n        recognizes.\"\"\"\n        loaders = []\n        for loader, suffixes in loader_details:\n            loaders.extend((suffix, loader) for suffix in suffixes)\n        self._loaders = loaders\n        # Base (directory) path\n        self.path = path or '.'\n        self._path_mtime = -1\n        self._path_cache = set()\n        self._relaxed_path_cache = set()\n\n    def invalidate_caches(self):\n        \"\"\"Invalidate the directory mtime.\"\"\"\n        self._path_mtime = -1\n\n    find_module = _find_module_shim\n\n    def find_loader(self, fullname):\n        \"\"\"Try to find a loader for the specified module, or the namespace\n        package portions. Returns (loader, list-of-portions).\"\"\"\n        is_namespace = False\n        tail_module = fullname.rpartition('.')[2]\n        try:\n            mtime = _os.stat(self.path).st_mtime\n        except OSError:\n            mtime = -1\n        if mtime != self._path_mtime:\n            self._fill_cache()\n            self._path_mtime = mtime\n        # tail_module keeps the original casing, for __file__ and friends\n        if _relax_case():\n            cache = self._relaxed_path_cache\n            cache_module = tail_module.lower()\n        else:\n            cache = self._path_cache\n            cache_module = tail_module\n        # Check if the module is the name of a directory (and thus a package).\n        if cache_module in cache:\n            base_path = _path_join(self.path, tail_module)\n            if _path_isdir(base_path):\n                for suffix, loader in self._loaders:\n                    init_filename = '__init__' + suffix\n                    full_path = _path_join(base_path, init_filename)\n                    if _path_isfile(full_path):\n                        return (loader(fullname, full_path), [base_path])\n                else:\n                    # A namespace package, return the path if we don't also\n                    #  find a module in the next section.\n                    is_namespace = True\n        # Check for a file w/ a proper suffix exists.\n        for suffix, loader in self._loaders:\n            full_path = _path_join(self.path, tail_module + suffix)\n            _verbose_message('trying {}'.format(full_path), verbosity=2)\n            if cache_module + suffix in cache:\n                if _path_isfile(full_path):\n                    return (loader(fullname, full_path), [])\n        if is_namespace:\n            _verbose_message('possible namespace for {}'.format(base_path))\n            return (None, [base_path])\n        return (None, [])\n\n    def _fill_cache(self):\n        \"\"\"Fill the cache of potential modules and packages for this directory.\"\"\"\n        path = self.path\n        try:\n            contents = _os.listdir(path)\n        except (FileNotFoundError, PermissionError, NotADirectoryError):\n            # Directory has either been removed, turned into a file, or made\n            # unreadable.\n            contents = []\n        # We store two cached versions, to handle runtime changes of the\n        # PYTHONCASEOK environment variable.\n        if not sys.platform.startswith('win'):\n            self._path_cache = set(contents)\n        else:\n            # Windows users can import modules with case-insensitive file\n            # suffixes (for legacy reasons). Make the suffix lowercase here\n            # so it's done once instead of for every import. This is safe as\n            # the specified suffixes to check against are always specified in a\n            # case-sensitive manner.\n            lower_suffix_contents = set()\n            for item in contents:\n                name, dot, suffix = item.partition('.')\n                if dot:\n                    new_name = '{}.{}'.format(name, suffix.lower())\n                else:\n                    new_name = name\n                lower_suffix_contents.add(new_name)\n            self._path_cache = lower_suffix_contents\n        if sys.platform.startswith(_CASE_INSENSITIVE_PLATFORMS):\n            self._relaxed_path_cache = set(fn.lower() for fn in contents)\n\n    @classmethod\n    def path_hook(cls, *loader_details):\n        \"\"\"A class method which returns a closure to use on sys.path_hook\n        which will return an instance using the specified loaders and the path\n        called on the closure.\n\n        If the path called on the closure is not a directory, ImportError is\n        raised.\n\n        \"\"\"\n        def path_hook_for_FileFinder(path):\n            \"\"\"Path hook for importlib.machinery.FileFinder.\"\"\"\n            if not _path_isdir(path):\n                raise ImportError(\"only directories are supported\", path=path)\n            return cls(path, *loader_details)\n\n        return path_hook_for_FileFinder\n\n    def __repr__(self):\n        return \"FileFinder(%r)\" % (self.path,)\n\n\n# Import itself ###############################################################\n\nclass _ImportLockContext:\n\n    \"\"\"Context manager for the import lock.\"\"\"\n\n    def __enter__(self):\n        \"\"\"Acquire the import lock.\"\"\"\n        _imp.acquire_lock()\n\n    def __exit__(self, exc_type, exc_value, exc_traceback):\n        \"\"\"Release the import lock regardless of any raised exceptions.\"\"\"\n        _imp.release_lock()\n\n\ndef _resolve_name(name, package, level):\n    \"\"\"Resolve a relative module name to an absolute one.\"\"\"\n    bits = package.rsplit('.', level - 1)\n    if len(bits) < level:\n        raise ValueError('attempted relative import beyond top-level package')\n    base = bits[0]\n    return '{}.{}'.format(base, name) if name else base\n\n\ndef _find_module(name, path):\n    \"\"\"Find a module's loader.\"\"\"\n    if not sys.meta_path:\n        _warnings.warn('sys.meta_path is empty', ImportWarning)\n    for finder in sys.meta_path:\n        with _ImportLockContext():\n            loader = finder.find_module(name, path)\n        if loader is not None:\n            # The parent import may have already imported this module.\n            if name not in sys.modules:\n                return loader\n            else:\n                return sys.modules[name].__loader__\n    else:\n        return None\n\n\ndef _sanity_check(name, package, level):\n    \"\"\"Verify arguments are \"sane\".\"\"\"\n    if not isinstance(name, str):\n        raise TypeError(\"module name must be str, not {}\".format(type(name)))\n    if level < 0:\n        raise ValueError('level must be >= 0')\n    if package:\n        if not isinstance(package, str):\n            raise TypeError(\"__package__ not set to a string\")\n        elif package not in sys.modules:\n            msg = (\"Parent module {!r} not loaded, cannot perform relative \"\n                   \"import\")\n            raise SystemError(msg.format(package))\n    if not name and level == 0:\n        raise ValueError(\"Empty module name\")\n\n\n_ERR_MSG = 'No module named {!r}'\n\ndef _find_and_load_unlocked(name, import_):\n    path = None\n    parent = name.rpartition('.')[0]\n    if parent:\n        if parent not in sys.modules:\n            _call_with_frames_removed(import_, parent)\n        # Crazy side-effects!\n        if name in sys.modules:\n            return sys.modules[name]\n        # Backwards-compatibility; be nicer to skip the dict lookup.\n        parent_module = sys.modules[parent]\n        try:\n            path = parent_module.__path__\n        except AttributeError:\n            msg = (_ERR_MSG + '; {} is not a package').format(name, parent)\n            raise ImportError(msg, name=name)\n    loader = _find_module(name, path)\n    if loader is None:\n        exc = ImportError(_ERR_MSG.format(name), name=name)\n        # TODO(brett): switch to a proper ModuleNotFound exception in Python\n        # 3.4.\n        exc._not_found = True\n        raise exc\n    elif name not in sys.modules:\n        # The parent import may have already imported this module.\n        loader.load_module(name)\n        _verbose_message('import {!r} # {!r}', name, loader)\n    # Backwards-compatibility; be nicer to skip the dict lookup.\n    module = sys.modules[name]\n    if parent:\n        # Set the module as an attribute on its parent.\n        parent_module = sys.modules[parent]\n        setattr(parent_module, name.rpartition('.')[2], module)\n    # Set __package__ if the loader did not.\n    if getattr(module, '__package__', None) is None:\n        try:\n            module.__package__ = module.__name__\n            if not hasattr(module, '__path__'):\n                module.__package__ = module.__package__.rpartition('.')[0]\n        except AttributeError:\n            pass\n    # Set loader if need be.\n    if not hasattr(module, '__loader__'):\n        try:\n            module.__loader__ = loader\n        except AttributeError:\n            pass\n    return module\n\n\ndef _find_and_load(name, import_):\n    \"\"\"Find and load the module, and release the import lock.\"\"\"\n    try:\n        lock = _get_module_lock(name)\n    finally:\n        _imp.release_lock()\n    lock.acquire()\n    try:\n        return _find_and_load_unlocked(name, import_)\n    finally:\n        lock.release()\n\n\ndef _gcd_import(name, package=None, level=0):\n    \"\"\"Import and return the module based on its name, the package the call is\n    being made from, and the level adjustment.\n\n    This function represents the greatest common denominator of functionality\n    between import_module and __import__. This includes setting __package__ if\n    the loader did not.\n\n    \"\"\"\n    _sanity_check(name, package, level)\n    if level > 0:\n        name = _resolve_name(name, package, level)\n    _imp.acquire_lock()\n    if name not in sys.modules:\n        return _find_and_load(name, _gcd_import)\n    module = sys.modules[name]\n    if module is None:\n        _imp.release_lock()\n        message = (\"import of {} halted; \"\n                    \"None in sys.modules\".format(name))\n        raise ImportError(message, name=name)\n    _lock_unlock_module(name)\n    return module\n\ndef _handle_fromlist(module, fromlist, import_):\n    \"\"\"Figure out what __import__ should return.\n\n    The import_ parameter is a callable which takes the name of module to\n    import. It is required to decouple the function from assuming importlib's\n    import implementation is desired.\n\n    \"\"\"\n    # The hell that is fromlist ...\n    # If a package was imported, try to import stuff from fromlist.\n    if hasattr(module, '__path__'):\n        if '*' in fromlist:\n            fromlist = list(fromlist)\n            fromlist.remove('*')\n            if hasattr(module, '__all__'):\n                fromlist.extend(module.__all__)\n        for x in fromlist:\n            if not hasattr(module, x):\n                from_name = '{}.{}'.format(module.__name__, x)\n                try:\n                    _call_with_frames_removed(import_, from_name)\n                except ImportError as exc:\n                    # Backwards-compatibility dictates we ignore failed\n                    # imports triggered by fromlist for modules that don't\n                    # exist.\n                    # TODO(brett): In Python 3.4, have import raise\n                    #   ModuleNotFound and catch that.\n                    if getattr(exc, '_not_found', False):\n                        if exc.name == from_name:\n                            continue\n                    raise\n    return module\n\n\ndef _calc___package__(globals):\n    \"\"\"Calculate what __package__ should be.\n\n    __package__ is not guaranteed to be defined or could be set to None\n    to represent that its proper value is unknown.\n\n    \"\"\"\n    package = globals.get('__package__')\n    if package is None:\n        package = globals['__name__']\n        if '__path__' not in globals:\n            package = package.rpartition('.')[0]\n    return package\n\n\ndef _get_supported_file_loaders():\n    \"\"\"Returns a list of file-based module loaders.\n\n    Each item is a tuple (loader, suffixes).\n    \"\"\"\n    extensions = ExtensionFileLoader, _imp.extension_suffixes()\n    source = SourceFileLoader, SOURCE_SUFFIXES\n    bytecode = SourcelessFileLoader, BYTECODE_SUFFIXES\n    return [extensions, source, bytecode]\n\n\ndef __import__(name, globals=None, locals=None, fromlist=(), level=0):\n    \"\"\"Import a module.\n\n    The 'globals' argument is used to infer where the import is occuring from\n    to handle relative imports. The 'locals' argument is ignored. The\n    'fromlist' argument specifies what should exist as attributes on the module\n    being imported (e.g. ``from module import <fromlist>``).  The 'level'\n    argument represents the package location to import from in a relative\n    import (e.g. ``from ..pkg import mod`` would have a 'level' of 2).\n\n    \"\"\"\n    if level == 0:\n        module = _gcd_import(name)\n    else:\n        globals_ = globals if globals is not None else {}\n        package = _calc___package__(globals_)\n        module = _gcd_import(name, package, level)\n    if not fromlist:\n        # Return up to the first dot in 'name'. This is complicated by the fact\n        # that 'name' may be relative.\n        if level == 0:\n            return _gcd_import(name.partition('.')[0])\n        elif not name:\n            return module\n        else:\n            # Figure out where to slice the module's name up to the first dot\n            # in 'name'.\n            cut_off = len(name) - len(name.partition('.')[0])\n            # Slice end needs to be positive to alleviate need to special-case\n            # when ``'.' not in name``.\n            return sys.modules[module.__name__[:len(module.__name__)-cut_off]]\n    else:\n        return _handle_fromlist(module, fromlist, _gcd_import)\n\n\n\ndef _setup(sys_module, _imp_module):\n    \"\"\"Setup importlib by importing needed built-in modules and injecting them\n    into the global namespace.\n\n    As sys is needed for sys.modules access and _imp is needed to load built-in\n    modules, those two modules must be explicitly passed in.\n\n    \"\"\"\n\n    global _imp, sys, BYTECODE_SUFFIXES\n    _imp = _imp_module\n    sys = sys_module\n\n    if sys.flags.optimize:\n        BYTECODE_SUFFIXES = OPTIMIZED_BYTECODE_SUFFIXES\n    else:\n        BYTECODE_SUFFIXES = DEBUG_BYTECODE_SUFFIXES\n\n    module_type = type(sys)\n    for name, module in sys.modules.items():\n        if isinstance(module, module_type):\n            if not hasattr(module, '__loader__'):\n                if name in sys.builtin_module_names:\n                    module.__loader__ = BuiltinImporter\n                #fix me brython\n                #elif _imp.is_frozen(name):\n                #    module.__loader__ = FrozenImporter\n\n    self_module = sys.modules[__name__]\n    for builtin_name in ('_io', '_warnings', 'builtins', 'marshal'):\n        if builtin_name not in sys.modules:\n            builtin_module = BuiltinImporter.load_module(builtin_name)\n        else:\n            builtin_module = sys.modules[builtin_name]\n        setattr(self_module, builtin_name, builtin_module)\n\n    os_details = ('posix', ['/']), ('nt', ['\\\\', '/']), ('os2', ['\\\\', '/'])\n    for builtin_os, path_separators in os_details:\n        # Assumption made in _path_join()\n        assert all(len(sep) == 1 for sep in path_separators)\n        path_sep = path_separators[0]\n        if builtin_os in sys.modules:\n            os_module = sys.modules[builtin_os]\n            break\n        else:\n            try:\n                os_module = BuiltinImporter.load_module(builtin_os)\n                # TODO: rip out os2 code after 3.3 is released as per PEP 11\n                if builtin_os == 'os2' and 'EMX GCC' in sys.version:\n                    path_sep = path_separators[1]\n                break\n            except ImportError:\n                continue\n    else:\n        raise ImportError('importlib requires posix or nt')\n\n    try:\n        thread_module = BuiltinImporter.load_module('_thread')\n    except ImportError:\n        # Python was built without threads\n        thread_module = None\n    weakref_module = BuiltinImporter.load_module('_weakref')\n\n    if builtin_os == 'nt':\n        winreg_module = BuiltinImporter.load_module('winreg')\n        setattr(self_module, '_winreg', winreg_module)\n\n    setattr(self_module, '_os', os_module)\n    setattr(self_module, '_thread', thread_module)\n    setattr(self_module, '_weakref', weakref_module)\n    setattr(self_module, 'path_sep', path_sep)\n    setattr(self_module, 'path_separators', set(path_separators))\n    # Constants\n    setattr(self_module, '_relax_case', _make_relax_case())\n    EXTENSION_SUFFIXES.extend(_imp.extension_suffixes())\n    if builtin_os == 'nt':\n        SOURCE_SUFFIXES.append('.pyw')\n        if '_d.pyd' in EXTENSION_SUFFIXES:\n            WindowsRegistryFinder.DEBUG_BUILD = True\n\ndef _install(sys_module, _imp_module):\n    \"\"\"Install importlib as the implementation of import.\"\"\"\n    _setup(sys_module, _imp_module)\n    supported_loaders = _get_supported_file_loaders()\n    sys.path_hooks.extend([FileFinder.path_hook(*supported_loaders)])\n    sys.meta_path.append(BuiltinImporter)\n    sys.meta_path.append(FrozenImporter)\n    if _os.__name__ == 'nt':\n        sys.meta_path.append(WindowsRegistryFinder)\n    sys.meta_path.append(PathFinder)\n"], "_abcoll": [".py", "# Copyright 2007 Google, Inc. All Rights Reserved.\n# Licensed to PSF under a Contributor Agreement.\n\n\"\"\"Abstract Base Classes (ABCs) for collections, according to PEP 3119.\n\nDON'T USE THIS MODULE DIRECTLY!  The classes here should be imported\nvia collections; they are defined here only to alleviate certain\nbootstrapping issues.  Unit tests are in test_collections.\n\"\"\"\n\nfrom abc import ABCMeta, abstractmethod\nimport sys\n\n__all__ = [\"Hashable\", \"Iterable\", \"Iterator\",\n           \"Sized\", \"Container\", \"Callable\",\n           \"Set\", \"MutableSet\",\n           \"Mapping\", \"MutableMapping\",\n           \"MappingView\", \"KeysView\", \"ItemsView\", \"ValuesView\",\n           \"Sequence\", \"MutableSequence\",\n           \"ByteString\",\n           ]\n\n\"\"\"\n### collection related types which are not exposed through builtin ###\n## iterators ##\n#fixme brython\n#bytes_iterator = type(iter(b''))\nbytes_iterator = type(iter(''))\n#fixme brython\n#bytearray_iterator = type(iter(bytearray()))\n#callable_iterator = ???\ndict_keyiterator = type(iter({}.keys()))\ndict_valueiterator = type(iter({}.values()))\ndict_itemiterator = type(iter({}.items()))\nlist_iterator = type(iter([]))\nlist_reverseiterator = type(iter(reversed([])))\nrange_iterator = type(iter(range(0)))\nset_iterator = type(iter(set()))\nstr_iterator = type(iter(\"\"))\ntuple_iterator = type(iter(()))\nzip_iterator = type(iter(zip()))\n## views ##\ndict_keys = type({}.keys())\ndict_values = type({}.values())\ndict_items = type({}.items())\n## misc ##\ndict_proxy = type(type.__dict__)\n\"\"\"\n\ndef abstractmethod(self):\n    return self\n\n### ONE-TRICK PONIES ###\n\n\n#class Iterable(metaclass=ABCMeta):\nclass Iterable:\n\n    @abstractmethod\n    def __iter__(self):\n        while False:\n            yield None\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Iterable:\n            if any(\"__iter__\" in B.__dict__ for B in C.__mro__):\n                return True\n        return NotImplemented\n\n\n#class Sized(metaclass=ABCMeta):\nclass Sized:\n\n    @abstractmethod\n    def __len__(self):\n        return 0\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Sized:\n            if any(\"__len__\" in B.__dict__ for B in C.__mro__):\n                return True\n        return NotImplemented\n\n\n#class Container(metaclass=ABCMeta):\nclass Container:\n\n    @abstractmethod\n    def __contains__(self, x):\n        return False\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Container:\n            if any(\"__contains__\" in B.__dict__ for B in C.__mro__):\n                return True\n        return NotImplemented\n\n### MAPPINGS ###\n\n\nclass Mapping(Sized, Iterable, Container):\n\n    @abstractmethod\n    def __getitem__(self, key):\n        raise KeyError\n\n    def get(self, key, default=None):\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def __contains__(self, key):\n        try:\n            self[key]\n        except KeyError:\n            return False\n        else:\n            return True\n\n    def keys(self):\n        return KeysView(self)\n\n    def items(self):\n        return ItemsView(self)\n\n    def values(self):\n        return ValuesView(self)\n\n    def __eq__(self, other):\n        if not isinstance(other, Mapping):\n            return NotImplemented\n        return dict(self.items()) == dict(other.items())\n\n    def __ne__(self, other):\n        return not (self == other)\n\n\nclass MutableMapping(Mapping):\n\n    @abstractmethod\n    def __setitem__(self, key, value):\n        raise KeyError\n\n    @abstractmethod\n    def __delitem__(self, key):\n        raise KeyError\n\n    __marker = object()\n\n    def pop(self, key, default=__marker):\n        try:\n            value = self[key]\n        except KeyError:\n            if default is self.__marker:\n                raise\n            return default\n        else:\n            del self[key]\n            return value\n\n    def popitem(self):\n        try:\n            key = next(iter(self))\n        except StopIteration:\n            raise KeyError\n        value = self[key]\n        del self[key]\n        return key, value\n\n    def clear(self):\n        try:\n            while True:\n                self.popitem()\n        except KeyError:\n            pass\n\n    def update(*args, **kwds):\n        if len(args) > 2:\n            raise TypeError(\"update() takes at most 2 positional \"\n                            \"arguments ({} given)\".format(len(args)))\n        elif not args:\n            raise TypeError(\"update() takes at least 1 argument (0 given)\")\n        self = args[0]\n        other = args[1] if len(args) >= 2 else ()\n\n        if isinstance(other, Mapping):\n            for key in other:\n                self[key] = other[key]\n        elif hasattr(other, \"keys\"):\n            for key in other.keys():\n                self[key] = other[key]\n        else:\n            for key, value in other:\n                self[key] = value\n        for key, value in kwds.items():\n            self[key] = value\n\n    def setdefault(self, key, default=None):\n        try:\n            return self[key]\n        except KeyError:\n            self[key] = default\n        return default\n\n#MutableMapping.register(dict)\n"], "xml.dom.minicompat": [".py", "\"\"\"Python version compatibility support for minidom.\"\"\"\n\n# This module should only be imported using \"import *\".\n#\n# The following names are defined:\n#\n#   NodeList      -- lightest possible NodeList implementation\n#\n#   EmptyNodeList -- lightest possible NodeList that is guaranteed to\n#                    remain empty (immutable)\n#\n#   StringTypes   -- tuple of defined string types\n#\n#   defproperty   -- function used in conjunction with GetattrMagic;\n#                    using these together is needed to make them work\n#                    as efficiently as possible in both Python 2.2+\n#                    and older versions.  For example:\n#\n#                        class MyClass(GetattrMagic):\n#                            def _get_myattr(self):\n#                                return something\n#\n#                        defproperty(MyClass, \"myattr\",\n#                                    \"return some value\")\n#\n#                    For Python 2.2 and newer, this will construct a\n#                    property object on the class, which avoids\n#                    needing to override __getattr__().  It will only\n#                    work for read-only attributes.\n#\n#                    For older versions of Python, inheriting from\n#                    GetattrMagic will use the traditional\n#                    __getattr__() hackery to achieve the same effect,\n#                    but less efficiently.\n#\n#                    defproperty() should be used for each version of\n#                    the relevant _get_<property>() function.\n\n__all__ = [\"NodeList\", \"EmptyNodeList\", \"StringTypes\", \"defproperty\"]\n\nimport xml.dom\n\nStringTypes = (str,)\n\n\nclass NodeList(list):\n    __slots__ = ()\n\n    def item(self, index):\n        if 0 <= index < len(self):\n            return self[index]\n\n    def _get_length(self):\n        return len(self)\n\n    def _set_length(self, value):\n        raise xml.dom.NoModificationAllowedErr(\n            \"attempt to modify read-only attribute 'length'\")\n\n    length = property(_get_length, _set_length,\n                      doc=\"The number of nodes in the NodeList.\")\n\n    def __getstate__(self):\n        return list(self)\n\n    def __setstate__(self, state):\n        self[:] = state\n\n\nclass EmptyNodeList(tuple):\n    __slots__ = ()\n\n    def __add__(self, other):\n        NL = NodeList()\n        NL.extend(other)\n        return NL\n\n    def __radd__(self, other):\n        NL = NodeList()\n        NL.extend(other)\n        return NL\n\n    def item(self, index):\n        return None\n\n    def _get_length(self):\n        return 0\n\n    def _set_length(self, value):\n        raise xml.dom.NoModificationAllowedErr(\n            \"attempt to modify read-only attribute 'length'\")\n\n    length = property(_get_length, _set_length,\n                      doc=\"The number of nodes in the NodeList.\")\n\n\ndef defproperty(klass, name, doc):\n    get = getattr(klass, (\"_get_\" + name))\n    def set(self, value, name=name):\n        raise xml.dom.NoModificationAllowedErr(\n            \"attempt to modify read-only attribute \" + repr(name))\n    assert not hasattr(klass, \"_set_\" + name), \\\n           \"expected not to find _set_\" + name\n    prop = property(get, set, doc=doc)\n    setattr(klass, name, prop)\n"], "test": [".py", "# Dummy file to make this directory a package.\n", 1], "getopt": [".py", "\"\"\"Parser for command line options.\n\nThis module helps scripts to parse the command line arguments in\nsys.argv.  It supports the same conventions as the Unix getopt()\nfunction (including the special meanings of arguments of the form `-'\nand `--').  Long options similar to those supported by GNU software\nmay be used as well via an optional third argument.  This module\nprovides two functions and an exception:\n\ngetopt() -- Parse command line options\ngnu_getopt() -- Like getopt(), but allow option and non-option arguments\nto be intermixed.\nGetoptError -- exception (class) raised with 'opt' attribute, which is the\noption involved with the exception.\n\"\"\"\n\n# Long option support added by Lars Wirzenius <liw@iki.fi>.\n#\n# Gerrit Holl <gerrit@nl.linux.org> moved the string-based exceptions\n# to class-based exceptions.\n#\n# Peter \u00c5strand <astrand@lysator.liu.se> added gnu_getopt().\n#\n# TODO for gnu_getopt():\n#\n# - GNU getopt_long_only mechanism\n# - allow the caller to specify ordering\n# - RETURN_IN_ORDER option\n# - GNU extension with '-' as first character of option string\n# - optional arguments, specified by double colons\n# - a option string with a W followed by semicolon should\n#   treat \"-W foo\" as \"--foo\"\n\n__all__ = [\"GetoptError\",\"error\",\"getopt\",\"gnu_getopt\"]\n\nimport os\ntry:\n    from gettext import gettext as _\nexcept ImportError:\n    # Bootstrapping Python: gettext's dependencies not built yet\n    def _(s): return s\n\nclass GetoptError(Exception):\n    opt = ''\n    msg = ''\n    def __init__(self, msg, opt=''):\n        self.msg = msg\n        self.opt = opt\n        Exception.__init__(self, msg, opt)\n\n    def __str__(self):\n        return self.msg\n\nerror = GetoptError # backward compatibility\n\ndef getopt(args, shortopts, longopts = []):\n    \"\"\"getopt(args, options[, long_options]) -> opts, args\n\n    Parses command line options and parameter list.  args is the\n    argument list to be parsed, without the leading reference to the\n    running program.  Typically, this means \"sys.argv[1:]\".  shortopts\n    is the string of option letters that the script wants to\n    recognize, with options that require an argument followed by a\n    colon (i.e., the same format that Unix getopt() uses).  If\n    specified, longopts is a list of strings with the names of the\n    long options which should be supported.  The leading '--'\n    characters should not be included in the option name.  Options\n    which require an argument should be followed by an equal sign\n    ('=').\n\n    The return value consists of two elements: the first is a list of\n    (option, value) pairs; the second is the list of program arguments\n    left after the option list was stripped (this is a trailing slice\n    of the first argument).  Each option-and-value pair returned has\n    the option as its first element, prefixed with a hyphen (e.g.,\n    '-x'), and the option argument as its second element, or an empty\n    string if the option has no argument.  The options occur in the\n    list in the same order in which they were found, thus allowing\n    multiple occurrences.  Long and short options may be mixed.\n\n    \"\"\"\n\n    opts = []\n    if type(longopts) == type(\"\"):\n        longopts = [longopts]\n    else:\n        longopts = list(longopts)\n    while args and args[0].startswith('-') and args[0] != '-':\n        if args[0] == '--':\n            args = args[1:]\n            break\n        if args[0].startswith('--'):\n            opts, args = do_longs(opts, args[0][2:], longopts, args[1:])\n        else:\n            opts, args = do_shorts(opts, args[0][1:], shortopts, args[1:])\n\n    return opts, args\n\ndef gnu_getopt(args, shortopts, longopts = []):\n    \"\"\"getopt(args, options[, long_options]) -> opts, args\n\n    This function works like getopt(), except that GNU style scanning\n    mode is used by default. This means that option and non-option\n    arguments may be intermixed. The getopt() function stops\n    processing options as soon as a non-option argument is\n    encountered.\n\n    If the first character of the option string is `+', or if the\n    environment variable POSIXLY_CORRECT is set, then option\n    processing stops as soon as a non-option argument is encountered.\n\n    \"\"\"\n\n    opts = []\n    prog_args = []\n    if isinstance(longopts, str):\n        longopts = [longopts]\n    else:\n        longopts = list(longopts)\n\n    # Allow options after non-option arguments?\n    if shortopts.startswith('+'):\n        shortopts = shortopts[1:]\n        all_options_first = True\n    elif os.environ.get(\"POSIXLY_CORRECT\"):\n        all_options_first = True\n    else:\n        all_options_first = False\n\n    while args:\n        if args[0] == '--':\n            prog_args += args[1:]\n            break\n\n        if args[0][:2] == '--':\n            opts, args = do_longs(opts, args[0][2:], longopts, args[1:])\n        elif args[0][:1] == '-' and args[0] != '-':\n            opts, args = do_shorts(opts, args[0][1:], shortopts, args[1:])\n        else:\n            if all_options_first:\n                prog_args += args\n                break\n            else:\n                prog_args.append(args[0])\n                args = args[1:]\n\n    return opts, prog_args\n\ndef do_longs(opts, opt, longopts, args):\n    try:\n        i = opt.index('=')\n    except ValueError:\n        optarg = None\n    else:\n        opt, optarg = opt[:i], opt[i+1:]\n\n    has_arg, opt = long_has_args(opt, longopts)\n    if has_arg:\n        if optarg is None:\n            if not args:\n                raise GetoptError(_('option --%s requires argument') % opt, opt)\n            optarg, args = args[0], args[1:]\n    elif optarg is not None:\n        raise GetoptError(_('option --%s must not have an argument') % opt, opt)\n    opts.append(('--' + opt, optarg or ''))\n    return opts, args\n\n# Return:\n#   has_arg?\n#   full option name\ndef long_has_args(opt, longopts):\n    possibilities = [o for o in longopts if o.startswith(opt)]\n    if not possibilities:\n        raise GetoptError(_('option --%s not recognized') % opt, opt)\n    # Is there an exact match?\n    if opt in possibilities:\n        return False, opt\n    elif opt + '=' in possibilities:\n        return True, opt\n    # No exact match, so better be unique.\n    if len(possibilities) > 1:\n        # XXX since possibilities contains all valid continuations, might be\n        # nice to work them into the error msg\n        raise GetoptError(_('option --%s not a unique prefix') % opt, opt)\n    assert len(possibilities) == 1\n    unique_match = possibilities[0]\n    has_arg = unique_match.endswith('=')\n    if has_arg:\n        unique_match = unique_match[:-1]\n    return has_arg, unique_match\n\ndef do_shorts(opts, optstring, shortopts, args):\n    while optstring != '':\n        opt, optstring = optstring[0], optstring[1:]\n        if short_has_arg(opt, shortopts):\n            if optstring == '':\n                if not args:\n                    raise GetoptError(_('option -%s requires argument') % opt,\n                                      opt)\n                optstring, args = args[0], args[1:]\n            optarg, optstring = optstring, ''\n        else:\n            optarg = ''\n        opts.append(('-' + opt, optarg))\n    return opts, args\n\ndef short_has_arg(opt, shortopts):\n    for i in range(len(shortopts)):\n        if opt == shortopts[i] != ':':\n            return shortopts.startswith(':', i+1)\n    raise GetoptError(_('option -%s not recognized') % opt, opt)\n\nif __name__ == '__main__':\n    import sys\n    print(getopt(sys.argv[1:], \"a:b\", [\"alpha=\", \"beta\"]))\n"], "csv": [".py", "\n\"\"\"\ncsv.py - read/write/investigate CSV files\n\"\"\"\n\nimport re\nfrom _csv import Error, __version__, writer, reader, register_dialect, \\\n                 unregister_dialect, get_dialect, list_dialects, \\\n                 field_size_limit, \\\n                 QUOTE_MINIMAL, QUOTE_ALL, QUOTE_NONNUMERIC, QUOTE_NONE, \\\n                 __doc__\nfrom _csv import Dialect as _Dialect\n\nfrom io import StringIO\n\n__all__ = [ \"QUOTE_MINIMAL\", \"QUOTE_ALL\", \"QUOTE_NONNUMERIC\", \"QUOTE_NONE\",\n            \"Error\", \"Dialect\", \"__doc__\", \"excel\", \"excel_tab\",\n            \"field_size_limit\", \"reader\", \"writer\",\n            \"register_dialect\", \"get_dialect\", \"list_dialects\", \"Sniffer\",\n            \"unregister_dialect\", \"__version__\", \"DictReader\", \"DictWriter\" ]\n\nclass Dialect:\n    \"\"\"Describe a CSV dialect.\n\n    This must be subclassed (see csv.excel).  Valid attributes are:\n    delimiter, quotechar, escapechar, doublequote, skipinitialspace,\n    lineterminator, quoting.\n\n    \"\"\"\n    _name = \"\"\n    _valid = False\n    # placeholders\n    delimiter = None\n    quotechar = None\n    escapechar = None\n    doublequote = None\n    skipinitialspace = None\n    lineterminator = None\n    quoting = None\n\n    def __init__(self):\n        if self.__class__ != Dialect:\n            self._valid = True\n        self._validate()\n\n    def _validate(self):\n        try:\n            _Dialect(self)\n        except TypeError as e:\n            # We do this for compatibility with py2.3\n            raise Error(str(e))\n\nclass excel(Dialect):\n    \"\"\"Describe the usual properties of Excel-generated CSV files.\"\"\"\n    delimiter = ','\n    quotechar = '\"'\n    doublequote = True\n    skipinitialspace = False\n    lineterminator = '\\r\\n'\n    quoting = QUOTE_MINIMAL\nregister_dialect(\"excel\", excel)\n\nclass excel_tab(excel):\n    \"\"\"Describe the usual properties of Excel-generated TAB-delimited files.\"\"\"\n    delimiter = '\\t'\nregister_dialect(\"excel-tab\", excel_tab)\n\nclass unix_dialect(Dialect):\n    \"\"\"Describe the usual properties of Unix-generated CSV files.\"\"\"\n    delimiter = ','\n    quotechar = '\"'\n    doublequote = True\n    skipinitialspace = False\n    lineterminator = '\\n'\n    quoting = QUOTE_ALL\nregister_dialect(\"unix\", unix_dialect)\n\n\nclass DictReader:\n    def __init__(self, f, fieldnames=None, restkey=None, restval=None,\n                 dialect=\"excel\", *args, **kwds):\n        self._fieldnames = fieldnames   # list of keys for the dict\n        self.restkey = restkey          # key to catch long rows\n        self.restval = restval          # default value for short rows\n        self.reader = reader(f, dialect, *args, **kwds)\n        self.dialect = dialect\n        self.line_num = 0\n\n    def __iter__(self):\n        return self\n\n    @property\n    def fieldnames(self):\n        if self._fieldnames is None:\n            try:\n                self._fieldnames = next(self.reader)\n            except StopIteration:\n                pass\n        self.line_num = self.reader.line_num\n        return self._fieldnames\n\n    @fieldnames.setter\n    def fieldnames(self, value):\n        self._fieldnames = value\n\n    def __next__(self):\n        if self.line_num == 0:\n            # Used only for its side effect.\n            self.fieldnames\n        row = next(self.reader)\n        self.line_num = self.reader.line_num\n\n        # unlike the basic reader, we prefer not to return blanks,\n        # because we will typically wind up with a dict full of None\n        # values\n        while row == []:\n            row = next(self.reader)\n        d = dict(zip(self.fieldnames, row))\n        lf = len(self.fieldnames)\n        lr = len(row)\n        if lf < lr:\n            d[self.restkey] = row[lf:]\n        elif lf > lr:\n            for key in self.fieldnames[lr:]:\n                d[key] = self.restval\n        return d\n\n\nclass DictWriter:\n    def __init__(self, f, fieldnames, restval=\"\", extrasaction=\"raise\",\n                 dialect=\"excel\", *args, **kwds):\n        self.fieldnames = fieldnames    # list of keys for the dict\n        self.restval = restval          # for writing short dicts\n        if extrasaction.lower() not in (\"raise\", \"ignore\"):\n            raise ValueError(\"extrasaction (%s) must be 'raise' or 'ignore'\"\n                             % extrasaction)\n        self.extrasaction = extrasaction\n        self.writer = writer(f, dialect, *args, **kwds)\n\n    def writeheader(self):\n        header = dict(zip(self.fieldnames, self.fieldnames))\n        self.writerow(header)\n\n    def _dict_to_list(self, rowdict):\n        if self.extrasaction == \"raise\":\n            wrong_fields = [k for k in rowdict if k not in self.fieldnames]\n            if wrong_fields:\n                raise ValueError(\"dict contains fields not in fieldnames: \"\n                                 + \", \".join(wrong_fields))\n        return [rowdict.get(key, self.restval) for key in self.fieldnames]\n\n    def writerow(self, rowdict):\n        return self.writer.writerow(self._dict_to_list(rowdict))\n\n    def writerows(self, rowdicts):\n        rows = []\n        for rowdict in rowdicts:\n            rows.append(self._dict_to_list(rowdict))\n        return self.writer.writerows(rows)\n\n# Guard Sniffer's type checking against builds that exclude complex()\ntry:\n    complex\nexcept NameError:\n    complex = float\n\nclass Sniffer:\n    '''\n    \"Sniffs\" the format of a CSV file (i.e. delimiter, quotechar)\n    Returns a Dialect object.\n    '''\n    def __init__(self):\n        # in case there is more than one possible delimiter\n        self.preferred = [',', '\\t', ';', ' ', ':']\n\n\n    def sniff(self, sample, delimiters=None):\n        \"\"\"\n        Returns a dialect (or None) corresponding to the sample\n        \"\"\"\n\n        quotechar, doublequote, delimiter, skipinitialspace = \\\n                   self._guess_quote_and_delimiter(sample, delimiters)\n        if not delimiter:\n            delimiter, skipinitialspace = self._guess_delimiter(sample,\n                                                                delimiters)\n\n        if not delimiter:\n            raise Error(\"Could not determine delimiter\")\n\n        class dialect(Dialect):\n            _name = \"sniffed\"\n            lineterminator = '\\r\\n'\n            quoting = QUOTE_MINIMAL\n            # escapechar = ''\n\n        dialect.doublequote = doublequote\n        dialect.delimiter = delimiter\n        # _csv.reader won't accept a quotechar of ''\n        dialect.quotechar = quotechar or '\"'\n        dialect.skipinitialspace = skipinitialspace\n\n        return dialect\n\n\n    def _guess_quote_and_delimiter(self, data, delimiters):\n        \"\"\"\n        Looks for text enclosed between two identical quotes\n        (the probable quotechar) which are preceded and followed\n        by the same character (the probable delimiter).\n        For example:\n                         ,'some text',\n        The quote with the most wins, same with the delimiter.\n        If there is no quotechar the delimiter can't be determined\n        this way.\n        \"\"\"\n\n        matches = []\n        for restr in ('(?P<delim>[^\\w\\n\"\\'])(?P<space> ?)(?P<quote>[\"\\']).*?(?P=quote)(?P=delim)', # ,\".*?\",\n                      '(?:^|\\n)(?P<quote>[\"\\']).*?(?P=quote)(?P<delim>[^\\w\\n\"\\'])(?P<space> ?)',   #  \".*?\",\n                      '(?P<delim>>[^\\w\\n\"\\'])(?P<space> ?)(?P<quote>[\"\\']).*?(?P=quote)(?:$|\\n)',  # ,\".*?\"\n                      '(?:^|\\n)(?P<quote>[\"\\']).*?(?P=quote)(?:$|\\n)'):                            #  \".*?\" (no delim, no space)\n            regexp = re.compile(restr, re.DOTALL | re.MULTILINE)\n            matches = regexp.findall(data)\n            if matches:\n                break\n\n        if not matches:\n            # (quotechar, doublequote, delimiter, skipinitialspace)\n            return ('', False, None, 0)\n        quotes = {}\n        delims = {}\n        spaces = 0\n        for m in matches:\n            n = regexp.groupindex['quote'] - 1\n            key = m[n]\n            if key:\n                quotes[key] = quotes.get(key, 0) + 1\n            try:\n                n = regexp.groupindex['delim'] - 1\n                key = m[n]\n            except KeyError:\n                continue\n            if key and (delimiters is None or key in delimiters):\n                delims[key] = delims.get(key, 0) + 1\n            try:\n                n = regexp.groupindex['space'] - 1\n            except KeyError:\n                continue\n            if m[n]:\n                spaces += 1\n\n        quotechar = max(quotes, key=quotes.get)\n\n        if delims:\n            delim = max(delims, key=delims.get)\n            skipinitialspace = delims[delim] == spaces\n            if delim == '\\n': # most likely a file with a single column\n                delim = ''\n        else:\n            # there is *no* delimiter, it's a single column of quoted data\n            delim = ''\n            skipinitialspace = 0\n\n        # if we see an extra quote between delimiters, we've got a\n        # double quoted format\n        dq_regexp = re.compile(\n                               r\"((%(delim)s)|^)\\W*%(quote)s[^%(delim)s\\n]*%(quote)s[^%(delim)s\\n]*%(quote)s\\W*((%(delim)s)|$)\" % \\\n                               {'delim':re.escape(delim), 'quote':quotechar}, re.MULTILINE)\n\n\n\n        if dq_regexp.search(data):\n            doublequote = True\n        else:\n            doublequote = False\n\n        return (quotechar, doublequote, delim, skipinitialspace)\n\n\n    def _guess_delimiter(self, data, delimiters):\n        \"\"\"\n        The delimiter /should/ occur the same number of times on\n        each row. However, due to malformed data, it may not. We don't want\n        an all or nothing approach, so we allow for small variations in this\n        number.\n          1) build a table of the frequency of each character on every line.\n          2) build a table of frequencies of this frequency (meta-frequency?),\n             e.g.  'x occurred 5 times in 10 rows, 6 times in 1000 rows,\n             7 times in 2 rows'\n          3) use the mode of the meta-frequency to determine the /expected/\n             frequency for that character\n          4) find out how often the character actually meets that goal\n          5) the character that best meets its goal is the delimiter\n        For performance reasons, the data is evaluated in chunks, so it can\n        try and evaluate the smallest portion of the data possible, evaluating\n        additional chunks as necessary.\n        \"\"\"\n\n        data = list(filter(None, data.split('\\n')))\n\n        ascii = [chr(c) for c in range(127)] # 7-bit ASCII\n\n        # build frequency tables\n        chunkLength = min(10, len(data))\n        iteration = 0\n        charFrequency = {}\n        modes = {}\n        delims = {}\n        start, end = 0, min(chunkLength, len(data))\n        while start < len(data):\n            iteration += 1\n            for line in data[start:end]:\n                for char in ascii:\n                    metaFrequency = charFrequency.get(char, {})\n                    # must count even if frequency is 0\n                    freq = line.count(char)\n                    # value is the mode\n                    metaFrequency[freq] = metaFrequency.get(freq, 0) + 1\n                    charFrequency[char] = metaFrequency\n\n            for char in charFrequency.keys():\n                items = list(charFrequency[char].items())\n                if len(items) == 1 and items[0][0] == 0:\n                    continue\n                # get the mode of the frequencies\n                if len(items) > 1:\n                    modes[char] = max(items, key=lambda x: x[1])\n                    # adjust the mode - subtract the sum of all\n                    # other frequencies\n                    items.remove(modes[char])\n                    modes[char] = (modes[char][0], modes[char][1]\n                                   - sum(item[1] for item in items))\n                else:\n                    modes[char] = items[0]\n\n            # build a list of possible delimiters\n            modeList = modes.items()\n            total = float(chunkLength * iteration)\n            # (rows of consistent data) / (number of rows) = 100%\n            consistency = 1.0\n            # minimum consistency threshold\n            threshold = 0.9\n            while len(delims) == 0 and consistency >= threshold:\n                for k, v in modeList:\n                    if v[0] > 0 and v[1] > 0:\n                        if ((v[1]/total) >= consistency and\n                            (delimiters is None or k in delimiters)):\n                            delims[k] = v\n                consistency -= 0.01\n\n            if len(delims) == 1:\n                delim = list(delims.keys())[0]\n                skipinitialspace = (data[0].count(delim) ==\n                                    data[0].count(\"%c \" % delim))\n                return (delim, skipinitialspace)\n\n            # analyze another chunkLength lines\n            start = end\n            end += chunkLength\n\n        if not delims:\n            return ('', 0)\n\n        # if there's more than one, fall back to a 'preferred' list\n        if len(delims) > 1:\n            for d in self.preferred:\n                if d in delims.keys():\n                    skipinitialspace = (data[0].count(d) ==\n                                        data[0].count(\"%c \" % d))\n                    return (d, skipinitialspace)\n\n        # nothing else indicates a preference, pick the character that\n        # dominates(?)\n        items = [(v,k) for (k,v) in delims.items()]\n        items.sort()\n        delim = items[-1][1]\n\n        skipinitialspace = (data[0].count(delim) ==\n                            data[0].count(\"%c \" % delim))\n        return (delim, skipinitialspace)\n\n\n    def has_header(self, sample):\n        # Creates a dictionary of types of data in each column. If any\n        # column is of a single type (say, integers), *except* for the first\n        # row, then the first row is presumed to be labels. If the type\n        # can't be determined, it is assumed to be a string in which case\n        # the length of the string is the determining factor: if all of the\n        # rows except for the first are the same length, it's a header.\n        # Finally, a 'vote' is taken at the end for each column, adding or\n        # subtracting from the likelihood of the first row being a header.\n\n        rdr = reader(StringIO(sample), self.sniff(sample))\n\n        header = next(rdr) # assume first row is header\n\n        columns = len(header)\n        columnTypes = {}\n        for i in range(columns): columnTypes[i] = None\n\n        checked = 0\n        for row in rdr:\n            # arbitrary number of rows to check, to keep it sane\n            if checked > 20:\n                break\n            checked += 1\n\n            if len(row) != columns:\n                continue # skip rows that have irregular number of columns\n\n            for col in list(columnTypes.keys()):\n\n                for thisType in [int, float, complex]:\n                    try:\n                        thisType(row[col])\n                        break\n                    except (ValueError, OverflowError):\n                        pass\n                else:\n                    # fallback to length of string\n                    thisType = len(row[col])\n\n                if thisType != columnTypes[col]:\n                    if columnTypes[col] is None: # add new column type\n                        columnTypes[col] = thisType\n                    else:\n                        # type is inconsistent, remove column from\n                        # consideration\n                        del columnTypes[col]\n\n        # finally, compare results against first row and \"vote\"\n        # on whether it's a header\n        hasHeader = 0\n        for col, colType in columnTypes.items():\n            if type(colType) == type(0): # it's a length\n                if len(header[col]) != colType:\n                    hasHeader += 1\n                else:\n                    hasHeader -= 1\n            else: # attempt typecast\n                try:\n                    colType(header[col])\n                except (ValueError, TypeError):\n                    hasHeader += 1\n                else:\n                    hasHeader -= 1\n\n        return hasHeader > 0\n"], "crypto_js.rollups.sha3": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(v,p){var d={},u=d.lib={},r=function(){},f=u.Base={extend:function(a){r.prototype=this;var b=new r;a&&b.mixIn(a);b.hasOwnProperty(\"init\")||(b.init=function(){b.$super.init.apply(this,arguments)});b.init.prototype=b;b.$super=this;return b},create:function(){var a=this.extend();a.init.apply(a,arguments);return a},init:function(){},mixIn:function(a){for(var b in a)a.hasOwnProperty(b)&&(this[b]=a[b]);a.hasOwnProperty(\"toString\")&&(this.toString=a.toString)},clone:function(){return this.init.prototype.extend(this)}},\ns=u.WordArray=f.extend({init:function(a,b){a=this.words=a||[];this.sigBytes=b!=p?b:4*a.length},toString:function(a){return(a||y).stringify(this)},concat:function(a){var b=this.words,c=a.words,j=this.sigBytes;a=a.sigBytes;this.clamp();if(j%4)for(var n=0;n<a;n++)b[j+n>>>2]|=(c[n>>>2]>>>24-8*(n%4)&255)<<24-8*((j+n)%4);else if(65535<c.length)for(n=0;n<a;n+=4)b[j+n>>>2]=c[n>>>2];else b.push.apply(b,c);this.sigBytes+=a;return this},clamp:function(){var a=this.words,b=this.sigBytes;a[b>>>2]&=4294967295<<\n32-8*(b%4);a.length=v.ceil(b/4)},clone:function(){var a=f.clone.call(this);a.words=this.words.slice(0);return a},random:function(a){for(var b=[],c=0;c<a;c+=4)b.push(4294967296*v.random()|0);return new s.init(b,a)}}),x=d.enc={},y=x.Hex={stringify:function(a){var b=a.words;a=a.sigBytes;for(var c=[],j=0;j<a;j++){var n=b[j>>>2]>>>24-8*(j%4)&255;c.push((n>>>4).toString(16));c.push((n&15).toString(16))}return c.join(\"\")},parse:function(a){for(var b=a.length,c=[],j=0;j<b;j+=2)c[j>>>3]|=parseInt(a.substr(j,\n2),16)<<24-4*(j%8);return new s.init(c,b/2)}},e=x.Latin1={stringify:function(a){var b=a.words;a=a.sigBytes;for(var c=[],j=0;j<a;j++)c.push(String.fromCharCode(b[j>>>2]>>>24-8*(j%4)&255));return c.join(\"\")},parse:function(a){for(var b=a.length,c=[],j=0;j<b;j++)c[j>>>2]|=(a.charCodeAt(j)&255)<<24-8*(j%4);return new s.init(c,b)}},q=x.Utf8={stringify:function(a){try{return decodeURIComponent(escape(e.stringify(a)))}catch(b){throw Error(\"Malformed UTF-8 data\");}},parse:function(a){return e.parse(unescape(encodeURIComponent(a)))}},\nt=u.BufferedBlockAlgorithm=f.extend({reset:function(){this._data=new s.init;this._nDataBytes=0},_append:function(a){\"string\"==typeof a&&(a=q.parse(a));this._data.concat(a);this._nDataBytes+=a.sigBytes},_process:function(a){var b=this._data,c=b.words,j=b.sigBytes,n=this.blockSize,e=j/(4*n),e=a?v.ceil(e):v.max((e|0)-this._minBufferSize,0);a=e*n;j=v.min(4*a,j);if(a){for(var f=0;f<a;f+=n)this._doProcessBlock(c,f);f=c.splice(0,a);b.sigBytes-=j}return new s.init(f,j)},clone:function(){var a=f.clone.call(this);\na._data=this._data.clone();return a},_minBufferSize:0});u.Hasher=t.extend({cfg:f.extend(),init:function(a){this.cfg=this.cfg.extend(a);this.reset()},reset:function(){t.reset.call(this);this._doReset()},update:function(a){this._append(a);this._process();return this},finalize:function(a){a&&this._append(a);return this._doFinalize()},blockSize:16,_createHelper:function(a){return function(b,c){return(new a.init(c)).finalize(b)}},_createHmacHelper:function(a){return function(b,c){return(new w.HMAC.init(a,\nc)).finalize(b)}}});var w=d.algo={};return d}(Math);\n(function(v){var p=CryptoJS,d=p.lib,u=d.Base,r=d.WordArray,p=p.x64={};p.Word=u.extend({init:function(f,s){this.high=f;this.low=s}});p.WordArray=u.extend({init:function(f,s){f=this.words=f||[];this.sigBytes=s!=v?s:8*f.length},toX32:function(){for(var f=this.words,s=f.length,d=[],p=0;p<s;p++){var e=f[p];d.push(e.high);d.push(e.low)}return r.create(d,this.sigBytes)},clone:function(){for(var f=u.clone.call(this),d=f.words=this.words.slice(0),p=d.length,r=0;r<p;r++)d[r]=d[r].clone();return f}})})();\n(function(v){for(var p=CryptoJS,d=p.lib,u=d.WordArray,r=d.Hasher,f=p.x64.Word,d=p.algo,s=[],x=[],y=[],e=1,q=0,t=0;24>t;t++){s[e+5*q]=(t+1)*(t+2)/2%64;var w=(2*e+3*q)%5,e=q%5,q=w}for(e=0;5>e;e++)for(q=0;5>q;q++)x[e+5*q]=q+5*((2*e+3*q)%5);e=1;for(q=0;24>q;q++){for(var a=w=t=0;7>a;a++){if(e&1){var b=(1<<a)-1;32>b?w^=1<<b:t^=1<<b-32}e=e&128?e<<1^113:e<<1}y[q]=f.create(t,w)}for(var c=[],e=0;25>e;e++)c[e]=f.create();d=d.SHA3=r.extend({cfg:r.cfg.extend({outputLength:512}),_doReset:function(){for(var a=this._state=\n[],b=0;25>b;b++)a[b]=new f.init;this.blockSize=(1600-2*this.cfg.outputLength)/32},_doProcessBlock:function(a,b){for(var e=this._state,f=this.blockSize/2,h=0;h<f;h++){var l=a[b+2*h],m=a[b+2*h+1],l=(l<<8|l>>>24)&16711935|(l<<24|l>>>8)&4278255360,m=(m<<8|m>>>24)&16711935|(m<<24|m>>>8)&4278255360,g=e[h];g.high^=m;g.low^=l}for(f=0;24>f;f++){for(h=0;5>h;h++){for(var d=l=0,k=0;5>k;k++)g=e[h+5*k],l^=g.high,d^=g.low;g=c[h];g.high=l;g.low=d}for(h=0;5>h;h++){g=c[(h+4)%5];l=c[(h+1)%5];m=l.high;k=l.low;l=g.high^\n(m<<1|k>>>31);d=g.low^(k<<1|m>>>31);for(k=0;5>k;k++)g=e[h+5*k],g.high^=l,g.low^=d}for(m=1;25>m;m++)g=e[m],h=g.high,g=g.low,k=s[m],32>k?(l=h<<k|g>>>32-k,d=g<<k|h>>>32-k):(l=g<<k-32|h>>>64-k,d=h<<k-32|g>>>64-k),g=c[x[m]],g.high=l,g.low=d;g=c[0];h=e[0];g.high=h.high;g.low=h.low;for(h=0;5>h;h++)for(k=0;5>k;k++)m=h+5*k,g=e[m],l=c[m],m=c[(h+1)%5+5*k],d=c[(h+2)%5+5*k],g.high=l.high^~m.high&d.high,g.low=l.low^~m.low&d.low;g=e[0];h=y[f];g.high^=h.high;g.low^=h.low}},_doFinalize:function(){var a=this._data,\nb=a.words,c=8*a.sigBytes,e=32*this.blockSize;b[c>>>5]|=1<<24-c%32;b[(v.ceil((c+1)/e)*e>>>5)-1]|=128;a.sigBytes=4*b.length;this._process();for(var a=this._state,b=this.cfg.outputLength/8,c=b/8,e=[],h=0;h<c;h++){var d=a[h],f=d.high,d=d.low,f=(f<<8|f>>>24)&16711935|(f<<24|f>>>8)&4278255360,d=(d<<8|d>>>24)&16711935|(d<<24|d>>>8)&4278255360;e.push(d);e.push(f)}return new u.init(e,b)},clone:function(){for(var a=r.clone.call(this),b=a._state=this._state.slice(0),c=0;25>c;c++)b[c]=b[c].clone();return a}});\np.SHA3=r._createHelper(d);p.HmacSHA3=r._createHmacHelper(d)})(Math);\n"], "crypto_js.rollups.sha1": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(e,m){var p={},j=p.lib={},l=function(){},f=j.Base={extend:function(a){l.prototype=this;var c=new l;a&&c.mixIn(a);c.hasOwnProperty(\"init\")||(c.init=function(){c.$super.init.apply(this,arguments)});c.init.prototype=c;c.$super=this;return c},create:function(){var a=this.extend();a.init.apply(a,arguments);return a},init:function(){},mixIn:function(a){for(var c in a)a.hasOwnProperty(c)&&(this[c]=a[c]);a.hasOwnProperty(\"toString\")&&(this.toString=a.toString)},clone:function(){return this.init.prototype.extend(this)}},\nn=j.WordArray=f.extend({init:function(a,c){a=this.words=a||[];this.sigBytes=c!=m?c:4*a.length},toString:function(a){return(a||h).stringify(this)},concat:function(a){var c=this.words,q=a.words,d=this.sigBytes;a=a.sigBytes;this.clamp();if(d%4)for(var b=0;b<a;b++)c[d+b>>>2]|=(q[b>>>2]>>>24-8*(b%4)&255)<<24-8*((d+b)%4);else if(65535<q.length)for(b=0;b<a;b+=4)c[d+b>>>2]=q[b>>>2];else c.push.apply(c,q);this.sigBytes+=a;return this},clamp:function(){var a=this.words,c=this.sigBytes;a[c>>>2]&=4294967295<<\n32-8*(c%4);a.length=e.ceil(c/4)},clone:function(){var a=f.clone.call(this);a.words=this.words.slice(0);return a},random:function(a){for(var c=[],b=0;b<a;b+=4)c.push(4294967296*e.random()|0);return new n.init(c,a)}}),b=p.enc={},h=b.Hex={stringify:function(a){var c=a.words;a=a.sigBytes;for(var b=[],d=0;d<a;d++){var f=c[d>>>2]>>>24-8*(d%4)&255;b.push((f>>>4).toString(16));b.push((f&15).toString(16))}return b.join(\"\")},parse:function(a){for(var c=a.length,b=[],d=0;d<c;d+=2)b[d>>>3]|=parseInt(a.substr(d,\n2),16)<<24-4*(d%8);return new n.init(b,c/2)}},g=b.Latin1={stringify:function(a){var c=a.words;a=a.sigBytes;for(var b=[],d=0;d<a;d++)b.push(String.fromCharCode(c[d>>>2]>>>24-8*(d%4)&255));return b.join(\"\")},parse:function(a){for(var c=a.length,b=[],d=0;d<c;d++)b[d>>>2]|=(a.charCodeAt(d)&255)<<24-8*(d%4);return new n.init(b,c)}},r=b.Utf8={stringify:function(a){try{return decodeURIComponent(escape(g.stringify(a)))}catch(c){throw Error(\"Malformed UTF-8 data\");}},parse:function(a){return g.parse(unescape(encodeURIComponent(a)))}},\nk=j.BufferedBlockAlgorithm=f.extend({reset:function(){this._data=new n.init;this._nDataBytes=0},_append:function(a){\"string\"==typeof a&&(a=r.parse(a));this._data.concat(a);this._nDataBytes+=a.sigBytes},_process:function(a){var c=this._data,b=c.words,d=c.sigBytes,f=this.blockSize,h=d/(4*f),h=a?e.ceil(h):e.max((h|0)-this._minBufferSize,0);a=h*f;d=e.min(4*a,d);if(a){for(var g=0;g<a;g+=f)this._doProcessBlock(b,g);g=b.splice(0,a);c.sigBytes-=d}return new n.init(g,d)},clone:function(){var a=f.clone.call(this);\na._data=this._data.clone();return a},_minBufferSize:0});j.Hasher=k.extend({cfg:f.extend(),init:function(a){this.cfg=this.cfg.extend(a);this.reset()},reset:function(){k.reset.call(this);this._doReset()},update:function(a){this._append(a);this._process();return this},finalize:function(a){a&&this._append(a);return this._doFinalize()},blockSize:16,_createHelper:function(a){return function(c,b){return(new a.init(b)).finalize(c)}},_createHmacHelper:function(a){return function(b,f){return(new s.HMAC.init(a,\nf)).finalize(b)}}});var s=p.algo={};return p}(Math);\n(function(){var e=CryptoJS,m=e.lib,p=m.WordArray,j=m.Hasher,l=[],m=e.algo.SHA1=j.extend({_doReset:function(){this._hash=new p.init([1732584193,4023233417,2562383102,271733878,3285377520])},_doProcessBlock:function(f,n){for(var b=this._hash.words,h=b[0],g=b[1],e=b[2],k=b[3],j=b[4],a=0;80>a;a++){if(16>a)l[a]=f[n+a]|0;else{var c=l[a-3]^l[a-8]^l[a-14]^l[a-16];l[a]=c<<1|c>>>31}c=(h<<5|h>>>27)+j+l[a];c=20>a?c+((g&e|~g&k)+1518500249):40>a?c+((g^e^k)+1859775393):60>a?c+((g&e|g&k|e&k)-1894007588):c+((g^e^\nk)-899497514);j=k;k=e;e=g<<30|g>>>2;g=h;h=c}b[0]=b[0]+h|0;b[1]=b[1]+g|0;b[2]=b[2]+e|0;b[3]=b[3]+k|0;b[4]=b[4]+j|0},_doFinalize:function(){var f=this._data,e=f.words,b=8*this._nDataBytes,h=8*f.sigBytes;e[h>>>5]|=128<<24-h%32;e[(h+64>>>9<<4)+14]=Math.floor(b/4294967296);e[(h+64>>>9<<4)+15]=b;f.sigBytes=4*e.length;this._process();return this._hash},clone:function(){var e=j.clone.call(this);e._hash=this._hash.clone();return e}});e.SHA1=j._createHelper(m);e.HmacSHA1=j._createHmacHelper(m)})();\n"], "genericpath": [".py", "\"\"\"\nPath operations common to more than one OS\nDo not use directly.  The OS specific modules import the appropriate\nfunctions from this module themselves.\n\"\"\"\nimport os\nimport stat\n\n__all__ = ['commonprefix', 'exists', 'getatime', 'getctime', 'getmtime',\n           'getsize', 'isdir', 'isfile']\n\n\n# Does a path exist?\n# This is false for dangling symbolic links on systems that support them.\ndef exists(path):\n    \"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\n    try:\n        os.stat(path)\n    except os.error:\n        return False\n    return True\n\n\n# This follows symbolic links, so both islink() and isdir() can be true\n# for the same path on systems that support symlinks\ndef isfile(path):\n    \"\"\"Test whether a path is a regular file\"\"\"\n    try:\n        st = os.stat(path)\n    except os.error:\n        return False\n    return stat.S_ISREG(st.st_mode)\n\n\n# Is a path a directory?\n# This follows symbolic links, so both islink() and isdir()\n# can be true for the same path on systems that support symlinks\ndef isdir(s):\n    \"\"\"Return true if the pathname refers to an existing directory.\"\"\"\n    try:\n        st = os.stat(s)\n    except os.error:\n        return False\n    return stat.S_ISDIR(st.st_mode)\n\n\ndef getsize(filename):\n    \"\"\"Return the size of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_size\n\n\ndef getmtime(filename):\n    \"\"\"Return the last modification time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_mtime\n\n\ndef getatime(filename):\n    \"\"\"Return the last access time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_atime\n\n\ndef getctime(filename):\n    \"\"\"Return the metadata change time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_ctime\n\n\n# Return the longest prefix of all list elements.\ndef commonprefix(m):\n    \"Given a list of pathnames, returns the longest common leading component\"\n    if not m: return ''\n    s1 = min(m)\n    s2 = max(m)\n    for i, c in enumerate(s1):\n        if c != s2[i]:\n            return s1[:i]\n    return s1\n\n# Split a path in root and extension.\n# The extension is everything starting at the last dot in the last\n# pathname component; the root is everything before that.\n# It is always true that root + ext == p.\n\n# Generic implementation of splitext, to be parametrized with\n# the separators\ndef _splitext(p, sep, altsep, extsep):\n    \"\"\"Split the extension from a pathname.\n\n    Extension is everything from the last dot to the end, ignoring\n    leading dots.  Returns \"(root, ext)\"; ext may be empty.\"\"\"\n    # NOTE: This code must work for text and bytes strings.\n\n    sepIndex = p.rfind(sep)\n    if altsep:\n        altsepIndex = p.rfind(altsep)\n        sepIndex = max(sepIndex, altsepIndex)\n\n    dotIndex = p.rfind(extsep)\n    if dotIndex > sepIndex:\n        # skip all leading dots\n        filenameIndex = sepIndex + 1\n        while filenameIndex < dotIndex:\n            if p[filenameIndex:filenameIndex+1] != extsep:\n                return p[:dotIndex], p[dotIndex:]\n            filenameIndex += 1\n\n    return p, p[:0]\n"], "stat": [".py", "\"\"\"Constants/functions for interpreting results of os.stat() and os.lstat().\n\nSuggested usage: from stat import *\n\"\"\"\n\n# Indices for stat struct members in the tuple returned by os.stat()\n\nST_MODE  = 0\nST_INO   = 1\nST_DEV   = 2\nST_NLINK = 3\nST_UID   = 4\nST_GID   = 5\nST_SIZE  = 6\nST_ATIME = 7\nST_MTIME = 8\nST_CTIME = 9\n\n# Extract bits from the mode\n\ndef S_IMODE(mode):\n    \"\"\"Return the portion of the file's mode that can be set by\n    os.chmod().\n    \"\"\"\n    return mode & 0o7777\n\ndef S_IFMT(mode):\n    \"\"\"Return the portion of the file's mode that describes the\n    file type.\n    \"\"\"\n    return mode & 0o170000\n\n# Constants used as S_IFMT() for various file types\n# (not all are implemented on all systems)\n\nS_IFDIR  = 0o040000  # directory\nS_IFCHR  = 0o020000  # character device\nS_IFBLK  = 0o060000  # block device\nS_IFREG  = 0o100000  # regular file\nS_IFIFO  = 0o010000  # fifo (named pipe)\nS_IFLNK  = 0o120000  # symbolic link\nS_IFSOCK = 0o140000  # socket file\n\n# Functions to test for each file type\n\ndef S_ISDIR(mode):\n    \"\"\"Return True if mode is from a directory.\"\"\"\n    return S_IFMT(mode) == S_IFDIR\n\ndef S_ISCHR(mode):\n    \"\"\"Return True if mode is from a character special device file.\"\"\"\n    return S_IFMT(mode) == S_IFCHR\n\ndef S_ISBLK(mode):\n    \"\"\"Return True if mode is from a block special device file.\"\"\"\n    return S_IFMT(mode) == S_IFBLK\n\ndef S_ISREG(mode):\n    \"\"\"Return True if mode is from a regular file.\"\"\"\n    return S_IFMT(mode) == S_IFREG\n\ndef S_ISFIFO(mode):\n    \"\"\"Return True if mode is from a FIFO (named pipe).\"\"\"\n    return S_IFMT(mode) == S_IFIFO\n\ndef S_ISLNK(mode):\n    \"\"\"Return True if mode is from a symbolic link.\"\"\"\n    return S_IFMT(mode) == S_IFLNK\n\ndef S_ISSOCK(mode):\n    \"\"\"Return True if mode is from a socket.\"\"\"\n    return S_IFMT(mode) == S_IFSOCK\n\n# Names for permission bits\n\nS_ISUID = 0o4000  # set UID bit\nS_ISGID = 0o2000  # set GID bit\nS_ENFMT = S_ISGID # file locking enforcement\nS_ISVTX = 0o1000  # sticky bit\nS_IREAD = 0o0400  # Unix V7 synonym for S_IRUSR\nS_IWRITE = 0o0200 # Unix V7 synonym for S_IWUSR\nS_IEXEC = 0o0100  # Unix V7 synonym for S_IXUSR\nS_IRWXU = 0o0700  # mask for owner permissions\nS_IRUSR = 0o0400  # read by owner\nS_IWUSR = 0o0200  # write by owner\nS_IXUSR = 0o0100  # execute by owner\nS_IRWXG = 0o0070  # mask for group permissions\nS_IRGRP = 0o0040  # read by group\nS_IWGRP = 0o0020  # write by group\nS_IXGRP = 0o0010  # execute by group\nS_IRWXO = 0o0007  # mask for others (not in group) permissions\nS_IROTH = 0o0004  # read by others\nS_IWOTH = 0o0002  # write by others\nS_IXOTH = 0o0001  # execute by others\n\n# Names for file flags\n\nUF_NODUMP    = 0x00000001  # do not dump file\nUF_IMMUTABLE = 0x00000002  # file may not be changed\nUF_APPEND    = 0x00000004  # file may only be appended to\nUF_OPAQUE    = 0x00000008  # directory is opaque when viewed through a union stack\nUF_NOUNLINK  = 0x00000010  # file may not be renamed or deleted\nUF_COMPRESSED = 0x00000020 # OS X: file is hfs-compressed\nUF_HIDDEN    = 0x00008000  # OS X: file should not be displayed\nSF_ARCHIVED  = 0x00010000  # file may be archived\nSF_IMMUTABLE = 0x00020000  # file may not be changed\nSF_APPEND    = 0x00040000  # file may only be appended to\nSF_NOUNLINK  = 0x00100000  # file may not be renamed or deleted\nSF_SNAPSHOT  = 0x00200000  # file is a snapshot file\n\n\n_filemode_table = (\n    ((S_IFLNK,         \"l\"),\n     (S_IFREG,         \"-\"),\n     (S_IFBLK,         \"b\"),\n     (S_IFDIR,         \"d\"),\n     (S_IFCHR,         \"c\"),\n     (S_IFIFO,         \"p\")),\n\n    ((S_IRUSR,         \"r\"),),\n    ((S_IWUSR,         \"w\"),),\n    ((S_IXUSR|S_ISUID, \"s\"),\n     (S_ISUID,         \"S\"),\n     (S_IXUSR,         \"x\")),\n\n    ((S_IRGRP,         \"r\"),),\n    ((S_IWGRP,         \"w\"),),\n    ((S_IXGRP|S_ISGID, \"s\"),\n     (S_ISGID,         \"S\"),\n     (S_IXGRP,         \"x\")),\n\n    ((S_IROTH,         \"r\"),),\n    ((S_IWOTH,         \"w\"),),\n    ((S_IXOTH|S_ISVTX, \"t\"),\n     (S_ISVTX,         \"T\"),\n     (S_IXOTH,         \"x\"))\n)\n\ndef filemode(mode):\n    \"\"\"Convert a file's mode to a string of the form '-rwxrwxrwx'.\"\"\"\n    perm = []\n    for table in _filemode_table:\n        for bit, char in table:\n            if mode & bit == bit:\n                perm.append(char)\n                break\n        else:\n            perm.append(\"-\")\n    return \"\".join(perm)\n"], "http": [".py", "# This directory is a Python package.\n", 1], "xml.sax.saxutils": [".py", "\"\"\"\\\nA library of useful helper classes to the SAX classes, for the\nconvenience of application and driver writers.\n\"\"\"\n\nimport os, urllib.parse, urllib.request\nimport io\nfrom . import handler\nfrom . import xmlreader\n\ndef __dict_replace(s, d):\n    \"\"\"Replace substrings of a string using a dictionary.\"\"\"\n    for key, value in d.items():\n        s = s.replace(key, value)\n    return s\n\ndef escape(data, entities={}):\n    \"\"\"Escape &, <, and > in a string of data.\n\n    You can escape other strings of data by passing a dictionary as\n    the optional entities parameter.  The keys and values must all be\n    strings; each key will be replaced with its corresponding value.\n    \"\"\"\n\n    # must do ampersand first\n    data = data.replace(\"&\", \"&amp;\")\n    data = data.replace(\">\", \"&gt;\")\n    data = data.replace(\"<\", \"&lt;\")\n    if entities:\n        data = __dict_replace(data, entities)\n    return data\n\ndef unescape(data, entities={}):\n    \"\"\"Unescape &amp;, &lt;, and &gt; in a string of data.\n\n    You can unescape other strings of data by passing a dictionary as\n    the optional entities parameter.  The keys and values must all be\n    strings; each key will be replaced with its corresponding value.\n    \"\"\"\n    data = data.replace(\"&lt;\", \"<\")\n    data = data.replace(\"&gt;\", \">\")\n    if entities:\n        data = __dict_replace(data, entities)\n    # must do ampersand last\n    return data.replace(\"&amp;\", \"&\")\n\ndef quoteattr(data, entities={}):\n    \"\"\"Escape and quote an attribute value.\n\n    Escape &, <, and > in a string of data, then quote it for use as\n    an attribute value.  The \\\" character will be escaped as well, if\n    necessary.\n\n    You can escape other strings of data by passing a dictionary as\n    the optional entities parameter.  The keys and values must all be\n    strings; each key will be replaced with its corresponding value.\n    \"\"\"\n    entities = entities.copy()\n    entities.update({'\\n': '&#10;', '\\r': '&#13;', '\\t':'&#9;'})\n    data = escape(data, entities)\n    if '\"' in data:\n        if \"'\" in data:\n            data = '\"%s\"' % data.replace('\"', \"&quot;\")\n        else:\n            data = \"'%s'\" % data\n    else:\n        data = '\"%s\"' % data\n    return data\n\n\ndef _gettextwriter(out, encoding):\n    if out is None:\n        import sys\n        return sys.stdout\n\n    if isinstance(out, io.TextIOBase):\n        # use a text writer as is\n        return out\n\n    # wrap a binary writer with TextIOWrapper\n    if isinstance(out, io.RawIOBase):\n        # Keep the original file open when the TextIOWrapper is\n        # destroyed\n        class _wrapper:\n            __class__ = out.__class__\n            def __getattr__(self, name):\n                return getattr(out, name)\n        buffer = _wrapper()\n        buffer.close = lambda: None\n    else:\n        # This is to handle passed objects that aren't in the\n        # IOBase hierarchy, but just have a write method\n        buffer = io.BufferedIOBase()\n        buffer.writable = lambda: True\n        buffer.write = out.write\n        try:\n            # TextIOWrapper uses this methods to determine\n            # if BOM (for UTF-16, etc) should be added\n            buffer.seekable = out.seekable\n            buffer.tell = out.tell\n        except AttributeError:\n            pass\n    return io.TextIOWrapper(buffer, encoding=encoding,\n                            errors='xmlcharrefreplace',\n                            newline='\\n',\n                            write_through=True)\n\nclass XMLGenerator(handler.ContentHandler):\n\n    def __init__(self, out=None, encoding=\"iso-8859-1\", short_empty_elements=False):\n        handler.ContentHandler.__init__(self)\n        out = _gettextwriter(out, encoding)\n        self._write = out.write\n        self._flush = out.flush\n        self._ns_contexts = [{}] # contains uri -> prefix dicts\n        self._current_context = self._ns_contexts[-1]\n        self._undeclared_ns_maps = []\n        self._encoding = encoding\n        self._short_empty_elements = short_empty_elements\n        self._pending_start_element = False\n\n    def _qname(self, name):\n        \"\"\"Builds a qualified name from a (ns_url, localname) pair\"\"\"\n        if name[0]:\n            # Per http://www.w3.org/XML/1998/namespace, The 'xml' prefix is\n            # bound by definition to http://www.w3.org/XML/1998/namespace.  It\n            # does not need to be declared and will not usually be found in\n            # self._current_context.\n            if 'http://www.w3.org/XML/1998/namespace' == name[0]:\n                return 'xml:' + name[1]\n            # The name is in a non-empty namespace\n            prefix = self._current_context[name[0]]\n            if prefix:\n                # If it is not the default namespace, prepend the prefix\n                return prefix + \":\" + name[1]\n        # Return the unqualified name\n        return name[1]\n\n    def _finish_pending_start_element(self,endElement=False):\n        if self._pending_start_element:\n            self._write('>')\n            self._pending_start_element = False\n\n    # ContentHandler methods\n\n    def startDocument(self):\n        self._write('<?xml version=\"1.0\" encoding=\"%s\"?>\\n' %\n                        self._encoding)\n\n    def endDocument(self):\n        self._flush()\n\n    def startPrefixMapping(self, prefix, uri):\n        self._ns_contexts.append(self._current_context.copy())\n        self._current_context[uri] = prefix\n        self._undeclared_ns_maps.append((prefix, uri))\n\n    def endPrefixMapping(self, prefix):\n        self._current_context = self._ns_contexts[-1]\n        del self._ns_contexts[-1]\n\n    def startElement(self, name, attrs):\n        self._finish_pending_start_element()\n        self._write('<' + name)\n        for (name, value) in attrs.items():\n            self._write(' %s=%s' % (name, quoteattr(value)))\n        if self._short_empty_elements:\n            self._pending_start_element = True\n        else:\n            self._write(\">\")\n\n    def endElement(self, name):\n        if self._pending_start_element:\n            self._write('/>')\n            self._pending_start_element = False\n        else:\n            self._write('</%s>' % name)\n\n    def startElementNS(self, name, qname, attrs):\n        self._finish_pending_start_element()\n        self._write('<' + self._qname(name))\n\n        for prefix, uri in self._undeclared_ns_maps:\n            if prefix:\n                self._write(' xmlns:%s=\"%s\"' % (prefix, uri))\n            else:\n                self._write(' xmlns=\"%s\"' % uri)\n        self._undeclared_ns_maps = []\n\n        for (name, value) in attrs.items():\n            self._write(' %s=%s' % (self._qname(name), quoteattr(value)))\n        if self._short_empty_elements:\n            self._pending_start_element = True\n        else:\n            self._write(\">\")\n\n    def endElementNS(self, name, qname):\n        if self._pending_start_element:\n            self._write('/>')\n            self._pending_start_element = False\n        else:\n            self._write('</%s>' % self._qname(name))\n\n    def characters(self, content):\n        if content:\n            self._finish_pending_start_element()\n            self._write(escape(content))\n\n    def ignorableWhitespace(self, content):\n        if content:\n            self._finish_pending_start_element()\n            self._write(content)\n\n    def processingInstruction(self, target, data):\n        self._finish_pending_start_element()\n        self._write('<?%s %s?>' % (target, data))\n\n\nclass XMLFilterBase(xmlreader.XMLReader):\n    \"\"\"This class is designed to sit between an XMLReader and the\n    client application's event handlers.  By default, it does nothing\n    but pass requests up to the reader and events on to the handlers\n    unmodified, but subclasses can override specific methods to modify\n    the event stream or the configuration requests as they pass\n    through.\"\"\"\n\n    def __init__(self, parent = None):\n        xmlreader.XMLReader.__init__(self)\n        self._parent = parent\n\n    # ErrorHandler methods\n\n    def error(self, exception):\n        self._err_handler.error(exception)\n\n    def fatalError(self, exception):\n        self._err_handler.fatalError(exception)\n\n    def warning(self, exception):\n        self._err_handler.warning(exception)\n\n    # ContentHandler methods\n\n    def setDocumentLocator(self, locator):\n        self._cont_handler.setDocumentLocator(locator)\n\n    def startDocument(self):\n        self._cont_handler.startDocument()\n\n    def endDocument(self):\n        self._cont_handler.endDocument()\n\n    def startPrefixMapping(self, prefix, uri):\n        self._cont_handler.startPrefixMapping(prefix, uri)\n\n    def endPrefixMapping(self, prefix):\n        self._cont_handler.endPrefixMapping(prefix)\n\n    def startElement(self, name, attrs):\n        self._cont_handler.startElement(name, attrs)\n\n    def endElement(self, name):\n        self._cont_handler.endElement(name)\n\n    def startElementNS(self, name, qname, attrs):\n        self._cont_handler.startElementNS(name, qname, attrs)\n\n    def endElementNS(self, name, qname):\n        self._cont_handler.endElementNS(name, qname)\n\n    def characters(self, content):\n        self._cont_handler.characters(content)\n\n    def ignorableWhitespace(self, chars):\n        self._cont_handler.ignorableWhitespace(chars)\n\n    def processingInstruction(self, target, data):\n        self._cont_handler.processingInstruction(target, data)\n\n    def skippedEntity(self, name):\n        self._cont_handler.skippedEntity(name)\n\n    # DTDHandler methods\n\n    def notationDecl(self, name, publicId, systemId):\n        self._dtd_handler.notationDecl(name, publicId, systemId)\n\n    def unparsedEntityDecl(self, name, publicId, systemId, ndata):\n        self._dtd_handler.unparsedEntityDecl(name, publicId, systemId, ndata)\n\n    # EntityResolver methods\n\n    def resolveEntity(self, publicId, systemId):\n        return self._ent_handler.resolveEntity(publicId, systemId)\n\n    # XMLReader methods\n\n    def parse(self, source):\n        self._parent.setContentHandler(self)\n        self._parent.setErrorHandler(self)\n        self._parent.setEntityResolver(self)\n        self._parent.setDTDHandler(self)\n        self._parent.parse(source)\n\n    def setLocale(self, locale):\n        self._parent.setLocale(locale)\n\n    def getFeature(self, name):\n        return self._parent.getFeature(name)\n\n    def setFeature(self, name, state):\n        self._parent.setFeature(name, state)\n\n    def getProperty(self, name):\n        return self._parent.getProperty(name)\n\n    def setProperty(self, name, value):\n        self._parent.setProperty(name, value)\n\n    # XMLFilter methods\n\n    def getParent(self):\n        return self._parent\n\n    def setParent(self, parent):\n        self._parent = parent\n\n# --- Utility functions\n\ndef prepare_input_source(source, base=\"\"):\n    \"\"\"This function takes an InputSource and an optional base URL and\n    returns a fully resolved InputSource object ready for reading.\"\"\"\n\n    if isinstance(source, str):\n        source = xmlreader.InputSource(source)\n    elif hasattr(source, \"read\"):\n        f = source\n        source = xmlreader.InputSource()\n        source.setByteStream(f)\n        if hasattr(f, \"name\"):\n            source.setSystemId(f.name)\n\n    if source.getByteStream() is None:\n        sysid = source.getSystemId()\n        basehead = os.path.dirname(os.path.normpath(base))\n        sysidfilename = os.path.join(basehead, sysid)\n        if os.path.isfile(sysidfilename):\n            source.setSystemId(sysidfilename)\n            f = open(sysidfilename, \"rb\")\n        else:\n            source.setSystemId(urllib.parse.urljoin(base, sysid))\n            f = urllib.request.urlopen(source.getSystemId())\n\n        source.setByteStream(f)\n\n    return source\n"], "warnings": [".py", "\"\"\"Python part of the warnings subsystem.\"\"\"\n\n# Note: function level imports should *not* be used\n# in this module as it may cause import lock deadlock.\n# See bug 683658.\nimport linecache\nimport sys\n\n__all__ = [\"warn\", \"showwarning\", \"formatwarning\", \"filterwarnings\",\n           \"resetwarnings\", \"catch_warnings\"]\n\n\ndef showwarning(message, category, filename, lineno, file=None, line=None):\n    \"\"\"Hook to write a warning to a file; replace if you like.\"\"\"\n    if file is None:\n        file = sys.stderr\n    try:\n        file.write(formatwarning(message, category, filename, lineno, line))\n    except IOError:\n        pass # the file (probably stderr) is invalid - this warning gets lost.\n\ndef formatwarning(message, category, filename, lineno, line=None):\n    \"\"\"Function to format a warning the standard way.\"\"\"\n    s =  \"%s:%s: %s: %s\\n\" % (filename, lineno, category.__name__, message)\n    line = linecache.getline(filename, lineno) if line is None else line\n    if line:\n        line = line.strip()\n        s += \"  %s\\n\" % line\n    return s\n\ndef filterwarnings(action, message=\"\", category=Warning, module=\"\", lineno=0,\n                   append=False):\n    \"\"\"Insert an entry into the list of warnings filters (at the front).\n\n    'action' -- one of \"error\", \"ignore\", \"always\", \"default\", \"module\",\n                or \"once\"\n    'message' -- a regex that the warning message must match\n    'category' -- a class that the warning must be a subclass of\n    'module' -- a regex that the module name must match\n    'lineno' -- an integer line number, 0 matches all warnings\n    'append' -- if true, append to the list of filters\n    \"\"\"\n    import re\n    assert action in (\"error\", \"ignore\", \"always\", \"default\", \"module\",\n                      \"once\"), \"invalid action: %r\" % (action,)\n    assert isinstance(message, str), \"message must be a string\"\n    assert isinstance(category, type), \"category must be a class\"\n    assert issubclass(category, Warning), \"category must be a Warning subclass\"\n    assert isinstance(module, str), \"module must be a string\"\n    assert isinstance(lineno, int) and lineno >= 0, \\\n           \"lineno must be an int >= 0\"\n    item = (action, re.compile(message, re.I), category,\n            re.compile(module), lineno)\n    if append:\n        filters.append(item)\n    else:\n        filters.insert(0, item)\n\ndef simplefilter(action, category=Warning, lineno=0, append=False):\n    \"\"\"Insert a simple entry into the list of warnings filters (at the front).\n\n    A simple filter matches all modules and messages.\n    'action' -- one of \"error\", \"ignore\", \"always\", \"default\", \"module\",\n                or \"once\"\n    'category' -- a class that the warning must be a subclass of\n    'lineno' -- an integer line number, 0 matches all warnings\n    'append' -- if true, append to the list of filters\n    \"\"\"\n    assert action in (\"error\", \"ignore\", \"always\", \"default\", \"module\",\n                      \"once\"), \"invalid action: %r\" % (action,)\n    assert isinstance(lineno, int) and lineno >= 0, \\\n           \"lineno must be an int >= 0\"\n    item = (action, None, category, None, lineno)\n    if append:\n        filters.append(item)\n    else:\n        filters.insert(0, item)\n\ndef resetwarnings():\n    \"\"\"Clear the list of warning filters, so that no filters are active.\"\"\"\n    filters[:] = []\n\nclass _OptionError(Exception):\n    \"\"\"Exception used by option processing helpers.\"\"\"\n    pass\n\n# Helper to process -W options passed via sys.warnoptions\ndef _processoptions(args):\n    for arg in args:\n        try:\n            _setoption(arg)\n        except _OptionError as msg:\n            print(\"Invalid -W option ignored:\", msg, file=sys.stderr)\n\n# Helper for _processoptions()\ndef _setoption(arg):\n    import re\n    parts = arg.split(':')\n    if len(parts) > 5:\n        raise _OptionError(\"too many fields (max 5): %r\" % (arg,))\n    while len(parts) < 5:\n        parts.append('')\n    action, message, category, module, lineno = [s.strip()\n                                                 for s in parts]\n    action = _getaction(action)\n    message = re.escape(message)\n    category = _getcategory(category)\n    module = re.escape(module)\n    if module:\n        module = module + '$'\n    if lineno:\n        try:\n            lineno = int(lineno)\n            if lineno < 0:\n                raise ValueError\n        except (ValueError, OverflowError):\n            raise _OptionError(\"invalid lineno %r\" % (lineno,))\n    else:\n        lineno = 0\n    filterwarnings(action, message, category, module, lineno)\n\n# Helper for _setoption()\ndef _getaction(action):\n    if not action:\n        return \"default\"\n    if action == \"all\": return \"always\" # Alias\n    for a in ('default', 'always', 'ignore', 'module', 'once', 'error'):\n        if a.startswith(action):\n            return a\n    raise _OptionError(\"invalid action: %r\" % (action,))\n\n# Helper for _setoption()\ndef _getcategory(category):\n    import re\n    if not category:\n        return Warning\n    if re.match(\"^[a-zA-Z0-9_]+$\", category):\n        try:\n            cat = eval(category)\n        except NameError:\n            raise _OptionError(\"unknown warning category: %r\" % (category,))\n    else:\n        i = category.rfind(\".\")\n        module = category[:i]\n        klass = category[i+1:]\n        try:\n            m = __import__(module, None, None, [klass])\n        except ImportError:\n            raise _OptionError(\"invalid module name: %r\" % (module,))\n        try:\n            cat = getattr(m, klass)\n        except AttributeError:\n            raise _OptionError(\"unknown warning category: %r\" % (category,))\n    if not issubclass(cat, Warning):\n        raise _OptionError(\"invalid warning category: %r\" % (category,))\n    return cat\n\n\n# Code typically replaced by _warnings\ndef warn(message, category=None, stacklevel=1):\n    \"\"\"Issue a warning, or maybe ignore it or raise an exception.\"\"\"\n    # Check if message is already a Warning object\n    if isinstance(message, Warning):\n        category = message.__class__\n    # Check category argument\n    if category is None:\n        category = UserWarning\n    assert issubclass(category, Warning)\n    # Get context information\n    try:\n        caller = sys._getframe(stacklevel)\n    except ValueError:\n        globals = sys.__dict__\n        lineno = 1\n    else:\n        globals = caller.f_globals\n        lineno = caller.f_lineno\n    if '__name__' in globals:\n        module = globals['__name__']\n    else:\n        module = \"<string>\"\n    filename = globals.get('__file__')\n    if filename:\n        fnl = filename.lower()\n        if fnl.endswith((\".pyc\", \".pyo\")):\n            filename = filename[:-1]\n    else:\n        if module == \"__main__\":\n            try:\n                filename = sys.argv[0]\n            except AttributeError:\n                # embedded interpreters don't have sys.argv, see bug #839151\n                filename = '__main__'\n        if not filename:\n            filename = module\n    registry = globals.setdefault(\"__warningregistry__\", {})\n    warn_explicit(message, category, filename, lineno, module, registry,\n                  globals)\n\ndef warn_explicit(message, category, filename, lineno,\n                  module=None, registry=None, module_globals=None):\n    lineno = int(lineno)\n    if module is None:\n        module = filename or \"<unknown>\"\n        if module[-3:].lower() == \".py\":\n            module = module[:-3] # XXX What about leading pathname?\n    if registry is None:\n        registry = {}\n    if isinstance(message, Warning):\n        text = str(message)\n        category = message.__class__\n    else:\n        text = message\n        message = category(message)\n    key = (text, category, lineno)\n    # Quick test for common case\n    if registry.get(key):\n        return\n    # Search the filters\n    for item in filters:\n        action, msg, cat, mod, ln = item\n        if ((msg is None or msg.match(text)) and\n            issubclass(category, cat) and\n            (mod is None or mod.match(module)) and\n            (ln == 0 or lineno == ln)):\n            break\n    else:\n        action = defaultaction\n    # Early exit actions\n    if action == \"ignore\":\n        registry[key] = 1\n        return\n\n    # Prime the linecache for formatting, in case the\n    # \"file\" is actually in a zipfile or something.\n    linecache.getlines(filename, module_globals)\n\n    if action == \"error\":\n        raise message\n    # Other actions\n    if action == \"once\":\n        registry[key] = 1\n        oncekey = (text, category)\n        if onceregistry.get(oncekey):\n            return\n        onceregistry[oncekey] = 1\n    elif action == \"always\":\n        pass\n    elif action == \"module\":\n        registry[key] = 1\n        altkey = (text, category, 0)\n        if registry.get(altkey):\n            return\n        registry[altkey] = 1\n    elif action == \"default\":\n        registry[key] = 1\n    else:\n        # Unrecognized actions are errors\n        raise RuntimeError(\n              \"Unrecognized action (%r) in warnings.filters:\\n %s\" %\n              (action, item))\n    if not callable(showwarning):\n        raise TypeError(\"warnings.showwarning() must be set to a \"\n                        \"function or method\")\n    # Print message and context\n    showwarning(message, category, filename, lineno)\n\n\nclass WarningMessage(object):\n\n    \"\"\"Holds the result of a single showwarning() call.\"\"\"\n\n    _WARNING_DETAILS = (\"message\", \"category\", \"filename\", \"lineno\", \"file\",\n                        \"line\")\n\n    def __init__(self, message, category, filename, lineno, file=None,\n                    line=None):\n        local_values = locals()\n        for attr in self._WARNING_DETAILS:\n            setattr(self, attr, local_values[attr])\n        self._category_name = category.__name__ if category else None\n\n    def __str__(self):\n        return (\"{message : %r, category : %r, filename : %r, lineno : %s, \"\n                    \"line : %r}\" % (self.message, self._category_name,\n                                    self.filename, self.lineno, self.line))\n\n\nclass catch_warnings(object):\n\n    \"\"\"A context manager that copies and restores the warnings filter upon\n    exiting the context.\n\n    The 'record' argument specifies whether warnings should be captured by a\n    custom implementation of warnings.showwarning() and be appended to a list\n    returned by the context manager. Otherwise None is returned by the context\n    manager. The objects appended to the list are arguments whose attributes\n    mirror the arguments to showwarning().\n\n    The 'module' argument is to specify an alternative module to the module\n    named 'warnings' and imported under that name. This argument is only useful\n    when testing the warnings module itself.\n\n    \"\"\"\n\n    def __init__(self, *, record=False, module=None):\n        \"\"\"Specify whether to record warnings and if an alternative module\n        should be used other than sys.modules['warnings'].\n\n        For compatibility with Python 3.0, please consider all arguments to be\n        keyword-only.\n\n        \"\"\"\n        self._record = record\n        self._module = sys.modules['warnings'] if module is None else module\n        self._entered = False\n\n    def __repr__(self):\n        args = []\n        if self._record:\n            args.append(\"record=True\")\n        if self._module is not sys.modules['warnings']:\n            args.append(\"module=%r\" % self._module)\n        name = type(self).__name__\n        return \"%s(%s)\" % (name, \", \".join(args))\n\n    def __enter__(self):\n        if self._entered:\n            raise RuntimeError(\"Cannot enter %r twice\" % self)\n        self._entered = True\n        self._filters = self._module.filters\n        self._module.filters = self._filters[:]\n        self._showwarning = self._module.showwarning\n        if self._record:\n            log = []\n            def showwarning(*args, **kwargs):\n                log.append(WarningMessage(*args, **kwargs))\n            self._module.showwarning = showwarning\n            return log\n        else:\n            return None\n\n    def __exit__(self, *exc_info):\n        if not self._entered:\n            raise RuntimeError(\"Cannot exit %r without entering first\" % self)\n        self._module.filters = self._filters\n        self._module.showwarning = self._showwarning\n\n\n# filters contains a sequence of filter 5-tuples\n# The components of the 5-tuple are:\n# - an action: error, ignore, always, default, module, or once\n# - a compiled regex that must match the warning message\n# - a class representing the warning category\n# - a compiled regex that must match the module that is being warned\n# - a line number for the line being warning, or 0 to mean any line\n# If either if the compiled regexs are None, match anything.\n_warnings_defaults = False\ntry:\n    from _warnings import (filters, _defaultaction, _onceregistry,\n                            warn, warn_explicit)\n    defaultaction = _defaultaction\n    onceregistry = _onceregistry\n    _warnings_defaults = True\nexcept ImportError:\n    filters = []\n    defaultaction = \"default\"\n    onceregistry = {}\n\n\n# Module initialization\n_processoptions(sys.warnoptions)\nif not _warnings_defaults:\n    silence = [ImportWarning, PendingDeprecationWarning]\n    silence.append(DeprecationWarning)\n    for cls in silence:\n        simplefilter(\"ignore\", category=cls)\n    bytes_warning = sys.flags.bytes_warning\n    if bytes_warning > 1:\n        bytes_action = \"error\"\n    elif bytes_warning:\n        bytes_action = \"default\"\n    else:\n        bytes_action = \"ignore\"\n    simplefilter(bytes_action, category=BytesWarning, append=1)\n    # resource usage warnings are enabled by default in pydebug mode\n    if hasattr(sys, 'gettotalrefcount'):\n        resource_action = \"always\"\n    else:\n        resource_action = \"ignore\"\n    simplefilter(resource_action, category=ResourceWarning, append=1)\n\ndel _warnings_defaults\n"], "html.entities": [".py", "\"\"\"HTML character entity references.\"\"\"\n\n# maps the HTML entity name to the Unicode codepoint\nname2codepoint = {\n    'AElig':    0x00c6, # latin capital letter AE = latin capital ligature AE, U+00C6 ISOlat1\n    'Aacute':   0x00c1, # latin capital letter A with acute, U+00C1 ISOlat1\n    'Acirc':    0x00c2, # latin capital letter A with circumflex, U+00C2 ISOlat1\n    'Agrave':   0x00c0, # latin capital letter A with grave = latin capital letter A grave, U+00C0 ISOlat1\n    'Alpha':    0x0391, # greek capital letter alpha, U+0391\n    'Aring':    0x00c5, # latin capital letter A with ring above = latin capital letter A ring, U+00C5 ISOlat1\n    'Atilde':   0x00c3, # latin capital letter A with tilde, U+00C3 ISOlat1\n    'Auml':     0x00c4, # latin capital letter A with diaeresis, U+00C4 ISOlat1\n    'Beta':     0x0392, # greek capital letter beta, U+0392\n    'Ccedil':   0x00c7, # latin capital letter C with cedilla, U+00C7 ISOlat1\n    'Chi':      0x03a7, # greek capital letter chi, U+03A7\n    'Dagger':   0x2021, # double dagger, U+2021 ISOpub\n    'Delta':    0x0394, # greek capital letter delta, U+0394 ISOgrk3\n    'ETH':      0x00d0, # latin capital letter ETH, U+00D0 ISOlat1\n    'Eacute':   0x00c9, # latin capital letter E with acute, U+00C9 ISOlat1\n    'Ecirc':    0x00ca, # latin capital letter E with circumflex, U+00CA ISOlat1\n    'Egrave':   0x00c8, # latin capital letter E with grave, U+00C8 ISOlat1\n    'Epsilon':  0x0395, # greek capital letter epsilon, U+0395\n    'Eta':      0x0397, # greek capital letter eta, U+0397\n    'Euml':     0x00cb, # latin capital letter E with diaeresis, U+00CB ISOlat1\n    'Gamma':    0x0393, # greek capital letter gamma, U+0393 ISOgrk3\n    'Iacute':   0x00cd, # latin capital letter I with acute, U+00CD ISOlat1\n    'Icirc':    0x00ce, # latin capital letter I with circumflex, U+00CE ISOlat1\n    'Igrave':   0x00cc, # latin capital letter I with grave, U+00CC ISOlat1\n    'Iota':     0x0399, # greek capital letter iota, U+0399\n    'Iuml':     0x00cf, # latin capital letter I with diaeresis, U+00CF ISOlat1\n    'Kappa':    0x039a, # greek capital letter kappa, U+039A\n    'Lambda':   0x039b, # greek capital letter lambda, U+039B ISOgrk3\n    'Mu':       0x039c, # greek capital letter mu, U+039C\n    'Ntilde':   0x00d1, # latin capital letter N with tilde, U+00D1 ISOlat1\n    'Nu':       0x039d, # greek capital letter nu, U+039D\n    'OElig':    0x0152, # latin capital ligature OE, U+0152 ISOlat2\n    'Oacute':   0x00d3, # latin capital letter O with acute, U+00D3 ISOlat1\n    'Ocirc':    0x00d4, # latin capital letter O with circumflex, U+00D4 ISOlat1\n    'Ograve':   0x00d2, # latin capital letter O with grave, U+00D2 ISOlat1\n    'Omega':    0x03a9, # greek capital letter omega, U+03A9 ISOgrk3\n    'Omicron':  0x039f, # greek capital letter omicron, U+039F\n    'Oslash':   0x00d8, # latin capital letter O with stroke = latin capital letter O slash, U+00D8 ISOlat1\n    'Otilde':   0x00d5, # latin capital letter O with tilde, U+00D5 ISOlat1\n    'Ouml':     0x00d6, # latin capital letter O with diaeresis, U+00D6 ISOlat1\n    'Phi':      0x03a6, # greek capital letter phi, U+03A6 ISOgrk3\n    'Pi':       0x03a0, # greek capital letter pi, U+03A0 ISOgrk3\n    'Prime':    0x2033, # double prime = seconds = inches, U+2033 ISOtech\n    'Psi':      0x03a8, # greek capital letter psi, U+03A8 ISOgrk3\n    'Rho':      0x03a1, # greek capital letter rho, U+03A1\n    'Scaron':   0x0160, # latin capital letter S with caron, U+0160 ISOlat2\n    'Sigma':    0x03a3, # greek capital letter sigma, U+03A3 ISOgrk3\n    'THORN':    0x00de, # latin capital letter THORN, U+00DE ISOlat1\n    'Tau':      0x03a4, # greek capital letter tau, U+03A4\n    'Theta':    0x0398, # greek capital letter theta, U+0398 ISOgrk3\n    'Uacute':   0x00da, # latin capital letter U with acute, U+00DA ISOlat1\n    'Ucirc':    0x00db, # latin capital letter U with circumflex, U+00DB ISOlat1\n    'Ugrave':   0x00d9, # latin capital letter U with grave, U+00D9 ISOlat1\n    'Upsilon':  0x03a5, # greek capital letter upsilon, U+03A5 ISOgrk3\n    'Uuml':     0x00dc, # latin capital letter U with diaeresis, U+00DC ISOlat1\n    'Xi':       0x039e, # greek capital letter xi, U+039E ISOgrk3\n    'Yacute':   0x00dd, # latin capital letter Y with acute, U+00DD ISOlat1\n    'Yuml':     0x0178, # latin capital letter Y with diaeresis, U+0178 ISOlat2\n    'Zeta':     0x0396, # greek capital letter zeta, U+0396\n    'aacute':   0x00e1, # latin small letter a with acute, U+00E1 ISOlat1\n    'acirc':    0x00e2, # latin small letter a with circumflex, U+00E2 ISOlat1\n    'acute':    0x00b4, # acute accent = spacing acute, U+00B4 ISOdia\n    'aelig':    0x00e6, # latin small letter ae = latin small ligature ae, U+00E6 ISOlat1\n    'agrave':   0x00e0, # latin small letter a with grave = latin small letter a grave, U+00E0 ISOlat1\n    'alefsym':  0x2135, # alef symbol = first transfinite cardinal, U+2135 NEW\n    'alpha':    0x03b1, # greek small letter alpha, U+03B1 ISOgrk3\n    'amp':      0x0026, # ampersand, U+0026 ISOnum\n    'and':      0x2227, # logical and = wedge, U+2227 ISOtech\n    'ang':      0x2220, # angle, U+2220 ISOamso\n    'aring':    0x00e5, # latin small letter a with ring above = latin small letter a ring, U+00E5 ISOlat1\n    'asymp':    0x2248, # almost equal to = asymptotic to, U+2248 ISOamsr\n    'atilde':   0x00e3, # latin small letter a with tilde, U+00E3 ISOlat1\n    'auml':     0x00e4, # latin small letter a with diaeresis, U+00E4 ISOlat1\n    'bdquo':    0x201e, # double low-9 quotation mark, U+201E NEW\n    'beta':     0x03b2, # greek small letter beta, U+03B2 ISOgrk3\n    'brvbar':   0x00a6, # broken bar = broken vertical bar, U+00A6 ISOnum\n    'bull':     0x2022, # bullet = black small circle, U+2022 ISOpub\n    'cap':      0x2229, # intersection = cap, U+2229 ISOtech\n    'ccedil':   0x00e7, # latin small letter c with cedilla, U+00E7 ISOlat1\n    'cedil':    0x00b8, # cedilla = spacing cedilla, U+00B8 ISOdia\n    'cent':     0x00a2, # cent sign, U+00A2 ISOnum\n    'chi':      0x03c7, # greek small letter chi, U+03C7 ISOgrk3\n    'circ':     0x02c6, # modifier letter circumflex accent, U+02C6 ISOpub\n    'clubs':    0x2663, # black club suit = shamrock, U+2663 ISOpub\n    'cong':     0x2245, # approximately equal to, U+2245 ISOtech\n    'copy':     0x00a9, # copyright sign, U+00A9 ISOnum\n    'crarr':    0x21b5, # downwards arrow with corner leftwards = carriage return, U+21B5 NEW\n    'cup':      0x222a, # union = cup, U+222A ISOtech\n    'curren':   0x00a4, # currency sign, U+00A4 ISOnum\n    'dArr':     0x21d3, # downwards double arrow, U+21D3 ISOamsa\n    'dagger':   0x2020, # dagger, U+2020 ISOpub\n    'darr':     0x2193, # downwards arrow, U+2193 ISOnum\n    'deg':      0x00b0, # degree sign, U+00B0 ISOnum\n    'delta':    0x03b4, # greek small letter delta, U+03B4 ISOgrk3\n    'diams':    0x2666, # black diamond suit, U+2666 ISOpub\n    'divide':   0x00f7, # division sign, U+00F7 ISOnum\n    'eacute':   0x00e9, # latin small letter e with acute, U+00E9 ISOlat1\n    'ecirc':    0x00ea, # latin small letter e with circumflex, U+00EA ISOlat1\n    'egrave':   0x00e8, # latin small letter e with grave, U+00E8 ISOlat1\n    'empty':    0x2205, # empty set = null set = diameter, U+2205 ISOamso\n    'emsp':     0x2003, # em space, U+2003 ISOpub\n    'ensp':     0x2002, # en space, U+2002 ISOpub\n    'epsilon':  0x03b5, # greek small letter epsilon, U+03B5 ISOgrk3\n    'equiv':    0x2261, # identical to, U+2261 ISOtech\n    'eta':      0x03b7, # greek small letter eta, U+03B7 ISOgrk3\n    'eth':      0x00f0, # latin small letter eth, U+00F0 ISOlat1\n    'euml':     0x00eb, # latin small letter e with diaeresis, U+00EB ISOlat1\n    'euro':     0x20ac, # euro sign, U+20AC NEW\n    'exist':    0x2203, # there exists, U+2203 ISOtech\n    'fnof':     0x0192, # latin small f with hook = function = florin, U+0192 ISOtech\n    'forall':   0x2200, # for all, U+2200 ISOtech\n    'frac12':   0x00bd, # vulgar fraction one half = fraction one half, U+00BD ISOnum\n    'frac14':   0x00bc, # vulgar fraction one quarter = fraction one quarter, U+00BC ISOnum\n    'frac34':   0x00be, # vulgar fraction three quarters = fraction three quarters, U+00BE ISOnum\n    'frasl':    0x2044, # fraction slash, U+2044 NEW\n    'gamma':    0x03b3, # greek small letter gamma, U+03B3 ISOgrk3\n    'ge':       0x2265, # greater-than or equal to, U+2265 ISOtech\n    'gt':       0x003e, # greater-than sign, U+003E ISOnum\n    'hArr':     0x21d4, # left right double arrow, U+21D4 ISOamsa\n    'harr':     0x2194, # left right arrow, U+2194 ISOamsa\n    'hearts':   0x2665, # black heart suit = valentine, U+2665 ISOpub\n    'hellip':   0x2026, # horizontal ellipsis = three dot leader, U+2026 ISOpub\n    'iacute':   0x00ed, # latin small letter i with acute, U+00ED ISOlat1\n    'icirc':    0x00ee, # latin small letter i with circumflex, U+00EE ISOlat1\n    'iexcl':    0x00a1, # inverted exclamation mark, U+00A1 ISOnum\n    'igrave':   0x00ec, # latin small letter i with grave, U+00EC ISOlat1\n    'image':    0x2111, # blackletter capital I = imaginary part, U+2111 ISOamso\n    'infin':    0x221e, # infinity, U+221E ISOtech\n    'int':      0x222b, # integral, U+222B ISOtech\n    'iota':     0x03b9, # greek small letter iota, U+03B9 ISOgrk3\n    'iquest':   0x00bf, # inverted question mark = turned question mark, U+00BF ISOnum\n    'isin':     0x2208, # element of, U+2208 ISOtech\n    'iuml':     0x00ef, # latin small letter i with diaeresis, U+00EF ISOlat1\n    'kappa':    0x03ba, # greek small letter kappa, U+03BA ISOgrk3\n    'lArr':     0x21d0, # leftwards double arrow, U+21D0 ISOtech\n    'lambda':   0x03bb, # greek small letter lambda, U+03BB ISOgrk3\n    'lang':     0x2329, # left-pointing angle bracket = bra, U+2329 ISOtech\n    'laquo':    0x00ab, # left-pointing double angle quotation mark = left pointing guillemet, U+00AB ISOnum\n    'larr':     0x2190, # leftwards arrow, U+2190 ISOnum\n    'lceil':    0x2308, # left ceiling = apl upstile, U+2308 ISOamsc\n    'ldquo':    0x201c, # left double quotation mark, U+201C ISOnum\n    'le':       0x2264, # less-than or equal to, U+2264 ISOtech\n    'lfloor':   0x230a, # left floor = apl downstile, U+230A ISOamsc\n    'lowast':   0x2217, # asterisk operator, U+2217 ISOtech\n    'loz':      0x25ca, # lozenge, U+25CA ISOpub\n    'lrm':      0x200e, # left-to-right mark, U+200E NEW RFC 2070\n    'lsaquo':   0x2039, # single left-pointing angle quotation mark, U+2039 ISO proposed\n    'lsquo':    0x2018, # left single quotation mark, U+2018 ISOnum\n    'lt':       0x003c, # less-than sign, U+003C ISOnum\n    'macr':     0x00af, # macron = spacing macron = overline = APL overbar, U+00AF ISOdia\n    'mdash':    0x2014, # em dash, U+2014 ISOpub\n    'micro':    0x00b5, # micro sign, U+00B5 ISOnum\n    'middot':   0x00b7, # middle dot = Georgian comma = Greek middle dot, U+00B7 ISOnum\n    'minus':    0x2212, # minus sign, U+2212 ISOtech\n    'mu':       0x03bc, # greek small letter mu, U+03BC ISOgrk3\n    'nabla':    0x2207, # nabla = backward difference, U+2207 ISOtech\n    'nbsp':     0x00a0, # no-break space = non-breaking space, U+00A0 ISOnum\n    'ndash':    0x2013, # en dash, U+2013 ISOpub\n    'ne':       0x2260, # not equal to, U+2260 ISOtech\n    'ni':       0x220b, # contains as member, U+220B ISOtech\n    'not':      0x00ac, # not sign, U+00AC ISOnum\n    'notin':    0x2209, # not an element of, U+2209 ISOtech\n    'nsub':     0x2284, # not a subset of, U+2284 ISOamsn\n    'ntilde':   0x00f1, # latin small letter n with tilde, U+00F1 ISOlat1\n    'nu':       0x03bd, # greek small letter nu, U+03BD ISOgrk3\n    'oacute':   0x00f3, # latin small letter o with acute, U+00F3 ISOlat1\n    'ocirc':    0x00f4, # latin small letter o with circumflex, U+00F4 ISOlat1\n    'oelig':    0x0153, # latin small ligature oe, U+0153 ISOlat2\n    'ograve':   0x00f2, # latin small letter o with grave, U+00F2 ISOlat1\n    'oline':    0x203e, # overline = spacing overscore, U+203E NEW\n    'omega':    0x03c9, # greek small letter omega, U+03C9 ISOgrk3\n    'omicron':  0x03bf, # greek small letter omicron, U+03BF NEW\n    'oplus':    0x2295, # circled plus = direct sum, U+2295 ISOamsb\n    'or':       0x2228, # logical or = vee, U+2228 ISOtech\n    'ordf':     0x00aa, # feminine ordinal indicator, U+00AA ISOnum\n    'ordm':     0x00ba, # masculine ordinal indicator, U+00BA ISOnum\n    'oslash':   0x00f8, # latin small letter o with stroke, = latin small letter o slash, U+00F8 ISOlat1\n    'otilde':   0x00f5, # latin small letter o with tilde, U+00F5 ISOlat1\n    'otimes':   0x2297, # circled times = vector product, U+2297 ISOamsb\n    'ouml':     0x00f6, # latin small letter o with diaeresis, U+00F6 ISOlat1\n    'para':     0x00b6, # pilcrow sign = paragraph sign, U+00B6 ISOnum\n    'part':     0x2202, # partial differential, U+2202 ISOtech\n    'permil':   0x2030, # per mille sign, U+2030 ISOtech\n    'perp':     0x22a5, # up tack = orthogonal to = perpendicular, U+22A5 ISOtech\n    'phi':      0x03c6, # greek small letter phi, U+03C6 ISOgrk3\n    'pi':       0x03c0, # greek small letter pi, U+03C0 ISOgrk3\n    'piv':      0x03d6, # greek pi symbol, U+03D6 ISOgrk3\n    'plusmn':   0x00b1, # plus-minus sign = plus-or-minus sign, U+00B1 ISOnum\n    'pound':    0x00a3, # pound sign, U+00A3 ISOnum\n    'prime':    0x2032, # prime = minutes = feet, U+2032 ISOtech\n    'prod':     0x220f, # n-ary product = product sign, U+220F ISOamsb\n    'prop':     0x221d, # proportional to, U+221D ISOtech\n    'psi':      0x03c8, # greek small letter psi, U+03C8 ISOgrk3\n    'quot':     0x0022, # quotation mark = APL quote, U+0022 ISOnum\n    'rArr':     0x21d2, # rightwards double arrow, U+21D2 ISOtech\n    'radic':    0x221a, # square root = radical sign, U+221A ISOtech\n    'rang':     0x232a, # right-pointing angle bracket = ket, U+232A ISOtech\n    'raquo':    0x00bb, # right-pointing double angle quotation mark = right pointing guillemet, U+00BB ISOnum\n    'rarr':     0x2192, # rightwards arrow, U+2192 ISOnum\n    'rceil':    0x2309, # right ceiling, U+2309 ISOamsc\n    'rdquo':    0x201d, # right double quotation mark, U+201D ISOnum\n    'real':     0x211c, # blackletter capital R = real part symbol, U+211C ISOamso\n    'reg':      0x00ae, # registered sign = registered trade mark sign, U+00AE ISOnum\n    'rfloor':   0x230b, # right floor, U+230B ISOamsc\n    'rho':      0x03c1, # greek small letter rho, U+03C1 ISOgrk3\n    'rlm':      0x200f, # right-to-left mark, U+200F NEW RFC 2070\n    'rsaquo':   0x203a, # single right-pointing angle quotation mark, U+203A ISO proposed\n    'rsquo':    0x2019, # right single quotation mark, U+2019 ISOnum\n    'sbquo':    0x201a, # single low-9 quotation mark, U+201A NEW\n    'scaron':   0x0161, # latin small letter s with caron, U+0161 ISOlat2\n    'sdot':     0x22c5, # dot operator, U+22C5 ISOamsb\n    'sect':     0x00a7, # section sign, U+00A7 ISOnum\n    'shy':      0x00ad, # soft hyphen = discretionary hyphen, U+00AD ISOnum\n    'sigma':    0x03c3, # greek small letter sigma, U+03C3 ISOgrk3\n    'sigmaf':   0x03c2, # greek small letter final sigma, U+03C2 ISOgrk3\n    'sim':      0x223c, # tilde operator = varies with = similar to, U+223C ISOtech\n    'spades':   0x2660, # black spade suit, U+2660 ISOpub\n    'sub':      0x2282, # subset of, U+2282 ISOtech\n    'sube':     0x2286, # subset of or equal to, U+2286 ISOtech\n    'sum':      0x2211, # n-ary sumation, U+2211 ISOamsb\n    'sup':      0x2283, # superset of, U+2283 ISOtech\n    'sup1':     0x00b9, # superscript one = superscript digit one, U+00B9 ISOnum\n    'sup2':     0x00b2, # superscript two = superscript digit two = squared, U+00B2 ISOnum\n    'sup3':     0x00b3, # superscript three = superscript digit three = cubed, U+00B3 ISOnum\n    'supe':     0x2287, # superset of or equal to, U+2287 ISOtech\n    'szlig':    0x00df, # latin small letter sharp s = ess-zed, U+00DF ISOlat1\n    'tau':      0x03c4, # greek small letter tau, U+03C4 ISOgrk3\n    'there4':   0x2234, # therefore, U+2234 ISOtech\n    'theta':    0x03b8, # greek small letter theta, U+03B8 ISOgrk3\n    'thetasym': 0x03d1, # greek small letter theta symbol, U+03D1 NEW\n    'thinsp':   0x2009, # thin space, U+2009 ISOpub\n    'thorn':    0x00fe, # latin small letter thorn with, U+00FE ISOlat1\n    'tilde':    0x02dc, # small tilde, U+02DC ISOdia\n    'times':    0x00d7, # multiplication sign, U+00D7 ISOnum\n    'trade':    0x2122, # trade mark sign, U+2122 ISOnum\n    'uArr':     0x21d1, # upwards double arrow, U+21D1 ISOamsa\n    'uacute':   0x00fa, # latin small letter u with acute, U+00FA ISOlat1\n    'uarr':     0x2191, # upwards arrow, U+2191 ISOnum\n    'ucirc':    0x00fb, # latin small letter u with circumflex, U+00FB ISOlat1\n    'ugrave':   0x00f9, # latin small letter u with grave, U+00F9 ISOlat1\n    'uml':      0x00a8, # diaeresis = spacing diaeresis, U+00A8 ISOdia\n    'upsih':    0x03d2, # greek upsilon with hook symbol, U+03D2 NEW\n    'upsilon':  0x03c5, # greek small letter upsilon, U+03C5 ISOgrk3\n    'uuml':     0x00fc, # latin small letter u with diaeresis, U+00FC ISOlat1\n    'weierp':   0x2118, # script capital P = power set = Weierstrass p, U+2118 ISOamso\n    'xi':       0x03be, # greek small letter xi, U+03BE ISOgrk3\n    'yacute':   0x00fd, # latin small letter y with acute, U+00FD ISOlat1\n    'yen':      0x00a5, # yen sign = yuan sign, U+00A5 ISOnum\n    'yuml':     0x00ff, # latin small letter y with diaeresis, U+00FF ISOlat1\n    'zeta':     0x03b6, # greek small letter zeta, U+03B6 ISOgrk3\n    'zwj':      0x200d, # zero width joiner, U+200D NEW RFC 2070\n    'zwnj':     0x200c, # zero width non-joiner, U+200C NEW RFC 2070\n}\n\n\n# maps the HTML5 named character references to the equivalent Unicode character(s)\nhtml5 = {\n    'Aacute': '\\xc1',\n    'aacute': '\\xe1',\n    'Aacute;': '\\xc1',\n    'aacute;': '\\xe1',\n    'Abreve;': '\\u0102',\n    'abreve;': '\\u0103',\n    'ac;': '\\u223e',\n    'acd;': '\\u223f',\n    'acE;': '\\u223e\\u0333',\n    'Acirc': '\\xc2',\n    'acirc': '\\xe2',\n    'Acirc;': '\\xc2',\n    'acirc;': '\\xe2',\n    'acute': '\\xb4',\n    'acute;': '\\xb4',\n    'Acy;': '\\u0410',\n    'acy;': '\\u0430',\n    'AElig': '\\xc6',\n    'aelig': '\\xe6',\n    'AElig;': '\\xc6',\n    'aelig;': '\\xe6',\n    'af;': '\\u2061',\n    'Afr;': '\\U0001d504',\n    'afr;': '\\U0001d51e',\n    'Agrave': '\\xc0',\n    'agrave': '\\xe0',\n    'Agrave;': '\\xc0',\n    'agrave;': '\\xe0',\n    'alefsym;': '\\u2135',\n    'aleph;': '\\u2135',\n    'Alpha;': '\\u0391',\n    'alpha;': '\\u03b1',\n    'Amacr;': '\\u0100',\n    'amacr;': '\\u0101',\n    'amalg;': '\\u2a3f',\n    'AMP': '&',\n    'amp': '&',\n    'AMP;': '&',\n    'amp;': '&',\n    'And;': '\\u2a53',\n    'and;': '\\u2227',\n    'andand;': '\\u2a55',\n    'andd;': '\\u2a5c',\n    'andslope;': '\\u2a58',\n    'andv;': '\\u2a5a',\n    'ang;': '\\u2220',\n    'ange;': '\\u29a4',\n    'angle;': '\\u2220',\n    'angmsd;': '\\u2221',\n    'angmsdaa;': '\\u29a8',\n    'angmsdab;': '\\u29a9',\n    'angmsdac;': '\\u29aa',\n    'angmsdad;': '\\u29ab',\n    'angmsdae;': '\\u29ac',\n    'angmsdaf;': '\\u29ad',\n    'angmsdag;': '\\u29ae',\n    'angmsdah;': '\\u29af',\n    'angrt;': '\\u221f',\n    'angrtvb;': '\\u22be',\n    'angrtvbd;': '\\u299d',\n    'angsph;': '\\u2222',\n    'angst;': '\\xc5',\n    'angzarr;': '\\u237c',\n    'Aogon;': '\\u0104',\n    'aogon;': '\\u0105',\n    'Aopf;': '\\U0001d538',\n    'aopf;': '\\U0001d552',\n    'ap;': '\\u2248',\n    'apacir;': '\\u2a6f',\n    'apE;': '\\u2a70',\n    'ape;': '\\u224a',\n    'apid;': '\\u224b',\n    'apos;': \"'\",\n    'ApplyFunction;': '\\u2061',\n    'approx;': '\\u2248',\n    'approxeq;': '\\u224a',\n    'Aring': '\\xc5',\n    'aring': '\\xe5',\n    'Aring;': '\\xc5',\n    'aring;': '\\xe5',\n    'Ascr;': '\\U0001d49c',\n    'ascr;': '\\U0001d4b6',\n    'Assign;': '\\u2254',\n    'ast;': '*',\n    'asymp;': '\\u2248',\n    'asympeq;': '\\u224d',\n    'Atilde': '\\xc3',\n    'atilde': '\\xe3',\n    'Atilde;': '\\xc3',\n    'atilde;': '\\xe3',\n    'Auml': '\\xc4',\n    'auml': '\\xe4',\n    'Auml;': '\\xc4',\n    'auml;': '\\xe4',\n    'awconint;': '\\u2233',\n    'awint;': '\\u2a11',\n    'backcong;': '\\u224c',\n    'backepsilon;': '\\u03f6',\n    'backprime;': '\\u2035',\n    'backsim;': '\\u223d',\n    'backsimeq;': '\\u22cd',\n    'Backslash;': '\\u2216',\n    'Barv;': '\\u2ae7',\n    'barvee;': '\\u22bd',\n    'Barwed;': '\\u2306',\n    'barwed;': '\\u2305',\n    'barwedge;': '\\u2305',\n    'bbrk;': '\\u23b5',\n    'bbrktbrk;': '\\u23b6',\n    'bcong;': '\\u224c',\n    'Bcy;': '\\u0411',\n    'bcy;': '\\u0431',\n    'bdquo;': '\\u201e',\n    'becaus;': '\\u2235',\n    'Because;': '\\u2235',\n    'because;': '\\u2235',\n    'bemptyv;': '\\u29b0',\n    'bepsi;': '\\u03f6',\n    'bernou;': '\\u212c',\n    'Bernoullis;': '\\u212c',\n    'Beta;': '\\u0392',\n    'beta;': '\\u03b2',\n    'beth;': '\\u2136',\n    'between;': '\\u226c',\n    'Bfr;': '\\U0001d505',\n    'bfr;': '\\U0001d51f',\n    'bigcap;': '\\u22c2',\n    'bigcirc;': '\\u25ef',\n    'bigcup;': '\\u22c3',\n    'bigodot;': '\\u2a00',\n    'bigoplus;': '\\u2a01',\n    'bigotimes;': '\\u2a02',\n    'bigsqcup;': '\\u2a06',\n    'bigstar;': '\\u2605',\n    'bigtriangledown;': '\\u25bd',\n    'bigtriangleup;': '\\u25b3',\n    'biguplus;': '\\u2a04',\n    'bigvee;': '\\u22c1',\n    'bigwedge;': '\\u22c0',\n    'bkarow;': '\\u290d',\n    'blacklozenge;': '\\u29eb',\n    'blacksquare;': '\\u25aa',\n    'blacktriangle;': '\\u25b4',\n    'blacktriangledown;': '\\u25be',\n    'blacktriangleleft;': '\\u25c2',\n    'blacktriangleright;': '\\u25b8',\n    'blank;': '\\u2423',\n    'blk12;': '\\u2592',\n    'blk14;': '\\u2591',\n    'blk34;': '\\u2593',\n    'block;': '\\u2588',\n    'bne;': '=\\u20e5',\n    'bnequiv;': '\\u2261\\u20e5',\n    'bNot;': '\\u2aed',\n    'bnot;': '\\u2310',\n    'Bopf;': '\\U0001d539',\n    'bopf;': '\\U0001d553',\n    'bot;': '\\u22a5',\n    'bottom;': '\\u22a5',\n    'bowtie;': '\\u22c8',\n    'boxbox;': '\\u29c9',\n    'boxDL;': '\\u2557',\n    'boxDl;': '\\u2556',\n    'boxdL;': '\\u2555',\n    'boxdl;': '\\u2510',\n    'boxDR;': '\\u2554',\n    'boxDr;': '\\u2553',\n    'boxdR;': '\\u2552',\n    'boxdr;': '\\u250c',\n    'boxH;': '\\u2550',\n    'boxh;': '\\u2500',\n    'boxHD;': '\\u2566',\n    'boxHd;': '\\u2564',\n    'boxhD;': '\\u2565',\n    'boxhd;': '\\u252c',\n    'boxHU;': '\\u2569',\n    'boxHu;': '\\u2567',\n    'boxhU;': '\\u2568',\n    'boxhu;': '\\u2534',\n    'boxminus;': '\\u229f',\n    'boxplus;': '\\u229e',\n    'boxtimes;': '\\u22a0',\n    'boxUL;': '\\u255d',\n    'boxUl;': '\\u255c',\n    'boxuL;': '\\u255b',\n    'boxul;': '\\u2518',\n    'boxUR;': '\\u255a',\n    'boxUr;': '\\u2559',\n    'boxuR;': '\\u2558',\n    'boxur;': '\\u2514',\n    'boxV;': '\\u2551',\n    'boxv;': '\\u2502',\n    'boxVH;': '\\u256c',\n    'boxVh;': '\\u256b',\n    'boxvH;': '\\u256a',\n    'boxvh;': '\\u253c',\n    'boxVL;': '\\u2563',\n    'boxVl;': '\\u2562',\n    'boxvL;': '\\u2561',\n    'boxvl;': '\\u2524',\n    'boxVR;': '\\u2560',\n    'boxVr;': '\\u255f',\n    'boxvR;': '\\u255e',\n    'boxvr;': '\\u251c',\n    'bprime;': '\\u2035',\n    'Breve;': '\\u02d8',\n    'breve;': '\\u02d8',\n    'brvbar': '\\xa6',\n    'brvbar;': '\\xa6',\n    'Bscr;': '\\u212c',\n    'bscr;': '\\U0001d4b7',\n    'bsemi;': '\\u204f',\n    'bsim;': '\\u223d',\n    'bsime;': '\\u22cd',\n    'bsol;': '\\\\',\n    'bsolb;': '\\u29c5',\n    'bsolhsub;': '\\u27c8',\n    'bull;': '\\u2022',\n    'bullet;': '\\u2022',\n    'bump;': '\\u224e',\n    'bumpE;': '\\u2aae',\n    'bumpe;': '\\u224f',\n    'Bumpeq;': '\\u224e',\n    'bumpeq;': '\\u224f',\n    'Cacute;': '\\u0106',\n    'cacute;': '\\u0107',\n    'Cap;': '\\u22d2',\n    'cap;': '\\u2229',\n    'capand;': '\\u2a44',\n    'capbrcup;': '\\u2a49',\n    'capcap;': '\\u2a4b',\n    'capcup;': '\\u2a47',\n    'capdot;': '\\u2a40',\n    'CapitalDifferentialD;': '\\u2145',\n    'caps;': '\\u2229\\ufe00',\n    'caret;': '\\u2041',\n    'caron;': '\\u02c7',\n    'Cayleys;': '\\u212d',\n    'ccaps;': '\\u2a4d',\n    'Ccaron;': '\\u010c',\n    'ccaron;': '\\u010d',\n    'Ccedil': '\\xc7',\n    'ccedil': '\\xe7',\n    'Ccedil;': '\\xc7',\n    'ccedil;': '\\xe7',\n    'Ccirc;': '\\u0108',\n    'ccirc;': '\\u0109',\n    'Cconint;': '\\u2230',\n    'ccups;': '\\u2a4c',\n    'ccupssm;': '\\u2a50',\n    'Cdot;': '\\u010a',\n    'cdot;': '\\u010b',\n    'cedil': '\\xb8',\n    'cedil;': '\\xb8',\n    'Cedilla;': '\\xb8',\n    'cemptyv;': '\\u29b2',\n    'cent': '\\xa2',\n    'cent;': '\\xa2',\n    'CenterDot;': '\\xb7',\n    'centerdot;': '\\xb7',\n    'Cfr;': '\\u212d',\n    'cfr;': '\\U0001d520',\n    'CHcy;': '\\u0427',\n    'chcy;': '\\u0447',\n    'check;': '\\u2713',\n    'checkmark;': '\\u2713',\n    'Chi;': '\\u03a7',\n    'chi;': '\\u03c7',\n    'cir;': '\\u25cb',\n    'circ;': '\\u02c6',\n    'circeq;': '\\u2257',\n    'circlearrowleft;': '\\u21ba',\n    'circlearrowright;': '\\u21bb',\n    'circledast;': '\\u229b',\n    'circledcirc;': '\\u229a',\n    'circleddash;': '\\u229d',\n    'CircleDot;': '\\u2299',\n    'circledR;': '\\xae',\n    'circledS;': '\\u24c8',\n    'CircleMinus;': '\\u2296',\n    'CirclePlus;': '\\u2295',\n    'CircleTimes;': '\\u2297',\n    'cirE;': '\\u29c3',\n    'cire;': '\\u2257',\n    'cirfnint;': '\\u2a10',\n    'cirmid;': '\\u2aef',\n    'cirscir;': '\\u29c2',\n    'ClockwiseContourIntegral;': '\\u2232',\n    'CloseCurlyDoubleQuote;': '\\u201d',\n    'CloseCurlyQuote;': '\\u2019',\n    'clubs;': '\\u2663',\n    'clubsuit;': '\\u2663',\n    'Colon;': '\\u2237',\n    'colon;': ':',\n    'Colone;': '\\u2a74',\n    'colone;': '\\u2254',\n    'coloneq;': '\\u2254',\n    'comma;': ',',\n    'commat;': '@',\n    'comp;': '\\u2201',\n    'compfn;': '\\u2218',\n    'complement;': '\\u2201',\n    'complexes;': '\\u2102',\n    'cong;': '\\u2245',\n    'congdot;': '\\u2a6d',\n    'Congruent;': '\\u2261',\n    'Conint;': '\\u222f',\n    'conint;': '\\u222e',\n    'ContourIntegral;': '\\u222e',\n    'Copf;': '\\u2102',\n    'copf;': '\\U0001d554',\n    'coprod;': '\\u2210',\n    'Coproduct;': '\\u2210',\n    'COPY': '\\xa9',\n    'copy': '\\xa9',\n    'COPY;': '\\xa9',\n    'copy;': '\\xa9',\n    'copysr;': '\\u2117',\n    'CounterClockwiseContourIntegral;': '\\u2233',\n    'crarr;': '\\u21b5',\n    'Cross;': '\\u2a2f',\n    'cross;': '\\u2717',\n    'Cscr;': '\\U0001d49e',\n    'cscr;': '\\U0001d4b8',\n    'csub;': '\\u2acf',\n    'csube;': '\\u2ad1',\n    'csup;': '\\u2ad0',\n    'csupe;': '\\u2ad2',\n    'ctdot;': '\\u22ef',\n    'cudarrl;': '\\u2938',\n    'cudarrr;': '\\u2935',\n    'cuepr;': '\\u22de',\n    'cuesc;': '\\u22df',\n    'cularr;': '\\u21b6',\n    'cularrp;': '\\u293d',\n    'Cup;': '\\u22d3',\n    'cup;': '\\u222a',\n    'cupbrcap;': '\\u2a48',\n    'CupCap;': '\\u224d',\n    'cupcap;': '\\u2a46',\n    'cupcup;': '\\u2a4a',\n    'cupdot;': '\\u228d',\n    'cupor;': '\\u2a45',\n    'cups;': '\\u222a\\ufe00',\n    'curarr;': '\\u21b7',\n    'curarrm;': '\\u293c',\n    'curlyeqprec;': '\\u22de',\n    'curlyeqsucc;': '\\u22df',\n    'curlyvee;': '\\u22ce',\n    'curlywedge;': '\\u22cf',\n    'curren': '\\xa4',\n    'curren;': '\\xa4',\n    'curvearrowleft;': '\\u21b6',\n    'curvearrowright;': '\\u21b7',\n    'cuvee;': '\\u22ce',\n    'cuwed;': '\\u22cf',\n    'cwconint;': '\\u2232',\n    'cwint;': '\\u2231',\n    'cylcty;': '\\u232d',\n    'Dagger;': '\\u2021',\n    'dagger;': '\\u2020',\n    'daleth;': '\\u2138',\n    'Darr;': '\\u21a1',\n    'dArr;': '\\u21d3',\n    'darr;': '\\u2193',\n    'dash;': '\\u2010',\n    'Dashv;': '\\u2ae4',\n    'dashv;': '\\u22a3',\n    'dbkarow;': '\\u290f',\n    'dblac;': '\\u02dd',\n    'Dcaron;': '\\u010e',\n    'dcaron;': '\\u010f',\n    'Dcy;': '\\u0414',\n    'dcy;': '\\u0434',\n    'DD;': '\\u2145',\n    'dd;': '\\u2146',\n    'ddagger;': '\\u2021',\n    'ddarr;': '\\u21ca',\n    'DDotrahd;': '\\u2911',\n    'ddotseq;': '\\u2a77',\n    'deg': '\\xb0',\n    'deg;': '\\xb0',\n    'Del;': '\\u2207',\n    'Delta;': '\\u0394',\n    'delta;': '\\u03b4',\n    'demptyv;': '\\u29b1',\n    'dfisht;': '\\u297f',\n    'Dfr;': '\\U0001d507',\n    'dfr;': '\\U0001d521',\n    'dHar;': '\\u2965',\n    'dharl;': '\\u21c3',\n    'dharr;': '\\u21c2',\n    'DiacriticalAcute;': '\\xb4',\n    'DiacriticalDot;': '\\u02d9',\n    'DiacriticalDoubleAcute;': '\\u02dd',\n    'DiacriticalGrave;': '`',\n    'DiacriticalTilde;': '\\u02dc',\n    'diam;': '\\u22c4',\n    'Diamond;': '\\u22c4',\n    'diamond;': '\\u22c4',\n    'diamondsuit;': '\\u2666',\n    'diams;': '\\u2666',\n    'die;': '\\xa8',\n    'DifferentialD;': '\\u2146',\n    'digamma;': '\\u03dd',\n    'disin;': '\\u22f2',\n    'div;': '\\xf7',\n    'divide': '\\xf7',\n    'divide;': '\\xf7',\n    'divideontimes;': '\\u22c7',\n    'divonx;': '\\u22c7',\n    'DJcy;': '\\u0402',\n    'djcy;': '\\u0452',\n    'dlcorn;': '\\u231e',\n    'dlcrop;': '\\u230d',\n    'dollar;': '$',\n    'Dopf;': '\\U0001d53b',\n    'dopf;': '\\U0001d555',\n    'Dot;': '\\xa8',\n    'dot;': '\\u02d9',\n    'DotDot;': '\\u20dc',\n    'doteq;': '\\u2250',\n    'doteqdot;': '\\u2251',\n    'DotEqual;': '\\u2250',\n    'dotminus;': '\\u2238',\n    'dotplus;': '\\u2214',\n    'dotsquare;': '\\u22a1',\n    'doublebarwedge;': '\\u2306',\n    'DoubleContourIntegral;': '\\u222f',\n    'DoubleDot;': '\\xa8',\n    'DoubleDownArrow;': '\\u21d3',\n    'DoubleLeftArrow;': '\\u21d0',\n    'DoubleLeftRightArrow;': '\\u21d4',\n    'DoubleLeftTee;': '\\u2ae4',\n    'DoubleLongLeftArrow;': '\\u27f8',\n    'DoubleLongLeftRightArrow;': '\\u27fa',\n    'DoubleLongRightArrow;': '\\u27f9',\n    'DoubleRightArrow;': '\\u21d2',\n    'DoubleRightTee;': '\\u22a8',\n    'DoubleUpArrow;': '\\u21d1',\n    'DoubleUpDownArrow;': '\\u21d5',\n    'DoubleVerticalBar;': '\\u2225',\n    'DownArrow;': '\\u2193',\n    'Downarrow;': '\\u21d3',\n    'downarrow;': '\\u2193',\n    'DownArrowBar;': '\\u2913',\n    'DownArrowUpArrow;': '\\u21f5',\n    'DownBreve;': '\\u0311',\n    'downdownarrows;': '\\u21ca',\n    'downharpoonleft;': '\\u21c3',\n    'downharpoonright;': '\\u21c2',\n    'DownLeftRightVector;': '\\u2950',\n    'DownLeftTeeVector;': '\\u295e',\n    'DownLeftVector;': '\\u21bd',\n    'DownLeftVectorBar;': '\\u2956',\n    'DownRightTeeVector;': '\\u295f',\n    'DownRightVector;': '\\u21c1',\n    'DownRightVectorBar;': '\\u2957',\n    'DownTee;': '\\u22a4',\n    'DownTeeArrow;': '\\u21a7',\n    'drbkarow;': '\\u2910',\n    'drcorn;': '\\u231f',\n    'drcrop;': '\\u230c',\n    'Dscr;': '\\U0001d49f',\n    'dscr;': '\\U0001d4b9',\n    'DScy;': '\\u0405',\n    'dscy;': '\\u0455',\n    'dsol;': '\\u29f6',\n    'Dstrok;': '\\u0110',\n    'dstrok;': '\\u0111',\n    'dtdot;': '\\u22f1',\n    'dtri;': '\\u25bf',\n    'dtrif;': '\\u25be',\n    'duarr;': '\\u21f5',\n    'duhar;': '\\u296f',\n    'dwangle;': '\\u29a6',\n    'DZcy;': '\\u040f',\n    'dzcy;': '\\u045f',\n    'dzigrarr;': '\\u27ff',\n    'Eacute': '\\xc9',\n    'eacute': '\\xe9',\n    'Eacute;': '\\xc9',\n    'eacute;': '\\xe9',\n    'easter;': '\\u2a6e',\n    'Ecaron;': '\\u011a',\n    'ecaron;': '\\u011b',\n    'ecir;': '\\u2256',\n    'Ecirc': '\\xca',\n    'ecirc': '\\xea',\n    'Ecirc;': '\\xca',\n    'ecirc;': '\\xea',\n    'ecolon;': '\\u2255',\n    'Ecy;': '\\u042d',\n    'ecy;': '\\u044d',\n    'eDDot;': '\\u2a77',\n    'Edot;': '\\u0116',\n    'eDot;': '\\u2251',\n    'edot;': '\\u0117',\n    'ee;': '\\u2147',\n    'efDot;': '\\u2252',\n    'Efr;': '\\U0001d508',\n    'efr;': '\\U0001d522',\n    'eg;': '\\u2a9a',\n    'Egrave': '\\xc8',\n    'egrave': '\\xe8',\n    'Egrave;': '\\xc8',\n    'egrave;': '\\xe8',\n    'egs;': '\\u2a96',\n    'egsdot;': '\\u2a98',\n    'el;': '\\u2a99',\n    'Element;': '\\u2208',\n    'elinters;': '\\u23e7',\n    'ell;': '\\u2113',\n    'els;': '\\u2a95',\n    'elsdot;': '\\u2a97',\n    'Emacr;': '\\u0112',\n    'emacr;': '\\u0113',\n    'empty;': '\\u2205',\n    'emptyset;': '\\u2205',\n    'EmptySmallSquare;': '\\u25fb',\n    'emptyv;': '\\u2205',\n    'EmptyVerySmallSquare;': '\\u25ab',\n    'emsp13;': '\\u2004',\n    'emsp14;': '\\u2005',\n    'emsp;': '\\u2003',\n    'ENG;': '\\u014a',\n    'eng;': '\\u014b',\n    'ensp;': '\\u2002',\n    'Eogon;': '\\u0118',\n    'eogon;': '\\u0119',\n    'Eopf;': '\\U0001d53c',\n    'eopf;': '\\U0001d556',\n    'epar;': '\\u22d5',\n    'eparsl;': '\\u29e3',\n    'eplus;': '\\u2a71',\n    'epsi;': '\\u03b5',\n    'Epsilon;': '\\u0395',\n    'epsilon;': '\\u03b5',\n    'epsiv;': '\\u03f5',\n    'eqcirc;': '\\u2256',\n    'eqcolon;': '\\u2255',\n    'eqsim;': '\\u2242',\n    'eqslantgtr;': '\\u2a96',\n    'eqslantless;': '\\u2a95',\n    'Equal;': '\\u2a75',\n    'equals;': '=',\n    'EqualTilde;': '\\u2242',\n    'equest;': '\\u225f',\n    'Equilibrium;': '\\u21cc',\n    'equiv;': '\\u2261',\n    'equivDD;': '\\u2a78',\n    'eqvparsl;': '\\u29e5',\n    'erarr;': '\\u2971',\n    'erDot;': '\\u2253',\n    'Escr;': '\\u2130',\n    'escr;': '\\u212f',\n    'esdot;': '\\u2250',\n    'Esim;': '\\u2a73',\n    'esim;': '\\u2242',\n    'Eta;': '\\u0397',\n    'eta;': '\\u03b7',\n    'ETH': '\\xd0',\n    'eth': '\\xf0',\n    'ETH;': '\\xd0',\n    'eth;': '\\xf0',\n    'Euml': '\\xcb',\n    'euml': '\\xeb',\n    'Euml;': '\\xcb',\n    'euml;': '\\xeb',\n    'euro;': '\\u20ac',\n    'excl;': '!',\n    'exist;': '\\u2203',\n    'Exists;': '\\u2203',\n    'expectation;': '\\u2130',\n    'ExponentialE;': '\\u2147',\n    'exponentiale;': '\\u2147',\n    'fallingdotseq;': '\\u2252',\n    'Fcy;': '\\u0424',\n    'fcy;': '\\u0444',\n    'female;': '\\u2640',\n    'ffilig;': '\\ufb03',\n    'fflig;': '\\ufb00',\n    'ffllig;': '\\ufb04',\n    'Ffr;': '\\U0001d509',\n    'ffr;': '\\U0001d523',\n    'filig;': '\\ufb01',\n    'FilledSmallSquare;': '\\u25fc',\n    'FilledVerySmallSquare;': '\\u25aa',\n    'fjlig;': 'fj',\n    'flat;': '\\u266d',\n    'fllig;': '\\ufb02',\n    'fltns;': '\\u25b1',\n    'fnof;': '\\u0192',\n    'Fopf;': '\\U0001d53d',\n    'fopf;': '\\U0001d557',\n    'ForAll;': '\\u2200',\n    'forall;': '\\u2200',\n    'fork;': '\\u22d4',\n    'forkv;': '\\u2ad9',\n    'Fouriertrf;': '\\u2131',\n    'fpartint;': '\\u2a0d',\n    'frac12': '\\xbd',\n    'frac12;': '\\xbd',\n    'frac13;': '\\u2153',\n    'frac14': '\\xbc',\n    'frac14;': '\\xbc',\n    'frac15;': '\\u2155',\n    'frac16;': '\\u2159',\n    'frac18;': '\\u215b',\n    'frac23;': '\\u2154',\n    'frac25;': '\\u2156',\n    'frac34': '\\xbe',\n    'frac34;': '\\xbe',\n    'frac35;': '\\u2157',\n    'frac38;': '\\u215c',\n    'frac45;': '\\u2158',\n    'frac56;': '\\u215a',\n    'frac58;': '\\u215d',\n    'frac78;': '\\u215e',\n    'frasl;': '\\u2044',\n    'frown;': '\\u2322',\n    'Fscr;': '\\u2131',\n    'fscr;': '\\U0001d4bb',\n    'gacute;': '\\u01f5',\n    'Gamma;': '\\u0393',\n    'gamma;': '\\u03b3',\n    'Gammad;': '\\u03dc',\n    'gammad;': '\\u03dd',\n    'gap;': '\\u2a86',\n    'Gbreve;': '\\u011e',\n    'gbreve;': '\\u011f',\n    'Gcedil;': '\\u0122',\n    'Gcirc;': '\\u011c',\n    'gcirc;': '\\u011d',\n    'Gcy;': '\\u0413',\n    'gcy;': '\\u0433',\n    'Gdot;': '\\u0120',\n    'gdot;': '\\u0121',\n    'gE;': '\\u2267',\n    'ge;': '\\u2265',\n    'gEl;': '\\u2a8c',\n    'gel;': '\\u22db',\n    'geq;': '\\u2265',\n    'geqq;': '\\u2267',\n    'geqslant;': '\\u2a7e',\n    'ges;': '\\u2a7e',\n    'gescc;': '\\u2aa9',\n    'gesdot;': '\\u2a80',\n    'gesdoto;': '\\u2a82',\n    'gesdotol;': '\\u2a84',\n    'gesl;': '\\u22db\\ufe00',\n    'gesles;': '\\u2a94',\n    'Gfr;': '\\U0001d50a',\n    'gfr;': '\\U0001d524',\n    'Gg;': '\\u22d9',\n    'gg;': '\\u226b',\n    'ggg;': '\\u22d9',\n    'gimel;': '\\u2137',\n    'GJcy;': '\\u0403',\n    'gjcy;': '\\u0453',\n    'gl;': '\\u2277',\n    'gla;': '\\u2aa5',\n    'glE;': '\\u2a92',\n    'glj;': '\\u2aa4',\n    'gnap;': '\\u2a8a',\n    'gnapprox;': '\\u2a8a',\n    'gnE;': '\\u2269',\n    'gne;': '\\u2a88',\n    'gneq;': '\\u2a88',\n    'gneqq;': '\\u2269',\n    'gnsim;': '\\u22e7',\n    'Gopf;': '\\U0001d53e',\n    'gopf;': '\\U0001d558',\n    'grave;': '`',\n    'GreaterEqual;': '\\u2265',\n    'GreaterEqualLess;': '\\u22db',\n    'GreaterFullEqual;': '\\u2267',\n    'GreaterGreater;': '\\u2aa2',\n    'GreaterLess;': '\\u2277',\n    'GreaterSlantEqual;': '\\u2a7e',\n    'GreaterTilde;': '\\u2273',\n    'Gscr;': '\\U0001d4a2',\n    'gscr;': '\\u210a',\n    'gsim;': '\\u2273',\n    'gsime;': '\\u2a8e',\n    'gsiml;': '\\u2a90',\n    'GT': '>',\n    'gt': '>',\n    'GT;': '>',\n    'Gt;': '\\u226b',\n    'gt;': '>',\n    'gtcc;': '\\u2aa7',\n    'gtcir;': '\\u2a7a',\n    'gtdot;': '\\u22d7',\n    'gtlPar;': '\\u2995',\n    'gtquest;': '\\u2a7c',\n    'gtrapprox;': '\\u2a86',\n    'gtrarr;': '\\u2978',\n    'gtrdot;': '\\u22d7',\n    'gtreqless;': '\\u22db',\n    'gtreqqless;': '\\u2a8c',\n    'gtrless;': '\\u2277',\n    'gtrsim;': '\\u2273',\n    'gvertneqq;': '\\u2269\\ufe00',\n    'gvnE;': '\\u2269\\ufe00',\n    'Hacek;': '\\u02c7',\n    'hairsp;': '\\u200a',\n    'half;': '\\xbd',\n    'hamilt;': '\\u210b',\n    'HARDcy;': '\\u042a',\n    'hardcy;': '\\u044a',\n    'hArr;': '\\u21d4',\n    'harr;': '\\u2194',\n    'harrcir;': '\\u2948',\n    'harrw;': '\\u21ad',\n    'Hat;': '^',\n    'hbar;': '\\u210f',\n    'Hcirc;': '\\u0124',\n    'hcirc;': '\\u0125',\n    'hearts;': '\\u2665',\n    'heartsuit;': '\\u2665',\n    'hellip;': '\\u2026',\n    'hercon;': '\\u22b9',\n    'Hfr;': '\\u210c',\n    'hfr;': '\\U0001d525',\n    'HilbertSpace;': '\\u210b',\n    'hksearow;': '\\u2925',\n    'hkswarow;': '\\u2926',\n    'hoarr;': '\\u21ff',\n    'homtht;': '\\u223b',\n    'hookleftarrow;': '\\u21a9',\n    'hookrightarrow;': '\\u21aa',\n    'Hopf;': '\\u210d',\n    'hopf;': '\\U0001d559',\n    'horbar;': '\\u2015',\n    'HorizontalLine;': '\\u2500',\n    'Hscr;': '\\u210b',\n    'hscr;': '\\U0001d4bd',\n    'hslash;': '\\u210f',\n    'Hstrok;': '\\u0126',\n    'hstrok;': '\\u0127',\n    'HumpDownHump;': '\\u224e',\n    'HumpEqual;': '\\u224f',\n    'hybull;': '\\u2043',\n    'hyphen;': '\\u2010',\n    'Iacute': '\\xcd',\n    'iacute': '\\xed',\n    'Iacute;': '\\xcd',\n    'iacute;': '\\xed',\n    'ic;': '\\u2063',\n    'Icirc': '\\xce',\n    'icirc': '\\xee',\n    'Icirc;': '\\xce',\n    'icirc;': '\\xee',\n    'Icy;': '\\u0418',\n    'icy;': '\\u0438',\n    'Idot;': '\\u0130',\n    'IEcy;': '\\u0415',\n    'iecy;': '\\u0435',\n    'iexcl': '\\xa1',\n    'iexcl;': '\\xa1',\n    'iff;': '\\u21d4',\n    'Ifr;': '\\u2111',\n    'ifr;': '\\U0001d526',\n    'Igrave': '\\xcc',\n    'igrave': '\\xec',\n    'Igrave;': '\\xcc',\n    'igrave;': '\\xec',\n    'ii;': '\\u2148',\n    'iiiint;': '\\u2a0c',\n    'iiint;': '\\u222d',\n    'iinfin;': '\\u29dc',\n    'iiota;': '\\u2129',\n    'IJlig;': '\\u0132',\n    'ijlig;': '\\u0133',\n    'Im;': '\\u2111',\n    'Imacr;': '\\u012a',\n    'imacr;': '\\u012b',\n    'image;': '\\u2111',\n    'ImaginaryI;': '\\u2148',\n    'imagline;': '\\u2110',\n    'imagpart;': '\\u2111',\n    'imath;': '\\u0131',\n    'imof;': '\\u22b7',\n    'imped;': '\\u01b5',\n    'Implies;': '\\u21d2',\n    'in;': '\\u2208',\n    'incare;': '\\u2105',\n    'infin;': '\\u221e',\n    'infintie;': '\\u29dd',\n    'inodot;': '\\u0131',\n    'Int;': '\\u222c',\n    'int;': '\\u222b',\n    'intcal;': '\\u22ba',\n    'integers;': '\\u2124',\n    'Integral;': '\\u222b',\n    'intercal;': '\\u22ba',\n    'Intersection;': '\\u22c2',\n    'intlarhk;': '\\u2a17',\n    'intprod;': '\\u2a3c',\n    'InvisibleComma;': '\\u2063',\n    'InvisibleTimes;': '\\u2062',\n    'IOcy;': '\\u0401',\n    'iocy;': '\\u0451',\n    'Iogon;': '\\u012e',\n    'iogon;': '\\u012f',\n    'Iopf;': '\\U0001d540',\n    'iopf;': '\\U0001d55a',\n    'Iota;': '\\u0399',\n    'iota;': '\\u03b9',\n    'iprod;': '\\u2a3c',\n    'iquest': '\\xbf',\n    'iquest;': '\\xbf',\n    'Iscr;': '\\u2110',\n    'iscr;': '\\U0001d4be',\n    'isin;': '\\u2208',\n    'isindot;': '\\u22f5',\n    'isinE;': '\\u22f9',\n    'isins;': '\\u22f4',\n    'isinsv;': '\\u22f3',\n    'isinv;': '\\u2208',\n    'it;': '\\u2062',\n    'Itilde;': '\\u0128',\n    'itilde;': '\\u0129',\n    'Iukcy;': '\\u0406',\n    'iukcy;': '\\u0456',\n    'Iuml': '\\xcf',\n    'iuml': '\\xef',\n    'Iuml;': '\\xcf',\n    'iuml;': '\\xef',\n    'Jcirc;': '\\u0134',\n    'jcirc;': '\\u0135',\n    'Jcy;': '\\u0419',\n    'jcy;': '\\u0439',\n    'Jfr;': '\\U0001d50d',\n    'jfr;': '\\U0001d527',\n    'jmath;': '\\u0237',\n    'Jopf;': '\\U0001d541',\n    'jopf;': '\\U0001d55b',\n    'Jscr;': '\\U0001d4a5',\n    'jscr;': '\\U0001d4bf',\n    'Jsercy;': '\\u0408',\n    'jsercy;': '\\u0458',\n    'Jukcy;': '\\u0404',\n    'jukcy;': '\\u0454',\n    'Kappa;': '\\u039a',\n    'kappa;': '\\u03ba',\n    'kappav;': '\\u03f0',\n    'Kcedil;': '\\u0136',\n    'kcedil;': '\\u0137',\n    'Kcy;': '\\u041a',\n    'kcy;': '\\u043a',\n    'Kfr;': '\\U0001d50e',\n    'kfr;': '\\U0001d528',\n    'kgreen;': '\\u0138',\n    'KHcy;': '\\u0425',\n    'khcy;': '\\u0445',\n    'KJcy;': '\\u040c',\n    'kjcy;': '\\u045c',\n    'Kopf;': '\\U0001d542',\n    'kopf;': '\\U0001d55c',\n    'Kscr;': '\\U0001d4a6',\n    'kscr;': '\\U0001d4c0',\n    'lAarr;': '\\u21da',\n    'Lacute;': '\\u0139',\n    'lacute;': '\\u013a',\n    'laemptyv;': '\\u29b4',\n    'lagran;': '\\u2112',\n    'Lambda;': '\\u039b',\n    'lambda;': '\\u03bb',\n    'Lang;': '\\u27ea',\n    'lang;': '\\u27e8',\n    'langd;': '\\u2991',\n    'langle;': '\\u27e8',\n    'lap;': '\\u2a85',\n    'Laplacetrf;': '\\u2112',\n    'laquo': '\\xab',\n    'laquo;': '\\xab',\n    'Larr;': '\\u219e',\n    'lArr;': '\\u21d0',\n    'larr;': '\\u2190',\n    'larrb;': '\\u21e4',\n    'larrbfs;': '\\u291f',\n    'larrfs;': '\\u291d',\n    'larrhk;': '\\u21a9',\n    'larrlp;': '\\u21ab',\n    'larrpl;': '\\u2939',\n    'larrsim;': '\\u2973',\n    'larrtl;': '\\u21a2',\n    'lat;': '\\u2aab',\n    'lAtail;': '\\u291b',\n    'latail;': '\\u2919',\n    'late;': '\\u2aad',\n    'lates;': '\\u2aad\\ufe00',\n    'lBarr;': '\\u290e',\n    'lbarr;': '\\u290c',\n    'lbbrk;': '\\u2772',\n    'lbrace;': '{',\n    'lbrack;': '[',\n    'lbrke;': '\\u298b',\n    'lbrksld;': '\\u298f',\n    'lbrkslu;': '\\u298d',\n    'Lcaron;': '\\u013d',\n    'lcaron;': '\\u013e',\n    'Lcedil;': '\\u013b',\n    'lcedil;': '\\u013c',\n    'lceil;': '\\u2308',\n    'lcub;': '{',\n    'Lcy;': '\\u041b',\n    'lcy;': '\\u043b',\n    'ldca;': '\\u2936',\n    'ldquo;': '\\u201c',\n    'ldquor;': '\\u201e',\n    'ldrdhar;': '\\u2967',\n    'ldrushar;': '\\u294b',\n    'ldsh;': '\\u21b2',\n    'lE;': '\\u2266',\n    'le;': '\\u2264',\n    'LeftAngleBracket;': '\\u27e8',\n    'LeftArrow;': '\\u2190',\n    'Leftarrow;': '\\u21d0',\n    'leftarrow;': '\\u2190',\n    'LeftArrowBar;': '\\u21e4',\n    'LeftArrowRightArrow;': '\\u21c6',\n    'leftarrowtail;': '\\u21a2',\n    'LeftCeiling;': '\\u2308',\n    'LeftDoubleBracket;': '\\u27e6',\n    'LeftDownTeeVector;': '\\u2961',\n    'LeftDownVector;': '\\u21c3',\n    'LeftDownVectorBar;': '\\u2959',\n    'LeftFloor;': '\\u230a',\n    'leftharpoondown;': '\\u21bd',\n    'leftharpoonup;': '\\u21bc',\n    'leftleftarrows;': '\\u21c7',\n    'LeftRightArrow;': '\\u2194',\n    'Leftrightarrow;': '\\u21d4',\n    'leftrightarrow;': '\\u2194',\n    'leftrightarrows;': '\\u21c6',\n    'leftrightharpoons;': '\\u21cb',\n    'leftrightsquigarrow;': '\\u21ad',\n    'LeftRightVector;': '\\u294e',\n    'LeftTee;': '\\u22a3',\n    'LeftTeeArrow;': '\\u21a4',\n    'LeftTeeVector;': '\\u295a',\n    'leftthreetimes;': '\\u22cb',\n    'LeftTriangle;': '\\u22b2',\n    'LeftTriangleBar;': '\\u29cf',\n    'LeftTriangleEqual;': '\\u22b4',\n    'LeftUpDownVector;': '\\u2951',\n    'LeftUpTeeVector;': '\\u2960',\n    'LeftUpVector;': '\\u21bf',\n    'LeftUpVectorBar;': '\\u2958',\n    'LeftVector;': '\\u21bc',\n    'LeftVectorBar;': '\\u2952',\n    'lEg;': '\\u2a8b',\n    'leg;': '\\u22da',\n    'leq;': '\\u2264',\n    'leqq;': '\\u2266',\n    'leqslant;': '\\u2a7d',\n    'les;': '\\u2a7d',\n    'lescc;': '\\u2aa8',\n    'lesdot;': '\\u2a7f',\n    'lesdoto;': '\\u2a81',\n    'lesdotor;': '\\u2a83',\n    'lesg;': '\\u22da\\ufe00',\n    'lesges;': '\\u2a93',\n    'lessapprox;': '\\u2a85',\n    'lessdot;': '\\u22d6',\n    'lesseqgtr;': '\\u22da',\n    'lesseqqgtr;': '\\u2a8b',\n    'LessEqualGreater;': '\\u22da',\n    'LessFullEqual;': '\\u2266',\n    'LessGreater;': '\\u2276',\n    'lessgtr;': '\\u2276',\n    'LessLess;': '\\u2aa1',\n    'lesssim;': '\\u2272',\n    'LessSlantEqual;': '\\u2a7d',\n    'LessTilde;': '\\u2272',\n    'lfisht;': '\\u297c',\n    'lfloor;': '\\u230a',\n    'Lfr;': '\\U0001d50f',\n    'lfr;': '\\U0001d529',\n    'lg;': '\\u2276',\n    'lgE;': '\\u2a91',\n    'lHar;': '\\u2962',\n    'lhard;': '\\u21bd',\n    'lharu;': '\\u21bc',\n    'lharul;': '\\u296a',\n    'lhblk;': '\\u2584',\n    'LJcy;': '\\u0409',\n    'ljcy;': '\\u0459',\n    'Ll;': '\\u22d8',\n    'll;': '\\u226a',\n    'llarr;': '\\u21c7',\n    'llcorner;': '\\u231e',\n    'Lleftarrow;': '\\u21da',\n    'llhard;': '\\u296b',\n    'lltri;': '\\u25fa',\n    'Lmidot;': '\\u013f',\n    'lmidot;': '\\u0140',\n    'lmoust;': '\\u23b0',\n    'lmoustache;': '\\u23b0',\n    'lnap;': '\\u2a89',\n    'lnapprox;': '\\u2a89',\n    'lnE;': '\\u2268',\n    'lne;': '\\u2a87',\n    'lneq;': '\\u2a87',\n    'lneqq;': '\\u2268',\n    'lnsim;': '\\u22e6',\n    'loang;': '\\u27ec',\n    'loarr;': '\\u21fd',\n    'lobrk;': '\\u27e6',\n    'LongLeftArrow;': '\\u27f5',\n    'Longleftarrow;': '\\u27f8',\n    'longleftarrow;': '\\u27f5',\n    'LongLeftRightArrow;': '\\u27f7',\n    'Longleftrightarrow;': '\\u27fa',\n    'longleftrightarrow;': '\\u27f7',\n    'longmapsto;': '\\u27fc',\n    'LongRightArrow;': '\\u27f6',\n    'Longrightarrow;': '\\u27f9',\n    'longrightarrow;': '\\u27f6',\n    'looparrowleft;': '\\u21ab',\n    'looparrowright;': '\\u21ac',\n    'lopar;': '\\u2985',\n    'Lopf;': '\\U0001d543',\n    'lopf;': '\\U0001d55d',\n    'loplus;': '\\u2a2d',\n    'lotimes;': '\\u2a34',\n    'lowast;': '\\u2217',\n    'lowbar;': '_',\n    'LowerLeftArrow;': '\\u2199',\n    'LowerRightArrow;': '\\u2198',\n    'loz;': '\\u25ca',\n    'lozenge;': '\\u25ca',\n    'lozf;': '\\u29eb',\n    'lpar;': '(',\n    'lparlt;': '\\u2993',\n    'lrarr;': '\\u21c6',\n    'lrcorner;': '\\u231f',\n    'lrhar;': '\\u21cb',\n    'lrhard;': '\\u296d',\n    'lrm;': '\\u200e',\n    'lrtri;': '\\u22bf',\n    'lsaquo;': '\\u2039',\n    'Lscr;': '\\u2112',\n    'lscr;': '\\U0001d4c1',\n    'Lsh;': '\\u21b0',\n    'lsh;': '\\u21b0',\n    'lsim;': '\\u2272',\n    'lsime;': '\\u2a8d',\n    'lsimg;': '\\u2a8f',\n    'lsqb;': '[',\n    'lsquo;': '\\u2018',\n    'lsquor;': '\\u201a',\n    'Lstrok;': '\\u0141',\n    'lstrok;': '\\u0142',\n    'LT': '<',\n    'lt': '<',\n    'LT;': '<',\n    'Lt;': '\\u226a',\n    'lt;': '<',\n    'ltcc;': '\\u2aa6',\n    'ltcir;': '\\u2a79',\n    'ltdot;': '\\u22d6',\n    'lthree;': '\\u22cb',\n    'ltimes;': '\\u22c9',\n    'ltlarr;': '\\u2976',\n    'ltquest;': '\\u2a7b',\n    'ltri;': '\\u25c3',\n    'ltrie;': '\\u22b4',\n    'ltrif;': '\\u25c2',\n    'ltrPar;': '\\u2996',\n    'lurdshar;': '\\u294a',\n    'luruhar;': '\\u2966',\n    'lvertneqq;': '\\u2268\\ufe00',\n    'lvnE;': '\\u2268\\ufe00',\n    'macr': '\\xaf',\n    'macr;': '\\xaf',\n    'male;': '\\u2642',\n    'malt;': '\\u2720',\n    'maltese;': '\\u2720',\n    'Map;': '\\u2905',\n    'map;': '\\u21a6',\n    'mapsto;': '\\u21a6',\n    'mapstodown;': '\\u21a7',\n    'mapstoleft;': '\\u21a4',\n    'mapstoup;': '\\u21a5',\n    'marker;': '\\u25ae',\n    'mcomma;': '\\u2a29',\n    'Mcy;': '\\u041c',\n    'mcy;': '\\u043c',\n    'mdash;': '\\u2014',\n    'mDDot;': '\\u223a',\n    'measuredangle;': '\\u2221',\n    'MediumSpace;': '\\u205f',\n    'Mellintrf;': '\\u2133',\n    'Mfr;': '\\U0001d510',\n    'mfr;': '\\U0001d52a',\n    'mho;': '\\u2127',\n    'micro': '\\xb5',\n    'micro;': '\\xb5',\n    'mid;': '\\u2223',\n    'midast;': '*',\n    'midcir;': '\\u2af0',\n    'middot': '\\xb7',\n    'middot;': '\\xb7',\n    'minus;': '\\u2212',\n    'minusb;': '\\u229f',\n    'minusd;': '\\u2238',\n    'minusdu;': '\\u2a2a',\n    'MinusPlus;': '\\u2213',\n    'mlcp;': '\\u2adb',\n    'mldr;': '\\u2026',\n    'mnplus;': '\\u2213',\n    'models;': '\\u22a7',\n    'Mopf;': '\\U0001d544',\n    'mopf;': '\\U0001d55e',\n    'mp;': '\\u2213',\n    'Mscr;': '\\u2133',\n    'mscr;': '\\U0001d4c2',\n    'mstpos;': '\\u223e',\n    'Mu;': '\\u039c',\n    'mu;': '\\u03bc',\n    'multimap;': '\\u22b8',\n    'mumap;': '\\u22b8',\n    'nabla;': '\\u2207',\n    'Nacute;': '\\u0143',\n    'nacute;': '\\u0144',\n    'nang;': '\\u2220\\u20d2',\n    'nap;': '\\u2249',\n    'napE;': '\\u2a70\\u0338',\n    'napid;': '\\u224b\\u0338',\n    'napos;': '\\u0149',\n    'napprox;': '\\u2249',\n    'natur;': '\\u266e',\n    'natural;': '\\u266e',\n    'naturals;': '\\u2115',\n    'nbsp': '\\xa0',\n    'nbsp;': '\\xa0',\n    'nbump;': '\\u224e\\u0338',\n    'nbumpe;': '\\u224f\\u0338',\n    'ncap;': '\\u2a43',\n    'Ncaron;': '\\u0147',\n    'ncaron;': '\\u0148',\n    'Ncedil;': '\\u0145',\n    'ncedil;': '\\u0146',\n    'ncong;': '\\u2247',\n    'ncongdot;': '\\u2a6d\\u0338',\n    'ncup;': '\\u2a42',\n    'Ncy;': '\\u041d',\n    'ncy;': '\\u043d',\n    'ndash;': '\\u2013',\n    'ne;': '\\u2260',\n    'nearhk;': '\\u2924',\n    'neArr;': '\\u21d7',\n    'nearr;': '\\u2197',\n    'nearrow;': '\\u2197',\n    'nedot;': '\\u2250\\u0338',\n    'NegativeMediumSpace;': '\\u200b',\n    'NegativeThickSpace;': '\\u200b',\n    'NegativeThinSpace;': '\\u200b',\n    'NegativeVeryThinSpace;': '\\u200b',\n    'nequiv;': '\\u2262',\n    'nesear;': '\\u2928',\n    'nesim;': '\\u2242\\u0338',\n    'NestedGreaterGreater;': '\\u226b',\n    'NestedLessLess;': '\\u226a',\n    'NewLine;': '\\n',\n    'nexist;': '\\u2204',\n    'nexists;': '\\u2204',\n    'Nfr;': '\\U0001d511',\n    'nfr;': '\\U0001d52b',\n    'ngE;': '\\u2267\\u0338',\n    'nge;': '\\u2271',\n    'ngeq;': '\\u2271',\n    'ngeqq;': '\\u2267\\u0338',\n    'ngeqslant;': '\\u2a7e\\u0338',\n    'nges;': '\\u2a7e\\u0338',\n    'nGg;': '\\u22d9\\u0338',\n    'ngsim;': '\\u2275',\n    'nGt;': '\\u226b\\u20d2',\n    'ngt;': '\\u226f',\n    'ngtr;': '\\u226f',\n    'nGtv;': '\\u226b\\u0338',\n    'nhArr;': '\\u21ce',\n    'nharr;': '\\u21ae',\n    'nhpar;': '\\u2af2',\n    'ni;': '\\u220b',\n    'nis;': '\\u22fc',\n    'nisd;': '\\u22fa',\n    'niv;': '\\u220b',\n    'NJcy;': '\\u040a',\n    'njcy;': '\\u045a',\n    'nlArr;': '\\u21cd',\n    'nlarr;': '\\u219a',\n    'nldr;': '\\u2025',\n    'nlE;': '\\u2266\\u0338',\n    'nle;': '\\u2270',\n    'nLeftarrow;': '\\u21cd',\n    'nleftarrow;': '\\u219a',\n    'nLeftrightarrow;': '\\u21ce',\n    'nleftrightarrow;': '\\u21ae',\n    'nleq;': '\\u2270',\n    'nleqq;': '\\u2266\\u0338',\n    'nleqslant;': '\\u2a7d\\u0338',\n    'nles;': '\\u2a7d\\u0338',\n    'nless;': '\\u226e',\n    'nLl;': '\\u22d8\\u0338',\n    'nlsim;': '\\u2274',\n    'nLt;': '\\u226a\\u20d2',\n    'nlt;': '\\u226e',\n    'nltri;': '\\u22ea',\n    'nltrie;': '\\u22ec',\n    'nLtv;': '\\u226a\\u0338',\n    'nmid;': '\\u2224',\n    'NoBreak;': '\\u2060',\n    'NonBreakingSpace;': '\\xa0',\n    'Nopf;': '\\u2115',\n    'nopf;': '\\U0001d55f',\n    'not': '\\xac',\n    'Not;': '\\u2aec',\n    'not;': '\\xac',\n    'NotCongruent;': '\\u2262',\n    'NotCupCap;': '\\u226d',\n    'NotDoubleVerticalBar;': '\\u2226',\n    'NotElement;': '\\u2209',\n    'NotEqual;': '\\u2260',\n    'NotEqualTilde;': '\\u2242\\u0338',\n    'NotExists;': '\\u2204',\n    'NotGreater;': '\\u226f',\n    'NotGreaterEqual;': '\\u2271',\n    'NotGreaterFullEqual;': '\\u2267\\u0338',\n    'NotGreaterGreater;': '\\u226b\\u0338',\n    'NotGreaterLess;': '\\u2279',\n    'NotGreaterSlantEqual;': '\\u2a7e\\u0338',\n    'NotGreaterTilde;': '\\u2275',\n    'NotHumpDownHump;': '\\u224e\\u0338',\n    'NotHumpEqual;': '\\u224f\\u0338',\n    'notin;': '\\u2209',\n    'notindot;': '\\u22f5\\u0338',\n    'notinE;': '\\u22f9\\u0338',\n    'notinva;': '\\u2209',\n    'notinvb;': '\\u22f7',\n    'notinvc;': '\\u22f6',\n    'NotLeftTriangle;': '\\u22ea',\n    'NotLeftTriangleBar;': '\\u29cf\\u0338',\n    'NotLeftTriangleEqual;': '\\u22ec',\n    'NotLess;': '\\u226e',\n    'NotLessEqual;': '\\u2270',\n    'NotLessGreater;': '\\u2278',\n    'NotLessLess;': '\\u226a\\u0338',\n    'NotLessSlantEqual;': '\\u2a7d\\u0338',\n    'NotLessTilde;': '\\u2274',\n    'NotNestedGreaterGreater;': '\\u2aa2\\u0338',\n    'NotNestedLessLess;': '\\u2aa1\\u0338',\n    'notni;': '\\u220c',\n    'notniva;': '\\u220c',\n    'notnivb;': '\\u22fe',\n    'notnivc;': '\\u22fd',\n    'NotPrecedes;': '\\u2280',\n    'NotPrecedesEqual;': '\\u2aaf\\u0338',\n    'NotPrecedesSlantEqual;': '\\u22e0',\n    'NotReverseElement;': '\\u220c',\n    'NotRightTriangle;': '\\u22eb',\n    'NotRightTriangleBar;': '\\u29d0\\u0338',\n    'NotRightTriangleEqual;': '\\u22ed',\n    'NotSquareSubset;': '\\u228f\\u0338',\n    'NotSquareSubsetEqual;': '\\u22e2',\n    'NotSquareSuperset;': '\\u2290\\u0338',\n    'NotSquareSupersetEqual;': '\\u22e3',\n    'NotSubset;': '\\u2282\\u20d2',\n    'NotSubsetEqual;': '\\u2288',\n    'NotSucceeds;': '\\u2281',\n    'NotSucceedsEqual;': '\\u2ab0\\u0338',\n    'NotSucceedsSlantEqual;': '\\u22e1',\n    'NotSucceedsTilde;': '\\u227f\\u0338',\n    'NotSuperset;': '\\u2283\\u20d2',\n    'NotSupersetEqual;': '\\u2289',\n    'NotTilde;': '\\u2241',\n    'NotTildeEqual;': '\\u2244',\n    'NotTildeFullEqual;': '\\u2247',\n    'NotTildeTilde;': '\\u2249',\n    'NotVerticalBar;': '\\u2224',\n    'npar;': '\\u2226',\n    'nparallel;': '\\u2226',\n    'nparsl;': '\\u2afd\\u20e5',\n    'npart;': '\\u2202\\u0338',\n    'npolint;': '\\u2a14',\n    'npr;': '\\u2280',\n    'nprcue;': '\\u22e0',\n    'npre;': '\\u2aaf\\u0338',\n    'nprec;': '\\u2280',\n    'npreceq;': '\\u2aaf\\u0338',\n    'nrArr;': '\\u21cf',\n    'nrarr;': '\\u219b',\n    'nrarrc;': '\\u2933\\u0338',\n    'nrarrw;': '\\u219d\\u0338',\n    'nRightarrow;': '\\u21cf',\n    'nrightarrow;': '\\u219b',\n    'nrtri;': '\\u22eb',\n    'nrtrie;': '\\u22ed',\n    'nsc;': '\\u2281',\n    'nsccue;': '\\u22e1',\n    'nsce;': '\\u2ab0\\u0338',\n    'Nscr;': '\\U0001d4a9',\n    'nscr;': '\\U0001d4c3',\n    'nshortmid;': '\\u2224',\n    'nshortparallel;': '\\u2226',\n    'nsim;': '\\u2241',\n    'nsime;': '\\u2244',\n    'nsimeq;': '\\u2244',\n    'nsmid;': '\\u2224',\n    'nspar;': '\\u2226',\n    'nsqsube;': '\\u22e2',\n    'nsqsupe;': '\\u22e3',\n    'nsub;': '\\u2284',\n    'nsubE;': '\\u2ac5\\u0338',\n    'nsube;': '\\u2288',\n    'nsubset;': '\\u2282\\u20d2',\n    'nsubseteq;': '\\u2288',\n    'nsubseteqq;': '\\u2ac5\\u0338',\n    'nsucc;': '\\u2281',\n    'nsucceq;': '\\u2ab0\\u0338',\n    'nsup;': '\\u2285',\n    'nsupE;': '\\u2ac6\\u0338',\n    'nsupe;': '\\u2289',\n    'nsupset;': '\\u2283\\u20d2',\n    'nsupseteq;': '\\u2289',\n    'nsupseteqq;': '\\u2ac6\\u0338',\n    'ntgl;': '\\u2279',\n    'Ntilde': '\\xd1',\n    'ntilde': '\\xf1',\n    'Ntilde;': '\\xd1',\n    'ntilde;': '\\xf1',\n    'ntlg;': '\\u2278',\n    'ntriangleleft;': '\\u22ea',\n    'ntrianglelefteq;': '\\u22ec',\n    'ntriangleright;': '\\u22eb',\n    'ntrianglerighteq;': '\\u22ed',\n    'Nu;': '\\u039d',\n    'nu;': '\\u03bd',\n    'num;': '#',\n    'numero;': '\\u2116',\n    'numsp;': '\\u2007',\n    'nvap;': '\\u224d\\u20d2',\n    'nVDash;': '\\u22af',\n    'nVdash;': '\\u22ae',\n    'nvDash;': '\\u22ad',\n    'nvdash;': '\\u22ac',\n    'nvge;': '\\u2265\\u20d2',\n    'nvgt;': '>\\u20d2',\n    'nvHarr;': '\\u2904',\n    'nvinfin;': '\\u29de',\n    'nvlArr;': '\\u2902',\n    'nvle;': '\\u2264\\u20d2',\n    'nvlt;': '<\\u20d2',\n    'nvltrie;': '\\u22b4\\u20d2',\n    'nvrArr;': '\\u2903',\n    'nvrtrie;': '\\u22b5\\u20d2',\n    'nvsim;': '\\u223c\\u20d2',\n    'nwarhk;': '\\u2923',\n    'nwArr;': '\\u21d6',\n    'nwarr;': '\\u2196',\n    'nwarrow;': '\\u2196',\n    'nwnear;': '\\u2927',\n    'Oacute': '\\xd3',\n    'oacute': '\\xf3',\n    'Oacute;': '\\xd3',\n    'oacute;': '\\xf3',\n    'oast;': '\\u229b',\n    'ocir;': '\\u229a',\n    'Ocirc': '\\xd4',\n    'ocirc': '\\xf4',\n    'Ocirc;': '\\xd4',\n    'ocirc;': '\\xf4',\n    'Ocy;': '\\u041e',\n    'ocy;': '\\u043e',\n    'odash;': '\\u229d',\n    'Odblac;': '\\u0150',\n    'odblac;': '\\u0151',\n    'odiv;': '\\u2a38',\n    'odot;': '\\u2299',\n    'odsold;': '\\u29bc',\n    'OElig;': '\\u0152',\n    'oelig;': '\\u0153',\n    'ofcir;': '\\u29bf',\n    'Ofr;': '\\U0001d512',\n    'ofr;': '\\U0001d52c',\n    'ogon;': '\\u02db',\n    'Ograve': '\\xd2',\n    'ograve': '\\xf2',\n    'Ograve;': '\\xd2',\n    'ograve;': '\\xf2',\n    'ogt;': '\\u29c1',\n    'ohbar;': '\\u29b5',\n    'ohm;': '\\u03a9',\n    'oint;': '\\u222e',\n    'olarr;': '\\u21ba',\n    'olcir;': '\\u29be',\n    'olcross;': '\\u29bb',\n    'oline;': '\\u203e',\n    'olt;': '\\u29c0',\n    'Omacr;': '\\u014c',\n    'omacr;': '\\u014d',\n    'Omega;': '\\u03a9',\n    'omega;': '\\u03c9',\n    'Omicron;': '\\u039f',\n    'omicron;': '\\u03bf',\n    'omid;': '\\u29b6',\n    'ominus;': '\\u2296',\n    'Oopf;': '\\U0001d546',\n    'oopf;': '\\U0001d560',\n    'opar;': '\\u29b7',\n    'OpenCurlyDoubleQuote;': '\\u201c',\n    'OpenCurlyQuote;': '\\u2018',\n    'operp;': '\\u29b9',\n    'oplus;': '\\u2295',\n    'Or;': '\\u2a54',\n    'or;': '\\u2228',\n    'orarr;': '\\u21bb',\n    'ord;': '\\u2a5d',\n    'order;': '\\u2134',\n    'orderof;': '\\u2134',\n    'ordf': '\\xaa',\n    'ordf;': '\\xaa',\n    'ordm': '\\xba',\n    'ordm;': '\\xba',\n    'origof;': '\\u22b6',\n    'oror;': '\\u2a56',\n    'orslope;': '\\u2a57',\n    'orv;': '\\u2a5b',\n    'oS;': '\\u24c8',\n    'Oscr;': '\\U0001d4aa',\n    'oscr;': '\\u2134',\n    'Oslash': '\\xd8',\n    'oslash': '\\xf8',\n    'Oslash;': '\\xd8',\n    'oslash;': '\\xf8',\n    'osol;': '\\u2298',\n    'Otilde': '\\xd5',\n    'otilde': '\\xf5',\n    'Otilde;': '\\xd5',\n    'otilde;': '\\xf5',\n    'Otimes;': '\\u2a37',\n    'otimes;': '\\u2297',\n    'otimesas;': '\\u2a36',\n    'Ouml': '\\xd6',\n    'ouml': '\\xf6',\n    'Ouml;': '\\xd6',\n    'ouml;': '\\xf6',\n    'ovbar;': '\\u233d',\n    'OverBar;': '\\u203e',\n    'OverBrace;': '\\u23de',\n    'OverBracket;': '\\u23b4',\n    'OverParenthesis;': '\\u23dc',\n    'par;': '\\u2225',\n    'para': '\\xb6',\n    'para;': '\\xb6',\n    'parallel;': '\\u2225',\n    'parsim;': '\\u2af3',\n    'parsl;': '\\u2afd',\n    'part;': '\\u2202',\n    'PartialD;': '\\u2202',\n    'Pcy;': '\\u041f',\n    'pcy;': '\\u043f',\n    'percnt;': '%',\n    'period;': '.',\n    'permil;': '\\u2030',\n    'perp;': '\\u22a5',\n    'pertenk;': '\\u2031',\n    'Pfr;': '\\U0001d513',\n    'pfr;': '\\U0001d52d',\n    'Phi;': '\\u03a6',\n    'phi;': '\\u03c6',\n    'phiv;': '\\u03d5',\n    'phmmat;': '\\u2133',\n    'phone;': '\\u260e',\n    'Pi;': '\\u03a0',\n    'pi;': '\\u03c0',\n    'pitchfork;': '\\u22d4',\n    'piv;': '\\u03d6',\n    'planck;': '\\u210f',\n    'planckh;': '\\u210e',\n    'plankv;': '\\u210f',\n    'plus;': '+',\n    'plusacir;': '\\u2a23',\n    'plusb;': '\\u229e',\n    'pluscir;': '\\u2a22',\n    'plusdo;': '\\u2214',\n    'plusdu;': '\\u2a25',\n    'pluse;': '\\u2a72',\n    'PlusMinus;': '\\xb1',\n    'plusmn': '\\xb1',\n    'plusmn;': '\\xb1',\n    'plussim;': '\\u2a26',\n    'plustwo;': '\\u2a27',\n    'pm;': '\\xb1',\n    'Poincareplane;': '\\u210c',\n    'pointint;': '\\u2a15',\n    'Popf;': '\\u2119',\n    'popf;': '\\U0001d561',\n    'pound': '\\xa3',\n    'pound;': '\\xa3',\n    'Pr;': '\\u2abb',\n    'pr;': '\\u227a',\n    'prap;': '\\u2ab7',\n    'prcue;': '\\u227c',\n    'prE;': '\\u2ab3',\n    'pre;': '\\u2aaf',\n    'prec;': '\\u227a',\n    'precapprox;': '\\u2ab7',\n    'preccurlyeq;': '\\u227c',\n    'Precedes;': '\\u227a',\n    'PrecedesEqual;': '\\u2aaf',\n    'PrecedesSlantEqual;': '\\u227c',\n    'PrecedesTilde;': '\\u227e',\n    'preceq;': '\\u2aaf',\n    'precnapprox;': '\\u2ab9',\n    'precneqq;': '\\u2ab5',\n    'precnsim;': '\\u22e8',\n    'precsim;': '\\u227e',\n    'Prime;': '\\u2033',\n    'prime;': '\\u2032',\n    'primes;': '\\u2119',\n    'prnap;': '\\u2ab9',\n    'prnE;': '\\u2ab5',\n    'prnsim;': '\\u22e8',\n    'prod;': '\\u220f',\n    'Product;': '\\u220f',\n    'profalar;': '\\u232e',\n    'profline;': '\\u2312',\n    'profsurf;': '\\u2313',\n    'prop;': '\\u221d',\n    'Proportion;': '\\u2237',\n    'Proportional;': '\\u221d',\n    'propto;': '\\u221d',\n    'prsim;': '\\u227e',\n    'prurel;': '\\u22b0',\n    'Pscr;': '\\U0001d4ab',\n    'pscr;': '\\U0001d4c5',\n    'Psi;': '\\u03a8',\n    'psi;': '\\u03c8',\n    'puncsp;': '\\u2008',\n    'Qfr;': '\\U0001d514',\n    'qfr;': '\\U0001d52e',\n    'qint;': '\\u2a0c',\n    'Qopf;': '\\u211a',\n    'qopf;': '\\U0001d562',\n    'qprime;': '\\u2057',\n    'Qscr;': '\\U0001d4ac',\n    'qscr;': '\\U0001d4c6',\n    'quaternions;': '\\u210d',\n    'quatint;': '\\u2a16',\n    'quest;': '?',\n    'questeq;': '\\u225f',\n    'QUOT': '\"',\n    'quot': '\"',\n    'QUOT;': '\"',\n    'quot;': '\"',\n    'rAarr;': '\\u21db',\n    'race;': '\\u223d\\u0331',\n    'Racute;': '\\u0154',\n    'racute;': '\\u0155',\n    'radic;': '\\u221a',\n    'raemptyv;': '\\u29b3',\n    'Rang;': '\\u27eb',\n    'rang;': '\\u27e9',\n    'rangd;': '\\u2992',\n    'range;': '\\u29a5',\n    'rangle;': '\\u27e9',\n    'raquo': '\\xbb',\n    'raquo;': '\\xbb',\n    'Rarr;': '\\u21a0',\n    'rArr;': '\\u21d2',\n    'rarr;': '\\u2192',\n    'rarrap;': '\\u2975',\n    'rarrb;': '\\u21e5',\n    'rarrbfs;': '\\u2920',\n    'rarrc;': '\\u2933',\n    'rarrfs;': '\\u291e',\n    'rarrhk;': '\\u21aa',\n    'rarrlp;': '\\u21ac',\n    'rarrpl;': '\\u2945',\n    'rarrsim;': '\\u2974',\n    'Rarrtl;': '\\u2916',\n    'rarrtl;': '\\u21a3',\n    'rarrw;': '\\u219d',\n    'rAtail;': '\\u291c',\n    'ratail;': '\\u291a',\n    'ratio;': '\\u2236',\n    'rationals;': '\\u211a',\n    'RBarr;': '\\u2910',\n    'rBarr;': '\\u290f',\n    'rbarr;': '\\u290d',\n    'rbbrk;': '\\u2773',\n    'rbrace;': '}',\n    'rbrack;': ']',\n    'rbrke;': '\\u298c',\n    'rbrksld;': '\\u298e',\n    'rbrkslu;': '\\u2990',\n    'Rcaron;': '\\u0158',\n    'rcaron;': '\\u0159',\n    'Rcedil;': '\\u0156',\n    'rcedil;': '\\u0157',\n    'rceil;': '\\u2309',\n    'rcub;': '}',\n    'Rcy;': '\\u0420',\n    'rcy;': '\\u0440',\n    'rdca;': '\\u2937',\n    'rdldhar;': '\\u2969',\n    'rdquo;': '\\u201d',\n    'rdquor;': '\\u201d',\n    'rdsh;': '\\u21b3',\n    'Re;': '\\u211c',\n    'real;': '\\u211c',\n    'realine;': '\\u211b',\n    'realpart;': '\\u211c',\n    'reals;': '\\u211d',\n    'rect;': '\\u25ad',\n    'REG': '\\xae',\n    'reg': '\\xae',\n    'REG;': '\\xae',\n    'reg;': '\\xae',\n    'ReverseElement;': '\\u220b',\n    'ReverseEquilibrium;': '\\u21cb',\n    'ReverseUpEquilibrium;': '\\u296f',\n    'rfisht;': '\\u297d',\n    'rfloor;': '\\u230b',\n    'Rfr;': '\\u211c',\n    'rfr;': '\\U0001d52f',\n    'rHar;': '\\u2964',\n    'rhard;': '\\u21c1',\n    'rharu;': '\\u21c0',\n    'rharul;': '\\u296c',\n    'Rho;': '\\u03a1',\n    'rho;': '\\u03c1',\n    'rhov;': '\\u03f1',\n    'RightAngleBracket;': '\\u27e9',\n    'RightArrow;': '\\u2192',\n    'Rightarrow;': '\\u21d2',\n    'rightarrow;': '\\u2192',\n    'RightArrowBar;': '\\u21e5',\n    'RightArrowLeftArrow;': '\\u21c4',\n    'rightarrowtail;': '\\u21a3',\n    'RightCeiling;': '\\u2309',\n    'RightDoubleBracket;': '\\u27e7',\n    'RightDownTeeVector;': '\\u295d',\n    'RightDownVector;': '\\u21c2',\n    'RightDownVectorBar;': '\\u2955',\n    'RightFloor;': '\\u230b',\n    'rightharpoondown;': '\\u21c1',\n    'rightharpoonup;': '\\u21c0',\n    'rightleftarrows;': '\\u21c4',\n    'rightleftharpoons;': '\\u21cc',\n    'rightrightarrows;': '\\u21c9',\n    'rightsquigarrow;': '\\u219d',\n    'RightTee;': '\\u22a2',\n    'RightTeeArrow;': '\\u21a6',\n    'RightTeeVector;': '\\u295b',\n    'rightthreetimes;': '\\u22cc',\n    'RightTriangle;': '\\u22b3',\n    'RightTriangleBar;': '\\u29d0',\n    'RightTriangleEqual;': '\\u22b5',\n    'RightUpDownVector;': '\\u294f',\n    'RightUpTeeVector;': '\\u295c',\n    'RightUpVector;': '\\u21be',\n    'RightUpVectorBar;': '\\u2954',\n    'RightVector;': '\\u21c0',\n    'RightVectorBar;': '\\u2953',\n    'ring;': '\\u02da',\n    'risingdotseq;': '\\u2253',\n    'rlarr;': '\\u21c4',\n    'rlhar;': '\\u21cc',\n    'rlm;': '\\u200f',\n    'rmoust;': '\\u23b1',\n    'rmoustache;': '\\u23b1',\n    'rnmid;': '\\u2aee',\n    'roang;': '\\u27ed',\n    'roarr;': '\\u21fe',\n    'robrk;': '\\u27e7',\n    'ropar;': '\\u2986',\n    'Ropf;': '\\u211d',\n    'ropf;': '\\U0001d563',\n    'roplus;': '\\u2a2e',\n    'rotimes;': '\\u2a35',\n    'RoundImplies;': '\\u2970',\n    'rpar;': ')',\n    'rpargt;': '\\u2994',\n    'rppolint;': '\\u2a12',\n    'rrarr;': '\\u21c9',\n    'Rrightarrow;': '\\u21db',\n    'rsaquo;': '\\u203a',\n    'Rscr;': '\\u211b',\n    'rscr;': '\\U0001d4c7',\n    'Rsh;': '\\u21b1',\n    'rsh;': '\\u21b1',\n    'rsqb;': ']',\n    'rsquo;': '\\u2019',\n    'rsquor;': '\\u2019',\n    'rthree;': '\\u22cc',\n    'rtimes;': '\\u22ca',\n    'rtri;': '\\u25b9',\n    'rtrie;': '\\u22b5',\n    'rtrif;': '\\u25b8',\n    'rtriltri;': '\\u29ce',\n    'RuleDelayed;': '\\u29f4',\n    'ruluhar;': '\\u2968',\n    'rx;': '\\u211e',\n    'Sacute;': '\\u015a',\n    'sacute;': '\\u015b',\n    'sbquo;': '\\u201a',\n    'Sc;': '\\u2abc',\n    'sc;': '\\u227b',\n    'scap;': '\\u2ab8',\n    'Scaron;': '\\u0160',\n    'scaron;': '\\u0161',\n    'sccue;': '\\u227d',\n    'scE;': '\\u2ab4',\n    'sce;': '\\u2ab0',\n    'Scedil;': '\\u015e',\n    'scedil;': '\\u015f',\n    'Scirc;': '\\u015c',\n    'scirc;': '\\u015d',\n    'scnap;': '\\u2aba',\n    'scnE;': '\\u2ab6',\n    'scnsim;': '\\u22e9',\n    'scpolint;': '\\u2a13',\n    'scsim;': '\\u227f',\n    'Scy;': '\\u0421',\n    'scy;': '\\u0441',\n    'sdot;': '\\u22c5',\n    'sdotb;': '\\u22a1',\n    'sdote;': '\\u2a66',\n    'searhk;': '\\u2925',\n    'seArr;': '\\u21d8',\n    'searr;': '\\u2198',\n    'searrow;': '\\u2198',\n    'sect': '\\xa7',\n    'sect;': '\\xa7',\n    'semi;': ';',\n    'seswar;': '\\u2929',\n    'setminus;': '\\u2216',\n    'setmn;': '\\u2216',\n    'sext;': '\\u2736',\n    'Sfr;': '\\U0001d516',\n    'sfr;': '\\U0001d530',\n    'sfrown;': '\\u2322',\n    'sharp;': '\\u266f',\n    'SHCHcy;': '\\u0429',\n    'shchcy;': '\\u0449',\n    'SHcy;': '\\u0428',\n    'shcy;': '\\u0448',\n    'ShortDownArrow;': '\\u2193',\n    'ShortLeftArrow;': '\\u2190',\n    'shortmid;': '\\u2223',\n    'shortparallel;': '\\u2225',\n    'ShortRightArrow;': '\\u2192',\n    'ShortUpArrow;': '\\u2191',\n    'shy': '\\xad',\n    'shy;': '\\xad',\n    'Sigma;': '\\u03a3',\n    'sigma;': '\\u03c3',\n    'sigmaf;': '\\u03c2',\n    'sigmav;': '\\u03c2',\n    'sim;': '\\u223c',\n    'simdot;': '\\u2a6a',\n    'sime;': '\\u2243',\n    'simeq;': '\\u2243',\n    'simg;': '\\u2a9e',\n    'simgE;': '\\u2aa0',\n    'siml;': '\\u2a9d',\n    'simlE;': '\\u2a9f',\n    'simne;': '\\u2246',\n    'simplus;': '\\u2a24',\n    'simrarr;': '\\u2972',\n    'slarr;': '\\u2190',\n    'SmallCircle;': '\\u2218',\n    'smallsetminus;': '\\u2216',\n    'smashp;': '\\u2a33',\n    'smeparsl;': '\\u29e4',\n    'smid;': '\\u2223',\n    'smile;': '\\u2323',\n    'smt;': '\\u2aaa',\n    'smte;': '\\u2aac',\n    'smtes;': '\\u2aac\\ufe00',\n    'SOFTcy;': '\\u042c',\n    'softcy;': '\\u044c',\n    'sol;': '/',\n    'solb;': '\\u29c4',\n    'solbar;': '\\u233f',\n    'Sopf;': '\\U0001d54a',\n    'sopf;': '\\U0001d564',\n    'spades;': '\\u2660',\n    'spadesuit;': '\\u2660',\n    'spar;': '\\u2225',\n    'sqcap;': '\\u2293',\n    'sqcaps;': '\\u2293\\ufe00',\n    'sqcup;': '\\u2294',\n    'sqcups;': '\\u2294\\ufe00',\n    'Sqrt;': '\\u221a',\n    'sqsub;': '\\u228f',\n    'sqsube;': '\\u2291',\n    'sqsubset;': '\\u228f',\n    'sqsubseteq;': '\\u2291',\n    'sqsup;': '\\u2290',\n    'sqsupe;': '\\u2292',\n    'sqsupset;': '\\u2290',\n    'sqsupseteq;': '\\u2292',\n    'squ;': '\\u25a1',\n    'Square;': '\\u25a1',\n    'square;': '\\u25a1',\n    'SquareIntersection;': '\\u2293',\n    'SquareSubset;': '\\u228f',\n    'SquareSubsetEqual;': '\\u2291',\n    'SquareSuperset;': '\\u2290',\n    'SquareSupersetEqual;': '\\u2292',\n    'SquareUnion;': '\\u2294',\n    'squarf;': '\\u25aa',\n    'squf;': '\\u25aa',\n    'srarr;': '\\u2192',\n    'Sscr;': '\\U0001d4ae',\n    'sscr;': '\\U0001d4c8',\n    'ssetmn;': '\\u2216',\n    'ssmile;': '\\u2323',\n    'sstarf;': '\\u22c6',\n    'Star;': '\\u22c6',\n    'star;': '\\u2606',\n    'starf;': '\\u2605',\n    'straightepsilon;': '\\u03f5',\n    'straightphi;': '\\u03d5',\n    'strns;': '\\xaf',\n    'Sub;': '\\u22d0',\n    'sub;': '\\u2282',\n    'subdot;': '\\u2abd',\n    'subE;': '\\u2ac5',\n    'sube;': '\\u2286',\n    'subedot;': '\\u2ac3',\n    'submult;': '\\u2ac1',\n    'subnE;': '\\u2acb',\n    'subne;': '\\u228a',\n    'subplus;': '\\u2abf',\n    'subrarr;': '\\u2979',\n    'Subset;': '\\u22d0',\n    'subset;': '\\u2282',\n    'subseteq;': '\\u2286',\n    'subseteqq;': '\\u2ac5',\n    'SubsetEqual;': '\\u2286',\n    'subsetneq;': '\\u228a',\n    'subsetneqq;': '\\u2acb',\n    'subsim;': '\\u2ac7',\n    'subsub;': '\\u2ad5',\n    'subsup;': '\\u2ad3',\n    'succ;': '\\u227b',\n    'succapprox;': '\\u2ab8',\n    'succcurlyeq;': '\\u227d',\n    'Succeeds;': '\\u227b',\n    'SucceedsEqual;': '\\u2ab0',\n    'SucceedsSlantEqual;': '\\u227d',\n    'SucceedsTilde;': '\\u227f',\n    'succeq;': '\\u2ab0',\n    'succnapprox;': '\\u2aba',\n    'succneqq;': '\\u2ab6',\n    'succnsim;': '\\u22e9',\n    'succsim;': '\\u227f',\n    'SuchThat;': '\\u220b',\n    'Sum;': '\\u2211',\n    'sum;': '\\u2211',\n    'sung;': '\\u266a',\n    'sup1': '\\xb9',\n    'sup1;': '\\xb9',\n    'sup2': '\\xb2',\n    'sup2;': '\\xb2',\n    'sup3': '\\xb3',\n    'sup3;': '\\xb3',\n    'Sup;': '\\u22d1',\n    'sup;': '\\u2283',\n    'supdot;': '\\u2abe',\n    'supdsub;': '\\u2ad8',\n    'supE;': '\\u2ac6',\n    'supe;': '\\u2287',\n    'supedot;': '\\u2ac4',\n    'Superset;': '\\u2283',\n    'SupersetEqual;': '\\u2287',\n    'suphsol;': '\\u27c9',\n    'suphsub;': '\\u2ad7',\n    'suplarr;': '\\u297b',\n    'supmult;': '\\u2ac2',\n    'supnE;': '\\u2acc',\n    'supne;': '\\u228b',\n    'supplus;': '\\u2ac0',\n    'Supset;': '\\u22d1',\n    'supset;': '\\u2283',\n    'supseteq;': '\\u2287',\n    'supseteqq;': '\\u2ac6',\n    'supsetneq;': '\\u228b',\n    'supsetneqq;': '\\u2acc',\n    'supsim;': '\\u2ac8',\n    'supsub;': '\\u2ad4',\n    'supsup;': '\\u2ad6',\n    'swarhk;': '\\u2926',\n    'swArr;': '\\u21d9',\n    'swarr;': '\\u2199',\n    'swarrow;': '\\u2199',\n    'swnwar;': '\\u292a',\n    'szlig': '\\xdf',\n    'szlig;': '\\xdf',\n    'Tab;': '\\t',\n    'target;': '\\u2316',\n    'Tau;': '\\u03a4',\n    'tau;': '\\u03c4',\n    'tbrk;': '\\u23b4',\n    'Tcaron;': '\\u0164',\n    'tcaron;': '\\u0165',\n    'Tcedil;': '\\u0162',\n    'tcedil;': '\\u0163',\n    'Tcy;': '\\u0422',\n    'tcy;': '\\u0442',\n    'tdot;': '\\u20db',\n    'telrec;': '\\u2315',\n    'Tfr;': '\\U0001d517',\n    'tfr;': '\\U0001d531',\n    'there4;': '\\u2234',\n    'Therefore;': '\\u2234',\n    'therefore;': '\\u2234',\n    'Theta;': '\\u0398',\n    'theta;': '\\u03b8',\n    'thetasym;': '\\u03d1',\n    'thetav;': '\\u03d1',\n    'thickapprox;': '\\u2248',\n    'thicksim;': '\\u223c',\n    'ThickSpace;': '\\u205f\\u200a',\n    'thinsp;': '\\u2009',\n    'ThinSpace;': '\\u2009',\n    'thkap;': '\\u2248',\n    'thksim;': '\\u223c',\n    'THORN': '\\xde',\n    'thorn': '\\xfe',\n    'THORN;': '\\xde',\n    'thorn;': '\\xfe',\n    'Tilde;': '\\u223c',\n    'tilde;': '\\u02dc',\n    'TildeEqual;': '\\u2243',\n    'TildeFullEqual;': '\\u2245',\n    'TildeTilde;': '\\u2248',\n    'times': '\\xd7',\n    'times;': '\\xd7',\n    'timesb;': '\\u22a0',\n    'timesbar;': '\\u2a31',\n    'timesd;': '\\u2a30',\n    'tint;': '\\u222d',\n    'toea;': '\\u2928',\n    'top;': '\\u22a4',\n    'topbot;': '\\u2336',\n    'topcir;': '\\u2af1',\n    'Topf;': '\\U0001d54b',\n    'topf;': '\\U0001d565',\n    'topfork;': '\\u2ada',\n    'tosa;': '\\u2929',\n    'tprime;': '\\u2034',\n    'TRADE;': '\\u2122',\n    'trade;': '\\u2122',\n    'triangle;': '\\u25b5',\n    'triangledown;': '\\u25bf',\n    'triangleleft;': '\\u25c3',\n    'trianglelefteq;': '\\u22b4',\n    'triangleq;': '\\u225c',\n    'triangleright;': '\\u25b9',\n    'trianglerighteq;': '\\u22b5',\n    'tridot;': '\\u25ec',\n    'trie;': '\\u225c',\n    'triminus;': '\\u2a3a',\n    'TripleDot;': '\\u20db',\n    'triplus;': '\\u2a39',\n    'trisb;': '\\u29cd',\n    'tritime;': '\\u2a3b',\n    'trpezium;': '\\u23e2',\n    'Tscr;': '\\U0001d4af',\n    'tscr;': '\\U0001d4c9',\n    'TScy;': '\\u0426',\n    'tscy;': '\\u0446',\n    'TSHcy;': '\\u040b',\n    'tshcy;': '\\u045b',\n    'Tstrok;': '\\u0166',\n    'tstrok;': '\\u0167',\n    'twixt;': '\\u226c',\n    'twoheadleftarrow;': '\\u219e',\n    'twoheadrightarrow;': '\\u21a0',\n    'Uacute': '\\xda',\n    'uacute': '\\xfa',\n    'Uacute;': '\\xda',\n    'uacute;': '\\xfa',\n    'Uarr;': '\\u219f',\n    'uArr;': '\\u21d1',\n    'uarr;': '\\u2191',\n    'Uarrocir;': '\\u2949',\n    'Ubrcy;': '\\u040e',\n    'ubrcy;': '\\u045e',\n    'Ubreve;': '\\u016c',\n    'ubreve;': '\\u016d',\n    'Ucirc': '\\xdb',\n    'ucirc': '\\xfb',\n    'Ucirc;': '\\xdb',\n    'ucirc;': '\\xfb',\n    'Ucy;': '\\u0423',\n    'ucy;': '\\u0443',\n    'udarr;': '\\u21c5',\n    'Udblac;': '\\u0170',\n    'udblac;': '\\u0171',\n    'udhar;': '\\u296e',\n    'ufisht;': '\\u297e',\n    'Ufr;': '\\U0001d518',\n    'ufr;': '\\U0001d532',\n    'Ugrave': '\\xd9',\n    'ugrave': '\\xf9',\n    'Ugrave;': '\\xd9',\n    'ugrave;': '\\xf9',\n    'uHar;': '\\u2963',\n    'uharl;': '\\u21bf',\n    'uharr;': '\\u21be',\n    'uhblk;': '\\u2580',\n    'ulcorn;': '\\u231c',\n    'ulcorner;': '\\u231c',\n    'ulcrop;': '\\u230f',\n    'ultri;': '\\u25f8',\n    'Umacr;': '\\u016a',\n    'umacr;': '\\u016b',\n    'uml': '\\xa8',\n    'uml;': '\\xa8',\n    'UnderBar;': '_',\n    'UnderBrace;': '\\u23df',\n    'UnderBracket;': '\\u23b5',\n    'UnderParenthesis;': '\\u23dd',\n    'Union;': '\\u22c3',\n    'UnionPlus;': '\\u228e',\n    'Uogon;': '\\u0172',\n    'uogon;': '\\u0173',\n    'Uopf;': '\\U0001d54c',\n    'uopf;': '\\U0001d566',\n    'UpArrow;': '\\u2191',\n    'Uparrow;': '\\u21d1',\n    'uparrow;': '\\u2191',\n    'UpArrowBar;': '\\u2912',\n    'UpArrowDownArrow;': '\\u21c5',\n    'UpDownArrow;': '\\u2195',\n    'Updownarrow;': '\\u21d5',\n    'updownarrow;': '\\u2195',\n    'UpEquilibrium;': '\\u296e',\n    'upharpoonleft;': '\\u21bf',\n    'upharpoonright;': '\\u21be',\n    'uplus;': '\\u228e',\n    'UpperLeftArrow;': '\\u2196',\n    'UpperRightArrow;': '\\u2197',\n    'Upsi;': '\\u03d2',\n    'upsi;': '\\u03c5',\n    'upsih;': '\\u03d2',\n    'Upsilon;': '\\u03a5',\n    'upsilon;': '\\u03c5',\n    'UpTee;': '\\u22a5',\n    'UpTeeArrow;': '\\u21a5',\n    'upuparrows;': '\\u21c8',\n    'urcorn;': '\\u231d',\n    'urcorner;': '\\u231d',\n    'urcrop;': '\\u230e',\n    'Uring;': '\\u016e',\n    'uring;': '\\u016f',\n    'urtri;': '\\u25f9',\n    'Uscr;': '\\U0001d4b0',\n    'uscr;': '\\U0001d4ca',\n    'utdot;': '\\u22f0',\n    'Utilde;': '\\u0168',\n    'utilde;': '\\u0169',\n    'utri;': '\\u25b5',\n    'utrif;': '\\u25b4',\n    'uuarr;': '\\u21c8',\n    'Uuml': '\\xdc',\n    'uuml': '\\xfc',\n    'Uuml;': '\\xdc',\n    'uuml;': '\\xfc',\n    'uwangle;': '\\u29a7',\n    'vangrt;': '\\u299c',\n    'varepsilon;': '\\u03f5',\n    'varkappa;': '\\u03f0',\n    'varnothing;': '\\u2205',\n    'varphi;': '\\u03d5',\n    'varpi;': '\\u03d6',\n    'varpropto;': '\\u221d',\n    'vArr;': '\\u21d5',\n    'varr;': '\\u2195',\n    'varrho;': '\\u03f1',\n    'varsigma;': '\\u03c2',\n    'varsubsetneq;': '\\u228a\\ufe00',\n    'varsubsetneqq;': '\\u2acb\\ufe00',\n    'varsupsetneq;': '\\u228b\\ufe00',\n    'varsupsetneqq;': '\\u2acc\\ufe00',\n    'vartheta;': '\\u03d1',\n    'vartriangleleft;': '\\u22b2',\n    'vartriangleright;': '\\u22b3',\n    'Vbar;': '\\u2aeb',\n    'vBar;': '\\u2ae8',\n    'vBarv;': '\\u2ae9',\n    'Vcy;': '\\u0412',\n    'vcy;': '\\u0432',\n    'VDash;': '\\u22ab',\n    'Vdash;': '\\u22a9',\n    'vDash;': '\\u22a8',\n    'vdash;': '\\u22a2',\n    'Vdashl;': '\\u2ae6',\n    'Vee;': '\\u22c1',\n    'vee;': '\\u2228',\n    'veebar;': '\\u22bb',\n    'veeeq;': '\\u225a',\n    'vellip;': '\\u22ee',\n    'Verbar;': '\\u2016',\n    'verbar;': '|',\n    'Vert;': '\\u2016',\n    'vert;': '|',\n    'VerticalBar;': '\\u2223',\n    'VerticalLine;': '|',\n    'VerticalSeparator;': '\\u2758',\n    'VerticalTilde;': '\\u2240',\n    'VeryThinSpace;': '\\u200a',\n    'Vfr;': '\\U0001d519',\n    'vfr;': '\\U0001d533',\n    'vltri;': '\\u22b2',\n    'vnsub;': '\\u2282\\u20d2',\n    'vnsup;': '\\u2283\\u20d2',\n    'Vopf;': '\\U0001d54d',\n    'vopf;': '\\U0001d567',\n    'vprop;': '\\u221d',\n    'vrtri;': '\\u22b3',\n    'Vscr;': '\\U0001d4b1',\n    'vscr;': '\\U0001d4cb',\n    'vsubnE;': '\\u2acb\\ufe00',\n    'vsubne;': '\\u228a\\ufe00',\n    'vsupnE;': '\\u2acc\\ufe00',\n    'vsupne;': '\\u228b\\ufe00',\n    'Vvdash;': '\\u22aa',\n    'vzigzag;': '\\u299a',\n    'Wcirc;': '\\u0174',\n    'wcirc;': '\\u0175',\n    'wedbar;': '\\u2a5f',\n    'Wedge;': '\\u22c0',\n    'wedge;': '\\u2227',\n    'wedgeq;': '\\u2259',\n    'weierp;': '\\u2118',\n    'Wfr;': '\\U0001d51a',\n    'wfr;': '\\U0001d534',\n    'Wopf;': '\\U0001d54e',\n    'wopf;': '\\U0001d568',\n    'wp;': '\\u2118',\n    'wr;': '\\u2240',\n    'wreath;': '\\u2240',\n    'Wscr;': '\\U0001d4b2',\n    'wscr;': '\\U0001d4cc',\n    'xcap;': '\\u22c2',\n    'xcirc;': '\\u25ef',\n    'xcup;': '\\u22c3',\n    'xdtri;': '\\u25bd',\n    'Xfr;': '\\U0001d51b',\n    'xfr;': '\\U0001d535',\n    'xhArr;': '\\u27fa',\n    'xharr;': '\\u27f7',\n    'Xi;': '\\u039e',\n    'xi;': '\\u03be',\n    'xlArr;': '\\u27f8',\n    'xlarr;': '\\u27f5',\n    'xmap;': '\\u27fc',\n    'xnis;': '\\u22fb',\n    'xodot;': '\\u2a00',\n    'Xopf;': '\\U0001d54f',\n    'xopf;': '\\U0001d569',\n    'xoplus;': '\\u2a01',\n    'xotime;': '\\u2a02',\n    'xrArr;': '\\u27f9',\n    'xrarr;': '\\u27f6',\n    'Xscr;': '\\U0001d4b3',\n    'xscr;': '\\U0001d4cd',\n    'xsqcup;': '\\u2a06',\n    'xuplus;': '\\u2a04',\n    'xutri;': '\\u25b3',\n    'xvee;': '\\u22c1',\n    'xwedge;': '\\u22c0',\n    'Yacute': '\\xdd',\n    'yacute': '\\xfd',\n    'Yacute;': '\\xdd',\n    'yacute;': '\\xfd',\n    'YAcy;': '\\u042f',\n    'yacy;': '\\u044f',\n    'Ycirc;': '\\u0176',\n    'ycirc;': '\\u0177',\n    'Ycy;': '\\u042b',\n    'ycy;': '\\u044b',\n    'yen': '\\xa5',\n    'yen;': '\\xa5',\n    'Yfr;': '\\U0001d51c',\n    'yfr;': '\\U0001d536',\n    'YIcy;': '\\u0407',\n    'yicy;': '\\u0457',\n    'Yopf;': '\\U0001d550',\n    'yopf;': '\\U0001d56a',\n    'Yscr;': '\\U0001d4b4',\n    'yscr;': '\\U0001d4ce',\n    'YUcy;': '\\u042e',\n    'yucy;': '\\u044e',\n    'yuml': '\\xff',\n    'Yuml;': '\\u0178',\n    'yuml;': '\\xff',\n    'Zacute;': '\\u0179',\n    'zacute;': '\\u017a',\n    'Zcaron;': '\\u017d',\n    'zcaron;': '\\u017e',\n    'Zcy;': '\\u0417',\n    'zcy;': '\\u0437',\n    'Zdot;': '\\u017b',\n    'zdot;': '\\u017c',\n    'zeetrf;': '\\u2128',\n    'ZeroWidthSpace;': '\\u200b',\n    'Zeta;': '\\u0396',\n    'zeta;': '\\u03b6',\n    'Zfr;': '\\u2128',\n    'zfr;': '\\U0001d537',\n    'ZHcy;': '\\u0416',\n    'zhcy;': '\\u0436',\n    'zigrarr;': '\\u21dd',\n    'Zopf;': '\\u2124',\n    'zopf;': '\\U0001d56b',\n    'Zscr;': '\\U0001d4b5',\n    'zscr;': '\\U0001d4cf',\n    'zwj;': '\\u200d',\n    'zwnj;': '\\u200c',\n}\n\n# maps the Unicode codepoint to the HTML entity name\ncodepoint2name = {}\n\n# maps the HTML entity name to the character\n# (or a character reference if the character is outside the Latin-1 range)\nentitydefs = {}\n\nfor (name, codepoint) in name2codepoint.items():\n    codepoint2name[codepoint] = name\n    entitydefs[name] = chr(codepoint)\n\ndel name, codepoint\n"], "unittest.test.test_loader": [".py", "import sys\nimport types\n\n\nimport unittest\n\n\nclass Test_TestLoader(unittest.TestCase):\n\n    ### Tests for TestLoader.loadTestsFromTestCase\n    ################################################################\n\n    # \"Return a suite of all tests cases contained in the TestCase-derived\n    # class testCaseClass\"\n    def test_loadTestsFromTestCase(self):\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foo_bar(self): pass\n\n        tests = unittest.TestSuite([Foo('test_1'), Foo('test_2')])\n\n        loader = unittest.TestLoader()\n        self.assertEqual(loader.loadTestsFromTestCase(Foo), tests)\n\n    # \"Return a suite of all tests cases contained in the TestCase-derived\n    # class testCaseClass\"\n    #\n    # Make sure it does the right thing even if no tests were found\n    def test_loadTestsFromTestCase__no_matches(self):\n        class Foo(unittest.TestCase):\n            def foo_bar(self): pass\n\n        empty_suite = unittest.TestSuite()\n\n        loader = unittest.TestLoader()\n        self.assertEqual(loader.loadTestsFromTestCase(Foo), empty_suite)\n\n    # \"Return a suite of all tests cases contained in the TestCase-derived\n    # class testCaseClass\"\n    #\n    # What happens if loadTestsFromTestCase() is given an object\n    # that isn't a subclass of TestCase? Specifically, what happens\n    # if testCaseClass is a subclass of TestSuite?\n    #\n    # This is checked for specifically in the code, so we better add a\n    # test for it.\n    def test_loadTestsFromTestCase__TestSuite_subclass(self):\n        class NotATestCase(unittest.TestSuite):\n            pass\n\n        loader = unittest.TestLoader()\n        try:\n            loader.loadTestsFromTestCase(NotATestCase)\n        except TypeError:\n            pass\n        else:\n            self.fail('Should raise TypeError')\n\n    # \"Return a suite of all tests cases contained in the TestCase-derived\n    # class testCaseClass\"\n    #\n    # Make sure loadTestsFromTestCase() picks up the default test method\n    # name (as specified by TestCase), even though the method name does\n    # not match the default TestLoader.testMethodPrefix string\n    def test_loadTestsFromTestCase__default_method_name(self):\n        class Foo(unittest.TestCase):\n            def runTest(self):\n                pass\n\n        loader = unittest.TestLoader()\n        # This has to be false for the test to succeed\n        self.assertFalse('runTest'.startswith(loader.testMethodPrefix))\n\n        suite = loader.loadTestsFromTestCase(Foo)\n        self.assertIsInstance(suite, loader.suiteClass)\n        self.assertEqual(list(suite), [Foo('runTest')])\n\n    ################################################################\n    ### /Tests for TestLoader.loadTestsFromTestCase\n\n    ### Tests for TestLoader.loadTestsFromModule\n    ################################################################\n\n    # \"This method searches `module` for classes derived from TestCase\"\n    def test_loadTestsFromModule__TestCase_subclass(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testcase_1 = MyTestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromModule(m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        expected = [loader.suiteClass([MyTestCase('test')])]\n        self.assertEqual(list(suite), expected)\n\n    # \"This method searches `module` for classes derived from TestCase\"\n    #\n    # What happens if no tests are found (no TestCase instances)?\n    def test_loadTestsFromModule__no_TestCase_instances(self):\n        m = types.ModuleType('m')\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromModule(m)\n        self.assertIsInstance(suite, loader.suiteClass)\n        self.assertEqual(list(suite), [])\n\n    # \"This method searches `module` for classes derived from TestCase\"\n    #\n    # What happens if no tests are found (TestCases instances, but no tests)?\n    def test_loadTestsFromModule__no_TestCase_tests(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            pass\n        m.testcase_1 = MyTestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromModule(m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        self.assertEqual(list(suite), [loader.suiteClass()])\n\n    # \"This method searches `module` for classes derived from TestCase\"s\n    #\n    # What happens if loadTestsFromModule() is given something other\n    # than a module?\n    #\n    # XXX Currently, it succeeds anyway. This flexibility\n    # should either be documented or loadTestsFromModule() should\n    # raise a TypeError\n    #\n    # XXX Certain people are using this behaviour. We'll add a test for it\n    def test_loadTestsFromModule__not_a_module(self):\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n\n        class NotAModule(object):\n            test_2 = MyTestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromModule(NotAModule)\n\n        reference = [unittest.TestSuite([MyTestCase('test')])]\n        self.assertEqual(list(suite), reference)\n\n\n    # Check that loadTestsFromModule honors (or not) a module\n    # with a load_tests function.\n    def test_loadTestsFromModule__load_tests(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testcase_1 = MyTestCase\n\n        load_tests_args = []\n        def load_tests(loader, tests, pattern):\n            self.assertIsInstance(tests, unittest.TestSuite)\n            load_tests_args.extend((loader, tests, pattern))\n            return tests\n        m.load_tests = load_tests\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromModule(m)\n        self.assertIsInstance(suite, unittest.TestSuite)\n        self.assertEqual(load_tests_args, [loader, suite, None])\n\n        load_tests_args = []\n        suite = loader.loadTestsFromModule(m, use_load_tests=False)\n        self.assertEqual(load_tests_args, [])\n\n    def test_loadTestsFromModule__faulty_load_tests(self):\n        m = types.ModuleType('m')\n\n        def load_tests(loader, tests, pattern):\n            raise TypeError('some failure')\n        m.load_tests = load_tests\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromModule(m)\n        self.assertIsInstance(suite, unittest.TestSuite)\n        self.assertEqual(suite.countTestCases(), 1)\n        test = list(suite)[0]\n\n        self.assertRaisesRegex(TypeError, \"some failure\", test.m)\n\n    ################################################################\n    ### /Tests for TestLoader.loadTestsFromModule()\n\n    ### Tests for TestLoader.loadTestsFromName()\n    ################################################################\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # Is ValueError raised in response to an empty name?\n    def test_loadTestsFromName__empty_name(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromName('')\n        except ValueError as e:\n            self.assertEqual(str(e), \"Empty module name\")\n        else:\n            self.fail(\"TestLoader.loadTestsFromName failed to raise ValueError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # What happens when the name contains invalid characters?\n    def test_loadTestsFromName__malformed_name(self):\n        loader = unittest.TestLoader()\n\n        # XXX Should this raise ValueError or ImportError?\n        try:\n            loader.loadTestsFromName('abc () //')\n        except ValueError:\n            pass\n        except ImportError:\n            pass\n        else:\n            self.fail(\"TestLoader.loadTestsFromName failed to raise ValueError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to a\n    # module\"\n    #\n    # What happens when a module by that name can't be found?\n    def test_loadTestsFromName__unknown_module_name(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromName('sdasfasfasdf')\n        except ImportError as e:\n            self.assertEqual(str(e), \"No module named 'sdasfasfasdf'\")\n        else:\n            self.fail(\"TestLoader.loadTestsFromName failed to raise ImportError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # What happens when the module is found, but the attribute can't?\n    def test_loadTestsFromName__unknown_attr_name(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromName('unittest.sdasfasfasdf')\n        except AttributeError as e:\n            self.assertEqual(str(e), \"'module' object has no attribute 'sdasfasfasdf'\")\n        else:\n            self.fail(\"TestLoader.loadTestsFromName failed to raise AttributeError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # What happens when we provide the module, but the attribute can't be\n    # found?\n    def test_loadTestsFromName__relative_unknown_name(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromName('sdasfasfasdf', unittest)\n        except AttributeError as e:\n            self.assertEqual(str(e), \"'module' object has no attribute 'sdasfasfasdf'\")\n        else:\n            self.fail(\"TestLoader.loadTestsFromName failed to raise AttributeError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    # ...\n    # \"The method optionally resolves name relative to the given module\"\n    #\n    # Does loadTestsFromName raise ValueError when passed an empty\n    # name relative to a provided module?\n    #\n    # XXX Should probably raise a ValueError instead of an AttributeError\n    def test_loadTestsFromName__relative_empty_name(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromName('', unittest)\n        except AttributeError as e:\n            pass\n        else:\n            self.fail(\"Failed to raise AttributeError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    # ...\n    # \"The method optionally resolves name relative to the given module\"\n    #\n    # What happens when an impossible name is given, relative to the provided\n    # `module`?\n    def test_loadTestsFromName__relative_malformed_name(self):\n        loader = unittest.TestLoader()\n\n        # XXX Should this raise AttributeError or ValueError?\n        try:\n            loader.loadTestsFromName('abc () //', unittest)\n        except ValueError:\n            pass\n        except AttributeError:\n            pass\n        else:\n            self.fail(\"TestLoader.loadTestsFromName failed to raise ValueError\")\n\n    # \"The method optionally resolves name relative to the given module\"\n    #\n    # Does loadTestsFromName raise TypeError when the `module` argument\n    # isn't a module object?\n    #\n    # XXX Accepts the not-a-module object, ignorning the object's type\n    # This should raise an exception or the method name should be changed\n    #\n    # XXX Some people are relying on this, so keep it for now\n    def test_loadTestsFromName__relative_not_a_module(self):\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n\n        class NotAModule(object):\n            test_2 = MyTestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromName('test_2', NotAModule)\n\n        reference = [MyTestCase('test')]\n        self.assertEqual(list(suite), reference)\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # Does it raise an exception if the name resolves to an invalid\n    # object?\n    def test_loadTestsFromName__relative_bad_object(self):\n        m = types.ModuleType('m')\n        m.testcase_1 = object()\n\n        loader = unittest.TestLoader()\n        try:\n            loader.loadTestsFromName('testcase_1', m)\n        except TypeError:\n            pass\n        else:\n            self.fail(\"Should have raised TypeError\")\n\n    # \"The specifier name is a ``dotted name'' that may\n    # resolve either to ... a test case class\"\n    def test_loadTestsFromName__relative_TestCase_subclass(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testcase_1 = MyTestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromName('testcase_1', m)\n        self.assertIsInstance(suite, loader.suiteClass)\n        self.assertEqual(list(suite), [MyTestCase('test')])\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    def test_loadTestsFromName__relative_TestSuite(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testsuite = unittest.TestSuite([MyTestCase('test')])\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromName('testsuite', m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        self.assertEqual(list(suite), [MyTestCase('test')])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a test method within a test case class\"\n    def test_loadTestsFromName__relative_testmethod(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testcase_1 = MyTestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromName('testcase_1.test', m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        self.assertEqual(list(suite), [MyTestCase('test')])\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # Does loadTestsFromName() raise the proper exception when trying to\n    # resolve \"a test method within a test case class\" that doesn't exist\n    # for the given name (relative to a provided module)?\n    def test_loadTestsFromName__relative_invalid_testmethod(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testcase_1 = MyTestCase\n\n        loader = unittest.TestLoader()\n        try:\n            loader.loadTestsFromName('testcase_1.testfoo', m)\n        except AttributeError as e:\n            self.assertEqual(str(e), \"type object 'MyTestCase' has no attribute 'testfoo'\")\n        else:\n            self.fail(\"Failed to raise AttributeError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a callable object which returns a ... TestSuite instance\"\n    def test_loadTestsFromName__callable__TestSuite(self):\n        m = types.ModuleType('m')\n        testcase_1 = unittest.FunctionTestCase(lambda: None)\n        testcase_2 = unittest.FunctionTestCase(lambda: None)\n        def return_TestSuite():\n            return unittest.TestSuite([testcase_1, testcase_2])\n        m.return_TestSuite = return_TestSuite\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromName('return_TestSuite', m)\n        self.assertIsInstance(suite, loader.suiteClass)\n        self.assertEqual(list(suite), [testcase_1, testcase_2])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a callable object which returns a TestCase ... instance\"\n    def test_loadTestsFromName__callable__TestCase_instance(self):\n        m = types.ModuleType('m')\n        testcase_1 = unittest.FunctionTestCase(lambda: None)\n        def return_TestCase():\n            return testcase_1\n        m.return_TestCase = return_TestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromName('return_TestCase', m)\n        self.assertIsInstance(suite, loader.suiteClass)\n        self.assertEqual(list(suite), [testcase_1])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a callable object which returns a TestCase ... instance\"\n    #*****************************************************************\n    #Override the suiteClass attribute to ensure that the suiteClass\n    #attribute is used\n    def test_loadTestsFromName__callable__TestCase_instance_ProperSuiteClass(self):\n        class SubTestSuite(unittest.TestSuite):\n            pass\n        m = types.ModuleType('m')\n        testcase_1 = unittest.FunctionTestCase(lambda: None)\n        def return_TestCase():\n            return testcase_1\n        m.return_TestCase = return_TestCase\n\n        loader = unittest.TestLoader()\n        loader.suiteClass = SubTestSuite\n        suite = loader.loadTestsFromName('return_TestCase', m)\n        self.assertIsInstance(suite, loader.suiteClass)\n        self.assertEqual(list(suite), [testcase_1])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a test method within a test case class\"\n    #*****************************************************************\n    #Override the suiteClass attribute to ensure that the suiteClass\n    #attribute is used\n    def test_loadTestsFromName__relative_testmethod_ProperSuiteClass(self):\n        class SubTestSuite(unittest.TestSuite):\n            pass\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testcase_1 = MyTestCase\n\n        loader = unittest.TestLoader()\n        loader.suiteClass=SubTestSuite\n        suite = loader.loadTestsFromName('testcase_1.test', m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        self.assertEqual(list(suite), [MyTestCase('test')])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a callable object which returns a TestCase or TestSuite instance\"\n    #\n    # What happens if the callable returns something else?\n    def test_loadTestsFromName__callable__wrong_type(self):\n        m = types.ModuleType('m')\n        def return_wrong():\n            return 6\n        m.return_wrong = return_wrong\n\n        loader = unittest.TestLoader()\n        try:\n            suite = loader.loadTestsFromName('return_wrong', m)\n        except TypeError:\n            pass\n        else:\n            self.fail(\"TestLoader.loadTestsFromName failed to raise TypeError\")\n\n    # \"The specifier can refer to modules and packages which have not been\n    # imported; they will be imported as a side-effect\"\n    def test_loadTestsFromName__module_not_loaded(self):\n        # We're going to try to load this module as a side-effect, so it\n        # better not be loaded before we try.\n        #\n        module_name = 'unittest.test.dummy'\n        sys.modules.pop(module_name, None)\n\n        loader = unittest.TestLoader()\n        try:\n            suite = loader.loadTestsFromName(module_name)\n\n            self.assertIsInstance(suite, loader.suiteClass)\n            self.assertEqual(list(suite), [])\n\n            # module should now be loaded, thanks to loadTestsFromName()\n            self.assertIn(module_name, sys.modules)\n        finally:\n            if module_name in sys.modules:\n                del sys.modules[module_name]\n\n    ################################################################\n    ### Tests for TestLoader.loadTestsFromName()\n\n    ### Tests for TestLoader.loadTestsFromNames()\n    ################################################################\n\n    # \"Similar to loadTestsFromName(), but takes a sequence of names rather\n    # than a single name.\"\n    #\n    # What happens if that sequence of names is empty?\n    def test_loadTestsFromNames__empty_name_list(self):\n        loader = unittest.TestLoader()\n\n        suite = loader.loadTestsFromNames([])\n        self.assertIsInstance(suite, loader.suiteClass)\n        self.assertEqual(list(suite), [])\n\n    # \"Similar to loadTestsFromName(), but takes a sequence of names rather\n    # than a single name.\"\n    # ...\n    # \"The method optionally resolves name relative to the given module\"\n    #\n    # What happens if that sequence of names is empty?\n    #\n    # XXX Should this raise a ValueError or just return an empty TestSuite?\n    def test_loadTestsFromNames__relative_empty_name_list(self):\n        loader = unittest.TestLoader()\n\n        suite = loader.loadTestsFromNames([], unittest)\n        self.assertIsInstance(suite, loader.suiteClass)\n        self.assertEqual(list(suite), [])\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # Is ValueError raised in response to an empty name?\n    def test_loadTestsFromNames__empty_name(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromNames([''])\n        except ValueError as e:\n            self.assertEqual(str(e), \"Empty module name\")\n        else:\n            self.fail(\"TestLoader.loadTestsFromNames failed to raise ValueError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # What happens when presented with an impossible module name?\n    def test_loadTestsFromNames__malformed_name(self):\n        loader = unittest.TestLoader()\n\n        # XXX Should this raise ValueError or ImportError?\n        try:\n            loader.loadTestsFromNames(['abc () //'])\n        except ValueError:\n            pass\n        except ImportError:\n            pass\n        else:\n            self.fail(\"TestLoader.loadTestsFromNames failed to raise ValueError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # What happens when no module can be found for the given name?\n    def test_loadTestsFromNames__unknown_module_name(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromNames(['sdasfasfasdf'])\n        except ImportError as e:\n            self.assertEqual(str(e), \"No module named 'sdasfasfasdf'\")\n        else:\n            self.fail(\"TestLoader.loadTestsFromNames failed to raise ImportError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # What happens when the module can be found, but not the attribute?\n    def test_loadTestsFromNames__unknown_attr_name(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromNames(['unittest.sdasfasfasdf', 'unittest'])\n        except AttributeError as e:\n            self.assertEqual(str(e), \"'module' object has no attribute 'sdasfasfasdf'\")\n        else:\n            self.fail(\"TestLoader.loadTestsFromNames failed to raise AttributeError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    # ...\n    # \"The method optionally resolves name relative to the given module\"\n    #\n    # What happens when given an unknown attribute on a specified `module`\n    # argument?\n    def test_loadTestsFromNames__unknown_name_relative_1(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromNames(['sdasfasfasdf'], unittest)\n        except AttributeError as e:\n            self.assertEqual(str(e), \"'module' object has no attribute 'sdasfasfasdf'\")\n        else:\n            self.fail(\"TestLoader.loadTestsFromName failed to raise AttributeError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    # ...\n    # \"The method optionally resolves name relative to the given module\"\n    #\n    # Do unknown attributes (relative to a provided module) still raise an\n    # exception even in the presence of valid attribute names?\n    def test_loadTestsFromNames__unknown_name_relative_2(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromNames(['TestCase', 'sdasfasfasdf'], unittest)\n        except AttributeError as e:\n            self.assertEqual(str(e), \"'module' object has no attribute 'sdasfasfasdf'\")\n        else:\n            self.fail(\"TestLoader.loadTestsFromName failed to raise AttributeError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    # ...\n    # \"The method optionally resolves name relative to the given module\"\n    #\n    # What happens when faced with the empty string?\n    #\n    # XXX This currently raises AttributeError, though ValueError is probably\n    # more appropriate\n    def test_loadTestsFromNames__relative_empty_name(self):\n        loader = unittest.TestLoader()\n\n        try:\n            loader.loadTestsFromNames([''], unittest)\n        except AttributeError:\n            pass\n        else:\n            self.fail(\"Failed to raise ValueError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    # ...\n    # \"The method optionally resolves name relative to the given module\"\n    #\n    # What happens when presented with an impossible attribute name?\n    def test_loadTestsFromNames__relative_malformed_name(self):\n        loader = unittest.TestLoader()\n\n        # XXX Should this raise AttributeError or ValueError?\n        try:\n            loader.loadTestsFromNames(['abc () //'], unittest)\n        except AttributeError:\n            pass\n        except ValueError:\n            pass\n        else:\n            self.fail(\"TestLoader.loadTestsFromNames failed to raise ValueError\")\n\n    # \"The method optionally resolves name relative to the given module\"\n    #\n    # Does loadTestsFromNames() make sure the provided `module` is in fact\n    # a module?\n    #\n    # XXX This validation is currently not done. This flexibility should\n    # either be documented or a TypeError should be raised.\n    def test_loadTestsFromNames__relative_not_a_module(self):\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n\n        class NotAModule(object):\n            test_2 = MyTestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromNames(['test_2'], NotAModule)\n\n        reference = [unittest.TestSuite([MyTestCase('test')])]\n        self.assertEqual(list(suite), reference)\n\n    # \"The specifier name is a ``dotted name'' that may resolve either to\n    # a module, a test case class, a TestSuite instance, a test method\n    # within a test case class, or a callable object which returns a\n    # TestCase or TestSuite instance.\"\n    #\n    # Does it raise an exception if the name resolves to an invalid\n    # object?\n    def test_loadTestsFromNames__relative_bad_object(self):\n        m = types.ModuleType('m')\n        m.testcase_1 = object()\n\n        loader = unittest.TestLoader()\n        try:\n            loader.loadTestsFromNames(['testcase_1'], m)\n        except TypeError:\n            pass\n        else:\n            self.fail(\"Should have raised TypeError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a test case class\"\n    def test_loadTestsFromNames__relative_TestCase_subclass(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testcase_1 = MyTestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromNames(['testcase_1'], m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        expected = loader.suiteClass([MyTestCase('test')])\n        self.assertEqual(list(suite), [expected])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a TestSuite instance\"\n    def test_loadTestsFromNames__relative_TestSuite(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testsuite = unittest.TestSuite([MyTestCase('test')])\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromNames(['testsuite'], m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        self.assertEqual(list(suite), [m.testsuite])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to ... a\n    # test method within a test case class\"\n    def test_loadTestsFromNames__relative_testmethod(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testcase_1 = MyTestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromNames(['testcase_1.test'], m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        ref_suite = unittest.TestSuite([MyTestCase('test')])\n        self.assertEqual(list(suite), [ref_suite])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to ... a\n    # test method within a test case class\"\n    #\n    # Does the method gracefully handle names that initially look like they\n    # resolve to \"a test method within a test case class\" but don't?\n    def test_loadTestsFromNames__relative_invalid_testmethod(self):\n        m = types.ModuleType('m')\n        class MyTestCase(unittest.TestCase):\n            def test(self):\n                pass\n        m.testcase_1 = MyTestCase\n\n        loader = unittest.TestLoader()\n        try:\n            loader.loadTestsFromNames(['testcase_1.testfoo'], m)\n        except AttributeError as e:\n            self.assertEqual(str(e), \"type object 'MyTestCase' has no attribute 'testfoo'\")\n        else:\n            self.fail(\"Failed to raise AttributeError\")\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a callable object which returns a ... TestSuite instance\"\n    def test_loadTestsFromNames__callable__TestSuite(self):\n        m = types.ModuleType('m')\n        testcase_1 = unittest.FunctionTestCase(lambda: None)\n        testcase_2 = unittest.FunctionTestCase(lambda: None)\n        def return_TestSuite():\n            return unittest.TestSuite([testcase_1, testcase_2])\n        m.return_TestSuite = return_TestSuite\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromNames(['return_TestSuite'], m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        expected = unittest.TestSuite([testcase_1, testcase_2])\n        self.assertEqual(list(suite), [expected])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a callable object which returns a TestCase ... instance\"\n    def test_loadTestsFromNames__callable__TestCase_instance(self):\n        m = types.ModuleType('m')\n        testcase_1 = unittest.FunctionTestCase(lambda: None)\n        def return_TestCase():\n            return testcase_1\n        m.return_TestCase = return_TestCase\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromNames(['return_TestCase'], m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        ref_suite = unittest.TestSuite([testcase_1])\n        self.assertEqual(list(suite), [ref_suite])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a callable object which returns a TestCase or TestSuite instance\"\n    #\n    # Are staticmethods handled correctly?\n    def test_loadTestsFromNames__callable__call_staticmethod(self):\n        m = types.ModuleType('m')\n        class Test1(unittest.TestCase):\n            def test(self):\n                pass\n\n        testcase_1 = Test1('test')\n        class Foo(unittest.TestCase):\n            @staticmethod\n            def foo():\n                return testcase_1\n        m.Foo = Foo\n\n        loader = unittest.TestLoader()\n        suite = loader.loadTestsFromNames(['Foo.foo'], m)\n        self.assertIsInstance(suite, loader.suiteClass)\n\n        ref_suite = unittest.TestSuite([testcase_1])\n        self.assertEqual(list(suite), [ref_suite])\n\n    # \"The specifier name is a ``dotted name'' that may resolve ... to\n    # ... a callable object which returns a TestCase or TestSuite instance\"\n    #\n    # What happens when the callable returns something else?\n    def test_loadTestsFromNames__callable__wrong_type(self):\n        m = types.ModuleType('m')\n        def return_wrong():\n            return 6\n        m.return_wrong = return_wrong\n\n        loader = unittest.TestLoader()\n        try:\n            suite = loader.loadTestsFromNames(['return_wrong'], m)\n        except TypeError:\n            pass\n        else:\n            self.fail(\"TestLoader.loadTestsFromNames failed to raise TypeError\")\n\n    # \"The specifier can refer to modules and packages which have not been\n    # imported; they will be imported as a side-effect\"\n    def test_loadTestsFromNames__module_not_loaded(self):\n        # We're going to try to load this module as a side-effect, so it\n        # better not be loaded before we try.\n        #\n        module_name = 'unittest.test.dummy'\n        sys.modules.pop(module_name, None)\n\n        loader = unittest.TestLoader()\n        try:\n            suite = loader.loadTestsFromNames([module_name])\n\n            self.assertIsInstance(suite, loader.suiteClass)\n            self.assertEqual(list(suite), [unittest.TestSuite()])\n\n            # module should now be loaded, thanks to loadTestsFromName()\n            self.assertIn(module_name, sys.modules)\n        finally:\n            if module_name in sys.modules:\n                del sys.modules[module_name]\n\n    ################################################################\n    ### /Tests for TestLoader.loadTestsFromNames()\n\n    ### Tests for TestLoader.getTestCaseNames()\n    ################################################################\n\n    # \"Return a sorted sequence of method names found within testCaseClass\"\n    #\n    # Test.foobar is defined to make sure getTestCaseNames() respects\n    # loader.testMethodPrefix\n    def test_getTestCaseNames(self):\n        class Test(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foobar(self): pass\n\n        loader = unittest.TestLoader()\n\n        self.assertEqual(loader.getTestCaseNames(Test), ['test_1', 'test_2'])\n\n    # \"Return a sorted sequence of method names found within testCaseClass\"\n    #\n    # Does getTestCaseNames() behave appropriately if no tests are found?\n    def test_getTestCaseNames__no_tests(self):\n        class Test(unittest.TestCase):\n            def foobar(self): pass\n\n        loader = unittest.TestLoader()\n\n        self.assertEqual(loader.getTestCaseNames(Test), [])\n\n    # \"Return a sorted sequence of method names found within testCaseClass\"\n    #\n    # Are not-TestCases handled gracefully?\n    #\n    # XXX This should raise a TypeError, not return a list\n    #\n    # XXX It's too late in the 2.5 release cycle to fix this, but it should\n    # probably be revisited for 2.6\n    def test_getTestCaseNames__not_a_TestCase(self):\n        class BadCase(int):\n            def test_foo(self):\n                pass\n\n        loader = unittest.TestLoader()\n        names = loader.getTestCaseNames(BadCase)\n\n        self.assertEqual(names, ['test_foo'])\n\n    # \"Return a sorted sequence of method names found within testCaseClass\"\n    #\n    # Make sure inherited names are handled.\n    #\n    # TestP.foobar is defined to make sure getTestCaseNames() respects\n    # loader.testMethodPrefix\n    def test_getTestCaseNames__inheritance(self):\n        class TestP(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foobar(self): pass\n\n        class TestC(TestP):\n            def test_1(self): pass\n            def test_3(self): pass\n\n        loader = unittest.TestLoader()\n\n        names = ['test_1', 'test_2', 'test_3']\n        self.assertEqual(loader.getTestCaseNames(TestC), names)\n\n    ################################################################\n    ### /Tests for TestLoader.getTestCaseNames()\n\n    ### Tests for TestLoader.testMethodPrefix\n    ################################################################\n\n    # \"String giving the prefix of method names which will be interpreted as\n    # test methods\"\n    #\n    # Implicit in the documentation is that testMethodPrefix is respected by\n    # all loadTestsFrom* methods.\n    def test_testMethodPrefix__loadTestsFromTestCase(self):\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foo_bar(self): pass\n\n        tests_1 = unittest.TestSuite([Foo('foo_bar')])\n        tests_2 = unittest.TestSuite([Foo('test_1'), Foo('test_2')])\n\n        loader = unittest.TestLoader()\n        loader.testMethodPrefix = 'foo'\n        self.assertEqual(loader.loadTestsFromTestCase(Foo), tests_1)\n\n        loader.testMethodPrefix = 'test'\n        self.assertEqual(loader.loadTestsFromTestCase(Foo), tests_2)\n\n    # \"String giving the prefix of method names which will be interpreted as\n    # test methods\"\n    #\n    # Implicit in the documentation is that testMethodPrefix is respected by\n    # all loadTestsFrom* methods.\n    def test_testMethodPrefix__loadTestsFromModule(self):\n        m = types.ModuleType('m')\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foo_bar(self): pass\n        m.Foo = Foo\n\n        tests_1 = [unittest.TestSuite([Foo('foo_bar')])]\n        tests_2 = [unittest.TestSuite([Foo('test_1'), Foo('test_2')])]\n\n        loader = unittest.TestLoader()\n        loader.testMethodPrefix = 'foo'\n        self.assertEqual(list(loader.loadTestsFromModule(m)), tests_1)\n\n        loader.testMethodPrefix = 'test'\n        self.assertEqual(list(loader.loadTestsFromModule(m)), tests_2)\n\n    # \"String giving the prefix of method names which will be interpreted as\n    # test methods\"\n    #\n    # Implicit in the documentation is that testMethodPrefix is respected by\n    # all loadTestsFrom* methods.\n    def test_testMethodPrefix__loadTestsFromName(self):\n        m = types.ModuleType('m')\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foo_bar(self): pass\n        m.Foo = Foo\n\n        tests_1 = unittest.TestSuite([Foo('foo_bar')])\n        tests_2 = unittest.TestSuite([Foo('test_1'), Foo('test_2')])\n\n        loader = unittest.TestLoader()\n        loader.testMethodPrefix = 'foo'\n        self.assertEqual(loader.loadTestsFromName('Foo', m), tests_1)\n\n        loader.testMethodPrefix = 'test'\n        self.assertEqual(loader.loadTestsFromName('Foo', m), tests_2)\n\n    # \"String giving the prefix of method names which will be interpreted as\n    # test methods\"\n    #\n    # Implicit in the documentation is that testMethodPrefix is respected by\n    # all loadTestsFrom* methods.\n    def test_testMethodPrefix__loadTestsFromNames(self):\n        m = types.ModuleType('m')\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foo_bar(self): pass\n        m.Foo = Foo\n\n        tests_1 = unittest.TestSuite([unittest.TestSuite([Foo('foo_bar')])])\n        tests_2 = unittest.TestSuite([Foo('test_1'), Foo('test_2')])\n        tests_2 = unittest.TestSuite([tests_2])\n\n        loader = unittest.TestLoader()\n        loader.testMethodPrefix = 'foo'\n        self.assertEqual(loader.loadTestsFromNames(['Foo'], m), tests_1)\n\n        loader.testMethodPrefix = 'test'\n        self.assertEqual(loader.loadTestsFromNames(['Foo'], m), tests_2)\n\n    # \"The default value is 'test'\"\n    def test_testMethodPrefix__default_value(self):\n        loader = unittest.TestLoader()\n        self.assertEqual(loader.testMethodPrefix, 'test')\n\n    ################################################################\n    ### /Tests for TestLoader.testMethodPrefix\n\n    ### Tests for TestLoader.sortTestMethodsUsing\n    ################################################################\n\n    # \"Function to be used to compare method names when sorting them in\n    # getTestCaseNames() and all the loadTestsFromX() methods\"\n    def test_sortTestMethodsUsing__loadTestsFromTestCase(self):\n        def reversed_cmp(x, y):\n            return -((x > y) - (x < y))\n\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n\n        loader = unittest.TestLoader()\n        loader.sortTestMethodsUsing = reversed_cmp\n\n        tests = loader.suiteClass([Foo('test_2'), Foo('test_1')])\n        self.assertEqual(loader.loadTestsFromTestCase(Foo), tests)\n\n    # \"Function to be used to compare method names when sorting them in\n    # getTestCaseNames() and all the loadTestsFromX() methods\"\n    def test_sortTestMethodsUsing__loadTestsFromModule(self):\n        def reversed_cmp(x, y):\n            return -((x > y) - (x < y))\n\n        m = types.ModuleType('m')\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n        m.Foo = Foo\n\n        loader = unittest.TestLoader()\n        loader.sortTestMethodsUsing = reversed_cmp\n\n        tests = [loader.suiteClass([Foo('test_2'), Foo('test_1')])]\n        self.assertEqual(list(loader.loadTestsFromModule(m)), tests)\n\n    # \"Function to be used to compare method names when sorting them in\n    # getTestCaseNames() and all the loadTestsFromX() methods\"\n    def test_sortTestMethodsUsing__loadTestsFromName(self):\n        def reversed_cmp(x, y):\n            return -((x > y) - (x < y))\n\n        m = types.ModuleType('m')\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n        m.Foo = Foo\n\n        loader = unittest.TestLoader()\n        loader.sortTestMethodsUsing = reversed_cmp\n\n        tests = loader.suiteClass([Foo('test_2'), Foo('test_1')])\n        self.assertEqual(loader.loadTestsFromName('Foo', m), tests)\n\n    # \"Function to be used to compare method names when sorting them in\n    # getTestCaseNames() and all the loadTestsFromX() methods\"\n    def test_sortTestMethodsUsing__loadTestsFromNames(self):\n        def reversed_cmp(x, y):\n            return -((x > y) - (x < y))\n\n        m = types.ModuleType('m')\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n        m.Foo = Foo\n\n        loader = unittest.TestLoader()\n        loader.sortTestMethodsUsing = reversed_cmp\n\n        tests = [loader.suiteClass([Foo('test_2'), Foo('test_1')])]\n        self.assertEqual(list(loader.loadTestsFromNames(['Foo'], m)), tests)\n\n    # \"Function to be used to compare method names when sorting them in\n    # getTestCaseNames()\"\n    #\n    # Does it actually affect getTestCaseNames()?\n    def test_sortTestMethodsUsing__getTestCaseNames(self):\n        def reversed_cmp(x, y):\n            return -((x > y) - (x < y))\n\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n\n        loader = unittest.TestLoader()\n        loader.sortTestMethodsUsing = reversed_cmp\n\n        test_names = ['test_2', 'test_1']\n        self.assertEqual(loader.getTestCaseNames(Foo), test_names)\n\n    # \"The default value is the built-in cmp() function\"\n    # Since cmp is now defunct, we simply verify that the results\n    # occur in the same order as they would with the default sort.\n    def test_sortTestMethodsUsing__default_value(self):\n        loader = unittest.TestLoader()\n\n        class Foo(unittest.TestCase):\n            def test_2(self): pass\n            def test_3(self): pass\n            def test_1(self): pass\n\n        test_names = ['test_2', 'test_3', 'test_1']\n        self.assertEqual(loader.getTestCaseNames(Foo), sorted(test_names))\n\n\n    # \"it can be set to None to disable the sort.\"\n    #\n    # XXX How is this different from reassigning cmp? Are the tests returned\n    # in a random order or something? This behaviour should die\n    def test_sortTestMethodsUsing__None(self):\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n\n        loader = unittest.TestLoader()\n        loader.sortTestMethodsUsing = None\n\n        test_names = ['test_2', 'test_1']\n        self.assertEqual(set(loader.getTestCaseNames(Foo)), set(test_names))\n\n    ################################################################\n    ### /Tests for TestLoader.sortTestMethodsUsing\n\n    ### Tests for TestLoader.suiteClass\n    ################################################################\n\n    # \"Callable object that constructs a test suite from a list of tests.\"\n    def test_suiteClass__loadTestsFromTestCase(self):\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foo_bar(self): pass\n\n        tests = [Foo('test_1'), Foo('test_2')]\n\n        loader = unittest.TestLoader()\n        loader.suiteClass = list\n        self.assertEqual(loader.loadTestsFromTestCase(Foo), tests)\n\n    # It is implicit in the documentation for TestLoader.suiteClass that\n    # all TestLoader.loadTestsFrom* methods respect it. Let's make sure\n    def test_suiteClass__loadTestsFromModule(self):\n        m = types.ModuleType('m')\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foo_bar(self): pass\n        m.Foo = Foo\n\n        tests = [[Foo('test_1'), Foo('test_2')]]\n\n        loader = unittest.TestLoader()\n        loader.suiteClass = list\n        self.assertEqual(loader.loadTestsFromModule(m), tests)\n\n    # It is implicit in the documentation for TestLoader.suiteClass that\n    # all TestLoader.loadTestsFrom* methods respect it. Let's make sure\n    def test_suiteClass__loadTestsFromName(self):\n        m = types.ModuleType('m')\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foo_bar(self): pass\n        m.Foo = Foo\n\n        tests = [Foo('test_1'), Foo('test_2')]\n\n        loader = unittest.TestLoader()\n        loader.suiteClass = list\n        self.assertEqual(loader.loadTestsFromName('Foo', m), tests)\n\n    # It is implicit in the documentation for TestLoader.suiteClass that\n    # all TestLoader.loadTestsFrom* methods respect it. Let's make sure\n    def test_suiteClass__loadTestsFromNames(self):\n        m = types.ModuleType('m')\n        class Foo(unittest.TestCase):\n            def test_1(self): pass\n            def test_2(self): pass\n            def foo_bar(self): pass\n        m.Foo = Foo\n\n        tests = [[Foo('test_1'), Foo('test_2')]]\n\n        loader = unittest.TestLoader()\n        loader.suiteClass = list\n        self.assertEqual(loader.loadTestsFromNames(['Foo'], m), tests)\n\n    # \"The default value is the TestSuite class\"\n    def test_suiteClass__default_value(self):\n        loader = unittest.TestLoader()\n        self.assertTrue(loader.suiteClass is unittest.TestSuite)\n"], "unittest.test.test_runner": [".py", "import io\nimport os\nimport sys\nimport pickle\nimport subprocess\n\nimport unittest\n\nfrom .support import LoggingResult, ResultWithNoStartTestRunStopTestRun\n\n\nclass TestCleanUp(unittest.TestCase):\n\n    def testCleanUp(self):\n        class TestableTest(unittest.TestCase):\n            def testNothing(self):\n                pass\n\n        test = TestableTest('testNothing')\n        self.assertEqual(test._cleanups, [])\n\n        cleanups = []\n\n        def cleanup1(*args, **kwargs):\n            cleanups.append((1, args, kwargs))\n\n        def cleanup2(*args, **kwargs):\n            cleanups.append((2, args, kwargs))\n\n        test.addCleanup(cleanup1, 1, 2, 3, four='hello', five='goodbye')\n        test.addCleanup(cleanup2)\n\n        self.assertEqual(test._cleanups,\n                         [(cleanup1, (1, 2, 3), dict(four='hello', five='goodbye')),\n                          (cleanup2, (), {})])\n\n        self.assertTrue(test.doCleanups())\n        self.assertEqual(cleanups, [(2, (), {}), (1, (1, 2, 3), dict(four='hello', five='goodbye'))])\n\n    def testCleanUpWithErrors(self):\n        class TestableTest(unittest.TestCase):\n            def testNothing(self):\n                pass\n\n        class MockOutcome(object):\n            success = True\n            errors = []\n\n        test = TestableTest('testNothing')\n        test._outcomeForDoCleanups = MockOutcome\n\n        exc1 = Exception('foo')\n        exc2 = Exception('bar')\n        def cleanup1():\n            raise exc1\n\n        def cleanup2():\n            raise exc2\n\n        test.addCleanup(cleanup1)\n        test.addCleanup(cleanup2)\n\n        self.assertFalse(test.doCleanups())\n        self.assertFalse(MockOutcome.success)\n\n        (Type1, instance1, _), (Type2, instance2, _) = reversed(MockOutcome.errors)\n        self.assertEqual((Type1, instance1), (Exception, exc1))\n        self.assertEqual((Type2, instance2), (Exception, exc2))\n\n    def testCleanupInRun(self):\n        blowUp = False\n        ordering = []\n\n        class TestableTest(unittest.TestCase):\n            def setUp(self):\n                ordering.append('setUp')\n                if blowUp:\n                    raise Exception('foo')\n\n            def testNothing(self):\n                ordering.append('test')\n\n            def tearDown(self):\n                ordering.append('tearDown')\n\n        test = TestableTest('testNothing')\n\n        def cleanup1():\n            ordering.append('cleanup1')\n        def cleanup2():\n            ordering.append('cleanup2')\n        test.addCleanup(cleanup1)\n        test.addCleanup(cleanup2)\n\n        def success(some_test):\n            self.assertEqual(some_test, test)\n            ordering.append('success')\n\n        result = unittest.TestResult()\n        result.addSuccess = success\n\n        test.run(result)\n        self.assertEqual(ordering, ['setUp', 'test', 'tearDown',\n                                    'cleanup2', 'cleanup1', 'success'])\n\n        blowUp = True\n        ordering = []\n        test = TestableTest('testNothing')\n        test.addCleanup(cleanup1)\n        test.run(result)\n        self.assertEqual(ordering, ['setUp', 'cleanup1'])\n\n    def testTestCaseDebugExecutesCleanups(self):\n        ordering = []\n\n        class TestableTest(unittest.TestCase):\n            def setUp(self):\n                ordering.append('setUp')\n                self.addCleanup(cleanup1)\n\n            def testNothing(self):\n                ordering.append('test')\n\n            def tearDown(self):\n                ordering.append('tearDown')\n\n        test = TestableTest('testNothing')\n\n        def cleanup1():\n            ordering.append('cleanup1')\n            test.addCleanup(cleanup2)\n        def cleanup2():\n            ordering.append('cleanup2')\n\n        test.debug()\n        self.assertEqual(ordering, ['setUp', 'test', 'tearDown', 'cleanup1', 'cleanup2'])\n\n\nclass Test_TextTestRunner(unittest.TestCase):\n    \"\"\"Tests for TextTestRunner.\"\"\"\n\n    def test_init(self):\n        runner = unittest.TextTestRunner()\n        self.assertFalse(runner.failfast)\n        self.assertFalse(runner.buffer)\n        self.assertEqual(runner.verbosity, 1)\n        self.assertEqual(runner.warnings, None)\n        self.assertTrue(runner.descriptions)\n        self.assertEqual(runner.resultclass, unittest.TextTestResult)\n\n\n    def testBufferAndFailfast(self):\n        class Test(unittest.TestCase):\n            def testFoo(self):\n                pass\n        result = unittest.TestResult()\n        runner = unittest.TextTestRunner(stream=io.StringIO(), failfast=True,\n                                           buffer=True)\n        # Use our result object\n        runner._makeResult = lambda: result\n        runner.run(Test('testFoo'))\n\n        self.assertTrue(result.failfast)\n        self.assertTrue(result.buffer)\n\n    def testRunnerRegistersResult(self):\n        class Test(unittest.TestCase):\n            def testFoo(self):\n                pass\n        originalRegisterResult = unittest.runner.registerResult\n        def cleanup():\n            unittest.runner.registerResult = originalRegisterResult\n        self.addCleanup(cleanup)\n\n        result = unittest.TestResult()\n        runner = unittest.TextTestRunner(stream=io.StringIO())\n        # Use our result object\n        runner._makeResult = lambda: result\n\n        self.wasRegistered = 0\n        def fakeRegisterResult(thisResult):\n            self.wasRegistered += 1\n            self.assertEqual(thisResult, result)\n        unittest.runner.registerResult = fakeRegisterResult\n\n        runner.run(unittest.TestSuite())\n        self.assertEqual(self.wasRegistered, 1)\n\n    def test_works_with_result_without_startTestRun_stopTestRun(self):\n        class OldTextResult(ResultWithNoStartTestRunStopTestRun):\n            separator2 = ''\n            def printErrors(self):\n                pass\n\n        class Runner(unittest.TextTestRunner):\n            def __init__(self):\n                super(Runner, self).__init__(io.StringIO())\n\n            def _makeResult(self):\n                return OldTextResult()\n\n        runner = Runner()\n        runner.run(unittest.TestSuite())\n\n    def test_startTestRun_stopTestRun_called(self):\n        class LoggingTextResult(LoggingResult):\n            separator2 = ''\n            def printErrors(self):\n                pass\n\n        class LoggingRunner(unittest.TextTestRunner):\n            def __init__(self, events):\n                super(LoggingRunner, self).__init__(io.StringIO())\n                self._events = events\n\n            def _makeResult(self):\n                return LoggingTextResult(self._events)\n\n        events = []\n        runner = LoggingRunner(events)\n        runner.run(unittest.TestSuite())\n        expected = ['startTestRun', 'stopTestRun']\n        self.assertEqual(events, expected)\n\n    def test_pickle_unpickle(self):\n        # Issue #7197: a TextTestRunner should be (un)pickleable. This is\n        # required by test_multiprocessing under Windows (in verbose mode).\n        stream = io.StringIO(\"foo\")\n        runner = unittest.TextTestRunner(stream)\n        for protocol in range(2, pickle.HIGHEST_PROTOCOL + 1):\n            s = pickle.dumps(runner, protocol)\n            obj = pickle.loads(s)\n            # StringIO objects never compare equal, a cheap test instead.\n            self.assertEqual(obj.stream.getvalue(), stream.getvalue())\n\n    def test_resultclass(self):\n        def MockResultClass(*args):\n            return args\n        STREAM = object()\n        DESCRIPTIONS = object()\n        VERBOSITY = object()\n        runner = unittest.TextTestRunner(STREAM, DESCRIPTIONS, VERBOSITY,\n                                         resultclass=MockResultClass)\n        self.assertEqual(runner.resultclass, MockResultClass)\n\n        expectedresult = (runner.stream, DESCRIPTIONS, VERBOSITY)\n        self.assertEqual(runner._makeResult(), expectedresult)\n\n    def test_warnings(self):\n        \"\"\"\n        Check that warnings argument of TextTestRunner correctly affects the\n        behavior of the warnings.\n        \"\"\"\n        # see #10535 and the _test_warnings file for more information\n\n        def get_parse_out_err(p):\n            return [b.splitlines() for b in p.communicate()]\n        opts = dict(stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n                    cwd=os.path.dirname(__file__))\n        ae_msg = b'Please use assertEqual instead.'\n        at_msg = b'Please use assertTrue instead.'\n\n        # no args -> all the warnings are printed, unittest warnings only once\n        p = subprocess.Popen([sys.executable, '_test_warnings.py'], **opts)\n        out, err = get_parse_out_err(p)\n        self.assertIn(b'OK', err)\n        # check that the total number of warnings in the output is correct\n        self.assertEqual(len(out), 12)\n        # check that the numbers of the different kind of warnings is correct\n        for msg in [b'dw', b'iw', b'uw']:\n            self.assertEqual(out.count(msg), 3)\n        for msg in [ae_msg, at_msg, b'rw']:\n            self.assertEqual(out.count(msg), 1)\n\n        args_list = (\n            # passing 'ignore' as warnings arg -> no warnings\n            [sys.executable, '_test_warnings.py', 'ignore'],\n            # -W doesn't affect the result if the arg is passed\n            [sys.executable, '-Wa', '_test_warnings.py', 'ignore'],\n            # -W affects the result if the arg is not passed\n            [sys.executable, '-Wi', '_test_warnings.py']\n        )\n        # in all these cases no warnings are printed\n        for args in args_list:\n            p = subprocess.Popen(args, **opts)\n            out, err = get_parse_out_err(p)\n            self.assertIn(b'OK', err)\n            self.assertEqual(len(out), 0)\n\n\n        # passing 'always' as warnings arg -> all the warnings printed,\n        #                                     unittest warnings only once\n        p = subprocess.Popen([sys.executable, '_test_warnings.py', 'always'],\n                             **opts)\n        out, err = get_parse_out_err(p)\n        self.assertIn(b'OK', err)\n        self.assertEqual(len(out), 14)\n        for msg in [b'dw', b'iw', b'uw', b'rw']:\n            self.assertEqual(out.count(msg), 3)\n        for msg in [ae_msg, at_msg]:\n            self.assertEqual(out.count(msg), 1)\n\n    def testStdErrLookedUpAtInstantiationTime(self):\n        # see issue 10786\n        old_stderr = sys.stderr\n        f = io.StringIO()\n        sys.stderr = f\n        try:\n            runner = unittest.TextTestRunner()\n            self.assertTrue(runner.stream.stream is f)\n        finally:\n            sys.stderr = old_stderr\n\n    def testSpecifiedStreamUsed(self):\n        # see issue 10786\n        f = io.StringIO()\n        runner = unittest.TextTestRunner(f)\n        self.assertTrue(runner.stream.stream is f)\n"], "urllib.request": [".py", "from browser import ajax\n\nclass FileIO:\n  def __init__(self, data):\n      self._data=data\n\n  def read(self):\n      return self._data\n\ndef urlopen(url, data=None, timeout=None):\n    global result\n    result=None\n\n    def on_complete(req):\n        global result\n        result=req\n\n    _ajax=ajax.ajax()\n    _ajax.bind('complete', on_complete)\n    if timeout is not None:\n       _ajax.set_timeout(timeout)\n\n    _ajax.open('GET', url, False)\n    if data is None:\n       _ajax.send()\n    else:\n       _ajax.send(data)\n\n    if isinstance(result.text, str):\n       return FileIO(result.text), url, result.headers\n\n    return FileIO(result.text()), url, result.headers\n"], "encodings.utf_8": [".py", "\"\"\" Python 'utf-8' Codec\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\nimport codecs\n\n### Codec APIs\n\nencode = codecs.utf_8_encode\n\ndef decode(input, errors='strict'):\n    return codecs.utf_8_decode(input, errors, True)\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def encode(self, input, final=False):\n        return codecs.utf_8_encode(input, self.errors)[0]\n\nclass IncrementalDecoder(codecs.BufferedIncrementalDecoder):\n    _buffer_decode = codecs.utf_8_decode\n\nclass StreamWriter(codecs.StreamWriter):\n    encode = codecs.utf_8_encode\n\nclass StreamReader(codecs.StreamReader):\n    decode = codecs.utf_8_decode\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='utf-8',\n        encode=encode,\n        decode=decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=StreamReader,\n        streamwriter=StreamWriter,\n    )\n"], "sys": [".py", "# hack to return special attributes\nfrom _sys import *\nfrom javascript import JSObject\n\nhas_local_storage=__BRYTHON__.has_local_storage\nhas_json=__BRYTHON__.has_json\n\nargv = ['__main__']\n\nbase_exec_prefix = __BRYTHON__.brython_path\n\nbase_prefix = __BRYTHON__.brython_path\n\nbuiltin_module_names=__BRYTHON__.builtin_module_names\n\nbyteorder='little'\n\ndef exc_info():\n    exc = __BRYTHON__.exception_stack[-1]\n    return (exc.__class__,exc,exc.traceback)\n    \nexec_prefix = __BRYTHON__.brython_path\n\nexecutable = __BRYTHON__.brython_path+'/brython.js'\n\ndef exit(i=None):\n    raise SystemExit('')\n\nclass flag_class:\n  def __init__(self):\n      self.debug=0\n      self.inspect=0\n      self.interactive=0\n      self.optimize=0\n      self.dont_write_bytecode=0\n      self.no_user_site=0\n      self.no_site=0\n      self.ignore_environment=0\n      self.verbose=0\n      self.bytes_warning=0\n      self.quiet=0\n      self.hash_randomization=1\n\nflags=flag_class()\n\ndef getfilesystemencoding(*args,**kw):\n    \"\"\"getfilesystemencoding() -> string    \n    Return the encoding used to convert Unicode filenames in\n    operating system filenames.\"\"\"\n    return 'utf-8'\n    \nmaxsize=2147483647\n\nmaxunicode=1114111\n\npath = __BRYTHON__.path\n\npath_hooks = list(JSObject(__BRYTHON__.path_hooks))\n\nplatform=\"brython\"\n\nprefix = __BRYTHON__.brython_path\n\nversion = '.'.join(str(x) for x in __BRYTHON__.version_info[:3])\n#todo, put in a 'real' date, etc\nversion += \" (default, Feb 29 2013, 00:00:00) \\n[Javascript 1.5]\"\nhexversion = 0x03000000   # python 3.0\n\nclass __version_info(object):\n    def __init__(self, version_info):\n        self.version_info = version_info\n        self.major = version_info[0]\n        self.minor = version_info[1]\n        self.micro = version_info[2]\n        self.releaselevel = version_info[3]\n        self.serial = version_info[4]\n\n    def __getitem__(self, index):\n        if isinstance(self.version_info[index], list):\n           return tuple(self.version_info[index])\n        return self.version_info[index]\n\n    def hexversion(self):\n        try:\n          return '0%d0%d0%d' % (self.major, self.minor, self.micro)\n        finally:  #probably some invalid char in minor (rc, etc)\n          return '0%d0000' % (self.major)\n\n    def __str__(self):\n        _s=\"sys.version(major=%d, minor=%d, micro=%d, releaselevel='%s', serial=%d)\"\n        return _s % (self.major, self.minor, self.micro, \n                     self.releaselevel, self.serial)\n        #return str(self.version_info)\n\n#eventually this needs to be the real python version such as 3.0, 3.1, etc\nversion_info=__version_info(__BRYTHON__.version_info)\n\nclass _implementation:\n  def __init__(self):\n      self.name='brython'\n      self.version = __version_info(__BRYTHON__.implementation)\n      self.hexversion = self.version.hexversion()\n      self.cache_tag=None\n\n  def __repr__(self):\n      return \"namespace(name='%s' version=%s hexversion='%s')\" % (self.name, self.version, self.hexversion)\n\n  def __str__(self):\n      return \"namespace(name='%s' version=%s hexversion='%s')\" % (self.name, self.version, self.hexversion)\n\nimplementation=_implementation()\n\nclass _hash_info:\n  def __init__(self):\n      self.width=32, \n      self.modulus=2147483647\n      self.inf=314159 \n      self.nan=0\n      self.imag=1000003\n      self.algorithm='siphash24' \n      self.hash_bits=64 \n      self.seed_bits=128 \n      cutoff=0\n\n  def __repr(self):\n      #fix me\n      return \"sys.hash_info(width=32, modulus=2147483647, inf=314159, nan=0, imag=1000003, algorithm='siphash24', hash_bits=64, seed_bits=128, cutoff=0)\"\n\nhash_info=_hash_info()\n\nwarnoptions=[]\n\ndef getfilesystemencoding():\n    return 'utf-8'\n\n#delete objects not in python sys module namespace\ndel JSObject\ndel _implementation\n"], "browser.svg": [".py", "from _svg import *"], "markdown2": [".py", "import browser.html\nimport re\n\nclass URL:\n    def __init__(self,src):\n        elts = src.split(maxsplit=1)\n        self.href = elts[0]\n        self.alt = ''\n        if len(elts)==2:\n            alt = elts[1]\n            if alt[0]=='\"' and alt[-1]=='\"':self.alt=alt[1:-1]\n            elif alt[0]==\"'\" and alt[-1]==\"'\":self.alt=alt[1:-1]\n            elif alt[0]==\"(\" and alt[-1]==\")\":self.alt=alt[1:-1]\n        \nclass CodeBlock:\n    def __init__(self,line):\n        self.lines = [line]\n    \n    def to_html(self):\n        if self.lines[0].startswith(\"`\"):\n            self.lines.pop(0)\n        res = escape('\\n'.join(self.lines))\n        res = unmark(res)\n        res = '<pre class=\"marked\">%s</pre>\\n' %res\n        return res,[]\n\nclass Marked:\n    def __init__(self, line=''):\n        self.line = line\n        self.children = []\n\n    def to_html(self):\n        return apply_markdown(self.line)\n        \n# get references\nrefs = {}\nref_pattern = r\"^\\[(.*)\\]:\\s+(.*)\"\n\ndef mark(src):\n\n    global refs\n    refs = {}\n    # split source in sections\n    # sections can be :\n    # - a block-level HTML element (markdown syntax will not be processed)\n    # - a script\n    # - a span-level HTML tag (markdown syntax will be processed)\n    # - a code block\n    \n    # normalise line feeds\n    src = src.replace('\\r\\n','\\n')\n    \n    # lines followed by dashes\n    src = re.sub(r'(.*?)\\n=+\\n', '\\n# \\\\1\\n', src)\n    src = re.sub(r'(.*?)\\n-+\\n', '\\n## \\\\1\\n', src) \n\n    lines = src.split('\\n')\n    \n    i = bq = 0\n    ul = ol = 0\n    \n    while i<len(lines):\n\n        # enclose lines starting by > in a blockquote\n        if lines[i].startswith('>'):\n            nb = 1\n            while nb<len(lines[i]) and lines[i][nb]=='>':\n                nb += 1\n            lines[i] = lines[i][nb:]\n            if nb>bq:\n                lines.insert(i,'<blockquote>'*(nb-bq))\n                i += 1\n                bq = nb\n            elif nb<bq:\n                lines.insert(i,'</blockquote>'*(bq-nb))\n                i += 1\n                bq = nb\n        elif bq>0:\n            lines.insert(i,'</blockquote>'*bq)\n            i += 1\n            bq = 0\n\n        # unordered lists\n        if lines[i].strip() and lines[i].lstrip()[0] in '-+*' \\\n            and (i==0 or ul or not lines[i-1].strip()):\n            print('is ul',lines[i])\n            # line indentation indicates nesting level\n            nb = 1+len(lines[i])-len(lines[i].lstrip())\n            lines[i] = '<li>'+lines[i][1+nb:]\n            if nb>ul:\n                lines.insert(i,'<ul>'*(nb-ul))\n                i += 1\n            elif nb<ul:\n                lines.insert(i,'</ul>'*(ul-nb))\n                i += 1\n            ul = nb\n        elif ul:\n            lines.insert(i,'</ul>'*ul)\n            i += 1\n            ul = 0\n\n        # ordered lists\n        mo = re.search(r'^(\\d+\\.)',lines[i])\n        if mo:\n            if not ol:\n                lines.insert(i,'<ol>')\n                i += 1\n            lines[i] = '<li>'+lines[i][len(mo.groups()[0]):]\n            ol = 1\n        elif ol:\n            lines.insert(i,'</ol>')\n            i += 1\n            ol = 0\n        i += 1\n    \n    sections = []\n    scripts = []\n    section = Marked()\n\n    i = 0\n    while i<len(lines):\n        line = lines[i]\n        if line.strip() and line.startswith('    '):\n            if isinstance(section,Marked) and section.line:\n                sections.append(section)\n            section = CodeBlock(line[4:])\n            j = i+1\n            while j<len(lines) and lines[j].strip() \\\n                and lines[j].startswith('    '):\n                    section.lines.append(lines[j][4:])\n                    j += 1\n            sections.append(section)\n            section = Marked()\n            i = j   \n            continue\n        elif line.lower().startswith('<script'):\n            if isinstance(section,Marked) and section.line:\n                sections.append(section)\n                section = Marked()\n            j = i+1\n            while j<len(lines):\n                if lines[j].lower().startswith('</script>'):\n                    scripts.append('\\n'.join(lines[i+1:j]))\n                    for k in range(i,j+1):\n                        lines[k] = ''\n                    break\n                j += 1\n            i = j\n            continue\n        else:\n            mo = re.search(ref_pattern,line)\n            if mo is not None:\n                if isinstance(section,Marked) and section.line:\n                    sections.append(section)\n                    section = Marked()\n                key = mo.groups()[0]\n                value = URL(mo.groups()[1])\n                refs[key.lower()] = value\n            else:\n                if line.strip():\n                    if section.line:\n                        section.line += ' '\n                    section.line += line\n                else:\n                    sections.append(section)\n                    section = Marked()\n            i += 1\n\n    res = ''\n    for section in sections:\n        mk,_scripts = section.to_html()\n        res += '<p>'+mk+'\\n'\n        scripts += _scripts\n    return res,scripts\n\ndef escape(czone):\n    czone = czone.replace('&','&amp;')\n    czone = czone.replace('<','&lt;')\n    czone = czone.replace('>','&gt;')\n    return czone\n\ndef s_escape(mo):\n    # used in re.sub\n    czone = mo.string[mo.start():mo.end()]\n    return escape(czone)\n\ndef unmark(code_zone):\n    # convert _ to &#95; inside inline code\n    code_zone = code_zone.replace('_','&#95;')\n    return code_zone\n\ndef s_unmark(mo):\n    # convert _ to &#95; inside inline code\n    code_zone = mo.string[mo.start():mo.end()]\n    code_zone = code_zone.replace('_','&#95;')\n    return code_zone\n\ndef apply_markdown(src):\n\n    scripts = []\n\n    # replace \\` by &#96;\n    src = re.sub(r'\\\\\\`','&#96;',src)\n\n    # escape < > & in inline code\n    code_pattern = r'\\`(\\S.*?\\S)\\`'\n    src = re.sub(code_pattern,s_escape,src)\n    # also convert _\n    src = re.sub(code_pattern,s_unmark,src)\n    \n    # inline links\n    link_pattern1 = r'\\[(.+?)\\]\\s?\\((.+?)\\)'\n    def repl(mo):\n        g1,g2 = mo.groups()\n        g2 = re.sub('_','&#95;',g2)\n        return '<a href=\"%s\">%s</a>' %(g2,g1)\n    src = re.sub(link_pattern1,repl,src)\n\n    # reference links\n    link_pattern2 = r'\\[(.+?)\\]\\s?\\[(.*?)\\]'\n    while True:\n        mo = re.search(link_pattern2,src)\n        if mo is None:break\n        text,key = mo.groups()\n        print(text,key)\n        if not key:key=text # implicit link name\n        if key.lower() not in refs:\n            raise KeyError('unknow reference %s' %key)\n        url = refs[key.lower()]\n        repl = '<a href=\"'+url.href+'\"'\n        if url.alt:\n            repl += ' title=\"'+url.alt+'\"'\n        repl += '>%s</a>' %text\n        src = re.sub(link_pattern2,repl,src,count=1)\n\n    # emphasis\n\n    # replace \\* by &#42;\n    src = re.sub(r'\\\\\\*','&#42;',src)\n    # replace \\_ by &#95;\n    src = re.sub(r'\\\\\\_','&#95;',src)\n    # _ and * surrounded by spaces are not markup\n    src = re.sub(r' _ ',' &#95; ',src)\n    src = re.sub(r' \\* ',' &#42; ',src)\n\n    strong_patterns = [('STRONG',r'\\*\\*(.*?)\\*\\*'),('B',r'__(.*?)__')]\n    for tag,strong_pattern in strong_patterns:\n        src = re.sub(strong_pattern,r'<%s>\\1</%s>' %(tag,tag),src)\n\n    em_patterns = [('EM',r'\\*(.*?)\\*'),('I',r'\\_(.*?)\\_')]\n    for tag,em_pattern in em_patterns:\n        src = re.sub(em_pattern,r'<%s>\\1</%s>' %(tag,tag),src)\n\n    # inline code\n    # replace \\` by &#96;\n    src = re.sub(r'\\\\\\`','&#96;',src)\n\n    code_pattern = r'\\`(.*?)\\`'\n    src = re.sub(code_pattern,r'<code>\\1</code>',src)\n\n    # ordered lists\n    lines = src.split('\\n')\n           \n    atx_header_pattern = '^(#+)(.*)(#*)'\n    for i,line in enumerate(lines):\n        print('line [%s]' %line, line.startswith('#'))\n        mo = re.search(atx_header_pattern,line)\n        if not mo:continue\n        print('pattern matches')\n        level = len(mo.groups()[0])\n        lines[i] = re.sub(atx_header_pattern,\n            '<H%s>%s</H%s>\\n' %(level,mo.groups()[1],level),\n            line,count=1)\n\n    src = '\\n'.join(lines)      \n    src = re.sub('\\n\\n+','\\n<p>',src)+'\\n'\n\n    return src,scripts\n"], "types": [".py", "\"\"\"\nDefine names for built-in types that aren't directly accessible as a builtin.\n\"\"\"\nimport sys\n\n# Iterators in Python aren't a matter of type but of protocol.  A large\n# and changing number of builtin types implement *some* flavor of\n# iterator.  Don't check the type!  Use hasattr to check for both\n# \"__iter__\" and \"__next__\" attributes instead.\n\ndef _f(): pass\nFunctionType = type(_f)\nLambdaType = type(lambda: None)         # Same as FunctionType\nCodeType = type(_f.__code__)\nMappingProxyType = type(type.__dict__)\nSimpleNamespace = type(sys.implementation)\n\ndef _g():\n    yield 1\nGeneratorType = type(_g())\n\nclass _C:\n    def _m(self): pass\nMethodType = type(_C()._m)\n\nBuiltinFunctionType = type(len)\nBuiltinMethodType = type([].append)     # Same as BuiltinFunctionType\n\nModuleType = type(sys)\n\ntry:\n    raise TypeError\nexcept TypeError:\n    tb = sys.exc_info()[2]\n    TracebackType = type(tb)\n    FrameType = type(tb.tb_frame)\n    tb = None; del tb\n\n# For Jython, the following two types are identical\nGetSetDescriptorType = type(FunctionType.__code__)\nMemberDescriptorType = type(FunctionType.__globals__)\n\ndel sys, _f, _g, _C,                              # Not for export\n\n\n# Provide a PEP 3115 compliant mechanism for class creation\ndef new_class(name, bases=(), kwds=None, exec_body=None):\n    \"\"\"Create a class object dynamically using the appropriate metaclass.\"\"\"\n    meta, ns, kwds = prepare_class(name, bases, kwds)\n    if exec_body is not None:\n        exec_body(ns)\n    return meta(name, bases, ns, **kwds)\n\ndef prepare_class(name, bases=(), kwds=None):\n    \"\"\"Call the __prepare__ method of the appropriate metaclass.\n\n    Returns (metaclass, namespace, kwds) as a 3-tuple\n\n    *metaclass* is the appropriate metaclass\n    *namespace* is the prepared class namespace\n    *kwds* is an updated copy of the passed in kwds argument with any\n    'metaclass' entry removed. If no kwds argument is passed in, this will\n    be an empty dict.\n    \"\"\"\n    if kwds is None:\n        kwds = {}\n    else:\n        kwds = dict(kwds) # Don't alter the provided mapping\n    if 'metaclass' in kwds:\n        meta = kwds.pop('metaclass')\n    else:\n        if bases:\n            meta = type(bases[0])\n        else:\n            meta = type\n    if isinstance(meta, type):\n        # when meta is a type, we first determine the most-derived metaclass\n        # instead of invoking the initial candidate directly\n        meta = _calculate_meta(meta, bases)\n    if hasattr(meta, '__prepare__'):\n        ns = meta.__prepare__(name, bases, **kwds)\n    else:\n        ns = {}\n    return meta, ns, kwds\n\ndef _calculate_meta(meta, bases):\n    \"\"\"Calculate the most derived metaclass.\"\"\"\n    winner = meta\n    for base in bases:\n        base_meta = type(base)\n        if issubclass(winner, base_meta):\n            continue\n        if issubclass(base_meta, winner):\n            winner = base_meta\n            continue\n        # else:\n        raise TypeError(\"metaclass conflict: \"\n                        \"the metaclass of a derived class \"\n                        \"must be a (non-strict) subclass \"\n                        \"of the metaclasses of all its bases\")\n    return winner\n"], "xml.sax.expatreader": [".py", "\"\"\"\nSAX driver for the pyexpat C module.  This driver works with\npyexpat.__version__ == '2.22'.\n\"\"\"\n\nversion = \"0.20\"\n\nfrom xml.sax._exceptions import *\nfrom xml.sax.handler import feature_validation, feature_namespaces\nfrom xml.sax.handler import feature_namespace_prefixes\nfrom xml.sax.handler import feature_external_ges, feature_external_pes\nfrom xml.sax.handler import feature_string_interning\nfrom xml.sax.handler import property_xml_string, property_interning_dict\n\n# xml.parsers.expat does not raise ImportError in Jython\nimport sys\nif sys.platform[:4] == \"java\":\n    raise SAXReaderNotAvailable(\"expat not available in Java\", None)\ndel sys\n\ntry:\n    from xml.parsers import expat\nexcept ImportError:\n    raise SAXReaderNotAvailable(\"expat not supported\", None)\nelse:\n    if not hasattr(expat, \"ParserCreate\"):\n        raise SAXReaderNotAvailable(\"expat not supported\", None)\nfrom xml.sax import xmlreader, saxutils, handler\n\nAttributesImpl = xmlreader.AttributesImpl\nAttributesNSImpl = xmlreader.AttributesNSImpl\n\n# If we're using a sufficiently recent version of Python, we can use\n# weak references to avoid cycles between the parser and content\n# handler, otherwise we'll just have to pretend.\ntry:\n    import _weakref\nexcept ImportError:\n    def _mkproxy(o):\n        return o\nelse:\n    import weakref\n    _mkproxy = weakref.proxy\n    del weakref, _weakref\n\n# --- ExpatLocator\n\nclass ExpatLocator(xmlreader.Locator):\n    \"\"\"Locator for use with the ExpatParser class.\n\n    This uses a weak reference to the parser object to avoid creating\n    a circular reference between the parser and the content handler.\n    \"\"\"\n    def __init__(self, parser):\n        self._ref = _mkproxy(parser)\n\n    def getColumnNumber(self):\n        parser = self._ref\n        if parser._parser is None:\n            return None\n        return parser._parser.ErrorColumnNumber\n\n    def getLineNumber(self):\n        parser = self._ref\n        if parser._parser is None:\n            return 1\n        return parser._parser.ErrorLineNumber\n\n    def getPublicId(self):\n        parser = self._ref\n        if parser is None:\n            return None\n        return parser._source.getPublicId()\n\n    def getSystemId(self):\n        parser = self._ref\n        if parser is None:\n            return None\n        return parser._source.getSystemId()\n\n\n# --- ExpatParser\n\nclass ExpatParser(xmlreader.IncrementalParser, xmlreader.Locator):\n    \"\"\"SAX driver for the pyexpat C module.\"\"\"\n\n    def __init__(self, namespaceHandling=0, bufsize=2**16-20):\n        xmlreader.IncrementalParser.__init__(self, bufsize)\n        self._source = xmlreader.InputSource()\n        self._parser = None\n        self._namespaces = namespaceHandling\n        self._lex_handler_prop = None\n        self._parsing = 0\n        self._entity_stack = []\n        self._external_ges = 1\n        self._interning = None\n\n    # XMLReader methods\n\n    def parse(self, source):\n        \"Parse an XML document from a URL or an InputSource.\"\n        source = saxutils.prepare_input_source(source)\n\n        self._source = source\n        self.reset()\n        self._cont_handler.setDocumentLocator(ExpatLocator(self))\n        xmlreader.IncrementalParser.parse(self, source)\n\n    def prepareParser(self, source):\n        if source.getSystemId() is not None:\n            self._parser.SetBase(source.getSystemId())\n\n    # Redefined setContentHandler to allow changing handlers during parsing\n\n    def setContentHandler(self, handler):\n        xmlreader.IncrementalParser.setContentHandler(self, handler)\n        if self._parsing:\n            self._reset_cont_handler()\n\n    def getFeature(self, name):\n        if name == feature_namespaces:\n            return self._namespaces\n        elif name == feature_string_interning:\n            return self._interning is not None\n        elif name in (feature_validation, feature_external_pes,\n                      feature_namespace_prefixes):\n            return 0\n        elif name == feature_external_ges:\n            return self._external_ges\n        raise SAXNotRecognizedException(\"Feature '%s' not recognized\" % name)\n\n    def setFeature(self, name, state):\n        if self._parsing:\n            raise SAXNotSupportedException(\"Cannot set features while parsing\")\n\n        if name == feature_namespaces:\n            self._namespaces = state\n        elif name == feature_external_ges:\n            self._external_ges = state\n        elif name == feature_string_interning:\n            if state:\n                if self._interning is None:\n                    self._interning = {}\n            else:\n                self._interning = None\n        elif name == feature_validation:\n            if state:\n                raise SAXNotSupportedException(\n                    \"expat does not support validation\")\n        elif name == feature_external_pes:\n            if state:\n                raise SAXNotSupportedException(\n                    \"expat does not read external parameter entities\")\n        elif name == feature_namespace_prefixes:\n            if state:\n                raise SAXNotSupportedException(\n                    \"expat does not report namespace prefixes\")\n        else:\n            raise SAXNotRecognizedException(\n                \"Feature '%s' not recognized\" % name)\n\n    def getProperty(self, name):\n        if name == handler.property_lexical_handler:\n            return self._lex_handler_prop\n        elif name == property_interning_dict:\n            return self._interning\n        elif name == property_xml_string:\n            if self._parser:\n                if hasattr(self._parser, \"GetInputContext\"):\n                    return self._parser.GetInputContext()\n                else:\n                    raise SAXNotRecognizedException(\n                        \"This version of expat does not support getting\"\n                        \" the XML string\")\n            else:\n                raise SAXNotSupportedException(\n                    \"XML string cannot be returned when not parsing\")\n        raise SAXNotRecognizedException(\"Property '%s' not recognized\" % name)\n\n    def setProperty(self, name, value):\n        if name == handler.property_lexical_handler:\n            self._lex_handler_prop = value\n            if self._parsing:\n                self._reset_lex_handler_prop()\n        elif name == property_interning_dict:\n            self._interning = value\n        elif name == property_xml_string:\n            raise SAXNotSupportedException(\"Property '%s' cannot be set\" %\n                                           name)\n        else:\n            raise SAXNotRecognizedException(\"Property '%s' not recognized\" %\n                                            name)\n\n    # IncrementalParser methods\n\n    def feed(self, data, isFinal = 0):\n        if not self._parsing:\n            self.reset()\n            self._parsing = 1\n            self._cont_handler.startDocument()\n\n        try:\n            # The isFinal parameter is internal to the expat reader.\n            # If it is set to true, expat will check validity of the entire\n            # document. When feeding chunks, they are not normally final -\n            # except when invoked from close.\n            self._parser.Parse(data, isFinal)\n        except expat.error as e:\n            exc = SAXParseException(expat.ErrorString(e.code), e, self)\n            # FIXME: when to invoke error()?\n            self._err_handler.fatalError(exc)\n\n    def close(self):\n        if self._entity_stack:\n            # If we are completing an external entity, do nothing here\n            return\n        self.feed(\"\", isFinal = 1)\n        self._cont_handler.endDocument()\n        self._parsing = 0\n        # break cycle created by expat handlers pointing to our methods\n        self._parser = None\n        bs = self._source.getByteStream()\n        if bs is not None:\n            bs.close()\n\n    def _reset_cont_handler(self):\n        self._parser.ProcessingInstructionHandler = \\\n                                    self._cont_handler.processingInstruction\n        self._parser.CharacterDataHandler = self._cont_handler.characters\n\n    def _reset_lex_handler_prop(self):\n        lex = self._lex_handler_prop\n        parser = self._parser\n        if lex is None:\n            parser.CommentHandler = None\n            parser.StartCdataSectionHandler = None\n            parser.EndCdataSectionHandler = None\n            parser.StartDoctypeDeclHandler = None\n            parser.EndDoctypeDeclHandler = None\n        else:\n            parser.CommentHandler = lex.comment\n            parser.StartCdataSectionHandler = lex.startCDATA\n            parser.EndCdataSectionHandler = lex.endCDATA\n            parser.StartDoctypeDeclHandler = self.start_doctype_decl\n            parser.EndDoctypeDeclHandler = lex.endDTD\n\n    def reset(self):\n        if self._namespaces:\n            self._parser = expat.ParserCreate(self._source.getEncoding(), \" \",\n                                              intern=self._interning)\n            self._parser.namespace_prefixes = 1\n            self._parser.StartElementHandler = self.start_element_ns\n            self._parser.EndElementHandler = self.end_element_ns\n        else:\n            self._parser = expat.ParserCreate(self._source.getEncoding(),\n                                              intern = self._interning)\n            self._parser.StartElementHandler = self.start_element\n            self._parser.EndElementHandler = self.end_element\n\n        self._reset_cont_handler()\n        self._parser.UnparsedEntityDeclHandler = self.unparsed_entity_decl\n        self._parser.NotationDeclHandler = self.notation_decl\n        self._parser.StartNamespaceDeclHandler = self.start_namespace_decl\n        self._parser.EndNamespaceDeclHandler = self.end_namespace_decl\n\n        self._decl_handler_prop = None\n        if self._lex_handler_prop:\n            self._reset_lex_handler_prop()\n#         self._parser.DefaultHandler =\n#         self._parser.DefaultHandlerExpand =\n#         self._parser.NotStandaloneHandler =\n        self._parser.ExternalEntityRefHandler = self.external_entity_ref\n        try:\n            self._parser.SkippedEntityHandler = self.skipped_entity_handler\n        except AttributeError:\n            # This pyexpat does not support SkippedEntity\n            pass\n        self._parser.SetParamEntityParsing(\n            expat.XML_PARAM_ENTITY_PARSING_UNLESS_STANDALONE)\n\n        self._parsing = 0\n        self._entity_stack = []\n\n    # Locator methods\n\n    def getColumnNumber(self):\n        if self._parser is None:\n            return None\n        return self._parser.ErrorColumnNumber\n\n    def getLineNumber(self):\n        if self._parser is None:\n            return 1\n        return self._parser.ErrorLineNumber\n\n    def getPublicId(self):\n        return self._source.getPublicId()\n\n    def getSystemId(self):\n        return self._source.getSystemId()\n\n    # event handlers\n    def start_element(self, name, attrs):\n        self._cont_handler.startElement(name, AttributesImpl(attrs))\n\n    def end_element(self, name):\n        self._cont_handler.endElement(name)\n\n    def start_element_ns(self, name, attrs):\n        pair = name.split()\n        if len(pair) == 1:\n            # no namespace\n            pair = (None, name)\n        elif len(pair) == 3:\n            pair = pair[0], pair[1]\n        else:\n            # default namespace\n            pair = tuple(pair)\n\n        newattrs = {}\n        qnames = {}\n        for (aname, value) in attrs.items():\n            parts = aname.split()\n            length = len(parts)\n            if length == 1:\n                # no namespace\n                qname = aname\n                apair = (None, aname)\n            elif length == 3:\n                qname = \"%s:%s\" % (parts[2], parts[1])\n                apair = parts[0], parts[1]\n            else:\n                # default namespace\n                qname = parts[1]\n                apair = tuple(parts)\n\n            newattrs[apair] = value\n            qnames[apair] = qname\n\n        self._cont_handler.startElementNS(pair, None,\n                                          AttributesNSImpl(newattrs, qnames))\n\n    def end_element_ns(self, name):\n        pair = name.split()\n        if len(pair) == 1:\n            pair = (None, name)\n        elif len(pair) == 3:\n            pair = pair[0], pair[1]\n        else:\n            pair = tuple(pair)\n\n        self._cont_handler.endElementNS(pair, None)\n\n    # this is not used (call directly to ContentHandler)\n    def processing_instruction(self, target, data):\n        self._cont_handler.processingInstruction(target, data)\n\n    # this is not used (call directly to ContentHandler)\n    def character_data(self, data):\n        self._cont_handler.characters(data)\n\n    def start_namespace_decl(self, prefix, uri):\n        self._cont_handler.startPrefixMapping(prefix, uri)\n\n    def end_namespace_decl(self, prefix):\n        self._cont_handler.endPrefixMapping(prefix)\n\n    def start_doctype_decl(self, name, sysid, pubid, has_internal_subset):\n        self._lex_handler_prop.startDTD(name, pubid, sysid)\n\n    def unparsed_entity_decl(self, name, base, sysid, pubid, notation_name):\n        self._dtd_handler.unparsedEntityDecl(name, pubid, sysid, notation_name)\n\n    def notation_decl(self, name, base, sysid, pubid):\n        self._dtd_handler.notationDecl(name, pubid, sysid)\n\n    def external_entity_ref(self, context, base, sysid, pubid):\n        if not self._external_ges:\n            return 1\n\n        source = self._ent_handler.resolveEntity(pubid, sysid)\n        source = saxutils.prepare_input_source(source,\n                                               self._source.getSystemId() or\n                                               \"\")\n\n        self._entity_stack.append((self._parser, self._source))\n        self._parser = self._parser.ExternalEntityParserCreate(context)\n        self._source = source\n\n        try:\n            xmlreader.IncrementalParser.parse(self, source)\n        except:\n            return 0  # FIXME: save error info here?\n\n        (self._parser, self._source) = self._entity_stack[-1]\n        del self._entity_stack[-1]\n        return 1\n\n    def skipped_entity_handler(self, name, is_pe):\n        if is_pe:\n            # The SAX spec requires to report skipped PEs with a '%'\n            name = '%'+name\n        self._cont_handler.skippedEntity(name)\n\n# ---\n\ndef create_parser(*args, **kwargs):\n    return ExpatParser(*args, **kwargs)\n\n# ---\n\nif __name__ == \"__main__\":\n    import xml.sax.saxutils\n    p = create_parser()\n    p.setContentHandler(xml.sax.saxutils.XMLGenerator())\n    p.setErrorHandler(xml.sax.ErrorHandler())\n    p.parse(\"http://www.ibiblio.org/xml/examples/shakespeare/hamlet.xml\")\n"], "unittest.test.test_case": [".py", "import difflib\nimport pprint\nimport pickle\nimport re\nimport sys\nimport warnings\nimport weakref\nimport inspect\n\nfrom copy import deepcopy\nfrom test import support\n\nimport unittest\n\nfrom .support import (\n    TestEquality, TestHashing, LoggingResult,\n    ResultWithNoStartTestRunStopTestRun\n)\n\n\nclass Test(object):\n    \"Keep these TestCase classes out of the main namespace\"\n\n    class Foo(unittest.TestCase):\n        def runTest(self): pass\n        def test1(self): pass\n\n    class Bar(Foo):\n        def test2(self): pass\n\n    class LoggingTestCase(unittest.TestCase):\n        \"\"\"A test case which logs its calls.\"\"\"\n\n        def __init__(self, events):\n            super(Test.LoggingTestCase, self).__init__('test')\n            self.events = events\n\n        def setUp(self):\n            self.events.append('setUp')\n\n        def test(self):\n            self.events.append('test')\n\n        def tearDown(self):\n            self.events.append('tearDown')\n\n\nclass Test_TestCase(unittest.TestCase, TestEquality, TestHashing):\n\n    ### Set up attributes used by inherited tests\n    ################################################################\n\n    # Used by TestHashing.test_hash and TestEquality.test_eq\n    eq_pairs = [(Test.Foo('test1'), Test.Foo('test1'))]\n\n    # Used by TestEquality.test_ne\n    ne_pairs = [(Test.Foo('test1'), Test.Foo('runTest')),\n                (Test.Foo('test1'), Test.Bar('test1')),\n                (Test.Foo('test1'), Test.Bar('test2'))]\n\n    ################################################################\n    ### /Set up attributes used by inherited tests\n\n\n    # \"class TestCase([methodName])\"\n    # ...\n    # \"Each instance of TestCase will run a single test method: the\n    # method named methodName.\"\n    # ...\n    # \"methodName defaults to \"runTest\".\"\n    #\n    # Make sure it really is optional, and that it defaults to the proper\n    # thing.\n    def test_init__no_test_name(self):\n        class Test(unittest.TestCase):\n            def runTest(self): raise MyException()\n            def test(self): pass\n\n        self.assertEqual(Test().id()[-13:], '.Test.runTest')\n\n        # test that TestCase can be instantiated with no args\n        # primarily for use at the interactive interpreter\n        test = unittest.TestCase()\n        test.assertEqual(3, 3)\n        with test.assertRaises(test.failureException):\n            test.assertEqual(3, 2)\n\n        with self.assertRaises(AttributeError):\n            test.run()\n\n    # \"class TestCase([methodName])\"\n    # ...\n    # \"Each instance of TestCase will run a single test method: the\n    # method named methodName.\"\n    def test_init__test_name__valid(self):\n        class Test(unittest.TestCase):\n            def runTest(self): raise MyException()\n            def test(self): pass\n\n        self.assertEqual(Test('test').id()[-10:], '.Test.test')\n\n    # \"class TestCase([methodName])\"\n    # ...\n    # \"Each instance of TestCase will run a single test method: the\n    # method named methodName.\"\n    def test_init__test_name__invalid(self):\n        class Test(unittest.TestCase):\n            def runTest(self): raise MyException()\n            def test(self): pass\n\n        try:\n            Test('testfoo')\n        except ValueError:\n            pass\n        else:\n            self.fail(\"Failed to raise ValueError\")\n\n    # \"Return the number of tests represented by the this test object. For\n    # TestCase instances, this will always be 1\"\n    def test_countTestCases(self):\n        class Foo(unittest.TestCase):\n            def test(self): pass\n\n        self.assertEqual(Foo('test').countTestCases(), 1)\n\n    # \"Return the default type of test result object to be used to run this\n    # test. For TestCase instances, this will always be\n    # unittest.TestResult;  subclasses of TestCase should\n    # override this as necessary.\"\n    def test_defaultTestResult(self):\n        class Foo(unittest.TestCase):\n            def runTest(self):\n                pass\n\n        result = Foo().defaultTestResult()\n        self.assertEqual(type(result), unittest.TestResult)\n\n    # \"When a setUp() method is defined, the test runner will run that method\n    # prior to each test. Likewise, if a tearDown() method is defined, the\n    # test runner will invoke that method after each test. In the example,\n    # setUp() was used to create a fresh sequence for each test.\"\n    #\n    # Make sure the proper call order is maintained, even if setUp() raises\n    # an exception.\n    def test_run_call_order__error_in_setUp(self):\n        events = []\n        result = LoggingResult(events)\n\n        class Foo(Test.LoggingTestCase):\n            def setUp(self):\n                super(Foo, self).setUp()\n                raise RuntimeError('raised by Foo.setUp')\n\n        Foo(events).run(result)\n        expected = ['startTest', 'setUp', 'addError', 'stopTest']\n        self.assertEqual(events, expected)\n\n    # \"With a temporary result stopTestRun is called when setUp errors.\n    def test_run_call_order__error_in_setUp_default_result(self):\n        events = []\n\n        class Foo(Test.LoggingTestCase):\n            def defaultTestResult(self):\n                return LoggingResult(self.events)\n\n            def setUp(self):\n                super(Foo, self).setUp()\n                raise RuntimeError('raised by Foo.setUp')\n\n        Foo(events).run()\n        expected = ['startTestRun', 'startTest', 'setUp', 'addError',\n                    'stopTest', 'stopTestRun']\n        self.assertEqual(events, expected)\n\n    # \"When a setUp() method is defined, the test runner will run that method\n    # prior to each test. Likewise, if a tearDown() method is defined, the\n    # test runner will invoke that method after each test. In the example,\n    # setUp() was used to create a fresh sequence for each test.\"\n    #\n    # Make sure the proper call order is maintained, even if the test raises\n    # an error (as opposed to a failure).\n    def test_run_call_order__error_in_test(self):\n        events = []\n        result = LoggingResult(events)\n\n        class Foo(Test.LoggingTestCase):\n            def test(self):\n                super(Foo, self).test()\n                raise RuntimeError('raised by Foo.test')\n\n        expected = ['startTest', 'setUp', 'test', 'tearDown',\n                    'addError', 'stopTest']\n        Foo(events).run(result)\n        self.assertEqual(events, expected)\n\n    # \"With a default result, an error in the test still results in stopTestRun\n    # being called.\"\n    def test_run_call_order__error_in_test_default_result(self):\n        events = []\n\n        class Foo(Test.LoggingTestCase):\n            def defaultTestResult(self):\n                return LoggingResult(self.events)\n\n            def test(self):\n                super(Foo, self).test()\n                raise RuntimeError('raised by Foo.test')\n\n        expected = ['startTestRun', 'startTest', 'setUp', 'test',\n                    'tearDown', 'addError', 'stopTest', 'stopTestRun']\n        Foo(events).run()\n        self.assertEqual(events, expected)\n\n    # \"When a setUp() method is defined, the test runner will run that method\n    # prior to each test. Likewise, if a tearDown() method is defined, the\n    # test runner will invoke that method after each test. In the example,\n    # setUp() was used to create a fresh sequence for each test.\"\n    #\n    # Make sure the proper call order is maintained, even if the test signals\n    # a failure (as opposed to an error).\n    def test_run_call_order__failure_in_test(self):\n        events = []\n        result = LoggingResult(events)\n\n        class Foo(Test.LoggingTestCase):\n            def test(self):\n                super(Foo, self).test()\n                self.fail('raised by Foo.test')\n\n        expected = ['startTest', 'setUp', 'test', 'tearDown',\n                    'addFailure', 'stopTest']\n        Foo(events).run(result)\n        self.assertEqual(events, expected)\n\n    # \"When a test fails with a default result stopTestRun is still called.\"\n    def test_run_call_order__failure_in_test_default_result(self):\n\n        class Foo(Test.LoggingTestCase):\n            def defaultTestResult(self):\n                return LoggingResult(self.events)\n            def test(self):\n                super(Foo, self).test()\n                self.fail('raised by Foo.test')\n\n        expected = ['startTestRun', 'startTest', 'setUp', 'test',\n                    'tearDown', 'addFailure', 'stopTest', 'stopTestRun']\n        events = []\n        Foo(events).run()\n        self.assertEqual(events, expected)\n\n    # \"When a setUp() method is defined, the test runner will run that method\n    # prior to each test. Likewise, if a tearDown() method is defined, the\n    # test runner will invoke that method after each test. In the example,\n    # setUp() was used to create a fresh sequence for each test.\"\n    #\n    # Make sure the proper call order is maintained, even if tearDown() raises\n    # an exception.\n    def test_run_call_order__error_in_tearDown(self):\n        events = []\n        result = LoggingResult(events)\n\n        class Foo(Test.LoggingTestCase):\n            def tearDown(self):\n                super(Foo, self).tearDown()\n                raise RuntimeError('raised by Foo.tearDown')\n\n        Foo(events).run(result)\n        expected = ['startTest', 'setUp', 'test', 'tearDown', 'addError',\n                    'stopTest']\n        self.assertEqual(events, expected)\n\n    # \"When tearDown errors with a default result stopTestRun is still called.\"\n    def test_run_call_order__error_in_tearDown_default_result(self):\n\n        class Foo(Test.LoggingTestCase):\n            def defaultTestResult(self):\n                return LoggingResult(self.events)\n            def tearDown(self):\n                super(Foo, self).tearDown()\n                raise RuntimeError('raised by Foo.tearDown')\n\n        events = []\n        Foo(events).run()\n        expected = ['startTestRun', 'startTest', 'setUp', 'test', 'tearDown',\n                    'addError', 'stopTest', 'stopTestRun']\n        self.assertEqual(events, expected)\n\n    # \"TestCase.run() still works when the defaultTestResult is a TestResult\n    # that does not support startTestRun and stopTestRun.\n    def test_run_call_order_default_result(self):\n\n        class Foo(unittest.TestCase):\n            def defaultTestResult(self):\n                return ResultWithNoStartTestRunStopTestRun()\n            def test(self):\n                pass\n\n        Foo('test').run()\n\n    # \"This class attribute gives the exception raised by the test() method.\n    # If a test framework needs to use a specialized exception, possibly to\n    # carry additional information, it must subclass this exception in\n    # order to ``play fair'' with the framework.  The initial value of this\n    # attribute is AssertionError\"\n    def test_failureException__default(self):\n        class Foo(unittest.TestCase):\n            def test(self):\n                pass\n\n        self.assertTrue(Foo('test').failureException is AssertionError)\n\n    # \"This class attribute gives the exception raised by the test() method.\n    # If a test framework needs to use a specialized exception, possibly to\n    # carry additional information, it must subclass this exception in\n    # order to ``play fair'' with the framework.\"\n    #\n    # Make sure TestCase.run() respects the designated failureException\n    def test_failureException__subclassing__explicit_raise(self):\n        events = []\n        result = LoggingResult(events)\n\n        class Foo(unittest.TestCase):\n            def test(self):\n                raise RuntimeError()\n\n            failureException = RuntimeError\n\n        self.assertTrue(Foo('test').failureException is RuntimeError)\n\n\n        Foo('test').run(result)\n        expected = ['startTest', 'addFailure', 'stopTest']\n        self.assertEqual(events, expected)\n\n    # \"This class attribute gives the exception raised by the test() method.\n    # If a test framework needs to use a specialized exception, possibly to\n    # carry additional information, it must subclass this exception in\n    # order to ``play fair'' with the framework.\"\n    #\n    # Make sure TestCase.run() respects the designated failureException\n    def test_failureException__subclassing__implicit_raise(self):\n        events = []\n        result = LoggingResult(events)\n\n        class Foo(unittest.TestCase):\n            def test(self):\n                self.fail(\"foo\")\n\n            failureException = RuntimeError\n\n        self.assertTrue(Foo('test').failureException is RuntimeError)\n\n\n        Foo('test').run(result)\n        expected = ['startTest', 'addFailure', 'stopTest']\n        self.assertEqual(events, expected)\n\n    # \"The default implementation does nothing.\"\n    def test_setUp(self):\n        class Foo(unittest.TestCase):\n            def runTest(self):\n                pass\n\n        # ... and nothing should happen\n        Foo().setUp()\n\n    # \"The default implementation does nothing.\"\n    def test_tearDown(self):\n        class Foo(unittest.TestCase):\n            def runTest(self):\n                pass\n\n        # ... and nothing should happen\n        Foo().tearDown()\n\n    # \"Return a string identifying the specific test case.\"\n    #\n    # Because of the vague nature of the docs, I'm not going to lock this\n    # test down too much. Really all that can be asserted is that the id()\n    # will be a string (either 8-byte or unicode -- again, because the docs\n    # just say \"string\")\n    def test_id(self):\n        class Foo(unittest.TestCase):\n            def runTest(self):\n                pass\n\n        self.assertIsInstance(Foo().id(), str)\n\n\n    # \"If result is omitted or None, a temporary result object is created,\n    # used, and is made available to the caller. As TestCase owns the\n    # temporary result startTestRun and stopTestRun are called.\n\n    def test_run__uses_defaultTestResult(self):\n        events = []\n        defaultResult = LoggingResult(events)\n\n        class Foo(unittest.TestCase):\n            def test(self):\n                events.append('test')\n\n            def defaultTestResult(self):\n                return defaultResult\n\n        # Make run() find a result object on its own\n        result = Foo('test').run()\n\n        self.assertIs(result, defaultResult)\n        expected = ['startTestRun', 'startTest', 'test', 'addSuccess',\n            'stopTest', 'stopTestRun']\n        self.assertEqual(events, expected)\n\n\n    # \"The result object is returned to run's caller\"\n    def test_run__returns_given_result(self):\n\n        class Foo(unittest.TestCase):\n            def test(self):\n                pass\n\n        result = unittest.TestResult()\n\n        retval = Foo('test').run(result)\n        self.assertIs(retval, result)\n\n\n    # \"The same effect [as method run] may be had by simply calling the\n    # TestCase instance.\"\n    def test_call__invoking_an_instance_delegates_to_run(self):\n        resultIn = unittest.TestResult()\n        resultOut = unittest.TestResult()\n\n        class Foo(unittest.TestCase):\n            def test(self):\n                pass\n\n            def run(self, result):\n                self.assertIs(result, resultIn)\n                return resultOut\n\n        retval = Foo('test')(resultIn)\n\n        self.assertIs(retval, resultOut)\n\n\n    def testShortDescriptionWithoutDocstring(self):\n        self.assertIsNone(self.shortDescription())\n\n    @unittest.skipIf(sys.flags.optimize >= 2,\n                     \"Docstrings are omitted with -O2 and above\")\n    def testShortDescriptionWithOneLineDocstring(self):\n        \"\"\"Tests shortDescription() for a method with a docstring.\"\"\"\n        self.assertEqual(\n                self.shortDescription(),\n                'Tests shortDescription() for a method with a docstring.')\n\n    @unittest.skipIf(sys.flags.optimize >= 2,\n                     \"Docstrings are omitted with -O2 and above\")\n    def testShortDescriptionWithMultiLineDocstring(self):\n        \"\"\"Tests shortDescription() for a method with a longer docstring.\n\n        This method ensures that only the first line of a docstring is\n        returned used in the short description, no matter how long the\n        whole thing is.\n        \"\"\"\n        self.assertEqual(\n                self.shortDescription(),\n                 'Tests shortDescription() for a method with a longer '\n                 'docstring.')\n\n    def testAddTypeEqualityFunc(self):\n        class SadSnake(object):\n            \"\"\"Dummy class for test_addTypeEqualityFunc.\"\"\"\n        s1, s2 = SadSnake(), SadSnake()\n        self.assertFalse(s1 == s2)\n        def AllSnakesCreatedEqual(a, b, msg=None):\n            return type(a) == type(b) == SadSnake\n        self.addTypeEqualityFunc(SadSnake, AllSnakesCreatedEqual)\n        self.assertEqual(s1, s2)\n        # No this doesn't clean up and remove the SadSnake equality func\n        # from this TestCase instance but since its a local nothing else\n        # will ever notice that.\n\n    def testAssertIs(self):\n        thing = object()\n        self.assertIs(thing, thing)\n        self.assertRaises(self.failureException, self.assertIs, thing, object())\n\n    def testAssertIsNot(self):\n        thing = object()\n        self.assertIsNot(thing, object())\n        self.assertRaises(self.failureException, self.assertIsNot, thing, thing)\n\n    def testAssertIsInstance(self):\n        thing = []\n        self.assertIsInstance(thing, list)\n        self.assertRaises(self.failureException, self.assertIsInstance,\n                          thing, dict)\n\n    def testAssertNotIsInstance(self):\n        thing = []\n        self.assertNotIsInstance(thing, dict)\n        self.assertRaises(self.failureException, self.assertNotIsInstance,\n                          thing, list)\n\n    def testAssertIn(self):\n        animals = {'monkey': 'banana', 'cow': 'grass', 'seal': 'fish'}\n\n        self.assertIn('a', 'abc')\n        self.assertIn(2, [1, 2, 3])\n        self.assertIn('monkey', animals)\n\n        self.assertNotIn('d', 'abc')\n        self.assertNotIn(0, [1, 2, 3])\n        self.assertNotIn('otter', animals)\n\n        self.assertRaises(self.failureException, self.assertIn, 'x', 'abc')\n        self.assertRaises(self.failureException, self.assertIn, 4, [1, 2, 3])\n        self.assertRaises(self.failureException, self.assertIn, 'elephant',\n                          animals)\n\n        self.assertRaises(self.failureException, self.assertNotIn, 'c', 'abc')\n        self.assertRaises(self.failureException, self.assertNotIn, 1, [1, 2, 3])\n        self.assertRaises(self.failureException, self.assertNotIn, 'cow',\n                          animals)\n\n    def testAssertDictContainsSubset(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", DeprecationWarning)\n\n            self.assertDictContainsSubset({}, {})\n            self.assertDictContainsSubset({}, {'a': 1})\n            self.assertDictContainsSubset({'a': 1}, {'a': 1})\n            self.assertDictContainsSubset({'a': 1}, {'a': 1, 'b': 2})\n            self.assertDictContainsSubset({'a': 1, 'b': 2}, {'a': 1, 'b': 2})\n\n            with self.assertRaises(self.failureException):\n                self.assertDictContainsSubset({1: \"one\"}, {})\n\n            with self.assertRaises(self.failureException):\n                self.assertDictContainsSubset({'a': 2}, {'a': 1})\n\n            with self.assertRaises(self.failureException):\n                self.assertDictContainsSubset({'c': 1}, {'a': 1})\n\n            with self.assertRaises(self.failureException):\n                self.assertDictContainsSubset({'a': 1, 'c': 1}, {'a': 1})\n\n            with self.assertRaises(self.failureException):\n                self.assertDictContainsSubset({'a': 1, 'c': 1}, {'a': 1})\n\n            one = ''.join(chr(i) for i in range(255))\n            # this used to cause a UnicodeDecodeError constructing the failure msg\n            with self.assertRaises(self.failureException):\n                self.assertDictContainsSubset({'foo': one}, {'foo': '\\uFFFD'})\n\n    def testAssertEqual(self):\n        equal_pairs = [\n                ((), ()),\n                ({}, {}),\n                ([], []),\n                (set(), set()),\n                (frozenset(), frozenset())]\n        for a, b in equal_pairs:\n            # This mess of try excepts is to test the assertEqual behavior\n            # itself.\n            try:\n                self.assertEqual(a, b)\n            except self.failureException:\n                self.fail('assertEqual(%r, %r) failed' % (a, b))\n            try:\n                self.assertEqual(a, b, msg='foo')\n            except self.failureException:\n                self.fail('assertEqual(%r, %r) with msg= failed' % (a, b))\n            try:\n                self.assertEqual(a, b, 'foo')\n            except self.failureException:\n                self.fail('assertEqual(%r, %r) with third parameter failed' %\n                          (a, b))\n\n        unequal_pairs = [\n               ((), []),\n               ({}, set()),\n               (set([4,1]), frozenset([4,2])),\n               (frozenset([4,5]), set([2,3])),\n               (set([3,4]), set([5,4]))]\n        for a, b in unequal_pairs:\n            self.assertRaises(self.failureException, self.assertEqual, a, b)\n            self.assertRaises(self.failureException, self.assertEqual, a, b,\n                              'foo')\n            self.assertRaises(self.failureException, self.assertEqual, a, b,\n                              msg='foo')\n\n    def testEquality(self):\n        self.assertListEqual([], [])\n        self.assertTupleEqual((), ())\n        self.assertSequenceEqual([], ())\n\n        a = [0, 'a', []]\n        b = []\n        self.assertRaises(unittest.TestCase.failureException,\n                          self.assertListEqual, a, b)\n        self.assertRaises(unittest.TestCase.failureException,\n                          self.assertListEqual, tuple(a), tuple(b))\n        self.assertRaises(unittest.TestCase.failureException,\n                          self.assertSequenceEqual, a, tuple(b))\n\n        b.extend(a)\n        self.assertListEqual(a, b)\n        self.assertTupleEqual(tuple(a), tuple(b))\n        self.assertSequenceEqual(a, tuple(b))\n        self.assertSequenceEqual(tuple(a), b)\n\n        self.assertRaises(self.failureException, self.assertListEqual,\n                          a, tuple(b))\n        self.assertRaises(self.failureException, self.assertTupleEqual,\n                          tuple(a), b)\n        self.assertRaises(self.failureException, self.assertListEqual, None, b)\n        self.assertRaises(self.failureException, self.assertTupleEqual, None,\n                          tuple(b))\n        self.assertRaises(self.failureException, self.assertSequenceEqual,\n                          None, tuple(b))\n        self.assertRaises(self.failureException, self.assertListEqual, 1, 1)\n        self.assertRaises(self.failureException, self.assertTupleEqual, 1, 1)\n        self.assertRaises(self.failureException, self.assertSequenceEqual,\n                          1, 1)\n\n        self.assertDictEqual({}, {})\n\n        c = { 'x': 1 }\n        d = {}\n        self.assertRaises(unittest.TestCase.failureException,\n                          self.assertDictEqual, c, d)\n\n        d.update(c)\n        self.assertDictEqual(c, d)\n\n        d['x'] = 0\n        self.assertRaises(unittest.TestCase.failureException,\n                          self.assertDictEqual, c, d, 'These are unequal')\n\n        self.assertRaises(self.failureException, self.assertDictEqual, None, d)\n        self.assertRaises(self.failureException, self.assertDictEqual, [], d)\n        self.assertRaises(self.failureException, self.assertDictEqual, 1, 1)\n\n    def testAssertSequenceEqualMaxDiff(self):\n        self.assertEqual(self.maxDiff, 80*8)\n        seq1 = 'a' + 'x' * 80**2\n        seq2 = 'b' + 'x' * 80**2\n        diff = '\\n'.join(difflib.ndiff(pprint.pformat(seq1).splitlines(),\n                                       pprint.pformat(seq2).splitlines()))\n        # the +1 is the leading \\n added by assertSequenceEqual\n        omitted = unittest.case.DIFF_OMITTED % (len(diff) + 1,)\n\n        self.maxDiff = len(diff)//2\n        try:\n\n            self.assertSequenceEqual(seq1, seq2)\n        except self.failureException as e:\n            msg = e.args[0]\n        else:\n            self.fail('assertSequenceEqual did not fail.')\n        self.assertTrue(len(msg) < len(diff))\n        self.assertIn(omitted, msg)\n\n        self.maxDiff = len(diff) * 2\n        try:\n            self.assertSequenceEqual(seq1, seq2)\n        except self.failureException as e:\n            msg = e.args[0]\n        else:\n            self.fail('assertSequenceEqual did not fail.')\n        self.assertTrue(len(msg) > len(diff))\n        self.assertNotIn(omitted, msg)\n\n        self.maxDiff = None\n        try:\n            self.assertSequenceEqual(seq1, seq2)\n        except self.failureException as e:\n            msg = e.args[0]\n        else:\n            self.fail('assertSequenceEqual did not fail.')\n        self.assertTrue(len(msg) > len(diff))\n        self.assertNotIn(omitted, msg)\n\n    def testTruncateMessage(self):\n        self.maxDiff = 1\n        message = self._truncateMessage('foo', 'bar')\n        omitted = unittest.case.DIFF_OMITTED % len('bar')\n        self.assertEqual(message, 'foo' + omitted)\n\n        self.maxDiff = None\n        message = self._truncateMessage('foo', 'bar')\n        self.assertEqual(message, 'foobar')\n\n        self.maxDiff = 4\n        message = self._truncateMessage('foo', 'bar')\n        self.assertEqual(message, 'foobar')\n\n    def testAssertDictEqualTruncates(self):\n        test = unittest.TestCase('assertEqual')\n        def truncate(msg, diff):\n            return 'foo'\n        test._truncateMessage = truncate\n        try:\n            test.assertDictEqual({}, {1: 0})\n        except self.failureException as e:\n            self.assertEqual(str(e), 'foo')\n        else:\n            self.fail('assertDictEqual did not fail')\n\n    def testAssertMultiLineEqualTruncates(self):\n        test = unittest.TestCase('assertEqual')\n        def truncate(msg, diff):\n            return 'foo'\n        test._truncateMessage = truncate\n        try:\n            test.assertMultiLineEqual('foo', 'bar')\n        except self.failureException as e:\n            self.assertEqual(str(e), 'foo')\n        else:\n            self.fail('assertMultiLineEqual did not fail')\n\n    def testAssertEqual_diffThreshold(self):\n        # check threshold value\n        self.assertEqual(self._diffThreshold, 2**16)\n        # disable madDiff to get diff markers\n        self.maxDiff = None\n\n        # set a lower threshold value and add a cleanup to restore it\n        old_threshold = self._diffThreshold\n        self._diffThreshold = 2**8\n        self.addCleanup(lambda: setattr(self, '_diffThreshold', old_threshold))\n\n        # under the threshold: diff marker (^) in error message\n        s = 'x' * (2**7)\n        with self.assertRaises(self.failureException) as cm:\n            self.assertEqual(s + 'a', s + 'b')\n        self.assertIn('^', str(cm.exception))\n        self.assertEqual(s + 'a', s + 'a')\n\n        # over the threshold: diff not used and marker (^) not in error message\n        s = 'x' * (2**9)\n        # if the path that uses difflib is taken, _truncateMessage will be\n        # called -- replace it with explodingTruncation to verify that this\n        # doesn't happen\n        def explodingTruncation(message, diff):\n            raise SystemError('this should not be raised')\n        old_truncate = self._truncateMessage\n        self._truncateMessage = explodingTruncation\n        self.addCleanup(lambda: setattr(self, '_truncateMessage', old_truncate))\n\n        s1, s2 = s + 'a', s + 'b'\n        with self.assertRaises(self.failureException) as cm:\n            self.assertEqual(s1, s2)\n        self.assertNotIn('^', str(cm.exception))\n        self.assertEqual(str(cm.exception), '%r != %r' % (s1, s2))\n        self.assertEqual(s + 'a', s + 'a')\n\n    def testAssertCountEqual(self):\n        a = object()\n        self.assertCountEqual([1, 2, 3], [3, 2, 1])\n        self.assertCountEqual(['foo', 'bar', 'baz'], ['bar', 'baz', 'foo'])\n        self.assertCountEqual([a, a, 2, 2, 3], (a, 2, 3, a, 2))\n        self.assertCountEqual([1, \"2\", \"a\", \"a\"], [\"a\", \"2\", True, \"a\"])\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [1, 2] + [3] * 100, [1] * 100 + [2, 3])\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [1, \"2\", \"a\", \"a\"], [\"a\", \"2\", True, 1])\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [10], [10, 11])\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [10, 11], [10])\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [10, 11, 10], [10, 11])\n\n        # Test that sequences of unhashable objects can be tested for sameness:\n        self.assertCountEqual([[1, 2], [3, 4], 0], [False, [3, 4], [1, 2]])\n        # Test that iterator of unhashable objects can be tested for sameness:\n        self.assertCountEqual(iter([1, 2, [], 3, 4]),\n                              iter([1, 2, [], 3, 4]))\n\n        # hashable types, but not orderable\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [], [divmod, 'x', 1, 5j, 2j, frozenset()])\n        # comparing dicts\n        self.assertCountEqual([{'a': 1}, {'b': 2}], [{'b': 2}, {'a': 1}])\n        # comparing heterogenous non-hashable sequences\n        self.assertCountEqual([1, 'x', divmod, []], [divmod, [], 'x', 1])\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [], [divmod, [], 'x', 1, 5j, 2j, set()])\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [[1]], [[2]])\n\n        # Same elements, but not same sequence length\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [1, 1, 2], [2, 1])\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [1, 1, \"2\", \"a\", \"a\"], [\"2\", \"2\", True, \"a\"])\n        self.assertRaises(self.failureException, self.assertCountEqual,\n                          [1, {'b': 2}, None, True], [{'b': 2}, True, None])\n\n        # Same elements which don't reliably compare, in\n        # different order, see issue 10242\n        a = [{2,4}, {1,2}]\n        b = a[::-1]\n        self.assertCountEqual(a, b)\n\n        # test utility functions supporting assertCountEqual()\n\n        diffs = set(unittest.util._count_diff_all_purpose('aaabccd', 'abbbcce'))\n        expected = {(3,1,'a'), (1,3,'b'), (1,0,'d'), (0,1,'e')}\n        self.assertEqual(diffs, expected)\n\n        diffs = unittest.util._count_diff_all_purpose([[]], [])\n        self.assertEqual(diffs, [(1, 0, [])])\n\n        diffs = set(unittest.util._count_diff_hashable('aaabccd', 'abbbcce'))\n        expected = {(3,1,'a'), (1,3,'b'), (1,0,'d'), (0,1,'e')}\n        self.assertEqual(diffs, expected)\n\n    def testAssertSetEqual(self):\n        set1 = set()\n        set2 = set()\n        self.assertSetEqual(set1, set2)\n\n        self.assertRaises(self.failureException, self.assertSetEqual, None, set2)\n        self.assertRaises(self.failureException, self.assertSetEqual, [], set2)\n        self.assertRaises(self.failureException, self.assertSetEqual, set1, None)\n        self.assertRaises(self.failureException, self.assertSetEqual, set1, [])\n\n        set1 = set(['a'])\n        set2 = set()\n        self.assertRaises(self.failureException, self.assertSetEqual, set1, set2)\n\n        set1 = set(['a'])\n        set2 = set(['a'])\n        self.assertSetEqual(set1, set2)\n\n        set1 = set(['a'])\n        set2 = set(['a', 'b'])\n        self.assertRaises(self.failureException, self.assertSetEqual, set1, set2)\n\n        set1 = set(['a'])\n        set2 = frozenset(['a', 'b'])\n        self.assertRaises(self.failureException, self.assertSetEqual, set1, set2)\n\n        set1 = set(['a', 'b'])\n        set2 = frozenset(['a', 'b'])\n        self.assertSetEqual(set1, set2)\n\n        set1 = set()\n        set2 = \"foo\"\n        self.assertRaises(self.failureException, self.assertSetEqual, set1, set2)\n        self.assertRaises(self.failureException, self.assertSetEqual, set2, set1)\n\n        # make sure any string formatting is tuple-safe\n        set1 = set([(0, 1), (2, 3)])\n        set2 = set([(4, 5)])\n        self.assertRaises(self.failureException, self.assertSetEqual, set1, set2)\n\n    def testInequality(self):\n        # Try ints\n        self.assertGreater(2, 1)\n        self.assertGreaterEqual(2, 1)\n        self.assertGreaterEqual(1, 1)\n        self.assertLess(1, 2)\n        self.assertLessEqual(1, 2)\n        self.assertLessEqual(1, 1)\n        self.assertRaises(self.failureException, self.assertGreater, 1, 2)\n        self.assertRaises(self.failureException, self.assertGreater, 1, 1)\n        self.assertRaises(self.failureException, self.assertGreaterEqual, 1, 2)\n        self.assertRaises(self.failureException, self.assertLess, 2, 1)\n        self.assertRaises(self.failureException, self.assertLess, 1, 1)\n        self.assertRaises(self.failureException, self.assertLessEqual, 2, 1)\n\n        # Try Floats\n        self.assertGreater(1.1, 1.0)\n        self.assertGreaterEqual(1.1, 1.0)\n        self.assertGreaterEqual(1.0, 1.0)\n        self.assertLess(1.0, 1.1)\n        self.assertLessEqual(1.0, 1.1)\n        self.assertLessEqual(1.0, 1.0)\n        self.assertRaises(self.failureException, self.assertGreater, 1.0, 1.1)\n        self.assertRaises(self.failureException, self.assertGreater, 1.0, 1.0)\n        self.assertRaises(self.failureException, self.assertGreaterEqual, 1.0, 1.1)\n        self.assertRaises(self.failureException, self.assertLess, 1.1, 1.0)\n        self.assertRaises(self.failureException, self.assertLess, 1.0, 1.0)\n        self.assertRaises(self.failureException, self.assertLessEqual, 1.1, 1.0)\n\n        # Try Strings\n        self.assertGreater('bug', 'ant')\n        self.assertGreaterEqual('bug', 'ant')\n        self.assertGreaterEqual('ant', 'ant')\n        self.assertLess('ant', 'bug')\n        self.assertLessEqual('ant', 'bug')\n        self.assertLessEqual('ant', 'ant')\n        self.assertRaises(self.failureException, self.assertGreater, 'ant', 'bug')\n        self.assertRaises(self.failureException, self.assertGreater, 'ant', 'ant')\n        self.assertRaises(self.failureException, self.assertGreaterEqual, 'ant', 'bug')\n        self.assertRaises(self.failureException, self.assertLess, 'bug', 'ant')\n        self.assertRaises(self.failureException, self.assertLess, 'ant', 'ant')\n        self.assertRaises(self.failureException, self.assertLessEqual, 'bug', 'ant')\n\n        # Try bytes\n        self.assertGreater(b'bug', b'ant')\n        self.assertGreaterEqual(b'bug', b'ant')\n        self.assertGreaterEqual(b'ant', b'ant')\n        self.assertLess(b'ant', b'bug')\n        self.assertLessEqual(b'ant', b'bug')\n        self.assertLessEqual(b'ant', b'ant')\n        self.assertRaises(self.failureException, self.assertGreater, b'ant', b'bug')\n        self.assertRaises(self.failureException, self.assertGreater, b'ant', b'ant')\n        self.assertRaises(self.failureException, self.assertGreaterEqual, b'ant',\n                          b'bug')\n        self.assertRaises(self.failureException, self.assertLess, b'bug', b'ant')\n        self.assertRaises(self.failureException, self.assertLess, b'ant', b'ant')\n        self.assertRaises(self.failureException, self.assertLessEqual, b'bug', b'ant')\n\n    def testAssertMultiLineEqual(self):\n        sample_text = \"\"\"\\\nhttp://www.python.org/doc/2.3/lib/module-unittest.html\ntest case\n    A test case is the smallest unit of testing. [...]\n\"\"\"\n        revised_sample_text = \"\"\"\\\nhttp://www.python.org/doc/2.4.1/lib/module-unittest.html\ntest case\n    A test case is the smallest unit of testing. [...] You may provide your\n    own implementation that does not subclass from TestCase, of course.\n\"\"\"\n        sample_text_error = \"\"\"\\\n- http://www.python.org/doc/2.3/lib/module-unittest.html\n?                             ^\n+ http://www.python.org/doc/2.4.1/lib/module-unittest.html\n?                             ^^^\n  test case\n-     A test case is the smallest unit of testing. [...]\n+     A test case is the smallest unit of testing. [...] You may provide your\n?                                                       +++++++++++++++++++++\n+     own implementation that does not subclass from TestCase, of course.\n\"\"\"\n        self.maxDiff = None\n        try:\n            self.assertMultiLineEqual(sample_text, revised_sample_text)\n        except self.failureException as e:\n            # need to remove the first line of the error message\n            error = str(e).split('\\n', 1)[1]\n\n            # no fair testing ourself with ourself, and assertEqual is used for strings\n            # so can't use assertEqual either. Just use assertTrue.\n            self.assertTrue(sample_text_error == error)\n\n    def testAsertEqualSingleLine(self):\n        sample_text = \"laden swallows fly slowly\"\n        revised_sample_text = \"unladen swallows fly quickly\"\n        sample_text_error = \"\"\"\\\n- laden swallows fly slowly\n?                    ^^^^\n+ unladen swallows fly quickly\n? ++                   ^^^^^\n\"\"\"\n        try:\n            self.assertEqual(sample_text, revised_sample_text)\n        except self.failureException as e:\n            error = str(e).split('\\n', 1)[1]\n            self.assertTrue(sample_text_error == error)\n\n    def testAssertIsNone(self):\n        self.assertIsNone(None)\n        self.assertRaises(self.failureException, self.assertIsNone, False)\n        self.assertIsNotNone('DjZoPloGears on Rails')\n        self.assertRaises(self.failureException, self.assertIsNotNone, None)\n\n    def testAssertRegex(self):\n        self.assertRegex('asdfabasdf', r'ab+')\n        self.assertRaises(self.failureException, self.assertRegex,\n                          'saaas', r'aaaa')\n\n    def testAssertRaisesRegex(self):\n        class ExceptionMock(Exception):\n            pass\n\n        def Stub():\n            raise ExceptionMock('We expect')\n\n        self.assertRaisesRegex(ExceptionMock, re.compile('expect$'), Stub)\n        self.assertRaisesRegex(ExceptionMock, 'expect$', Stub)\n\n    def testAssertNotRaisesRegex(self):\n        self.assertRaisesRegex(\n                self.failureException, '^Exception not raised by <lambda>$',\n                self.assertRaisesRegex, Exception, re.compile('x'),\n                lambda: None)\n        self.assertRaisesRegex(\n                self.failureException, '^Exception not raised by <lambda>$',\n                self.assertRaisesRegex, Exception, 'x',\n                lambda: None)\n\n    def testAssertRaisesRegexMismatch(self):\n        def Stub():\n            raise Exception('Unexpected')\n\n        self.assertRaisesRegex(\n                self.failureException,\n                r'\"\\^Expected\\$\" does not match \"Unexpected\"',\n                self.assertRaisesRegex, Exception, '^Expected$',\n                Stub)\n        self.assertRaisesRegex(\n                self.failureException,\n                r'\"\\^Expected\\$\" does not match \"Unexpected\"',\n                self.assertRaisesRegex, Exception,\n                re.compile('^Expected$'), Stub)\n\n    def testAssertRaisesExcValue(self):\n        class ExceptionMock(Exception):\n            pass\n\n        def Stub(foo):\n            raise ExceptionMock(foo)\n        v = \"particular value\"\n\n        ctx = self.assertRaises(ExceptionMock)\n        with ctx:\n            Stub(v)\n        e = ctx.exception\n        self.assertIsInstance(e, ExceptionMock)\n        self.assertEqual(e.args[0], v)\n\n    def testAssertWarnsCallable(self):\n        def _runtime_warn():\n            warnings.warn(\"foo\", RuntimeWarning)\n        # Success when the right warning is triggered, even several times\n        self.assertWarns(RuntimeWarning, _runtime_warn)\n        self.assertWarns(RuntimeWarning, _runtime_warn)\n        # A tuple of warning classes is accepted\n        self.assertWarns((DeprecationWarning, RuntimeWarning), _runtime_warn)\n        # *args and **kwargs also work\n        self.assertWarns(RuntimeWarning,\n                         warnings.warn, \"foo\", category=RuntimeWarning)\n        # Failure when no warning is triggered\n        with self.assertRaises(self.failureException):\n            self.assertWarns(RuntimeWarning, lambda: 0)\n        # Failure when another warning is triggered\n        with warnings.catch_warnings():\n            # Force default filter (in case tests are run with -We)\n            warnings.simplefilter(\"default\", RuntimeWarning)\n            with self.assertRaises(self.failureException):\n                self.assertWarns(DeprecationWarning, _runtime_warn)\n        # Filters for other warnings are not modified\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"error\", RuntimeWarning)\n            with self.assertRaises(RuntimeWarning):\n                self.assertWarns(DeprecationWarning, _runtime_warn)\n\n    def testAssertWarnsContext(self):\n        # Believe it or not, it is preferrable to duplicate all tests above,\n        # to make sure the __warningregistry__ $@ is circumvented correctly.\n        def _runtime_warn():\n            warnings.warn(\"foo\", RuntimeWarning)\n        _runtime_warn_lineno = inspect.getsourcelines(_runtime_warn)[1]\n        with self.assertWarns(RuntimeWarning) as cm:\n            _runtime_warn()\n        # A tuple of warning classes is accepted\n        with self.assertWarns((DeprecationWarning, RuntimeWarning)) as cm:\n            _runtime_warn()\n        # The context manager exposes various useful attributes\n        self.assertIsInstance(cm.warning, RuntimeWarning)\n        self.assertEqual(cm.warning.args[0], \"foo\")\n        self.assertIn(\"test_case.py\", cm.filename)\n        self.assertEqual(cm.lineno, _runtime_warn_lineno + 1)\n        # Same with several warnings\n        with self.assertWarns(RuntimeWarning):\n            _runtime_warn()\n            _runtime_warn()\n        with self.assertWarns(RuntimeWarning):\n            warnings.warn(\"foo\", category=RuntimeWarning)\n        # Failure when no warning is triggered\n        with self.assertRaises(self.failureException):\n            with self.assertWarns(RuntimeWarning):\n                pass\n        # Failure when another warning is triggered\n        with warnings.catch_warnings():\n            # Force default filter (in case tests are run with -We)\n            warnings.simplefilter(\"default\", RuntimeWarning)\n            with self.assertRaises(self.failureException):\n                with self.assertWarns(DeprecationWarning):\n                    _runtime_warn()\n        # Filters for other warnings are not modified\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"error\", RuntimeWarning)\n            with self.assertRaises(RuntimeWarning):\n                with self.assertWarns(DeprecationWarning):\n                    _runtime_warn()\n\n    def testAssertWarnsRegexCallable(self):\n        def _runtime_warn(msg):\n            warnings.warn(msg, RuntimeWarning)\n        self.assertWarnsRegex(RuntimeWarning, \"o+\",\n                              _runtime_warn, \"foox\")\n        # Failure when no warning is triggered\n        with self.assertRaises(self.failureException):\n            self.assertWarnsRegex(RuntimeWarning, \"o+\",\n                                  lambda: 0)\n        # Failure when another warning is triggered\n        with warnings.catch_warnings():\n            # Force default filter (in case tests are run with -We)\n            warnings.simplefilter(\"default\", RuntimeWarning)\n            with self.assertRaises(self.failureException):\n                self.assertWarnsRegex(DeprecationWarning, \"o+\",\n                                      _runtime_warn, \"foox\")\n        # Failure when message doesn't match\n        with self.assertRaises(self.failureException):\n            self.assertWarnsRegex(RuntimeWarning, \"o+\",\n                                  _runtime_warn, \"barz\")\n        # A little trickier: we ask RuntimeWarnings to be raised, and then\n        # check for some of them.  It is implementation-defined whether\n        # non-matching RuntimeWarnings are simply re-raised, or produce a\n        # failureException.\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"error\", RuntimeWarning)\n            with self.assertRaises((RuntimeWarning, self.failureException)):\n                self.assertWarnsRegex(RuntimeWarning, \"o+\",\n                                      _runtime_warn, \"barz\")\n\n    def testAssertWarnsRegexContext(self):\n        # Same as above, but with assertWarnsRegex as a context manager\n        def _runtime_warn(msg):\n            warnings.warn(msg, RuntimeWarning)\n        _runtime_warn_lineno = inspect.getsourcelines(_runtime_warn)[1]\n        with self.assertWarnsRegex(RuntimeWarning, \"o+\") as cm:\n            _runtime_warn(\"foox\")\n        self.assertIsInstance(cm.warning, RuntimeWarning)\n        self.assertEqual(cm.warning.args[0], \"foox\")\n        self.assertIn(\"test_case.py\", cm.filename)\n        self.assertEqual(cm.lineno, _runtime_warn_lineno + 1)\n        # Failure when no warning is triggered\n        with self.assertRaises(self.failureException):\n            with self.assertWarnsRegex(RuntimeWarning, \"o+\"):\n                pass\n        # Failure when another warning is triggered\n        with warnings.catch_warnings():\n            # Force default filter (in case tests are run with -We)\n            warnings.simplefilter(\"default\", RuntimeWarning)\n            with self.assertRaises(self.failureException):\n                with self.assertWarnsRegex(DeprecationWarning, \"o+\"):\n                    _runtime_warn(\"foox\")\n        # Failure when message doesn't match\n        with self.assertRaises(self.failureException):\n            with self.assertWarnsRegex(RuntimeWarning, \"o+\"):\n                _runtime_warn(\"barz\")\n        # A little trickier: we ask RuntimeWarnings to be raised, and then\n        # check for some of them.  It is implementation-defined whether\n        # non-matching RuntimeWarnings are simply re-raised, or produce a\n        # failureException.\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"error\", RuntimeWarning)\n            with self.assertRaises((RuntimeWarning, self.failureException)):\n                with self.assertWarnsRegex(RuntimeWarning, \"o+\"):\n                    _runtime_warn(\"barz\")\n\n    def testDeprecatedMethodNames(self):\n        \"\"\"\n        Test that the deprecated methods raise a DeprecationWarning. See #9424.\n        \"\"\"\n        old = (\n            (self.failIfEqual, (3, 5)),\n            (self.assertNotEquals, (3, 5)),\n            (self.failUnlessEqual, (3, 3)),\n            (self.assertEquals, (3, 3)),\n            (self.failUnlessAlmostEqual, (2.0, 2.0)),\n            (self.assertAlmostEquals, (2.0, 2.0)),\n            (self.failIfAlmostEqual, (3.0, 5.0)),\n            (self.assertNotAlmostEquals, (3.0, 5.0)),\n            (self.failUnless, (True,)),\n            (self.assert_, (True,)),\n            (self.failUnlessRaises, (TypeError, lambda _: 3.14 + 'spam')),\n            (self.failIf, (False,)),\n            (self.assertDictContainsSubset, (dict(a=1, b=2), dict(a=1, b=2, c=3))),\n            (self.assertRaisesRegexp, (KeyError, 'foo', lambda: {}['foo'])),\n            (self.assertRegexpMatches, ('bar', 'bar')),\n        )\n        for meth, args in old:\n            with self.assertWarns(DeprecationWarning):\n                meth(*args)\n\n    # disable this test for now. When the version where the fail* methods will\n    # be removed is decided, re-enable it and update the version\n    def _testDeprecatedFailMethods(self):\n        \"\"\"Test that the deprecated fail* methods get removed in 3.x\"\"\"\n        if sys.version_info[:2] < (3, 3):\n            return\n        deprecated_names = [\n            'failIfEqual', 'failUnlessEqual', 'failUnlessAlmostEqual',\n            'failIfAlmostEqual', 'failUnless', 'failUnlessRaises', 'failIf',\n            'assertDictContainsSubset',\n        ]\n        for deprecated_name in deprecated_names:\n            with self.assertRaises(AttributeError):\n                getattr(self, deprecated_name)  # remove these in 3.x\n\n    def testDeepcopy(self):\n        # Issue: 5660\n        class TestableTest(unittest.TestCase):\n            def testNothing(self):\n                pass\n\n        test = TestableTest('testNothing')\n\n        # This shouldn't blow up\n        deepcopy(test)\n\n    def testPickle(self):\n        # Issue 10326\n\n        # Can't use TestCase classes defined in Test class as\n        # pickle does not work with inner classes\n        test = unittest.TestCase('run')\n        for protocol in range(pickle.HIGHEST_PROTOCOL + 1):\n\n            # blew up prior to fix\n            pickled_test = pickle.dumps(test, protocol=protocol)\n            unpickled_test = pickle.loads(pickled_test)\n            self.assertEqual(test, unpickled_test)\n\n            # exercise the TestCase instance in a way that will invoke\n            # the type equality lookup mechanism\n            unpickled_test.assertEqual(set(), set())\n\n    def testKeyboardInterrupt(self):\n        def _raise(self=None):\n            raise KeyboardInterrupt\n        def nothing(self):\n            pass\n\n        class Test1(unittest.TestCase):\n            test_something = _raise\n\n        class Test2(unittest.TestCase):\n            setUp = _raise\n            test_something = nothing\n\n        class Test3(unittest.TestCase):\n            test_something = nothing\n            tearDown = _raise\n\n        class Test4(unittest.TestCase):\n            def test_something(self):\n                self.addCleanup(_raise)\n\n        for klass in (Test1, Test2, Test3, Test4):\n            with self.assertRaises(KeyboardInterrupt):\n                klass('test_something').run()\n\n    def testSkippingEverywhere(self):\n        def _skip(self=None):\n            raise unittest.SkipTest('some reason')\n        def nothing(self):\n            pass\n\n        class Test1(unittest.TestCase):\n            test_something = _skip\n\n        class Test2(unittest.TestCase):\n            setUp = _skip\n            test_something = nothing\n\n        class Test3(unittest.TestCase):\n            test_something = nothing\n            tearDown = _skip\n\n        class Test4(unittest.TestCase):\n            def test_something(self):\n                self.addCleanup(_skip)\n\n        for klass in (Test1, Test2, Test3, Test4):\n            result = unittest.TestResult()\n            klass('test_something').run(result)\n            self.assertEqual(len(result.skipped), 1)\n            self.assertEqual(result.testsRun, 1)\n\n    def testSystemExit(self):\n        def _raise(self=None):\n            raise SystemExit\n        def nothing(self):\n            pass\n\n        class Test1(unittest.TestCase):\n            test_something = _raise\n\n        class Test2(unittest.TestCase):\n            setUp = _raise\n            test_something = nothing\n\n        class Test3(unittest.TestCase):\n            test_something = nothing\n            tearDown = _raise\n\n        class Test4(unittest.TestCase):\n            def test_something(self):\n                self.addCleanup(_raise)\n\n        for klass in (Test1, Test2, Test3, Test4):\n            result = unittest.TestResult()\n            klass('test_something').run(result)\n            self.assertEqual(len(result.errors), 1)\n            self.assertEqual(result.testsRun, 1)\n\n    @support.cpython_only\n    def testNoCycles(self):\n        case = unittest.TestCase()\n        wr = weakref.ref(case)\n        with support.disable_gc():\n            del case\n            self.assertFalse(wr())\n"], "unittest.util": [".py", "\"\"\"Various utility functions.\"\"\"\n\nfrom collections import namedtuple, OrderedDict\n\n__unittest = True\n\n_MAX_LENGTH = 80\ndef safe_repr(obj, short=False):\n    try:\n        result = repr(obj)\n    except Exception:\n        result = object.__repr__(obj)\n    if not short or len(result) < _MAX_LENGTH:\n        return result\n    return result[:_MAX_LENGTH] + ' [truncated]...'\n\ndef strclass(cls):\n    return \"%s.%s\" % (cls.__module__, cls.__name__)\n\ndef sorted_list_difference(expected, actual):\n    \"\"\"Finds elements in only one or the other of two, sorted input lists.\n\n    Returns a two-element tuple of lists.    The first list contains those\n    elements in the \"expected\" list but not in the \"actual\" list, and the\n    second contains those elements in the \"actual\" list but not in the\n    \"expected\" list.    Duplicate elements in either input list are ignored.\n    \"\"\"\n    i = j = 0\n    missing = []\n    unexpected = []\n    while True:\n        try:\n            e = expected[i]\n            a = actual[j]\n            if e < a:\n                missing.append(e)\n                i += 1\n                while expected[i] == e:\n                    i += 1\n            elif e > a:\n                unexpected.append(a)\n                j += 1\n                while actual[j] == a:\n                    j += 1\n            else:\n                i += 1\n                try:\n                    while expected[i] == e:\n                        i += 1\n                finally:\n                    j += 1\n                    while actual[j] == a:\n                        j += 1\n        except IndexError:\n            missing.extend(expected[i:])\n            unexpected.extend(actual[j:])\n            break\n    return missing, unexpected\n\n\ndef unorderable_list_difference(expected, actual):\n    \"\"\"Same behavior as sorted_list_difference but\n    for lists of unorderable items (like dicts).\n\n    As it does a linear search per item (remove) it\n    has O(n*n) performance.\"\"\"\n    missing = []\n    while expected:\n        item = expected.pop()\n        try:\n            actual.remove(item)\n        except ValueError:\n            missing.append(item)\n\n    # anything left in actual is unexpected\n    return missing, actual\n\ndef three_way_cmp(x, y):\n    \"\"\"Return -1 if x < y, 0 if x == y and 1 if x > y\"\"\"\n    return (x > y) - (x < y)\n\n_Mismatch = namedtuple('Mismatch', 'actual expected value')\n\ndef _count_diff_all_purpose(actual, expected):\n    'Returns list of (cnt_act, cnt_exp, elem) triples where the counts differ'\n    # elements need not be hashable\n    s, t = list(actual), list(expected)\n    m, n = len(s), len(t)\n    NULL = object()\n    result = []\n    for i, elem in enumerate(s):\n        if elem is NULL:\n            continue\n        cnt_s = cnt_t = 0\n        for j in range(i, m):\n            if s[j] == elem:\n                cnt_s += 1\n                s[j] = NULL\n        for j, other_elem in enumerate(t):\n            if other_elem == elem:\n                cnt_t += 1\n                t[j] = NULL\n        if cnt_s != cnt_t:\n            diff = _Mismatch(cnt_s, cnt_t, elem)\n            result.append(diff)\n\n    for i, elem in enumerate(t):\n        if elem is NULL:\n            continue\n        cnt_t = 0\n        for j in range(i, n):\n            if t[j] == elem:\n                cnt_t += 1\n                t[j] = NULL\n        diff = _Mismatch(0, cnt_t, elem)\n        result.append(diff)\n    return result\n\ndef _ordered_count(iterable):\n    'Return dict of element counts, in the order they were first seen'\n    c = OrderedDict()\n    for elem in iterable:\n        c[elem] = c.get(elem, 0) + 1\n    return c\n\ndef _count_diff_hashable(actual, expected):\n    'Returns list of (cnt_act, cnt_exp, elem) triples where the counts differ'\n    # elements must be hashable\n    s, t = _ordered_count(actual), _ordered_count(expected)\n    result = []\n    for elem, cnt_s in s.items():\n        cnt_t = t.get(elem, 0)\n        if cnt_s != cnt_t:\n            diff = _Mismatch(cnt_s, cnt_t, elem)\n            result.append(diff)\n    for elem, cnt_t in t.items():\n        if elem not in s:\n            diff = _Mismatch(0, cnt_t, elem)\n            result.append(diff)\n    return result\n"], "_weakref": [".py", "class ProxyType:\n\n    def __init__(self,obj):\n        self.obj = obj\n\nCallableProxyType = ProxyType\nProxyTypes = [ProxyType,CallableProxyType]\n\nclass ReferenceType:\n\n    def __init__(self,obj,callback):\n        self.obj = obj\n        self.callback = callback\n\nclass ref:\n\n    def __init__(self,obj,callback=None):\n        self.obj = ReferenceType(obj,callback)\n        self.callback=callback\n\ndef getweakrefcount(obj):\n    return 1\n\ndef getweakrefs(obj):\n    return obj\n\n\ndef proxy(obj,callback):\n    return ProxyType(obj)\n\n"], "difflib": [".py", "#! /usr/bin/env python3\n\n\"\"\"\nModule difflib -- helpers for computing deltas between objects.\n\nFunction get_close_matches(word, possibilities, n=3, cutoff=0.6):\n    Use SequenceMatcher to return list of the best \"good enough\" matches.\n\nFunction context_diff(a, b):\n    For two lists of strings, return a delta in context diff format.\n\nFunction ndiff(a, b):\n    Return a delta: the difference between `a` and `b` (lists of strings).\n\nFunction restore(delta, which):\n    Return one of the two sequences that generated an ndiff delta.\n\nFunction unified_diff(a, b):\n    For two lists of strings, return a delta in unified diff format.\n\nClass SequenceMatcher:\n    A flexible class for comparing pairs of sequences of any type.\n\nClass Differ:\n    For producing human-readable deltas from sequences of lines of text.\n\nClass HtmlDiff:\n    For producing HTML side by side comparison with change highlights.\n\"\"\"\n\n__all__ = ['get_close_matches', 'ndiff', 'restore', 'SequenceMatcher',\n           'Differ','IS_CHARACTER_JUNK', 'IS_LINE_JUNK', 'context_diff',\n           'unified_diff', 'HtmlDiff', 'Match']\n\nimport warnings\nimport heapq\nfrom collections import namedtuple as _namedtuple\n\nMatch = _namedtuple('Match', 'a b size')\n\ndef _calculate_ratio(matches, length):\n    if length:\n        return 2.0 * matches / length\n    return 1.0\n\nclass SequenceMatcher:\n\n    \"\"\"\n    SequenceMatcher is a flexible class for comparing pairs of sequences of\n    any type, so long as the sequence elements are hashable.  The basic\n    algorithm predates, and is a little fancier than, an algorithm\n    published in the late 1980's by Ratcliff and Obershelp under the\n    hyperbolic name \"gestalt pattern matching\".  The basic idea is to find\n    the longest contiguous matching subsequence that contains no \"junk\"\n    elements (R-O doesn't address junk).  The same idea is then applied\n    recursively to the pieces of the sequences to the left and to the right\n    of the matching subsequence.  This does not yield minimal edit\n    sequences, but does tend to yield matches that \"look right\" to people.\n\n    SequenceMatcher tries to compute a \"human-friendly diff\" between two\n    sequences.  Unlike e.g. UNIX(tm) diff, the fundamental notion is the\n    longest *contiguous* & junk-free matching subsequence.  That's what\n    catches peoples' eyes.  The Windows(tm) windiff has another interesting\n    notion, pairing up elements that appear uniquely in each sequence.\n    That, and the method here, appear to yield more intuitive difference\n    reports than does diff.  This method appears to be the least vulnerable\n    to synching up on blocks of \"junk lines\", though (like blank lines in\n    ordinary text files, or maybe \"<P>\" lines in HTML files).  That may be\n    because this is the only method of the 3 that has a *concept* of\n    \"junk\" <wink>.\n\n    Example, comparing two strings, and considering blanks to be \"junk\":\n\n    >>> s = SequenceMatcher(lambda x: x == \" \",\n    ...                     \"private Thread currentThread;\",\n    ...                     \"private volatile Thread currentThread;\")\n    >>>\n\n    .ratio() returns a float in [0, 1], measuring the \"similarity\" of the\n    sequences.  As a rule of thumb, a .ratio() value over 0.6 means the\n    sequences are close matches:\n\n    >>> print(round(s.ratio(), 3))\n    0.866\n    >>>\n\n    If you're only interested in where the sequences match,\n    .get_matching_blocks() is handy:\n\n    >>> for block in s.get_matching_blocks():\n    ...     print(\"a[%d] and b[%d] match for %d elements\" % block)\n    a[0] and b[0] match for 8 elements\n    a[8] and b[17] match for 21 elements\n    a[29] and b[38] match for 0 elements\n\n    Note that the last tuple returned by .get_matching_blocks() is always a\n    dummy, (len(a), len(b), 0), and this is the only case in which the last\n    tuple element (number of elements matched) is 0.\n\n    If you want to know how to change the first sequence into the second,\n    use .get_opcodes():\n\n    >>> for opcode in s.get_opcodes():\n    ...     print(\"%6s a[%d:%d] b[%d:%d]\" % opcode)\n     equal a[0:8] b[0:8]\n    insert a[8:8] b[8:17]\n     equal a[8:29] b[17:38]\n\n    See the Differ class for a fancy human-friendly file differencer, which\n    uses SequenceMatcher both to compare sequences of lines, and to compare\n    sequences of characters within similar (near-matching) lines.\n\n    See also function get_close_matches() in this module, which shows how\n    simple code building on SequenceMatcher can be used to do useful work.\n\n    Timing:  Basic R-O is cubic time worst case and quadratic time expected\n    case.  SequenceMatcher is quadratic time for the worst case and has\n    expected-case behavior dependent in a complicated way on how many\n    elements the sequences have in common; best case time is linear.\n\n    Methods:\n\n    __init__(isjunk=None, a='', b='')\n        Construct a SequenceMatcher.\n\n    set_seqs(a, b)\n        Set the two sequences to be compared.\n\n    set_seq1(a)\n        Set the first sequence to be compared.\n\n    set_seq2(b)\n        Set the second sequence to be compared.\n\n    find_longest_match(alo, ahi, blo, bhi)\n        Find longest matching block in a[alo:ahi] and b[blo:bhi].\n\n    get_matching_blocks()\n        Return list of triples describing matching subsequences.\n\n    get_opcodes()\n        Return list of 5-tuples describing how to turn a into b.\n\n    ratio()\n        Return a measure of the sequences' similarity (float in [0,1]).\n\n    quick_ratio()\n        Return an upper bound on .ratio() relatively quickly.\n\n    real_quick_ratio()\n        Return an upper bound on ratio() very quickly.\n    \"\"\"\n\n    def __init__(self, isjunk=None, a='', b='', autojunk=True):\n        \"\"\"Construct a SequenceMatcher.\n\n        Optional arg isjunk is None (the default), or a one-argument\n        function that takes a sequence element and returns true iff the\n        element is junk.  None is equivalent to passing \"lambda x: 0\", i.e.\n        no elements are considered to be junk.  For example, pass\n            lambda x: x in \" \\\\t\"\n        if you're comparing lines as sequences of characters, and don't\n        want to synch up on blanks or hard tabs.\n\n        Optional arg a is the first of two sequences to be compared.  By\n        default, an empty string.  The elements of a must be hashable.  See\n        also .set_seqs() and .set_seq1().\n\n        Optional arg b is the second of two sequences to be compared.  By\n        default, an empty string.  The elements of b must be hashable. See\n        also .set_seqs() and .set_seq2().\n\n        Optional arg autojunk should be set to False to disable the\n        \"automatic junk heuristic\" that treats popular elements as junk\n        (see module documentation for more information).\n        \"\"\"\n\n        # Members:\n        # a\n        #      first sequence\n        # b\n        #      second sequence; differences are computed as \"what do\n        #      we need to do to 'a' to change it into 'b'?\"\n        # b2j\n        #      for x in b, b2j[x] is a list of the indices (into b)\n        #      at which x appears; junk and popular elements do not appear\n        # fullbcount\n        #      for x in b, fullbcount[x] == the number of times x\n        #      appears in b; only materialized if really needed (used\n        #      only for computing quick_ratio())\n        # matching_blocks\n        #      a list of (i, j, k) triples, where a[i:i+k] == b[j:j+k];\n        #      ascending & non-overlapping in i and in j; terminated by\n        #      a dummy (len(a), len(b), 0) sentinel\n        # opcodes\n        #      a list of (tag, i1, i2, j1, j2) tuples, where tag is\n        #      one of\n        #          'replace'   a[i1:i2] should be replaced by b[j1:j2]\n        #          'delete'    a[i1:i2] should be deleted\n        #          'insert'    b[j1:j2] should be inserted\n        #          'equal'     a[i1:i2] == b[j1:j2]\n        # isjunk\n        #      a user-supplied function taking a sequence element and\n        #      returning true iff the element is \"junk\" -- this has\n        #      subtle but helpful effects on the algorithm, which I'll\n        #      get around to writing up someday <0.9 wink>.\n        #      DON'T USE!  Only __chain_b uses this.  Use \"in self.bjunk\".\n        # bjunk\n        #      the items in b for which isjunk is True.\n        # bpopular\n        #      nonjunk items in b treated as junk by the heuristic (if used).\n\n        self.isjunk = isjunk\n        self.a = self.b = None\n        self.autojunk = autojunk\n        self.set_seqs(a, b)\n\n    def set_seqs(self, a, b):\n        \"\"\"Set the two sequences to be compared.\n\n        >>> s = SequenceMatcher()\n        >>> s.set_seqs(\"abcd\", \"bcde\")\n        >>> s.ratio()\n        0.75\n        \"\"\"\n\n        self.set_seq1(a)\n        self.set_seq2(b)\n\n    def set_seq1(self, a):\n        \"\"\"Set the first sequence to be compared.\n\n        The second sequence to be compared is not changed.\n\n        >>> s = SequenceMatcher(None, \"abcd\", \"bcde\")\n        >>> s.ratio()\n        0.75\n        >>> s.set_seq1(\"bcde\")\n        >>> s.ratio()\n        1.0\n        >>>\n\n        SequenceMatcher computes and caches detailed information about the\n        second sequence, so if you want to compare one sequence S against\n        many sequences, use .set_seq2(S) once and call .set_seq1(x)\n        repeatedly for each of the other sequences.\n\n        See also set_seqs() and set_seq2().\n        \"\"\"\n\n        if a is self.a:\n            return\n        self.a = a\n        self.matching_blocks = self.opcodes = None\n\n    def set_seq2(self, b):\n        \"\"\"Set the second sequence to be compared.\n\n        The first sequence to be compared is not changed.\n\n        >>> s = SequenceMatcher(None, \"abcd\", \"bcde\")\n        >>> s.ratio()\n        0.75\n        >>> s.set_seq2(\"abcd\")\n        >>> s.ratio()\n        1.0\n        >>>\n\n        SequenceMatcher computes and caches detailed information about the\n        second sequence, so if you want to compare one sequence S against\n        many sequences, use .set_seq2(S) once and call .set_seq1(x)\n        repeatedly for each of the other sequences.\n\n        See also set_seqs() and set_seq1().\n        \"\"\"\n\n        if b is self.b:\n            return\n        self.b = b\n        self.matching_blocks = self.opcodes = None\n        self.fullbcount = None\n        self.__chain_b()\n\n    # For each element x in b, set b2j[x] to a list of the indices in\n    # b where x appears; the indices are in increasing order; note that\n    # the number of times x appears in b is len(b2j[x]) ...\n    # when self.isjunk is defined, junk elements don't show up in this\n    # map at all, which stops the central find_longest_match method\n    # from starting any matching block at a junk element ...\n    # b2j also does not contain entries for \"popular\" elements, meaning\n    # elements that account for more than 1 + 1% of the total elements, and\n    # when the sequence is reasonably large (>= 200 elements); this can\n    # be viewed as an adaptive notion of semi-junk, and yields an enormous\n    # speedup when, e.g., comparing program files with hundreds of\n    # instances of \"return NULL;\" ...\n    # note that this is only called when b changes; so for cross-product\n    # kinds of matches, it's best to call set_seq2 once, then set_seq1\n    # repeatedly\n\n    def __chain_b(self):\n        # Because isjunk is a user-defined (not C) function, and we test\n        # for junk a LOT, it's important to minimize the number of calls.\n        # Before the tricks described here, __chain_b was by far the most\n        # time-consuming routine in the whole module!  If anyone sees\n        # Jim Roskind, thank him again for profile.py -- I never would\n        # have guessed that.\n        # The first trick is to build b2j ignoring the possibility\n        # of junk.  I.e., we don't call isjunk at all yet.  Throwing\n        # out the junk later is much cheaper than building b2j \"right\"\n        # from the start.\n        b = self.b\n        self.b2j = b2j = {}\n\n        for i, elt in enumerate(b):\n            indices = b2j.setdefault(elt, [])\n            indices.append(i)\n\n        # Purge junk elements\n        self.bjunk = junk = set()\n        isjunk = self.isjunk\n        if isjunk:\n            for elt in b2j.keys():\n                if isjunk(elt):\n                    junk.add(elt)\n            for elt in junk: # separate loop avoids separate list of keys\n                del b2j[elt]\n\n        # Purge popular elements that are not junk\n        self.bpopular = popular = set()\n        n = len(b)\n        if self.autojunk and n >= 200:\n            ntest = n // 100 + 1\n            for elt, idxs in b2j.items():\n                if len(idxs) > ntest:\n                    popular.add(elt)\n            for elt in popular: # ditto; as fast for 1% deletion\n                del b2j[elt]\n\n    def isbjunk(self, item):\n        \"Deprecated; use 'item in SequenceMatcher().bjunk'.\"\n        warnings.warn(\"'SequenceMatcher().isbjunk(item)' is deprecated;\\n\"\n                      \"use 'item in SMinstance.bjunk' instead.\",\n                      DeprecationWarning, 2)\n        return item in self.bjunk\n\n    def isbpopular(self, item):\n        \"Deprecated; use 'item in SequenceMatcher().bpopular'.\"\n        warnings.warn(\"'SequenceMatcher().isbpopular(item)' is deprecated;\\n\"\n                      \"use 'item in SMinstance.bpopular' instead.\",\n                      DeprecationWarning, 2)\n        return item in self.bpopular\n\n    def find_longest_match(self, alo, ahi, blo, bhi):\n        \"\"\"Find longest matching block in a[alo:ahi] and b[blo:bhi].\n\n        If isjunk is not defined:\n\n        Return (i,j,k) such that a[i:i+k] is equal to b[j:j+k], where\n            alo <= i <= i+k <= ahi\n            blo <= j <= j+k <= bhi\n        and for all (i',j',k') meeting those conditions,\n            k >= k'\n            i <= i'\n            and if i == i', j <= j'\n\n        In other words, of all maximal matching blocks, return one that\n        starts earliest in a, and of all those maximal matching blocks that\n        start earliest in a, return the one that starts earliest in b.\n\n        >>> s = SequenceMatcher(None, \" abcd\", \"abcd abcd\")\n        >>> s.find_longest_match(0, 5, 0, 9)\n        Match(a=0, b=4, size=5)\n\n        If isjunk is defined, first the longest matching block is\n        determined as above, but with the additional restriction that no\n        junk element appears in the block.  Then that block is extended as\n        far as possible by matching (only) junk elements on both sides.  So\n        the resulting block never matches on junk except as identical junk\n        happens to be adjacent to an \"interesting\" match.\n\n        Here's the same example as before, but considering blanks to be\n        junk.  That prevents \" abcd\" from matching the \" abcd\" at the tail\n        end of the second sequence directly.  Instead only the \"abcd\" can\n        match, and matches the leftmost \"abcd\" in the second sequence:\n\n        >>> s = SequenceMatcher(lambda x: x==\" \", \" abcd\", \"abcd abcd\")\n        >>> s.find_longest_match(0, 5, 0, 9)\n        Match(a=1, b=0, size=4)\n\n        If no blocks match, return (alo, blo, 0).\n\n        >>> s = SequenceMatcher(None, \"ab\", \"c\")\n        >>> s.find_longest_match(0, 2, 0, 1)\n        Match(a=0, b=0, size=0)\n        \"\"\"\n\n        # CAUTION:  stripping common prefix or suffix would be incorrect.\n        # E.g.,\n        #    ab\n        #    acab\n        # Longest matching block is \"ab\", but if common prefix is\n        # stripped, it's \"a\" (tied with \"b\").  UNIX(tm) diff does so\n        # strip, so ends up claiming that ab is changed to acab by\n        # inserting \"ca\" in the middle.  That's minimal but unintuitive:\n        # \"it's obvious\" that someone inserted \"ac\" at the front.\n        # Windiff ends up at the same place as diff, but by pairing up\n        # the unique 'b's and then matching the first two 'a's.\n\n        a, b, b2j, isbjunk = self.a, self.b, self.b2j, self.bjunk.__contains__\n        besti, bestj, bestsize = alo, blo, 0\n        # find longest junk-free match\n        # during an iteration of the loop, j2len[j] = length of longest\n        # junk-free match ending with a[i-1] and b[j]\n        j2len = {}\n        nothing = []\n        for i in range(alo, ahi):\n            # look at all instances of a[i] in b; note that because\n            # b2j has no junk keys, the loop is skipped if a[i] is junk\n            j2lenget = j2len.get\n            newj2len = {}\n            for j in b2j.get(a[i], nothing):\n                # a[i] matches b[j]\n                if j < blo:\n                    continue\n                if j >= bhi:\n                    break\n                k = newj2len[j] = j2lenget(j-1, 0) + 1\n                if k > bestsize:\n                    besti, bestj, bestsize = i-k+1, j-k+1, k\n            j2len = newj2len\n\n        # Extend the best by non-junk elements on each end.  In particular,\n        # \"popular\" non-junk elements aren't in b2j, which greatly speeds\n        # the inner loop above, but also means \"the best\" match so far\n        # doesn't contain any junk *or* popular non-junk elements.\n        while besti > alo and bestj > blo and \\\n              not isbjunk(b[bestj-1]) and \\\n              a[besti-1] == b[bestj-1]:\n            besti, bestj, bestsize = besti-1, bestj-1, bestsize+1\n        while besti+bestsize < ahi and bestj+bestsize < bhi and \\\n              not isbjunk(b[bestj+bestsize]) and \\\n              a[besti+bestsize] == b[bestj+bestsize]:\n            bestsize += 1\n\n        # Now that we have a wholly interesting match (albeit possibly\n        # empty!), we may as well suck up the matching junk on each\n        # side of it too.  Can't think of a good reason not to, and it\n        # saves post-processing the (possibly considerable) expense of\n        # figuring out what to do with it.  In the case of an empty\n        # interesting match, this is clearly the right thing to do,\n        # because no other kind of match is possible in the regions.\n        while besti > alo and bestj > blo and \\\n              isbjunk(b[bestj-1]) and \\\n              a[besti-1] == b[bestj-1]:\n            besti, bestj, bestsize = besti-1, bestj-1, bestsize+1\n        while besti+bestsize < ahi and bestj+bestsize < bhi and \\\n              isbjunk(b[bestj+bestsize]) and \\\n              a[besti+bestsize] == b[bestj+bestsize]:\n            bestsize = bestsize + 1\n\n        return Match(besti, bestj, bestsize)\n\n    def get_matching_blocks(self):\n        \"\"\"Return list of triples describing matching subsequences.\n\n        Each triple is of the form (i, j, n), and means that\n        a[i:i+n] == b[j:j+n].  The triples are monotonically increasing in\n        i and in j.  New in Python 2.5, it's also guaranteed that if\n        (i, j, n) and (i', j', n') are adjacent triples in the list, and\n        the second is not the last triple in the list, then i+n != i' or\n        j+n != j'.  IOW, adjacent triples never describe adjacent equal\n        blocks.\n\n        The last triple is a dummy, (len(a), len(b), 0), and is the only\n        triple with n==0.\n\n        >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\")\n        >>> list(s.get_matching_blocks())\n        [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]\n        \"\"\"\n\n        if self.matching_blocks is not None:\n            return self.matching_blocks\n        la, lb = len(self.a), len(self.b)\n\n        # This is most naturally expressed as a recursive algorithm, but\n        # at least one user bumped into extreme use cases that exceeded\n        # the recursion limit on their box.  So, now we maintain a list\n        # ('queue`) of blocks we still need to look at, and append partial\n        # results to `matching_blocks` in a loop; the matches are sorted\n        # at the end.\n        queue = [(0, la, 0, lb)]\n        matching_blocks = []\n        while queue:\n            alo, ahi, blo, bhi = queue.pop()\n            i, j, k = x = self.find_longest_match(alo, ahi, blo, bhi)\n            # a[alo:i] vs b[blo:j] unknown\n            # a[i:i+k] same as b[j:j+k]\n            # a[i+k:ahi] vs b[j+k:bhi] unknown\n            if k:   # if k is 0, there was no matching block\n                matching_blocks.append(x)\n                if alo < i and blo < j:\n                    queue.append((alo, i, blo, j))\n                if i+k < ahi and j+k < bhi:\n                    queue.append((i+k, ahi, j+k, bhi))\n        matching_blocks.sort()\n\n        # It's possible that we have adjacent equal blocks in the\n        # matching_blocks list now.  Starting with 2.5, this code was added\n        # to collapse them.\n        i1 = j1 = k1 = 0\n        non_adjacent = []\n        for i2, j2, k2 in matching_blocks:\n            # Is this block adjacent to i1, j1, k1?\n            if i1 + k1 == i2 and j1 + k1 == j2:\n                # Yes, so collapse them -- this just increases the length of\n                # the first block by the length of the second, and the first\n                # block so lengthened remains the block to compare against.\n                k1 += k2\n            else:\n                # Not adjacent.  Remember the first block (k1==0 means it's\n                # the dummy we started with), and make the second block the\n                # new block to compare against.\n                if k1:\n                    non_adjacent.append((i1, j1, k1))\n                i1, j1, k1 = i2, j2, k2\n        if k1:\n            non_adjacent.append((i1, j1, k1))\n\n        non_adjacent.append( (la, lb, 0) )\n        self.matching_blocks = non_adjacent\n        return map(Match._make, self.matching_blocks)\n\n    def get_opcodes(self):\n        \"\"\"Return list of 5-tuples describing how to turn a into b.\n\n        Each tuple is of the form (tag, i1, i2, j1, j2).  The first tuple\n        has i1 == j1 == 0, and remaining tuples have i1 == the i2 from the\n        tuple preceding it, and likewise for j1 == the previous j2.\n\n        The tags are strings, with these meanings:\n\n        'replace':  a[i1:i2] should be replaced by b[j1:j2]\n        'delete':   a[i1:i2] should be deleted.\n                    Note that j1==j2 in this case.\n        'insert':   b[j1:j2] should be inserted at a[i1:i1].\n                    Note that i1==i2 in this case.\n        'equal':    a[i1:i2] == b[j1:j2]\n\n        >>> a = \"qabxcd\"\n        >>> b = \"abycdf\"\n        >>> s = SequenceMatcher(None, a, b)\n        >>> for tag, i1, i2, j1, j2 in s.get_opcodes():\n        ...    print((\"%7s a[%d:%d] (%s) b[%d:%d] (%s)\" %\n        ...           (tag, i1, i2, a[i1:i2], j1, j2, b[j1:j2])))\n         delete a[0:1] (q) b[0:0] ()\n          equal a[1:3] (ab) b[0:2] (ab)\n        replace a[3:4] (x) b[2:3] (y)\n          equal a[4:6] (cd) b[3:5] (cd)\n         insert a[6:6] () b[5:6] (f)\n        \"\"\"\n\n        if self.opcodes is not None:\n            return self.opcodes\n        i = j = 0\n        self.opcodes = answer = []\n        for ai, bj, size in self.get_matching_blocks():\n            # invariant:  we've pumped out correct diffs to change\n            # a[:i] into b[:j], and the next matching block is\n            # a[ai:ai+size] == b[bj:bj+size].  So we need to pump\n            # out a diff to change a[i:ai] into b[j:bj], pump out\n            # the matching block, and move (i,j) beyond the match\n            tag = ''\n            if i < ai and j < bj:\n                tag = 'replace'\n            elif i < ai:\n                tag = 'delete'\n            elif j < bj:\n                tag = 'insert'\n            if tag:\n                answer.append( (tag, i, ai, j, bj) )\n            i, j = ai+size, bj+size\n            # the list of matching blocks is terminated by a\n            # sentinel with size 0\n            if size:\n                answer.append( ('equal', ai, i, bj, j) )\n        return answer\n\n    def get_grouped_opcodes(self, n=3):\n        \"\"\" Isolate change clusters by eliminating ranges with no changes.\n\n        Return a generator of groups with up to n lines of context.\n        Each group is in the same format as returned by get_opcodes().\n\n        >>> from pprint import pprint\n        >>> a = list(map(str, range(1,40)))\n        >>> b = a[:]\n        >>> b[8:8] = ['i']     # Make an insertion\n        >>> b[20] += 'x'       # Make a replacement\n        >>> b[23:28] = []      # Make a deletion\n        >>> b[30] += 'y'       # Make another replacement\n        >>> pprint(list(SequenceMatcher(None,a,b).get_grouped_opcodes()))\n        [[('equal', 5, 8, 5, 8), ('insert', 8, 8, 8, 9), ('equal', 8, 11, 9, 12)],\n         [('equal', 16, 19, 17, 20),\n          ('replace', 19, 20, 20, 21),\n          ('equal', 20, 22, 21, 23),\n          ('delete', 22, 27, 23, 23),\n          ('equal', 27, 30, 23, 26)],\n         [('equal', 31, 34, 27, 30),\n          ('replace', 34, 35, 30, 31),\n          ('equal', 35, 38, 31, 34)]]\n        \"\"\"\n\n        codes = self.get_opcodes()\n        if not codes:\n            codes = [(\"equal\", 0, 1, 0, 1)]\n        # Fixup leading and trailing groups if they show no changes.\n        if codes[0][0] == 'equal':\n            tag, i1, i2, j1, j2 = codes[0]\n            codes[0] = tag, max(i1, i2-n), i2, max(j1, j2-n), j2\n        if codes[-1][0] == 'equal':\n            tag, i1, i2, j1, j2 = codes[-1]\n            codes[-1] = tag, i1, min(i2, i1+n), j1, min(j2, j1+n)\n\n        nn = n + n\n        group = []\n        for tag, i1, i2, j1, j2 in codes:\n            # End the current group and start a new one whenever\n            # there is a large range with no changes.\n            if tag == 'equal' and i2-i1 > nn:\n                group.append((tag, i1, min(i2, i1+n), j1, min(j2, j1+n)))\n                yield group\n                group = []\n                i1, j1 = max(i1, i2-n), max(j1, j2-n)\n            group.append((tag, i1, i2, j1 ,j2))\n        if group and not (len(group)==1 and group[0][0] == 'equal'):\n            yield group\n\n    def ratio(self):\n        \"\"\"Return a measure of the sequences' similarity (float in [0,1]).\n\n        Where T is the total number of elements in both sequences, and\n        M is the number of matches, this is 2.0*M / T.\n        Note that this is 1 if the sequences are identical, and 0 if\n        they have nothing in common.\n\n        .ratio() is expensive to compute if you haven't already computed\n        .get_matching_blocks() or .get_opcodes(), in which case you may\n        want to try .quick_ratio() or .real_quick_ratio() first to get an\n        upper bound.\n\n        >>> s = SequenceMatcher(None, \"abcd\", \"bcde\")\n        >>> s.ratio()\n        0.75\n        >>> s.quick_ratio()\n        0.75\n        >>> s.real_quick_ratio()\n        1.0\n        \"\"\"\n\n        matches = sum(triple[-1] for triple in self.get_matching_blocks())\n        return _calculate_ratio(matches, len(self.a) + len(self.b))\n\n    def quick_ratio(self):\n        \"\"\"Return an upper bound on ratio() relatively quickly.\n\n        This isn't defined beyond that it is an upper bound on .ratio(), and\n        is faster to compute.\n        \"\"\"\n\n        # viewing a and b as multisets, set matches to the cardinality\n        # of their intersection; this counts the number of matches\n        # without regard to order, so is clearly an upper bound\n        if self.fullbcount is None:\n            self.fullbcount = fullbcount = {}\n            for elt in self.b:\n                fullbcount[elt] = fullbcount.get(elt, 0) + 1\n        fullbcount = self.fullbcount\n        # avail[x] is the number of times x appears in 'b' less the\n        # number of times we've seen it in 'a' so far ... kinda\n        avail = {}\n        availhas, matches = avail.__contains__, 0\n        for elt in self.a:\n            if availhas(elt):\n                numb = avail[elt]\n            else:\n                numb = fullbcount.get(elt, 0)\n            avail[elt] = numb - 1\n            if numb > 0:\n                matches = matches + 1\n        return _calculate_ratio(matches, len(self.a) + len(self.b))\n\n    def real_quick_ratio(self):\n        \"\"\"Return an upper bound on ratio() very quickly.\n\n        This isn't defined beyond that it is an upper bound on .ratio(), and\n        is faster to compute than either .ratio() or .quick_ratio().\n        \"\"\"\n\n        la, lb = len(self.a), len(self.b)\n        # can't have more matches than the number of elements in the\n        # shorter sequence\n        return _calculate_ratio(min(la, lb), la + lb)\n\ndef get_close_matches(word, possibilities, n=3, cutoff=0.6):\n    \"\"\"Use SequenceMatcher to return list of the best \"good enough\" matches.\n\n    word is a sequence for which close matches are desired (typically a\n    string).\n\n    possibilities is a list of sequences against which to match word\n    (typically a list of strings).\n\n    Optional arg n (default 3) is the maximum number of close matches to\n    return.  n must be > 0.\n\n    Optional arg cutoff (default 0.6) is a float in [0, 1].  Possibilities\n    that don't score at least that similar to word are ignored.\n\n    The best (no more than n) matches among the possibilities are returned\n    in a list, sorted by similarity score, most similar first.\n\n    >>> get_close_matches(\"appel\", [\"ape\", \"apple\", \"peach\", \"puppy\"])\n    ['apple', 'ape']\n    >>> import keyword as _keyword\n    >>> get_close_matches(\"wheel\", _keyword.kwlist)\n    ['while']\n    >>> get_close_matches(\"Apple\", _keyword.kwlist)\n    []\n    >>> get_close_matches(\"accept\", _keyword.kwlist)\n    ['except']\n    \"\"\"\n\n    if not n >  0:\n        raise ValueError(\"n must be > 0: %r\" % (n,))\n    if not 0.0 <= cutoff <= 1.0:\n        raise ValueError(\"cutoff must be in [0.0, 1.0]: %r\" % (cutoff,))\n    result = []\n    s = SequenceMatcher()\n    s.set_seq2(word)\n    for x in possibilities:\n        s.set_seq1(x)\n        if s.real_quick_ratio() >= cutoff and \\\n           s.quick_ratio() >= cutoff and \\\n           s.ratio() >= cutoff:\n            result.append((s.ratio(), x))\n\n    # Move the best scorers to head of list\n    result = heapq.nlargest(n, result)\n    # Strip scores for the best n matches\n    return [x for score, x in result]\n\ndef _count_leading(line, ch):\n    \"\"\"\n    Return number of `ch` characters at the start of `line`.\n\n    Example:\n\n    >>> _count_leading('   abc', ' ')\n    3\n    \"\"\"\n\n    i, n = 0, len(line)\n    while i < n and line[i] == ch:\n        i += 1\n    return i\n\nclass Differ:\n    r\"\"\"\n    Differ is a class for comparing sequences of lines of text, and\n    producing human-readable differences or deltas.  Differ uses\n    SequenceMatcher both to compare sequences of lines, and to compare\n    sequences of characters within similar (near-matching) lines.\n\n    Each line of a Differ delta begins with a two-letter code:\n\n        '- '    line unique to sequence 1\n        '+ '    line unique to sequence 2\n        '  '    line common to both sequences\n        '? '    line not present in either input sequence\n\n    Lines beginning with '? ' attempt to guide the eye to intraline\n    differences, and were not present in either input sequence.  These lines\n    can be confusing if the sequences contain tab characters.\n\n    Note that Differ makes no claim to produce a *minimal* diff.  To the\n    contrary, minimal diffs are often counter-intuitive, because they synch\n    up anywhere possible, sometimes accidental matches 100 pages apart.\n    Restricting synch points to contiguous matches preserves some notion of\n    locality, at the occasional cost of producing a longer diff.\n\n    Example: Comparing two texts.\n\n    First we set up the texts, sequences of individual single-line strings\n    ending with newlines (such sequences can also be obtained from the\n    `readlines()` method of file-like objects):\n\n    >>> text1 = '''  1. Beautiful is better than ugly.\n    ...   2. Explicit is better than implicit.\n    ...   3. Simple is better than complex.\n    ...   4. Complex is better than complicated.\n    ... '''.splitlines(keepends=True)\n    >>> len(text1)\n    4\n    >>> text1[0][-1]\n    '\\n'\n    >>> text2 = '''  1. Beautiful is better than ugly.\n    ...   3.   Simple is better than complex.\n    ...   4. Complicated is better than complex.\n    ...   5. Flat is better than nested.\n    ... '''.splitlines(keepends=True)\n\n    Next we instantiate a Differ object:\n\n    >>> d = Differ()\n\n    Note that when instantiating a Differ object we may pass functions to\n    filter out line and character 'junk'.  See Differ.__init__ for details.\n\n    Finally, we compare the two:\n\n    >>> result = list(d.compare(text1, text2))\n\n    'result' is a list of strings, so let's pretty-print it:\n\n    >>> from pprint import pprint as _pprint\n    >>> _pprint(result)\n    ['    1. Beautiful is better than ugly.\\n',\n     '-   2. Explicit is better than implicit.\\n',\n     '-   3. Simple is better than complex.\\n',\n     '+   3.   Simple is better than complex.\\n',\n     '?     ++\\n',\n     '-   4. Complex is better than complicated.\\n',\n     '?            ^                     ---- ^\\n',\n     '+   4. Complicated is better than complex.\\n',\n     '?           ++++ ^                      ^\\n',\n     '+   5. Flat is better than nested.\\n']\n\n    As a single multi-line string it looks like this:\n\n    >>> print(''.join(result), end=\"\")\n        1. Beautiful is better than ugly.\n    -   2. Explicit is better than implicit.\n    -   3. Simple is better than complex.\n    +   3.   Simple is better than complex.\n    ?     ++\n    -   4. Complex is better than complicated.\n    ?            ^                     ---- ^\n    +   4. Complicated is better than complex.\n    ?           ++++ ^                      ^\n    +   5. Flat is better than nested.\n\n    Methods:\n\n    __init__(linejunk=None, charjunk=None)\n        Construct a text differencer, with optional filters.\n\n    compare(a, b)\n        Compare two sequences of lines; generate the resulting delta.\n    \"\"\"\n\n    def __init__(self, linejunk=None, charjunk=None):\n        \"\"\"\n        Construct a text differencer, with optional filters.\n\n        The two optional keyword parameters are for filter functions:\n\n        - `linejunk`: A function that should accept a single string argument,\n          and return true iff the string is junk. The module-level function\n          `IS_LINE_JUNK` may be used to filter out lines without visible\n          characters, except for at most one splat ('#').  It is recommended\n          to leave linejunk None; as of Python 2.3, the underlying\n          SequenceMatcher class has grown an adaptive notion of \"noise\" lines\n          that's better than any static definition the author has ever been\n          able to craft.\n\n        - `charjunk`: A function that should accept a string of length 1. The\n          module-level function `IS_CHARACTER_JUNK` may be used to filter out\n          whitespace characters (a blank or tab; **note**: bad idea to include\n          newline in this!).  Use of IS_CHARACTER_JUNK is recommended.\n        \"\"\"\n\n        self.linejunk = linejunk\n        self.charjunk = charjunk\n\n    def compare(self, a, b):\n        r\"\"\"\n        Compare two sequences of lines; generate the resulting delta.\n\n        Each sequence must contain individual single-line strings ending with\n        newlines. Such sequences can be obtained from the `readlines()` method\n        of file-like objects.  The delta generated also consists of newline-\n        terminated strings, ready to be printed as-is via the writeline()\n        method of a file-like object.\n\n        Example:\n\n        >>> print(''.join(Differ().compare('one\\ntwo\\nthree\\n'.splitlines(True),\n        ...                                'ore\\ntree\\nemu\\n'.splitlines(True))),\n        ...       end=\"\")\n        - one\n        ?  ^\n        + ore\n        ?  ^\n        - two\n        - three\n        ?  -\n        + tree\n        + emu\n        \"\"\"\n\n        cruncher = SequenceMatcher(self.linejunk, a, b)\n        for tag, alo, ahi, blo, bhi in cruncher.get_opcodes():\n            if tag == 'replace':\n                g = self._fancy_replace(a, alo, ahi, b, blo, bhi)\n            elif tag == 'delete':\n                g = self._dump('-', a, alo, ahi)\n            elif tag == 'insert':\n                g = self._dump('+', b, blo, bhi)\n            elif tag == 'equal':\n                g = self._dump(' ', a, alo, ahi)\n            else:\n                raise ValueError('unknown tag %r' % (tag,))\n\n            for line in g:\n                yield line\n\n    def _dump(self, tag, x, lo, hi):\n        \"\"\"Generate comparison results for a same-tagged range.\"\"\"\n        for i in range(lo, hi):\n            yield '%s %s' % (tag, x[i])\n\n    def _plain_replace(self, a, alo, ahi, b, blo, bhi):\n        assert alo < ahi and blo < bhi\n        # dump the shorter block first -- reduces the burden on short-term\n        # memory if the blocks are of very different sizes\n        if bhi - blo < ahi - alo:\n            first  = self._dump('+', b, blo, bhi)\n            second = self._dump('-', a, alo, ahi)\n        else:\n            first  = self._dump('-', a, alo, ahi)\n            second = self._dump('+', b, blo, bhi)\n\n        for g in first, second:\n            for line in g:\n                yield line\n\n    def _fancy_replace(self, a, alo, ahi, b, blo, bhi):\n        r\"\"\"\n        When replacing one block of lines with another, search the blocks\n        for *similar* lines; the best-matching pair (if any) is used as a\n        synch point, and intraline difference marking is done on the\n        similar pair. Lots of work, but often worth it.\n\n        Example:\n\n        >>> d = Differ()\n        >>> results = d._fancy_replace(['abcDefghiJkl\\n'], 0, 1,\n        ...                            ['abcdefGhijkl\\n'], 0, 1)\n        >>> print(''.join(results), end=\"\")\n        - abcDefghiJkl\n        ?    ^  ^  ^\n        + abcdefGhijkl\n        ?    ^  ^  ^\n        \"\"\"\n\n        # don't synch up unless the lines have a similarity score of at\n        # least cutoff; best_ratio tracks the best score seen so far\n        best_ratio, cutoff = 0.74, 0.75\n        cruncher = SequenceMatcher(self.charjunk)\n        eqi, eqj = None, None   # 1st indices of equal lines (if any)\n\n        # search for the pair that matches best without being identical\n        # (identical lines must be junk lines, & we don't want to synch up\n        # on junk -- unless we have to)\n        for j in range(blo, bhi):\n            bj = b[j]\n            cruncher.set_seq2(bj)\n            for i in range(alo, ahi):\n                ai = a[i]\n                if ai == bj:\n                    if eqi is None:\n                        eqi, eqj = i, j\n                    continue\n                cruncher.set_seq1(ai)\n                # computing similarity is expensive, so use the quick\n                # upper bounds first -- have seen this speed up messy\n                # compares by a factor of 3.\n                # note that ratio() is only expensive to compute the first\n                # time it's called on a sequence pair; the expensive part\n                # of the computation is cached by cruncher\n                if cruncher.real_quick_ratio() > best_ratio and \\\n                      cruncher.quick_ratio() > best_ratio and \\\n                      cruncher.ratio() > best_ratio:\n                    best_ratio, best_i, best_j = cruncher.ratio(), i, j\n        if best_ratio < cutoff:\n            # no non-identical \"pretty close\" pair\n            if eqi is None:\n                # no identical pair either -- treat it as a straight replace\n                for line in self._plain_replace(a, alo, ahi, b, blo, bhi):\n                    yield line\n                return\n            # no close pair, but an identical pair -- synch up on that\n            best_i, best_j, best_ratio = eqi, eqj, 1.0\n        else:\n            # there's a close pair, so forget the identical pair (if any)\n            eqi = None\n\n        # a[best_i] very similar to b[best_j]; eqi is None iff they're not\n        # identical\n\n        # pump out diffs from before the synch point\n        for line in self._fancy_helper(a, alo, best_i, b, blo, best_j):\n            yield line\n\n        # do intraline marking on the synch pair\n        aelt, belt = a[best_i], b[best_j]\n        if eqi is None:\n            # pump out a '-', '?', '+', '?' quad for the synched lines\n            atags = btags = \"\"\n            cruncher.set_seqs(aelt, belt)\n            for tag, ai1, ai2, bj1, bj2 in cruncher.get_opcodes():\n                la, lb = ai2 - ai1, bj2 - bj1\n                if tag == 'replace':\n                    atags += '^' * la\n                    btags += '^' * lb\n                elif tag == 'delete':\n                    atags += '-' * la\n                elif tag == 'insert':\n                    btags += '+' * lb\n                elif tag == 'equal':\n                    atags += ' ' * la\n                    btags += ' ' * lb\n                else:\n                    raise ValueError('unknown tag %r' % (tag,))\n            for line in self._qformat(aelt, belt, atags, btags):\n                yield line\n        else:\n            # the synch pair is identical\n            yield '  ' + aelt\n\n        # pump out diffs from after the synch point\n        for line in self._fancy_helper(a, best_i+1, ahi, b, best_j+1, bhi):\n            yield line\n\n    def _fancy_helper(self, a, alo, ahi, b, blo, bhi):\n        g = []\n        if alo < ahi:\n            if blo < bhi:\n                g = self._fancy_replace(a, alo, ahi, b, blo, bhi)\n            else:\n                g = self._dump('-', a, alo, ahi)\n        elif blo < bhi:\n            g = self._dump('+', b, blo, bhi)\n\n        for line in g:\n            yield line\n\n    def _qformat(self, aline, bline, atags, btags):\n        r\"\"\"\n        Format \"?\" output and deal with leading tabs.\n\n        Example:\n\n        >>> d = Differ()\n        >>> results = d._qformat('\\tabcDefghiJkl\\n', '\\tabcdefGhijkl\\n',\n        ...                      '  ^ ^  ^      ', '  ^ ^  ^      ')\n        >>> for line in results: print(repr(line))\n        ...\n        '- \\tabcDefghiJkl\\n'\n        '? \\t ^ ^  ^\\n'\n        '+ \\tabcdefGhijkl\\n'\n        '? \\t ^ ^  ^\\n'\n        \"\"\"\n\n        # Can hurt, but will probably help most of the time.\n        common = min(_count_leading(aline, \"\\t\"),\n                     _count_leading(bline, \"\\t\"))\n        common = min(common, _count_leading(atags[:common], \" \"))\n        common = min(common, _count_leading(btags[:common], \" \"))\n        atags = atags[common:].rstrip()\n        btags = btags[common:].rstrip()\n\n        yield \"- \" + aline\n        if atags:\n            yield \"? %s%s\\n\" % (\"\\t\" * common, atags)\n\n        yield \"+ \" + bline\n        if btags:\n            yield \"? %s%s\\n\" % (\"\\t\" * common, btags)\n\n# With respect to junk, an earlier version of ndiff simply refused to\n# *start* a match with a junk element.  The result was cases like this:\n#     before: private Thread currentThread;\n#     after:  private volatile Thread currentThread;\n# If you consider whitespace to be junk, the longest contiguous match\n# not starting with junk is \"e Thread currentThread\".  So ndiff reported\n# that \"e volatil\" was inserted between the 't' and the 'e' in \"private\".\n# While an accurate view, to people that's absurd.  The current version\n# looks for matching blocks that are entirely junk-free, then extends the\n# longest one of those as far as possible but only with matching junk.\n# So now \"currentThread\" is matched, then extended to suck up the\n# preceding blank; then \"private\" is matched, and extended to suck up the\n# following blank; then \"Thread\" is matched; and finally ndiff reports\n# that \"volatile \" was inserted before \"Thread\".  The only quibble\n# remaining is that perhaps it was really the case that \" volatile\"\n# was inserted after \"private\".  I can live with that <wink>.\n\nimport re\n\ndef IS_LINE_JUNK(line, pat=re.compile(r\"\\s*#?\\s*$\").match):\n    r\"\"\"\n    Return 1 for ignorable line: iff `line` is blank or contains a single '#'.\n\n    Examples:\n\n    >>> IS_LINE_JUNK('\\n')\n    True\n    >>> IS_LINE_JUNK('  #   \\n')\n    True\n    >>> IS_LINE_JUNK('hello\\n')\n    False\n    \"\"\"\n\n    return pat(line) is not None\n\ndef IS_CHARACTER_JUNK(ch, ws=\" \\t\"):\n    r\"\"\"\n    Return 1 for ignorable character: iff `ch` is a space or tab.\n\n    Examples:\n\n    >>> IS_CHARACTER_JUNK(' ')\n    True\n    >>> IS_CHARACTER_JUNK('\\t')\n    True\n    >>> IS_CHARACTER_JUNK('\\n')\n    False\n    >>> IS_CHARACTER_JUNK('x')\n    False\n    \"\"\"\n\n    return ch in ws\n\n\n########################################################################\n###  Unified Diff\n########################################################################\n\ndef _format_range_unified(start, stop):\n    'Convert range to the \"ed\" format'\n    # Per the diff spec at http://www.unix.org/single_unix_specification/\n    beginning = start + 1     # lines start numbering with one\n    length = stop - start\n    if length == 1:\n        return '{}'.format(beginning)\n    if not length:\n        beginning -= 1        # empty ranges begin at line just before the range\n    return '{},{}'.format(beginning, length)\n\ndef unified_diff(a, b, fromfile='', tofile='', fromfiledate='',\n                 tofiledate='', n=3, lineterm='\\n'):\n    r\"\"\"\n    Compare two sequences of lines; generate the delta as a unified diff.\n\n    Unified diffs are a compact way of showing line changes and a few\n    lines of context.  The number of context lines is set by 'n' which\n    defaults to three.\n\n    By default, the diff control lines (those with ---, +++, or @@) are\n    created with a trailing newline.  This is helpful so that inputs\n    created from file.readlines() result in diffs that are suitable for\n    file.writelines() since both the inputs and outputs have trailing\n    newlines.\n\n    For inputs that do not have trailing newlines, set the lineterm\n    argument to \"\" so that the output will be uniformly newline free.\n\n    The unidiff format normally has a header for filenames and modification\n    times.  Any or all of these may be specified using strings for\n    'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.\n    The modification times are normally expressed in the ISO 8601 format.\n\n    Example:\n\n    >>> for line in unified_diff('one two three four'.split(),\n    ...             'zero one tree four'.split(), 'Original', 'Current',\n    ...             '2005-01-26 23:30:50', '2010-04-02 10:20:52',\n    ...             lineterm=''):\n    ...     print(line)                 # doctest: +NORMALIZE_WHITESPACE\n    --- Original        2005-01-26 23:30:50\n    +++ Current         2010-04-02 10:20:52\n    @@ -1,4 +1,4 @@\n    +zero\n     one\n    -two\n    -three\n    +tree\n     four\n    \"\"\"\n\n    started = False\n    for group in SequenceMatcher(None,a,b).get_grouped_opcodes(n):\n        if not started:\n            started = True\n            fromdate = '\\t{}'.format(fromfiledate) if fromfiledate else ''\n            todate = '\\t{}'.format(tofiledate) if tofiledate else ''\n            yield '--- {}{}{}'.format(fromfile, fromdate, lineterm)\n            yield '+++ {}{}{}'.format(tofile, todate, lineterm)\n\n        first, last = group[0], group[-1]\n        file1_range = _format_range_unified(first[1], last[2])\n        file2_range = _format_range_unified(first[3], last[4])\n        yield '@@ -{} +{} @@{}'.format(file1_range, file2_range, lineterm)\n\n        for tag, i1, i2, j1, j2 in group:\n            if tag == 'equal':\n                for line in a[i1:i2]:\n                    yield ' ' + line\n                continue\n            if tag in {'replace', 'delete'}:\n                for line in a[i1:i2]:\n                    yield '-' + line\n            if tag in {'replace', 'insert'}:\n                for line in b[j1:j2]:\n                    yield '+' + line\n\n\n########################################################################\n###  Context Diff\n########################################################################\n\ndef _format_range_context(start, stop):\n    'Convert range to the \"ed\" format'\n    # Per the diff spec at http://www.unix.org/single_unix_specification/\n    beginning = start + 1     # lines start numbering with one\n    length = stop - start\n    if not length:\n        beginning -= 1        # empty ranges begin at line just before the range\n    if length <= 1:\n        return '{}'.format(beginning)\n    return '{},{}'.format(beginning, beginning + length - 1)\n\n# See http://www.unix.org/single_unix_specification/\ndef context_diff(a, b, fromfile='', tofile='',\n                 fromfiledate='', tofiledate='', n=3, lineterm='\\n'):\n    r\"\"\"\n    Compare two sequences of lines; generate the delta as a context diff.\n\n    Context diffs are a compact way of showing line changes and a few\n    lines of context.  The number of context lines is set by 'n' which\n    defaults to three.\n\n    By default, the diff control lines (those with *** or ---) are\n    created with a trailing newline.  This is helpful so that inputs\n    created from file.readlines() result in diffs that are suitable for\n    file.writelines() since both the inputs and outputs have trailing\n    newlines.\n\n    For inputs that do not have trailing newlines, set the lineterm\n    argument to \"\" so that the output will be uniformly newline free.\n\n    The context diff format normally has a header for filenames and\n    modification times.  Any or all of these may be specified using\n    strings for 'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.\n    The modification times are normally expressed in the ISO 8601 format.\n    If not specified, the strings default to blanks.\n\n    Example:\n\n    >>> print(''.join(context_diff('one\\ntwo\\nthree\\nfour\\n'.splitlines(True),\n    ...       'zero\\none\\ntree\\nfour\\n'.splitlines(True), 'Original', 'Current')),\n    ...       end=\"\")\n    *** Original\n    --- Current\n    ***************\n    *** 1,4 ****\n      one\n    ! two\n    ! three\n      four\n    --- 1,4 ----\n    + zero\n      one\n    ! tree\n      four\n    \"\"\"\n\n    prefix = dict(insert='+ ', delete='- ', replace='! ', equal='  ')\n    started = False\n    for group in SequenceMatcher(None,a,b).get_grouped_opcodes(n):\n        if not started:\n            started = True\n            fromdate = '\\t{}'.format(fromfiledate) if fromfiledate else ''\n            todate = '\\t{}'.format(tofiledate) if tofiledate else ''\n            yield '*** {}{}{}'.format(fromfile, fromdate, lineterm)\n            yield '--- {}{}{}'.format(tofile, todate, lineterm)\n\n        first, last = group[0], group[-1]\n        yield '***************' + lineterm\n\n        file1_range = _format_range_context(first[1], last[2])\n        yield '*** {} ****{}'.format(file1_range, lineterm)\n\n        if any(tag in {'replace', 'delete'} for tag, _, _, _, _ in group):\n            for tag, i1, i2, _, _ in group:\n                if tag != 'insert':\n                    for line in a[i1:i2]:\n                        yield prefix[tag] + line\n\n        file2_range = _format_range_context(first[3], last[4])\n        yield '--- {} ----{}'.format(file2_range, lineterm)\n\n        if any(tag in {'replace', 'insert'} for tag, _, _, _, _ in group):\n            for tag, _, _, j1, j2 in group:\n                if tag != 'delete':\n                    for line in b[j1:j2]:\n                        yield prefix[tag] + line\n\ndef ndiff(a, b, linejunk=None, charjunk=IS_CHARACTER_JUNK):\n    r\"\"\"\n    Compare `a` and `b` (lists of strings); return a `Differ`-style delta.\n\n    Optional keyword parameters `linejunk` and `charjunk` are for filter\n    functions (or None):\n\n    - linejunk: A function that should accept a single string argument, and\n      return true iff the string is junk.  The default is None, and is\n      recommended; as of Python 2.3, an adaptive notion of \"noise\" lines is\n      used that does a good job on its own.\n\n    - charjunk: A function that should accept a string of length 1. The\n      default is module-level function IS_CHARACTER_JUNK, which filters out\n      whitespace characters (a blank or tab; note: bad idea to include newline\n      in this!).\n\n    Tools/scripts/ndiff.py is a command-line front-end to this function.\n\n    Example:\n\n    >>> diff = ndiff('one\\ntwo\\nthree\\n'.splitlines(keepends=True),\n    ...              'ore\\ntree\\nemu\\n'.splitlines(keepends=True))\n    >>> print(''.join(diff), end=\"\")\n    - one\n    ?  ^\n    + ore\n    ?  ^\n    - two\n    - three\n    ?  -\n    + tree\n    + emu\n    \"\"\"\n    return Differ(linejunk, charjunk).compare(a, b)\n\ndef _mdiff(fromlines, tolines, context=None, linejunk=None,\n           charjunk=IS_CHARACTER_JUNK):\n    r\"\"\"Returns generator yielding marked up from/to side by side differences.\n\n    Arguments:\n    fromlines -- list of text lines to compared to tolines\n    tolines -- list of text lines to be compared to fromlines\n    context -- number of context lines to display on each side of difference,\n               if None, all from/to text lines will be generated.\n    linejunk -- passed on to ndiff (see ndiff documentation)\n    charjunk -- passed on to ndiff (see ndiff documentation)\n\n    This function returns an iterator which returns a tuple:\n    (from line tuple, to line tuple, boolean flag)\n\n    from/to line tuple -- (line num, line text)\n        line num -- integer or None (to indicate a context separation)\n        line text -- original line text with following markers inserted:\n            '\\0+' -- marks start of added text\n            '\\0-' -- marks start of deleted text\n            '\\0^' -- marks start of changed text\n            '\\1' -- marks end of added/deleted/changed text\n\n    boolean flag -- None indicates context separation, True indicates\n        either \"from\" or \"to\" line contains a change, otherwise False.\n\n    This function/iterator was originally developed to generate side by side\n    file difference for making HTML pages (see HtmlDiff class for example\n    usage).\n\n    Note, this function utilizes the ndiff function to generate the side by\n    side difference markup.  Optional ndiff arguments may be passed to this\n    function and they in turn will be passed to ndiff.\n    \"\"\"\n    import re\n\n    # regular expression for finding intraline change indices\n    change_re = re.compile('(\\++|\\-+|\\^+)')\n\n    # create the difference iterator to generate the differences\n    diff_lines_iterator = ndiff(fromlines,tolines,linejunk,charjunk)\n\n    def _make_line(lines, format_key, side, num_lines=[0,0]):\n        \"\"\"Returns line of text with user's change markup and line formatting.\n\n        lines -- list of lines from the ndiff generator to produce a line of\n                 text from.  When producing the line of text to return, the\n                 lines used are removed from this list.\n        format_key -- '+' return first line in list with \"add\" markup around\n                          the entire line.\n                      '-' return first line in list with \"delete\" markup around\n                          the entire line.\n                      '?' return first line in list with add/delete/change\n                          intraline markup (indices obtained from second line)\n                      None return first line in list with no markup\n        side -- indice into the num_lines list (0=from,1=to)\n        num_lines -- from/to current line number.  This is NOT intended to be a\n                     passed parameter.  It is present as a keyword argument to\n                     maintain memory of the current line numbers between calls\n                     of this function.\n\n        Note, this function is purposefully not defined at the module scope so\n        that data it needs from its parent function (within whose context it\n        is defined) does not need to be of module scope.\n        \"\"\"\n        num_lines[side] += 1\n        # Handle case where no user markup is to be added, just return line of\n        # text with user's line format to allow for usage of the line number.\n        if format_key is None:\n            return (num_lines[side],lines.pop(0)[2:])\n        # Handle case of intraline changes\n        if format_key == '?':\n            text, markers = lines.pop(0), lines.pop(0)\n            # find intraline changes (store change type and indices in tuples)\n            sub_info = []\n            def record_sub_info(match_object,sub_info=sub_info):\n                sub_info.append([match_object.group(1)[0],match_object.span()])\n                return match_object.group(1)\n            change_re.sub(record_sub_info,markers)\n            # process each tuple inserting our special marks that won't be\n            # noticed by an xml/html escaper.\n            for key,(begin,end) in sub_info[::-1]:\n                text = text[0:begin]+'\\0'+key+text[begin:end]+'\\1'+text[end:]\n            text = text[2:]\n        # Handle case of add/delete entire line\n        else:\n            text = lines.pop(0)[2:]\n            # if line of text is just a newline, insert a space so there is\n            # something for the user to highlight and see.\n            if not text:\n                text = ' '\n            # insert marks that won't be noticed by an xml/html escaper.\n            text = '\\0' + format_key + text + '\\1'\n        # Return line of text, first allow user's line formatter to do its\n        # thing (such as adding the line number) then replace the special\n        # marks with what the user's change markup.\n        return (num_lines[side],text)\n\n    def _line_iterator():\n        \"\"\"Yields from/to lines of text with a change indication.\n\n        This function is an iterator.  It itself pulls lines from a\n        differencing iterator, processes them and yields them.  When it can\n        it yields both a \"from\" and a \"to\" line, otherwise it will yield one\n        or the other.  In addition to yielding the lines of from/to text, a\n        boolean flag is yielded to indicate if the text line(s) have\n        differences in them.\n\n        Note, this function is purposefully not defined at the module scope so\n        that data it needs from its parent function (within whose context it\n        is defined) does not need to be of module scope.\n        \"\"\"\n        lines = []\n        num_blanks_pending, num_blanks_to_yield = 0, 0\n        while True:\n            # Load up next 4 lines so we can look ahead, create strings which\n            # are a concatenation of the first character of each of the 4 lines\n            # so we can do some very readable comparisons.\n            while len(lines) < 4:\n                try:\n                    lines.append(next(diff_lines_iterator))\n                except StopIteration:\n                    lines.append('X')\n            s = ''.join([line[0] for line in lines])\n            if s.startswith('X'):\n                # When no more lines, pump out any remaining blank lines so the\n                # corresponding add/delete lines get a matching blank line so\n                # all line pairs get yielded at the next level.\n                num_blanks_to_yield = num_blanks_pending\n            elif s.startswith('-?+?'):\n                # simple intraline change\n                yield _make_line(lines,'?',0), _make_line(lines,'?',1), True\n                continue\n            elif s.startswith('--++'):\n                # in delete block, add block coming: we do NOT want to get\n                # caught up on blank lines yet, just process the delete line\n                num_blanks_pending -= 1\n                yield _make_line(lines,'-',0), None, True\n                continue\n            elif s.startswith(('--?+', '--+', '- ')):\n                # in delete block and see a intraline change or unchanged line\n                # coming: yield the delete line and then blanks\n                from_line,to_line = _make_line(lines,'-',0), None\n                num_blanks_to_yield,num_blanks_pending = num_blanks_pending-1,0\n            elif s.startswith('-+?'):\n                # intraline change\n                yield _make_line(lines,None,0), _make_line(lines,'?',1), True\n                continue\n            elif s.startswith('-?+'):\n                # intraline change\n                yield _make_line(lines,'?',0), _make_line(lines,None,1), True\n                continue\n            elif s.startswith('-'):\n                # delete FROM line\n                num_blanks_pending -= 1\n                yield _make_line(lines,'-',0), None, True\n                continue\n            elif s.startswith('+--'):\n                # in add block, delete block coming: we do NOT want to get\n                # caught up on blank lines yet, just process the add line\n                num_blanks_pending += 1\n                yield None, _make_line(lines,'+',1), True\n                continue\n            elif s.startswith(('+ ', '+-')):\n                # will be leaving an add block: yield blanks then add line\n                from_line, to_line = None, _make_line(lines,'+',1)\n                num_blanks_to_yield,num_blanks_pending = num_blanks_pending+1,0\n            elif s.startswith('+'):\n                # inside an add block, yield the add line\n                num_blanks_pending += 1\n                yield None, _make_line(lines,'+',1), True\n                continue\n            elif s.startswith(' '):\n                # unchanged text, yield it to both sides\n                yield _make_line(lines[:],None,0),_make_line(lines,None,1),False\n                continue\n            # Catch up on the blank lines so when we yield the next from/to\n            # pair, they are lined up.\n            while(num_blanks_to_yield < 0):\n                num_blanks_to_yield += 1\n                yield None,('','\\n'),True\n            while(num_blanks_to_yield > 0):\n                num_blanks_to_yield -= 1\n                yield ('','\\n'),None,True\n            if s.startswith('X'):\n                raise StopIteration\n            else:\n                yield from_line,to_line,True\n\n    def _line_pair_iterator():\n        \"\"\"Yields from/to lines of text with a change indication.\n\n        This function is an iterator.  It itself pulls lines from the line\n        iterator.  Its difference from that iterator is that this function\n        always yields a pair of from/to text lines (with the change\n        indication).  If necessary it will collect single from/to lines\n        until it has a matching pair from/to pair to yield.\n\n        Note, this function is purposefully not defined at the module scope so\n        that data it needs from its parent function (within whose context it\n        is defined) does not need to be of module scope.\n        \"\"\"\n        line_iterator = _line_iterator()\n        fromlines,tolines=[],[]\n        while True:\n            # Collecting lines of text until we have a from/to pair\n            while (len(fromlines)==0 or len(tolines)==0):\n                from_line, to_line, found_diff = next(line_iterator)\n                if from_line is not None:\n                    fromlines.append((from_line,found_diff))\n                if to_line is not None:\n                    tolines.append((to_line,found_diff))\n            # Once we have a pair, remove them from the collection and yield it\n            from_line, fromDiff = fromlines.pop(0)\n            to_line, to_diff = tolines.pop(0)\n            yield (from_line,to_line,fromDiff or to_diff)\n\n    # Handle case where user does not want context differencing, just yield\n    # them up without doing anything else with them.\n    line_pair_iterator = _line_pair_iterator()\n    if context is None:\n        while True:\n            yield next(line_pair_iterator)\n    # Handle case where user wants context differencing.  We must do some\n    # storage of lines until we know for sure that they are to be yielded.\n    else:\n        context += 1\n        lines_to_write = 0\n        while True:\n            # Store lines up until we find a difference, note use of a\n            # circular queue because we only need to keep around what\n            # we need for context.\n            index, contextLines = 0, [None]*(context)\n            found_diff = False\n            while(found_diff is False):\n                from_line, to_line, found_diff = next(line_pair_iterator)\n                i = index % context\n                contextLines[i] = (from_line, to_line, found_diff)\n                index += 1\n            # Yield lines that we have collected so far, but first yield\n            # the user's separator.\n            if index > context:\n                yield None, None, None\n                lines_to_write = context\n            else:\n                lines_to_write = index\n                index = 0\n            while(lines_to_write):\n                i = index % context\n                index += 1\n                yield contextLines[i]\n                lines_to_write -= 1\n            # Now yield the context lines after the change\n            lines_to_write = context-1\n            while(lines_to_write):\n                from_line, to_line, found_diff = next(line_pair_iterator)\n                # If another change within the context, extend the context\n                if found_diff:\n                    lines_to_write = context-1\n                else:\n                    lines_to_write -= 1\n                yield from_line, to_line, found_diff\n\n\n_file_template = \"\"\"\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n          \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n\n<html>\n\n<head>\n    <meta http-equiv=\"Content-Type\"\n          content=\"text/html; charset=ISO-8859-1\" />\n    <title></title>\n    <style type=\"text/css\">%(styles)s\n    </style>\n</head>\n\n<body>\n    %(table)s%(legend)s\n</body>\n\n</html>\"\"\"\n\n_styles = \"\"\"\n        table.diff {font-family:Courier; border:medium;}\n        .diff_header {background-color:#e0e0e0}\n        td.diff_header {text-align:right}\n        .diff_next {background-color:#c0c0c0}\n        .diff_add {background-color:#aaffaa}\n        .diff_chg {background-color:#ffff77}\n        .diff_sub {background-color:#ffaaaa}\"\"\"\n\n_table_template = \"\"\"\n    <table class=\"diff\" id=\"difflib_chg_%(prefix)s_top\"\n           cellspacing=\"0\" cellpadding=\"0\" rules=\"groups\" >\n        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n        %(header_row)s\n        <tbody>\n%(data_rows)s        </tbody>\n    </table>\"\"\"\n\n_legend = \"\"\"\n    <table class=\"diff\" summary=\"Legends\">\n        <tr> <th colspan=\"2\"> Legends </th> </tr>\n        <tr> <td> <table border=\"\" summary=\"Colors\">\n                      <tr><th> Colors </th> </tr>\n                      <tr><td class=\"diff_add\">&nbsp;Added&nbsp;</td></tr>\n                      <tr><td class=\"diff_chg\">Changed</td> </tr>\n                      <tr><td class=\"diff_sub\">Deleted</td> </tr>\n                  </table></td>\n             <td> <table border=\"\" summary=\"Links\">\n                      <tr><th colspan=\"2\"> Links </th> </tr>\n                      <tr><td>(f)irst change</td> </tr>\n                      <tr><td>(n)ext change</td> </tr>\n                      <tr><td>(t)op</td> </tr>\n                  </table></td> </tr>\n    </table>\"\"\"\n\nclass HtmlDiff(object):\n    \"\"\"For producing HTML side by side comparison with change highlights.\n\n    This class can be used to create an HTML table (or a complete HTML file\n    containing the table) showing a side by side, line by line comparison\n    of text with inter-line and intra-line change highlights.  The table can\n    be generated in either full or contextual difference mode.\n\n    The following methods are provided for HTML generation:\n\n    make_table -- generates HTML for a single side by side table\n    make_file -- generates complete HTML file with a single side by side table\n\n    See tools/scripts/diff.py for an example usage of this class.\n    \"\"\"\n\n    _file_template = _file_template\n    _styles = _styles\n    _table_template = _table_template\n    _legend = _legend\n    _default_prefix = 0\n\n    def __init__(self,tabsize=8,wrapcolumn=None,linejunk=None,\n                 charjunk=IS_CHARACTER_JUNK):\n        \"\"\"HtmlDiff instance initializer\n\n        Arguments:\n        tabsize -- tab stop spacing, defaults to 8.\n        wrapcolumn -- column number where lines are broken and wrapped,\n            defaults to None where lines are not wrapped.\n        linejunk,charjunk -- keyword arguments passed into ndiff() (used to by\n            HtmlDiff() to generate the side by side HTML differences).  See\n            ndiff() documentation for argument default values and descriptions.\n        \"\"\"\n        self._tabsize = tabsize\n        self._wrapcolumn = wrapcolumn\n        self._linejunk = linejunk\n        self._charjunk = charjunk\n\n    def make_file(self,fromlines,tolines,fromdesc='',todesc='',context=False,\n                  numlines=5):\n        \"\"\"Returns HTML file of side by side comparison with change highlights\n\n        Arguments:\n        fromlines -- list of \"from\" lines\n        tolines -- list of \"to\" lines\n        fromdesc -- \"from\" file column header string\n        todesc -- \"to\" file column header string\n        context -- set to True for contextual differences (defaults to False\n            which shows full differences).\n        numlines -- number of context lines.  When context is set True,\n            controls number of lines displayed before and after the change.\n            When context is False, controls the number of lines to place\n            the \"next\" link anchors before the next change (so click of\n            \"next\" link jumps to just before the change).\n        \"\"\"\n\n        return self._file_template % dict(\n            styles = self._styles,\n            legend = self._legend,\n            table = self.make_table(fromlines,tolines,fromdesc,todesc,\n                                    context=context,numlines=numlines))\n\n    def _tab_newline_replace(self,fromlines,tolines):\n        \"\"\"Returns from/to line lists with tabs expanded and newlines removed.\n\n        Instead of tab characters being replaced by the number of spaces\n        needed to fill in to the next tab stop, this function will fill\n        the space with tab characters.  This is done so that the difference\n        algorithms can identify changes in a file when tabs are replaced by\n        spaces and vice versa.  At the end of the HTML generation, the tab\n        characters will be replaced with a nonbreakable space.\n        \"\"\"\n        def expand_tabs(line):\n            # hide real spaces\n            line = line.replace(' ','\\0')\n            # expand tabs into spaces\n            line = line.expandtabs(self._tabsize)\n            # replace spaces from expanded tabs back into tab characters\n            # (we'll replace them with markup after we do differencing)\n            line = line.replace(' ','\\t')\n            return line.replace('\\0',' ').rstrip('\\n')\n        fromlines = [expand_tabs(line) for line in fromlines]\n        tolines = [expand_tabs(line) for line in tolines]\n        return fromlines,tolines\n\n    def _split_line(self,data_list,line_num,text):\n        \"\"\"Builds list of text lines by splitting text lines at wrap point\n\n        This function will determine if the input text line needs to be\n        wrapped (split) into separate lines.  If so, the first wrap point\n        will be determined and the first line appended to the output\n        text line list.  This function is used recursively to handle\n        the second part of the split line to further split it.\n        \"\"\"\n        # if blank line or context separator, just add it to the output list\n        if not line_num:\n            data_list.append((line_num,text))\n            return\n\n        # if line text doesn't need wrapping, just add it to the output list\n        size = len(text)\n        max = self._wrapcolumn\n        if (size <= max) or ((size -(text.count('\\0')*3)) <= max):\n            data_list.append((line_num,text))\n            return\n\n        # scan text looking for the wrap point, keeping track if the wrap\n        # point is inside markers\n        i = 0\n        n = 0\n        mark = ''\n        while n < max and i < size:\n            if text[i] == '\\0':\n                i += 1\n                mark = text[i]\n                i += 1\n            elif text[i] == '\\1':\n                i += 1\n                mark = ''\n            else:\n                i += 1\n                n += 1\n\n        # wrap point is inside text, break it up into separate lines\n        line1 = text[:i]\n        line2 = text[i:]\n\n        # if wrap point is inside markers, place end marker at end of first\n        # line and start marker at beginning of second line because each\n        # line will have its own table tag markup around it.\n        if mark:\n            line1 = line1 + '\\1'\n            line2 = '\\0' + mark + line2\n\n        # tack on first line onto the output list\n        data_list.append((line_num,line1))\n\n        # use this routine again to wrap the remaining text\n        self._split_line(data_list,'>',line2)\n\n    def _line_wrapper(self,diffs):\n        \"\"\"Returns iterator that splits (wraps) mdiff text lines\"\"\"\n\n        # pull from/to data and flags from mdiff iterator\n        for fromdata,todata,flag in diffs:\n            # check for context separators and pass them through\n            if flag is None:\n                yield fromdata,todata,flag\n                continue\n            (fromline,fromtext),(toline,totext) = fromdata,todata\n            # for each from/to line split it at the wrap column to form\n            # list of text lines.\n            fromlist,tolist = [],[]\n            self._split_line(fromlist,fromline,fromtext)\n            self._split_line(tolist,toline,totext)\n            # yield from/to line in pairs inserting blank lines as\n            # necessary when one side has more wrapped lines\n            while fromlist or tolist:\n                if fromlist:\n                    fromdata = fromlist.pop(0)\n                else:\n                    fromdata = ('',' ')\n                if tolist:\n                    todata = tolist.pop(0)\n                else:\n                    todata = ('',' ')\n                yield fromdata,todata,flag\n\n    def _collect_lines(self,diffs):\n        \"\"\"Collects mdiff output into separate lists\n\n        Before storing the mdiff from/to data into a list, it is converted\n        into a single line of text with HTML markup.\n        \"\"\"\n\n        fromlist,tolist,flaglist = [],[],[]\n        # pull from/to data and flags from mdiff style iterator\n        for fromdata,todata,flag in diffs:\n            try:\n                # store HTML markup of the lines into the lists\n                fromlist.append(self._format_line(0,flag,*fromdata))\n                tolist.append(self._format_line(1,flag,*todata))\n            except TypeError:\n                # exceptions occur for lines where context separators go\n                fromlist.append(None)\n                tolist.append(None)\n            flaglist.append(flag)\n        return fromlist,tolist,flaglist\n\n    def _format_line(self,side,flag,linenum,text):\n        \"\"\"Returns HTML markup of \"from\" / \"to\" text lines\n\n        side -- 0 or 1 indicating \"from\" or \"to\" text\n        flag -- indicates if difference on line\n        linenum -- line number (used for line number column)\n        text -- line text to be marked up\n        \"\"\"\n        try:\n            linenum = '%d' % linenum\n            id = ' id=\"%s%s\"' % (self._prefix[side],linenum)\n        except TypeError:\n            # handle blank lines where linenum is '>' or ''\n            id = ''\n        # replace those things that would get confused with HTML symbols\n        text=text.replace(\"&\",\"&amp;\").replace(\">\",\"&gt;\").replace(\"<\",\"&lt;\")\n\n        # make space non-breakable so they don't get compressed or line wrapped\n        text = text.replace(' ','&nbsp;').rstrip()\n\n        return '<td class=\"diff_header\"%s>%s</td><td nowrap=\"nowrap\">%s</td>' \\\n               % (id,linenum,text)\n\n    def _make_prefix(self):\n        \"\"\"Create unique anchor prefixes\"\"\"\n\n        # Generate a unique anchor prefix so multiple tables\n        # can exist on the same HTML page without conflicts.\n        fromprefix = \"from%d_\" % HtmlDiff._default_prefix\n        toprefix = \"to%d_\" % HtmlDiff._default_prefix\n        HtmlDiff._default_prefix += 1\n        # store prefixes so line format method has access\n        self._prefix = [fromprefix,toprefix]\n\n    def _convert_flags(self,fromlist,tolist,flaglist,context,numlines):\n        \"\"\"Makes list of \"next\" links\"\"\"\n\n        # all anchor names will be generated using the unique \"to\" prefix\n        toprefix = self._prefix[1]\n\n        # process change flags, generating middle column of next anchors/links\n        next_id = ['']*len(flaglist)\n        next_href = ['']*len(flaglist)\n        num_chg, in_change = 0, False\n        last = 0\n        for i,flag in enumerate(flaglist):\n            if flag:\n                if not in_change:\n                    in_change = True\n                    last = i\n                    # at the beginning of a change, drop an anchor a few lines\n                    # (the context lines) before the change for the previous\n                    # link\n                    i = max([0,i-numlines])\n                    next_id[i] = ' id=\"difflib_chg_%s_%d\"' % (toprefix,num_chg)\n                    # at the beginning of a change, drop a link to the next\n                    # change\n                    num_chg += 1\n                    next_href[last] = '<a href=\"#difflib_chg_%s_%d\">n</a>' % (\n                         toprefix,num_chg)\n            else:\n                in_change = False\n        # check for cases where there is no content to avoid exceptions\n        if not flaglist:\n            flaglist = [False]\n            next_id = ['']\n            next_href = ['']\n            last = 0\n            if context:\n                fromlist = ['<td></td><td>&nbsp;No Differences Found&nbsp;</td>']\n                tolist = fromlist\n            else:\n                fromlist = tolist = ['<td></td><td>&nbsp;Empty File&nbsp;</td>']\n        # if not a change on first line, drop a link\n        if not flaglist[0]:\n            next_href[0] = '<a href=\"#difflib_chg_%s_0\">f</a>' % toprefix\n        # redo the last link to link to the top\n        next_href[last] = '<a href=\"#difflib_chg_%s_top\">t</a>' % (toprefix)\n\n        return fromlist,tolist,flaglist,next_href,next_id\n\n    def make_table(self,fromlines,tolines,fromdesc='',todesc='',context=False,\n                   numlines=5):\n        \"\"\"Returns HTML table of side by side comparison with change highlights\n\n        Arguments:\n        fromlines -- list of \"from\" lines\n        tolines -- list of \"to\" lines\n        fromdesc -- \"from\" file column header string\n        todesc -- \"to\" file column header string\n        context -- set to True for contextual differences (defaults to False\n            which shows full differences).\n        numlines -- number of context lines.  When context is set True,\n            controls number of lines displayed before and after the change.\n            When context is False, controls the number of lines to place\n            the \"next\" link anchors before the next change (so click of\n            \"next\" link jumps to just before the change).\n        \"\"\"\n\n        # make unique anchor prefixes so that multiple tables may exist\n        # on the same page without conflict.\n        self._make_prefix()\n\n        # change tabs to spaces before it gets more difficult after we insert\n        # markup\n        fromlines,tolines = self._tab_newline_replace(fromlines,tolines)\n\n        # create diffs iterator which generates side by side from/to data\n        if context:\n            context_lines = numlines\n        else:\n            context_lines = None\n        diffs = _mdiff(fromlines,tolines,context_lines,linejunk=self._linejunk,\n                      charjunk=self._charjunk)\n\n        # set up iterator to wrap lines that exceed desired width\n        if self._wrapcolumn:\n            diffs = self._line_wrapper(diffs)\n\n        # collect up from/to lines and flags into lists (also format the lines)\n        fromlist,tolist,flaglist = self._collect_lines(diffs)\n\n        # process change flags, generating middle column of next anchors/links\n        fromlist,tolist,flaglist,next_href,next_id = self._convert_flags(\n            fromlist,tolist,flaglist,context,numlines)\n\n        s = []\n        fmt = '            <tr><td class=\"diff_next\"%s>%s</td>%s' + \\\n              '<td class=\"diff_next\">%s</td>%s</tr>\\n'\n        for i in range(len(flaglist)):\n            if flaglist[i] is None:\n                # mdiff yields None on separator lines skip the bogus ones\n                # generated for the first line\n                if i > 0:\n                    s.append('        </tbody>        \\n        <tbody>\\n')\n            else:\n                s.append( fmt % (next_id[i],next_href[i],fromlist[i],\n                                           next_href[i],tolist[i]))\n        if fromdesc or todesc:\n            header_row = '<thead><tr>%s%s%s%s</tr></thead>' % (\n                '<th class=\"diff_next\"><br /></th>',\n                '<th colspan=\"2\" class=\"diff_header\">%s</th>' % fromdesc,\n                '<th class=\"diff_next\"><br /></th>',\n                '<th colspan=\"2\" class=\"diff_header\">%s</th>' % todesc)\n        else:\n            header_row = ''\n\n        table = self._table_template % dict(\n            data_rows=''.join(s),\n            header_row=header_row,\n            prefix=self._prefix[1])\n\n        return table.replace('\\0+','<span class=\"diff_add\">'). \\\n                     replace('\\0-','<span class=\"diff_sub\">'). \\\n                     replace('\\0^','<span class=\"diff_chg\">'). \\\n                     replace('\\1','</span>'). \\\n                     replace('\\t','&nbsp;')\n\ndel re\n\ndef restore(delta, which):\n    r\"\"\"\n    Generate one of the two sequences that generated a delta.\n\n    Given a `delta` produced by `Differ.compare()` or `ndiff()`, extract\n    lines originating from file 1 or 2 (parameter `which`), stripping off line\n    prefixes.\n\n    Examples:\n\n    >>> diff = ndiff('one\\ntwo\\nthree\\n'.splitlines(keepends=True),\n    ...              'ore\\ntree\\nemu\\n'.splitlines(keepends=True))\n    >>> diff = list(diff)\n    >>> print(''.join(restore(diff, 1)), end=\"\")\n    one\n    two\n    three\n    >>> print(''.join(restore(diff, 2)), end=\"\")\n    ore\n    tree\n    emu\n    \"\"\"\n    try:\n        tag = {1: \"- \", 2: \"+ \"}[int(which)]\n    except KeyError:\n        raise ValueError('unknown delta choice (must be 1 or 2): %r'\n                           % which)\n    prefixes = (\"  \", tag)\n    for line in delta:\n        if line[:2] in prefixes:\n            yield line[2:]\n\ndef _test():\n    import doctest, difflib\n    return doctest.testmod(difflib)\n\nif __name__ == \"__main__\":\n    _test()\n"], "_io": [".py", "\"\"\"\nPython implementation of the io module.\n\"\"\"\n\nimport os\nimport abc\nimport codecs\nimport errno\n# Import _thread instead of threading to reduce startup cost\ntry:\n    from _thread import allocate_lock as Lock\nexcept ImportError:\n    from _dummy_thread import allocate_lock as Lock\n\nimport io\n#brython fix me\n#from io import (__all__, SEEK_SET, SEEK_CUR, SEEK_END)\nSEEK_SET=0\nSEEK_CUR=1\nSEEK_END=2\n\nvalid_seek_flags = {0, 1, 2}  # Hardwired values\nif hasattr(os, 'SEEK_HOLE') :\n    valid_seek_flags.add(os.SEEK_HOLE)\n    valid_seek_flags.add(os.SEEK_DATA)\n\n# open() uses st_blksize whenever we can\nDEFAULT_BUFFER_SIZE = 8 * 1024  # bytes\n\n# NOTE: Base classes defined here are registered with the \"official\" ABCs\n# defined in io.py. We don't use real inheritance though, because we don't\n# want to inherit the C implementations.\n\n# Rebind for compatibility\nBlockingIOError = BlockingIOError\n\n\ndef __open(file, mode=\"r\", buffering=-1, encoding=None, errors=None,\n         newline=None, closefd=True, opener=None):\n\n    r\"\"\"Open file and return a stream.  Raise IOError upon failure.\n\n    file is either a text or byte string giving the name (and the path\n    if the file isn't in the current working directory) of the file to\n    be opened or an integer file descriptor of the file to be\n    wrapped. (If a file descriptor is given, it is closed when the\n    returned I/O object is closed, unless closefd is set to False.)\n\n    mode is an optional string that specifies the mode in which the file is\n    opened. It defaults to 'r' which means open for reading in text mode. Other\n    common values are 'w' for writing (truncating the file if it already\n    exists), 'x' for exclusive creation of a new file, and 'a' for appending\n    (which on some Unix systems, means that all writes append to the end of the\n    file regardless of the current seek position). In text mode, if encoding is\n    not specified the encoding used is platform dependent. (For reading and\n    writing raw bytes use binary mode and leave encoding unspecified.) The\n    available modes are:\n\n    ========= ===============================================================\n    Character Meaning\n    --------- ---------------------------------------------------------------\n    'r'       open for reading (default)\n    'w'       open for writing, truncating the file first\n    'x'       create a new file and open it for writing\n    'a'       open for writing, appending to the end of the file if it exists\n    'b'       binary mode\n    't'       text mode (default)\n    '+'       open a disk file for updating (reading and writing)\n    'U'       universal newline mode (for backwards compatibility; unneeded\n              for new code)\n    ========= ===============================================================\n\n    The default mode is 'rt' (open for reading text). For binary random\n    access, the mode 'w+b' opens and truncates the file to 0 bytes, while\n    'r+b' opens the file without truncation. The 'x' mode implies 'w' and\n    raises an `FileExistsError` if the file already exists.\n\n    Python distinguishes between files opened in binary and text modes,\n    even when the underlying operating system doesn't. Files opened in\n    binary mode (appending 'b' to the mode argument) return contents as\n    bytes objects without any decoding. In text mode (the default, or when\n    't' is appended to the mode argument), the contents of the file are\n    returned as strings, the bytes having been first decoded using a\n    platform-dependent encoding or using the specified encoding if given.\n\n    buffering is an optional integer used to set the buffering policy.\n    Pass 0 to switch buffering off (only allowed in binary mode), 1 to select\n    line buffering (only usable in text mode), and an integer > 1 to indicate\n    the size of a fixed-size chunk buffer.  When no buffering argument is\n    given, the default buffering policy works as follows:\n\n    * Binary files are buffered in fixed-size chunks; the size of the buffer\n      is chosen using a heuristic trying to determine the underlying device's\n      \"block size\" and falling back on `io.DEFAULT_BUFFER_SIZE`.\n      On many systems, the buffer will typically be 4096 or 8192 bytes long.\n\n    * \"Interactive\" text files (files for which isatty() returns True)\n      use line buffering.  Other text files use the policy described above\n      for binary files.\n\n    encoding is the str name of the encoding used to decode or encode the\n    file. This should only be used in text mode. The default encoding is\n    platform dependent, but any encoding supported by Python can be\n    passed.  See the codecs module for the list of supported encodings.\n\n    errors is an optional string that specifies how encoding errors are to\n    be handled---this argument should not be used in binary mode. Pass\n    'strict' to raise a ValueError exception if there is an encoding error\n    (the default of None has the same effect), or pass 'ignore' to ignore\n    errors. (Note that ignoring encoding errors can lead to data loss.)\n    See the documentation for codecs.register for a list of the permitted\n    encoding error strings.\n\n    newline is a string controlling how universal newlines works (it only\n    applies to text mode). It can be None, '', '\\n', '\\r', and '\\r\\n'.  It works\n    as follows:\n\n    * On input, if newline is None, universal newlines mode is\n      enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n      these are translated into '\\n' before being returned to the\n      caller. If it is '', universal newline mode is enabled, but line\n      endings are returned to the caller untranslated. If it has any of\n      the other legal values, input lines are only terminated by the given\n      string, and the line ending is returned to the caller untranslated.\n\n    * On output, if newline is None, any '\\n' characters written are\n      translated to the system default line separator, os.linesep. If\n      newline is '', no translation takes place. If newline is any of the\n      other legal values, any '\\n' characters written are translated to\n      the given string.\n\n    closedfd is a bool. If closefd is False, the underlying file descriptor will\n    be kept open when the file is closed. This does not work when a file name is\n    given and must be True in that case.\n\n    A custom opener can be used by passing a callable as *opener*. The\n    underlying file descriptor for the file object is then obtained by calling\n    *opener* with (*file*, *flags*). *opener* must return an open file\n    descriptor (passing os.open as *opener* results in functionality similar to\n    passing None).\n\n    open() returns a file object whose type depends on the mode, and\n    through which the standard file operations such as reading and writing\n    are performed. When open() is used to open a file in a text mode ('w',\n    'r', 'wt', 'rt', etc.), it returns a TextIOWrapper. When used to open\n    a file in a binary mode, the returned class varies: in read binary\n    mode, it returns a BufferedReader; in write binary and append binary\n    modes, it returns a BufferedWriter, and in read/write mode, it returns\n    a BufferedRandom.\n\n    It is also possible to use a string or bytearray as a file for both\n    reading and writing. For strings StringIO can be used like a file\n    opened in a text mode, and for bytes a BytesIO can be used like a file\n    opened in a binary mode.\n    \"\"\"\n    if not isinstance(file, (str, bytes, int)):\n        raise TypeError(\"invalid file: %r\" % file)\n    if not isinstance(mode, str):\n        raise TypeError(\"invalid mode: %r\" % mode)\n    if not isinstance(buffering, int):\n        raise TypeError(\"invalid buffering: %r\" % buffering)\n    if encoding is not None and not isinstance(encoding, str):\n        raise TypeError(\"invalid encoding: %r\" % encoding)\n    if errors is not None and not isinstance(errors, str):\n        raise TypeError(\"invalid errors: %r\" % errors)\n    modes = set(mode)\n    if modes - set(\"axrwb+tU\") or len(mode) > len(modes):\n        raise ValueError(\"invalid mode: %r\" % mode)\n    creating = \"x\" in modes\n    reading = \"r\" in modes\n    writing = \"w\" in modes\n    appending = \"a\" in modes\n    updating = \"+\" in modes\n    text = \"t\" in modes\n    binary = \"b\" in modes\n    if \"U\" in modes:\n        if creating or writing or appending:\n            raise ValueError(\"can't use U and writing mode at once\")\n        reading = True\n    if text and binary:\n        raise ValueError(\"can't have text and binary mode at once\")\n    if creating + reading + writing + appending > 1:\n        raise ValueError(\"can't have read/write/append mode at once\")\n    if not (creating or reading or writing or appending):\n        raise ValueError(\"must have exactly one of read/write/append mode\")\n    if binary and encoding is not None:\n        raise ValueError(\"binary mode doesn't take an encoding argument\")\n    if binary and errors is not None:\n        raise ValueError(\"binary mode doesn't take an errors argument\")\n    if binary and newline is not None:\n        raise ValueError(\"binary mode doesn't take a newline argument\")\n    raw = FileIO(file,\n                 (creating and \"x\" or \"\") +\n                 (reading and \"r\" or \"\") +\n                 (writing and \"w\" or \"\") +\n                 (appending and \"a\" or \"\") +\n                 (updating and \"+\" or \"\"),\n                 closefd, opener=opener)\n    line_buffering = False\n    if buffering == 1 or buffering < 0 and raw.isatty():\n        buffering = -1\n        line_buffering = True\n    if buffering < 0:\n        buffering = DEFAULT_BUFFER_SIZE\n        try:\n            bs = os.fstat(raw.fileno()).st_blksize\n        except (os.error, AttributeError):\n            pass\n        else:\n            if bs > 1:\n                buffering = bs\n    if buffering < 0:\n        raise ValueError(\"invalid buffering size\")\n    if buffering == 0:\n        if binary:\n            return raw\n        raise ValueError(\"can't have unbuffered text I/O\")\n    if updating:\n        buffer = BufferedRandom(raw, buffering)\n    elif creating or writing or appending:\n        buffer = BufferedWriter(raw, buffering)\n    elif reading:\n        buffer = BufferedReader(raw, buffering)\n    else:\n        raise ValueError(\"unknown mode: %r\" % mode)\n    if binary:\n        return buffer\n    text = TextIOWrapper(buffer, encoding, errors, newline, line_buffering)\n    text.mode = mode\n    return text\n\n\nclass DocDescriptor:\n    \"\"\"Helper for builtins.open.__doc__\n    \"\"\"\n    def __get__(self, obj, typ):\n        return (\n            \"open(file, mode='r', buffering=-1, encoding=None, \"\n                 \"errors=None, newline=None, closefd=True)\\n\\n\" +\n            open.__doc__)\n\nclass OpenWrapper:\n    \"\"\"Wrapper for builtins.open\n\n    Trick so that open won't become a bound method when stored\n    as a class variable (as dbm.dumb does).\n\n    See initstdio() in Python/pythonrun.c.\n    \"\"\"\n    __doc__ = DocDescriptor()\n\n    def __new__(cls, *args, **kwargs):\n        return open(*args, **kwargs)\n\n\n# In normal operation, both `UnsupportedOperation`s should be bound to the\n# same object.\ntry:\n    UnsupportedOperation = io.UnsupportedOperation\nexcept AttributeError:\n    class UnsupportedOperation(ValueError, IOError):\n        pass\n\n\nclass IOBase(metaclass=abc.ABCMeta):\n\n    \"\"\"The abstract base class for all I/O classes, acting on streams of\n    bytes. There is no public constructor.\n\n    This class provides dummy implementations for many methods that\n    derived classes can override selectively; the default implementations\n    represent a file that cannot be read, written or seeked.\n\n    Even though IOBase does not declare read, readinto, or write because\n    their signatures will vary, implementations and clients should\n    consider those methods part of the interface. Also, implementations\n    may raise UnsupportedOperation when operations they do not support are\n    called.\n\n    The basic type used for binary data read from or written to a file is\n    bytes. bytearrays are accepted too, and in some cases (such as\n    readinto) needed. Text I/O classes work with str data.\n\n    Note that calling any method (even inquiries) on a closed stream is\n    undefined. Implementations may raise IOError in this case.\n\n    IOBase (and its subclasses) support the iterator protocol, meaning\n    that an IOBase object can be iterated over yielding the lines in a\n    stream.\n\n    IOBase also supports the :keyword:`with` statement. In this example,\n    fp is closed after the suite of the with statement is complete:\n\n    with open('spam.txt', 'r') as fp:\n        fp.write('Spam and eggs!')\n    \"\"\"\n\n    ### Internal ###\n\n    def _unsupported(self, name):\n        \"\"\"Internal: raise an IOError exception for unsupported operations.\"\"\"\n        raise UnsupportedOperation(\"%s.%s() not supported\" %\n                                   (self.__class__.__name__, name))\n\n    ### Positioning ###\n\n    def seek(self, pos, whence=0):\n        \"\"\"Change stream position.\n\n        Change the stream position to byte offset pos. Argument pos is\n        interpreted relative to the position indicated by whence.  Values\n        for whence are ints:\n\n        * 0 -- start of stream (the default); offset should be zero or positive\n        * 1 -- current stream position; offset may be negative\n        * 2 -- end of stream; offset is usually negative\n        Some operating systems / file systems could provide additional values.\n\n        Return an int indicating the new absolute position.\n        \"\"\"\n        self._unsupported(\"seek\")\n\n    def tell(self):\n        \"\"\"Return an int indicating the current stream position.\"\"\"\n        return self.seek(0, 1)\n\n    def truncate(self, pos=None):\n        \"\"\"Truncate file to size bytes.\n\n        Size defaults to the current IO position as reported by tell().  Return\n        the new size.\n        \"\"\"\n        self._unsupported(\"truncate\")\n\n    ### Flush and close ###\n\n    def flush(self):\n        \"\"\"Flush write buffers, if applicable.\n\n        This is not implemented for read-only and non-blocking streams.\n        \"\"\"\n        self._checkClosed()\n        # XXX Should this return the number of bytes written???\n\n    __closed = False\n\n    def close(self):\n        \"\"\"Flush and close the IO object.\n\n        This method has no effect if the file is already closed.\n        \"\"\"\n        if not self.__closed:\n            try:\n                self.flush()\n            finally:\n                self.__closed = True\n\n    def __del__(self):\n        \"\"\"Destructor.  Calls close().\"\"\"\n        # The try/except block is in case this is called at program\n        # exit time, when it's possible that globals have already been\n        # deleted, and then the close() call might fail.  Since\n        # there's nothing we can do about such failures and they annoy\n        # the end users, we suppress the traceback.\n        try:\n            self.close()\n        except:\n            pass\n\n    ### Inquiries ###\n\n    def seekable(self):\n        \"\"\"Return a bool indicating whether object supports random access.\n\n        If False, seek(), tell() and truncate() will raise UnsupportedOperation.\n        This method may need to do a test seek().\n        \"\"\"\n        return False\n\n    def _checkSeekable(self, msg=None):\n        \"\"\"Internal: raise UnsupportedOperation if file is not seekable\n        \"\"\"\n        if not self.seekable():\n            raise UnsupportedOperation(\"File or stream is not seekable.\"\n                                       if msg is None else msg)\n\n    def readable(self):\n        \"\"\"Return a bool indicating whether object was opened for reading.\n\n        If False, read() will raise UnsupportedOperation.\n        \"\"\"\n        return False\n\n    def _checkReadable(self, msg=None):\n        \"\"\"Internal: raise UnsupportedOperation if file is not readable\n        \"\"\"\n        if not self.readable():\n            raise UnsupportedOperation(\"File or stream is not readable.\"\n                                       if msg is None else msg)\n\n    def writable(self):\n        \"\"\"Return a bool indicating whether object was opened for writing.\n\n        If False, write() and truncate() will raise UnsupportedOperation.\n        \"\"\"\n        return False\n\n    def _checkWritable(self, msg=None):\n        \"\"\"Internal: raise UnsupportedOperation if file is not writable\n        \"\"\"\n        if not self.writable():\n            raise UnsupportedOperation(\"File or stream is not writable.\"\n                                       if msg is None else msg)\n\n    @property\n    def closed(self):\n        \"\"\"closed: bool.  True iff the file has been closed.\n\n        For backwards compatibility, this is a property, not a predicate.\n        \"\"\"\n        return self.__closed\n\n    def _checkClosed(self, msg=None):\n        \"\"\"Internal: raise an ValueError if file is closed\n        \"\"\"\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file.\"\n                             if msg is None else msg)\n\n    ### Context manager ###\n\n    def __enter__(self):  # That's a forward reference\n        \"\"\"Context management protocol.  Returns self (an instance of IOBase).\"\"\"\n        self._checkClosed()\n        return self\n\n    def __exit__(self, *args):\n        \"\"\"Context management protocol.  Calls close()\"\"\"\n        self.close()\n\n    ### Lower-level APIs ###\n\n    # XXX Should these be present even if unimplemented?\n\n    def fileno(self):\n        \"\"\"Returns underlying file descriptor (an int) if one exists.\n\n        An IOError is raised if the IO object does not use a file descriptor.\n        \"\"\"\n        self._unsupported(\"fileno\")\n\n    def isatty(self):\n        \"\"\"Return a bool indicating whether this is an 'interactive' stream.\n\n        Return False if it can't be determined.\n        \"\"\"\n        self._checkClosed()\n        return False\n\n    ### Readline[s] and writelines ###\n\n    def readline(self, limit=-1):\n        r\"\"\"Read and return a line of bytes from the stream.\n\n        If limit is specified, at most limit bytes will be read.\n        Limit should be an int.\n\n        The line terminator is always b'\\n' for binary files; for text\n        files, the newlines argument to open can be used to select the line\n        terminator(s) recognized.\n        \"\"\"\n        # For backwards compatibility, a (slowish) readline().\n        if hasattr(self, \"peek\"):\n            def nreadahead():\n                readahead = self.peek(1)\n                if not readahead:\n                    return 1\n                n = (readahead.find(b\"\\n\") + 1) or len(readahead)\n                if limit >= 0:\n                    n = min(n, limit)\n                return n\n        else:\n            def nreadahead():\n                return 1\n        if limit is None:\n            limit = -1\n        elif not isinstance(limit, int):\n            raise TypeError(\"limit must be an integer\")\n        res = bytearray()\n        while limit < 0 or len(res) < limit:\n            b = self.read(nreadahead())\n            if not b:\n                break\n            res += b\n            if res.endswith(b\"\\n\"):\n                break\n        return bytes(res)\n\n    def __iter__(self):\n        self._checkClosed()\n        return self\n\n    def __next__(self):\n        line = self.readline()\n        if not line:\n            raise StopIteration\n        return line\n\n    def readlines(self, hint=None):\n        \"\"\"Return a list of lines from the stream.\n\n        hint can be specified to control the number of lines read: no more\n        lines will be read if the total size (in bytes/characters) of all\n        lines so far exceeds hint.\n        \"\"\"\n        if hint is None or hint <= 0:\n            return list(self)\n        n = 0\n        lines = []\n        for line in self:\n            lines.append(line)\n            n += len(line)\n            if n >= hint:\n                break\n        return lines\n\n    def writelines(self, lines):\n        self._checkClosed()\n        for line in lines:\n            self.write(line)\n\n#fix me brython\n#io.IOBase.register(IOBase)\n\n\nclass RawIOBase(IOBase):\n\n    \"\"\"Base class for raw binary I/O.\"\"\"\n\n    # The read() method is implemented by calling readinto(); derived\n    # classes that want to support read() only need to implement\n    # readinto() as a primitive operation.  In general, readinto() can be\n    # more efficient than read().\n\n    # (It would be tempting to also provide an implementation of\n    # readinto() in terms of read(), in case the latter is a more suitable\n    # primitive operation, but that would lead to nasty recursion in case\n    # a subclass doesn't implement either.)\n\n    def read(self, n=-1):\n        \"\"\"Read and return up to n bytes, where n is an int.\n\n        Returns an empty bytes object on EOF, or None if the object is\n        set not to block and has no data to read.\n        \"\"\"\n        if n is None:\n            n = -1\n        if n < 0:\n            return self.readall()\n        b = bytearray(n.__index__())\n        n = self.readinto(b)\n        if n is None:\n            return None\n        del b[n:]\n        return bytes(b)\n\n    def readall(self):\n        \"\"\"Read until EOF, using multiple read() call.\"\"\"\n        res = bytearray()\n        while True:\n            data = self.read(DEFAULT_BUFFER_SIZE)\n            if not data:\n                break\n            res += data\n        if res:\n            return bytes(res)\n        else:\n            # b'' or None\n            return data\n\n    def readinto(self, b):\n        \"\"\"Read up to len(b) bytes into bytearray b.\n\n        Returns an int representing the number of bytes read (0 for EOF), or\n        None if the object is set not to block and has no data to read.\n        \"\"\"\n        self._unsupported(\"readinto\")\n\n    def write(self, b):\n        \"\"\"Write the given buffer to the IO stream.\n\n        Returns the number of bytes written, which may be less than len(b).\n        \"\"\"\n        self._unsupported(\"write\")\n\n#io.RawIOBase.register(RawIOBase)\n#fix me brython\n#from _io import FileIO\n#RawIOBase.register(FileIO)\n\n\nclass BufferedIOBase(IOBase):\n\n    \"\"\"Base class for buffered IO objects.\n\n    The main difference with RawIOBase is that the read() method\n    supports omitting the size argument, and does not have a default\n    implementation that defers to readinto().\n\n    In addition, read(), readinto() and write() may raise\n    BlockingIOError if the underlying raw stream is in non-blocking\n    mode and not ready; unlike their raw counterparts, they will never\n    return None.\n\n    A typical implementation should not inherit from a RawIOBase\n    implementation, but wrap one.\n    \"\"\"\n\n    def read(self, n=None):\n        \"\"\"Read and return up to n bytes, where n is an int.\n\n        If the argument is omitted, None, or negative, reads and\n        returns all data until EOF.\n\n        If the argument is positive, and the underlying raw stream is\n        not 'interactive', multiple raw reads may be issued to satisfy\n        the byte count (unless EOF is reached first).  But for\n        interactive raw streams (XXX and for pipes?), at most one raw\n        read will be issued, and a short result does not imply that\n        EOF is imminent.\n\n        Returns an empty bytes array on EOF.\n\n        Raises BlockingIOError if the underlying raw stream has no\n        data at the moment.\n        \"\"\"\n        self._unsupported(\"read\")\n\n    def read1(self, n=None):\n        \"\"\"Read up to n bytes with at most one read() system call,\n        where n is an int.\n        \"\"\"\n        self._unsupported(\"read1\")\n\n    def readinto(self, b):\n        \"\"\"Read up to len(b) bytes into bytearray b.\n\n        Like read(), this may issue multiple reads to the underlying raw\n        stream, unless the latter is 'interactive'.\n\n        Returns an int representing the number of bytes read (0 for EOF).\n\n        Raises BlockingIOError if the underlying raw stream has no\n        data at the moment.\n        \"\"\"\n        # XXX This ought to work with anything that supports the buffer API\n        data = self.read(len(b))\n        n = len(data)\n        try:\n            b[:n] = data\n        except TypeError as err:\n            import array\n            if not isinstance(b, array.array):\n                raise err\n            b[:n] = array.array('b', data)\n        return n\n\n    def write(self, b):\n        \"\"\"Write the given bytes buffer to the IO stream.\n\n        Return the number of bytes written, which is never less than\n        len(b).\n\n        Raises BlockingIOError if the buffer is full and the\n        underlying raw stream cannot accept more data at the moment.\n        \"\"\"\n        self._unsupported(\"write\")\n\n    def detach(self):\n        \"\"\"\n        Separate the underlying raw stream from the buffer and return it.\n\n        After the raw stream has been detached, the buffer is in an unusable\n        state.\n        \"\"\"\n        self._unsupported(\"detach\")\n\n#fix me brython\n#io.BufferedIOBase.register(BufferedIOBase)\n\n\nclass _BufferedIOMixin(BufferedIOBase):\n\n    \"\"\"A mixin implementation of BufferedIOBase with an underlying raw stream.\n\n    This passes most requests on to the underlying raw stream.  It\n    does *not* provide implementations of read(), readinto() or\n    write().\n    \"\"\"\n\n    def __init__(self, raw):\n        self._raw = raw\n\n    ### Positioning ###\n\n    def seek(self, pos, whence=0):\n        new_position = self.raw.seek(pos, whence)\n        if new_position < 0:\n            raise IOError(\"seek() returned an invalid position\")\n        return new_position\n\n    def tell(self):\n        pos = self.raw.tell()\n        if pos < 0:\n            raise IOError(\"tell() returned an invalid position\")\n        return pos\n\n    def truncate(self, pos=None):\n        # Flush the stream.  We're mixing buffered I/O with lower-level I/O,\n        # and a flush may be necessary to synch both views of the current\n        # file state.\n        self.flush()\n\n        if pos is None:\n            pos = self.tell()\n        # XXX: Should seek() be used, instead of passing the position\n        # XXX  directly to truncate?\n        return self.raw.truncate(pos)\n\n    ### Flush and close ###\n\n    def flush(self):\n        if self.closed:\n            raise ValueError(\"flush of closed file\")\n        self.raw.flush()\n\n    def close(self):\n        if self.raw is not None and not self.closed:\n            try:\n                # may raise BlockingIOError or BrokenPipeError etc\n                self.flush()\n            finally:\n                self.raw.close()\n\n    def detach(self):\n        if self.raw is None:\n            raise ValueError(\"raw stream already detached\")\n        self.flush()\n        raw = self._raw\n        self._raw = None\n        return raw\n\n    ### Inquiries ###\n\n    def seekable(self):\n        return self.raw.seekable()\n\n    def readable(self):\n        return self.raw.readable()\n\n    def writable(self):\n        return self.raw.writable()\n\n    @property\n    def raw(self):\n        return self._raw\n\n    @property\n    def closed(self):\n        return self.raw.closed\n\n    @property\n    def name(self):\n        return self.raw.name\n\n    @property\n    def mode(self):\n        return self.raw.mode\n\n    def __getstate__(self):\n        raise TypeError(\"can not serialize a '{0}' object\"\n                        .format(self.__class__.__name__))\n\n    def __repr__(self):\n        clsname = self.__class__.__name__\n        try:\n            name = self.name\n        except AttributeError:\n            return \"<_io.{0}>\".format(clsname)\n        else:\n            return \"<_io.{0} name={1!r}>\".format(clsname, name)\n\n    ### Lower-level APIs ###\n\n    def fileno(self):\n        return self.raw.fileno()\n\n    def isatty(self):\n        return self.raw.isatty()\n\n\nclass BytesIO(BufferedIOBase):\n\n    \"\"\"Buffered I/O implementation using an in-memory bytes buffer.\"\"\"\n\n    def __init__(self, initial_bytes=None):\n        buf = bytearray()\n        if initial_bytes is not None:\n            buf += initial_bytes\n        self._buffer = buf\n        self._pos = 0\n\n    def __getstate__(self):\n        if self.closed:\n            raise ValueError(\"__getstate__ on closed file\")\n        return self.__dict__.copy()\n\n    def getvalue(self):\n        \"\"\"Return the bytes value (contents) of the buffer\n        \"\"\"\n        if self.closed:\n            raise ValueError(\"getvalue on closed file\")\n        return bytes(self._buffer)\n\n    def getbuffer(self):\n        \"\"\"Return a readable and writable view of the buffer.\n        \"\"\"\n        return memoryview(self._buffer)\n\n    def read(self, n=None):\n        if self.closed:\n            raise ValueError(\"read from closed file\")\n        if n is None:\n            n = -1\n        if n < 0:\n            n = len(self._buffer)\n        if len(self._buffer) <= self._pos:\n            return b\"\"\n        newpos = min(len(self._buffer), self._pos + n)\n        b = self._buffer[self._pos : newpos]\n        self._pos = newpos\n        return bytes(b)\n\n    def read1(self, n):\n        \"\"\"This is the same as read.\n        \"\"\"\n        return self.read(n)\n\n    def write(self, b):\n        if self.closed:\n            raise ValueError(\"write to closed file\")\n        if isinstance(b, str):\n            raise TypeError(\"can't write str to binary stream\")\n        n = len(b)\n        if n == 0:\n            return 0\n        pos = self._pos\n        if pos > len(self._buffer):\n            # Inserts null bytes between the current end of the file\n            # and the new write position.\n            padding = b'\\x00' * (pos - len(self._buffer))\n            self._buffer += padding\n        self._buffer[pos:pos + n] = b\n        self._pos += n\n        return n\n\n    def seek(self, pos, whence=0):\n        if self.closed:\n            raise ValueError(\"seek on closed file\")\n        try:\n            pos.__index__\n        except AttributeError as err:\n            raise TypeError(\"an integer is required\") from err\n        if whence == 0:\n            if pos < 0:\n                raise ValueError(\"negative seek position %r\" % (pos,))\n            self._pos = pos\n        elif whence == 1:\n            self._pos = max(0, self._pos + pos)\n        elif whence == 2:\n            self._pos = max(0, len(self._buffer) + pos)\n        else:\n            raise ValueError(\"unsupported whence value\")\n        return self._pos\n\n    def tell(self):\n        if self.closed:\n            raise ValueError(\"tell on closed file\")\n        return self._pos\n\n    def truncate(self, pos=None):\n        if self.closed:\n            raise ValueError(\"truncate on closed file\")\n        if pos is None:\n            pos = self._pos\n        else:\n            try:\n                pos.__index__\n            except AttributeError as err:\n                raise TypeError(\"an integer is required\") from err\n            if pos < 0:\n                raise ValueError(\"negative truncate position %r\" % (pos,))\n        del self._buffer[pos:]\n        return pos\n\n    def readable(self):\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file.\")\n        return True\n\n    def writable(self):\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file.\")\n        return True\n\n    def seekable(self):\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file.\")\n        return True\n\n\nclass BufferedReader(_BufferedIOMixin):\n\n    \"\"\"BufferedReader(raw[, buffer_size])\n\n    A buffer for a readable, sequential BaseRawIO object.\n\n    The constructor creates a BufferedReader for the given readable raw\n    stream and buffer_size. If buffer_size is omitted, DEFAULT_BUFFER_SIZE\n    is used.\n    \"\"\"\n\n    def __init__(self, raw, buffer_size=DEFAULT_BUFFER_SIZE):\n        \"\"\"Create a new buffered reader using the given readable raw IO object.\n        \"\"\"\n        if not raw.readable():\n            raise IOError('\"raw\" argument must be readable.')\n\n        _BufferedIOMixin.__init__(self, raw)\n        if buffer_size <= 0:\n            raise ValueError(\"invalid buffer size\")\n        self.buffer_size = buffer_size\n        self._reset_read_buf()\n        self._read_lock = Lock()\n\n    def _reset_read_buf(self):\n        self._read_buf = b\"\"\n        self._read_pos = 0\n\n    def read(self, n=None):\n        \"\"\"Read n bytes.\n\n        Returns exactly n bytes of data unless the underlying raw IO\n        stream reaches EOF or if the call would block in non-blocking\n        mode. If n is negative, read until EOF or until read() would\n        block.\n        \"\"\"\n        if n is not None and n < -1:\n            raise ValueError(\"invalid number of bytes to read\")\n        with self._read_lock:\n            return self._read_unlocked(n)\n\n    def _read_unlocked(self, n=None):\n        nodata_val = b\"\"\n        empty_values = (b\"\", None)\n        buf = self._read_buf\n        pos = self._read_pos\n\n        # Special case for when the number of bytes to read is unspecified.\n        if n is None or n == -1:\n            self._reset_read_buf()\n            if hasattr(self.raw, 'readall'):\n                chunk = self.raw.readall()\n                if chunk is None:\n                    return buf[pos:] or None\n                else:\n                    return buf[pos:] + chunk\n            chunks = [buf[pos:]]  # Strip the consumed bytes.\n            current_size = 0\n            while True:\n                # Read until EOF or until read() would block.\n                try:\n                    chunk = self.raw.read()\n                except InterruptedError:\n                    continue\n                if chunk in empty_values:\n                    nodata_val = chunk\n                    break\n                current_size += len(chunk)\n                chunks.append(chunk)\n            return b\"\".join(chunks) or nodata_val\n\n        # The number of bytes to read is specified, return at most n bytes.\n        avail = len(buf) - pos  # Length of the available buffered data.\n        if n <= avail:\n            # Fast path: the data to read is fully buffered.\n            self._read_pos += n\n            return buf[pos:pos+n]\n        # Slow path: read from the stream until enough bytes are read,\n        # or until an EOF occurs or until read() would block.\n        chunks = [buf[pos:]]\n        wanted = max(self.buffer_size, n)\n        while avail < n:\n            try:\n                chunk = self.raw.read(wanted)\n            except InterruptedError:\n                continue\n            if chunk in empty_values:\n                nodata_val = chunk\n                break\n            avail += len(chunk)\n            chunks.append(chunk)\n        # n is more then avail only when an EOF occurred or when\n        # read() would have blocked.\n        n = min(n, avail)\n        out = b\"\".join(chunks)\n        self._read_buf = out[n:]  # Save the extra data in the buffer.\n        self._read_pos = 0\n        return out[:n] if out else nodata_val\n\n    def peek(self, n=0):\n        \"\"\"Returns buffered bytes without advancing the position.\n\n        The argument indicates a desired minimal number of bytes; we\n        do at most one raw read to satisfy it.  We never return more\n        than self.buffer_size.\n        \"\"\"\n        with self._read_lock:\n            return self._peek_unlocked(n)\n\n    def _peek_unlocked(self, n=0):\n        want = min(n, self.buffer_size)\n        have = len(self._read_buf) - self._read_pos\n        if have < want or have <= 0:\n            to_read = self.buffer_size - have\n            while True:\n                try:\n                    current = self.raw.read(to_read)\n                except InterruptedError:\n                    continue\n                break\n            if current:\n                self._read_buf = self._read_buf[self._read_pos:] + current\n                self._read_pos = 0\n        return self._read_buf[self._read_pos:]\n\n    def read1(self, n):\n        \"\"\"Reads up to n bytes, with at most one read() system call.\"\"\"\n        # Returns up to n bytes.  If at least one byte is buffered, we\n        # only return buffered bytes.  Otherwise, we do one raw read.\n        if n < 0:\n            raise ValueError(\"number of bytes to read must be positive\")\n        if n == 0:\n            return b\"\"\n        with self._read_lock:\n            self._peek_unlocked(1)\n            return self._read_unlocked(\n                min(n, len(self._read_buf) - self._read_pos))\n\n    def tell(self):\n        return _BufferedIOMixin.tell(self) - len(self._read_buf) + self._read_pos\n\n    def seek(self, pos, whence=0):\n        if whence not in valid_seek_flags:\n            raise ValueError(\"invalid whence value\")\n        with self._read_lock:\n            if whence == 1:\n                pos -= len(self._read_buf) - self._read_pos\n            pos = _BufferedIOMixin.seek(self, pos, whence)\n            self._reset_read_buf()\n            return pos\n\nclass BufferedWriter(_BufferedIOMixin):\n\n    \"\"\"A buffer for a writeable sequential RawIO object.\n\n    The constructor creates a BufferedWriter for the given writeable raw\n    stream. If the buffer_size is not given, it defaults to\n    DEFAULT_BUFFER_SIZE.\n    \"\"\"\n\n    def __init__(self, raw, buffer_size=DEFAULT_BUFFER_SIZE):\n        if not raw.writable():\n            raise IOError('\"raw\" argument must be writable.')\n\n        _BufferedIOMixin.__init__(self, raw)\n        if buffer_size <= 0:\n            raise ValueError(\"invalid buffer size\")\n        self.buffer_size = buffer_size\n        self._write_buf = bytearray()\n        self._write_lock = Lock()\n\n    def write(self, b):\n        if self.closed:\n            raise ValueError(\"write to closed file\")\n        if isinstance(b, str):\n            raise TypeError(\"can't write str to binary stream\")\n        with self._write_lock:\n            # XXX we can implement some more tricks to try and avoid\n            # partial writes\n            if len(self._write_buf) > self.buffer_size:\n                # We're full, so let's pre-flush the buffer.  (This may\n                # raise BlockingIOError with characters_written == 0.)\n                self._flush_unlocked()\n            before = len(self._write_buf)\n            self._write_buf.extend(b)\n            written = len(self._write_buf) - before\n            if len(self._write_buf) > self.buffer_size:\n                try:\n                    self._flush_unlocked()\n                except BlockingIOError as e:\n                    if len(self._write_buf) > self.buffer_size:\n                        # We've hit the buffer_size. We have to accept a partial\n                        # write and cut back our buffer.\n                        overage = len(self._write_buf) - self.buffer_size\n                        written -= overage\n                        self._write_buf = self._write_buf[:self.buffer_size]\n                        raise BlockingIOError(e.errno, e.strerror, written)\n            return written\n\n    def truncate(self, pos=None):\n        with self._write_lock:\n            self._flush_unlocked()\n            if pos is None:\n                pos = self.raw.tell()\n            return self.raw.truncate(pos)\n\n    def flush(self):\n        with self._write_lock:\n            self._flush_unlocked()\n\n    def _flush_unlocked(self):\n        if self.closed:\n            raise ValueError(\"flush of closed file\")\n        while self._write_buf:\n            try:\n                n = self.raw.write(self._write_buf)\n            except InterruptedError:\n                continue\n            except BlockingIOError:\n                raise RuntimeError(\"self.raw should implement RawIOBase: it \"\n                                   \"should not raise BlockingIOError\")\n            if n is None:\n                raise BlockingIOError(\n                    errno.EAGAIN,\n                    \"write could not complete without blocking\", 0)\n            if n > len(self._write_buf) or n < 0:\n                raise IOError(\"write() returned incorrect number of bytes\")\n            del self._write_buf[:n]\n\n    def tell(self):\n        return _BufferedIOMixin.tell(self) + len(self._write_buf)\n\n    def seek(self, pos, whence=0):\n        if whence not in valid_seek_flags:\n            raise ValueError(\"invalid whence value\")\n        with self._write_lock:\n            self._flush_unlocked()\n            return _BufferedIOMixin.seek(self, pos, whence)\n\n\nclass BufferedRWPair(BufferedIOBase):\n\n    \"\"\"A buffered reader and writer object together.\n\n    A buffered reader object and buffered writer object put together to\n    form a sequential IO object that can read and write. This is typically\n    used with a socket or two-way pipe.\n\n    reader and writer are RawIOBase objects that are readable and\n    writeable respectively. If the buffer_size is omitted it defaults to\n    DEFAULT_BUFFER_SIZE.\n    \"\"\"\n\n    # XXX The usefulness of this (compared to having two separate IO\n    # objects) is questionable.\n\n    def __init__(self, reader, writer, buffer_size=DEFAULT_BUFFER_SIZE):\n        \"\"\"Constructor.\n\n        The arguments are two RawIO instances.\n        \"\"\"\n        if not reader.readable():\n            raise IOError('\"reader\" argument must be readable.')\n\n        if not writer.writable():\n            raise IOError('\"writer\" argument must be writable.')\n\n        self.reader = BufferedReader(reader, buffer_size)\n        self.writer = BufferedWriter(writer, buffer_size)\n\n    def read(self, n=None):\n        if n is None:\n            n = -1\n        return self.reader.read(n)\n\n    def readinto(self, b):\n        return self.reader.readinto(b)\n\n    def write(self, b):\n        return self.writer.write(b)\n\n    def peek(self, n=0):\n        return self.reader.peek(n)\n\n    def read1(self, n):\n        return self.reader.read1(n)\n\n    def readable(self):\n        return self.reader.readable()\n\n    def writable(self):\n        return self.writer.writable()\n\n    def flush(self):\n        return self.writer.flush()\n\n    def close(self):\n        self.writer.close()\n        self.reader.close()\n\n    def isatty(self):\n        return self.reader.isatty() or self.writer.isatty()\n\n    @property\n    def closed(self):\n        return self.writer.closed\n\n\nclass BufferedRandom(BufferedWriter, BufferedReader):\n\n    \"\"\"A buffered interface to random access streams.\n\n    The constructor creates a reader and writer for a seekable stream,\n    raw, given in the first argument. If the buffer_size is omitted it\n    defaults to DEFAULT_BUFFER_SIZE.\n    \"\"\"\n\n    def __init__(self, raw, buffer_size=DEFAULT_BUFFER_SIZE):\n        raw._checkSeekable()\n        BufferedReader.__init__(self, raw, buffer_size)\n        BufferedWriter.__init__(self, raw, buffer_size)\n\n    def seek(self, pos, whence=0):\n        if whence not in valid_seek_flags:\n            raise ValueError(\"invalid whence value\")\n        self.flush()\n        if self._read_buf:\n            # Undo read ahead.\n            with self._read_lock:\n                self.raw.seek(self._read_pos - len(self._read_buf), 1)\n        # First do the raw seek, then empty the read buffer, so that\n        # if the raw seek fails, we don't lose buffered data forever.\n        pos = self.raw.seek(pos, whence)\n        with self._read_lock:\n            self._reset_read_buf()\n        if pos < 0:\n            raise IOError(\"seek() returned invalid position\")\n        return pos\n\n    def tell(self):\n        if self._write_buf:\n            return BufferedWriter.tell(self)\n        else:\n            return BufferedReader.tell(self)\n\n    def truncate(self, pos=None):\n        if pos is None:\n            pos = self.tell()\n        # Use seek to flush the read buffer.\n        return BufferedWriter.truncate(self, pos)\n\n    def read(self, n=None):\n        if n is None:\n            n = -1\n        self.flush()\n        return BufferedReader.read(self, n)\n\n    def readinto(self, b):\n        self.flush()\n        return BufferedReader.readinto(self, b)\n\n    def peek(self, n=0):\n        self.flush()\n        return BufferedReader.peek(self, n)\n\n    def read1(self, n):\n        self.flush()\n        return BufferedReader.read1(self, n)\n\n    def write(self, b):\n        if self._read_buf:\n            # Undo readahead\n            with self._read_lock:\n                self.raw.seek(self._read_pos - len(self._read_buf), 1)\n                self._reset_read_buf()\n        return BufferedWriter.write(self, b)\n\n\nclass TextIOBase(IOBase):\n\n    \"\"\"Base class for text I/O.\n\n    This class provides a character and line based interface to stream\n    I/O. There is no readinto method because Python's character strings\n    are immutable. There is no public constructor.\n    \"\"\"\n\n    def read(self, n=-1):\n        \"\"\"Read at most n characters from stream, where n is an int.\n\n        Read from underlying buffer until we have n characters or we hit EOF.\n        If n is negative or omitted, read until EOF.\n\n        Returns a string.\n        \"\"\"\n        self._unsupported(\"read\")\n\n    def write(self, s):\n        \"\"\"Write string s to stream and returning an int.\"\"\"\n        self._unsupported(\"write\")\n\n    def truncate(self, pos=None):\n        \"\"\"Truncate size to pos, where pos is an int.\"\"\"\n        self._unsupported(\"truncate\")\n\n    def readline(self):\n        \"\"\"Read until newline or EOF.\n\n        Returns an empty string if EOF is hit immediately.\n        \"\"\"\n        self._unsupported(\"readline\")\n\n    def detach(self):\n        \"\"\"\n        Separate the underlying buffer from the TextIOBase and return it.\n\n        After the underlying buffer has been detached, the TextIO is in an\n        unusable state.\n        \"\"\"\n        self._unsupported(\"detach\")\n\n    @property\n    def encoding(self):\n        \"\"\"Subclasses should override.\"\"\"\n        return None\n\n    @property\n    def newlines(self):\n        \"\"\"Line endings translated so far.\n\n        Only line endings translated during reading are considered.\n\n        Subclasses should override.\n        \"\"\"\n        return None\n\n    @property\n    def errors(self):\n        \"\"\"Error setting of the decoder or encoder.\n\n        Subclasses should override.\"\"\"\n        return None\n\n#fix me brython\n#io.TextIOBase.register(TextIOBase)\n\n\nclass IncrementalNewlineDecoder(codecs.IncrementalDecoder):\n    r\"\"\"Codec used when reading a file in universal newlines mode.  It wraps\n    another incremental decoder, translating \\r\\n and \\r into \\n.  It also\n    records the types of newlines encountered.  When used with\n    translate=False, it ensures that the newline sequence is returned in\n    one piece.\n    \"\"\"\n    def __init__(self, decoder, translate, errors='strict'):\n        codecs.IncrementalDecoder.__init__(self, errors=errors)\n        self.translate = translate\n        self.decoder = decoder\n        self.seennl = 0\n        self.pendingcr = False\n\n    def decode(self, input, final=False):\n        # decode input (with the eventual \\r from a previous pass)\n        if self.decoder is None:\n            output = input\n        else:\n            output = self.decoder.decode(input, final=final)\n        if self.pendingcr and (output or final):\n            output = \"\\r\" + output\n            self.pendingcr = False\n\n        # retain last \\r even when not translating data:\n        # then readline() is sure to get \\r\\n in one pass\n        if output.endswith(\"\\r\") and not final:\n            output = output[:-1]\n            self.pendingcr = True\n\n        # Record which newlines are read\n        crlf = output.count('\\r\\n')\n        cr = output.count('\\r') - crlf\n        lf = output.count('\\n') - crlf\n        self.seennl |= (lf and self._LF) | (cr and self._CR) \\\n                    | (crlf and self._CRLF)\n\n        if self.translate:\n            if crlf:\n                output = output.replace(\"\\r\\n\", \"\\n\")\n            if cr:\n                output = output.replace(\"\\r\", \"\\n\")\n\n        return output\n\n    def getstate(self):\n        if self.decoder is None:\n            buf = b\"\"\n            flag = 0\n        else:\n            buf, flag = self.decoder.getstate()\n        flag <<= 1\n        if self.pendingcr:\n            flag |= 1\n        return buf, flag\n\n    def setstate(self, state):\n        buf, flag = state\n        self.pendingcr = bool(flag & 1)\n        if self.decoder is not None:\n            self.decoder.setstate((buf, flag >> 1))\n\n    def reset(self):\n        self.seennl = 0\n        self.pendingcr = False\n        if self.decoder is not None:\n            self.decoder.reset()\n\n    _LF = 1\n    _CR = 2\n    _CRLF = 4\n\n    @property\n    def newlines(self):\n        return (None,\n                \"\\n\",\n                \"\\r\",\n                (\"\\r\", \"\\n\"),\n                \"\\r\\n\",\n                (\"\\n\", \"\\r\\n\"),\n                (\"\\r\", \"\\r\\n\"),\n                (\"\\r\", \"\\n\", \"\\r\\n\")\n               )[self.seennl]\n\n\nclass TextIOWrapper(TextIOBase):\n\n    r\"\"\"Character and line based layer over a BufferedIOBase object, buffer.\n\n    encoding gives the name of the encoding that the stream will be\n    decoded or encoded with. It defaults to locale.getpreferredencoding(False).\n\n    errors determines the strictness of encoding and decoding (see the\n    codecs.register) and defaults to \"strict\".\n\n    newline can be None, '', '\\n', '\\r', or '\\r\\n'.  It controls the\n    handling of line endings. If it is None, universal newlines is\n    enabled.  With this enabled, on input, the lines endings '\\n', '\\r',\n    or '\\r\\n' are translated to '\\n' before being returned to the\n    caller. Conversely, on output, '\\n' is translated to the system\n    default line separator, os.linesep. If newline is any other of its\n    legal values, that newline becomes the newline when the file is read\n    and it is returned untranslated. On output, '\\n' is converted to the\n    newline.\n\n    If line_buffering is True, a call to flush is implied when a call to\n    write contains a newline character.\n    \"\"\"\n\n    _CHUNK_SIZE = 2048\n\n    # The write_through argument has no effect here since this\n    # implementation always writes through.  The argument is present only\n    # so that the signature can match the signature of the C version.\n    def __init__(self, buffer, encoding=None, errors=None, newline=None,\n                 line_buffering=False, write_through=False):\n        if newline is not None and not isinstance(newline, str):\n            raise TypeError(\"illegal newline type: %r\" % (type(newline),))\n        if newline not in (None, \"\", \"\\n\", \"\\r\", \"\\r\\n\"):\n            raise ValueError(\"illegal newline value: %r\" % (newline,))\n        if encoding is None:\n            try:\n                encoding = os.device_encoding(buffer.fileno())\n            except (AttributeError, UnsupportedOperation):\n                pass\n            if encoding is None:\n                try:\n                    import locale\n                except ImportError:\n                    # Importing locale may fail if Python is being built\n                    encoding = \"ascii\"\n                else:\n                    encoding = locale.getpreferredencoding(False)\n\n        if not isinstance(encoding, str):\n            raise ValueError(\"invalid encoding: %r\" % encoding)\n\n        if errors is None:\n            errors = \"strict\"\n        else:\n            if not isinstance(errors, str):\n                raise ValueError(\"invalid errors: %r\" % errors)\n\n        self._buffer = buffer\n        self._line_buffering = line_buffering\n        self._encoding = encoding\n        self._errors = errors\n        self._readuniversal = not newline\n        self._readtranslate = newline is None\n        self._readnl = newline\n        self._writetranslate = newline != ''\n        self._writenl = newline or os.linesep\n        self._encoder = None\n        self._decoder = None\n        self._decoded_chars = ''  # buffer for text returned from decoder\n        self._decoded_chars_used = 0  # offset into _decoded_chars for read()\n        self._snapshot = None  # info for reconstructing decoder state\n        self._seekable = self._telling = self.buffer.seekable()\n        self._has_read1 = hasattr(self.buffer, 'read1')\n        self._b2cratio = 0.0\n\n        if self._seekable and self.writable():\n            position = self.buffer.tell()\n            if position != 0:\n                try:\n                    self._get_encoder().setstate(0)\n                except LookupError:\n                    # Sometimes the encoder doesn't exist\n                    pass\n\n    # self._snapshot is either None, or a tuple (dec_flags, next_input)\n    # where dec_flags is the second (integer) item of the decoder state\n    # and next_input is the chunk of input bytes that comes next after the\n    # snapshot point.  We use this to reconstruct decoder states in tell().\n\n    # Naming convention:\n    #   - \"bytes_...\" for integer variables that count input bytes\n    #   - \"chars_...\" for integer variables that count decoded characters\n\n    def __repr__(self):\n        result = \"<_io.TextIOWrapper\"\n        try:\n            name = self.name\n        except AttributeError:\n            pass\n        else:\n            result += \" name={0!r}\".format(name)\n        try:\n            mode = self.mode\n        except AttributeError:\n            pass\n        else:\n            result += \" mode={0!r}\".format(mode)\n        return result + \" encoding={0!r}>\".format(self.encoding)\n\n    @property\n    def encoding(self):\n        return self._encoding\n\n    @property\n    def errors(self):\n        return self._errors\n\n    @property\n    def line_buffering(self):\n        return self._line_buffering\n\n    @property\n    def buffer(self):\n        return self._buffer\n\n    def seekable(self):\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file.\")\n        return self._seekable\n\n    def readable(self):\n        return self.buffer.readable()\n\n    def writable(self):\n        return self.buffer.writable()\n\n    def flush(self):\n        self.buffer.flush()\n        self._telling = self._seekable\n\n    def close(self):\n        if self.buffer is not None and not self.closed:\n            try:\n                self.flush()\n            finally:\n                self.buffer.close()\n\n    @property\n    def closed(self):\n        return self.buffer.closed\n\n    @property\n    def name(self):\n        return self.buffer.name\n\n    def fileno(self):\n        return self.buffer.fileno()\n\n    def isatty(self):\n        return self.buffer.isatty()\n\n    def write(self, s):\n        'Write data, where s is a str'\n        if self.closed:\n            raise ValueError(\"write to closed file\")\n        if not isinstance(s, str):\n            raise TypeError(\"can't write %s to text stream\" %\n                            s.__class__.__name__)\n        length = len(s)\n        haslf = (self._writetranslate or self._line_buffering) and \"\\n\" in s\n        if haslf and self._writetranslate and self._writenl != \"\\n\":\n            s = s.replace(\"\\n\", self._writenl)\n        encoder = self._encoder or self._get_encoder()\n        # XXX What if we were just reading?\n        b = encoder.encode(s)\n        self.buffer.write(b)\n        if self._line_buffering and (haslf or \"\\r\" in s):\n            self.flush()\n        self._snapshot = None\n        if self._decoder:\n            self._decoder.reset()\n        return length\n\n    def _get_encoder(self):\n        make_encoder = codecs.getincrementalencoder(self._encoding)\n        self._encoder = make_encoder(self._errors)\n        return self._encoder\n\n    def _get_decoder(self):\n        make_decoder = codecs.getincrementaldecoder(self._encoding)\n        decoder = make_decoder(self._errors)\n        if self._readuniversal:\n            decoder = IncrementalNewlineDecoder(decoder, self._readtranslate)\n        self._decoder = decoder\n        return decoder\n\n    # The following three methods implement an ADT for _decoded_chars.\n    # Text returned from the decoder is buffered here until the client\n    # requests it by calling our read() or readline() method.\n    def _set_decoded_chars(self, chars):\n        \"\"\"Set the _decoded_chars buffer.\"\"\"\n        self._decoded_chars = chars\n        self._decoded_chars_used = 0\n\n    def _get_decoded_chars(self, n=None):\n        \"\"\"Advance into the _decoded_chars buffer.\"\"\"\n        offset = self._decoded_chars_used\n        if n is None:\n            chars = self._decoded_chars[offset:]\n        else:\n            chars = self._decoded_chars[offset:offset + n]\n        self._decoded_chars_used += len(chars)\n        return chars\n\n    def _rewind_decoded_chars(self, n):\n        \"\"\"Rewind the _decoded_chars buffer.\"\"\"\n        if self._decoded_chars_used < n:\n            raise AssertionError(\"rewind decoded_chars out of bounds\")\n        self._decoded_chars_used -= n\n\n    def _read_chunk(self):\n        \"\"\"\n        Read and decode the next chunk of data from the BufferedReader.\n        \"\"\"\n\n        # The return value is True unless EOF was reached.  The decoded\n        # string is placed in self._decoded_chars (replacing its previous\n        # value).  The entire input chunk is sent to the decoder, though\n        # some of it may remain buffered in the decoder, yet to be\n        # converted.\n\n        if self._decoder is None:\n            raise ValueError(\"no decoder\")\n\n        if self._telling:\n            # To prepare for tell(), we need to snapshot a point in the\n            # file where the decoder's input buffer is empty.\n\n            dec_buffer, dec_flags = self._decoder.getstate()\n            # Given this, we know there was a valid snapshot point\n            # len(dec_buffer) bytes ago with decoder state (b'', dec_flags).\n\n        # Read a chunk, decode it, and put the result in self._decoded_chars.\n        if self._has_read1:\n            input_chunk = self.buffer.read1(self._CHUNK_SIZE)\n        else:\n            input_chunk = self.buffer.read(self._CHUNK_SIZE)\n        eof = not input_chunk\n        decoded_chars = self._decoder.decode(input_chunk, eof)\n        self._set_decoded_chars(decoded_chars)\n        if decoded_chars:\n            self._b2cratio = len(input_chunk) / len(self._decoded_chars)\n        else:\n            self._b2cratio = 0.0\n\n        if self._telling:\n            # At the snapshot point, len(dec_buffer) bytes before the read,\n            # the next input to be decoded is dec_buffer + input_chunk.\n            self._snapshot = (dec_flags, dec_buffer + input_chunk)\n\n        return not eof\n\n    def _pack_cookie(self, position, dec_flags=0,\n                           bytes_to_feed=0, need_eof=0, chars_to_skip=0):\n        # The meaning of a tell() cookie is: seek to position, set the\n        # decoder flags to dec_flags, read bytes_to_feed bytes, feed them\n        # into the decoder with need_eof as the EOF flag, then skip\n        # chars_to_skip characters of the decoded result.  For most simple\n        # decoders, tell() will often just give a byte offset in the file.\n        return (position | (dec_flags<<64) | (bytes_to_feed<<128) |\n               (chars_to_skip<<192) | bool(need_eof)<<256)\n\n    def _unpack_cookie(self, bigint):\n        rest, position = divmod(bigint, 1<<64)\n        rest, dec_flags = divmod(rest, 1<<64)\n        rest, bytes_to_feed = divmod(rest, 1<<64)\n        need_eof, chars_to_skip = divmod(rest, 1<<64)\n        return position, dec_flags, bytes_to_feed, need_eof, chars_to_skip\n\n    def tell(self):\n        if not self._seekable:\n            raise UnsupportedOperation(\"underlying stream is not seekable\")\n        if not self._telling:\n            raise IOError(\"telling position disabled by next() call\")\n        self.flush()\n        position = self.buffer.tell()\n        decoder = self._decoder\n        if decoder is None or self._snapshot is None:\n            if self._decoded_chars:\n                # This should never happen.\n                raise AssertionError(\"pending decoded text\")\n            return position\n\n        # Skip backward to the snapshot point (see _read_chunk).\n        dec_flags, next_input = self._snapshot\n        position -= len(next_input)\n\n        # How many decoded characters have been used up since the snapshot?\n        chars_to_skip = self._decoded_chars_used\n        if chars_to_skip == 0:\n            # We haven't moved from the snapshot point.\n            return self._pack_cookie(position, dec_flags)\n\n        # Starting from the snapshot position, we will walk the decoder\n        # forward until it gives us enough decoded characters.\n        saved_state = decoder.getstate()\n        try:\n            # Fast search for an acceptable start point, close to our\n            # current pos.\n            # Rationale: calling decoder.decode() has a large overhead\n            # regardless of chunk size; we want the number of such calls to\n            # be O(1) in most situations (common decoders, non-crazy input).\n            # Actually, it will be exactly 1 for fixed-size codecs (all\n            # 8-bit codecs, also UTF-16 and UTF-32).\n            skip_bytes = int(self._b2cratio * chars_to_skip)\n            skip_back = 1\n            assert skip_bytes <= len(next_input)\n            while skip_bytes > 0:\n                decoder.setstate((b'', dec_flags))\n                # Decode up to temptative start point\n                n = len(decoder.decode(next_input[:skip_bytes]))\n                if n <= chars_to_skip:\n                    b, d = decoder.getstate()\n                    if not b:\n                        # Before pos and no bytes buffered in decoder => OK\n                        dec_flags = d\n                        chars_to_skip -= n\n                        break\n                    # Skip back by buffered amount and reset heuristic\n                    skip_bytes -= len(b)\n                    skip_back = 1\n                else:\n                    # We're too far ahead, skip back a bit\n                    skip_bytes -= skip_back\n                    skip_back = skip_back * 2\n            else:\n                skip_bytes = 0\n                decoder.setstate((b'', dec_flags))\n\n            # Note our initial start point.\n            start_pos = position + skip_bytes\n            start_flags = dec_flags\n            if chars_to_skip == 0:\n                # We haven't moved from the start point.\n                return self._pack_cookie(start_pos, start_flags)\n\n            # Feed the decoder one byte at a time.  As we go, note the\n            # nearest \"safe start point\" before the current location\n            # (a point where the decoder has nothing buffered, so seek()\n            # can safely start from there and advance to this location).\n            bytes_fed = 0\n            need_eof = 0\n            # Chars decoded since `start_pos`\n            chars_decoded = 0\n            for i in range(skip_bytes, len(next_input)):\n                bytes_fed += 1\n                chars_decoded += len(decoder.decode(next_input[i:i+1]))\n                dec_buffer, dec_flags = decoder.getstate()\n                if not dec_buffer and chars_decoded <= chars_to_skip:\n                    # Decoder buffer is empty, so this is a safe start point.\n                    start_pos += bytes_fed\n                    chars_to_skip -= chars_decoded\n                    start_flags, bytes_fed, chars_decoded = dec_flags, 0, 0\n                if chars_decoded >= chars_to_skip:\n                    break\n            else:\n                # We didn't get enough decoded data; signal EOF to get more.\n                chars_decoded += len(decoder.decode(b'', final=True))\n                need_eof = 1\n                if chars_decoded < chars_to_skip:\n                    raise IOError(\"can't reconstruct logical file position\")\n\n            # The returned cookie corresponds to the last safe start point.\n            return self._pack_cookie(\n                start_pos, start_flags, bytes_fed, need_eof, chars_to_skip)\n        finally:\n            decoder.setstate(saved_state)\n\n    def truncate(self, pos=None):\n        self.flush()\n        if pos is None:\n            pos = self.tell()\n        return self.buffer.truncate(pos)\n\n    def detach(self):\n        if self.buffer is None:\n            raise ValueError(\"buffer is already detached\")\n        self.flush()\n        buffer = self._buffer\n        self._buffer = None\n        return buffer\n\n    def seek(self, cookie, whence=0):\n        if self.closed:\n            raise ValueError(\"tell on closed file\")\n        if not self._seekable:\n            raise UnsupportedOperation(\"underlying stream is not seekable\")\n        if whence == 1: # seek relative to current position\n            if cookie != 0:\n                raise UnsupportedOperation(\"can't do nonzero cur-relative seeks\")\n            # Seeking to the current position should attempt to\n            # sync the underlying buffer with the current position.\n            whence = 0\n            cookie = self.tell()\n        if whence == 2: # seek relative to end of file\n            if cookie != 0:\n                raise UnsupportedOperation(\"can't do nonzero end-relative seeks\")\n            self.flush()\n            position = self.buffer.seek(0, 2)\n            self._set_decoded_chars('')\n            self._snapshot = None\n            if self._decoder:\n                self._decoder.reset()\n            return position\n        if whence != 0:\n            raise ValueError(\"unsupported whence (%r)\" % (whence,))\n        if cookie < 0:\n            raise ValueError(\"negative seek position %r\" % (cookie,))\n        self.flush()\n\n        # The strategy of seek() is to go back to the safe start point\n        # and replay the effect of read(chars_to_skip) from there.\n        start_pos, dec_flags, bytes_to_feed, need_eof, chars_to_skip = \\\n            self._unpack_cookie(cookie)\n\n        # Seek back to the safe start point.\n        self.buffer.seek(start_pos)\n        self._set_decoded_chars('')\n        self._snapshot = None\n\n        # Restore the decoder to its state from the safe start point.\n        if cookie == 0 and self._decoder:\n            self._decoder.reset()\n        elif self._decoder or dec_flags or chars_to_skip:\n            self._decoder = self._decoder or self._get_decoder()\n            self._decoder.setstate((b'', dec_flags))\n            self._snapshot = (dec_flags, b'')\n\n        if chars_to_skip:\n            # Just like _read_chunk, feed the decoder and save a snapshot.\n            input_chunk = self.buffer.read(bytes_to_feed)\n            self._set_decoded_chars(\n                self._decoder.decode(input_chunk, need_eof))\n            self._snapshot = (dec_flags, input_chunk)\n\n            # Skip chars_to_skip of the decoded characters.\n            if len(self._decoded_chars) < chars_to_skip:\n                raise IOError(\"can't restore logical file position\")\n            self._decoded_chars_used = chars_to_skip\n\n        # Finally, reset the encoder (merely useful for proper BOM handling)\n        try:\n            encoder = self._encoder or self._get_encoder()\n        except LookupError:\n            # Sometimes the encoder doesn't exist\n            pass\n        else:\n            if cookie != 0:\n                encoder.setstate(0)\n            else:\n                encoder.reset()\n        return cookie\n\n    def read(self, n=None):\n        self._checkReadable()\n        if n is None:\n            n = -1\n        decoder = self._decoder or self._get_decoder()\n        try:\n            n.__index__\n        except AttributeError as err:\n            raise TypeError(\"an integer is required\") from err\n        if n < 0:\n            # Read everything.\n            result = (self._get_decoded_chars() +\n                      decoder.decode(self.buffer.read(), final=True))\n            self._set_decoded_chars('')\n            self._snapshot = None\n            return result\n        else:\n            # Keep reading chunks until we have n characters to return.\n            eof = False\n            result = self._get_decoded_chars(n)\n            while len(result) < n and not eof:\n                eof = not self._read_chunk()\n                result += self._get_decoded_chars(n - len(result))\n            return result\n\n    def __next__(self):\n        self._telling = False\n        line = self.readline()\n        if not line:\n            self._snapshot = None\n            self._telling = self._seekable\n            raise StopIteration\n        return line\n\n    def readline(self, limit=None):\n        if self.closed:\n            raise ValueError(\"read from closed file\")\n        if limit is None:\n            limit = -1\n        elif not isinstance(limit, int):\n            raise TypeError(\"limit must be an integer\")\n\n        # Grab all the decoded text (we will rewind any extra bits later).\n        line = self._get_decoded_chars()\n\n        start = 0\n        # Make the decoder if it doesn't already exist.\n        if not self._decoder:\n            self._get_decoder()\n\n        pos = endpos = None\n        while True:\n            if self._readtranslate:\n                # Newlines are already translated, only search for \\n\n                pos = line.find('\\n', start)\n                if pos >= 0:\n                    endpos = pos + 1\n                    break\n                else:\n                    start = len(line)\n\n            elif self._readuniversal:\n                # Universal newline search. Find any of \\r, \\r\\n, \\n\n                # The decoder ensures that \\r\\n are not split in two pieces\n\n                # In C we'd look for these in parallel of course.\n                nlpos = line.find(\"\\n\", start)\n                crpos = line.find(\"\\r\", start)\n                if crpos == -1:\n                    if nlpos == -1:\n                        # Nothing found\n                        start = len(line)\n                    else:\n                        # Found \\n\n                        endpos = nlpos + 1\n                        break\n                elif nlpos == -1:\n                    # Found lone \\r\n                    endpos = crpos + 1\n                    break\n                elif nlpos < crpos:\n                    # Found \\n\n                    endpos = nlpos + 1\n                    break\n                elif nlpos == crpos + 1:\n                    # Found \\r\\n\n                    endpos = crpos + 2\n                    break\n                else:\n                    # Found \\r\n                    endpos = crpos + 1\n                    break\n            else:\n                # non-universal\n                pos = line.find(self._readnl)\n                if pos >= 0:\n                    endpos = pos + len(self._readnl)\n                    break\n\n            if limit >= 0 and len(line) >= limit:\n                endpos = limit  # reached length limit\n                break\n\n            # No line ending seen yet - get more data'\n            while self._read_chunk():\n                if self._decoded_chars:\n                    break\n            if self._decoded_chars:\n                line += self._get_decoded_chars()\n            else:\n                # end of file\n                self._set_decoded_chars('')\n                self._snapshot = None\n                return line\n\n        if limit >= 0 and endpos > limit:\n            endpos = limit  # don't exceed limit\n\n        # Rewind _decoded_chars to just after the line ending we found.\n        self._rewind_decoded_chars(len(line) - endpos)\n        return line[:endpos]\n\n    @property\n    def newlines(self):\n        return self._decoder.newlines if self._decoder else None\n\n\nclass StringIO(TextIOWrapper):\n    \"\"\"Text I/O implementation using an in-memory buffer.\n\n    The initial_value argument sets the value of object.  The newline\n    argument is like the one of TextIOWrapper's constructor.\n    \"\"\"\n\n    def __init__(self, initial_value=\"\", newline=\"\\n\"):\n        super(StringIO, self).__init__(BytesIO(),\n                                       encoding=\"utf-8\",\n                                       errors=\"strict\",\n                                       newline=newline)\n        # Issue #5645: make universal newlines semantics the same as in the\n        # C version, even under Windows.\n        if newline is None:\n            self._writetranslate = False\n        if initial_value is not None:\n            if not isinstance(initial_value, str):\n                raise TypeError(\"initial_value must be str or None, not {0}\"\n                                .format(type(initial_value).__name__))\n                initial_value = str(initial_value)\n            self.write(initial_value)\n            self.seek(0)\n\n    def getvalue(self):\n        self.flush()\n        return self.buffer.getvalue().decode(self._encoding, self._errors)\n\n    def __repr__(self):\n        # TextIOWrapper tells the encoding in its repr. In StringIO,\n        # that's a implementation detail.\n        return object.__repr__(self)\n\n    @property\n    def errors(self):\n        return None\n\n    @property\n    def encoding(self):\n        return None\n\n    def detach(self):\n        # This doesn't make sense on StringIO.\n        self._unsupported(\"detach\")\n"], "linecache": [".py", "\"\"\"Cache lines from files.\n\nThis is intended to read lines from modules imported -- hence if a filename\nis not found, it will look down the module search path for a file by\nthat name.\n\"\"\"\n\nimport sys\nimport os\nimport tokenize\n\n__all__ = [\"getline\", \"clearcache\", \"checkcache\"]\n\ndef getline(filename, lineno, module_globals=None):\n    lines = getlines(filename, module_globals)\n    if 1 <= lineno <= len(lines):\n        return lines[lineno-1]\n    else:\n        return ''\n\n\n# The cache\n\ncache = {} # The cache\n\n\ndef clearcache():\n    \"\"\"Clear the cache entirely.\"\"\"\n\n    global cache\n    cache = {}\n\n\ndef getlines(filename, module_globals=None):\n    \"\"\"Get the lines for a file from the cache.\n    Update the cache if it doesn't contain an entry for this file already.\"\"\"\n\n    if filename in cache:\n        return cache[filename][2]\n    else:\n        return updatecache(filename, module_globals)\n\n\ndef checkcache(filename=None):\n    \"\"\"Discard cache entries that are out of date.\n    (This is not checked upon each call!)\"\"\"\n\n    if filename is None:\n        filenames = list(cache.keys())\n    else:\n        if filename in cache:\n            filenames = [filename]\n        else:\n            return\n\n    for filename in filenames:\n        size, mtime, lines, fullname = cache[filename]\n        if mtime is None:\n            continue   # no-op for files loaded via a __loader__\n        try:\n            stat = os.stat(fullname)\n        except os.error:\n            del cache[filename]\n            continue\n        if size != stat.st_size or mtime != stat.st_mtime:\n            del cache[filename]\n\n\ndef updatecache(filename, module_globals=None):\n    \"\"\"Update a cache entry and return its list of lines.\n    If something's wrong, print a message, discard the cache entry,\n    and return an empty list.\"\"\"\n\n    if filename in cache:\n        del cache[filename]\n    if not filename or (filename.startswith('<') and filename.endswith('>')):\n        return []\n\n    fullname = filename\n    try:\n        stat = os.stat(fullname)\n    except OSError:\n        basename = filename\n\n        # Try for a __loader__, if available\n        if module_globals and '__loader__' in module_globals:\n            name = module_globals.get('__name__')\n            loader = module_globals['__loader__']\n            get_source = getattr(loader, 'get_source', None)\n\n            if name and get_source:\n                try:\n                    data = get_source(name)\n                except (ImportError, IOError):\n                    pass\n                else:\n                    if data is None:\n                        # No luck, the PEP302 loader cannot find the source\n                        # for this module.\n                        return []\n                    cache[filename] = (\n                        len(data), None,\n                        [line+'\\n' for line in data.splitlines()], fullname\n                    )\n                    return cache[filename][2]\n\n        # Try looking through the module search path, which is only useful\n        # when handling a relative filename.\n        if os.path.isabs(filename):\n            return []\n\n        for dirname in sys.path:\n            try:\n                fullname = os.path.join(dirname, basename)\n            except (TypeError, AttributeError):\n                # Not sufficiently string-like to do anything useful with.\n                continue\n            try:\n                stat = os.stat(fullname)\n                break\n            except os.error:\n                pass\n        else:\n            return []\n    try:\n        with tokenize.open(fullname) as fp:\n            lines = fp.readlines()\n    except IOError:\n        return []\n    if lines and not lines[-1].endswith('\\n'):\n        lines[-1] += '\\n'\n    size, mtime = stat.st_size, stat.st_mtime\n    cache[filename] = size, mtime, lines, fullname\n    return lines\n"], "_strptime": [".py", "\"\"\"Strptime-related classes and functions.\n\nCLASSES:\n    LocaleTime -- Discovers and stores locale-specific time information\n    TimeRE -- Creates regexes for pattern matching a string of text containing\n                time information\n\nFUNCTIONS:\n    _getlang -- Figure out what language is being used for the locale\n    strptime -- Calculates the time struct represented by the passed-in string\n\n\"\"\"\nimport time\nimport locale\nimport calendar\nfrom pyre import compile as re_compile\nfrom pyre import IGNORECASE\nfrom pyre import escape as re_escape\nfrom datetime import (date as datetime_date,\n                      timedelta as datetime_timedelta,\n                      timezone as datetime_timezone)\ntry:\n    from _thread import allocate_lock as _thread_allocate_lock\nexcept ImportError:\n    from _dummy_thread import allocate_lock as _thread_allocate_lock\n\n__all__ = []\n\ndef _getlang():\n    # Figure out what the current language is set to.\n    return locale.getlocale(locale.LC_TIME)\n\nclass LocaleTime(object):\n    \"\"\"Stores and handles locale-specific information related to time.\n\n    ATTRIBUTES:\n        f_weekday -- full weekday names (7-item list)\n        a_weekday -- abbreviated weekday names (7-item list)\n        f_month -- full month names (13-item list; dummy value in [0], which\n                    is added by code)\n        a_month -- abbreviated month names (13-item list, dummy value in\n                    [0], which is added by code)\n        am_pm -- AM/PM representation (2-item list)\n        LC_date_time -- format string for date/time representation (string)\n        LC_date -- format string for date representation (string)\n        LC_time -- format string for time representation (string)\n        timezone -- daylight- and non-daylight-savings timezone representation\n                    (2-item list of sets)\n        lang -- Language used by instance (2-item tuple)\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Set all attributes.\n\n        Order of methods called matters for dependency reasons.\n\n        The locale language is set at the offset and then checked again before\n        exiting.  This is to make sure that the attributes were not set with a\n        mix of information from more than one locale.  This would most likely\n        happen when using threads where one thread calls a locale-dependent\n        function while another thread changes the locale while the function in\n        the other thread is still running.  Proper coding would call for\n        locks to prevent changing the locale while locale-dependent code is\n        running.  The check here is done in case someone does not think about\n        doing this.\n\n        Only other possible issue is if someone changed the timezone and did\n        not call tz.tzset .  That is an issue for the programmer, though,\n        since changing the timezone is worthless without that call.\n\n        \"\"\"\n        self.lang = _getlang()\n        self.__calc_weekday()\n        self.__calc_month()\n        self.__calc_am_pm()\n        self.__calc_timezone()\n        self.__calc_date_time()\n        if _getlang() != self.lang:\n            raise ValueError(\"locale changed during initialization\")\n\n    def __pad(self, seq, front):\n        # Add '' to seq to either the front (is True), else the back.\n        seq = list(seq)\n        if front:\n            seq.insert(0, '')\n        else:\n            seq.append('')\n        return seq\n\n    def __calc_weekday(self):\n        # Set self.a_weekday and self.f_weekday using the calendar\n        # module.\n        a_weekday = [calendar.day_abbr[i].lower() for i in range(7)]\n        f_weekday = [calendar.day_name[i].lower() for i in range(7)]\n        self.a_weekday = a_weekday\n        self.f_weekday = f_weekday\n\n    def __calc_month(self):\n        # Set self.f_month and self.a_month using the calendar module.\n        a_month = [calendar.month_abbr[i].lower() for i in range(13)]\n        f_month = [calendar.month_name[i].lower() for i in range(13)]\n        self.a_month = a_month\n        self.f_month = f_month\n\n    def __calc_am_pm(self):\n        # Set self.am_pm by using time.strftime().\n\n        # The magic date (1999,3,17,hour,44,55,2,76,0) is not really that\n        # magical; just happened to have used it everywhere else where a\n        # static date was needed.\n        am_pm = []\n        for hour in (1, 22):\n            time_tuple = time.struct_time((1999,3,17,hour,44,55,2,76,0))\n            am_pm.append(time.strftime(\"%p\", time_tuple).lower())\n        self.am_pm = am_pm\n\n    def __calc_date_time(self):\n        # Set self.date_time, self.date, & self.time by using\n        # time.strftime().\n\n        # Use (1999,3,17,22,44,55,2,76,0) for magic date because the amount of\n        # overloaded numbers is minimized.  The order in which searches for\n        # values within the format string is very important; it eliminates\n        # possible ambiguity for what something represents.\n        time_tuple = time.struct_time((1999,3,17,22,44,55,2,76,0))\n        date_time = [None, None, None]\n        date_time[0] = time.strftime(\"%c\", time_tuple).lower()\n        date_time[1] = time.strftime(\"%x\", time_tuple).lower()\n        date_time[2] = time.strftime(\"%X\", time_tuple).lower()\n        replacement_pairs = [('%', '%%'), (self.f_weekday[2], '%A'),\n                    (self.f_month[3], '%B'), (self.a_weekday[2], '%a'),\n                    (self.a_month[3], '%b'), (self.am_pm[1], '%p'),\n                    ('1999', '%Y'), ('99', '%y'), ('22', '%H'),\n                    ('44', '%M'), ('55', '%S'), ('76', '%j'),\n                    ('17', '%d'), ('03', '%m'), ('3', '%m'),\n                    # '3' needed for when no leading zero.\n                    ('2', '%w'), ('10', '%I')]\n        replacement_pairs.extend([(tz, \"%Z\") for tz_values in self.timezone\n                                                for tz in tz_values])\n        for offset,directive in ((0,'%c'), (1,'%x'), (2,'%X')):\n            current_format = date_time[offset]\n            for old, new in replacement_pairs:\n                # Must deal with possible lack of locale info\n                # manifesting itself as the empty string (e.g., Swedish's\n                # lack of AM/PM info) or a platform returning a tuple of empty\n                # strings (e.g., MacOS 9 having timezone as ('','')).\n                if old:\n                    current_format = current_format.replace(old, new)\n            # If %W is used, then Sunday, 2005-01-03 will fall on week 0 since\n            # 2005-01-03 occurs before the first Monday of the year.  Otherwise\n            # %U is used.\n            time_tuple = time.struct_time((1999,1,3,1,1,1,6,3,0))\n            if '00' in time.strftime(directive, time_tuple):\n                U_W = '%W'\n            else:\n                U_W = '%U'\n            date_time[offset] = current_format.replace('11', U_W)\n        self.LC_date_time = date_time[0]\n        self.LC_date = date_time[1]\n        self.LC_time = date_time[2]\n\n    def __calc_timezone(self):\n        # Set self.timezone by using time.tzname.\n        # Do not worry about possibility of time.tzname[0] == timetzname[1]\n        # and time.daylight; handle that in strptime .\n        try:\n            time.tzset()\n        except AttributeError:\n            pass\n        no_saving = frozenset([\"utc\", \"gmt\", time.tzname[0].lower()])\n        if time.daylight:\n            has_saving = frozenset([time.tzname[1].lower()])\n        else:\n            has_saving = frozenset()\n        self.timezone = (no_saving, has_saving)\n\n\nclass TimeRE(dict):\n    \"\"\"Handle conversion from format directives to regexes.\"\"\"\n\n    def __init__(self, locale_time=None):\n        \"\"\"Create keys/values.\n\n        Order of execution is important for dependency reasons.\n\n        \"\"\"\n        if locale_time:\n            self.locale_time = locale_time\n        else:\n            self.locale_time = LocaleTime()\n        base = super()\n        base.__init__({\n            # The \" \\d\" part of the regex is to make %c from ANSI C work\n            'd': r\"(?P<d>3[0-1]|[1-2]\\d|0[1-9]|[1-9]| [1-9])\",\n            'f': r\"(?P<f>[0-9]{1,6})\",\n            'H': r\"(?P<H>2[0-3]|[0-1]\\d|\\d)\",\n            'I': r\"(?P<I>1[0-2]|0[1-9]|[1-9])\",\n            'j': r\"(?P<j>36[0-6]|3[0-5]\\d|[1-2]\\d\\d|0[1-9]\\d|00[1-9]|[1-9]\\d|0[1-9]|[1-9])\",\n            'm': r\"(?P<m>1[0-2]|0[1-9]|[1-9])\",\n            'M': r\"(?P<M>[0-5]\\d|\\d)\",\n            'S': r\"(?P<S>6[0-1]|[0-5]\\d|\\d)\",\n            'U': r\"(?P<U>5[0-3]|[0-4]\\d|\\d)\",\n            'w': r\"(?P<w>[0-6])\",\n            # W is set below by using 'U'\n            'y': r\"(?P<y>\\d\\d)\",\n            #XXX: Does 'Y' need to worry about having less or more than\n            #     4 digits?\n            'Y': r\"(?P<Y>\\d\\d\\d\\d)\",\n            'z': r\"(?P<z>[+-]\\d\\d[0-5]\\d)\",\n            'A': self.__seqToRE(self.locale_time.f_weekday, 'A'),\n            'a': self.__seqToRE(self.locale_time.a_weekday, 'a'),\n            'B': self.__seqToRE(self.locale_time.f_month[1:], 'B'),\n            'b': self.__seqToRE(self.locale_time.a_month[1:], 'b'),\n            'p': self.__seqToRE(self.locale_time.am_pm, 'p'),\n            'Z': self.__seqToRE((tz for tz_names in self.locale_time.timezone\n                                        for tz in tz_names),\n                                'Z'),\n            '%': '%'})\n        base.__setitem__('W', base.__getitem__('U').replace('U', 'W'))\n        base.__setitem__('c', self.pattern(self.locale_time.LC_date_time))\n        base.__setitem__('x', self.pattern(self.locale_time.LC_date))\n        base.__setitem__('X', self.pattern(self.locale_time.LC_time))\n\n    def __seqToRE(self, to_convert, directive):\n        \"\"\"Convert a list to a regex string for matching a directive.\n\n        Want possible matching values to be from longest to shortest.  This\n        prevents the possibility of a match occurring for a value that also\n        a substring of a larger value that should have matched (e.g., 'abc'\n        matching when 'abcdef' should have been the match).\n\n        \"\"\"\n        to_convert = sorted(to_convert, key=len, reverse=True)\n        for value in to_convert:\n            if value != '':\n                break\n        else:\n            return ''\n        regex = '|'.join(re_escape(stuff) for stuff in to_convert)\n        regex = '(?P<%s>%s' % (directive, regex)\n        return '%s)' % regex\n\n    def pattern(self, format):\n        \"\"\"Return regex pattern for the format string.\n\n        Need to make sure that any characters that might be interpreted as\n        regex syntax are escaped.\n\n        \"\"\"\n        processed_format = ''\n        # The sub() call escapes all characters that might be misconstrued\n        # as regex syntax.  Cannot use re.escape since we have to deal with\n        # format directives (%m, etc.).\n        regex_chars = re_compile(r\"([\\\\.^$*+?\\(\\){}\\[\\]|])\")\n        format = regex_chars.sub(r\"\\\\\\1\", format)\n        whitespace_replacement = re_compile('\\s+')\n        format = whitespace_replacement.sub('\\s+', format)\n        while '%' in format:\n            directive_index = format.index('%')+1\n            processed_format = \"%s%s%s\" % (processed_format,\n                                           format[:directive_index-1],\n                                           self[format[directive_index]])\n            format = format[directive_index+1:]\n        return \"%s%s\" % (processed_format, format)\n\n    def compile(self, format):\n        \"\"\"Return a compiled re object for the format string.\"\"\"\n        return re_compile(self.pattern(format), IGNORECASE)\n\n_cache_lock = _thread_allocate_lock()\n# DO NOT modify _TimeRE_cache or _regex_cache without acquiring the cache lock\n# first!\n_TimeRE_cache = TimeRE()\n_CACHE_MAX_SIZE = 5 # Max number of regexes stored in _regex_cache\n_regex_cache = {}\n\ndef _calc_julian_from_U_or_W(year, week_of_year, day_of_week, week_starts_Mon):\n    \"\"\"Calculate the Julian day based on the year, week of the year, and day of\n    the week, with week_start_day representing whether the week of the year\n    assumes the week starts on Sunday or Monday (6 or 0).\"\"\"\n    first_weekday = datetime_date(year, 1, 1).weekday()\n    # If we are dealing with the %U directive (week starts on Sunday), it's\n    # easier to just shift the view to Sunday being the first day of the\n    # week.\n    if not week_starts_Mon:\n        first_weekday = (first_weekday + 1) % 7\n        day_of_week = (day_of_week + 1) % 7\n    # Need to watch out for a week 0 (when the first day of the year is not\n    # the same as that specified by %U or %W).\n    week_0_length = (7 - first_weekday) % 7\n    if week_of_year == 0:\n        return 1 + day_of_week - first_weekday\n    else:\n        days_to_week = week_0_length + (7 * (week_of_year - 1))\n        return 1 + days_to_week + day_of_week\n\n\ndef _strptime(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n    \"\"\"Return a 2-tuple consisting of a time struct and an int containing\n    the number of microseconds based on the input string and the\n    format string.\"\"\"\n\n    for index, arg in enumerate([data_string, format]):\n        if not isinstance(arg, str):\n            msg = \"strptime() argument {} must be str, not {}\"\n            raise TypeError(msg.format(index, type(arg)))\n\n    global _TimeRE_cache, _regex_cache\n    with _cache_lock:\n\n        if _getlang() != _TimeRE_cache.locale_time.lang:\n            _TimeRE_cache = TimeRE()\n            _regex_cache.clear()\n        if len(_regex_cache) > _CACHE_MAX_SIZE:\n            _regex_cache.clear()\n        locale_time = _TimeRE_cache.locale_time\n        format_regex = _regex_cache.get(format)\n        if not format_regex:\n            try:\n                format_regex = _TimeRE_cache.compile(format)\n            # KeyError raised when a bad format is found; can be specified as\n            # \\\\, in which case it was a stray % but with a space after it\n            except KeyError as err:\n                bad_directive = err.args[0]\n                if bad_directive == \"\\\\\":\n                    bad_directive = \"%\"\n                del err\n                raise ValueError(\"'%s' is a bad directive in format '%s'\" %\n                                    (bad_directive, format)) from None\n            # IndexError only occurs when the format string is \"%\"\n            except IndexError:\n                raise ValueError(\"stray %% in format '%s'\" % format) from None\n            _regex_cache[format] = format_regex\n    found = format_regex.match(data_string)\n    if not found:\n        raise ValueError(\"time data %r does not match format %r\" %\n                         (data_string, format))\n    if len(data_string) != found.end():\n        raise ValueError(\"unconverted data remains: %s\" %\n                          data_string[found.end():])\n\n    year = None\n    month = day = 1\n    hour = minute = second = fraction = 0\n    tz = -1\n    tzoffset = None\n    # Default to -1 to signify that values not known; not critical to have,\n    # though\n    week_of_year = -1\n    week_of_year_start = -1\n    # weekday and julian defaulted to -1 so as to signal need to calculate\n    # values\n    weekday = julian = -1\n    found_dict = found.groupdict()\n    for group_key in found_dict.keys():\n        # Directives not explicitly handled below:\n        #   c, x, X\n        #      handled by making out of other directives\n        #   U, W\n        #      worthless without day of the week\n        if group_key == 'y':\n            year = int(found_dict['y'])\n            # Open Group specification for strptime() states that a %y\n            #value in the range of [00, 68] is in the century 2000, while\n            #[69,99] is in the century 1900\n            if year <= 68:\n                year += 2000\n            else:\n                year += 1900\n        elif group_key == 'Y':\n            year = int(found_dict['Y'])\n        elif group_key == 'm':\n            month = int(found_dict['m'])\n        elif group_key == 'B':\n            month = locale_time.f_month.index(found_dict['B'].lower())\n        elif group_key == 'b':\n            month = locale_time.a_month.index(found_dict['b'].lower())\n        elif group_key == 'd':\n            day = int(found_dict['d'])\n        elif group_key == 'H':\n            hour = int(found_dict['H'])\n        elif group_key == 'I':\n            hour = int(found_dict['I'])\n            ampm = found_dict.get('p', '').lower()\n            # If there was no AM/PM indicator, we'll treat this like AM\n            if ampm in ('', locale_time.am_pm[0]):\n                # We're in AM so the hour is correct unless we're\n                # looking at 12 midnight.\n                # 12 midnight == 12 AM == hour 0\n                if hour == 12:\n                    hour = 0\n            elif ampm == locale_time.am_pm[1]:\n                # We're in PM so we need to add 12 to the hour unless\n                # we're looking at 12 noon.\n                # 12 noon == 12 PM == hour 12\n                if hour != 12:\n                    hour += 12\n        elif group_key == 'M':\n            minute = int(found_dict['M'])\n        elif group_key == 'S':\n            second = int(found_dict['S'])\n        elif group_key == 'f':\n            s = found_dict['f']\n            # Pad to always return microseconds.\n            s += \"0\" * (6 - len(s))\n            fraction = int(s)\n        elif group_key == 'A':\n            weekday = locale_time.f_weekday.index(found_dict['A'].lower())\n        elif group_key == 'a':\n            weekday = locale_time.a_weekday.index(found_dict['a'].lower())\n        elif group_key == 'w':\n            weekday = int(found_dict['w'])\n            if weekday == 0:\n                weekday = 6\n            else:\n                weekday -= 1\n        elif group_key == 'j':\n            julian = int(found_dict['j'])\n        elif group_key in ('U', 'W'):\n            week_of_year = int(found_dict[group_key])\n            if group_key == 'U':\n                # U starts week on Sunday.\n                week_of_year_start = 6\n            else:\n                # W starts week on Monday.\n                week_of_year_start = 0\n        elif group_key == 'z':\n            z = found_dict['z']\n            tzoffset = int(z[1:3]) * 60 + int(z[3:5])\n            if z.startswith(\"-\"):\n                tzoffset = -tzoffset\n        elif group_key == 'Z':\n            # Since -1 is default value only need to worry about setting tz if\n            # it can be something other than -1.\n            found_zone = found_dict['Z'].lower()\n            for value, tz_values in enumerate(locale_time.timezone):\n                if found_zone in tz_values:\n                    # Deal with bad locale setup where timezone names are the\n                    # same and yet time.daylight is true; too ambiguous to\n                    # be able to tell what timezone has daylight savings\n                    if (time.tzname[0] == time.tzname[1] and\n                       time.daylight and found_zone not in (\"utc\", \"gmt\")):\n                        break\n                    else:\n                        tz = value\n                        break\n    leap_year_fix = False\n    if year is None and month == 2 and day == 29:\n        year = 1904  # 1904 is first leap year of 20th century\n        leap_year_fix = True\n    elif year is None:\n        year = 1900\n    # If we know the week of the year and what day of that week, we can figure\n    # out the Julian day of the year.\n    if julian == -1 and week_of_year != -1 and weekday != -1:\n        week_starts_Mon = True if week_of_year_start == 0 else False\n        julian = _calc_julian_from_U_or_W(year, week_of_year, weekday,\n                                            week_starts_Mon)\n    # Cannot pre-calculate datetime_date() since can change in Julian\n    # calculation and thus could have different value for the day of the week\n    # calculation.\n    if julian == -1:\n        # Need to add 1 to result since first day of the year is 1, not 0.\n        julian = datetime_date(year, month, day).toordinal() - \\\n                  datetime_date(year, 1, 1).toordinal() + 1\n    else:  # Assume that if they bothered to include Julian day it will\n           # be accurate.\n        datetime_result = datetime_date.fromordinal((julian - 1) + datetime_date(year, 1, 1).toordinal())\n        year = datetime_result.year\n        month = datetime_result.month\n        day = datetime_result.day\n    if weekday == -1:\n        weekday = datetime_date(year, month, day).weekday()\n    # Add timezone info\n    tzname = found_dict.get(\"Z\")\n    if tzoffset is not None:\n        gmtoff = tzoffset * 60\n    else:\n        gmtoff = None\n\n    if leap_year_fix:\n        # the caller didn't supply a year but asked for Feb 29th. We couldn't\n        # use the default of 1900 for computations. We set it back to ensure\n        # that February 29th is smaller than March 1st.\n        year = 1900\n\n    return (year, month, day,\n            hour, minute, second,\n            weekday, julian, tz, tzname, gmtoff), fraction\n\ndef _strptime_time(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n    \"\"\"Return a time struct based on the input string and the\n    format string.\"\"\"\n    tt = _strptime(data_string, format)[0]\n    return time.struct_time(tt[:time._STRUCT_TM_ITEMS])\n\ndef _strptime_datetime(cls, data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n    \"\"\"Return a class cls instance based on the input string and the\n    format string.\"\"\"\n    tt, fraction = _strptime(data_string, format)\n    tzname, gmtoff = tt[-2:]\n    args = tt[:6] + (fraction,)\n    if gmtoff is not None:\n        tzdelta = datetime_timedelta(seconds=gmtoff)\n        if tzname:\n            tz = datetime_timezone(tzdelta, tzname)\n        else:\n            tz = datetime_timezone(tzdelta)\n        args += (tz,)\n\n    return cls(*args)\n"], "unittest.test.test_assertions": [".py", "import datetime\nimport warnings\nimport unittest\nfrom itertools import product\n\n\nclass Test_Assertions(unittest.TestCase):\n    def test_AlmostEqual(self):\n        self.assertAlmostEqual(1.00000001, 1.0)\n        self.assertNotAlmostEqual(1.0000001, 1.0)\n        self.assertRaises(self.failureException,\n                          self.assertAlmostEqual, 1.0000001, 1.0)\n        self.assertRaises(self.failureException,\n                          self.assertNotAlmostEqual, 1.00000001, 1.0)\n\n        self.assertAlmostEqual(1.1, 1.0, places=0)\n        self.assertRaises(self.failureException,\n                          self.assertAlmostEqual, 1.1, 1.0, places=1)\n\n        self.assertAlmostEqual(0, .1+.1j, places=0)\n        self.assertNotAlmostEqual(0, .1+.1j, places=1)\n        self.assertRaises(self.failureException,\n                          self.assertAlmostEqual, 0, .1+.1j, places=1)\n        self.assertRaises(self.failureException,\n                          self.assertNotAlmostEqual, 0, .1+.1j, places=0)\n\n        self.assertAlmostEqual(float('inf'), float('inf'))\n        self.assertRaises(self.failureException, self.assertNotAlmostEqual,\n                          float('inf'), float('inf'))\n\n    def test_AmostEqualWithDelta(self):\n        self.assertAlmostEqual(1.1, 1.0, delta=0.5)\n        self.assertAlmostEqual(1.0, 1.1, delta=0.5)\n        self.assertNotAlmostEqual(1.1, 1.0, delta=0.05)\n        self.assertNotAlmostEqual(1.0, 1.1, delta=0.05)\n\n        self.assertRaises(self.failureException, self.assertAlmostEqual,\n                          1.1, 1.0, delta=0.05)\n        self.assertRaises(self.failureException, self.assertNotAlmostEqual,\n                          1.1, 1.0, delta=0.5)\n\n        self.assertRaises(TypeError, self.assertAlmostEqual,\n                          1.1, 1.0, places=2, delta=2)\n        self.assertRaises(TypeError, self.assertNotAlmostEqual,\n                          1.1, 1.0, places=2, delta=2)\n\n        first = datetime.datetime.now()\n        second = first + datetime.timedelta(seconds=10)\n        self.assertAlmostEqual(first, second,\n                               delta=datetime.timedelta(seconds=20))\n        self.assertNotAlmostEqual(first, second,\n                                  delta=datetime.timedelta(seconds=5))\n\n    def test_assertRaises(self):\n        def _raise(e):\n            raise e\n        self.assertRaises(KeyError, _raise, KeyError)\n        self.assertRaises(KeyError, _raise, KeyError(\"key\"))\n        try:\n            self.assertRaises(KeyError, lambda: None)\n        except self.failureException as e:\n            self.assertIn(\"KeyError not raised\", str(e))\n        else:\n            self.fail(\"assertRaises() didn't fail\")\n        try:\n            self.assertRaises(KeyError, _raise, ValueError)\n        except ValueError:\n            pass\n        else:\n            self.fail(\"assertRaises() didn't let exception pass through\")\n        with self.assertRaises(KeyError) as cm:\n            try:\n                raise KeyError\n            except Exception as e:\n                exc = e\n                raise\n        self.assertIs(cm.exception, exc)\n\n        with self.assertRaises(KeyError):\n            raise KeyError(\"key\")\n        try:\n            with self.assertRaises(KeyError):\n                pass\n        except self.failureException as e:\n            self.assertIn(\"KeyError not raised\", str(e))\n        else:\n            self.fail(\"assertRaises() didn't fail\")\n        try:\n            with self.assertRaises(KeyError):\n                raise ValueError\n        except ValueError:\n            pass\n        else:\n            self.fail(\"assertRaises() didn't let exception pass through\")\n\n    def testAssertNotRegex(self):\n        self.assertNotRegex('Ala ma kota', r'r+')\n        try:\n            self.assertNotRegex('Ala ma kota', r'k.t', 'Message')\n        except self.failureException as e:\n            self.assertIn(\"'kot'\", e.args[0])\n            self.assertIn('Message', e.args[0])\n        else:\n            self.fail('assertNotRegex should have failed.')\n\n\nclass TestLongMessage(unittest.TestCase):\n    \"\"\"Test that the individual asserts honour longMessage.\n    This actually tests all the message behaviour for\n    asserts that use longMessage.\"\"\"\n\n    def setUp(self):\n        class TestableTestFalse(unittest.TestCase):\n            longMessage = False\n            failureException = self.failureException\n\n            def testTest(self):\n                pass\n\n        class TestableTestTrue(unittest.TestCase):\n            longMessage = True\n            failureException = self.failureException\n\n            def testTest(self):\n                pass\n\n        self.testableTrue = TestableTestTrue('testTest')\n        self.testableFalse = TestableTestFalse('testTest')\n\n    def testDefault(self):\n        self.assertTrue(unittest.TestCase.longMessage)\n\n    def test_formatMsg(self):\n        self.assertEqual(self.testableFalse._formatMessage(None, \"foo\"), \"foo\")\n        self.assertEqual(self.testableFalse._formatMessage(\"foo\", \"bar\"), \"foo\")\n\n        self.assertEqual(self.testableTrue._formatMessage(None, \"foo\"), \"foo\")\n        self.assertEqual(self.testableTrue._formatMessage(\"foo\", \"bar\"), \"bar : foo\")\n\n        # This blows up if _formatMessage uses string concatenation\n        self.testableTrue._formatMessage(object(), 'foo')\n\n    def test_formatMessage_unicode_error(self):\n        one = ''.join(chr(i) for i in range(255))\n        # this used to cause a UnicodeDecodeError constructing msg\n        self.testableTrue._formatMessage(one, '\\uFFFD')\n\n    def assertMessages(self, methodName, args, errors):\n        \"\"\"\n        Check that methodName(*args) raises the correct error messages.\n        errors should be a list of 4 regex that match the error when:\n          1) longMessage = False and no msg passed;\n          2) longMessage = False and msg passed;\n          3) longMessage = True and no msg passed;\n          4) longMessage = True and msg passed;\n        \"\"\"\n        def getMethod(i):\n            useTestableFalse  = i < 2\n            if useTestableFalse:\n                test = self.testableFalse\n            else:\n                test = self.testableTrue\n            return getattr(test, methodName)\n\n        for i, expected_regex in enumerate(errors):\n            testMethod = getMethod(i)\n            kwargs = {}\n            withMsg = i % 2\n            if withMsg:\n                kwargs = {\"msg\": \"oops\"}\n\n            with self.assertRaisesRegex(self.failureException,\n                                        expected_regex=expected_regex):\n                testMethod(*args, **kwargs)\n\n    def testAssertTrue(self):\n        self.assertMessages('assertTrue', (False,),\n                            [\"^False is not true$\", \"^oops$\", \"^False is not true$\",\n                             \"^False is not true : oops$\"])\n\n    def testAssertFalse(self):\n        self.assertMessages('assertFalse', (True,),\n                            [\"^True is not false$\", \"^oops$\", \"^True is not false$\",\n                             \"^True is not false : oops$\"])\n\n    def testNotEqual(self):\n        self.assertMessages('assertNotEqual', (1, 1),\n                            [\"^1 == 1$\", \"^oops$\", \"^1 == 1$\",\n                             \"^1 == 1 : oops$\"])\n\n    def testAlmostEqual(self):\n        self.assertMessages('assertAlmostEqual', (1, 2),\n                            [\"^1 != 2 within 7 places$\", \"^oops$\",\n                             \"^1 != 2 within 7 places$\", \"^1 != 2 within 7 places : oops$\"])\n\n    def testNotAlmostEqual(self):\n        self.assertMessages('assertNotAlmostEqual', (1, 1),\n                            [\"^1 == 1 within 7 places$\", \"^oops$\",\n                             \"^1 == 1 within 7 places$\", \"^1 == 1 within 7 places : oops$\"])\n\n    def test_baseAssertEqual(self):\n        self.assertMessages('_baseAssertEqual', (1, 2),\n                            [\"^1 != 2$\", \"^oops$\", \"^1 != 2$\", \"^1 != 2 : oops$\"])\n\n    def testAssertSequenceEqual(self):\n        # Error messages are multiline so not testing on full message\n        # assertTupleEqual and assertListEqual delegate to this method\n        self.assertMessages('assertSequenceEqual', ([], [None]),\n                            [\"\\+ \\[None\\]$\", \"^oops$\", r\"\\+ \\[None\\]$\",\n                             r\"\\+ \\[None\\] : oops$\"])\n\n    def testAssertSetEqual(self):\n        self.assertMessages('assertSetEqual', (set(), set([None])),\n                            [\"None$\", \"^oops$\", \"None$\",\n                             \"None : oops$\"])\n\n    def testAssertIn(self):\n        self.assertMessages('assertIn', (None, []),\n                            ['^None not found in \\[\\]$', \"^oops$\",\n                             '^None not found in \\[\\]$',\n                             '^None not found in \\[\\] : oops$'])\n\n    def testAssertNotIn(self):\n        self.assertMessages('assertNotIn', (None, [None]),\n                            ['^None unexpectedly found in \\[None\\]$', \"^oops$\",\n                             '^None unexpectedly found in \\[None\\]$',\n                             '^None unexpectedly found in \\[None\\] : oops$'])\n\n    def testAssertDictEqual(self):\n        self.assertMessages('assertDictEqual', ({}, {'key': 'value'}),\n                            [r\"\\+ \\{'key': 'value'\\}$\", \"^oops$\",\n                             \"\\+ \\{'key': 'value'\\}$\",\n                             \"\\+ \\{'key': 'value'\\} : oops$\"])\n\n    def testAssertDictContainsSubset(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", DeprecationWarning)\n\n            self.assertMessages('assertDictContainsSubset', ({'key': 'value'}, {}),\n                                [\"^Missing: 'key'$\", \"^oops$\",\n                                 \"^Missing: 'key'$\",\n                                 \"^Missing: 'key' : oops$\"])\n\n    def testAssertMultiLineEqual(self):\n        self.assertMessages('assertMultiLineEqual', (\"\", \"foo\"),\n                            [r\"\\+ foo$\", \"^oops$\",\n                             r\"\\+ foo$\",\n                             r\"\\+ foo : oops$\"])\n\n    def testAssertLess(self):\n        self.assertMessages('assertLess', (2, 1),\n                            [\"^2 not less than 1$\", \"^oops$\",\n                             \"^2 not less than 1$\", \"^2 not less than 1 : oops$\"])\n\n    def testAssertLessEqual(self):\n        self.assertMessages('assertLessEqual', (2, 1),\n                            [\"^2 not less than or equal to 1$\", \"^oops$\",\n                             \"^2 not less than or equal to 1$\",\n                             \"^2 not less than or equal to 1 : oops$\"])\n\n    def testAssertGreater(self):\n        self.assertMessages('assertGreater', (1, 2),\n                            [\"^1 not greater than 2$\", \"^oops$\",\n                             \"^1 not greater than 2$\",\n                             \"^1 not greater than 2 : oops$\"])\n\n    def testAssertGreaterEqual(self):\n        self.assertMessages('assertGreaterEqual', (1, 2),\n                            [\"^1 not greater than or equal to 2$\", \"^oops$\",\n                             \"^1 not greater than or equal to 2$\",\n                             \"^1 not greater than or equal to 2 : oops$\"])\n\n    def testAssertIsNone(self):\n        self.assertMessages('assertIsNone', ('not None',),\n                            [\"^'not None' is not None$\", \"^oops$\",\n                             \"^'not None' is not None$\",\n                             \"^'not None' is not None : oops$\"])\n\n    def testAssertIsNotNone(self):\n        self.assertMessages('assertIsNotNone', (None,),\n                            [\"^unexpectedly None$\", \"^oops$\",\n                             \"^unexpectedly None$\",\n                             \"^unexpectedly None : oops$\"])\n\n    def testAssertIs(self):\n        self.assertMessages('assertIs', (None, 'foo'),\n                            [\"^None is not 'foo'$\", \"^oops$\",\n                             \"^None is not 'foo'$\",\n                             \"^None is not 'foo' : oops$\"])\n\n    def testAssertIsNot(self):\n        self.assertMessages('assertIsNot', (None, None),\n                            [\"^unexpectedly identical: None$\", \"^oops$\",\n                             \"^unexpectedly identical: None$\",\n                             \"^unexpectedly identical: None : oops$\"])\n\n\n    def assertMessagesCM(self, methodName, args, func, errors):\n        \"\"\"\n        Check that the correct error messages are raised while executing:\n          with method(*args):\n              func()\n        *errors* should be a list of 4 regex that match the error when:\n          1) longMessage = False and no msg passed;\n          2) longMessage = False and msg passed;\n          3) longMessage = True and no msg passed;\n          4) longMessage = True and msg passed;\n        \"\"\"\n        p = product((self.testableFalse, self.testableTrue),\n                    ({}, {\"msg\": \"oops\"}))\n        for (cls, kwargs), err in zip(p, errors):\n            method = getattr(cls, methodName)\n            with self.assertRaisesRegex(cls.failureException, err):\n                with method(*args, **kwargs) as cm:\n                    func()\n\n    def testAssertRaises(self):\n        self.assertMessagesCM('assertRaises', (TypeError,), lambda: None,\n                              ['^TypeError not raised$', '^oops$',\n                               '^TypeError not raised$',\n                               '^TypeError not raised : oops$'])\n\n    def testAssertRaisesRegex(self):\n        # test error not raised\n        self.assertMessagesCM('assertRaisesRegex', (TypeError, 'unused regex'),\n                              lambda: None,\n                              ['^TypeError not raised$', '^oops$',\n                               '^TypeError not raised$',\n                               '^TypeError not raised : oops$'])\n        # test error raised but with wrong message\n        def raise_wrong_message():\n            raise TypeError('foo')\n        self.assertMessagesCM('assertRaisesRegex', (TypeError, 'regex'),\n                              raise_wrong_message,\n                              ['^\"regex\" does not match \"foo\"$', '^oops$',\n                               '^\"regex\" does not match \"foo\"$',\n                               '^\"regex\" does not match \"foo\" : oops$'])\n\n    def testAssertWarns(self):\n        self.assertMessagesCM('assertWarns', (UserWarning,), lambda: None,\n                              ['^UserWarning not triggered$', '^oops$',\n                               '^UserWarning not triggered$',\n                               '^UserWarning not triggered : oops$'])\n\n    def testAssertWarnsRegex(self):\n        # test error not raised\n        self.assertMessagesCM('assertWarnsRegex', (UserWarning, 'unused regex'),\n                              lambda: None,\n                              ['^UserWarning not triggered$', '^oops$',\n                               '^UserWarning not triggered$',\n                               '^UserWarning not triggered : oops$'])\n        # test warning raised but with wrong message\n        def raise_wrong_message():\n            warnings.warn('foo')\n        self.assertMessagesCM('assertWarnsRegex', (UserWarning, 'regex'),\n                              raise_wrong_message,\n                              ['^\"regex\" does not match \"foo\"$', '^oops$',\n                               '^\"regex\" does not match \"foo\"$',\n                               '^\"regex\" does not match \"foo\" : oops$'])\n"], "unittest.test.testmock.testmagicmethods": [".py", "import unittest\nimport inspect\nimport sys\nfrom unittest.mock import Mock, MagicMock, _magics\n\n\n\nclass TestMockingMagicMethods(unittest.TestCase):\n\n    def test_deleting_magic_methods(self):\n        mock = Mock()\n        self.assertFalse(hasattr(mock, '__getitem__'))\n\n        mock.__getitem__ = Mock()\n        self.assertTrue(hasattr(mock, '__getitem__'))\n\n        del mock.__getitem__\n        self.assertFalse(hasattr(mock, '__getitem__'))\n\n\n    def test_magicmock_del(self):\n        mock = MagicMock()\n        # before using getitem\n        del mock.__getitem__\n        self.assertRaises(TypeError, lambda: mock['foo'])\n\n        mock = MagicMock()\n        # this time use it first\n        mock['foo']\n        del mock.__getitem__\n        self.assertRaises(TypeError, lambda: mock['foo'])\n\n\n    def test_magic_method_wrapping(self):\n        mock = Mock()\n        def f(self, name):\n            return self, 'fish'\n\n        mock.__getitem__ = f\n        self.assertFalse(mock.__getitem__ is f)\n        self.assertEqual(mock['foo'], (mock, 'fish'))\n        self.assertEqual(mock.__getitem__('foo'), (mock, 'fish'))\n\n        mock.__getitem__ = mock\n        self.assertTrue(mock.__getitem__ is mock)\n\n\n    def test_magic_methods_isolated_between_mocks(self):\n        mock1 = Mock()\n        mock2 = Mock()\n\n        mock1.__iter__ = Mock(return_value=iter([]))\n        self.assertEqual(list(mock1), [])\n        self.assertRaises(TypeError, lambda: list(mock2))\n\n\n    def test_repr(self):\n        mock = Mock()\n        self.assertEqual(repr(mock), \"<Mock id='%s'>\" % id(mock))\n        mock.__repr__ = lambda s: 'foo'\n        self.assertEqual(repr(mock), 'foo')\n\n\n    def test_str(self):\n        mock = Mock()\n        self.assertEqual(str(mock), object.__str__(mock))\n        mock.__str__ = lambda s: 'foo'\n        self.assertEqual(str(mock), 'foo')\n\n\n    def test_dict_methods(self):\n        mock = Mock()\n\n        self.assertRaises(TypeError, lambda: mock['foo'])\n        def _del():\n            del mock['foo']\n        def _set():\n            mock['foo'] = 3\n        self.assertRaises(TypeError, _del)\n        self.assertRaises(TypeError, _set)\n\n        _dict = {}\n        def getitem(s, name):\n            return _dict[name]\n        def setitem(s, name, value):\n            _dict[name] = value\n        def delitem(s, name):\n            del _dict[name]\n\n        mock.__setitem__ = setitem\n        mock.__getitem__ = getitem\n        mock.__delitem__ = delitem\n\n        self.assertRaises(KeyError, lambda: mock['foo'])\n        mock['foo'] = 'bar'\n        self.assertEqual(_dict, {'foo': 'bar'})\n        self.assertEqual(mock['foo'], 'bar')\n        del mock['foo']\n        self.assertEqual(_dict, {})\n\n\n    def test_numeric(self):\n        original = mock = Mock()\n        mock.value = 0\n\n        self.assertRaises(TypeError, lambda: mock + 3)\n\n        def add(self, other):\n            mock.value += other\n            return self\n        mock.__add__ = add\n        self.assertEqual(mock + 3, mock)\n        self.assertEqual(mock.value, 3)\n\n        del mock.__add__\n        def iadd(mock):\n            mock += 3\n        self.assertRaises(TypeError, iadd, mock)\n        mock.__iadd__ = add\n        mock += 6\n        self.assertEqual(mock, original)\n        self.assertEqual(mock.value, 9)\n\n        self.assertRaises(TypeError, lambda: 3 + mock)\n        mock.__radd__ = add\n        self.assertEqual(7 + mock, mock)\n        self.assertEqual(mock.value, 16)\n\n\n    def test_hash(self):\n        mock = Mock()\n        # test delegation\n        self.assertEqual(hash(mock), Mock.__hash__(mock))\n\n        def _hash(s):\n            return 3\n        mock.__hash__ = _hash\n        self.assertEqual(hash(mock), 3)\n\n\n    def test_nonzero(self):\n        m = Mock()\n        self.assertTrue(bool(m))\n\n        m.__bool__ = lambda s: False\n        self.assertFalse(bool(m))\n\n\n    def test_comparison(self):\n        mock = Mock()\n        def comp(s, o):\n            return True\n        mock.__lt__ = mock.__gt__ = mock.__le__ = mock.__ge__ = comp\n        self. assertTrue(mock < 3)\n        self. assertTrue(mock > 3)\n        self. assertTrue(mock <= 3)\n        self. assertTrue(mock >= 3)\n\n        self.assertRaises(TypeError, lambda: MagicMock() < object())\n        self.assertRaises(TypeError, lambda: object() < MagicMock())\n        self.assertRaises(TypeError, lambda: MagicMock() < MagicMock())\n        self.assertRaises(TypeError, lambda: MagicMock() > object())\n        self.assertRaises(TypeError, lambda: object() > MagicMock())\n        self.assertRaises(TypeError, lambda: MagicMock() > MagicMock())\n        self.assertRaises(TypeError, lambda: MagicMock() <= object())\n        self.assertRaises(TypeError, lambda: object() <= MagicMock())\n        self.assertRaises(TypeError, lambda: MagicMock() <= MagicMock())\n        self.assertRaises(TypeError, lambda: MagicMock() >= object())\n        self.assertRaises(TypeError, lambda: object() >= MagicMock())\n        self.assertRaises(TypeError, lambda: MagicMock() >= MagicMock())\n\n\n    def test_equality(self):\n        for mock in Mock(), MagicMock():\n            self.assertEqual(mock == mock, True)\n            self.assertIsInstance(mock == mock, bool)\n            self.assertEqual(mock != mock, False)\n            self.assertIsInstance(mock != mock, bool)\n            self.assertEqual(mock == object(), False)\n            self.assertEqual(mock != object(), True)\n\n            def eq(self, other):\n                return other == 3\n            mock.__eq__ = eq\n            self.assertTrue(mock == 3)\n            self.assertFalse(mock == 4)\n\n            def ne(self, other):\n                return other == 3\n            mock.__ne__ = ne\n            self.assertTrue(mock != 3)\n            self.assertFalse(mock != 4)\n\n        mock = MagicMock()\n        mock.__eq__.return_value = True\n        self.assertIsInstance(mock == 3, bool)\n        self.assertEqual(mock == 3, True)\n\n        mock.__ne__.return_value = False\n        self.assertIsInstance(mock != 3, bool)\n        self.assertEqual(mock != 3, False)\n\n\n    def test_len_contains_iter(self):\n        mock = Mock()\n\n        self.assertRaises(TypeError, len, mock)\n        self.assertRaises(TypeError, iter, mock)\n        self.assertRaises(TypeError, lambda: 'foo' in mock)\n\n        mock.__len__ = lambda s: 6\n        self.assertEqual(len(mock), 6)\n\n        mock.__contains__ = lambda s, o: o == 3\n        self.assertTrue(3 in mock)\n        self.assertFalse(6 in mock)\n\n        mock.__iter__ = lambda s: iter('foobarbaz')\n        self.assertEqual(list(mock), list('foobarbaz'))\n\n\n    def test_magicmock(self):\n        mock = MagicMock()\n\n        mock.__iter__.return_value = iter([1, 2, 3])\n        self.assertEqual(list(mock), [1, 2, 3])\n\n        getattr(mock, '__bool__').return_value = False\n        self.assertFalse(hasattr(mock, '__nonzero__'))\n        self.assertFalse(bool(mock))\n\n        for entry in _magics:\n            self.assertTrue(hasattr(mock, entry))\n        self.assertFalse(hasattr(mock, '__imaginery__'))\n\n\n    def test_magic_mock_equality(self):\n        mock = MagicMock()\n        self.assertIsInstance(mock == object(), bool)\n        self.assertIsInstance(mock != object(), bool)\n\n        self.assertEqual(mock == object(), False)\n        self.assertEqual(mock != object(), True)\n        self.assertEqual(mock == mock, True)\n        self.assertEqual(mock != mock, False)\n\n\n    def test_magicmock_defaults(self):\n        mock = MagicMock()\n        self.assertEqual(int(mock), 1)\n        self.assertEqual(complex(mock), 1j)\n        self.assertEqual(float(mock), 1.0)\n        self.assertNotIn(object(), mock)\n        self.assertEqual(len(mock), 0)\n        self.assertEqual(list(mock), [])\n        self.assertEqual(hash(mock), object.__hash__(mock))\n        self.assertEqual(str(mock), object.__str__(mock))\n        self.assertTrue(bool(mock))\n\n        # in Python 3 oct and hex use __index__\n        # so these tests are for __index__ in py3k\n        self.assertEqual(oct(mock), '0o1')\n        self.assertEqual(hex(mock), '0x1')\n        # how to test __sizeof__ ?\n\n\n    def test_magic_methods_and_spec(self):\n        class Iterable(object):\n            def __iter__(self):\n                pass\n\n        mock = Mock(spec=Iterable)\n        self.assertRaises(AttributeError, lambda: mock.__iter__)\n\n        mock.__iter__ = Mock(return_value=iter([]))\n        self.assertEqual(list(mock), [])\n\n        class NonIterable(object):\n            pass\n        mock = Mock(spec=NonIterable)\n        self.assertRaises(AttributeError, lambda: mock.__iter__)\n\n        def set_int():\n            mock.__int__ = Mock(return_value=iter([]))\n        self.assertRaises(AttributeError, set_int)\n\n        mock = MagicMock(spec=Iterable)\n        self.assertEqual(list(mock), [])\n        self.assertRaises(AttributeError, set_int)\n\n\n    def test_magic_methods_and_spec_set(self):\n        class Iterable(object):\n            def __iter__(self):\n                pass\n\n        mock = Mock(spec_set=Iterable)\n        self.assertRaises(AttributeError, lambda: mock.__iter__)\n\n        mock.__iter__ = Mock(return_value=iter([]))\n        self.assertEqual(list(mock), [])\n\n        class NonIterable(object):\n            pass\n        mock = Mock(spec_set=NonIterable)\n        self.assertRaises(AttributeError, lambda: mock.__iter__)\n\n        def set_int():\n            mock.__int__ = Mock(return_value=iter([]))\n        self.assertRaises(AttributeError, set_int)\n\n        mock = MagicMock(spec_set=Iterable)\n        self.assertEqual(list(mock), [])\n        self.assertRaises(AttributeError, set_int)\n\n\n    def test_setting_unsupported_magic_method(self):\n        mock = MagicMock()\n        def set_setattr():\n            mock.__setattr__ = lambda self, name: None\n        self.assertRaisesRegex(AttributeError,\n            \"Attempting to set unsupported magic method '__setattr__'.\",\n            set_setattr\n        )\n\n\n    def test_attributes_and_return_value(self):\n        mock = MagicMock()\n        attr = mock.foo\n        def _get_type(obj):\n            # the type of every mock (or magicmock) is a custom subclass\n            # so the real type is the second in the mro\n            return type(obj).__mro__[1]\n        self.assertEqual(_get_type(attr), MagicMock)\n\n        returned = mock()\n        self.assertEqual(_get_type(returned), MagicMock)\n\n\n    def test_magic_methods_are_magic_mocks(self):\n        mock = MagicMock()\n        self.assertIsInstance(mock.__getitem__, MagicMock)\n\n        mock[1][2].__getitem__.return_value = 3\n        self.assertEqual(mock[1][2][3], 3)\n\n\n    def test_magic_method_reset_mock(self):\n        mock = MagicMock()\n        str(mock)\n        self.assertTrue(mock.__str__.called)\n        mock.reset_mock()\n        self.assertFalse(mock.__str__.called)\n\n\n    def test_dir(self):\n        # overriding the default implementation\n        for mock in Mock(), MagicMock():\n            def _dir(self):\n                return ['foo']\n            mock.__dir__ = _dir\n            self.assertEqual(dir(mock), ['foo'])\n\n\n    @unittest.skipIf('PyPy' in sys.version, \"This fails differently on pypy\")\n    def test_bound_methods(self):\n        m = Mock()\n\n        # XXXX should this be an expected failure instead?\n\n        # this seems like it should work, but is hard to do without introducing\n        # other api inconsistencies. Failure message could be better though.\n        m.__iter__ = [3].__iter__\n        self.assertRaises(TypeError, iter, m)\n\n\n    def test_magic_method_type(self):\n        class Foo(MagicMock):\n            pass\n\n        foo = Foo()\n        self.assertIsInstance(foo.__int__, Foo)\n\n\n    def test_descriptor_from_class(self):\n        m = MagicMock()\n        type(m).__str__.return_value = 'foo'\n        self.assertEqual(str(m), 'foo')\n\n\n    def test_iterable_as_iter_return_value(self):\n        m = MagicMock()\n        m.__iter__.return_value = [1, 2, 3]\n        self.assertEqual(list(m), [1, 2, 3])\n        self.assertEqual(list(m), [1, 2, 3])\n\n        m.__iter__.return_value = iter([4, 5, 6])\n        self.assertEqual(list(m), [4, 5, 6])\n        self.assertEqual(list(m), [])\n\n\nif __name__ == '__main__':\n    unittest.main()\n"], "_browser": [".js", "var $module=(function($B) {\n  return {\n    alert:function(message){window.alert($B.builtins.str(message))},\n    confirm: function(message){return $B.JSObject(window.confirm(message))},\n    console:{log:function(data){window.console.log(data)}},\n    $$document:$B.$DOMNode(document),\n    doc: $B.$DOMNode(document),   //want to use document instead of doc\n    DOMEvent:$B.DOMEvent,\n    DOMNode:$B.DOMNode,\n    mouseCoords: function(ev){return $B.JSObject($mouseCoords(ev))},\n    prompt: function(message, default_value){\n        return $B.JSObject(window.prompt(message, default_value||''))\n    },\n    win: $B.win,\n    window: $B.win\n  }\n})(__BRYTHON__)\n"], "time": [".js", "var $module=(function($B){\n\nvar _b_ = $B.builtins\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\nvar stnames = ['tm_year','tm_mon','tm_mday','tm_hour','tm_min','tm_sec',\n    'tm_wday','tm_yday','tm_isdst']\n\nvar StructTimeDict = {__name__:'struct_time',__class__:$B.$type}\n\nStructTimeDict.__mro__ = [StructTimeDict,_b_.object.$dict]\n\nStructTimeDict.__getattr__ = function(self,name){\n    var ix = stnames.indexOf(name)\n    if(ix==-1){throw AttributeError(\n        \"'time.struct_time' object has no attribute '\"+name+\"'\")}\n    return StructTimeDict.__getitem__(self,ix)\n}\n\nStructTimeDict.__getitem__ = function(self, rank){\n    if(!typeof rank=='number'){throw _b_.TypeError(\n        'list indices must be integers, not '+$B.get_class(rank).__name__)\n    }\n    var res = self.value[rank]\n    if(res===undefined){throw _b_.KeyError(rank)}\n    return res\n}\n\nStructTimeDict.__repr__ = StructTimeDict.__str__ = function(self){\n    var res = 'time.struct_time('\n    var elts = []\n    for(var i=0;i<stnames.length;i++){\n        elts.push(stnames[i]+'='+self.value[i])\n    }\n    res += elts.join(', ')\n    return res+')'\n}\n\nfunction StructTime(args){\n    return {__class__:StructTimeDict, value: args}\n}\nStructTime.$type = $B.factory\nStructTime.$dict = StructTimeDict\nStructTimeDict.$factory = StructTime\n\nvar $mod = {\n    __name__ : 'time',\n    tzname: _b_.tuple(['', '']),\n    daylight: 0,      //fix me.. returns Non zero if DST timezone is defined\n    ctime: function(timestamp){\n       if (timestamp === undefined) {\n          timestamp=int(new Date().getTime()/1000);\n       }\n       var d=new Date(0);\n       d.setUTCSeconds(timestamp);\n       return d.toUTCString();\n    },\n    gmtime: function(){\n       var d=new Date();\n       return [d.getUTCFullYear(), d.getUTCMonth()+1, d.getUTCDate(),\n               d.getUTCHours(), d.getUTCMinutes(), d.getUTCSeconds(),\n               d.getUTCDay(), 0, 0]\n    },\n    perf_counter: function() {\n        return float((new Date()).getTime()/1000.0);\n    },\n\n    localtime : function(secs){\n       var d=new Date();\n       if (secs === undefined || secs === None){\n           return d.getTime()\n       } else {\n           d = new Date(secs * 1000)\n       }\n\n\n\n       // calculate if we are in daylight savings time or not.\n       // borrowed from http://stackoverflow.com/questions/11887934/check-if-daylight-saving-time-is-in-effect-and-if-it-is-for-how-many-hours\n       var jan = new Date(d.getFullYear(), 0, 1);\n       var jul = new Date(d.getFullYear(), 6, 1);\n       var dst=int(d.getTimezoneOffset() < Math.max(jan.getTimezoneOffset(), jul.getTimezoneOffset()));\n\n       return [d.getFullYear(), d.getMonth()+1, d.getDate(), d.getHours(),\n                    d.getMinutes(), d.getSeconds(), d.getDay(), 0, dst]\n       //fixme  (second to last value is 0 which is the number of days in this year..)\n    },\n    time : function(){return float((new Date().getTime())/1000)},\n\n    sleep : function(secs){},\n\n    strftime : function(format,arg){\n        function ns(arg,nb){\n            // left padding with 0\n            var res = arg.toString()\n            while(res.length<nb){res = '0'+res}\n            return res\n        }\n        if(arg){\n            var obj = new Date(arg[0],arg[1]-1,arg[2],arg[3],arg[4],arg[5],arg[6])\n        }else{\n            var obj=new Date()\n        }\n        var abb_weekdays = ['Su','Mo','Tu','We','Th','Fr','Sa']\n        var full_weekdays = ['Sunday','Monday','Tuesday','Wednesday',\n            'Thursday','Friday','Saturday']\n        var abb_months = ['Jan','Feb','Mar','Apr','May','Jun',\n            'Jul','Aug','Sep','Oct','Nov','Dec']\n        var full_months = ['January','February','March','April','May','June',\n            'July','August','September','October','November','December']\n        var res = format\n        res = res.replace(/%H/,ns(obj.getHours(),2))\n        res = res.replace(/%M/,ns(obj.getMinutes(),2))\n        res = res.replace(/%S/,ns(obj.getSeconds(),2))\n        res = res.replace(/%Y/,ns(obj.getFullYear(),4))\n        res = res.replace(/%y/,ns(obj.getFullYear(),4).substr(2))\n        res = res.replace(/%m/,ns(obj.getMonth()+1,2))\n        res = res.replace(/%d/,ns(obj.getDate(),2))\n        res = res.replace(/%a/,abb_weekdays[obj.getDay()])\n        res = res.replace(/%A/,full_weekdays[obj.getDay()])\n        res = res.replace(/%b/,abb_months[obj.getMonth()])\n        res = res.replace(/%B/,full_months[obj.getMonth()])\n        return res\n    },\n\n    struct_time : function(arg){\n        if(!isinstance(arg,[tuple,list])){\n            throw TypeError('constructor requires a sequence')\n        }\n        if(len(arg)!=9){\n            throw TypeError(\"time.struct_time() takes a 9-sequence (\"+len(arg)+\"-sequence given\")\n        }\n        var res = arg\n        var names = ['tm_year','tm_mon','tm_mday','tm_hour','tm_min','tm_sec','tm_wday',\n            'tm_yday','tm_isdst','tm_zone','tm_gmtoff']\n        res.__getattr__ = function(attr){\n            var ix = names.indexOf(attr)\n            if(ix>-1){return arg.__getitem__(ix)}\n            if(typeof res[attr]==='function'){\n                return (function(obj){\n                    return function(){return obj[attr].apply(obj,arguments)}\n                })(res)\n            }else if(res[attr]!==undefined){\n                return res[attr]\n            }else{throw AttributeError(\"object has no attribute '\"+attr+\"'\")}\n        }\n        return res\n    }\n}\n\nfunction to_struct_time(ptuple){\n    // Receives a packed tuple, pass its attribute \"arg\" to struct_time\n    var arg = ptuple.arg\n    // The tuple received from module _strptime has 7 elements, we must add\n    // the rank of day in the year in the range [1, 366]\n    var ml = [31,28,31,30,31,30,31,31,30,31,30,31]\n    if(arg[0]%4==0){ml[1]++}\n    console.log(ml)\n    var i=1, yday=0\n    while(i<arg[1]){yday+=ml[i-1];i++}\n    yday += arg[2]\n    arg.push(yday)\n    arg.push(-1)\n    return $mod.struct_time(arg)\n}\n\n$mod.strptime = function(string, format){\n    var _strptime = _b_.__import__('_strptime')\n    return StructTime(_strptime._strptime_datetime(to_struct_time, string, format))\n}\n\nreturn $mod\n})(__BRYTHON__)\n"], "pyre": [".py", "#\n# Secret Labs' Regular Expression Engine\n#\n# re-compatible interface for the sre matching engine\n#\n# Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\n#\n# This version of the SRE library can be redistributed under CNRI's\n# Python 1.6 license.  For any other use, please contact Secret Labs\n# AB (info@pythonware.com).\n#\n# Portions of this engine have been developed in cooperation with\n# CNRI.  Hewlett-Packard provided funding for 1.6 integration and\n# other compatibility work.\n#\n\nr\"\"\"Support for regular expressions (RE).\n\nThis module provides regular expression matching operations similar to\nthose found in Perl.  It supports both 8-bit and Unicode strings; both\nthe pattern and the strings being processed can contain null bytes and\ncharacters outside the US ASCII range.\n\nRegular expressions can contain both special and ordinary characters.\nMost ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\nregular expressions; they simply match themselves.  You can\nconcatenate ordinary characters, so last matches the string 'last'.\n\nThe special characters are:\n    \".\"      Matches any character except a newline.\n    \"^\"      Matches the start of the string.\n    \"$\"      Matches the end of the string or just before the newline at\n             the end of the string.\n    \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n             Greedy means that it will match as many repetitions as possible.\n    \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n    \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n    *?,+?,?? Non-greedy versions of the previous three special characters.\n    {m,n}    Matches from m to n repetitions of the preceding RE.\n    {m,n}?   Non-greedy version of the above.\n    \"\\\\\"     Either escapes special characters or signals a special sequence.\n    []       Indicates a set of characters.\n             A \"^\" as the first character indicates a complementing set.\n    \"|\"      A|B, creates an RE that will match either A or B.\n    (...)    Matches the RE inside the parentheses.\n             The contents can be retrieved or matched later in the string.\n    (?aiLmsux) Set the A, I, L, M, S, U, or X flag for the RE (see below).\n    (?:...)  Non-grouping version of regular parentheses.\n    (?P<name>...) The substring matched by the group is accessible by name.\n    (?P=name)     Matches the text matched earlier by the group named name.\n    (?#...)  A comment; ignored.\n    (?=...)  Matches if ... matches next, but doesn't consume the string.\n    (?!...)  Matches if ... doesn't match next.\n    (?<=...) Matches if preceded by ... (must be fixed length).\n    (?<!...) Matches if not preceded by ... (must be fixed length).\n    (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,\n                       the (optional) no pattern otherwise.\n\nThe special sequences consist of \"\\\\\" and a character from the list\nbelow.  If the ordinary character is not on the list, then the\nresulting RE will match the second character.\n    \\number  Matches the contents of the group of the same number.\n    \\A       Matches only at the start of the string.\n    \\Z       Matches only at the end of the string.\n    \\b       Matches the empty string, but only at the start or end of a word.\n    \\B       Matches the empty string, but not at the start or end of a word.\n    \\d       Matches any decimal digit; equivalent to the set [0-9] in\n             bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the whole\n             range of Unicode digits.\n    \\D       Matches any non-digit character; equivalent to [^\\d].\n    \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] in\n             bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the whole\n             range of Unicode whitespace characters.\n    \\S       Matches any non-whitespace character; equivalent to [^\\s].\n    \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]\n             in bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the\n             range of Unicode alphanumeric characters (letters plus digits\n             plus underscore).\n             With LOCALE, it will match the set [0-9_] plus characters defined\n             as letters for the current locale.\n    \\W       Matches the complement of \\w.\n    \\\\       Matches a literal backslash.\n\nThis module exports the following functions:\n    match    Match a regular expression pattern to the beginning of a string.\n    search   Search a string for the presence of a pattern.\n    sub      Substitute occurrences of a pattern found in a string.\n    subn     Same as sub, but also return the number of substitutions made.\n    split    Split a string by the occurrences of a pattern.\n    findall  Find all occurrences of a pattern in a string.\n    finditer Return an iterator yielding a match object for each match.\n    compile  Compile a pattern into a RegexObject.\n    purge    Clear the regular expression cache.\n    escape   Backslash all non-alphanumerics in a string.\n\nSome of the functions in this module takes flags as optional parameters:\n    A  ASCII       For string patterns, make \\w, \\W, \\b, \\B, \\d, \\D\n                   match the corresponding ASCII character categories\n                   (rather than the whole Unicode categories, which is the\n                   default).\n                   For bytes patterns, this flag is the only available\n                   behaviour and needn't be specified.\n    I  IGNORECASE  Perform case-insensitive matching.\n    L  LOCALE      Make \\w, \\W, \\b, \\B, dependent on the current locale.\n    M  MULTILINE   \"^\" matches the beginning of lines (after a newline)\n                   as well as the string.\n                   \"$\" matches the end of lines (before a newline) as well\n                   as the end of the string.\n    S  DOTALL      \".\" matches any character at all, including the newline.\n    X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.\n    U  UNICODE     For compatibility only. Ignored for string patterns (it\n                   is the default), and forbidden for bytes patterns.\n\nThis module also defines an exception 'error'.\n\n\"\"\"\n\nimport sys\nimport sre_compile\nimport sre_parse\nimport functools\n\n# public symbols\n__all__ = [ \"match\", \"search\", \"sub\", \"subn\", \"split\", \"findall\",\n    \"compile\", \"purge\", \"template\", \"escape\", \"A\", \"I\", \"L\", \"M\", \"S\", \"X\",\n    \"U\", \"ASCII\", \"IGNORECASE\", \"LOCALE\", \"MULTILINE\", \"DOTALL\", \"VERBOSE\",\n    \"UNICODE\", \"error\" ]\n\n__version__ = \"2.2.1\"\n\n# flags\nA = ASCII = sre_compile.SRE_FLAG_ASCII # assume ascii \"locale\"\nI = IGNORECASE = sre_compile.SRE_FLAG_IGNORECASE # ignore case\nL = LOCALE = sre_compile.SRE_FLAG_LOCALE # assume current 8-bit locale\nU = UNICODE = sre_compile.SRE_FLAG_UNICODE # assume unicode \"locale\"\nM = MULTILINE = sre_compile.SRE_FLAG_MULTILINE # make anchors look for newline\nS = DOTALL = sre_compile.SRE_FLAG_DOTALL # make dot match newline\nX = VERBOSE = sre_compile.SRE_FLAG_VERBOSE # ignore whitespace and comments\n\n# sre extensions (experimental, don't rely on these)\nT = TEMPLATE = sre_compile.SRE_FLAG_TEMPLATE # disable backtracking\nDEBUG = sre_compile.SRE_FLAG_DEBUG # dump pattern after compilation\n\n# sre exception\nerror = sre_compile.error\n\n# --------------------------------------------------------------------\n# public interface\n\ndef match(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern at the start of the string, returning\n    a match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).match(string)\n\ndef search(pattern, string, flags=0):\n    \"\"\"Scan through string looking for a match to the pattern, returning\n    a match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).search(string)\n\ndef sub(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in string by the\n    replacement repl.  repl can be either a string or a callable;\n    if a string, backslash escapes in it are processed.  If it is\n    a callable, it's passed the match object and must return\n    a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).sub(repl, string, count)\n\ndef subn(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return a 2-tuple containing (new_string, number).\n    new_string is the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in the source\n    string by the replacement repl.  number is the number of\n    substitutions that were made. repl can be either a string or a\n    callable; if a string, backslash escapes in it are processed.\n    If it is a callable, it's passed the match object and must\n    return a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).subn(repl, string, count)\n\ndef split(pattern, string, maxsplit=0, flags=0):\n    \"\"\"Split the source string by the occurrences of the pattern,\n    returning a list containing the resulting substrings.  If\n    capturing parentheses are used in pattern, then the text of all\n    groups in the pattern are also returned as part of the resulting\n    list.  If maxsplit is nonzero, at most maxsplit splits occur,\n    and the remainder of the string is returned as the final element\n    of the list.\"\"\"\n    return _compile(pattern, flags).split(string, maxsplit)\n\ndef findall(pattern, string, flags=0):\n    \"\"\"Return a list of all non-overlapping matches in the string.\n\n    If one or more capturing groups are present in the pattern, return\n    a list of groups; this will be a list of tuples if the pattern\n    has more than one group.\n\n    Empty matches are included in the result.\"\"\"\n    return _compile(pattern, flags).findall(string)\n\nif sys.hexversion >= 0x02020000:\n    __all__.append(\"finditer\")\n    def finditer(pattern, string, flags=0):\n        \"\"\"Return an iterator over all non-overlapping matches in the\n        string.  For each match, the iterator returns a match object.\n\n        Empty matches are included in the result.\"\"\"\n        return _compile(pattern, flags).finditer(string)\n\ndef compile(pattern, flags=0):\n    \"Compile a regular expression pattern, returning a pattern object.\"\n    #print(\"_re.py:214\")\n    return _compile(pattern, flags)\n\ndef purge():\n    \"Clear the regular expression caches\"\n    _cache.clear()\n    _cache_repl.clear()\n\ndef template(pattern, flags=0):\n    \"Compile a template pattern, returning a pattern object\"\n    return _compile(pattern, flags|T)\n\n_alphanum_str = frozenset(\n    \"_abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ01234567890\")\n_alphanum_bytes = frozenset(\n    b\"_abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ01234567890\")\n\ndef escape(pattern):\n    \"\"\"\n    Escape all the characters in pattern except ASCII letters, numbers and '_'.\n    \"\"\"\n    if isinstance(pattern, str):\n        alphanum = _alphanum_str\n        s = list(pattern)\n        for i, c in enumerate(pattern):\n            if c not in alphanum:\n                if c == \"\\000\":\n                    s[i] = \"\\\\000\"\n                else:\n                    s[i] = \"\\\\\" + c\n        return \"\".join(s)\n    else:\n        alphanum = _alphanum_bytes\n        s = []\n        esc = ord(b\"\\\\\")\n        for c in pattern:\n            if c in alphanum:\n                s.append(c)\n            else:\n                if c == 0:\n                    s.extend(b\"\\\\000\")\n                else:\n                    s.append(esc)\n                    s.append(c)\n        return bytes(s)\n\n# --------------------------------------------------------------------\n# internals\n\n_cache = {}\n_cache_repl = {}\n\n_pattern_type = type(sre_compile.compile(\"\", 0))\n\n_MAXCACHE = 512\ndef _compile(pattern, flags):\n    # internal: compile pattern\n    try:\n        #fixme brython\n        #return _cache[type(pattern), pattern, flags]\n        return _cache[\"%s:%s:%s\" % (type(pattern), pattern, flags)]\n    except KeyError:\n       pass\n    #print(pattern)\n    if isinstance(pattern, _pattern_type):\n        if flags:\n            raise ValueError(\n                \"Cannot process flags argument with a compiled pattern\")\n        return pattern\n    if not sre_compile.isstring(pattern):\n        raise TypeError(\"first argument must be string or compiled pattern\")\n    p = sre_compile.compile(pattern, flags)\n    #print('_compile', p)\n    if len(_cache) >= _MAXCACHE:\n        _cache.clear()\n    #fix me brython\n    #_cache[type(pattern), pattern, flags] = p\n    _cache[\"%s:%s:%s\" % (type(pattern), pattern, flags)]= p\n    return p\n\ndef _compile_repl(repl, pattern):\n    # internal: compile replacement pattern\n    try:\n        #fix me brython\n        #return _cache_repl[repl, pattern]\n        return _cache_repl[\"%s:%s\" % (repl, pattern)]\n    except KeyError:\n        pass\n    p = sre_parse.parse_template(repl, pattern)\n    if len(_cache_repl) >= _MAXCACHE:\n        _cache_repl.clear()\n    _cache_repl[\"%s:%s\" % (repl, pattern)] = p\n    #fix me brython\n    #_cache_repl[repl, pattern] = p\n    return p\n\ndef _expand(pattern, match, template):\n    # internal: match.expand implementation hook\n    template = sre_parse.parse_template(template, pattern)\n    return sre_parse.expand_template(template, match)\n\ndef _subx(pattern, template):\n    # internal: pattern.sub/subn implementation helper\n    template = _compile_repl(template, pattern)\n    if not template[0] and len(template[1]) == 1:\n        # literal replacement\n        return template[1][0]\n    def filter(match, template=template):\n        return sre_parse.expand_template(template, match)\n    return filter\n\n# register myself for pickling\n\nimport copyreg\n\ndef _pickle(p):\n    return _compile, (p.pattern, p.flags)\n\ncopyreg.pickle(_pattern_type, _pickle, _compile)\n\n# --------------------------------------------------------------------\n# experimental stuff (see python-dev discussions for details)\n\nclass Scanner:\n    def __init__(self, lexicon, flags=0):\n        from sre_constants import BRANCH, SUBPATTERN\n        self.lexicon = lexicon\n        # combine phrases into a compound pattern\n        p = []\n        s = sre_parse.Pattern()\n        s.flags = flags\n        for phrase, action in lexicon:\n            p.append(sre_parse.SubPattern(s, [\n                (SUBPATTERN, (len(p)+1, sre_parse.parse(phrase, flags))),\n                ]))\n        s.groups = len(p)+1\n        p = sre_parse.SubPattern(s, [(BRANCH, (None, p))])\n        self.scanner = sre_compile.compile(p)\n    def scan(self, string):\n        result = []\n        append = result.append\n        match = self.scanner.scanner(string).match\n        i = 0\n        while 1:\n            m = match()\n            if not m:\n                break\n            j = m.end()\n            if i == j:\n                break\n            action = self.lexicon[m.lastindex-1][1]\n            if callable(action):\n                self.match = m\n                action = action(self, m.group())\n            if action is not None:\n                append(action)\n            i = j\n        return result, string[i:]\n"], "unittest.test.test_skipping": [".py", "import unittest\n\nfrom .support import LoggingResult\n\n\nclass Test_TestSkipping(unittest.TestCase):\n\n    def test_skipping(self):\n        class Foo(unittest.TestCase):\n            def test_skip_me(self):\n                self.skipTest(\"skip\")\n        events = []\n        result = LoggingResult(events)\n        test = Foo(\"test_skip_me\")\n        test.run(result)\n        self.assertEqual(events, ['startTest', 'addSkip', 'stopTest'])\n        self.assertEqual(result.skipped, [(test, \"skip\")])\n\n        # Try letting setUp skip the test now.\n        class Foo(unittest.TestCase):\n            def setUp(self):\n                self.skipTest(\"testing\")\n            def test_nothing(self): pass\n        events = []\n        result = LoggingResult(events)\n        test = Foo(\"test_nothing\")\n        test.run(result)\n        self.assertEqual(events, ['startTest', 'addSkip', 'stopTest'])\n        self.assertEqual(result.skipped, [(test, \"testing\")])\n        self.assertEqual(result.testsRun, 1)\n\n    def test_skipping_decorators(self):\n        op_table = ((unittest.skipUnless, False, True),\n                    (unittest.skipIf, True, False))\n        for deco, do_skip, dont_skip in op_table:\n            class Foo(unittest.TestCase):\n                @deco(do_skip, \"testing\")\n                def test_skip(self): pass\n\n                @deco(dont_skip, \"testing\")\n                def test_dont_skip(self): pass\n            test_do_skip = Foo(\"test_skip\")\n            test_dont_skip = Foo(\"test_dont_skip\")\n            suite = unittest.TestSuite([test_do_skip, test_dont_skip])\n            events = []\n            result = LoggingResult(events)\n            suite.run(result)\n            self.assertEqual(len(result.skipped), 1)\n            expected = ['startTest', 'addSkip', 'stopTest',\n                        'startTest', 'addSuccess', 'stopTest']\n            self.assertEqual(events, expected)\n            self.assertEqual(result.testsRun, 2)\n            self.assertEqual(result.skipped, [(test_do_skip, \"testing\")])\n            self.assertTrue(result.wasSuccessful())\n\n    def test_skip_class(self):\n        @unittest.skip(\"testing\")\n        class Foo(unittest.TestCase):\n            def test_1(self):\n                record.append(1)\n        record = []\n        result = unittest.TestResult()\n        test = Foo(\"test_1\")\n        suite = unittest.TestSuite([test])\n        suite.run(result)\n        self.assertEqual(result.skipped, [(test, \"testing\")])\n        self.assertEqual(record, [])\n\n    def test_skip_non_unittest_class(self):\n        @unittest.skip(\"testing\")\n        class Mixin:\n            def test_1(self):\n                record.append(1)\n        class Foo(Mixin, unittest.TestCase):\n            pass\n        record = []\n        result = unittest.TestResult()\n        test = Foo(\"test_1\")\n        suite = unittest.TestSuite([test])\n        suite.run(result)\n        self.assertEqual(result.skipped, [(test, \"testing\")])\n        self.assertEqual(record, [])\n\n    def test_expected_failure(self):\n        class Foo(unittest.TestCase):\n            @unittest.expectedFailure\n            def test_die(self):\n                self.fail(\"help me!\")\n        events = []\n        result = LoggingResult(events)\n        test = Foo(\"test_die\")\n        test.run(result)\n        self.assertEqual(events,\n                         ['startTest', 'addExpectedFailure', 'stopTest'])\n        self.assertEqual(result.expectedFailures[0][0], test)\n        self.assertTrue(result.wasSuccessful())\n\n    def test_unexpected_success(self):\n        class Foo(unittest.TestCase):\n            @unittest.expectedFailure\n            def test_die(self):\n                pass\n        events = []\n        result = LoggingResult(events)\n        test = Foo(\"test_die\")\n        test.run(result)\n        self.assertEqual(events,\n                         ['startTest', 'addUnexpectedSuccess', 'stopTest'])\n        self.assertFalse(result.failures)\n        self.assertEqual(result.unexpectedSuccesses, [test])\n        self.assertTrue(result.wasSuccessful())\n\n    def test_skip_doesnt_run_setup(self):\n        class Foo(unittest.TestCase):\n            wasSetUp = False\n            wasTornDown = False\n            def setUp(self):\n                Foo.wasSetUp = True\n            def tornDown(self):\n                Foo.wasTornDown = True\n            @unittest.skip('testing')\n            def test_1(self):\n                pass\n\n        result = unittest.TestResult()\n        test = Foo(\"test_1\")\n        suite = unittest.TestSuite([test])\n        suite.run(result)\n        self.assertEqual(result.skipped, [(test, \"testing\")])\n        self.assertFalse(Foo.wasSetUp)\n        self.assertFalse(Foo.wasTornDown)\n\n    def test_decorated_skip(self):\n        def decorator(func):\n            def inner(*a):\n                return func(*a)\n            return inner\n\n        class Foo(unittest.TestCase):\n            @decorator\n            @unittest.skip('testing')\n            def test_1(self):\n                pass\n\n        result = unittest.TestResult()\n        test = Foo(\"test_1\")\n        suite = unittest.TestSuite([test])\n        suite.run(result)\n        self.assertEqual(result.skipped, [(test, \"testing\")])\n"], "optparse": [".py", "\"\"\"A powerful, extensible, and easy-to-use option parser.\n\nBy Greg Ward <gward@python.net>\n\nOriginally distributed as Optik.\n\nFor support, use the optik-users@lists.sourceforge.net mailing list\n(http://lists.sourceforge.net/lists/listinfo/optik-users).\n\nSimple usage example:\n\n   from optparse import OptionParser\n\n   parser = OptionParser()\n   parser.add_option(\"-f\", \"--file\", dest=\"filename\",\n                     help=\"write report to FILE\", metavar=\"FILE\")\n   parser.add_option(\"-q\", \"--quiet\",\n                     action=\"store_false\", dest=\"verbose\", default=True,\n                     help=\"don't print status messages to stdout\")\n\n   (options, args) = parser.parse_args()\n\"\"\"\n\n__version__ = \"1.5.3\"\n\n__all__ = ['Option',\n           'make_option',\n           'SUPPRESS_HELP',\n           'SUPPRESS_USAGE',\n           'Values',\n           'OptionContainer',\n           'OptionGroup',\n           'OptionParser',\n           'HelpFormatter',\n           'IndentedHelpFormatter',\n           'TitledHelpFormatter',\n           'OptParseError',\n           'OptionError',\n           'OptionConflictError',\n           'OptionValueError',\n           'BadOptionError']\n\n__copyright__ = \"\"\"\nCopyright (c) 2001-2006 Gregory P. Ward.  All rights reserved.\nCopyright (c) 2002-2006 Python Software Foundation.  All rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n  * Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n\n  * Redistributions in binary form must reproduce the above copyright\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n\n  * Neither the name of the author nor the names of its\n    contributors may be used to endorse or promote products derived from\n    this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\nIS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\nTO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR\nCONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\nEXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\nPROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\"\"\"\n\nimport sys, os\nimport textwrap\n\ndef _repr(self):\n    return \"<%s at 0x%x: %s>\" % (self.__class__.__name__, id(self), self)\n\n\n# This file was generated from:\n#   Id: option_parser.py 527 2006-07-23 15:21:30Z greg\n#   Id: option.py 522 2006-06-11 16:22:03Z gward\n#   Id: help.py 527 2006-07-23 15:21:30Z greg\n#   Id: errors.py 509 2006-04-20 00:58:24Z gward\n\ntry:\n    from gettext import gettext, ngettext\nexcept ImportError:\n    def gettext(message):\n        return message\n\n    def ngettext(singular, plural, n):\n        if n == 1:\n            return singular\n        return plural\n\n_ = gettext\n\n\nclass OptParseError (Exception):\n    def __init__(self, msg):\n        self.msg = msg\n\n    def __str__(self):\n        return self.msg\n\n\nclass OptionError (OptParseError):\n    \"\"\"\n    Raised if an Option instance is created with invalid or\n    inconsistent arguments.\n    \"\"\"\n\n    def __init__(self, msg, option):\n        self.msg = msg\n        self.option_id = str(option)\n\n    def __str__(self):\n        if self.option_id:\n            return \"option %s: %s\" % (self.option_id, self.msg)\n        else:\n            return self.msg\n\nclass OptionConflictError (OptionError):\n    \"\"\"\n    Raised if conflicting options are added to an OptionParser.\n    \"\"\"\n\nclass OptionValueError (OptParseError):\n    \"\"\"\n    Raised if an invalid option value is encountered on the command\n    line.\n    \"\"\"\n\nclass BadOptionError (OptParseError):\n    \"\"\"\n    Raised if an invalid option is seen on the command line.\n    \"\"\"\n    def __init__(self, opt_str):\n        self.opt_str = opt_str\n\n    def __str__(self):\n        return _(\"no such option: %s\") % self.opt_str\n\nclass AmbiguousOptionError (BadOptionError):\n    \"\"\"\n    Raised if an ambiguous option is seen on the command line.\n    \"\"\"\n    def __init__(self, opt_str, possibilities):\n        BadOptionError.__init__(self, opt_str)\n        self.possibilities = possibilities\n\n    def __str__(self):\n        return (_(\"ambiguous option: %s (%s?)\")\n                % (self.opt_str, \", \".join(self.possibilities)))\n\n\nclass HelpFormatter:\n\n    \"\"\"\n    Abstract base class for formatting option help.  OptionParser\n    instances should use one of the HelpFormatter subclasses for\n    formatting help; by default IndentedHelpFormatter is used.\n\n    Instance attributes:\n      parser : OptionParser\n        the controlling OptionParser instance\n      indent_increment : int\n        the number of columns to indent per nesting level\n      max_help_position : int\n        the maximum starting column for option help text\n      help_position : int\n        the calculated starting column for option help text;\n        initially the same as the maximum\n      width : int\n        total number of columns for output (pass None to constructor for\n        this value to be taken from the $COLUMNS environment variable)\n      level : int\n        current indentation level\n      current_indent : int\n        current indentation level (in columns)\n      help_width : int\n        number of columns available for option help text (calculated)\n      default_tag : str\n        text to replace with each option's default value, \"%default\"\n        by default.  Set to false value to disable default value expansion.\n      option_strings : { Option : str }\n        maps Option instances to the snippet of help text explaining\n        the syntax of that option, e.g. \"-h, --help\" or\n        \"-fFILE, --file=FILE\"\n      _short_opt_fmt : str\n        format string controlling how short options with values are\n        printed in help text.  Must be either \"%s%s\" (\"-fFILE\") or\n        \"%s %s\" (\"-f FILE\"), because those are the two syntaxes that\n        Optik supports.\n      _long_opt_fmt : str\n        similar but for long options; must be either \"%s %s\" (\"--file FILE\")\n        or \"%s=%s\" (\"--file=FILE\").\n    \"\"\"\n\n    NO_DEFAULT_VALUE = \"none\"\n\n    def __init__(self,\n                 indent_increment,\n                 max_help_position,\n                 width,\n                 short_first):\n        self.parser = None\n        self.indent_increment = indent_increment\n        self.help_position = self.max_help_position = max_help_position\n        if width is None:\n            try:\n                width = int(os.environ['COLUMNS'])\n            except (KeyError, ValueError):\n                width = 80\n            width -= 2\n        self.width = width\n        self.current_indent = 0\n        self.level = 0\n        self.help_width = None          # computed later\n        self.short_first = short_first\n        self.default_tag = \"%default\"\n        self.option_strings = {}\n        self._short_opt_fmt = \"%s %s\"\n        self._long_opt_fmt = \"%s=%s\"\n\n    def set_parser(self, parser):\n        self.parser = parser\n\n    def set_short_opt_delimiter(self, delim):\n        if delim not in (\"\", \" \"):\n            raise ValueError(\n                \"invalid metavar delimiter for short options: %r\" % delim)\n        self._short_opt_fmt = \"%s\" + delim + \"%s\"\n\n    def set_long_opt_delimiter(self, delim):\n        if delim not in (\"=\", \" \"):\n            raise ValueError(\n                \"invalid metavar delimiter for long options: %r\" % delim)\n        self._long_opt_fmt = \"%s\" + delim + \"%s\"\n\n    def indent(self):\n        self.current_indent += self.indent_increment\n        self.level += 1\n\n    def dedent(self):\n        self.current_indent -= self.indent_increment\n        assert self.current_indent >= 0, \"Indent decreased below 0.\"\n        self.level -= 1\n\n    def format_usage(self, usage):\n        raise NotImplementedError(\"subclasses must implement\")\n\n    def format_heading(self, heading):\n        raise NotImplementedError(\"subclasses must implement\")\n\n    def _format_text(self, text):\n        \"\"\"\n        Format a paragraph of free-form text for inclusion in the\n        help output at the current indentation level.\n        \"\"\"\n        text_width = self.width - self.current_indent\n        indent = \" \"*self.current_indent\n        return textwrap.fill(text,\n                             text_width,\n                             initial_indent=indent,\n                             subsequent_indent=indent)\n\n    def format_description(self, description):\n        if description:\n            return self._format_text(description) + \"\\n\"\n        else:\n            return \"\"\n\n    def format_epilog(self, epilog):\n        if epilog:\n            return \"\\n\" + self._format_text(epilog) + \"\\n\"\n        else:\n            return \"\"\n\n\n    def expand_default(self, option):\n        if self.parser is None or not self.default_tag:\n            return option.help\n\n        default_value = self.parser.defaults.get(option.dest)\n        if default_value is NO_DEFAULT or default_value is None:\n            default_value = self.NO_DEFAULT_VALUE\n\n        return option.help.replace(self.default_tag, str(default_value))\n\n    def format_option(self, option):\n        # The help for each option consists of two parts:\n        #   * the opt strings and metavars\n        #     eg. (\"-x\", or \"-fFILENAME, --file=FILENAME\")\n        #   * the user-supplied help string\n        #     eg. (\"turn on expert mode\", \"read data from FILENAME\")\n        #\n        # If possible, we write both of these on the same line:\n        #   -x      turn on expert mode\n        #\n        # But if the opt string list is too long, we put the help\n        # string on a second line, indented to the same column it would\n        # start in if it fit on the first line.\n        #   -fFILENAME, --file=FILENAME\n        #           read data from FILENAME\n        result = []\n        opts = self.option_strings[option]\n        opt_width = self.help_position - self.current_indent - 2\n        if len(opts) > opt_width:\n            opts = \"%*s%s\\n\" % (self.current_indent, \"\", opts)\n            indent_first = self.help_position\n        else:                       # start help on same line as opts\n            opts = \"%*s%-*s  \" % (self.current_indent, \"\", opt_width, opts)\n            indent_first = 0\n        result.append(opts)\n        if option.help:\n            help_text = self.expand_default(option)\n            help_lines = textwrap.wrap(help_text, self.help_width)\n            result.append(\"%*s%s\\n\" % (indent_first, \"\", help_lines[0]))\n            result.extend([\"%*s%s\\n\" % (self.help_position, \"\", line)\n                           for line in help_lines[1:]])\n        elif opts[-1] != \"\\n\":\n            result.append(\"\\n\")\n        return \"\".join(result)\n\n    def store_option_strings(self, parser):\n        self.indent()\n        max_len = 0\n        for opt in parser.option_list:\n            strings = self.format_option_strings(opt)\n            self.option_strings[opt] = strings\n            max_len = max(max_len, len(strings) + self.current_indent)\n        self.indent()\n        for group in parser.option_groups:\n            for opt in group.option_list:\n                strings = self.format_option_strings(opt)\n                self.option_strings[opt] = strings\n                max_len = max(max_len, len(strings) + self.current_indent)\n        self.dedent()\n        self.dedent()\n        self.help_position = min(max_len + 2, self.max_help_position)\n        self.help_width = self.width - self.help_position\n\n    def format_option_strings(self, option):\n        \"\"\"Return a comma-separated list of option strings & metavariables.\"\"\"\n        if option.takes_value():\n            metavar = option.metavar or option.dest.upper()\n            short_opts = [self._short_opt_fmt % (sopt, metavar)\n                          for sopt in option._short_opts]\n            long_opts = [self._long_opt_fmt % (lopt, metavar)\n                         for lopt in option._long_opts]\n        else:\n            short_opts = option._short_opts\n            long_opts = option._long_opts\n\n        if self.short_first:\n            opts = short_opts + long_opts\n        else:\n            opts = long_opts + short_opts\n\n        return \", \".join(opts)\n\nclass IndentedHelpFormatter (HelpFormatter):\n    \"\"\"Format help with indented section bodies.\n    \"\"\"\n\n    def __init__(self,\n                 indent_increment=2,\n                 max_help_position=24,\n                 width=None,\n                 short_first=1):\n        HelpFormatter.__init__(\n            self, indent_increment, max_help_position, width, short_first)\n\n    def format_usage(self, usage):\n        return _(\"Usage: %s\\n\") % usage\n\n    def format_heading(self, heading):\n        return \"%*s%s:\\n\" % (self.current_indent, \"\", heading)\n\n\nclass TitledHelpFormatter (HelpFormatter):\n    \"\"\"Format help with underlined section headers.\n    \"\"\"\n\n    def __init__(self,\n                 indent_increment=0,\n                 max_help_position=24,\n                 width=None,\n                 short_first=0):\n        HelpFormatter.__init__ (\n            self, indent_increment, max_help_position, width, short_first)\n\n    def format_usage(self, usage):\n        return \"%s  %s\\n\" % (self.format_heading(_(\"Usage\")), usage)\n\n    def format_heading(self, heading):\n        return \"%s\\n%s\\n\" % (heading, \"=-\"[self.level] * len(heading))\n\n\ndef _parse_num(val, type):\n    if val[:2].lower() == \"0x\":         # hexadecimal\n        radix = 16\n    elif val[:2].lower() == \"0b\":       # binary\n        radix = 2\n        val = val[2:] or \"0\"            # have to remove \"0b\" prefix\n    elif val[:1] == \"0\":                # octal\n        radix = 8\n    else:                               # decimal\n        radix = 10\n\n    return type(val, radix)\n\ndef _parse_int(val):\n    return _parse_num(val, int)\n\n_builtin_cvt = { \"int\" : (_parse_int, _(\"integer\")),\n                 \"long\" : (_parse_int, _(\"integer\")),\n                 \"float\" : (float, _(\"floating-point\")),\n                 \"complex\" : (complex, _(\"complex\")) }\n\ndef check_builtin(option, opt, value):\n    (cvt, what) = _builtin_cvt[option.type]\n    try:\n        return cvt(value)\n    except ValueError:\n        raise OptionValueError(\n            _(\"option %s: invalid %s value: %r\") % (opt, what, value))\n\ndef check_choice(option, opt, value):\n    if value in option.choices:\n        return value\n    else:\n        choices = \", \".join(map(repr, option.choices))\n        raise OptionValueError(\n            _(\"option %s: invalid choice: %r (choose from %s)\")\n            % (opt, value, choices))\n\n# Not supplying a default is different from a default of None,\n# so we need an explicit \"not supplied\" value.\nNO_DEFAULT = (\"NO\", \"DEFAULT\")\n\n\nclass Option:\n    \"\"\"\n    Instance attributes:\n      _short_opts : [string]\n      _long_opts : [string]\n\n      action : string\n      type : string\n      dest : string\n      default : any\n      nargs : int\n      const : any\n      choices : [string]\n      callback : function\n      callback_args : (any*)\n      callback_kwargs : { string : any }\n      help : string\n      metavar : string\n    \"\"\"\n\n    # The list of instance attributes that may be set through\n    # keyword args to the constructor.\n    ATTRS = ['action',\n             'type',\n             'dest',\n             'default',\n             'nargs',\n             'const',\n             'choices',\n             'callback',\n             'callback_args',\n             'callback_kwargs',\n             'help',\n             'metavar']\n\n    # The set of actions allowed by option parsers.  Explicitly listed\n    # here so the constructor can validate its arguments.\n    ACTIONS = (\"store\",\n               \"store_const\",\n               \"store_true\",\n               \"store_false\",\n               \"append\",\n               \"append_const\",\n               \"count\",\n               \"callback\",\n               \"help\",\n               \"version\")\n\n    # The set of actions that involve storing a value somewhere;\n    # also listed just for constructor argument validation.  (If\n    # the action is one of these, there must be a destination.)\n    STORE_ACTIONS = (\"store\",\n                     \"store_const\",\n                     \"store_true\",\n                     \"store_false\",\n                     \"append\",\n                     \"append_const\",\n                     \"count\")\n\n    # The set of actions for which it makes sense to supply a value\n    # type, ie. which may consume an argument from the command line.\n    TYPED_ACTIONS = (\"store\",\n                     \"append\",\n                     \"callback\")\n\n    # The set of actions which *require* a value type, ie. that\n    # always consume an argument from the command line.\n    ALWAYS_TYPED_ACTIONS = (\"store\",\n                            \"append\")\n\n    # The set of actions which take a 'const' attribute.\n    CONST_ACTIONS = (\"store_const\",\n                     \"append_const\")\n\n    # The set of known types for option parsers.  Again, listed here for\n    # constructor argument validation.\n    TYPES = (\"string\", \"int\", \"long\", \"float\", \"complex\", \"choice\")\n\n    # Dictionary of argument checking functions, which convert and\n    # validate option arguments according to the option type.\n    #\n    # Signature of checking functions is:\n    #   check(option : Option, opt : string, value : string) -> any\n    # where\n    #   option is the Option instance calling the checker\n    #   opt is the actual option seen on the command-line\n    #     (eg. \"-a\", \"--file\")\n    #   value is the option argument seen on the command-line\n    #\n    # The return value should be in the appropriate Python type\n    # for option.type -- eg. an integer if option.type == \"int\".\n    #\n    # If no checker is defined for a type, arguments will be\n    # unchecked and remain strings.\n    TYPE_CHECKER = { \"int\"    : check_builtin,\n                     \"long\"   : check_builtin,\n                     \"float\"  : check_builtin,\n                     \"complex\": check_builtin,\n                     \"choice\" : check_choice,\n                   }\n\n\n    # CHECK_METHODS is a list of unbound method objects; they are called\n    # by the constructor, in order, after all attributes are\n    # initialized.  The list is created and filled in later, after all\n    # the methods are actually defined.  (I just put it here because I\n    # like to define and document all class attributes in the same\n    # place.)  Subclasses that add another _check_*() method should\n    # define their own CHECK_METHODS list that adds their check method\n    # to those from this class.\n    CHECK_METHODS = None\n\n\n    # -- Constructor/initialization methods ----------------------------\n\n    def __init__(self, *opts, **attrs):\n        # Set _short_opts, _long_opts attrs from 'opts' tuple.\n        # Have to be set now, in case no option strings are supplied.\n        self._short_opts = []\n        self._long_opts = []\n        opts = self._check_opt_strings(opts)\n        self._set_opt_strings(opts)\n\n        # Set all other attrs (action, type, etc.) from 'attrs' dict\n        self._set_attrs(attrs)\n\n        # Check all the attributes we just set.  There are lots of\n        # complicated interdependencies, but luckily they can be farmed\n        # out to the _check_*() methods listed in CHECK_METHODS -- which\n        # could be handy for subclasses!  The one thing these all share\n        # is that they raise OptionError if they discover a problem.\n        for checker in self.CHECK_METHODS:\n            checker(self)\n\n    def _check_opt_strings(self, opts):\n        # Filter out None because early versions of Optik had exactly\n        # one short option and one long option, either of which\n        # could be None.\n        opts = [opt for opt in opts if opt]\n        if not opts:\n            raise TypeError(\"at least one option string must be supplied\")\n        return opts\n\n    def _set_opt_strings(self, opts):\n        for opt in opts:\n            if len(opt) < 2:\n                raise OptionError(\n                    \"invalid option string %r: \"\n                    \"must be at least two characters long\" % opt, self)\n            elif len(opt) == 2:\n                if not (opt[0] == \"-\" and opt[1] != \"-\"):\n                    raise OptionError(\n                        \"invalid short option string %r: \"\n                        \"must be of the form -x, (x any non-dash char)\" % opt,\n                        self)\n                self._short_opts.append(opt)\n            else:\n                if not (opt[0:2] == \"--\" and opt[2] != \"-\"):\n                    raise OptionError(\n                        \"invalid long option string %r: \"\n                        \"must start with --, followed by non-dash\" % opt,\n                        self)\n                self._long_opts.append(opt)\n\n    def _set_attrs(self, attrs):\n        for attr in self.ATTRS:\n            if attr in attrs:\n                setattr(self, attr, attrs[attr])\n                del attrs[attr]\n            else:\n                if attr == 'default':\n                    setattr(self, attr, NO_DEFAULT)\n                else:\n                    setattr(self, attr, None)\n        if attrs:\n            attrs = sorted(attrs.keys())\n            raise OptionError(\n                \"invalid keyword arguments: %s\" % \", \".join(attrs),\n                self)\n\n\n    # -- Constructor validation methods --------------------------------\n\n    def _check_action(self):\n        if self.action is None:\n            self.action = \"store\"\n        elif self.action not in self.ACTIONS:\n            raise OptionError(\"invalid action: %r\" % self.action, self)\n\n    def _check_type(self):\n        if self.type is None:\n            if self.action in self.ALWAYS_TYPED_ACTIONS:\n                if self.choices is not None:\n                    # The \"choices\" attribute implies \"choice\" type.\n                    self.type = \"choice\"\n                else:\n                    # No type given?  \"string\" is the most sensible default.\n                    self.type = \"string\"\n        else:\n            # Allow type objects or builtin type conversion functions\n            # (int, str, etc.) as an alternative to their names.  (The\n            # complicated check of builtins is only necessary for\n            # Python 2.1 and earlier, and is short-circuited by the\n            # first check on modern Pythons.)\n            import builtins\n            if ( isinstance(self.type, type) or\n                 (hasattr(self.type, \"__name__\") and\n                  getattr(builtins, self.type.__name__, None) is self.type) ):\n                self.type = self.type.__name__\n\n            if self.type == \"str\":\n                self.type = \"string\"\n\n            if self.type not in self.TYPES:\n                raise OptionError(\"invalid option type: %r\" % self.type, self)\n            if self.action not in self.TYPED_ACTIONS:\n                raise OptionError(\n                    \"must not supply a type for action %r\" % self.action, self)\n\n    def _check_choice(self):\n        if self.type == \"choice\":\n            if self.choices is None:\n                raise OptionError(\n                    \"must supply a list of choices for type 'choice'\", self)\n            elif not isinstance(self.choices, (tuple, list)):\n                raise OptionError(\n                    \"choices must be a list of strings ('%s' supplied)\"\n                    % str(type(self.choices)).split(\"'\")[1], self)\n        elif self.choices is not None:\n            raise OptionError(\n                \"must not supply choices for type %r\" % self.type, self)\n\n    def _check_dest(self):\n        # No destination given, and we need one for this action.  The\n        # self.type check is for callbacks that take a value.\n        takes_value = (self.action in self.STORE_ACTIONS or\n                       self.type is not None)\n        if self.dest is None and takes_value:\n\n            # Glean a destination from the first long option string,\n            # or from the first short option string if no long options.\n            if self._long_opts:\n                # eg. \"--foo-bar\" -> \"foo_bar\"\n                self.dest = self._long_opts[0][2:].replace('-', '_')\n            else:\n                self.dest = self._short_opts[0][1]\n\n    def _check_const(self):\n        if self.action not in self.CONST_ACTIONS and self.const is not None:\n            raise OptionError(\n                \"'const' must not be supplied for action %r\" % self.action,\n                self)\n\n    def _check_nargs(self):\n        if self.action in self.TYPED_ACTIONS:\n            if self.nargs is None:\n                self.nargs = 1\n        elif self.nargs is not None:\n            raise OptionError(\n                \"'nargs' must not be supplied for action %r\" % self.action,\n                self)\n\n    def _check_callback(self):\n        if self.action == \"callback\":\n            if not callable(self.callback):\n                raise OptionError(\n                    \"callback not callable: %r\" % self.callback, self)\n            if (self.callback_args is not None and\n                not isinstance(self.callback_args, tuple)):\n                raise OptionError(\n                    \"callback_args, if supplied, must be a tuple: not %r\"\n                    % self.callback_args, self)\n            if (self.callback_kwargs is not None and\n                not isinstance(self.callback_kwargs, dict)):\n                raise OptionError(\n                    \"callback_kwargs, if supplied, must be a dict: not %r\"\n                    % self.callback_kwargs, self)\n        else:\n            if self.callback is not None:\n                raise OptionError(\n                    \"callback supplied (%r) for non-callback option\"\n                    % self.callback, self)\n            if self.callback_args is not None:\n                raise OptionError(\n                    \"callback_args supplied for non-callback option\", self)\n            if self.callback_kwargs is not None:\n                raise OptionError(\n                    \"callback_kwargs supplied for non-callback option\", self)\n\n\n    CHECK_METHODS = [_check_action,\n                     _check_type,\n                     _check_choice,\n                     _check_dest,\n                     _check_const,\n                     _check_nargs,\n                     _check_callback]\n\n\n    # -- Miscellaneous methods -----------------------------------------\n\n    def __str__(self):\n        return \"/\".join(self._short_opts + self._long_opts)\n\n    __repr__ = _repr\n\n    def takes_value(self):\n        return self.type is not None\n\n    def get_opt_string(self):\n        if self._long_opts:\n            return self._long_opts[0]\n        else:\n            return self._short_opts[0]\n\n\n    # -- Processing methods --------------------------------------------\n\n    def check_value(self, opt, value):\n        checker = self.TYPE_CHECKER.get(self.type)\n        if checker is None:\n            return value\n        else:\n            return checker(self, opt, value)\n\n    def convert_value(self, opt, value):\n        if value is not None:\n            if self.nargs == 1:\n                return self.check_value(opt, value)\n            else:\n                return tuple([self.check_value(opt, v) for v in value])\n\n    def process(self, opt, value, values, parser):\n\n        # First, convert the value(s) to the right type.  Howl if any\n        # value(s) are bogus.\n        value = self.convert_value(opt, value)\n\n        # And then take whatever action is expected of us.\n        # This is a separate method to make life easier for\n        # subclasses to add new actions.\n        return self.take_action(\n            self.action, self.dest, opt, value, values, parser)\n\n    def take_action(self, action, dest, opt, value, values, parser):\n        if action == \"store\":\n            setattr(values, dest, value)\n        elif action == \"store_const\":\n            setattr(values, dest, self.const)\n        elif action == \"store_true\":\n            setattr(values, dest, True)\n        elif action == \"store_false\":\n            setattr(values, dest, False)\n        elif action == \"append\":\n            values.ensure_value(dest, []).append(value)\n        elif action == \"append_const\":\n            values.ensure_value(dest, []).append(self.const)\n        elif action == \"count\":\n            setattr(values, dest, values.ensure_value(dest, 0) + 1)\n        elif action == \"callback\":\n            args = self.callback_args or ()\n            kwargs = self.callback_kwargs or {}\n            self.callback(self, opt, value, parser, *args, **kwargs)\n        elif action == \"help\":\n            parser.print_help()\n            parser.exit()\n        elif action == \"version\":\n            parser.print_version()\n            parser.exit()\n        else:\n            raise ValueError(\"unknown action %r\" % self.action)\n\n        return 1\n\n# class Option\n\n\nSUPPRESS_HELP = \"SUPPRESS\"+\"HELP\"\nSUPPRESS_USAGE = \"SUPPRESS\"+\"USAGE\"\n\nclass Values:\n\n    def __init__(self, defaults=None):\n        if defaults:\n            for (attr, val) in defaults.items():\n                setattr(self, attr, val)\n\n    def __str__(self):\n        return str(self.__dict__)\n\n    __repr__ = _repr\n\n    def __eq__(self, other):\n        if isinstance(other, Values):\n            return self.__dict__ == other.__dict__\n        elif isinstance(other, dict):\n            return self.__dict__ == other\n        else:\n            return NotImplemented\n\n    def _update_careful(self, dict):\n        \"\"\"\n        Update the option values from an arbitrary dictionary, but only\n        use keys from dict that already have a corresponding attribute\n        in self.  Any keys in dict without a corresponding attribute\n        are silently ignored.\n        \"\"\"\n        for attr in dir(self):\n            if attr in dict:\n                dval = dict[attr]\n                if dval is not None:\n                    setattr(self, attr, dval)\n\n    def _update_loose(self, dict):\n        \"\"\"\n        Update the option values from an arbitrary dictionary,\n        using all keys from the dictionary regardless of whether\n        they have a corresponding attribute in self or not.\n        \"\"\"\n        self.__dict__.update(dict)\n\n    def _update(self, dict, mode):\n        if mode == \"careful\":\n            self._update_careful(dict)\n        elif mode == \"loose\":\n            self._update_loose(dict)\n        else:\n            raise ValueError(\"invalid update mode: %r\" % mode)\n\n    def read_module(self, modname, mode=\"careful\"):\n        __import__(modname)\n        mod = sys.modules[modname]\n        self._update(vars(mod), mode)\n\n    def read_file(self, filename, mode=\"careful\"):\n        vars = {}\n        exec(open(filename).read(), vars)\n        self._update(vars, mode)\n\n    def ensure_value(self, attr, value):\n        if not hasattr(self, attr) or getattr(self, attr) is None:\n            setattr(self, attr, value)\n        return getattr(self, attr)\n\n\nclass OptionContainer:\n\n    \"\"\"\n    Abstract base class.\n\n    Class attributes:\n      standard_option_list : [Option]\n        list of standard options that will be accepted by all instances\n        of this parser class (intended to be overridden by subclasses).\n\n    Instance attributes:\n      option_list : [Option]\n        the list of Option objects contained by this OptionContainer\n      _short_opt : { string : Option }\n        dictionary mapping short option strings, eg. \"-f\" or \"-X\",\n        to the Option instances that implement them.  If an Option\n        has multiple short option strings, it will appears in this\n        dictionary multiple times. [1]\n      _long_opt : { string : Option }\n        dictionary mapping long option strings, eg. \"--file\" or\n        \"--exclude\", to the Option instances that implement them.\n        Again, a given Option can occur multiple times in this\n        dictionary. [1]\n      defaults : { string : any }\n        dictionary mapping option destination names to default\n        values for each destination [1]\n\n    [1] These mappings are common to (shared by) all components of the\n        controlling OptionParser, where they are initially created.\n\n    \"\"\"\n\n    def __init__(self, option_class, conflict_handler, description):\n        # Initialize the option list and related data structures.\n        # This method must be provided by subclasses, and it must\n        # initialize at least the following instance attributes:\n        # option_list, _short_opt, _long_opt, defaults.\n        self._create_option_list()\n\n        self.option_class = option_class\n        self.set_conflict_handler(conflict_handler)\n        self.set_description(description)\n\n    def _create_option_mappings(self):\n        # For use by OptionParser constructor -- create the master\n        # option mappings used by this OptionParser and all\n        # OptionGroups that it owns.\n        self._short_opt = {}            # single letter -> Option instance\n        self._long_opt = {}             # long option -> Option instance\n        self.defaults = {}              # maps option dest -> default value\n\n\n    def _share_option_mappings(self, parser):\n        # For use by OptionGroup constructor -- use shared option\n        # mappings from the OptionParser that owns this OptionGroup.\n        self._short_opt = parser._short_opt\n        self._long_opt = parser._long_opt\n        self.defaults = parser.defaults\n\n    def set_conflict_handler(self, handler):\n        if handler not in (\"error\", \"resolve\"):\n            raise ValueError(\"invalid conflict_resolution value %r\" % handler)\n        self.conflict_handler = handler\n\n    def set_description(self, description):\n        self.description = description\n\n    def get_description(self):\n        return self.description\n\n\n    def destroy(self):\n        \"\"\"see OptionParser.destroy().\"\"\"\n        del self._short_opt\n        del self._long_opt\n        del self.defaults\n\n\n    # -- Option-adding methods -----------------------------------------\n\n    def _check_conflict(self, option):\n        conflict_opts = []\n        for opt in option._short_opts:\n            if opt in self._short_opt:\n                conflict_opts.append((opt, self._short_opt[opt]))\n        for opt in option._long_opts:\n            if opt in self._long_opt:\n                conflict_opts.append((opt, self._long_opt[opt]))\n\n        if conflict_opts:\n            handler = self.conflict_handler\n            if handler == \"error\":\n                raise OptionConflictError(\n                    \"conflicting option string(s): %s\"\n                    % \", \".join([co[0] for co in conflict_opts]),\n                    option)\n            elif handler == \"resolve\":\n                for (opt, c_option) in conflict_opts:\n                    if opt.startswith(\"--\"):\n                        c_option._long_opts.remove(opt)\n                        del self._long_opt[opt]\n                    else:\n                        c_option._short_opts.remove(opt)\n                        del self._short_opt[opt]\n                    if not (c_option._short_opts or c_option._long_opts):\n                        c_option.container.option_list.remove(c_option)\n\n    def add_option(self, *args, **kwargs):\n        \"\"\"add_option(Option)\n           add_option(opt_str, ..., kwarg=val, ...)\n        \"\"\"\n        if isinstance(args[0], str):\n            option = self.option_class(*args, **kwargs)\n        elif len(args) == 1 and not kwargs:\n            option = args[0]\n            if not isinstance(option, Option):\n                raise TypeError(\"not an Option instance: %r\" % option)\n        else:\n            raise TypeError(\"invalid arguments\")\n\n        self._check_conflict(option)\n\n        self.option_list.append(option)\n        option.container = self\n        for opt in option._short_opts:\n            self._short_opt[opt] = option\n        for opt in option._long_opts:\n            self._long_opt[opt] = option\n\n        if option.dest is not None:     # option has a dest, we need a default\n            if option.default is not NO_DEFAULT:\n                self.defaults[option.dest] = option.default\n            elif option.dest not in self.defaults:\n                self.defaults[option.dest] = None\n\n        return option\n\n    def add_options(self, option_list):\n        for option in option_list:\n            self.add_option(option)\n\n    # -- Option query/removal methods ----------------------------------\n\n    def get_option(self, opt_str):\n        return (self._short_opt.get(opt_str) or\n                self._long_opt.get(opt_str))\n\n    def has_option(self, opt_str):\n        return (opt_str in self._short_opt or\n                opt_str in self._long_opt)\n\n    def remove_option(self, opt_str):\n        option = self._short_opt.get(opt_str)\n        if option is None:\n            option = self._long_opt.get(opt_str)\n        if option is None:\n            raise ValueError(\"no such option %r\" % opt_str)\n\n        for opt in option._short_opts:\n            del self._short_opt[opt]\n        for opt in option._long_opts:\n            del self._long_opt[opt]\n        option.container.option_list.remove(option)\n\n\n    # -- Help-formatting methods ---------------------------------------\n\n    def format_option_help(self, formatter):\n        if not self.option_list:\n            return \"\"\n        result = []\n        for option in self.option_list:\n            if not option.help is SUPPRESS_HELP:\n                result.append(formatter.format_option(option))\n        return \"\".join(result)\n\n    def format_description(self, formatter):\n        return formatter.format_description(self.get_description())\n\n    def format_help(self, formatter):\n        result = []\n        if self.description:\n            result.append(self.format_description(formatter))\n        if self.option_list:\n            result.append(self.format_option_help(formatter))\n        return \"\\n\".join(result)\n\n\nclass OptionGroup (OptionContainer):\n\n    def __init__(self, parser, title, description=None):\n        self.parser = parser\n        OptionContainer.__init__(\n            self, parser.option_class, parser.conflict_handler, description)\n        self.title = title\n\n    def _create_option_list(self):\n        self.option_list = []\n        self._share_option_mappings(self.parser)\n\n    def set_title(self, title):\n        self.title = title\n\n    def destroy(self):\n        \"\"\"see OptionParser.destroy().\"\"\"\n        OptionContainer.destroy(self)\n        del self.option_list\n\n    # -- Help-formatting methods ---------------------------------------\n\n    def format_help(self, formatter):\n        result = formatter.format_heading(self.title)\n        formatter.indent()\n        result += OptionContainer.format_help(self, formatter)\n        formatter.dedent()\n        return result\n\n\nclass OptionParser (OptionContainer):\n\n    \"\"\"\n    Class attributes:\n      standard_option_list : [Option]\n        list of standard options that will be accepted by all instances\n        of this parser class (intended to be overridden by subclasses).\n\n    Instance attributes:\n      usage : string\n        a usage string for your program.  Before it is displayed\n        to the user, \"%prog\" will be expanded to the name of\n        your program (self.prog or os.path.basename(sys.argv[0])).\n      prog : string\n        the name of the current program (to override\n        os.path.basename(sys.argv[0])).\n      description : string\n        A paragraph of text giving a brief overview of your program.\n        optparse reformats this paragraph to fit the current terminal\n        width and prints it when the user requests help (after usage,\n        but before the list of options).\n      epilog : string\n        paragraph of help text to print after option help\n\n      option_groups : [OptionGroup]\n        list of option groups in this parser (option groups are\n        irrelevant for parsing the command-line, but very useful\n        for generating help)\n\n      allow_interspersed_args : bool = true\n        if true, positional arguments may be interspersed with options.\n        Assuming -a and -b each take a single argument, the command-line\n          -ablah foo bar -bboo baz\n        will be interpreted the same as\n          -ablah -bboo -- foo bar baz\n        If this flag were false, that command line would be interpreted as\n          -ablah -- foo bar -bboo baz\n        -- ie. we stop processing options as soon as we see the first\n        non-option argument.  (This is the tradition followed by\n        Python's getopt module, Perl's Getopt::Std, and other argument-\n        parsing libraries, but it is generally annoying to users.)\n\n      process_default_values : bool = true\n        if true, option default values are processed similarly to option\n        values from the command line: that is, they are passed to the\n        type-checking function for the option's type (as long as the\n        default value is a string).  (This really only matters if you\n        have defined custom types; see SF bug #955889.)  Set it to false\n        to restore the behaviour of Optik 1.4.1 and earlier.\n\n      rargs : [string]\n        the argument list currently being parsed.  Only set when\n        parse_args() is active, and continually trimmed down as\n        we consume arguments.  Mainly there for the benefit of\n        callback options.\n      largs : [string]\n        the list of leftover arguments that we have skipped while\n        parsing options.  If allow_interspersed_args is false, this\n        list is always empty.\n      values : Values\n        the set of option values currently being accumulated.  Only\n        set when parse_args() is active.  Also mainly for callbacks.\n\n    Because of the 'rargs', 'largs', and 'values' attributes,\n    OptionParser is not thread-safe.  If, for some perverse reason, you\n    need to parse command-line arguments simultaneously in different\n    threads, use different OptionParser instances.\n\n    \"\"\"\n\n    standard_option_list = []\n\n    def __init__(self,\n                 usage=None,\n                 option_list=None,\n                 option_class=Option,\n                 version=None,\n                 conflict_handler=\"error\",\n                 description=None,\n                 formatter=None,\n                 add_help_option=True,\n                 prog=None,\n                 epilog=None):\n        OptionContainer.__init__(\n            self, option_class, conflict_handler, description)\n        self.set_usage(usage)\n        self.prog = prog\n        self.version = version\n        self.allow_interspersed_args = True\n        self.process_default_values = True\n        if formatter is None:\n            formatter = IndentedHelpFormatter()\n        self.formatter = formatter\n        self.formatter.set_parser(self)\n        self.epilog = epilog\n\n        # Populate the option list; initial sources are the\n        # standard_option_list class attribute, the 'option_list'\n        # argument, and (if applicable) the _add_version_option() and\n        # _add_help_option() methods.\n        self._populate_option_list(option_list,\n                                   add_help=add_help_option)\n\n        self._init_parsing_state()\n\n\n    def destroy(self):\n        \"\"\"\n        Declare that you are done with this OptionParser.  This cleans up\n        reference cycles so the OptionParser (and all objects referenced by\n        it) can be garbage-collected promptly.  After calling destroy(), the\n        OptionParser is unusable.\n        \"\"\"\n        OptionContainer.destroy(self)\n        for group in self.option_groups:\n            group.destroy()\n        del self.option_list\n        del self.option_groups\n        del self.formatter\n\n\n    # -- Private methods -----------------------------------------------\n    # (used by our or OptionContainer's constructor)\n\n    def _create_option_list(self):\n        self.option_list = []\n        self.option_groups = []\n        self._create_option_mappings()\n\n    def _add_help_option(self):\n        self.add_option(\"-h\", \"--help\",\n                        action=\"help\",\n                        help=_(\"show this help message and exit\"))\n\n    def _add_version_option(self):\n        self.add_option(\"--version\",\n                        action=\"version\",\n                        help=_(\"show program's version number and exit\"))\n\n    def _populate_option_list(self, option_list, add_help=True):\n        if self.standard_option_list:\n            self.add_options(self.standard_option_list)\n        if option_list:\n            self.add_options(option_list)\n        if self.version:\n            self._add_version_option()\n        if add_help:\n            self._add_help_option()\n\n    def _init_parsing_state(self):\n        # These are set in parse_args() for the convenience of callbacks.\n        self.rargs = None\n        self.largs = None\n        self.values = None\n\n\n    # -- Simple modifier methods ---------------------------------------\n\n    def set_usage(self, usage):\n        if usage is None:\n            self.usage = _(\"%prog [options]\")\n        elif usage is SUPPRESS_USAGE:\n            self.usage = None\n        # For backwards compatibility with Optik 1.3 and earlier.\n        elif usage.lower().startswith(\"usage: \"):\n            self.usage = usage[7:]\n        else:\n            self.usage = usage\n\n    def enable_interspersed_args(self):\n        \"\"\"Set parsing to not stop on the first non-option, allowing\n        interspersing switches with command arguments. This is the\n        default behavior. See also disable_interspersed_args() and the\n        class documentation description of the attribute\n        allow_interspersed_args.\"\"\"\n        self.allow_interspersed_args = True\n\n    def disable_interspersed_args(self):\n        \"\"\"Set parsing to stop on the first non-option. Use this if\n        you have a command processor which runs another command that\n        has options of its own and you want to make sure these options\n        don't get confused.\n        \"\"\"\n        self.allow_interspersed_args = False\n\n    def set_process_default_values(self, process):\n        self.process_default_values = process\n\n    def set_default(self, dest, value):\n        self.defaults[dest] = value\n\n    def set_defaults(self, **kwargs):\n        self.defaults.update(kwargs)\n\n    def _get_all_options(self):\n        options = self.option_list[:]\n        for group in self.option_groups:\n            options.extend(group.option_list)\n        return options\n\n    def get_default_values(self):\n        if not self.process_default_values:\n            # Old, pre-Optik 1.5 behaviour.\n            return Values(self.defaults)\n\n        defaults = self.defaults.copy()\n        for option in self._get_all_options():\n            default = defaults.get(option.dest)\n            if isinstance(default, str):\n                opt_str = option.get_opt_string()\n                defaults[option.dest] = option.check_value(opt_str, default)\n\n        return Values(defaults)\n\n\n    # -- OptionGroup methods -------------------------------------------\n\n    def add_option_group(self, *args, **kwargs):\n        # XXX lots of overlap with OptionContainer.add_option()\n        if isinstance(args[0], str):\n            group = OptionGroup(self, *args, **kwargs)\n        elif len(args) == 1 and not kwargs:\n            group = args[0]\n            if not isinstance(group, OptionGroup):\n                raise TypeError(\"not an OptionGroup instance: %r\" % group)\n            if group.parser is not self:\n                raise ValueError(\"invalid OptionGroup (wrong parser)\")\n        else:\n            raise TypeError(\"invalid arguments\")\n\n        self.option_groups.append(group)\n        return group\n\n    def get_option_group(self, opt_str):\n        option = (self._short_opt.get(opt_str) or\n                  self._long_opt.get(opt_str))\n        if option and option.container is not self:\n            return option.container\n        return None\n\n\n    # -- Option-parsing methods ----------------------------------------\n\n    def _get_args(self, args):\n        if args is None:\n            return sys.argv[1:]\n        else:\n            return args[:]              # don't modify caller's list\n\n    def parse_args(self, args=None, values=None):\n        \"\"\"\n        parse_args(args : [string] = sys.argv[1:],\n                   values : Values = None)\n        -> (values : Values, args : [string])\n\n        Parse the command-line options found in 'args' (default:\n        sys.argv[1:]).  Any errors result in a call to 'error()', which\n        by default prints the usage message to stderr and calls\n        sys.exit() with an error message.  On success returns a pair\n        (values, args) where 'values' is an Values instance (with all\n        your option values) and 'args' is the list of arguments left\n        over after parsing options.\n        \"\"\"\n        rargs = self._get_args(args)\n        if values is None:\n            values = self.get_default_values()\n\n        # Store the halves of the argument list as attributes for the\n        # convenience of callbacks:\n        #   rargs\n        #     the rest of the command-line (the \"r\" stands for\n        #     \"remaining\" or \"right-hand\")\n        #   largs\n        #     the leftover arguments -- ie. what's left after removing\n        #     options and their arguments (the \"l\" stands for \"leftover\"\n        #     or \"left-hand\")\n        self.rargs = rargs\n        self.largs = largs = []\n        self.values = values\n\n        try:\n            stop = self._process_args(largs, rargs, values)\n        except (BadOptionError, OptionValueError) as err:\n            self.error(str(err))\n\n        args = largs + rargs\n        return self.check_values(values, args)\n\n    def check_values(self, values, args):\n        \"\"\"\n        check_values(values : Values, args : [string])\n        -> (values : Values, args : [string])\n\n        Check that the supplied option values and leftover arguments are\n        valid.  Returns the option values and leftover arguments\n        (possibly adjusted, possibly completely new -- whatever you\n        like).  Default implementation just returns the passed-in\n        values; subclasses may override as desired.\n        \"\"\"\n        return (values, args)\n\n    def _process_args(self, largs, rargs, values):\n        \"\"\"_process_args(largs : [string],\n                         rargs : [string],\n                         values : Values)\n\n        Process command-line arguments and populate 'values', consuming\n        options and arguments from 'rargs'.  If 'allow_interspersed_args' is\n        false, stop at the first non-option argument.  If true, accumulate any\n        interspersed non-option arguments in 'largs'.\n        \"\"\"\n        while rargs:\n            arg = rargs[0]\n            # We handle bare \"--\" explicitly, and bare \"-\" is handled by the\n            # standard arg handler since the short arg case ensures that the\n            # len of the opt string is greater than 1.\n            if arg == \"--\":\n                del rargs[0]\n                return\n            elif arg[0:2] == \"--\":\n                # process a single long option (possibly with value(s))\n                self._process_long_opt(rargs, values)\n            elif arg[:1] == \"-\" and len(arg) > 1:\n                # process a cluster of short options (possibly with\n                # value(s) for the last one only)\n                self._process_short_opts(rargs, values)\n            elif self.allow_interspersed_args:\n                largs.append(arg)\n                del rargs[0]\n            else:\n                return                  # stop now, leave this arg in rargs\n\n        # Say this is the original argument list:\n        # [arg0, arg1, ..., arg(i-1), arg(i), arg(i+1), ..., arg(N-1)]\n        #                            ^\n        # (we are about to process arg(i)).\n        #\n        # Then rargs is [arg(i), ..., arg(N-1)] and largs is a *subset* of\n        # [arg0, ..., arg(i-1)] (any options and their arguments will have\n        # been removed from largs).\n        #\n        # The while loop will usually consume 1 or more arguments per pass.\n        # If it consumes 1 (eg. arg is an option that takes no arguments),\n        # then after _process_arg() is done the situation is:\n        #\n        #   largs = subset of [arg0, ..., arg(i)]\n        #   rargs = [arg(i+1), ..., arg(N-1)]\n        #\n        # If allow_interspersed_args is false, largs will always be\n        # *empty* -- still a subset of [arg0, ..., arg(i-1)], but\n        # not a very interesting subset!\n\n    def _match_long_opt(self, opt):\n        \"\"\"_match_long_opt(opt : string) -> string\n\n        Determine which long option string 'opt' matches, ie. which one\n        it is an unambiguous abbreviation for.  Raises BadOptionError if\n        'opt' doesn't unambiguously match any long option string.\n        \"\"\"\n        return _match_abbrev(opt, self._long_opt)\n\n    def _process_long_opt(self, rargs, values):\n        arg = rargs.pop(0)\n\n        # Value explicitly attached to arg?  Pretend it's the next\n        # argument.\n        if \"=\" in arg:\n            (opt, next_arg) = arg.split(\"=\", 1)\n            rargs.insert(0, next_arg)\n            had_explicit_value = True\n        else:\n            opt = arg\n            had_explicit_value = False\n\n        opt = self._match_long_opt(opt)\n        option = self._long_opt[opt]\n        if option.takes_value():\n            nargs = option.nargs\n            if len(rargs) < nargs:\n                self.error(ngettext(\n                    \"%(option)s option requires %(number)d argument\",\n                    \"%(option)s option requires %(number)d arguments\",\n                    nargs) % {\"option\": opt, \"number\": nargs})\n            elif nargs == 1:\n                value = rargs.pop(0)\n            else:\n                value = tuple(rargs[0:nargs])\n                del rargs[0:nargs]\n\n        elif had_explicit_value:\n            self.error(_(\"%s option does not take a value\") % opt)\n\n        else:\n            value = None\n\n        option.process(opt, value, values, self)\n\n    def _process_short_opts(self, rargs, values):\n        arg = rargs.pop(0)\n        stop = False\n        i = 1\n        for ch in arg[1:]:\n            opt = \"-\" + ch\n            option = self._short_opt.get(opt)\n            i += 1                      # we have consumed a character\n\n            if not option:\n                raise BadOptionError(opt)\n            if option.takes_value():\n                # Any characters left in arg?  Pretend they're the\n                # next arg, and stop consuming characters of arg.\n                if i < len(arg):\n                    rargs.insert(0, arg[i:])\n                    stop = True\n\n                nargs = option.nargs\n                if len(rargs) < nargs:\n                    self.error(ngettext(\n                        \"%(option)s option requires %(number)d argument\",\n                        \"%(option)s option requires %(number)d arguments\",\n                        nargs) % {\"option\": opt, \"number\": nargs})\n                elif nargs == 1:\n                    value = rargs.pop(0)\n                else:\n                    value = tuple(rargs[0:nargs])\n                    del rargs[0:nargs]\n\n            else:                       # option doesn't take a value\n                value = None\n\n            option.process(opt, value, values, self)\n\n            if stop:\n                break\n\n\n    # -- Feedback methods ----------------------------------------------\n\n    def get_prog_name(self):\n        if self.prog is None:\n            return os.path.basename(sys.argv[0])\n        else:\n            return self.prog\n\n    def expand_prog_name(self, s):\n        return s.replace(\"%prog\", self.get_prog_name())\n\n    def get_description(self):\n        return self.expand_prog_name(self.description)\n\n    def exit(self, status=0, msg=None):\n        if msg:\n            sys.stderr.write(msg)\n        sys.exit(status)\n\n    def error(self, msg):\n        \"\"\"error(msg : string)\n\n        Print a usage message incorporating 'msg' to stderr and exit.\n        If you override this in a subclass, it should not return -- it\n        should either exit or raise an exception.\n        \"\"\"\n        self.print_usage(sys.stderr)\n        self.exit(2, \"%s: error: %s\\n\" % (self.get_prog_name(), msg))\n\n    def get_usage(self):\n        if self.usage:\n            return self.formatter.format_usage(\n                self.expand_prog_name(self.usage))\n        else:\n            return \"\"\n\n    def print_usage(self, file=None):\n        \"\"\"print_usage(file : file = stdout)\n\n        Print the usage message for the current program (self.usage) to\n        'file' (default stdout).  Any occurrence of the string \"%prog\" in\n        self.usage is replaced with the name of the current program\n        (basename of sys.argv[0]).  Does nothing if self.usage is empty\n        or not defined.\n        \"\"\"\n        if self.usage:\n            print(self.get_usage(), file=file)\n\n    def get_version(self):\n        if self.version:\n            return self.expand_prog_name(self.version)\n        else:\n            return \"\"\n\n    def print_version(self, file=None):\n        \"\"\"print_version(file : file = stdout)\n\n        Print the version message for this program (self.version) to\n        'file' (default stdout).  As with print_usage(), any occurrence\n        of \"%prog\" in self.version is replaced by the current program's\n        name.  Does nothing if self.version is empty or undefined.\n        \"\"\"\n        if self.version:\n            print(self.get_version(), file=file)\n\n    def format_option_help(self, formatter=None):\n        if formatter is None:\n            formatter = self.formatter\n        formatter.store_option_strings(self)\n        result = []\n        result.append(formatter.format_heading(_(\"Options\")))\n        formatter.indent()\n        if self.option_list:\n            result.append(OptionContainer.format_option_help(self, formatter))\n            result.append(\"\\n\")\n        for group in self.option_groups:\n            result.append(group.format_help(formatter))\n            result.append(\"\\n\")\n        formatter.dedent()\n        # Drop the last \"\\n\", or the header if no options or option groups:\n        return \"\".join(result[:-1])\n\n    def format_epilog(self, formatter):\n        return formatter.format_epilog(self.epilog)\n\n    def format_help(self, formatter=None):\n        if formatter is None:\n            formatter = self.formatter\n        result = []\n        if self.usage:\n            result.append(self.get_usage() + \"\\n\")\n        if self.description:\n            result.append(self.format_description(formatter) + \"\\n\")\n        result.append(self.format_option_help(formatter))\n        result.append(self.format_epilog(formatter))\n        return \"\".join(result)\n\n    def print_help(self, file=None):\n        \"\"\"print_help(file : file = stdout)\n\n        Print an extended help message, listing all options and any\n        help text provided with them, to 'file' (default stdout).\n        \"\"\"\n        if file is None:\n            file = sys.stdout\n        file.write(self.format_help())\n\n# class OptionParser\n\n\ndef _match_abbrev(s, wordmap):\n    \"\"\"_match_abbrev(s : string, wordmap : {string : Option}) -> string\n\n    Return the string key in 'wordmap' for which 's' is an unambiguous\n    abbreviation.  If 's' is found to be ambiguous or doesn't match any of\n    'words', raise BadOptionError.\n    \"\"\"\n    # Is there an exact match?\n    if s in wordmap:\n        return s\n    else:\n        # Isolate all words with s as a prefix.\n        possibilities = [word for word in wordmap.keys()\n                         if word.startswith(s)]\n        # No exact match, so there had better be just one possibility.\n        if len(possibilities) == 1:\n            return possibilities[0]\n        elif not possibilities:\n            raise BadOptionError(s)\n        else:\n            # More than one possible completion: ambiguous prefix.\n            possibilities.sort()\n            raise AmbiguousOptionError(s, possibilities)\n\n\n# Some day, there might be many Option classes.  As of Optik 1.3, the\n# preferred way to instantiate Options is indirectly, via make_option(),\n# which will become a factory function when there are many Option\n# classes.\nmake_option = Option\n"]};

