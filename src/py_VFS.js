__BRYTHON__.use_VFS = true;
__BRYTHON__.VFS={"heapq": [".py", "\"\"\n\n\n\n__about__ = \"\"\"Heap queues\n\n[explanation by Fran\u00e7ois Pinard]\n\nHeaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for\nall k, counting elements from 0.  For the sake of comparison,\nnon-existing elements are considered to be infinite.  The interesting\nproperty of a heap is that a[0] is always its smallest element.\n\nThe strange invariant above is meant to be an efficient memory\nrepresentation for a tournament.  The numbers below are `k', not a[k]:\n\n                                   0\n\n                  1                                 2\n\n          3               4                5               6\n\n      7       8       9       10      11      12      13      14\n\n    15 16   17 18   19 20   21 22   23 24   25 26   27 28   29 30\n\n\nIn the tree above, each cell `k' is topping `2*k+1' and `2*k+2'.  In\nan usual binary tournament we see in sports, each cell is the winner\nover the two cells it tops, and we can trace the winner down the tree\nto see all opponents s/he had.  However, in many computer applications\nof such tournaments, we do not need to trace the history of a winner.\nTo be more memory efficient, when a winner is promoted, we try to\nreplace it by something else at a lower level, and the rule becomes\nthat a cell and the two cells it tops contain three different items,\nbut the top cell \"wins\" over the two topped cells.\n\nIf this heap invariant is protected at all time, index 0 is clearly\nthe overall winner.  The simplest algorithmic way to remove it and\nfind the \"next\" winner is to move some loser (let's say cell 30 in the\ndiagram above) into the 0 position, and then percolate this new 0 down\nthe tree, exchanging values, until the invariant is re-established.\nThis is clearly logarithmic on the total number of items in the tree.\nBy iterating over all items, you get an O(n ln n) sort.\n\nA nice feature of this sort is that you can efficiently insert new\nitems while the sort is going on, provided that the inserted items are\nnot \"better\" than the last 0'th element you extracted.  This is\nespecially useful in simulation contexts, where the tree holds all\nincoming events, and the \"win\" condition means the smallest scheduled\ntime.  When an event schedule other events for execution, they are\nscheduled into the future, so they can easily go into the heap.  So, a\nheap is a good structure for implementing schedulers (this is what I\nused for my MIDI sequencer :-).\n\nVarious structures for implementing schedulers have been extensively\nstudied, and heaps are good for this, as they are reasonably speedy,\nthe speed is almost constant, and the worst case is not much different\nthan the average case.  However, there are other representations which\nare more efficient overall, yet the worst cases might be terrible.\n\nHeaps are also very useful in big disk sorts.  You most probably all\nknow that a big sort implies producing \"runs\" (which are pre-sorted\nsequences, which size is usually related to the amount of CPU memory),\nfollowed by a merging passes for these runs, which merging is often\nvery cleverly organised[1].  It is very important that the initial\nsort produces the longest runs possible.  Tournaments are a good way\nto that.  If, using all the memory available to hold a tournament, you\nreplace and percolate items that happen to fit the current run, you'll\nproduce runs which are twice the size of the memory for random input,\nand much better for input fuzzily ordered.\n\nMoreover, if you output the 0'th item on disk and get an input which\nmay not fit in the current tournament (because the value \"wins\" over\nthe last output value), it cannot fit in the heap, so the size of the\nheap decreases.  The freed memory could be cleverly reused immediately\nfor progressively building a second heap, which grows at exactly the\nsame rate the first heap is melting.  When the first heap completely\nvanishes, you switch heaps and start a new run.  Clever and quite\neffective!\n\nIn a word, heaps are useful memory structures to know.  I use them in\na few applications, and I think it is good to keep a `heap' module\naround. :-)\n\n--------------------\n[1] The disk balancing algorithms which are current, nowadays, are\nmore annoying than clever, and this is a consequence of the seeking\ncapabilities of the disks.  On devices which cannot seek, like big\ntape drives, the story was quite different, and one had to be very\nclever to ensure (far in advance) that each tape movement will be the\nmost effective possible (that is, will best participate at\n\"progressing\" the merge).  Some tapes were even able to read\nbackwards, and this was also used to avoid the rewinding time.\nBelieve me, real good tape sorts were quite spectacular to watch!\nFrom all times, sorting has always been a Great Art! :-)\n\"\"\"\n\n__all__ = ['heappush', 'heappop', 'heapify', 'heapreplace', 'merge',\n'nlargest', 'nsmallest', 'heappushpop']\n\nfrom itertools import islice, count, tee, chain\n\ndef heappush(heap, item):\n \"\"\n heap.append(item)\n _siftdown(heap, 0, len(heap)-1)\n \ndef heappop(heap):\n \"\"\n lastelt = heap.pop() \n if heap:\n  returnitem = heap[0]\n  heap[0] = lastelt\n  _siftup(heap, 0)\n else:\n  returnitem = lastelt\n return returnitem\n \ndef heapreplace(heap, item):\n \"\"\n returnitem = heap[0] \n heap[0] = item\n _siftup(heap, 0)\n return returnitem\n \ndef heappushpop(heap, item):\n \"\"\n if heap and heap[0] < item:\n  item, heap[0] = heap[0], item\n  _siftup(heap, 0)\n return item\n \ndef heapify(x):\n \"\"\n n = len(x)\n \n \n \n \n \n for i in reversed(range(n//2)):\n  _siftup(x, i)\n  \ndef _heappushpop_max(heap, item):\n \"\"\n if heap and item < heap[0]:\n  item, heap[0] = heap[0], item\n  _siftup_max(heap, 0)\n return item\n \ndef _heapify_max(x):\n \"\"\n n = len(x)\n for i in reversed(range(n//2)):\n  _siftup_max(x, i)\n  \ndef nlargest(n, iterable):\n \"\"\n if n < 0:\n  return []\n it = iter(iterable)\n result = list(islice(it, n))\n if not result:\n  return result\n heapify(result)\n _heappushpop = heappushpop\n for elem in it:\n  _heappushpop(result, elem)\n result.sort(reverse=True)\n return result\n \ndef nsmallest(n, iterable):\n \"\"\n if n < 0:\n  return []\n it = iter(iterable)\n result = list(islice(it, n))\n if not result:\n  return result\n _heapify_max(result)\n _heappushpop = _heappushpop_max\n for elem in it:\n  _heappushpop(result, elem)\n result.sort()\n return result\n \n \n \n \ndef _siftdown(heap, startpos, pos):\n newitem = heap[pos]\n \n \n while pos > startpos:\n  parentpos = (pos - 1) >> 1\n  parent = heap[parentpos]\n  if newitem < parent:\n   heap[pos] = parent\n   pos = parentpos\n   continue\n  break\n heap[pos] = newitem\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \ndef _siftup(heap, pos):\n endpos = len(heap)\n startpos = pos\n newitem = heap[pos]\n \n childpos = 2*pos + 1 \n while childpos < endpos:\n \n  rightpos = childpos + 1\n  if rightpos < endpos and not heap[childpos] < heap[rightpos]:\n   childpos = rightpos\n   \n  heap[pos] = heap[childpos]\n  pos = childpos\n  childpos = 2*pos + 1\n  \n  \n heap[pos] = newitem\n _siftdown(heap, startpos, pos)\n \ndef _siftdown_max(heap, startpos, pos):\n \"\"\n newitem = heap[pos]\n \n \n while pos > startpos:\n  parentpos = (pos - 1) >> 1\n  parent = heap[parentpos]\n  if parent < newitem:\n   heap[pos] = parent\n   pos = parentpos\n   continue\n  break\n heap[pos] = newitem\n \ndef _siftup_max(heap, pos):\n \"\"\n endpos = len(heap)\n startpos = pos\n newitem = heap[pos]\n \n childpos = 2*pos + 1 \n while childpos < endpos:\n \n  rightpos = childpos + 1\n  if rightpos < endpos and not heap[rightpos] < heap[childpos]:\n   childpos = rightpos\n   \n  heap[pos] = heap[childpos]\n  pos = childpos\n  childpos = 2*pos + 1\n  \n  \n heap[pos] = newitem\n _siftdown_max(heap, startpos, pos)\n \n \ntry:\n from _heapq import *\nexcept ImportError:\n pass\n \ndef merge(*iterables):\n \"\"\n _heappop, _heapreplace, _StopIteration = heappop, heapreplace, StopIteration\n _len = len\n \n h = []\n h_append = h.append\n for itnum, it in enumerate(map(iter, iterables)):\n  try:\n   next = it.__next__\n   h_append([next(), itnum, next])\n  except _StopIteration:\n   pass\n heapify(h)\n \n while _len(h) > 1:\n  try:\n   while True:\n    v, itnum, next = s = h[0]\n    yield v\n    s[0] = next() \n    _heapreplace(h, s) \n  except _StopIteration:\n   _heappop(h) \n if h:\n \n  v, itnum, next = h[0]\n  yield v\n  yield from next.__self__\n  \n  \n_nsmallest = nsmallest\ndef nsmallest(n, iterable, key=None):\n \"\"\n \n if n == 1:\n  it = iter(iterable)\n  head = list(islice(it, 1))\n  if not head:\n   return []\n  if key is None:\n   return [min(chain(head, it))]\n  return [min(chain(head, it), key=key)]\n  \n  \n try:\n  size = len(iterable)\n except (TypeError, AttributeError):\n  pass\n else:\n  if n >= size:\n   return sorted(iterable, key=key)[:n]\n   \n   \n if key is None:\n  it = zip(iterable, count()) \n  result = _nsmallest(n, it)\n  return [r[0] for r in result] \n  \n  \n in1, in2 = tee(iterable)\n it = zip(map(key, in1), count(), in2) \n result = _nsmallest(n, it)\n return [r[2] for r in result] \n \n_nlargest = nlargest\ndef nlargest(n, iterable, key=None):\n \"\"\n \n \n if n == 1:\n  it = iter(iterable)\n  head = list(islice(it, 1))\n  if not head:\n   return []\n  if key is None:\n   return [max(chain(head, it))]\n  return [max(chain(head, it), key=key)]\n  \n  \n try:\n  size = len(iterable)\n except (TypeError, AttributeError):\n  pass\n else:\n  if n >= size:\n   return sorted(iterable, key=key, reverse=True)[:n]\n   \n   \n if key is None:\n  it = zip(iterable, count(0,-1)) \n  result = _nlargest(n, it)\n  return [r[0] for r in result] \n  \n  \n in1, in2 = tee(iterable)\n it = zip(map(key, in1), count(0,-1), in2) \n result = _nlargest(n, it)\n return [r[2] for r in result] \n \nif __name__ == \"__main__\":\n\n heap = []\n data = [1, 3, 5, 7, 9, 2, 4, 6, 8, 0]\n for item in data:\n  heappush(heap, item)\n sort = []\n while heap:\n  sort.append(heappop(heap))\n print(sort)\n \n import doctest\n doctest.testmod()\n"], "crypto_js.rollups.sha384": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(a,c){var d={},j=d.lib={},f=function(){},m=j.Base={extend:function(a){f.prototype=this;var b=new f;a&&b.mixIn(a);b.hasOwnProperty(\"init\")||(b.init=function(){b.$super.init.apply(this,arguments)});b.init.prototype=b;b.$super=this;return b},create:function(){var a=this.extend();a.init.apply(a,arguments);return a},init:function(){},mixIn:function(a){for(var b in a)a.hasOwnProperty(b)&&(this[b]=a[b]);a.hasOwnProperty(\"toString\")&&(this.toString=a.toString)},clone:function(){return this.init.prototype.extend(this)}},\nB=j.WordArray=m.extend({init:function(a,b){a=this.words=a||[];this.sigBytes=b!=c?b:4*a.length},toString:function(a){return(a||y).stringify(this)},concat:function(a){var b=this.words,g=a.words,e=this.sigBytes;a=a.sigBytes;this.clamp();if(e%4)for(var k=0;k<a;k++)b[e+k>>>2]|=(g[k>>>2]>>>24-8*(k%4)&255)<<24-8*((e+k)%4);else if(65535<g.length)for(k=0;k<a;k+=4)b[e+k>>>2]=g[k>>>2];else b.push.apply(b,g);this.sigBytes+=a;return this},clamp:function(){var n=this.words,b=this.sigBytes;n[b>>>2]&=4294967295<<\n32-8*(b%4);n.length=a.ceil(b/4)},clone:function(){var a=m.clone.call(this);a.words=this.words.slice(0);return a},random:function(n){for(var b=[],g=0;g<n;g+=4)b.push(4294967296*a.random()|0);return new B.init(b,n)}}),v=d.enc={},y=v.Hex={stringify:function(a){var b=a.words;a=a.sigBytes;for(var g=[],e=0;e<a;e++){var k=b[e>>>2]>>>24-8*(e%4)&255;g.push((k>>>4).toString(16));g.push((k&15).toString(16))}return g.join(\"\")},parse:function(a){for(var b=a.length,g=[],e=0;e<b;e+=2)g[e>>>3]|=parseInt(a.substr(e,\n2),16)<<24-4*(e%8);return new B.init(g,b/2)}},F=v.Latin1={stringify:function(a){var b=a.words;a=a.sigBytes;for(var g=[],e=0;e<a;e++)g.push(String.fromCharCode(b[e>>>2]>>>24-8*(e%4)&255));return g.join(\"\")},parse:function(a){for(var b=a.length,g=[],e=0;e<b;e++)g[e>>>2]|=(a.charCodeAt(e)&255)<<24-8*(e%4);return new B.init(g,b)}},ha=v.Utf8={stringify:function(a){try{return decodeURIComponent(escape(F.stringify(a)))}catch(b){throw Error(\"Malformed UTF-8 data\");}},parse:function(a){return F.parse(unescape(encodeURIComponent(a)))}},\nZ=j.BufferedBlockAlgorithm=m.extend({reset:function(){this._data=new B.init;this._nDataBytes=0},_append:function(a){\"string\"==typeof a&&(a=ha.parse(a));this._data.concat(a);this._nDataBytes+=a.sigBytes},_process:function(n){var b=this._data,g=b.words,e=b.sigBytes,k=this.blockSize,m=e/(4*k),m=n?a.ceil(m):a.max((m|0)-this._minBufferSize,0);n=m*k;e=a.min(4*n,e);if(n){for(var c=0;c<n;c+=k)this._doProcessBlock(g,c);c=g.splice(0,n);b.sigBytes-=e}return new B.init(c,e)},clone:function(){var a=m.clone.call(this);\na._data=this._data.clone();return a},_minBufferSize:0});j.Hasher=Z.extend({cfg:m.extend(),init:function(a){this.cfg=this.cfg.extend(a);this.reset()},reset:function(){Z.reset.call(this);this._doReset()},update:function(a){this._append(a);this._process();return this},finalize:function(a){a&&this._append(a);return this._doFinalize()},blockSize:16,_createHelper:function(a){return function(b,g){return(new a.init(g)).finalize(b)}},_createHmacHelper:function(a){return function(b,g){return(new ia.HMAC.init(a,\ng)).finalize(b)}}});var ia=d.algo={};return d}(Math);\n(function(a){var c=CryptoJS,d=c.lib,j=d.Base,f=d.WordArray,c=c.x64={};c.Word=j.extend({init:function(a,c){this.high=a;this.low=c}});c.WordArray=j.extend({init:function(c,d){c=this.words=c||[];this.sigBytes=d!=a?d:8*c.length},toX32:function(){for(var a=this.words,c=a.length,d=[],j=0;j<c;j++){var F=a[j];d.push(F.high);d.push(F.low)}return f.create(d,this.sigBytes)},clone:function(){for(var a=j.clone.call(this),c=a.words=this.words.slice(0),d=c.length,f=0;f<d;f++)c[f]=c[f].clone();return a}})})();\n(function(){function a(){return f.create.apply(f,arguments)}for(var c=CryptoJS,d=c.lib.Hasher,j=c.x64,f=j.Word,m=j.WordArray,j=c.algo,B=[a(1116352408,3609767458),a(1899447441,602891725),a(3049323471,3964484399),a(3921009573,2173295548),a(961987163,4081628472),a(1508970993,3053834265),a(2453635748,2937671579),a(2870763221,3664609560),a(3624381080,2734883394),a(310598401,1164996542),a(607225278,1323610764),a(1426881987,3590304994),a(1925078388,4068182383),a(2162078206,991336113),a(2614888103,633803317),\na(3248222580,3479774868),a(3835390401,2666613458),a(4022224774,944711139),a(264347078,2341262773),a(604807628,2007800933),a(770255983,1495990901),a(1249150122,1856431235),a(1555081692,3175218132),a(1996064986,2198950837),a(2554220882,3999719339),a(2821834349,766784016),a(2952996808,2566594879),a(3210313671,3203337956),a(3336571891,1034457026),a(3584528711,2466948901),a(113926993,3758326383),a(338241895,168717936),a(666307205,1188179964),a(773529912,1546045734),a(1294757372,1522805485),a(1396182291,\n2643833823),a(1695183700,2343527390),a(1986661051,1014477480),a(2177026350,1206759142),a(2456956037,344077627),a(2730485921,1290863460),a(2820302411,3158454273),a(3259730800,3505952657),a(3345764771,106217008),a(3516065817,3606008344),a(3600352804,1432725776),a(4094571909,1467031594),a(275423344,851169720),a(430227734,3100823752),a(506948616,1363258195),a(659060556,3750685593),a(883997877,3785050280),a(958139571,3318307427),a(1322822218,3812723403),a(1537002063,2003034995),a(1747873779,3602036899),\na(1955562222,1575990012),a(2024104815,1125592928),a(2227730452,2716904306),a(2361852424,442776044),a(2428436474,593698344),a(2756734187,3733110249),a(3204031479,2999351573),a(3329325298,3815920427),a(3391569614,3928383900),a(3515267271,566280711),a(3940187606,3454069534),a(4118630271,4000239992),a(116418474,1914138554),a(174292421,2731055270),a(289380356,3203993006),a(460393269,320620315),a(685471733,587496836),a(852142971,1086792851),a(1017036298,365543100),a(1126000580,2618297676),a(1288033470,\n3409855158),a(1501505948,4234509866),a(1607167915,987167468),a(1816402316,1246189591)],v=[],y=0;80>y;y++)v[y]=a();j=j.SHA512=d.extend({_doReset:function(){this._hash=new m.init([new f.init(1779033703,4089235720),new f.init(3144134277,2227873595),new f.init(1013904242,4271175723),new f.init(2773480762,1595750129),new f.init(1359893119,2917565137),new f.init(2600822924,725511199),new f.init(528734635,4215389547),new f.init(1541459225,327033209)])},_doProcessBlock:function(a,c){for(var d=this._hash.words,\nf=d[0],j=d[1],b=d[2],g=d[3],e=d[4],k=d[5],m=d[6],d=d[7],y=f.high,M=f.low,$=j.high,N=j.low,aa=b.high,O=b.low,ba=g.high,P=g.low,ca=e.high,Q=e.low,da=k.high,R=k.low,ea=m.high,S=m.low,fa=d.high,T=d.low,s=y,p=M,G=$,D=N,H=aa,E=O,W=ba,I=P,t=ca,q=Q,U=da,J=R,V=ea,K=S,X=fa,L=T,u=0;80>u;u++){var z=v[u];if(16>u)var r=z.high=a[c+2*u]|0,h=z.low=a[c+2*u+1]|0;else{var r=v[u-15],h=r.high,w=r.low,r=(h>>>1|w<<31)^(h>>>8|w<<24)^h>>>7,w=(w>>>1|h<<31)^(w>>>8|h<<24)^(w>>>7|h<<25),C=v[u-2],h=C.high,l=C.low,C=(h>>>19|l<<\n13)^(h<<3|l>>>29)^h>>>6,l=(l>>>19|h<<13)^(l<<3|h>>>29)^(l>>>6|h<<26),h=v[u-7],Y=h.high,A=v[u-16],x=A.high,A=A.low,h=w+h.low,r=r+Y+(h>>>0<w>>>0?1:0),h=h+l,r=r+C+(h>>>0<l>>>0?1:0),h=h+A,r=r+x+(h>>>0<A>>>0?1:0);z.high=r;z.low=h}var Y=t&U^~t&V,A=q&J^~q&K,z=s&G^s&H^G&H,ja=p&D^p&E^D&E,w=(s>>>28|p<<4)^(s<<30|p>>>2)^(s<<25|p>>>7),C=(p>>>28|s<<4)^(p<<30|s>>>2)^(p<<25|s>>>7),l=B[u],ka=l.high,ga=l.low,l=L+((q>>>14|t<<18)^(q>>>18|t<<14)^(q<<23|t>>>9)),x=X+((t>>>14|q<<18)^(t>>>18|q<<14)^(t<<23|q>>>9))+(l>>>0<\nL>>>0?1:0),l=l+A,x=x+Y+(l>>>0<A>>>0?1:0),l=l+ga,x=x+ka+(l>>>0<ga>>>0?1:0),l=l+h,x=x+r+(l>>>0<h>>>0?1:0),h=C+ja,z=w+z+(h>>>0<C>>>0?1:0),X=V,L=K,V=U,K=J,U=t,J=q,q=I+l|0,t=W+x+(q>>>0<I>>>0?1:0)|0,W=H,I=E,H=G,E=D,G=s,D=p,p=l+h|0,s=x+z+(p>>>0<l>>>0?1:0)|0}M=f.low=M+p;f.high=y+s+(M>>>0<p>>>0?1:0);N=j.low=N+D;j.high=$+G+(N>>>0<D>>>0?1:0);O=b.low=O+E;b.high=aa+H+(O>>>0<E>>>0?1:0);P=g.low=P+I;g.high=ba+W+(P>>>0<I>>>0?1:0);Q=e.low=Q+q;e.high=ca+t+(Q>>>0<q>>>0?1:0);R=k.low=R+J;k.high=da+U+(R>>>0<J>>>0?1:0);\nS=m.low=S+K;m.high=ea+V+(S>>>0<K>>>0?1:0);T=d.low=T+L;d.high=fa+X+(T>>>0<L>>>0?1:0)},_doFinalize:function(){var a=this._data,c=a.words,d=8*this._nDataBytes,f=8*a.sigBytes;c[f>>>5]|=128<<24-f%32;c[(f+128>>>10<<5)+30]=Math.floor(d/4294967296);c[(f+128>>>10<<5)+31]=d;a.sigBytes=4*c.length;this._process();return this._hash.toX32()},clone:function(){var a=d.clone.call(this);a._hash=this._hash.clone();return a},blockSize:32});c.SHA512=d._createHelper(j);c.HmacSHA512=d._createHmacHelper(j)})();\n(function(){var a=CryptoJS,c=a.x64,d=c.Word,j=c.WordArray,c=a.algo,f=c.SHA512,c=c.SHA384=f.extend({_doReset:function(){this._hash=new j.init([new d.init(3418070365,3238371032),new d.init(1654270250,914150663),new d.init(2438529370,812702999),new d.init(355462360,4144912697),new d.init(1731405415,4290775857),new d.init(2394180231,1750603025),new d.init(3675008525,1694076839),new d.init(1203062813,3204075428)])},_doFinalize:function(){var a=f._doFinalize.call(this);a.sigBytes-=16;return a}});a.SHA384=\nf._createHelper(c);a.HmacSHA384=f._createHmacHelper(c)})();\n"], "functools": [".py", "\"\"\n\n\n\n\n\n\n\n\n__all__ = ['update_wrapper', 'wraps', 'WRAPPER_ASSIGNMENTS', 'WRAPPER_UPDATES',\n'total_ordering', 'cmp_to_key', 'lru_cache', 'reduce', 'partial']\n\nfrom _functools import partial, reduce\nfrom collections import namedtuple\ntry:\n from _thread import RLock\nexcept:\n class RLock:\n  \"\"\n  def __enter__(self): pass\n  def __exit__(self, exctype, excinst, exctb): pass\n  \n  \n  \n  \n  \n  \n  \n  \n  \nWRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__',\n'__annotations__')\nWRAPPER_UPDATES = ('__dict__',)\ndef update_wrapper(wrapper,\nwrapped,\nassigned = WRAPPER_ASSIGNMENTS,\nupdated = WRAPPER_UPDATES):\n \"\"\n wrapper.__wrapped__ = wrapped\n for attr in assigned:\n  try:\n   value = getattr(wrapped, attr)\n  except AttributeError:\n   pass\n  else:\n   setattr(wrapper, attr, value)\n for attr in updated:\n  getattr(wrapper, attr).update(getattr(wrapped, attr, {}))\n  \n return wrapper\n \ndef wraps(wrapped,\nassigned = WRAPPER_ASSIGNMENTS,\nupdated = WRAPPER_UPDATES):\n \"\"\n return partial(update_wrapper, wrapped=wrapped,\n assigned=assigned, updated=updated)\n \n \n \n \n \n \ndef total_ordering(cls):\n \"\"\n convert = {\n '__lt__': [('__gt__', lambda self, other: not (self < other or self == other)),\n ('__le__', lambda self, other: self < other or self == other),\n ('__ge__', lambda self, other: not self < other)],\n '__le__': [('__ge__', lambda self, other: not self <= other or self == other),\n ('__lt__', lambda self, other: self <= other and not self == other),\n ('__gt__', lambda self, other: not self <= other)],\n '__gt__': [('__lt__', lambda self, other: not (self > other or self == other)),\n ('__ge__', lambda self, other: self > other or self == other),\n ('__le__', lambda self, other: not self > other)],\n '__ge__': [('__le__', lambda self, other: (not self >= other) or self == other),\n ('__gt__', lambda self, other: self >= other and not self == other),\n ('__lt__', lambda self, other: not self >= other)]\n }\n \n roots = [op for op in convert if getattr(cls, op, None) is not getattr(object, op, None)]\n if not roots:\n  raise ValueError('must define at least one ordering operation: < > <= >=')\n root = max(roots) \n for opname, opfunc in convert[root]:\n  if opname not in roots:\n   opfunc.__name__ = opname\n   opfunc.__doc__ = getattr(int, opname).__doc__\n   setattr(cls, opname, opfunc)\n return cls\n \n \n \n \n \n \ndef cmp_to_key(mycmp):\n \"\"\n class K(object):\n  __slots__ = ['obj']\n  def __init__(self, obj):\n   self.obj = obj\n  def __lt__(self, other):\n   return mycmp(self.obj, other.obj) < 0\n  def __gt__(self, other):\n   return mycmp(self.obj, other.obj) > 0\n  def __eq__(self, other):\n   return mycmp(self.obj, other.obj) == 0\n  def __le__(self, other):\n   return mycmp(self.obj, other.obj) <= 0\n  def __ge__(self, other):\n   return mycmp(self.obj, other.obj) >= 0\n  def __ne__(self, other):\n   return mycmp(self.obj, other.obj) != 0\n  __hash__ = None\n return K\n \ntry:\n from _functools import cmp_to_key\nexcept ImportError:\n pass\n \n \n \n \n \n \n_CacheInfo = namedtuple(\"CacheInfo\", [\"hits\", \"misses\", \"maxsize\", \"currsize\"])\n\nclass _HashedSeq(list):\n \"\"\n \n __slots__ = 'hashvalue'\n \n def __init__(self, tup, hash=hash):\n  self[:] = tup\n  self.hashvalue = hash(tup)\n  \n def __hash__(self):\n  return self.hashvalue\n  \ndef _make_key(args, kwds, typed,\nkwd_mark = (object(),),\nfasttypes = {int, str, frozenset, type(None)},\nsorted=sorted, tuple=tuple, type=type, len=len):\n \"\"\n key = args\n if kwds:\n  sorted_items = sorted(kwds.items())\n  key += kwd_mark\n  for item in sorted_items:\n   key += item\n if typed:\n  key += tuple(type(v) for v in args)\n  if kwds:\n   key += tuple(type(v) for k, v in sorted_items)\n elif len(key) == 1 and type(key[0]) in fasttypes:\n  return key[0]\n return _HashedSeq(key)\n \ndef lru_cache(maxsize=128, typed=False):\n \"\"\n \n \n \n \n \n \n \n sentinel = object() \n make_key = _make_key \n PREV, NEXT, KEY, RESULT = 0, 1, 2, 3 \n \n def decorating_function(user_function):\n \n  cache = {}\n  hits = misses = 0\n  full = False\n  cache_get = cache.get \n  lock = RLock() \n  root = [] \n  root[:] = [root, root, None, None] \n  \n  if maxsize == 0:\n  \n   def wrapper(*args, **kwds):\n   \n    nonlocal misses\n    result = user_function(*args, **kwds)\n    misses += 1\n    return result\n    \n  elif maxsize is None:\n  \n   def wrapper(*args, **kwds):\n   \n    nonlocal hits, misses\n    key = make_key(args, kwds, typed)\n    result = cache_get(key, sentinel)\n    if result is not sentinel:\n     hits += 1\n     return result\n    result = user_function(*args, **kwds)\n    cache[key] = result\n    misses += 1\n    return result\n    \n  else:\n  \n   def wrapper(*args, **kwds):\n   \n    nonlocal root, hits, misses, full\n    key = make_key(args, kwds, typed)\n    with lock:\n     link = cache_get(key)\n     if link is not None:\n     \n      link_prev, link_next, _key, result = link\n      link_prev[NEXT] = link_next\n      link_next[PREV] = link_prev\n      last = root[PREV]\n      last[NEXT] = root[PREV] = link\n      link[PREV] = last\n      link[NEXT] = root\n      hits += 1\n      return result\n    result = user_function(*args, **kwds)\n    with lock:\n     if key in cache:\n     \n     \n     \n     \n      pass\n     elif full:\n     \n      oldroot = root\n      oldroot[KEY] = key\n      oldroot[RESULT] = result\n      \n      \n      \n      \n      \n      \n      root = oldroot[NEXT]\n      oldkey = root[KEY]\n      oldresult = root[RESULT]\n      root[KEY] = root[RESULT] = None\n      \n      del cache[oldkey]\n      \n      \n      \n      cache[key] = oldroot\n     else:\n     \n      last = root[PREV]\n      link = [last, root, key, result]\n      last[NEXT] = root[PREV] = cache[key] = link\n      full = (len(cache) >= maxsize)\n     misses += 1\n    return result\n    \n  def cache_info():\n   \"\"\n   with lock:\n    return _CacheInfo(hits, misses, maxsize, len(cache))\n    \n  def cache_clear():\n   \"\"\n   nonlocal hits, misses, full\n   with lock:\n    cache.clear()\n    root[:] = [root, root, None, None]\n    hits = misses = 0\n    full = False\n    \n  wrapper.cache_info = cache_info\n  wrapper.cache_clear = cache_clear\n  return update_wrapper(wrapper, user_function)\n  \n return decorating_function\n"], "random": [".py", "\"\"\n\nfrom warnings import warn as _warn\nfrom types import MethodType as _MethodType, BuiltinMethodType as _BuiltinMethodType\nfrom math import log as _log, exp as _exp, pi as _pi, e as _e, ceil as _ceil\nfrom math import sqrt as _sqrt, acos as _acos, cos as _cos, sin as _sin\nfrom os import urandom as _urandom\nfrom collections.abc import Set as _Set, Sequence as _Sequence\nfrom hashlib import sha512 as _sha512\n\n__all__ = [\"Random\",\"seed\",\"random\",\"uniform\",\"randint\",\"choice\",\"sample\",\n\"randrange\",\"shuffle\",\"normalvariate\",\"lognormvariate\",\n\"expovariate\",\"vonmisesvariate\",\"gammavariate\",\"triangular\",\n\"gauss\",\"betavariate\",\"paretovariate\",\"weibullvariate\",\n\"getstate\",\"setstate\", \"getrandbits\",\n\"SystemRandom\"]\n\nNV_MAGICCONST = 4 * _exp(-0.5)/_sqrt(2.0)\nTWOPI = 2.0*_pi\nLOG4 = _log(4.0)\nSG_MAGICCONST = 1.0 + _log(4.5)\nBPF = 53 \nRECIP_BPF = 2**-BPF\n\n\n\n\n\n\nimport _random\n\nclass Random(_random.Random):\n \"\"\n \n VERSION = 3 \n \n def __init__(self, x=None):\n  \"\"\n  \n  self.seed(x)\n  self.gauss_next = None\n  \n def seed(self, a=None, version=2):\n  \"\"\n  \n  if a is None:\n   try:\n    a = int.from_bytes(_urandom(32), 'big')\n   except NotImplementedError:\n    import time\n    a = int(time.time() * 256) \n    \n  if version == 2:\n   if isinstance(a, (str, bytes, bytearray)):\n    if isinstance(a, str):\n     a = a.encode()\n    a += _sha512(a).digest()\n    a = int.from_bytes(a, 'big')\n    \n  super().seed(a)\n  self.gauss_next = None\n  \n def getstate(self):\n  \"\"\n  return self.VERSION, super().getstate(), self.gauss_next\n  \n def setstate(self, state):\n  \"\"\n  version = state[0]\n  if version == 3:\n   version, internalstate, self.gauss_next = state\n   super().setstate(internalstate)\n  elif version == 2:\n   version, internalstate, self.gauss_next = state\n   \n   \n   \n   \n   try:\n    internalstate = tuple(x % (2**32) for x in internalstate)\n   except ValueError as e:\n    raise TypeError from e\n   super().setstate(internalstate)\n  else:\n   raise ValueError(\"state with version %s passed to \"\n   \"Random.setstate() of version %s\" %\n   (version, self.VERSION))\n   \n   \n   \n   \n   \n   \n def __getstate__(self): \n  return self.getstate()\n  \n def __setstate__(self, state): \n  self.setstate(state)\n  \n def __reduce__(self):\n  return self.__class__, (), self.getstate()\n  \n  \n  \n def randrange(self, start, stop=None, step=1, _int=int):\n  \"\"\n  \n  \n  \n  istart = _int(start)\n  if istart != start:\n   raise ValueError(\"non-integer arg 1 for randrange()\")\n  if stop is None:\n   if istart > 0:\n    return self._randbelow(istart)\n   raise ValueError(\"empty range for randrange()\")\n   \n   \n  istop = _int(stop)\n  if istop != stop:\n   raise ValueError(\"non-integer stop for randrange()\")\n  width = istop - istart\n  if step == 1 and width > 0:\n   return istart + self._randbelow(width)\n  if step == 1:\n   raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n   \n   \n  istep = _int(step)\n  if istep != step:\n   raise ValueError(\"non-integer step for randrange()\")\n  if istep > 0:\n   n = (width + istep - 1) // istep\n  elif istep < 0:\n   n = (width + istep + 1) // istep\n  else:\n   raise ValueError(\"zero step for randrange()\")\n   \n  if n <= 0:\n   raise ValueError(\"empty range for randrange()\")\n   \n  return istart + istep*self._randbelow(n)\n  \n def randint(self, a, b):\n  \"\"\n  \n  return self.randrange(a, b+1)\n  \n def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n Method=_MethodType, BuiltinMethod=_BuiltinMethodType):\n  \"\"\n  \n  getrandbits = self.getrandbits\n  \n  \n  if type(self.random) is BuiltinMethod or type(getrandbits) is Method:\n   k = n.bit_length() \n   r = getrandbits(k) \n   while r >= n:\n    r = getrandbits(k)\n   return r\n   \n   \n  random = self.random\n  if n >= maxsize:\n   _warn(\"Underlying random() generator does not supply \\n\"\n   \"enough bits to choose from a population range this large.\\n\"\n   \"To remove the range limitation, add a getrandbits() method.\")\n   return int(random() * n)\n  rem = maxsize % n\n  limit = (maxsize - rem) / maxsize \n  r = random()\n  while r >= limit:\n   r = random()\n  return int(r*maxsize) % n\n  \n  \n  \n def choice(self, seq):\n  \"\"\n  try:\n   i = self._randbelow(len(seq))\n  except ValueError:\n   raise IndexError('Cannot choose from an empty sequence')\n  return seq[i]\n  \n def shuffle(self, x, random=None):\n  \"\"\n  \n  if random is None:\n   randbelow = self._randbelow\n   for i in reversed(range(1, len(x))):\n   \n    j = randbelow(i+1)\n    x[i], x[j] = x[j], x[i]\n  else:\n   _int = int\n   for i in reversed(range(1, len(x))):\n   \n    j = _int(random() * (i+1))\n    x[i], x[j] = x[j], x[i]\n    \n def sample(self, population, k):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  if isinstance(population, _Set):\n   population = tuple(population)\n  if not isinstance(population, _Sequence):\n   raise TypeError(\"Population must be a sequence or set.  For dicts, use list(d).\")\n  randbelow = self._randbelow\n  n = len(population)\n  if not 0 <= k <= n:\n   raise ValueError(\"Sample larger than population\")\n  result = [None] * k\n  setsize = 21 \n  if k > 5:\n   setsize += 4 ** _ceil(_log(k * 3, 4)) \n  if n <= setsize:\n  \n   pool = list(population)\n   for i in range(k): \n    j = randbelow(n-i)\n    result[i] = pool[j]\n    pool[j] = pool[n-i-1] \n  else:\n   selected = set()\n   selected_add = selected.add\n   for i in range(k):\n    j = randbelow(n)\n    while j in selected:\n     j = randbelow(n)\n    selected_add(j)\n    result[i] = population[j]\n  return result\n  \n  \n  \n  \n  \n def uniform(self, a, b):\n  \"\"\n  return a + (b-a) * self.random()\n  \n  \n  \n def triangular(self, low=0.0, high=1.0, mode=None):\n  \"\"\n  u = self.random()\n  c = 0.5 if mode is None else (mode - low) / (high - low)\n  if u > c:\n   u = 1.0 - u\n   c = 1.0 - c\n   low, high = high, low\n  return low + (high - low) * (u * c) ** 0.5\n  \n  \n  \n def normalvariate(self, mu, sigma):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  random = self.random\n  while 1:\n   u1 = random()\n   u2 = 1.0 - random()\n   z = NV_MAGICCONST*(u1-0.5)/u2\n   zz = z*z/4.0\n   if zz <= -_log(u2):\n    break\n  return mu + z*sigma\n  \n  \n  \n def lognormvariate(self, mu, sigma):\n  \"\"\n  return _exp(self.normalvariate(mu, sigma))\n  \n  \n  \n def expovariate(self, lambd):\n  \"\"\n  \n  \n  \n  \n  \n  return -_log(1.0 - self.random())/lambd\n  \n  \n  \n def vonmisesvariate(self, mu, kappa):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  random = self.random\n  if kappa <= 1e-6:\n   return TWOPI * random()\n   \n  s = 0.5 / kappa\n  r = s + _sqrt(1.0 + s * s)\n  \n  while 1:\n   u1 = random()\n   z = _cos(_pi * u1)\n   \n   d = z / (r + z)\n   u2 = random()\n   if u2 < 1.0 - d * d or u2 <= (1.0 - d) * _exp(d):\n    break\n    \n  q = 1.0 / r\n  f = (q + z) / (1.0 + q * z)\n  u3 = random()\n  if u3 > 0.5:\n   theta = (mu + _acos(f)) % TWOPI\n  else:\n   theta = (mu - _acos(f)) % TWOPI\n   \n  return theta\n  \n  \n  \n def gammavariate(self, alpha, beta):\n  \"\"\n  \n  \n  \n  \n  \n  if alpha <= 0.0 or beta <= 0.0:\n   raise ValueError('gammavariate: alpha and beta must be > 0.0')\n   \n  random = self.random\n  if alpha > 1.0:\n  \n  \n  \n  \n  \n   ainv = _sqrt(2.0 * alpha - 1.0)\n   bbb = alpha - LOG4\n   ccc = alpha + ainv\n   \n   while 1:\n    u1 = random()\n    if not 1e-7 < u1 < .9999999:\n     continue\n    u2 = 1.0 - random()\n    v = _log(u1/(1.0-u1))/ainv\n    x = alpha*_exp(v)\n    z = u1*u1*u2\n    r = bbb+ccc*v-x\n    if r + SG_MAGICCONST - 4.5*z >= 0.0 or r >= _log(z):\n     return x * beta\n     \n  elif alpha == 1.0:\n  \n   u = random()\n   while u <= 1e-7:\n    u = random()\n   return -_log(u) * beta\n   \n  else: \n  \n  \n  \n   while 1:\n    u = random()\n    b = (_e + alpha)/_e\n    p = b*u\n    if p <= 1.0:\n     x = p ** (1.0/alpha)\n    else:\n     x = -_log((b-p)/alpha)\n    u1 = random()\n    if p > 1.0:\n     if u1 <= x ** (alpha - 1.0):\n      break\n    elif u1 <= _exp(-x):\n     break\n   return x * beta\n   \n   \n   \n def gauss(self, mu, sigma):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  random = self.random\n  z = self.gauss_next\n  self.gauss_next = None\n  if z is None:\n   x2pi = random() * TWOPI\n   g2rad = _sqrt(-2.0 * _log(1.0 - random()))\n   z = _cos(x2pi) * g2rad\n   self.gauss_next = _sin(x2pi) * g2rad\n   \n  return mu + z*sigma\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def betavariate(self, alpha, beta):\n  \"\"\n  \n  \n  \n  y = self.gammavariate(alpha, 1.)\n  if y == 0:\n   return 0.0\n  else:\n   return y / (y + self.gammavariate(beta, 1.))\n   \n   \n   \n def paretovariate(self, alpha):\n  \"\"\n  \n  \n  u = 1.0 - self.random()\n  return 1.0 / u ** (1.0/alpha)\n  \n  \n  \n def weibullvariate(self, alpha, beta):\n  \"\"\n  \n  \n  u = 1.0 - self.random()\n  return alpha * (-_log(u)) ** (1.0/beta)\n  \n  \n  \nclass SystemRandom(Random):\n \"\"\n \n def random(self):\n  \"\"\n  return (int.from_bytes(_urandom(7), 'big') >> 3) * RECIP_BPF\n  \n def getrandbits(self, k):\n  \"\"\n  if k <= 0:\n   raise ValueError('number of bits must be greater than zero')\n  if k != int(k):\n   raise TypeError('number of bits should be an integer')\n  numbytes = (k + 7) // 8 \n  x = int.from_bytes(_urandom(numbytes), 'big')\n  return x >> (numbytes * 8 - k) \n  \n def seed(self, *args, **kwds):\n  \"\"\n  return None\n  \n def _notimplemented(self, *args, **kwds):\n  \"\"\n  raise NotImplementedError('System entropy source does not have state.')\n getstate = setstate = _notimplemented\n \n \n \ndef _test_generator(n, func, args):\n import time\n print(n, 'times', func.__name__)\n total = 0.0\n sqsum = 0.0\n smallest = 1e10\n largest = -1e10\n t0 = time.time()\n for i in range(n):\n  x = func(*args)\n  total += x\n  sqsum = sqsum + x*x\n  smallest = min(x, smallest)\n  largest = max(x, largest)\n t1 = time.time()\n print(round(t1-t0, 3), 'sec,', end=' ')\n avg = total/n\n stddev = _sqrt(sqsum/n - avg*avg)\n print('avg %g, stddev %g, min %g, max %g' % (avg, stddev, smallest, largest))\n \n \ndef _test(N=2000):\n _test_generator(N, random, ())\n _test_generator(N, normalvariate, (0.0, 1.0))\n _test_generator(N, lognormvariate, (0.0, 1.0))\n _test_generator(N, vonmisesvariate, (0.0, 1.0))\n _test_generator(N, gammavariate, (0.01, 1.0))\n _test_generator(N, gammavariate, (0.1, 1.0))\n _test_generator(N, gammavariate, (0.1, 2.0))\n _test_generator(N, gammavariate, (0.5, 1.0))\n _test_generator(N, gammavariate, (0.9, 1.0))\n _test_generator(N, gammavariate, (1.0, 1.0))\n _test_generator(N, gammavariate, (2.0, 1.0))\n _test_generator(N, gammavariate, (20.0, 1.0))\n _test_generator(N, gammavariate, (200.0, 1.0))\n _test_generator(N, gauss, (0.0, 1.0))\n _test_generator(N, betavariate, (3.0, 3.0))\n _test_generator(N, triangular, (0.0, 1.0, 1.0/3.0))\n \n \n \n \n \n \n \n_inst = Random()\nseed = _inst.seed\nrandom = _inst.random\nuniform = _inst.uniform\ntriangular = _inst.triangular\nrandint = _inst.randint\nchoice = _inst.choice\nrandrange = _inst.randrange\nsample = _inst.sample\nshuffle = _inst.shuffle\nnormalvariate = _inst.normalvariate\nlognormvariate = _inst.lognormvariate\nexpovariate = _inst.expovariate\nvonmisesvariate = _inst.vonmisesvariate\ngammavariate = _inst.gammavariate\ngauss = _inst.gauss\nbetavariate = _inst.betavariate\nparetovariate = _inst.paretovariate\nweibullvariate = _inst.weibullvariate\ngetstate = _inst.getstate\nsetstate = _inst.setstate\ngetrandbits = _inst.getrandbits\n\nif __name__ == '__main__':\n _test()\n"], "test.test_re": [".py", "\n\n\n\nverbose = True\n\n\n\nimport re\n\n\n\nimport sre_constants\nimport sys\nimport string\nimport traceback\n\n\n\n\n\n\n\n\n\nimport unittest\n\nclass ReTests(unittest.TestCase):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n def test_search_star_plus(self):\n  self.assertEqual(re.search('x*', 'axx').span(0), (0, 0))\n  self.assertEqual(re.search('x*', 'axx').span(), (0, 0))\n  self.assertEqual(re.search('x+', 'axx').span(0), (1, 3))\n  self.assertEqual(re.search('x+', 'axx').span(), (1, 3))\n  self.assertEqual(re.search('x', 'aaa'), None)\n  self.assertEqual(re.match('a*', 'xxx').span(0), (0, 0))\n  self.assertEqual(re.match('a*', 'xxx').span(), (0, 0))\n  self.assertEqual(re.match('x*', 'xxxa').span(0), (0, 3))\n  self.assertEqual(re.match('x*', 'xxxa').span(), (0, 3))\n  self.assertEqual(re.match('a+', 'xxx'), None)\n  \n def bump_num(self, matchobj):\n  int_value = int(matchobj.group(0))\n  return str(int_value + 1)\n  \n def test_basic_re_sub(self):\n  self.assertEqual(re.sub(\"(?i)b+\", \"x\", \"bbbb BBBB\"), 'x x')\n  self.assertEqual(re.sub(r'\\d+', self.bump_num, '08.2 -2 23x99y'),\n  '9.3 -3 24x100y')\n  self.assertEqual(re.sub(r'\\d+', self.bump_num, '08.2 -2 23x99y', 3),\n  '9.3 -3 23x99y')\n  \n  self.assertEqual(re.sub('.', lambda m: r\"\\n\", 'x'), '\\\\n')\n  self.assertEqual(re.sub('.', r\"\\n\", 'x'), '\\n')\n  \n  s = r\"\\1\\1\"\n  self.assertEqual(re.sub('(.)', s, 'x'), 'xx')\n  self.assertEqual(re.sub('(.)', re.escape(s), 'x'), s)\n  self.assertEqual(re.sub('(.)', lambda m: s, 'x'), s)\n  \n  self.assertEqual(re.sub('(?P<a>x)', '\\g<a>\\g<a>', 'xx'), 'xxxx')\n  self.assertEqual(re.sub('(?P<a>x)', '\\g<a>\\g<1>', 'xx'), 'xxxx')\n  self.assertEqual(re.sub('(?P<unk>x)', '\\g<unk>\\g<unk>', 'xx'), 'xxxx')\n  self.assertEqual(re.sub('(?P<unk>x)', '\\g<1>\\g<1>', 'xx'), 'xxxx')\n  \n  self.assertEqual(re.sub('a',r'\\t\\n\\v\\r\\f\\a\\b\\B\\Z\\a\\A\\w\\W\\s\\S\\d\\D','a'),\n  '\\t\\n\\v\\r\\f\\a\\b\\\\B\\\\Z\\a\\\\A\\\\w\\\\W\\\\s\\\\S\\\\d\\\\D')\n  self.assertEqual(re.sub('a', '\\t\\n\\v\\r\\f\\a', 'a'), '\\t\\n\\v\\r\\f\\a')\n  self.assertEqual(re.sub('a', '\\t\\n\\v\\r\\f\\a', 'a'),\n  (chr(9)+chr(10)+chr(11)+chr(13)+chr(12)+chr(7)))\n  \n  self.assertEqual(re.sub('^\\s*', 'X', 'test'), 'Xtest')\n  \n def test_bug_449964(self):\n \n  self.assertEqual(re.sub(r'(?P<unk>x)', '\\g<1>\\g<1>\\\\b', 'xx'),\n  'xx\\bxx\\b')\n  \n def test_bug_449000(self):\n \n  self.assertEqual(re.sub(r'\\r\\n', r'\\n', 'abc\\r\\ndef\\r\\n'),\n  'abc\\ndef\\n')\n  self.assertEqual(re.sub('\\r\\n', r'\\n', 'abc\\r\\ndef\\r\\n'),\n  'abc\\ndef\\n')\n  self.assertEqual(re.sub(r'\\r\\n', '\\n', 'abc\\r\\ndef\\r\\n'),\n  'abc\\ndef\\n')\n  self.assertEqual(re.sub('\\r\\n', '\\n', 'abc\\r\\ndef\\r\\n'),\n  'abc\\ndef\\n')\n  \n def test_bug_1661(self):\n \n  pattern = re.compile('.')\n  self.assertRaises(ValueError, re.match, pattern, 'A', re.I)\n  self.assertRaises(ValueError, re.search, pattern, 'A', re.I)\n  self.assertRaises(ValueError, re.findall, pattern, 'A', re.I)\n  self.assertRaises(ValueError, re.compile, pattern, re.I)\n  \n def test_bug_3629(self):\n \n  re.compile(\"(?P<quote>)(?(quote))\")\n  \n def test_sub_template_numeric_escape(self):\n \n  self.assertEqual(re.sub('x', r'\\0', 'x'), '\\0')\n  self.assertEqual(re.sub('x', r'\\000', 'x'), '\\000')\n  self.assertEqual(re.sub('x', r'\\001', 'x'), '\\001')\n  self.assertEqual(re.sub('x', r'\\008', 'x'), '\\0' + '8')\n  self.assertEqual(re.sub('x', r'\\009', 'x'), '\\0' + '9')\n  self.assertEqual(re.sub('x', r'\\111', 'x'), '\\111')\n  self.assertEqual(re.sub('x', r'\\117', 'x'), '\\117')\n  \n  self.assertEqual(re.sub('x', r'\\1111', 'x'), '\\1111')\n  self.assertEqual(re.sub('x', r'\\1111', 'x'), '\\111' + '1')\n  \n  self.assertEqual(re.sub('x', r'\\00', 'x'), '\\x00')\n  self.assertEqual(re.sub('x', r'\\07', 'x'), '\\x07')\n  self.assertEqual(re.sub('x', r'\\08', 'x'), '\\0' + '8')\n  self.assertEqual(re.sub('x', r'\\09', 'x'), '\\0' + '9')\n  self.assertEqual(re.sub('x', r'\\0a', 'x'), '\\0' + 'a')\n  \n  self.assertEqual(re.sub('x', r'\\400', 'x'), '\\0')\n  self.assertEqual(re.sub('x', r'\\777', 'x'), '\\377')\n  \n  self.assertRaises(re.error, re.sub, 'x', r'\\1', 'x')\n  self.assertRaises(re.error, re.sub, 'x', r'\\8', 'x')\n  self.assertRaises(re.error, re.sub, 'x', r'\\9', 'x')\n  self.assertRaises(re.error, re.sub, 'x', r'\\11', 'x')\n  self.assertRaises(re.error, re.sub, 'x', r'\\18', 'x')\n  self.assertRaises(re.error, re.sub, 'x', r'\\1a', 'x')\n  self.assertRaises(re.error, re.sub, 'x', r'\\90', 'x')\n  self.assertRaises(re.error, re.sub, 'x', r'\\99', 'x')\n  self.assertRaises(re.error, re.sub, 'x', r'\\118', 'x') \n  self.assertRaises(re.error, re.sub, 'x', r'\\11a', 'x')\n  self.assertRaises(re.error, re.sub, 'x', r'\\181', 'x') \n  self.assertRaises(re.error, re.sub, 'x', r'\\800', 'x') \n  \n  \n  self.assertEqual(re.sub('(((((((((((x)))))))))))', r'\\11', 'x'), 'x')\n  self.assertEqual(re.sub('((((((((((y))))))))))(.)', r'\\118', 'xyz'),\n  'xz8')\n  self.assertEqual(re.sub('((((((((((y))))))))))(.)', r'\\11a', 'xyz'),\n  'xza')\n  \n def test_qualified_re_sub(self):\n  self.assertEqual(re.sub('a', 'b', 'aaaaa'), 'bbbbb')\n  self.assertEqual(re.sub('a', 'b', 'aaaaa', 1), 'baaaa')\n  \n def test_bug_114660(self):\n  self.assertEqual(re.sub(r'(\\S)\\s+(\\S)', r'\\1 \\2', 'hello  there'),\n  'hello there')\n  \n def test_bug_462270(self):\n \n  self.assertEqual(re.sub('x*', '-', 'abxd'), '-a-b-d-')\n  self.assertEqual(re.sub('x+', '-', 'abxd'), 'ab-d')\n  \n def test_symbolic_groups(self):\n  re.compile('(?P<a>x)(?P=a)(?(a)y)')\n  re.compile('(?P<a1>x)(?P=a1)(?(a1)y)')\n  self.assertRaises(re.error, re.compile, '(?P<a>)(?P<a>)')\n  self.assertRaises(re.error, re.compile, '(?Px)')\n  self.assertRaises(re.error, re.compile, '(?P=)')\n  self.assertRaises(re.error, re.compile, '(?P=1)')\n  self.assertRaises(re.error, re.compile, '(?P=a)')\n  self.assertRaises(re.error, re.compile, '(?P=a1)')\n  self.assertRaises(re.error, re.compile, '(?P=a.)')\n  self.assertRaises(re.error, re.compile, '(?P<)')\n  self.assertRaises(re.error, re.compile, '(?P<>)')\n  self.assertRaises(re.error, re.compile, '(?P<1>)')\n  self.assertRaises(re.error, re.compile, '(?P<a.>)')\n  self.assertRaises(re.error, re.compile, '(?())')\n  self.assertRaises(re.error, re.compile, '(?(a))')\n  self.assertRaises(re.error, re.compile, '(?(1a))')\n  self.assertRaises(re.error, re.compile, '(?(a.))')\n  \n  re.compile('(?P<\u00b5>x)(?P=\u00b5)(?(\u00b5)y)')\n  re.compile('(?P<\ud835\udd18\ud835\udd2b\ud835\udd26\ud835\udd20\ud835\udd2c\ud835\udd21\ud835\udd22>x)(?P=\ud835\udd18\ud835\udd2b\ud835\udd26\ud835\udd20\ud835\udd2c\ud835\udd21\ud835\udd22)(?(\ud835\udd18\ud835\udd2b\ud835\udd26\ud835\udd20\ud835\udd2c\ud835\udd21\ud835\udd22)y)')\n  self.assertRaises(re.error, re.compile, '(?P<\u00a9>x)')\n  \n def test_symbolic_refs(self):\n  self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<a', 'xx')\n  self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<', 'xx')\n  self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g', 'xx')\n  self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<a a>', 'xx')\n  self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<>', 'xx')\n  self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<1a1>', 'xx')\n  self.assertRaises(IndexError, re.sub, '(?P<a>x)', '\\g<ab>', 'xx')\n  self.assertRaises(re.error, re.sub, '(?P<a>x)|(?P<b>y)', '\\g<b>', 'xx')\n  self.assertRaises(re.error, re.sub, '(?P<a>x)|(?P<b>y)', '\\\\2', 'xx')\n  self.assertRaises(re.error, re.sub, '(?P<a>x)', '\\g<-1>', 'xx')\n  \n  self.assertEqual(re.sub('(?P<\u00b5>x)', r'\\g<\u00b5>', 'xx'), 'xx')\n  self.assertEqual(re.sub('(?P<\ud835\udd18\ud835\udd2b\ud835\udd26\ud835\udd20\ud835\udd2c\ud835\udd21\ud835\udd22>x)', r'\\g<\ud835\udd18\ud835\udd2b\ud835\udd26\ud835\udd20\ud835\udd2c\ud835\udd21\ud835\udd22>', 'xx'), 'xx')\n  self.assertRaises(re.error, re.sub, '(?P<a>x)', r'\\g<\u00a9>', 'xx')\n  \n def test_re_subn(self):\n  self.assertEqual(re.subn(\"(?i)b+\", \"x\", \"bbbb BBBB\"), ('x x', 2))\n  self.assertEqual(re.subn(\"b+\", \"x\", \"bbbb BBBB\"), ('x BBBB', 1))\n  self.assertEqual(re.subn(\"b+\", \"x\", \"xyz\"), ('xyz', 0))\n  self.assertEqual(re.subn(\"b*\", \"x\", \"xyz\"), ('xxxyxzx', 4))\n  self.assertEqual(re.subn(\"b*\", \"x\", \"xyz\", 2), ('xxxyz', 2))\n  \n def test_re_split(self):\n  self.assertEqual(re.split(\":\", \":a:b::c\"), ['', 'a', 'b', '', 'c'])\n  self.assertEqual(re.split(\":*\", \":a:b::c\"), ['', 'a', 'b', 'c'])\n  self.assertEqual(re.split(\"(:*)\", \":a:b::c\"),\n  ['', ':', 'a', ':', 'b', '::', 'c'])\n  self.assertEqual(re.split(\"(?::*)\", \":a:b::c\"), ['', 'a', 'b', 'c'])\n  self.assertEqual(re.split(\"(:)*\", \":a:b::c\"),\n  ['', ':', 'a', ':', 'b', ':', 'c'])\n  self.assertEqual(re.split(\"([b:]+)\", \":a:b::c\"),\n  ['', ':', 'a', ':b::', 'c'])\n  self.assertEqual(re.split(\"(b)|(:+)\", \":a:b::c\"),\n  ['', None, ':', 'a', None, ':', '', 'b', None, '',\n  None, '::', 'c'])\n  self.assertEqual(re.split(\"(?:b)|(?::+)\", \":a:b::c\"),\n  ['', 'a', '', '', 'c'])\n  \n def test_qualified_re_split(self):\n  self.assertEqual(re.split(\":\", \":a:b::c\", 2), ['', 'a', 'b::c'])\n  self.assertEqual(re.split(':', 'a:b:c:d', 2), ['a', 'b', 'c:d'])\n  self.assertEqual(re.split(\"(:)\", \":a:b::c\", 2),\n  ['', ':', 'a', ':', 'b::c'])\n  self.assertEqual(re.split(\"(:*)\", \":a:b::c\", 2),\n  ['', ':', 'a', ':', 'b::c'])\n  \n def test_re_findall(self):\n  self.assertEqual(re.findall(\":+\", \"abc\"), [])\n  self.assertEqual(re.findall(\":+\", \"a:b::c:::d\"), [\":\", \"::\", \":::\"])\n  self.assertEqual(re.findall(\"(:+)\", \"a:b::c:::d\"), [\":\", \"::\", \":::\"])\n  self.assertEqual(re.findall(\"(:)(:*)\", \"a:b::c:::d\"), [(\":\", \"\"),\n  (\":\", \":\"),\n  (\":\", \"::\")])\n  \n def test_bug_117612(self):\n  self.assertEqual(re.findall(r\"(a|(b))\", \"aba\"),\n  [(\"a\", \"\"),(\"b\", \"b\"),(\"a\", \"\")])\n  \n def test_re_match(self):\n  self.assertEqual(re.match('a', 'a').groups(), ())\n  self.assertEqual(re.match('(a)', 'a').groups(), ('a',))\n  self.assertEqual(re.match(r'(a)', 'a').group(0), 'a')\n  self.assertEqual(re.match(r'(a)', 'a').group(1), 'a')\n  self.assertEqual(re.match(r'(a)', 'a').group(1, 1), ('a', 'a'))\n  \n  pat = re.compile('((a)|(b))(c)?')\n  self.assertEqual(pat.match('a').groups(), ('a', 'a', None, None))\n  self.assertEqual(pat.match('b').groups(), ('b', None, 'b', None))\n  self.assertEqual(pat.match('ac').groups(), ('a', 'a', None, 'c'))\n  self.assertEqual(pat.match('bc').groups(), ('b', None, 'b', 'c'))\n  self.assertEqual(pat.match('bc').groups(\"\"), ('b', \"\", 'b', 'c'))\n  \n  \n  m = re.match('(a)', 'a')\n  self.assertEqual(m.group(0), 'a')\n  self.assertEqual(m.group(0), 'a')\n  self.assertEqual(m.group(1), 'a')\n  self.assertEqual(m.group(1, 1), ('a', 'a'))\n  \n  pat = re.compile('(?:(?P<a1>a)|(?P<b2>b))(?P<c3>c)?')\n  self.assertEqual(pat.match('a').group(1, 2, 3), ('a', None, None))\n  self.assertEqual(pat.match('b').group('a1', 'b2', 'c3'),\n  (None, 'b', None))\n  self.assertEqual(pat.match('ac').group(1, 'b2', 3), ('a', None, 'c'))\n  \n def test_re_groupref_exists(self):\n  self.assertEqual(re.match('^(\\()?([^()]+)(?(1)\\))$', '(a)').groups(),\n  ('(', 'a'))\n  self.assertEqual(re.match('^(\\()?([^()]+)(?(1)\\))$', 'a').groups(),\n  (None, 'a'))\n  self.assertEqual(re.match('^(\\()?([^()]+)(?(1)\\))$', 'a)'), None)\n  self.assertEqual(re.match('^(\\()?([^()]+)(?(1)\\))$', '(a'), None)\n  self.assertEqual(re.match('^(?:(a)|c)((?(1)b|d))$', 'ab').groups(),\n  ('a', 'b'))\n  self.assertEqual(re.match('^(?:(a)|c)((?(1)b|d))$', 'cd').groups(),\n  (None, 'd'))\n  self.assertEqual(re.match('^(?:(a)|c)((?(1)|d))$', 'cd').groups(),\n  (None, 'd'))\n  self.assertEqual(re.match('^(?:(a)|c)((?(1)|d))$', 'a').groups(),\n  ('a', ''))\n  \n  \n  p = re.compile('(?P<g1>a)(?P<g2>b)?((?(g2)c|d))')\n  self.assertEqual(p.match('abc').groups(),\n  ('a', 'b', 'c'))\n  self.assertEqual(p.match('ad').groups(),\n  ('a', None, 'd'))\n  self.assertEqual(p.match('abd'), None)\n  self.assertEqual(p.match('ac'), None)\n  \n  \n def test_re_groupref(self):\n  self.assertEqual(re.match(r'^(\\|)?([^()]+)\\1$', '|a|').groups(),\n  ('|', 'a'))\n  self.assertEqual(re.match(r'^(\\|)?([^()]+)\\1?$', 'a').groups(),\n  (None, 'a'))\n  self.assertEqual(re.match(r'^(\\|)?([^()]+)\\1$', 'a|'), None)\n  self.assertEqual(re.match(r'^(\\|)?([^()]+)\\1$', '|a'), None)\n  self.assertEqual(re.match(r'^(?:(a)|c)(\\1)$', 'aa').groups(),\n  ('a', 'a'))\n  self.assertEqual(re.match(r'^(?:(a)|c)(\\1)?$', 'c').groups(),\n  (None, None))\n  \n def test_groupdict(self):\n  self.assertEqual(re.match('(?P<first>first) (?P<second>second)',\n  'first second').groupdict(),\n  {'first':'first', 'second':'second'})\n  \n def test_expand(self):\n  self.assertEqual(re.match(\"(?P<first>first) (?P<second>second)\",\n  \"first second\")\n  .expand(r\"\\2 \\1 \\g<second> \\g<first>\"),\n  \"second first second first\")\n  \n def test_repeat_minmax(self):\n  self.assertEqual(re.match(\"^(\\w){1}$\", \"abc\"), None)\n  self.assertEqual(re.match(\"^(\\w){1}?$\", \"abc\"), None)\n  self.assertEqual(re.match(\"^(\\w){1,2}$\", \"abc\"), None)\n  self.assertEqual(re.match(\"^(\\w){1,2}?$\", \"abc\"), None)\n  \n  self.assertEqual(re.match(\"^(\\w){3}$\", \"abc\").group(1), \"c\")\n  self.assertEqual(re.match(\"^(\\w){1,3}$\", \"abc\").group(1), \"c\")\n  self.assertEqual(re.match(\"^(\\w){1,4}$\", \"abc\").group(1), \"c\")\n  self.assertEqual(re.match(\"^(\\w){3,4}?$\", \"abc\").group(1), \"c\")\n  self.assertEqual(re.match(\"^(\\w){3}?$\", \"abc\").group(1), \"c\")\n  self.assertEqual(re.match(\"^(\\w){1,3}?$\", \"abc\").group(1), \"c\")\n  self.assertEqual(re.match(\"^(\\w){1,4}?$\", \"abc\").group(1), \"c\")\n  self.assertEqual(re.match(\"^(\\w){3,4}?$\", \"abc\").group(1), \"c\")\n  \n  self.assertEqual(re.match(\"^x{1}$\", \"xxx\"), None)\n  self.assertEqual(re.match(\"^x{1}?$\", \"xxx\"), None)\n  self.assertEqual(re.match(\"^x{1,2}$\", \"xxx\"), None)\n  self.assertEqual(re.match(\"^x{1,2}?$\", \"xxx\"), None)\n  \n  self.assertNotEqual(re.match(\"^x{3}$\", \"xxx\"), None)\n  self.assertNotEqual(re.match(\"^x{1,3}$\", \"xxx\"), None)\n  self.assertNotEqual(re.match(\"^x{1,4}$\", \"xxx\"), None)\n  self.assertNotEqual(re.match(\"^x{3,4}?$\", \"xxx\"), None)\n  self.assertNotEqual(re.match(\"^x{3}?$\", \"xxx\"), None)\n  self.assertNotEqual(re.match(\"^x{1,3}?$\", \"xxx\"), None)\n  self.assertNotEqual(re.match(\"^x{1,4}?$\", \"xxx\"), None)\n  self.assertNotEqual(re.match(\"^x{3,4}?$\", \"xxx\"), None)\n  \n  self.assertEqual(re.match(\"^x{}$\", \"xxx\"), None)\n  self.assertNotEqual(re.match(\"^x{}$\", \"x{}\"), None)\n  \n def test_getattr(self):\n  self.assertEqual(re.compile(\"(?i)(a)(b)\").pattern, \"(?i)(a)(b)\")\n  self.assertEqual(re.compile(\"(?i)(a)(b)\").flags, re.I | re.U)\n  self.assertEqual(re.compile(\"(?i)(a)(b)\").groups, 2)\n  self.assertEqual(re.compile(\"(?i)(a)(b)\").groupindex, {})\n  self.assertEqual(re.compile(\"(?i)(?P<first>a)(?P<other>b)\").groupindex,\n  {'first': 1, 'other': 2})\n  \n  self.assertEqual(re.match(\"(a)\", \"a\").pos, 0)\n  self.assertEqual(re.match(\"(a)\", \"a\").endpos, 1)\n  self.assertEqual(re.match(\"(a)\", \"a\").string, \"a\")\n  self.assertEqual(re.match(\"(a)\", \"a\").regs, ((0, 1), (0, 1)))\n  self.assertNotEqual(re.match(\"(a)\", \"a\").re, None)\n  \n def test_special_escapes(self):\n  self.assertEqual(re.search(r\"\\b(b.)\\b\",\n  \"abcd abc bcd bx\").group(1), \"bx\")\n  self.assertEqual(re.search(r\"\\B(b.)\\B\",\n  \"abc bcd bc abxd\").group(1), \"bx\")\n  self.assertEqual(re.search(r\"\\b(b.)\\b\",\n  \"abcd abc bcd bx\", re.LOCALE).group(1), \"bx\")\n  self.assertEqual(re.search(r\"\\B(b.)\\B\",\n  \"abc bcd bc abxd\", re.LOCALE).group(1), \"bx\")\n  self.assertEqual(re.search(r\"\\b(b.)\\b\",\n  \"abcd abc bcd bx\", re.UNICODE).group(1), \"bx\")\n  self.assertEqual(re.search(r\"\\B(b.)\\B\",\n  \"abc bcd bc abxd\", re.UNICODE).group(1), \"bx\")\n  self.assertEqual(re.search(r\"^abc$\", \"\\nabc\\n\", re.M).group(0), \"abc\")\n  self.assertEqual(re.search(r\"^\\Aabc\\Z$\", \"abc\", re.M).group(0), \"abc\")\n  self.assertEqual(re.search(r\"^\\Aabc\\Z$\", \"\\nabc\\n\", re.M), None)\n  self.assertEqual(re.search(r\"\\b(b.)\\b\",\n  \"abcd abc bcd bx\").group(1), \"bx\")\n  self.assertEqual(re.search(r\"\\B(b.)\\B\",\n  \"abc bcd bc abxd\").group(1), \"bx\")\n  self.assertEqual(re.search(r\"^abc$\", \"\\nabc\\n\", re.M).group(0), \"abc\")\n  self.assertEqual(re.search(r\"^\\Aabc\\Z$\", \"abc\", re.M).group(0), \"abc\")\n  self.assertEqual(re.search(r\"^\\Aabc\\Z$\", \"\\nabc\\n\", re.M), None)\n  self.assertEqual(re.search(r\"\\d\\D\\w\\W\\s\\S\",\n  \"1aa! a\").group(0), \"1aa! a\")\n  self.assertEqual(re.search(r\"\\d\\D\\w\\W\\s\\S\",\n  \"1aa! a\", re.LOCALE).group(0), \"1aa! a\")\n  self.assertEqual(re.search(r\"\\d\\D\\w\\W\\s\\S\",\n  \"1aa! a\", re.UNICODE).group(0), \"1aa! a\")\n  \n def test_string_boundaries(self):\n \n  self.assertEqual(re.search(r\"\\b(abc)\\b\", \"abc\").group(1),\n  \"abc\")\n  \n  self.assertTrue(re.match(r\"\\b\", \"abc\"))\n  \n  self.assertTrue(re.search(r\"\\B\", \"abc\"))\n  \n  self.assertFalse(re.match(r\"\\B\", \"abc\"))\n  \n  \n  self.assertEqual(re.search(r\"\\B\", \"\"), None)\n  \n  \n  self.assertEqual(re.search(r\"\\b\", \"\"), None)\n  \n  \n  self.assertEqual(len(re.findall(r\"\\b\", \"a\")), 2)\n  self.assertEqual(len(re.findall(r\"\\B\", \"a\")), 0)\n  \n  self.assertEqual(len(re.findall(r\"\\b\", \" \")), 0)\n  self.assertEqual(len(re.findall(r\"\\b\", \"   \")), 0)\n  \n  self.assertEqual(len(re.findall(r\"\\B\", \" \")), 2)\n  \n def test_bigcharset(self):\n  self.assertEqual(re.match(\"([\\u2222\\u2223])\",\n  \"\\u2222\").group(1), \"\\u2222\")\n  self.assertEqual(re.match(\"([\\u2222\\u2223])\",\n  \"\\u2222\", re.UNICODE).group(1), \"\\u2222\")\n  \n def test_big_codesize(self):\n \n  r = re.compile('|'.join(('%d'%x for x in range(10000))))\n  self.assertIsNotNone(r.match('1000'))\n  self.assertIsNotNone(r.match('9999'))\n  \n def test_anyall(self):\n  self.assertEqual(re.match(\"a.b\", \"a\\nb\", re.DOTALL).group(0),\n  \"a\\nb\")\n  self.assertEqual(re.match(\"a.*b\", \"a\\n\\nb\", re.DOTALL).group(0),\n  \"a\\n\\nb\")\n  \n def test_non_consuming(self):\n  self.assertEqual(re.match(\"(a(?=\\s[^a]))\", \"a b\").group(1), \"a\")\n  self.assertEqual(re.match(\"(a(?=\\s[^a]*))\", \"a b\").group(1), \"a\")\n  self.assertEqual(re.match(\"(a(?=\\s[abc]))\", \"a b\").group(1), \"a\")\n  self.assertEqual(re.match(\"(a(?=\\s[abc]*))\", \"a bc\").group(1), \"a\")\n  self.assertEqual(re.match(r\"(a)(?=\\s\\1)\", \"a a\").group(1), \"a\")\n  self.assertEqual(re.match(r\"(a)(?=\\s\\1*)\", \"a aa\").group(1), \"a\")\n  self.assertEqual(re.match(r\"(a)(?=\\s(abc|a))\", \"a a\").group(1), \"a\")\n  \n  self.assertEqual(re.match(r\"(a(?!\\s[^a]))\", \"a a\").group(1), \"a\")\n  self.assertEqual(re.match(r\"(a(?!\\s[abc]))\", \"a d\").group(1), \"a\")\n  self.assertEqual(re.match(r\"(a)(?!\\s\\1)\", \"a b\").group(1), \"a\")\n  self.assertEqual(re.match(r\"(a)(?!\\s(abc|a))\", \"a b\").group(1), \"a\")\n  \n def test_ignore_case(self):\n  self.assertEqual(re.match(\"abc\", \"ABC\", re.I).group(0), \"ABC\")\n  self.assertEqual(re.match(\"abc\", \"ABC\", re.I).group(0), \"ABC\")\n  self.assertEqual(re.match(r\"(a\\s[^a])\", \"a b\", re.I).group(1), \"a b\")\n  self.assertEqual(re.match(r\"(a\\s[^a]*)\", \"a bb\", re.I).group(1), \"a bb\")\n  self.assertEqual(re.match(r\"(a\\s[abc])\", \"a b\", re.I).group(1), \"a b\")\n  self.assertEqual(re.match(r\"(a\\s[abc]*)\", \"a bb\", re.I).group(1), \"a bb\")\n  self.assertEqual(re.match(r\"((a)\\s\\2)\", \"a a\", re.I).group(1), \"a a\")\n  self.assertEqual(re.match(r\"((a)\\s\\2*)\", \"a aa\", re.I).group(1), \"a aa\")\n  self.assertEqual(re.match(r\"((a)\\s(abc|a))\", \"a a\", re.I).group(1), \"a a\")\n  self.assertEqual(re.match(r\"((a)\\s(abc|a)*)\", \"a aa\", re.I).group(1), \"a aa\")\n  \n def test_category(self):\n  self.assertEqual(re.match(r\"(\\s)\", \" \").group(1), \" \")\n  \n def test_getlower(self):\n  import _sre\n  self.assertEqual(_sre.getlower(ord('A'), 0), ord('a'))\n  self.assertEqual(_sre.getlower(ord('A'), re.LOCALE), ord('a'))\n  self.assertEqual(_sre.getlower(ord('A'), re.UNICODE), ord('a'))\n  \n  self.assertEqual(re.match(\"abc\", \"ABC\", re.I).group(0), \"ABC\")\n  self.assertEqual(re.match(\"abc\", \"ABC\", re.I).group(0), \"ABC\")\n  \n def test_not_literal(self):\n  self.assertEqual(re.search(\"\\s([^a])\", \" b\").group(1), \"b\")\n  self.assertEqual(re.search(\"\\s([^a]*)\", \" bb\").group(1), \"bb\")\n  \n def test_search_coverage(self):\n  self.assertEqual(re.search(\"\\s(b)\", \" b\").group(1), \"b\")\n  self.assertEqual(re.search(\"a\\s\", \"a \").group(0), \"a \")\n  \n def assertMatch(self, pattern, text, match=None, span=None,\n matcher=re.match):\n  if match is None and span is None:\n  \n   match = text\n   span = (0, len(text))\n  elif match is None or span is None:\n   raise ValueError('If match is not None, span should be specified '\n   '(and vice versa).')\n  m = matcher(pattern, text)\n  self.assertTrue(m)\n  self.assertEqual(m.group(), match)\n  self.assertEqual(m.span(), span)\n  \n def test_re_escape(self):\n  alnum_chars = string.ascii_letters + string.digits + '_'\n  p = ''.join(chr(i) for i in range(256))\n  for c in p:\n   if c in alnum_chars:\n    self.assertEqual(re.escape(c), c)\n   elif c == '\\x00':\n    self.assertEqual(re.escape(c), '\\\\000')\n   else:\n    self.assertEqual(re.escape(c), '\\\\' + c)\n   self.assertMatch(re.escape(c), c)\n  self.assertMatch(re.escape(p), p)\n  \n def test_re_escape_byte(self):\n  alnum_chars = (string.ascii_letters + string.digits + '_').encode('ascii')\n  p = bytes(range(256))\n  for i in p:\n   b = bytes([i])\n   if b in alnum_chars:\n    self.assertEqual(re.escape(b), b)\n   elif i == 0:\n    self.assertEqual(re.escape(b), b'\\\\000')\n   else:\n    self.assertEqual(re.escape(b), b'\\\\' + b)\n   self.assertMatch(re.escape(b), b)\n  self.assertMatch(re.escape(p), p)\n  \n def test_re_escape_non_ascii(self):\n  s = 'xxx\\u2620\\u2620\\u2620xxx'\n  s_escaped = re.escape(s)\n  self.assertEqual(s_escaped, 'xxx\\\\\\u2620\\\\\\u2620\\\\\\u2620xxx')\n  self.assertMatch(s_escaped, s)\n  self.assertMatch('.%s+.' % re.escape('\\u2620'), s,\n  'x\\u2620\\u2620\\u2620x', (2, 7), re.search)\n  \n def test_re_escape_non_ascii_bytes(self):\n  b = 'y\\u2620y\\u2620y'.encode('utf-8')\n  b_escaped = re.escape(b)\n  self.assertEqual(b_escaped, b'y\\\\\\xe2\\\\\\x98\\\\\\xa0y\\\\\\xe2\\\\\\x98\\\\\\xa0y')\n  self.assertMatch(b_escaped, b)\n  res = re.findall(re.escape('\\u2620'.encode('utf-8')), b)\n  self.assertEqual(len(res), 2)\n  \n def pickle_test(self, pickle):\n  oldpat = re.compile('a(?:b|(c|e){1,2}?|d)+?(.)')\n  s = pickle.dumps(oldpat)\n  newpat = pickle.loads(s)\n  self.assertEqual(oldpat, newpat)\n  \n def test_constants(self):\n  self.assertEqual(re.I, re.IGNORECASE)\n  self.assertEqual(re.L, re.LOCALE)\n  self.assertEqual(re.M, re.MULTILINE)\n  self.assertEqual(re.S, re.DOTALL)\n  self.assertEqual(re.X, re.VERBOSE)\n  \n def test_flags(self):\n  for flag in [re.I, re.M, re.X, re.S, re.L]:\n   self.assertNotEqual(re.compile('^pattern$', flag), None)\n   \n def test_sre_character_literals(self):\n  for i in [0, 8, 16, 32, 64, 127, 128, 255, 256, 0xFFFF, 0x10000, 0x10FFFF]:\n   if i < 256:\n    self.assertIsNotNone(re.match(r\"\\%03o\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"\\%03o0\" % i, chr(i)+\"0\"))\n    self.assertIsNotNone(re.match(r\"\\%03o8\" % i, chr(i)+\"8\"))\n    self.assertIsNotNone(re.match(r\"\\x%02x\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"\\x%02x0\" % i, chr(i)+\"0\"))\n    self.assertIsNotNone(re.match(r\"\\x%02xz\" % i, chr(i)+\"z\"))\n   if i < 0x10000:\n    self.assertIsNotNone(re.match(r\"\\u%04x\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"\\u%04x0\" % i, chr(i)+\"0\"))\n    self.assertIsNotNone(re.match(r\"\\u%04xz\" % i, chr(i)+\"z\"))\n   self.assertIsNotNone(re.match(r\"\\U%08x\" % i, chr(i)))\n   self.assertIsNotNone(re.match(r\"\\U%08x0\" % i, chr(i)+\"0\"))\n   self.assertIsNotNone(re.match(r\"\\U%08xz\" % i, chr(i)+\"z\"))\n  self.assertIsNotNone(re.match(r\"\\0\", \"\\000\"))\n  self.assertIsNotNone(re.match(r\"\\08\", \"\\0008\"))\n  self.assertIsNotNone(re.match(r\"\\01\", \"\\001\"))\n  self.assertIsNotNone(re.match(r\"\\018\", \"\\0018\"))\n  self.assertIsNotNone(re.match(r\"\\567\", chr(0o167)))\n  self.assertRaises(re.error, re.match, r\"\\911\", \"\")\n  self.assertRaises(re.error, re.match, r\"\\x1\", \"\")\n  self.assertRaises(re.error, re.match, r\"\\x1z\", \"\")\n  self.assertRaises(re.error, re.match, r\"\\u123\", \"\")\n  self.assertRaises(re.error, re.match, r\"\\u123z\", \"\")\n  self.assertRaises(re.error, re.match, r\"\\U0001234\", \"\")\n  self.assertRaises(re.error, re.match, r\"\\U0001234z\", \"\")\n  self.assertRaises(re.error, re.match, r\"\\U00110000\", \"\")\n  \n def test_sre_character_class_literals(self):\n  for i in [0, 8, 16, 32, 64, 127, 128, 255, 256, 0xFFFF, 0x10000, 0x10FFFF]:\n   if i < 256:\n    self.assertIsNotNone(re.match(r\"[\\%o]\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"[\\%o8]\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"[\\%03o]\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"[\\%03o0]\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"[\\%03o8]\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"[\\x%02x]\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"[\\x%02x0]\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"[\\x%02xz]\" % i, chr(i)))\n   if i < 0x10000:\n    self.assertIsNotNone(re.match(r\"[\\u%04x]\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"[\\u%04x0]\" % i, chr(i)))\n    self.assertIsNotNone(re.match(r\"[\\u%04xz]\" % i, chr(i)))\n   self.assertIsNotNone(re.match(r\"[\\U%08x]\" % i, chr(i)))\n   self.assertIsNotNone(re.match(r\"[\\U%08x0]\" % i, chr(i)+\"0\"))\n   self.assertIsNotNone(re.match(r\"[\\U%08xz]\" % i, chr(i)+\"z\"))\n  self.assertIsNotNone(re.match(r\"[\\U0001d49c-\\U0001d4b5]\", \"\\U0001d49e\"))\n  self.assertRaises(re.error, re.match, r\"[\\911]\", \"\")\n  self.assertRaises(re.error, re.match, r\"[\\x1z]\", \"\")\n  self.assertRaises(re.error, re.match, r\"[\\u123z]\", \"\")\n  self.assertRaises(re.error, re.match, r\"[\\U0001234z]\", \"\")\n  self.assertRaises(re.error, re.match, r\"[\\U00110000]\", \"\")\n  \n def test_sre_byte_literals(self):\n  for i in [0, 8, 16, 32, 64, 127, 128, 255]:\n   self.assertIsNotNone(re.match((r\"\\%03o\" % i).encode(), bytes([i])))\n   self.assertIsNotNone(re.match((r\"\\%03o0\" % i).encode(), bytes([i])+b\"0\"))\n   self.assertIsNotNone(re.match((r\"\\%03o8\" % i).encode(), bytes([i])+b\"8\"))\n   self.assertIsNotNone(re.match((r\"\\x%02x\" % i).encode(), bytes([i])))\n   self.assertIsNotNone(re.match((r\"\\x%02x0\" % i).encode(), bytes([i])+b\"0\"))\n   self.assertIsNotNone(re.match((r\"\\x%02xz\" % i).encode(), bytes([i])+b\"z\"))\n  self.assertIsNotNone(re.match(br\"\\u\", b'u'))\n  self.assertIsNotNone(re.match(br\"\\U\", b'U'))\n  self.assertIsNotNone(re.match(br\"\\0\", b\"\\000\"))\n  self.assertIsNotNone(re.match(br\"\\08\", b\"\\0008\"))\n  self.assertIsNotNone(re.match(br\"\\01\", b\"\\001\"))\n  self.assertIsNotNone(re.match(br\"\\018\", b\"\\0018\"))\n  self.assertIsNotNone(re.match(br\"\\567\", bytes([0o167])))\n  self.assertRaises(re.error, re.match, br\"\\911\", b\"\")\n  self.assertRaises(re.error, re.match, br\"\\x1\", b\"\")\n  self.assertRaises(re.error, re.match, br\"\\x1z\", b\"\")\n  \n def test_sre_byte_class_literals(self):\n  for i in [0, 8, 16, 32, 64, 127, 128, 255]:\n   self.assertIsNotNone(re.match((r\"[\\%o]\" % i).encode(), bytes([i])))\n   self.assertIsNotNone(re.match((r\"[\\%o8]\" % i).encode(), bytes([i])))\n   self.assertIsNotNone(re.match((r\"[\\%03o]\" % i).encode(), bytes([i])))\n   self.assertIsNotNone(re.match((r\"[\\%03o0]\" % i).encode(), bytes([i])))\n   self.assertIsNotNone(re.match((r\"[\\%03o8]\" % i).encode(), bytes([i])))\n   self.assertIsNotNone(re.match((r\"[\\x%02x]\" % i).encode(), bytes([i])))\n   self.assertIsNotNone(re.match((r\"[\\x%02x0]\" % i).encode(), bytes([i])))\n   self.assertIsNotNone(re.match((r\"[\\x%02xz]\" % i).encode(), bytes([i])))\n  self.assertIsNotNone(re.match(br\"[\\u]\", b'u'))\n  self.assertIsNotNone(re.match(br\"[\\U]\", b'U'))\n  self.assertRaises(re.error, re.match, br\"[\\911]\", \"\")\n  self.assertRaises(re.error, re.match, br\"[\\x1z]\", \"\")\n  \n def test_bug_113254(self):\n  self.assertEqual(re.match(r'(a)|(b)', 'b').start(1), -1)\n  self.assertEqual(re.match(r'(a)|(b)', 'b').end(1), -1)\n  self.assertEqual(re.match(r'(a)|(b)', 'b').span(1), (-1, -1))\n  \n def test_bug_527371(self):\n \n  self.assertEqual(re.match(r'(a)?a','a').lastindex, None)\n  self.assertEqual(re.match(r'(a)(b)?b','ab').lastindex, 1)\n  self.assertEqual(re.match(r'(?P<a>a)(?P<b>b)?b','ab').lastgroup, 'a')\n  self.assertEqual(re.match(\"(?P<a>a(b))\", \"ab\").lastgroup, 'a')\n  self.assertEqual(re.match(\"((a))\", \"a\").lastindex, 1)\n  \n def test_bug_545855(self):\n \n \n  self.assertRaises(re.error, re.compile, 'foo[a-')\n  \n def test_bug_418626(self):\n \n \n \n  self.assertEqual(re.match('.*?c', 10000*'ab'+'cd').end(0), 20001)\n  self.assertEqual(re.match('.*?cd', 5000*'ab'+'c'+5000*'ab'+'cde').end(0),\n  20003)\n  self.assertEqual(re.match('.*?cd', 20000*'abc'+'de').end(0), 60001)\n  \n  \n  self.assertEqual(re.search('(a|b)*?c', 10000*'ab'+'cd').end(0), 20001)\n  \n def test_bug_612074(self):\n  pat=\"[\"+re.escape(\"\\u2039\")+\"]\"\n  self.assertEqual(re.compile(pat) and 1, 1)\n  \n def test_stack_overflow(self):\n \n \n  self.assertEqual(re.match('(x)*', 50000*'x').group(1), 'x')\n  self.assertEqual(re.match('(x)*y', 50000*'x'+'y').group(1), 'x')\n  self.assertEqual(re.match('(x)*?y', 50000*'x'+'y').group(1), 'x')\n  \n def test_unlimited_zero_width_repeat(self):\n \n  self.assertIsNone(re.match(r'(?:a?)*y', 'z'))\n  self.assertIsNone(re.match(r'(?:a?)+y', 'z'))\n  self.assertIsNone(re.match(r'(?:a?){2,}y', 'z'))\n  self.assertIsNone(re.match(r'(?:a?)*?y', 'z'))\n  self.assertIsNone(re.match(r'(?:a?)+?y', 'z'))\n  self.assertIsNone(re.match(r'(?:a?){2,}?y', 'z'))\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_bug_448951(self):\n \n \n  for op in '','?','*':\n   self.assertEqual(re.match(r'((.%s):)?z'%op, 'z').groups(),\n   (None, None))\n   self.assertEqual(re.match(r'((.%s):)?z'%op, 'a:z').groups(),\n   ('a:', 'a'))\n   \n def test_bug_725106(self):\n \n  self.assertEqual(re.match('^((a)|b)*', 'abc').groups(),\n  ('b', 'a'))\n  self.assertEqual(re.match('^(([ab])|c)*', 'abc').groups(),\n  ('c', 'b'))\n  self.assertEqual(re.match('^((d)|[ab])*', 'abc').groups(),\n  ('b', None))\n  self.assertEqual(re.match('^((a)c|[ab])*', 'abc').groups(),\n  ('b', None))\n  self.assertEqual(re.match('^((a)|b)*?c', 'abc').groups(),\n  ('b', 'a'))\n  self.assertEqual(re.match('^(([ab])|c)*?d', 'abcd').groups(),\n  ('c', 'b'))\n  self.assertEqual(re.match('^((d)|[ab])*?c', 'abc').groups(),\n  ('b', None))\n  self.assertEqual(re.match('^((a)c|[ab])*?c', 'abc').groups(),\n  ('b', None))\n  \n def test_bug_725149(self):\n \n  self.assertEqual(re.match('(a)(?:(?=(b)*)c)*', 'abb').groups(),\n  ('a', None))\n  self.assertEqual(re.match('(a)((?!(b)*))*', 'abb').groups(),\n  ('a', None, None))\n  \n def test_bug_764548(self):\n \n  class my_unicode(str): pass\n  pat = re.compile(my_unicode(\"abc\"))\n  self.assertEqual(pat.match(\"xyz\"), None)\n  \n def test_finditer(self):\n  iter = re.finditer(r\":+\", \"a:b::c:::d\")\n  self.assertEqual([item.group(0) for item in iter],\n  [\":\", \"::\", \":::\"])\n  \n  pat = re.compile(r\":+\")\n  iter = pat.finditer(\"a:b::c:::d\", 1, 10)\n  self.assertEqual([item.group(0) for item in iter],\n  [\":\", \"::\", \":::\"])\n  \n  pat = re.compile(r\":+\")\n  iter = pat.finditer(\"a:b::c:::d\", pos=1, endpos=10)\n  self.assertEqual([item.group(0) for item in iter],\n  [\":\", \"::\", \":::\"])\n  \n  pat = re.compile(r\":+\")\n  iter = pat.finditer(\"a:b::c:::d\", endpos=10, pos=1)\n  self.assertEqual([item.group(0) for item in iter],\n  [\":\", \"::\", \":::\"])\n  \n  pat = re.compile(r\":+\")\n  iter = pat.finditer(\"a:b::c:::d\", pos=3, endpos=8)\n  self.assertEqual([item.group(0) for item in iter],\n  [\"::\", \"::\"])\n  \n def test_bug_926075(self):\n  self.assertTrue(re.compile('bug_926075') is not\n  re.compile(b'bug_926075'))\n  \n def test_bug_931848(self):\n  pattern = eval('\"[\\u002E\\u3002\\uFF0E\\uFF61]\"')\n  self.assertEqual(re.compile(pattern).split(\"a.b.c\"),\n  ['a','b','c'])\n  \n def test_bug_581080(self):\n  iter = re.finditer(r\"\\s\", \"a b\")\n  self.assertEqual(next(iter).span(), (1,2))\n  self.assertRaises(StopIteration, next, iter)\n  \n  scanner = re.compile(r\"\\s\").scanner(\"a b\")\n  self.assertEqual(scanner.search().span(), (1, 2))\n  self.assertEqual(scanner.search(), None)\n  \n def test_bug_817234(self):\n  iter = re.finditer(r\".*\", \"asdf\")\n  self.assertEqual(next(iter).span(), (0, 4))\n  self.assertEqual(next(iter).span(), (4, 4))\n  self.assertRaises(StopIteration, next, iter)\n  \n def test_bug_6561(self):\n \n \n \n  decimal_digits = [\n  '\\u0037', \n  '\\u0e58', \n  '\\uff10', \n  ]\n  for x in decimal_digits:\n   self.assertEqual(re.match('^\\d$', x).group(0), x)\n   \n  not_decimal_digits = [\n  '\\u2165', \n  '\\u3039', \n  '\\u2082', \n  '\\u32b4', \n  ]\n  for x in not_decimal_digits:\n   self.assertIsNone(re.match('^\\d$', x))\n   \n def test_empty_array(self):\n \n  import array\n  for typecode in 'bBuhHiIlLfd':\n   a = array.array(typecode)\n   self.assertEqual(re.compile(b\"bla\").match(a), None)\n   self.assertEqual(re.compile(b\"\").match(a).groups(), ())\n   \n def test_inline_flags(self):\n \n  upper_char = chr(0x1ea0) \n  lower_char = chr(0x1ea1) \n  \n  p = re.compile(upper_char, re.I | re.U)\n  q = p.match(lower_char)\n  self.assertNotEqual(q, None)\n  \n  p = re.compile(lower_char, re.I | re.U)\n  q = p.match(upper_char)\n  self.assertNotEqual(q, None)\n  \n  p = re.compile('(?i)' + upper_char, re.U)\n  q = p.match(lower_char)\n  self.assertNotEqual(q, None)\n  \n  p = re.compile('(?i)' + lower_char, re.U)\n  q = p.match(upper_char)\n  self.assertNotEqual(q, None)\n  \n  p = re.compile('(?iu)' + upper_char)\n  q = p.match(lower_char)\n  self.assertNotEqual(q, None)\n  \n  p = re.compile('(?iu)' + lower_char)\n  q = p.match(upper_char)\n  self.assertNotEqual(q, None)\n  \n def test_dollar_matches_twice(self):\n  \"\"\n  pattern = re.compile('$')\n  self.assertEqual(pattern.sub('#', 'a\\nb\\n'), 'a\\nb#\\n#')\n  self.assertEqual(pattern.sub('#', 'a\\nb\\nc'), 'a\\nb\\nc#')\n  self.assertEqual(pattern.sub('#', '\\n'), '#\\n#')\n  \n  pattern = re.compile('$', re.MULTILINE)\n  self.assertEqual(pattern.sub('#', 'a\\nb\\n' ), 'a#\\nb#\\n#' )\n  self.assertEqual(pattern.sub('#', 'a\\nb\\nc'), 'a#\\nb#\\nc#')\n  self.assertEqual(pattern.sub('#', '\\n'), '#\\n#')\n  \n def test_bytes_str_mixing(self):\n \n  pat = re.compile('.')\n  bpat = re.compile(b'.')\n  self.assertRaises(TypeError, pat.match, b'b')\n  self.assertRaises(TypeError, bpat.match, 'b')\n  self.assertRaises(TypeError, pat.sub, b'b', 'c')\n  self.assertRaises(TypeError, pat.sub, 'b', b'c')\n  self.assertRaises(TypeError, pat.sub, b'b', b'c')\n  self.assertRaises(TypeError, bpat.sub, b'b', 'c')\n  self.assertRaises(TypeError, bpat.sub, 'b', b'c')\n  self.assertRaises(TypeError, bpat.sub, 'b', 'c')\n  \n def test_ascii_and_unicode_flag(self):\n \n  for flags in (0, re.UNICODE):\n   pat = re.compile('\\xc0', flags | re.IGNORECASE)\n   self.assertNotEqual(pat.match('\\xe0'), None)\n   pat = re.compile('\\w', flags)\n   self.assertNotEqual(pat.match('\\xe0'), None)\n  pat = re.compile('\\xc0', re.ASCII | re.IGNORECASE)\n  self.assertEqual(pat.match('\\xe0'), None)\n  pat = re.compile('(?a)\\xc0', re.IGNORECASE)\n  self.assertEqual(pat.match('\\xe0'), None)\n  pat = re.compile('\\w', re.ASCII)\n  self.assertEqual(pat.match('\\xe0'), None)\n  pat = re.compile('(?a)\\w')\n  self.assertEqual(pat.match('\\xe0'), None)\n  \n  for flags in (0, re.ASCII):\n   pat = re.compile(b'\\xc0', re.IGNORECASE)\n   self.assertEqual(pat.match(b'\\xe0'), None)\n   pat = re.compile(b'\\w')\n   self.assertEqual(pat.match(b'\\xe0'), None)\n   \n  self.assertRaises(ValueError, re.compile, b'\\w', re.UNICODE)\n  self.assertRaises(ValueError, re.compile, b'(?u)\\w')\n  self.assertRaises(ValueError, re.compile, '\\w', re.UNICODE | re.ASCII)\n  self.assertRaises(ValueError, re.compile, '(?u)\\w', re.ASCII)\n  self.assertRaises(ValueError, re.compile, '(?a)\\w', re.UNICODE)\n  self.assertRaises(ValueError, re.compile, '(?au)\\w')\n  \n def test_bug_6509(self):\n \n \n  pat = re.compile('a(\\w)')\n  self.assertEqual(pat.sub('b\\\\1', 'ac'), 'bc')\n  pat = re.compile('a(.)')\n  self.assertEqual(pat.sub('b\\\\1', 'a\\u1234'), 'b\\u1234')\n  pat = re.compile('..')\n  self.assertEqual(pat.sub(lambda m: 'str', 'a5'), 'str')\n  \n  \n  pat = re.compile(b'a(\\w)')\n  self.assertEqual(pat.sub(b'b\\\\1', b'ac'), b'bc')\n  pat = re.compile(b'a(.)')\n  self.assertEqual(pat.sub(b'b\\\\1', b'a\\xCD'), b'b\\xCD')\n  pat = re.compile(b'..')\n  self.assertEqual(pat.sub(lambda m: b'bytes', b'a5'), b'bytes')\n  \n def test_dealloc(self):\n \n  import _sre\n  \n  \n  \n  \n  long_overflow = 2**128\n  self.assertRaises(TypeError, re.finditer, \"a\", {})\n  self.assertRaises(OverflowError, _sre.compile, \"abc\", 0, [long_overflow])\n  self.assertRaises(TypeError, _sre.compile, {}, 0, [])\n  \n def test_search_dot_unicode(self):\n  self.assertIsNotNone(re.search(\"123.*-\", '123abc-'))\n  self.assertIsNotNone(re.search(\"123.*-\", '123\\xe9-'))\n  self.assertIsNotNone(re.search(\"123.*-\", '123\\u20ac-'))\n  self.assertIsNotNone(re.search(\"123.*-\", '123\\U0010ffff-'))\n  self.assertIsNotNone(re.search(\"123.*-\", '123\\xe9\\u20ac\\U0010ffff-'))\n  \n def test_compile(self):\n \n  pattern = re.compile('random pattern')\n  self.assertIsInstance(pattern, re._pattern_type)\n  same_pattern = re.compile(pattern)\n  self.assertIsInstance(same_pattern, re._pattern_type)\n  self.assertIs(same_pattern, pattern)\n  \n  self.assertRaises(TypeError, re.compile, 0)\n  \n def test_bug_13899(self):\n \n \n  self.assertEqual(re.findall(r'[\\A\\B\\b\\C\\Z]', 'AB\\bCZ'),\n  ['A', 'B', '\\b', 'C', 'Z'])\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_bug_16688(self):\n \n \n  self.assertEqual(re.findall(r\"(?i)(a)\\1\", \"aa \\u0100\"), ['a'])\n  self.assertEqual(re.match(r\"(?s).{1,3}\", \"\\u0100\\u0100\").span(), (0, 2))\n  \n def test_repeat_minmax_overflow(self):\n \n  string = \"x\" * 100000\n  self.assertEqual(re.match(r\".{65535}\", string).span(), (0, 65535))\n  self.assertEqual(re.match(r\".{,65535}\", string).span(), (0, 65535))\n  self.assertEqual(re.match(r\".{65535,}?\", string).span(), (0, 65535))\n  self.assertEqual(re.match(r\".{65536}\", string).span(), (0, 65536))\n  self.assertEqual(re.match(r\".{,65536}\", string).span(), (0, 65536))\n  self.assertEqual(re.match(r\".{65536,}?\", string).span(), (0, 65536))\n  \n  self.assertRaises(OverflowError, re.compile, r\".{%d}\" % 2**128)\n  self.assertRaises(OverflowError, re.compile, r\".{,%d}\" % 2**128)\n  self.assertRaises(OverflowError, re.compile, r\".{%d,}?\" % 2**128)\n  self.assertRaises(OverflowError, re.compile, r\".{%d,%d}\" % (2**129, 2**128))\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_backref_group_name_in_exception(self):\n \n  with self.assertRaisesRegex(sre_constants.error, '<foo>'):\n   re.compile('(?P=<foo>)')\n   \n def test_group_name_in_exception(self):\n \n  with self.assertRaisesRegex(sre_constants.error, '\\?foo'):\n   re.compile('(?P<?foo>)')\n   \n   \ndef run_re_tests():\n from test.re_tests import tests, SUCCEED, FAIL, SYNTAX_ERROR\n if verbose:\n  print('Running re_tests test suite')\n else:\n \n \n  pass\n  \n for t in tests:\n  sys.stdout.flush()\n  pattern = s = outcome = repl = expected = None\n  if len(t) == 5:\n   pattern, s, outcome, repl, expected = t\n  elif len(t) == 3:\n   pattern, s, outcome = t\n  else:\n   raise ValueError('Test tuples should have 3 or 5 fields', t)\n   \n  try:\n   obj = re.compile(pattern)\n  except re.error:\n   if outcome == SYNTAX_ERROR: pass \n   else:\n    print('=== Syntax error:', t)\n  except KeyboardInterrupt: raise KeyboardInterrupt\n  except:\n   print('*** Unexpected error ***', t)\n   if verbose:\n    traceback.print_exc(file=sys.stdout)\n  else:\n   try:\n    result = obj.search(s)\n   except re.error as msg:\n    print('=== Unexpected exception', t, repr(msg))\n   if outcome == SYNTAX_ERROR:\n   \n    pass\n   elif outcome == FAIL:\n    if result is None: pass \n    else: print('=== Succeeded incorrectly', t)\n   elif outcome == SUCCEED:\n    if result is not None:\n    \n    \n     start, end = result.span(0)\n     vardict={'found': result.group(0),\n     'groups': result.group(),\n     'flags': result.re.flags}\n     for i in range(1, 100):\n      try:\n       gi = result.group(i)\n       \n       if gi is None:\n        gi = \"None\"\n      except IndexError:\n       gi = \"Error\"\n      vardict['g%d' % i] = gi\n     for i in result.re.groupindex.keys():\n      try:\n       gi = result.group(i)\n       if gi is None:\n        gi = \"None\"\n      except IndexError:\n       gi = \"Error\"\n      vardict[i] = gi\n     repl = eval(repl, vardict)\n     if repl != expected:\n      print('=== grouping error', t, end=' ')\n      print(repr(repl) + ' should be ' + repr(expected))\n    else:\n     print('=== Failed incorrectly', t)\n     \n     \n     \n    try:\n     bpat = bytes(pattern, \"ascii\")\n     bs = bytes(s, \"ascii\")\n    except UnicodeEncodeError:\n    \n     pass\n    else:\n     try:\n      bpat = re.compile(bpat)\n     except Exception:\n      print('=== Fails on bytes pattern compile', t)\n      if verbose:\n       traceback.print_exc(file=sys.stdout)\n     else:\n      bytes_result = bpat.search(bs)\n      if bytes_result is None:\n       print('=== Fails on bytes pattern match', t)\n       \n       \n       \n       \n       \n       \n    if pattern[:2] != '\\\\B' and pattern[-2:] != '\\\\B' and result is not None:\n     obj = re.compile(pattern)\n     result = obj.search(s, result.start(0), result.end(0) + 1)\n     if result is None:\n      print('=== Failed on range-limited match', t)\n      \n      \n      \n    obj = re.compile(pattern, re.IGNORECASE)\n    result = obj.search(s)\n    if result is None:\n     print('=== Fails on case-insensitive match', t)\n     \n     \n     \n    if '(?u)' not in pattern:\n     obj = re.compile(pattern, re.LOCALE)\n     result = obj.search(s)\n     if result is None:\n      print('=== Fails on locale-sensitive match', t)\n      \n      \n      \n    obj = re.compile(pattern, re.UNICODE)\n    result = obj.search(s)\n    if result is None:\n     print('=== Fails on unicode-sensitive match', t)\n     \n     \ndef test_main():\n\n\n run_re_tests()\n \nif __name__ == \"__main__\":\n test_main()\n"], "datetime": [".py", "\"\"\n\nimport time as _time\nimport math as _math\n\ndef _cmp(x, y):\n return 0 if x == y else 1 if x > y else -1\n \nMINYEAR = 1\nMAXYEAR = 9999\n_MAXORDINAL = 3652059 \n\n\n\n\n\n\n\n\n\n\n_DAYS_IN_MONTH = [None, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n\n_DAYS_BEFORE_MONTH = [None]\ndbm = 0\nfor dim in _DAYS_IN_MONTH[1:]:\n _DAYS_BEFORE_MONTH.append(dbm)\n dbm += dim\ndel dbm, dim\n\ndef _is_leap(year):\n \"\"\n return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n \ndef _days_before_year(year):\n \"\"\n y = year - 1\n return y*365 + y//4 - y//100 + y//400\n \ndef _days_in_month(year, month):\n \"\"\n assert 1 <= month <= 12, month\n if month == 2 and _is_leap(year):\n  return 29\n return _DAYS_IN_MONTH[month]\n \ndef _days_before_month(year, month):\n \"\"\n assert 1 <= month <= 12, 'month must be in 1..12'\n return _DAYS_BEFORE_MONTH[month] + (month > 2 and _is_leap(year))\n \ndef _ymd2ord(year, month, day):\n \"\"\n assert 1 <= month <= 12, 'month must be in 1..12'\n dim = _days_in_month(year, month)\n assert 1 <= day <= dim, ('day must be in 1..%d' % dim)\n return (_days_before_year(year) +\n _days_before_month(year, month) +\n day)\n \n_DI400Y = _days_before_year(401) \n_DI100Y = _days_before_year(101) \n_DI4Y = _days_before_year(5) \n\n\n\nassert _DI4Y == 4 * 365 + 1\n\n\n\nassert _DI400Y == 4 * _DI100Y + 1\n\n\n\nassert _DI100Y == 25 * _DI4Y - 1\n\ndef _ord2ymd(n):\n \"\"\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n n -= 1\n n400, n = divmod(n, _DI400Y)\n year = n400 * 400 + 1 \n \n \n \n \n \n \n n100, n = divmod(n, _DI100Y)\n \n \n n4, n = divmod(n, _DI4Y)\n \n \n \n n1, n = divmod(n, 365)\n \n year += n100 * 100 + n4 * 4 + n1\n if n1 == 4 or n100 == 4:\n  assert n == 0\n  return year-1, 12, 31\n  \n  \n  \n leapyear = n1 == 3 and (n4 != 24 or n100 == 3)\n assert leapyear == _is_leap(year)\n month = (n + 50) >> 5\n preceding = _DAYS_BEFORE_MONTH[month] + (month > 2 and leapyear)\n if preceding > n: \n  month -= 1\n  preceding -= _DAYS_IN_MONTH[month] + (month == 2 and leapyear)\n n -= preceding\n assert 0 <= n < _days_in_month(year, month)\n \n \n \n return year, month, n+1\n \n \n_MONTHNAMES = [None, \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n_DAYNAMES = [None, \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n\n\ndef _build_struct_time(y, m, d, hh, mm, ss, dstflag):\n wday = (_ymd2ord(y, m, d) + 6) % 7\n dnum = _days_before_month(y, m) + d\n return _time.struct_time((y, m, d, hh, mm, ss, wday, dnum, dstflag))\n \ndef _format_time(hh, mm, ss, us):\n\n result = \"%02d:%02d:%02d\" % (hh, mm, ss)\n if us:\n  result += \".%06d\" % us\n return result\n \n \ndef _wrap_strftime(object, format, timetuple):\n\n freplace = None \n zreplace = None \n Zreplace = None \n \n \n newformat = []\n push = newformat.append\n i, n = 0, len(format)\n while i < n:\n  ch = format[i]\n  i += 1\n  if ch == '%':\n   if i < n:\n    ch = format[i]\n    i += 1\n    if ch == 'f':\n     if freplace is None:\n      freplace = '%06d' % getattr(object,\n      'microsecond', 0)\n     newformat.append(freplace)\n    elif ch == 'z':\n     if zreplace is None:\n      zreplace = \"\"\n      if hasattr(object, \"utcoffset\"):\n       offset = object.utcoffset()\n       if offset is not None:\n        sign = '+'\n        if offset.days < 0:\n         offset = -offset\n         sign = '-'\n        h, m = divmod(offset, timedelta(hours=1))\n        assert not m % timedelta(minutes=1), \"whole minute\"\n        m //= timedelta(minutes=1)\n        zreplace = '%c%02d%02d' % (sign, h, m)\n     assert '%' not in zreplace\n     newformat.append(zreplace)\n    elif ch == 'Z':\n     if Zreplace is None:\n      Zreplace = \"\"\n      if hasattr(object, \"tzname\"):\n       s = object.tzname()\n       if s is not None:\n       \n        Zreplace = s.replace('%', '%%')\n     newformat.append(Zreplace)\n    else:\n     push('%')\n     push(ch)\n   else:\n    push('%')\n  else:\n   push(ch)\n newformat = \"\".join(newformat)\n return _time.strftime(newformat, timetuple)\n \ndef _call_tzinfo_method(tzinfo, methname, tzinfoarg):\n if tzinfo is None:\n  return None\n return getattr(tzinfo, methname)(tzinfoarg)\n \n \ndef _check_tzname(name):\n if name is not None and not isinstance(name, str):\n  raise TypeError(\"tzinfo.tzname() must return None or string, \"\n  \"not '%s'\" % type(name))\n  \n  \n  \n  \n  \n  \n  \ndef _check_utc_offset(name, offset):\n assert name in (\"utcoffset\", \"dst\")\n if offset is None:\n  return\n if not isinstance(offset, timedelta):\n  raise TypeError(\"tzinfo.%s() must return None \"\n  \"or timedelta, not '%s'\" % (name, type(offset)))\n if offset % timedelta(minutes=1) or offset.microseconds:\n  raise ValueError(\"tzinfo.%s() must return a whole number \"\n  \"of minutes, got %s\" % (name, offset))\n if not -timedelta(1) < offset < timedelta(1):\n  raise ValueError(\"%s()=%s, must be must be strictly between\"\n  \" -timedelta(hours=24) and timedelta(hours=24)\"\n  % (name, offset))\n  \ndef _check_date_fields(year, month, day):\n if not isinstance(year, int):\n  raise TypeError('int expected')\n if not MINYEAR <= year <= MAXYEAR:\n  raise ValueError('year must be in %d..%d' % (MINYEAR, MAXYEAR), year)\n if not 1 <= month <= 12:\n  raise ValueError('month must be in 1..12', month)\n dim = _days_in_month(year, month)\n if not 1 <= day <= dim:\n  raise ValueError('day must be in 1..%d' % dim, day)\n  \ndef _check_time_fields(hour, minute, second, microsecond):\n if not isinstance(hour, int):\n  raise TypeError('int expected')\n if not 0 <= hour <= 23:\n  raise ValueError('hour must be in 0..23', hour)\n if not 0 <= minute <= 59:\n  raise ValueError('minute must be in 0..59', minute)\n if not 0 <= second <= 59:\n  raise ValueError('second must be in 0..59', second)\n if not 0 <= microsecond <= 999999:\n  raise ValueError('microsecond must be in 0..999999', microsecond)\n  \ndef _check_tzinfo_arg(tz):\n if tz is not None and not isinstance(tz, tzinfo):\n  raise TypeError(\"tzinfo argument must be None or of a tzinfo subclass\")\n  \ndef _cmperror(x, y):\n raise TypeError(\"can't compare '%s' to '%s'\" % (\n type(x).__name__, type(y).__name__))\n \nclass timedelta:\n \"\"\n __slots__ = '_days', '_seconds', '_microseconds'\n \n def __new__(cls, days=0, seconds=0, microseconds=0,\n milliseconds=0, minutes=0, hours=0, weeks=0):\n \n \n \n \n \n \n \n \n \n \n \n \n  d = s = us = 0\n  \n  \n  days += weeks*7\n  seconds += minutes*60 + hours*3600\n  microseconds += milliseconds*1000\n  \n  \n  \n  if isinstance(days, float):\n   dayfrac, days = _math.modf(days)\n   daysecondsfrac, daysecondswhole = _math.modf(dayfrac * (24.*3600.))\n   assert daysecondswhole == int(daysecondswhole) \n   s = int(daysecondswhole)\n   assert days == int(days)\n   d = int(days)\n  else:\n   daysecondsfrac = 0.0\n   d = days\n  assert isinstance(daysecondsfrac, float)\n  assert abs(daysecondsfrac) <= 1.0\n  assert isinstance(d, int)\n  assert abs(s) <= 24 * 3600\n  \n  \n  if isinstance(seconds, float):\n   secondsfrac, seconds = _math.modf(seconds)\n   assert seconds == int(seconds)\n   seconds = int(seconds)\n   secondsfrac += daysecondsfrac\n   assert abs(secondsfrac) <= 2.0\n  else:\n   secondsfrac = daysecondsfrac\n   \n  assert isinstance(secondsfrac, float)\n  assert abs(secondsfrac) <= 2.0\n  \n  assert isinstance(seconds, int)\n  days, seconds = divmod(seconds, 24*3600)\n  d += days\n  s += int(seconds) \n  assert isinstance(s, int)\n  assert abs(s) <= 2 * 24 * 3600\n  \n  \n  usdouble = secondsfrac * 1e6\n  assert abs(usdouble) < 2.1e6 \n  \n  \n  if isinstance(microseconds, float):\n   microseconds += usdouble\n   microseconds = round(microseconds, 0)\n   seconds, microseconds = divmod(microseconds, 1e6)\n   assert microseconds == int(microseconds)\n   assert seconds == int(seconds)\n   days, seconds = divmod(seconds, 24.*3600.)\n   assert days == int(days)\n   assert seconds == int(seconds)\n   d += int(days)\n   s += int(seconds) \n   assert isinstance(s, int)\n   assert abs(s) <= 3 * 24 * 3600\n  else:\n   seconds, microseconds = divmod(microseconds, 1000000)\n   days, seconds = divmod(seconds, 24*3600)\n   d += days\n   s += int(seconds) \n   assert isinstance(s, int)\n   assert abs(s) <= 3 * 24 * 3600\n   microseconds = float(microseconds)\n   microseconds += usdouble\n   microseconds = round(microseconds, 0)\n  assert abs(s) <= 3 * 24 * 3600\n  assert abs(microseconds) < 3.1e6\n  \n  \n  assert isinstance(microseconds, float)\n  assert int(microseconds) == microseconds\n  us = int(microseconds)\n  seconds, us = divmod(us, 1000000)\n  s += seconds \n  assert isinstance(s, int)\n  days, s = divmod(s, 24*3600)\n  d += days\n  \n  assert isinstance(d, int)\n  assert isinstance(s, int) and 0 <= s < 24*3600\n  assert isinstance(us, int) and 0 <= us < 1000000\n  \n  self = object.__new__(cls)\n  \n  self._days = d\n  self._seconds = s\n  self._microseconds = us\n  if abs(d) > 999999999:\n   raise OverflowError(\"timedelta # of days is too large: %d\" % d)\n   \n  return self\n  \n def __repr__(self):\n  if self._microseconds:\n   return \"%s(%d, %d, %d)\" % ('datetime.' + self.__class__.__name__,\n   self._days,\n   self._seconds,\n   self._microseconds)\n  if self._seconds:\n   return \"%s(%d, %d)\" % ('datetime.' + self.__class__.__name__,\n   self._days,\n   self._seconds)\n  return \"%s(%d)\" % ('datetime.' + self.__class__.__name__, self._days)\n  \n def __str__(self):\n  mm, ss = divmod(self._seconds, 60)\n  hh, mm = divmod(mm, 60)\n  s = \"%d:%02d:%02d\" % (hh, mm, ss)\n  if self._days:\n   def plural(n):\n    return n, abs(n) != 1 and \"s\" or \"\"\n   s = (\"%d day%s, \" % plural(self._days)) + s\n  if self._microseconds:\n   s = s + \".%06d\" % self._microseconds\n  return s\n  \n def total_seconds(self):\n  \"\"\n  return ((self.days * 86400 + self.seconds)*10**6 +\n  self.microseconds) / 10**6\n  \n  \n @property\n def days(self):\n  \"\"\n  return self._days\n  \n @property\n def seconds(self):\n  \"\"\n  return self._seconds\n  \n @property\n def microseconds(self):\n  \"\"\n  return self._microseconds\n  \n def __add__(self, other):\n  if isinstance(other, timedelta):\n  \n  \n   return timedelta(self._days + other._days,\n   self._seconds + other._seconds,\n   self._microseconds + other._microseconds)\n  return NotImplemented\n  \n __radd__ = __add__\n \n def __sub__(self, other):\n  if isinstance(other, timedelta):\n  \n  \n   return timedelta(self._days - other._days,\n   self._seconds - other._seconds,\n   self._microseconds - other._microseconds)\n  return NotImplemented\n  \n def __rsub__(self, other):\n  if isinstance(other, timedelta):\n   return -self + other\n  return NotImplemented\n  \n def __neg__(self):\n \n \n  return timedelta(-self._days,\n  -self._seconds,\n  -self._microseconds)\n  \n def __pos__(self):\n  return self\n  \n def __abs__(self):\n  if self._days < 0:\n   return -self\n  else:\n   return self\n   \n def __mul__(self, other):\n  if isinstance(other, int):\n  \n  \n   return timedelta(self._days * other,\n   self._seconds * other,\n   self._microseconds * other)\n  if isinstance(other, float):\n   a, b = other.as_integer_ratio()\n   return self * a / b\n  return NotImplemented\n  \n __rmul__ = __mul__\n \n def _to_microseconds(self):\n  return ((self._days * (24*3600) + self._seconds) * 1000000 +\n  self._microseconds)\n  \n def __floordiv__(self, other):\n  if not isinstance(other, (int, timedelta)):\n   return NotImplemented\n  usec = self._to_microseconds()\n  if isinstance(other, timedelta):\n   return usec // other._to_microseconds()\n  if isinstance(other, int):\n   return timedelta(0, 0, usec // other)\n   \n def __truediv__(self, other):\n  if not isinstance(other, (int, float, timedelta)):\n   return NotImplemented\n  usec = self._to_microseconds()\n  if isinstance(other, timedelta):\n   return usec / other._to_microseconds()\n  if isinstance(other, int):\n   return timedelta(0, 0, usec / other)\n  if isinstance(other, float):\n   a, b = other.as_integer_ratio()\n   return timedelta(0, 0, b * usec / a)\n   \n def __mod__(self, other):\n  if isinstance(other, timedelta):\n   r = self._to_microseconds() % other._to_microseconds()\n   return timedelta(0, 0, r)\n  return NotImplemented\n  \n def __divmod__(self, other):\n  if isinstance(other, timedelta):\n   q, r = divmod(self._to_microseconds(),\n   other._to_microseconds())\n   return q, timedelta(0, 0, r)\n  return NotImplemented\n  \n  \n  \n def __eq__(self, other):\n  if isinstance(other, timedelta):\n   return self._cmp(other) == 0\n  else:\n   return False\n   \n def __ne__(self, other):\n  if isinstance(other, timedelta):\n   return self._cmp(other) != 0\n  else:\n   return True\n   \n def __le__(self, other):\n  if isinstance(other, timedelta):\n   return self._cmp(other) <= 0\n  else:\n   _cmperror(self, other)\n   \n def __lt__(self, other):\n  if isinstance(other, timedelta):\n   return self._cmp(other) < 0\n  else:\n   _cmperror(self, other)\n   \n def __ge__(self, other):\n  if isinstance(other, timedelta):\n   return self._cmp(other) >= 0\n  else:\n   _cmperror(self, other)\n   \n def __gt__(self, other):\n  if isinstance(other, timedelta):\n   return self._cmp(other) > 0\n  else:\n   _cmperror(self, other)\n   \n def _cmp(self, other):\n  assert isinstance(other, timedelta)\n  return _cmp(self._getstate(), other._getstate())\n  \n def __hash__(self):\n  return hash(self._getstate())\n  \n def __bool__(self):\n  return (self._days != 0 or\n  self._seconds != 0 or\n  self._microseconds != 0)\n  \n  \n  \n def _getstate(self):\n  return (self._days, self._seconds, self._microseconds)\n  \n def __reduce__(self):\n  return (self.__class__, self._getstate())\n  \ntimedelta.min = timedelta(-999999999)\ntimedelta.max = timedelta(days=999999999, hours=23, minutes=59, seconds=59,\nmicroseconds=999999)\ntimedelta.resolution = timedelta(microseconds=1)\n\nclass date:\n \"\"\n __slots__ = '_year', '_month', '_day'\n \n def __new__(cls, year, month=None, day=None):\n  \"\"\n  if (isinstance(year, bytes) and len(year) == 4 and\n  1 <= year[2] <= 12 and month is None): \n  \n   self = object.__new__(cls)\n   self.__setstate(year)\n   return self\n  _check_date_fields(year, month, day)\n  self = object.__new__(cls)\n  self._year = year\n  self._month = month\n  self._day = day\n  return self\n  \n  \n  \n @classmethod\n def fromtimestamp(cls, t):\n  \"\"\n  y, m, d, hh, mm, ss, weekday, jday, dst = _time.localtime(t)\n  return cls(y, m, d)\n  \n @classmethod\n def today(cls):\n  \"\"\n  t = _time.time()\n  return cls.fromtimestamp(t)\n  \n @classmethod\n def fromordinal(cls, n):\n  \"\"\n  y, m, d = _ord2ymd(n)\n  return cls(y, m, d)\n  \n  \n  \n def __repr__(self):\n  \"\"\n  return \"%s(%d, %d, %d)\" % ('datetime.' + self.__class__.__name__,\n  self._year,\n  self._month,\n  self._day)\n  \n  \n  \n  \n  \n  \n def ctime(self):\n  \"\"\n  weekday = self.toordinal() % 7 or 7\n  return \"%s %s %2d 00:00:00 %04d\" % (\n  _DAYNAMES[weekday],\n  _MONTHNAMES[self._month],\n  self._day, self._year)\n  \n def strftime(self, fmt):\n  \"\"\n  return _wrap_strftime(self, fmt, self.timetuple())\n  \n def __format__(self, fmt):\n  if len(fmt) != 0:\n   return self.strftime(fmt)\n  return str(self)\n  \n def isoformat(self):\n  \"\"\n  return \"%04d-%02d-%02d\" % (self._year, self._month, self._day)\n  \n __str__ = isoformat\n \n \n @property\n def year(self):\n  \"\"\n  return self._year\n  \n @property\n def month(self):\n  \"\"\n  return self._month\n  \n @property\n def day(self):\n  \"\"\n  return self._day\n  \n  \n  \n def timetuple(self):\n  \"\"\n  return _build_struct_time(self._year, self._month, self._day,\n  0, 0, 0, -1)\n  \n def toordinal(self):\n  \"\"\n  return _ymd2ord(self._year, self._month, self._day)\n  \n def replace(self, year=None, month=None, day=None):\n  \"\"\n  if year is None:\n   year = self._year\n  if month is None:\n   month = self._month\n  if day is None:\n   day = self._day\n  _check_date_fields(year, month, day)\n  return date(year, month, day)\n  \n  \n  \n def __eq__(self, other):\n  if isinstance(other, date):\n   return self._cmp(other) == 0\n  return NotImplemented\n  \n def __ne__(self, other):\n  if isinstance(other, date):\n   return self._cmp(other) != 0\n  return NotImplemented\n  \n def __le__(self, other):\n  if isinstance(other, date):\n   return self._cmp(other) <= 0\n  return NotImplemented\n  \n def __lt__(self, other):\n  if isinstance(other, date):\n   return self._cmp(other) < 0\n  return NotImplemented\n  \n def __ge__(self, other):\n  if isinstance(other, date):\n   return self._cmp(other) >= 0\n  return NotImplemented\n  \n def __gt__(self, other):\n  if isinstance(other, date):\n   return self._cmp(other) > 0\n  return NotImplemented\n  \n def _cmp(self, other):\n  assert isinstance(other, date)\n  y, m, d = self._year, self._month, self._day\n  y2, m2, d2 = other._year, other._month, other._day\n  return _cmp((y, m, d), (y2, m2, d2))\n  \n def __hash__(self):\n  \"\"\n  return hash(self._getstate())\n  \n  \n  \n def __add__(self, other):\n  \"\"\n  if isinstance(other, timedelta):\n   o = self.toordinal() + other.days\n   if 0 < o <= _MAXORDINAL:\n    return date.fromordinal(o)\n   raise OverflowError(\"result out of range\")\n  return NotImplemented\n  \n __radd__ = __add__\n \n def __sub__(self, other):\n  \"\"\n  if isinstance(other, timedelta):\n   return self + timedelta(-other.days)\n  if isinstance(other, date):\n   days1 = self.toordinal()\n   days2 = other.toordinal()\n   return timedelta(days1 - days2)\n  return NotImplemented\n  \n def weekday(self):\n  \"\"\n  return (self.toordinal() + 6) % 7\n  \n  \n  \n def isoweekday(self):\n  \"\"\n  \n  return self.toordinal() % 7 or 7\n  \n def isocalendar(self):\n  \"\"\n  year = self._year\n  week1monday = _isoweek1monday(year)\n  today = _ymd2ord(self._year, self._month, self._day)\n  \n  week, day = divmod(today - week1monday, 7)\n  if week < 0:\n   year -= 1\n   week1monday = _isoweek1monday(year)\n   week, day = divmod(today - week1monday, 7)\n  elif week >= 52:\n   if today >= _isoweek1monday(year+1):\n    year += 1\n    week = 0\n  return year, week+1, day+1\n  \n  \n  \n def _getstate(self):\n  yhi, ylo = divmod(self._year, 256)\n  return bytes([yhi, ylo, self._month, self._day]),\n  \n def __setstate(self, string):\n  if len(string) != 4 or not (1 <= string[2] <= 12):\n   raise TypeError(\"not enough arguments\")\n  yhi, ylo, self._month, self._day = string\n  self._year = yhi * 256 + ylo\n  \n def __reduce__(self):\n  return (self.__class__, self._getstate())\n  \n_date_class = date \n\ndate.min = date(1, 1, 1)\ndate.max = date(9999, 12, 31)\ndate.resolution = timedelta(days=1)\n\nclass tzinfo:\n \"\"\n __slots__ = ()\n def tzname(self, dt):\n  \"\"\n  raise NotImplementedError(\"tzinfo subclass must override tzname()\")\n  \n def utcoffset(self, dt):\n  \"\"\n  raise NotImplementedError(\"tzinfo subclass must override utcoffset()\")\n  \n def dst(self, dt):\n  \"\"\n  raise NotImplementedError(\"tzinfo subclass must override dst()\")\n  \n def fromutc(self, dt):\n  \"\"\n  \n  if not isinstance(dt, datetime):\n   raise TypeError(\"fromutc() requires a datetime argument\")\n  if dt.tzinfo is not self:\n   raise ValueError(\"dt.tzinfo is not self\")\n   \n  dtoff = dt.utcoffset()\n  if dtoff is None:\n   raise ValueError(\"fromutc() requires a non-None utcoffset() \"\n   \"result\")\n   \n   \n   \n  dtdst = dt.dst()\n  if dtdst is None:\n   raise ValueError(\"fromutc() requires a non-None dst() result\")\n  delta = dtoff - dtdst\n  if delta:\n   dt += delta\n   dtdst = dt.dst()\n   if dtdst is None:\n    raise ValueError(\"fromutc(): dt.dst gave inconsistent \"\n    \"results; cannot convert\")\n  return dt + dtdst\n  \n  \n  \n def __reduce__(self):\n  getinitargs = getattr(self, \"__getinitargs__\", None)\n  if getinitargs:\n   args = getinitargs()\n  else:\n   args = ()\n  getstate = getattr(self, \"__getstate__\", None)\n  if getstate:\n   state = getstate()\n  else:\n   state = getattr(self, \"__dict__\", None) or None\n  if state is None:\n   return (self.__class__, args)\n  else:\n   return (self.__class__, args, state)\n   \n_tzinfo_class = tzinfo\n\nclass time:\n \"\"\n \n def __new__(cls, hour=0, minute=0, second=0, microsecond=0, tzinfo=None):\n  \"\"\n  self = object.__new__(cls)\n  if isinstance(hour, bytes) and len(hour) == 6:\n  \n   self.__setstate(hour, minute or None)\n   return self\n  _check_tzinfo_arg(tzinfo)\n  _check_time_fields(hour, minute, second, microsecond)\n  self._hour = hour\n  self._minute = minute\n  self._second = second\n  self._microsecond = microsecond\n  self._tzinfo = tzinfo\n  return self\n  \n  \n @property\n def hour(self):\n  \"\"\n  return self._hour\n  \n @property\n def minute(self):\n  \"\"\n  return self._minute\n  \n @property\n def second(self):\n  \"\"\n  return self._second\n  \n @property\n def microsecond(self):\n  \"\"\n  return self._microsecond\n  \n @property\n def tzinfo(self):\n  \"\"\n  return self._tzinfo\n  \n  \n  \n  \n  \n def __eq__(self, other):\n  if isinstance(other, time):\n   return self._cmp(other, allow_mixed=True) == 0\n  else:\n   return False\n   \n def __ne__(self, other):\n  if isinstance(other, time):\n   return self._cmp(other, allow_mixed=True) != 0\n  else:\n   return True\n   \n def __le__(self, other):\n  if isinstance(other, time):\n   return self._cmp(other) <= 0\n  else:\n   _cmperror(self, other)\n   \n def __lt__(self, other):\n  if isinstance(other, time):\n   return self._cmp(other) < 0\n  else:\n   _cmperror(self, other)\n   \n def __ge__(self, other):\n  if isinstance(other, time):\n   return self._cmp(other) >= 0\n  else:\n   _cmperror(self, other)\n   \n def __gt__(self, other):\n  if isinstance(other, time):\n   return self._cmp(other) > 0\n  else:\n   _cmperror(self, other)\n   \n def _cmp(self, other, allow_mixed=False):\n  assert isinstance(other, time)\n  mytz = self._tzinfo\n  ottz = other._tzinfo\n  myoff = otoff = None\n  \n  if mytz is ottz:\n   base_compare = True\n  else:\n   myoff = self.utcoffset()\n   otoff = other.utcoffset()\n   base_compare = myoff == otoff\n   \n  if base_compare:\n   return _cmp((self._hour, self._minute, self._second,\n   self._microsecond),\n   (other._hour, other._minute, other._second,\n   other._microsecond))\n  if myoff is None or otoff is None:\n   if allow_mixed:\n    return 2 \n   else:\n    raise TypeError(\"cannot compare naive and aware times\")\n  myhhmm = self._hour * 60 + self._minute - myoff//timedelta(minutes=1)\n  othhmm = other._hour * 60 + other._minute - otoff//timedelta(minutes=1)\n  return _cmp((myhhmm, self._second, self._microsecond),\n  (othhmm, other._second, other._microsecond))\n  \n def __hash__(self):\n  \"\"\n  tzoff = self.utcoffset()\n  if not tzoff: \n   return hash(self._getstate()[0])\n  h, m = divmod(timedelta(hours=self.hour, minutes=self.minute) - tzoff,\n  timedelta(hours=1))\n  assert not m % timedelta(minutes=1), \"whole minute\"\n  m //= timedelta(minutes=1)\n  if 0 <= h < 24:\n   return hash(time(h, m, self.second, self.microsecond))\n  return hash((h, m, self.second, self.microsecond))\n  \n  \n  \n def _tzstr(self, sep=\":\"):\n  \"\"\n  off = self.utcoffset()\n  if off is not None:\n   if off.days < 0:\n    sign = \"-\"\n    off = -off\n   else:\n    sign = \"+\"\n   hh, mm = divmod(off, timedelta(hours=1))\n   assert not mm % timedelta(minutes=1), \"whole minute\"\n   mm //= timedelta(minutes=1)\n   assert 0 <= hh < 24\n   off = \"%s%02d%s%02d\" % (sign, hh, sep, mm)\n  return off\n  \n def __repr__(self):\n  \"\"\n  if self._microsecond != 0:\n   s = \", %d, %d\" % (self._second, self._microsecond)\n  elif self._second != 0:\n   s = \", %d\" % self._second\n  else:\n   s = \"\"\n  s= \"%s(%d, %d%s)\" % ('datetime.' + self.__class__.__name__,\n  self._hour, self._minute, s)\n  if self._tzinfo is not None:\n   assert s[-1:] == \")\"\n   s = s[:-1] + \", tzinfo=%r\" % self._tzinfo + \")\"\n  return s\n  \n def isoformat(self):\n  \"\"\n  s = _format_time(self._hour, self._minute, self._second,\n  self._microsecond)\n  tz = self._tzstr()\n  if tz:\n   s += tz\n  return s\n  \n __str__ = isoformat\n \n def strftime(self, fmt):\n  \"\"\n  \n  \n  timetuple = (1900, 1, 1,\n  self._hour, self._minute, self._second,\n  0, 1, -1)\n  return _wrap_strftime(self, fmt, timetuple)\n  \n def __format__(self, fmt):\n  if len(fmt) != 0:\n   return self.strftime(fmt)\n  return str(self)\n  \n  \n  \n def utcoffset(self):\n  \"\"\n  if self._tzinfo is None:\n   return None\n  offset = self._tzinfo.utcoffset(None)\n  _check_utc_offset(\"utcoffset\", offset)\n  return offset\n  \n def tzname(self):\n  \"\"\n  if self._tzinfo is None:\n   return None\n  name = self._tzinfo.tzname(None)\n  _check_tzname(name)\n  return name\n  \n def dst(self):\n  \"\"\n  if self._tzinfo is None:\n   return None\n  offset = self._tzinfo.dst(None)\n  _check_utc_offset(\"dst\", offset)\n  return offset\n  \n def replace(self, hour=None, minute=None, second=None, microsecond=None,\n tzinfo=True):\n  \"\"\n  if hour is None:\n   hour = self.hour\n  if minute is None:\n   minute = self.minute\n  if second is None:\n   second = self.second\n  if microsecond is None:\n   microsecond = self.microsecond\n  if tzinfo is True:\n   tzinfo = self.tzinfo\n  _check_time_fields(hour, minute, second, microsecond)\n  _check_tzinfo_arg(tzinfo)\n  return time(hour, minute, second, microsecond, tzinfo)\n  \n def __bool__(self):\n  if self.second or self.microsecond:\n   return True\n  offset = self.utcoffset() or timedelta(0)\n  return timedelta(hours=self.hour, minutes=self.minute) != offset\n  \n  \n  \n def _getstate(self):\n  us2, us3 = divmod(self._microsecond, 256)\n  us1, us2 = divmod(us2, 256)\n  basestate = bytes([self._hour, self._minute, self._second,\n  us1, us2, us3])\n  if self._tzinfo is None:\n   return (basestate,)\n  else:\n   return (basestate, self._tzinfo)\n   \n def __setstate(self, string, tzinfo):\n  if len(string) != 6 or string[0] >= 24:\n   raise TypeError(\"an integer is required\")\n  (self._hour, self._minute, self._second,\n  us1, us2, us3) = string\n  self._microsecond = (((us1 << 8) | us2) << 8) | us3\n  if tzinfo is None or isinstance(tzinfo, _tzinfo_class):\n   self._tzinfo = tzinfo\n  else:\n   raise TypeError(\"bad tzinfo state arg %r\" % tzinfo)\n   \n def __reduce__(self):\n  return (time, self._getstate())\n  \n_time_class = time \n\ntime.min = time(0, 0, 0)\ntime.max = time(23, 59, 59, 999999)\ntime.resolution = timedelta(microseconds=1)\n\nclass datetime(date):\n \"\"\n \n __slots__ = date.__slots__ + (\n '_hour', '_minute', '_second',\n '_microsecond', '_tzinfo')\n def __new__(cls, year, month=None, day=None, hour=0, minute=0, second=0,\n microsecond=0, tzinfo=None):\n  if isinstance(year, bytes) and len(year) == 10:\n  \n   self = date.__new__(cls, year[:4])\n   self.__setstate(year, month)\n   return self\n  _check_tzinfo_arg(tzinfo)\n  _check_time_fields(hour, minute, second, microsecond)\n  self = date.__new__(cls, year, month, day)\n  self._hour = hour\n  self._minute = minute\n  self._second = second\n  self._microsecond = microsecond\n  self._tzinfo = tzinfo\n  return self\n  \n  \n @property\n def hour(self):\n  \"\"\n  return self._hour\n  \n @property\n def minute(self):\n  \"\"\n  return self._minute\n  \n @property\n def second(self):\n  \"\"\n  return self._second\n  \n @property\n def microsecond(self):\n  \"\"\n  return self._microsecond\n  \n @property\n def tzinfo(self):\n  \"\"\n  return self._tzinfo\n  \n @classmethod\n def fromtimestamp(cls, t, tz=None):\n  \"\"\n  \n  _check_tzinfo_arg(tz)\n  \n  converter = _time.localtime if tz is None else _time.gmtime\n  \n  t, frac = divmod(t, 1.0)\n  us = int(frac * 1e6)\n  \n  \n  \n  \n  \n  if us == 1000000:\n   t += 1\n   us = 0\n  y, m, d, hh, mm, ss, weekday, jday, dst = converter(t)\n  ss = min(ss, 59) \n  result = cls(y, m, d, hh, mm, ss, us, tz)\n  if tz is not None:\n   result = tz.fromutc(result)\n  return result\n  \n @classmethod\n def utcfromtimestamp(cls, t):\n  \"\"\n  t, frac = divmod(t, 1.0)\n  us = int(frac * 1e6)\n  \n  \n  \n  \n  \n  if us == 1000000:\n   t += 1\n   us = 0\n  y, m, d, hh, mm, ss, weekday, jday, dst = _time.gmtime(t)\n  ss = min(ss, 59) \n  return cls(y, m, d, hh, mm, ss, us)\n  \n  \n  \n  \n  \n  \n @classmethod\n def now(cls, tz=None):\n  \"\"\n  t = _time.time()\n  return cls.fromtimestamp(t, tz)\n  \n @classmethod\n def utcnow(cls):\n  \"\"\n  t = _time.time()\n  return cls.utcfromtimestamp(t)\n  \n @classmethod\n def combine(cls, date, time):\n  \"\"\n  if not isinstance(date, _date_class):\n   raise TypeError(\"date argument must be a date instance\")\n  if not isinstance(time, _time_class):\n   raise TypeError(\"time argument must be a time instance\")\n  return cls(date.year, date.month, date.day,\n  time.hour, time.minute, time.second, time.microsecond,\n  time.tzinfo)\n  \n def timetuple(self):\n  \"\"\n  dst = self.dst()\n  if dst is None:\n   dst = -1\n  elif dst:\n   dst = 1\n  else:\n   dst = 0\n  return _build_struct_time(self.year, self.month, self.day,\n  self.hour, self.minute, self.second,\n  dst)\n  \n def timestamp(self):\n  \"\"\n  if self._tzinfo is None:\n   return _time.mktime((self.year, self.month, self.day,\n   self.hour, self.minute, self.second,\n   -1, -1, -1)) + self.microsecond / 1e6\n  else:\n   return (self - _EPOCH).total_seconds()\n   \n def utctimetuple(self):\n  \"\"\n  offset = self.utcoffset()\n  if offset:\n   self -= offset\n  y, m, d = self.year, self.month, self.day\n  hh, mm, ss = self.hour, self.minute, self.second\n  return _build_struct_time(y, m, d, hh, mm, ss, 0)\n  \n def date(self):\n  \"\"\n  return date(self._year, self._month, self._day)\n  \n def time(self):\n  \"\"\n  return time(self.hour, self.minute, self.second, self.microsecond)\n  \n def timetz(self):\n  \"\"\n  return time(self.hour, self.minute, self.second, self.microsecond,\n  self._tzinfo)\n  \n def replace(self, year=None, month=None, day=None, hour=None,\n minute=None, second=None, microsecond=None, tzinfo=True):\n  \"\"\n  if year is None:\n   year = self.year\n  if month is None:\n   month = self.month\n  if day is None:\n   day = self.day\n  if hour is None:\n   hour = self.hour\n  if minute is None:\n   minute = self.minute\n  if second is None:\n   second = self.second\n  if microsecond is None:\n   microsecond = self.microsecond\n  if tzinfo is True:\n   tzinfo = self.tzinfo\n  _check_date_fields(year, month, day)\n  _check_time_fields(hour, minute, second, microsecond)\n  _check_tzinfo_arg(tzinfo)\n  return datetime(year, month, day, hour, minute, second,\n  microsecond, tzinfo)\n  \n def astimezone(self, tz=None):\n  if tz is None:\n   if self.tzinfo is None:\n    raise ValueError(\"astimezone() requires an aware datetime\")\n   ts = (self - _EPOCH) // timedelta(seconds=1)\n   localtm = _time.localtime(ts)\n   local = datetime(*localtm[:6])\n   try:\n   \n    gmtoff = localtm.tm_gmtoff\n    zone = localtm.tm_zone\n   except AttributeError:\n   \n   \n   \n    delta = local - datetime(*_time.gmtime(ts)[:6])\n    dst = _time.daylight and localtm.tm_isdst > 0\n    gmtoff = -(_time.altzone if dst else _time.timezone)\n    if delta == timedelta(seconds=gmtoff):\n     tz = timezone(delta, _time.tzname[dst])\n    else:\n     tz = timezone(delta)\n   else:\n    tz = timezone(timedelta(seconds=gmtoff), zone)\n    \n  elif not isinstance(tz, tzinfo):\n   raise TypeError(\"tz argument must be an instance of tzinfo\")\n   \n  mytz = self.tzinfo\n  if mytz is None:\n   raise ValueError(\"astimezone() requires an aware datetime\")\n   \n  if tz is mytz:\n   return self\n   \n   \n  myoffset = self.utcoffset()\n  if myoffset is None:\n   raise ValueError(\"astimezone() requires an aware datetime\")\n  utc = (self - myoffset).replace(tzinfo=tz)\n  \n  \n  return tz.fromutc(utc)\n  \n  \n  \n def ctime(self):\n  \"\"\n  weekday = self.toordinal() % 7 or 7\n  return \"%s %s %2d %02d:%02d:%02d %04d\" % (\n  _DAYNAMES[weekday],\n  _MONTHNAMES[self._month],\n  self._day,\n  self._hour, self._minute, self._second,\n  self._year)\n  \n def isoformat(self, sep='T'):\n  \"\"\n  s = (\"%04d-%02d-%02d%c\" % (self._year, self._month, self._day,\n  sep) +\n  _format_time(self._hour, self._minute, self._second,\n  self._microsecond))\n  off = self.utcoffset()\n  if off is not None:\n   if off.days < 0:\n    sign = \"-\"\n    off = -off\n   else:\n    sign = \"+\"\n   hh, mm = divmod(off, timedelta(hours=1))\n   assert not mm % timedelta(minutes=1), \"whole minute\"\n   mm //= timedelta(minutes=1)\n   s += \"%s%02d:%02d\" % (sign, hh, mm)\n  return s\n  \n def __repr__(self):\n  \"\"\n  L = [self._year, self._month, self._day, \n  self._hour, self._minute, self._second, self._microsecond]\n  if L[-1] == 0:\n   del L[-1]\n  if L[-1] == 0:\n   del L[-1]\n  s = \", \".join(map(str, L))\n  s = \"%s(%s)\" % ('datetime.' + self.__class__.__name__, s)\n  if self._tzinfo is not None:\n   assert s[-1:] == \")\"\n   s = s[:-1] + \", tzinfo=%r\" % self._tzinfo + \")\"\n  return s\n  \n def __str__(self):\n  \"\"\n  return self.isoformat(sep=' ')\n  \n @classmethod\n def strptime(cls, date_string, format):\n  \"\"\n  import _strptime\n  return _strptime._strptime_datetime(cls, date_string, format)\n  \n def utcoffset(self):\n  \"\"\n  if self._tzinfo is None:\n   return None\n  offset = self._tzinfo.utcoffset(self)\n  _check_utc_offset(\"utcoffset\", offset)\n  return offset\n  \n def tzname(self):\n  \"\"\n  name = _call_tzinfo_method(self._tzinfo, \"tzname\", self)\n  _check_tzname(name)\n  return name\n  \n def dst(self):\n  \"\"\n  if self._tzinfo is None:\n   return None\n  offset = self._tzinfo.dst(self)\n  _check_utc_offset(\"dst\", offset)\n  return offset\n  \n  \n  \n def __eq__(self, other):\n  if isinstance(other, datetime):\n   return self._cmp(other, allow_mixed=True) == 0\n  elif not isinstance(other, date):\n   return NotImplemented\n  else:\n   return False\n   \n def __ne__(self, other):\n  if isinstance(other, datetime):\n   return self._cmp(other, allow_mixed=True) != 0\n  elif not isinstance(other, date):\n   return NotImplemented\n  else:\n   return True\n   \n def __le__(self, other):\n  if isinstance(other, datetime):\n   return self._cmp(other) <= 0\n  elif not isinstance(other, date):\n   return NotImplemented\n  else:\n   _cmperror(self, other)\n   \n def __lt__(self, other):\n  if isinstance(other, datetime):\n   return self._cmp(other) < 0\n  elif not isinstance(other, date):\n   return NotImplemented\n  else:\n   _cmperror(self, other)\n   \n def __ge__(self, other):\n  if isinstance(other, datetime):\n   return self._cmp(other) >= 0\n  elif not isinstance(other, date):\n   return NotImplemented\n  else:\n   _cmperror(self, other)\n   \n def __gt__(self, other):\n  if isinstance(other, datetime):\n   return self._cmp(other) > 0\n  elif not isinstance(other, date):\n   return NotImplemented\n  else:\n   _cmperror(self, other)\n   \n def _cmp(self, other, allow_mixed=False):\n  assert isinstance(other, datetime)\n  mytz = self._tzinfo\n  ottz = other._tzinfo\n  myoff = otoff = None\n  \n  if mytz is ottz:\n   base_compare = True\n  else:\n   myoff = self.utcoffset()\n   otoff = other.utcoffset()\n   base_compare = myoff == otoff\n   \n  if base_compare:\n   return _cmp((self._year, self._month, self._day,\n   self._hour, self._minute, self._second,\n   self._microsecond),\n   (other._year, other._month, other._day,\n   other._hour, other._minute, other._second,\n   other._microsecond))\n  if myoff is None or otoff is None:\n   if allow_mixed:\n    return 2 \n   else:\n    raise TypeError(\"cannot compare naive and aware datetimes\")\n    \n  diff = self - other \n  if diff.days < 0:\n   return -1\n  return diff and 1 or 0\n  \n def __add__(self, other):\n  \"\"\n  if not isinstance(other, timedelta):\n   return NotImplemented\n  delta = timedelta(self.toordinal(),\n  hours=self._hour,\n  minutes=self._minute,\n  seconds=self._second,\n  microseconds=self._microsecond)\n  delta += other\n  hour, rem = divmod(delta.seconds, 3600)\n  minute, second = divmod(rem, 60)\n  if 0 < delta.days <= _MAXORDINAL:\n   return datetime.combine(date.fromordinal(delta.days),\n   time(hour, minute, second,\n   delta.microseconds,\n   tzinfo=self._tzinfo))\n  raise OverflowError(\"result out of range\")\n  \n __radd__ = __add__\n \n def __sub__(self, other):\n  \"\"\n  if not isinstance(other, datetime):\n   if isinstance(other, timedelta):\n    return self + -other\n   return NotImplemented\n   \n  days1 = self.toordinal()\n  days2 = other.toordinal()\n  secs1 = self._second + self._minute * 60 + self._hour * 3600\n  secs2 = other._second + other._minute * 60 + other._hour * 3600\n  base = timedelta(days1 - days2,\n  secs1 - secs2,\n  self._microsecond - other._microsecond)\n  if self._tzinfo is other._tzinfo:\n   return base\n  myoff = self.utcoffset()\n  otoff = other.utcoffset()\n  if myoff == otoff:\n   return base\n  if myoff is None or otoff is None:\n   raise TypeError(\"cannot mix naive and timezone-aware time\")\n  return base + otoff - myoff\n  \n def __hash__(self):\n  tzoff = self.utcoffset()\n  if tzoff is None:\n   return hash(self._getstate()[0])\n  days = _ymd2ord(self.year, self.month, self.day)\n  seconds = self.hour * 3600 + self.minute * 60 + self.second\n  return hash(timedelta(days, seconds, self.microsecond) - tzoff)\n  \n  \n  \n def _getstate(self):\n  yhi, ylo = divmod(self._year, 256)\n  us2, us3 = divmod(self._microsecond, 256)\n  us1, us2 = divmod(us2, 256)\n  basestate = bytes([yhi, ylo, self._month, self._day,\n  self._hour, self._minute, self._second,\n  us1, us2, us3])\n  if self._tzinfo is None:\n   return (basestate,)\n  else:\n   return (basestate, self._tzinfo)\n   \n def __setstate(self, string, tzinfo):\n  (yhi, ylo, self._month, self._day, self._hour,\n  self._minute, self._second, us1, us2, us3) = string\n  self._year = yhi * 256 + ylo\n  self._microsecond = (((us1 << 8) | us2) << 8) | us3\n  if tzinfo is None or isinstance(tzinfo, _tzinfo_class):\n   self._tzinfo = tzinfo\n  else:\n   raise TypeError(\"bad tzinfo state arg %r\" % tzinfo)\n   \n def __reduce__(self):\n  return (self.__class__, self._getstate())\n  \n  \ndatetime.min = datetime(1, 1, 1)\ndatetime.max = datetime(9999, 12, 31, 23, 59, 59, 999999)\ndatetime.resolution = timedelta(microseconds=1)\n\n\ndef _isoweek1monday(year):\n\n\n THURSDAY = 3\n firstday = _ymd2ord(year, 1, 1)\n firstweekday = (firstday + 6) % 7 \n week1monday = firstday - firstweekday\n if firstweekday > THURSDAY:\n  week1monday += 7\n return week1monday\n \nclass timezone(tzinfo):\n __slots__ = '_offset', '_name'\n \n \n _Omitted = object()\n def __new__(cls, offset, name=_Omitted):\n  if not isinstance(offset, timedelta):\n   raise TypeError(\"offset must be a timedelta\")\n  if name is cls._Omitted:\n   if not offset:\n    return cls.utc\n   name = None\n  elif not isinstance(name, str):\n   raise TypeError(\"name must be a string\")\n  if not cls._minoffset <= offset <= cls._maxoffset:\n   raise ValueError(\"offset must be a timedelta\"\n   \" strictly between -timedelta(hours=24) and\"\n   \" timedelta(hours=24).\")\n  if (offset.microseconds != 0 or\n  offset.seconds % 60 != 0):\n   raise ValueError(\"offset must be a timedelta\"\n   \" representing a whole number of minutes\")\n  return cls._create(offset, name)\n  \n @classmethod\n def _create(cls, offset, name=None):\n  self = tzinfo.__new__(cls)\n  self._offset = offset\n  self._name = name\n  return self\n  \n def __getinitargs__(self):\n  \"\"\n  if self._name is None:\n   return (self._offset,)\n  return (self._offset, self._name)\n  \n def __eq__(self, other):\n  if type(other) != timezone:\n   return False\n  return self._offset == other._offset\n  \n def __hash__(self):\n  return hash(self._offset)\n  \n def __repr__(self):\n  \"\"\n  if self is self.utc:\n   return 'datetime.timezone.utc'\n  if self._name is None:\n   return \"%s(%r)\" % ('datetime.' + self.__class__.__name__,\n   self._offset)\n  return \"%s(%r, %r)\" % ('datetime.' + self.__class__.__name__,\n  self._offset, self._name)\n  \n def __str__(self):\n  return self.tzname(None)\n  \n def utcoffset(self, dt):\n  if isinstance(dt, datetime) or dt is None:\n   return self._offset\n  raise TypeError(\"utcoffset() argument must be a datetime instance\"\n  \" or None\")\n  \n def tzname(self, dt):\n  if isinstance(dt, datetime) or dt is None:\n   if self._name is None:\n    return self._name_from_offset(self._offset)\n   return self._name\n  raise TypeError(\"tzname() argument must be a datetime instance\"\n  \" or None\")\n  \n def dst(self, dt):\n  if isinstance(dt, datetime) or dt is None:\n   return None\n  raise TypeError(\"dst() argument must be a datetime instance\"\n  \" or None\")\n  \n def fromutc(self, dt):\n  if isinstance(dt, datetime):\n   if dt.tzinfo is not self:\n    raise ValueError(\"fromutc: dt.tzinfo \"\n    \"is not self\")\n   return dt + self._offset\n  raise TypeError(\"fromutc() argument must be a datetime instance\"\n  \" or None\")\n  \n _maxoffset = timedelta(hours=23, minutes=59)\n _minoffset = -_maxoffset\n \n @staticmethod\n def _name_from_offset(delta):\n  if delta < timedelta(0):\n   sign = '-'\n   delta = -delta\n  else:\n   sign = '+'\n  hours, rest = divmod(delta, timedelta(hours=1))\n  minutes = rest // timedelta(minutes=1)\n  return 'UTC{}{:02d}:{:02d}'.format(sign, hours, minutes)\n  \ntimezone.utc = timezone._create(timedelta(0))\ntimezone.min = timezone._create(timezone._minoffset)\ntimezone.max = timezone._create(timezone._maxoffset)\n_EPOCH = datetime(1970, 1, 1, tzinfo=timezone.utc)\n\"\"\ntry:\n from _datetime import *\nexcept ImportError:\n pass\nelse:\n\n del (_DAYNAMES, _DAYS_BEFORE_MONTH, _DAYS_IN_MONTH,\n _DI100Y, _DI400Y, _DI4Y, _MAXORDINAL, _MONTHNAMES,\n _build_struct_time, _call_tzinfo_method, _check_date_fields,\n _check_time_fields, _check_tzinfo_arg, _check_tzname,\n _check_utc_offset, _cmp, _cmperror, _date_class, _days_before_month,\n _days_before_year, _days_in_month, _format_time, _is_leap,\n _isoweek1monday, _math, _ord2ymd, _time, _time_class, _tzinfo_class,\n _wrap_strftime, _ymd2ord)\n \n \n \n \n from _datetime import __doc__\n"], "sysconfig": [".py", "\"\"\n\n\n\n\nvariables={'TANH_PRESERVES_ZERO_SIGN': 0, 'WITH_DOC_STRINGS': 0}\n\ndef get_config_var(var):\n if var in variables:\n  return variables[var]\n  \n raise NotImplementedError(\"sysconfig.py:get_config_var: variable '%s' does not exist\" % variable)\n"], "gc": [".py", "\"\"\n\n\nDEBUG_COLLECTABLE = 2\n\nDEBUG_LEAK = 38\n\nDEBUG_SAVEALL = 32\n\nDEBUG_STATS = 1\n\nDEBUG_UNCOLLECTABLE = 4\n\nclass __loader__:\n pass\n \ncallbacks = []\n\ndef collect(*args,**kw):\n \"\"\n pass\n \ndef disable(*args,**kw):\n \"\"\n pass\n \ndef enable(*args,**kw):\n \"\"\n pass\n \ngarbage = []\n\ndef get_count(*args,**kw):\n \"\"\n pass\n \ndef get_debug(*args,**kw):\n \"\"\n pass\n \ndef get_objects(*args,**kw):\n \"\"\n pass\n \ndef get_referents(*args,**kw):\n \"\"\n pass\n \ndef get_referrers(*args,**kw):\n \"\"\n pass\n \ndef get_threshold(*args,**kw):\n \"\"\n pass\n \ndef is_tracked(*args,**kw):\n \"\"\n pass\n \ndef isenabled(*args,**kw):\n \"\"\n pass\n \ndef set_debug(*args,**kw):\n \"\"\n pass\n \ndef set_threshold(*args,**kw):\n \"\"\n pass\n"], "_svg": [".js", "// creation of an HTML element\nvar $module = (function($B){\n\nvar _b_ = $B.builtins\nvar $TagSumDict = $B.$TagSum.$dict\n\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\nvar $svgNS = \"http://www.w3.org/2000/svg\"\nvar $xlinkNS = \"http://www.w3.org/1999/xlink\"\n\nfunction makeTagDict(tagName){\n    // return the dictionary for the class associated with tagName\n    var dict = {__class__:$B.$type,\n        __name__:tagName\n        }\n\n    dict.__init__ = function(){\n        var $ns=$B.$MakeArgs('pow',arguments,['self'],[],'args','kw')\n        var self = $ns['self']\n        var args = $ns['args']\n        if(args.length==1){\n            var first=args[0]\n            if(isinstance(first,[str,int,float])){\n                self.elt.appendChild(document.createTextNode(str(first)))\n            } else if(first.__class__===$TagSumDict){\n                for(var i=0;i<first.children.length;i++){\n                    self.elt.appendChild(first.children[i].elt)\n                }\n            } else { // argument is another DOMNode instance\n                try{self.elt.appendChild(first.elt)}\n                catch(err){throw ValueError('wrong element '+first)}\n            }\n        }\n\n        // attributes\n        try {\n            itr = $B.$dict_iterator($ns['kw'])\n            while (true) {\n                itm = itr.next()\n                var arg = itm[0]\n                var value = itm[1]\n                if(arg.toLowerCase().substr(0,2)===\"on\"){ \n                    // Event binding passed as argument \"onclick\", \"onfocus\"...\n                    // Better use method bind of DOMNode objects\n                    var js = '$B.DOMNode.bind(self,\"'\n                    js += arg.toLowerCase().substr(2)\n                    eval(js+'\",function(){'+value+'})')\n                }else if(arg.toLowerCase()==\"style\"){\n                    $B.DOMNode.set_style(self,value)\n                }else if(arg.toLowerCase().indexOf(\"href\") !== -1){ // xlink:href\n                    self.elt.setAttributeNS( \"http://www.w3.org/1999/xlink\",\"href\",value)\n                } else {\n                    if(value!==false){\n                        // option.selected=false sets it to true :-)\n                        try{\n                            arg = arg.toLowerCase()\n                            self.elt.setAttributeNS(null,arg,value)\n                            if(arg==\"class\"){ // for IE\n                                self.elt.setAttribute(\"className\",value)\n                            }\n                        }catch(err){\n                            throw ValueError(\"can't set attribute \"+arg)\n                        }\n                    }\n                }\n            }\n        } catch (err) {\n            if (err.__name__ !== \"StopIteration\") { throw err } else { $B.$pop_exc() }\n        }\n    }\n\n    dict.__mro__ = [dict,$B.DOMNode,$B.builtins.object.$dict]\n\n    dict.__new__ = function(cls){\n        var res = $B.$DOMNode(document.createElementNS($svgNS,tagName))\n        res.__class__ = cls.$dict\n        return res\n    }\n\n    return dict\n}\n\n\n// the classes used for tag sums, $TagSum and $TagSumClass \n// are defined in py_dom.js\n\nfunction makeFactory(tagName){\n    var factory = function(){\n        var res = $B.$DOMNode(document.createElementNS($svgNS,tagName))\n        res.__class__ = dicts[tagName]\n        // apply __init__\n        var args = [res]\n        for(var i=0;i<arguments.length;i++){args.push(arguments[i])}\n        dicts[tagName].__init__.apply(null,args)\n        return res\n    }\n    factory.__class__=$B.$factory\n    factory.$dict = dicts[tagName]\n    return factory\n}\n\n// SVG\nvar $svg_tags = ['a',\n'altGlyph',\n'altGlyphDef',\n'altGlyphItem',\n'animate',\n'animateColor',\n'animateMotion',\n'animateTransform',\n'circle',\n'clipPath',\n'color_profile', // instead of color-profile\n'cursor',\n'defs',\n'desc',\n'ellipse',\n'feBlend',\n'foreignObject', //patch to enable foreign objects\n'g',\n'image',\n'line',\n'linearGradient',\n'marker',\n'mask',\n'path',\n'pattern',\n'polygon',\n'polyline',\n'radialGradient',\n'rect',\n'set',\n'stop',\n'svg',\n'text',\n'tref',\n'tspan',\n'use']\n\n// create classes\nvar obj = new Object()\nvar dicts = {}\nfor(var i=0;i<$svg_tags.length;i++){\n    var tag = $svg_tags[i]\n    dicts[tag]=makeTagDict(tag)\n    obj[tag] = makeFactory(tag)\n    dicts[tag].$factory = obj[tag]\n}\nreturn obj\n})(__BRYTHON__)\n"], "external_import": [".py", "import os\nfrom browser import doc\nimport urllib.request\n\n\n\n\n\nclass ModuleFinder:\n def __init__(self, path_entry):\n  print(\"external_import here..\")\n  \n  self._module=None\n  if path_entry.startswith('http://'):\n   self.path_entry=path_entry\n  else:\n   raise ImportError()\n   \n def __str__(self):\n  return '<%s for \"%s\">' % (self.__class__.__name__, self.path_entry)\n  \n def find_module(self, fullname, path=None):\n  path = path or self.path_entry\n  \n  for _ext in ['js', 'pyj', 'py']:\n   _fp,_url,_headers=urllib.request.urlopen(path + '/' + '%s.%s' % (fullname, _ext))\n   self._module=_fp.read()\n   _fp.close()\n   if self._module is not None:\n    print(\"module found at %s:%s\" % (path, fullname))\n    return ModuleLoader(path, fullname, self._module)\n    \n  print('module %s not found' % fullname)\n  raise ImportError()\n  return None\n  \nclass ModuleLoader:\n \"\"\n \n def __init__(self, filepath, name, module_source):\n  self._filepath=filepath\n  self._name=name\n  self._module_source=module_source\n  \n def get_source(self):\n  return self._module_source\n  \n def is_package(self):\n  return '.' in self._name\n  \n def load_module(self):\n  if self._name in sys.modules:\n  \n   mod = sys.modules[self._name]\n   return mod\n   \n  _src=self.get_source()\n  if self._filepath.endswith('.js'):\n   mod=JSObject(import_js_module(_src, self._filepath, self._name))\n  elif self._filepath.endswith('.py'):\n   mod=JSObject(import_py_module(_src, self._filepath, self._name))\n  elif self._filepath.endswith('.pyj'):\n   mod=JSObject(import_pyj_module(_src, self._filepath, self._name))\n  else:\n   raise ImportError('Invalid Module: %s' % self._filepath)\n   \n   \n  mod.__file__ = self._filepath\n  mod.__name__ = self._name\n  mod.__path__ = os.path.abspath(self._filepath)\n  mod.__loader__ = self\n  mod.__package__ = '.'.join(self._name.split('.')[:-1])\n  \n  if self.is_package():\n   print('adding path for package')\n   \n   \n   mod.__path__ = [ self._filepath ]\n  else:\n   print('imported as regular module')\n   \n  print('creating a new module object for \"%s\"' % self._name)\n  sys.modules.setdefault(self._name, mod)\n  JSObject(__BRYTHON__.imported)[self._name]=mod\n  \n  return mod\n"], "_dummy_thread": [".py", "\"\"\n\n\n__all__ = ['error', 'start_new_thread', 'exit', 'get_ident', 'allocate_lock',\n'interrupt_main', 'LockType']\n\n\nTIMEOUT_MAX = 2**31\n\n\n\n\n\n\nerror = RuntimeError\n\ndef start_new_thread(function, args, kwargs={}):\n \"\"\n if type(args) != type(tuple()):\n  raise TypeError(\"2nd arg must be a tuple\")\n if type(kwargs) != type(dict()):\n  raise TypeError(\"3rd arg must be a dict\")\n global _main\n _main = False\n try:\n  function(*args, **kwargs)\n except SystemExit:\n  pass\n except:\n  import traceback\n  traceback.print_exc()\n _main = True\n global _interrupt\n if _interrupt:\n  _interrupt = False\n  raise KeyboardInterrupt\n  \ndef exit():\n \"\"\n raise SystemExit\n \ndef get_ident():\n \"\"\n return -1\n \ndef allocate_lock():\n \"\"\n return LockType()\n \ndef stack_size(size=None):\n \"\"\n if size is not None:\n  raise error(\"setting thread stack size not supported\")\n return 0\n \nclass LockType(object):\n \"\"\n \n def __init__(self):\n  self.locked_status = False\n  \n def acquire(self, waitflag=None, timeout=-1):\n  \"\"\n  if waitflag is None or waitflag:\n   self.locked_status = True\n   return True\n  else:\n   if not self.locked_status:\n    self.locked_status = True\n    return True\n   else:\n    if timeout > 0:\n     import time\n     time.sleep(timeout)\n    return False\n    \n __enter__ = acquire\n \n def __exit__(self, typ, val, tb):\n  self.release()\n  \n def release(self):\n  \"\"\n  \n  \n  if not self.locked_status:\n   raise error\n  self.locked_status = False\n  return True\n  \n def locked(self):\n  return self.locked_status\n  \n  \n_interrupt = False\n\n_main = True\n\ndef interrupt_main():\n \"\"\n if _main:\n  raise KeyboardInterrupt\n else:\n  global _interrupt\n  _interrupt = True\n"], "importlib.util": [".py", "\"\"\n\nfrom ._bootstrap import module_for_loader\nfrom ._bootstrap import set_loader\nfrom ._bootstrap import set_package\nfrom ._bootstrap import _resolve_name\n\n\ndef resolve_name(name, package):\n \"\"\n if not name.startswith('.'):\n  return name\n elif not package:\n  raise ValueError('{!r} is not a relative name '\n  '(no leading dot)'.format(name))\n level = 0\n for character in name:\n  if character != '.':\n   break\n  level += 1\n return _resolve_name(name[level:], package, level)\n"], "_markupbase": [".py", "\"\"\n\nimport re\n\n_declname_match = re.compile(r'[a-zA-Z][-_.a-zA-Z0-9]*\\s*').match\n_declstringlit_match = re.compile(r'(\\'[^\\']*\\'|\"[^\"]*\")\\s*').match\n_commentclose = re.compile(r'--\\s*>')\n_markedsectionclose = re.compile(r']\\s*]\\s*>')\n\n\n\n\n_msmarkedsectionclose = re.compile(r']\\s*>')\n\ndel re\n\n\nclass ParserBase:\n \"\"\n \n def __init__(self):\n  if self.__class__ is ParserBase:\n   raise RuntimeError(\n   \"_markupbase.ParserBase must be subclassed\")\n   \n def error(self, message):\n  raise NotImplementedError(\n  \"subclasses of ParserBase must override error()\")\n  \n def reset(self):\n  self.lineno = 1\n  self.offset = 0\n  \n def getpos(self):\n  \"\"\n  return self.lineno, self.offset\n  \n  \n  \n  \n  \n def updatepos(self, i, j):\n  if i >= j:\n   return j\n  rawdata = self.rawdata\n  nlines = rawdata.count(\"\\n\", i, j)\n  if nlines:\n   self.lineno = self.lineno + nlines\n   pos = rawdata.rindex(\"\\n\", i, j) \n   self.offset = j-(pos+1)\n  else:\n   self.offset = self.offset + j-i\n  return j\n  \n _decl_otherchars = ''\n \n \n def parse_declaration(self, i):\n \n \n \n \n \n \n \n \n \n \n  rawdata = self.rawdata\n  j = i + 2\n  assert rawdata[i:j] == \"<!\", \"unexpected call to parse_declaration\"\n  if rawdata[j:j+1] == \">\":\n  \n   return j + 1\n  if rawdata[j:j+1] in (\"-\", \"\"):\n  \n  \n   return -1\n   \n  n = len(rawdata)\n  if rawdata[j:j+2] == '--': \n  \n   return self.parse_comment(i)\n  elif rawdata[j] == '[': \n  \n  \n  \n  \n   return self.parse_marked_section(i)\n  else: \n   decltype, j = self._scan_name(j, i)\n  if j < 0:\n   return j\n  if decltype == \"doctype\":\n   self._decl_otherchars = ''\n  while j < n:\n   c = rawdata[j]\n   if c == \">\":\n   \n    data = rawdata[i+2:j]\n    if decltype == \"doctype\":\n     self.handle_decl(data)\n    else:\n    \n    \n    \n    \n     self.unknown_decl(data)\n    return j + 1\n   if c in \"\\\"'\":\n    m = _declstringlit_match(rawdata, j)\n    if not m:\n     return -1 \n    j = m.end()\n   elif c in \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n    name, j = self._scan_name(j, i)\n   elif c in self._decl_otherchars:\n    j = j + 1\n   elif c == \"[\":\n   \n    if decltype == \"doctype\":\n     j = self._parse_doctype_subset(j + 1, i)\n    elif decltype in {\"attlist\", \"linktype\", \"link\", \"element\"}:\n    \n    \n    \n    \n     self.error(\"unsupported '[' char in %s declaration\" % decltype)\n    else:\n     self.error(\"unexpected '[' char in declaration\")\n   else:\n    self.error(\n    \"unexpected %r char in declaration\" % rawdata[j])\n   if j < 0:\n    return j\n  return -1 \n  \n  \n  \n def parse_marked_section(self, i, report=1):\n  rawdata= self.rawdata\n  assert rawdata[i:i+3] == '<![', \"unexpected call to parse_marked_section()\"\n  sectName, j = self._scan_name( i+3, i )\n  if j < 0:\n   return j\n  if sectName in {\"temp\", \"cdata\", \"ignore\", \"include\", \"rcdata\"}:\n  \n   match= _markedsectionclose.search(rawdata, i+3)\n  elif sectName in {\"if\", \"else\", \"endif\"}:\n  \n   match= _msmarkedsectionclose.search(rawdata, i+3)\n  else:\n   self.error('unknown status keyword %r in marked section' % rawdata[i+3:j])\n  if not match:\n   return -1\n  if report:\n   j = match.start(0)\n   self.unknown_decl(rawdata[i+3: j])\n  return match.end(0)\n  \n  \n def parse_comment(self, i, report=1):\n  rawdata = self.rawdata\n  if rawdata[i:i+4] != '<!--':\n   self.error('unexpected call to parse_comment()')\n  match = _commentclose.search(rawdata, i+4)\n  if not match:\n   return -1\n  if report:\n   j = match.start(0)\n   self.handle_comment(rawdata[i+4: j])\n  return match.end(0)\n  \n  \n  \n def _parse_doctype_subset(self, i, declstartpos):\n  rawdata = self.rawdata\n  n = len(rawdata)\n  j = i\n  while j < n:\n   c = rawdata[j]\n   if c == \"<\":\n    s = rawdata[j:j+2]\n    if s == \"<\":\n    \n     return -1\n    if s != \"<!\":\n     self.updatepos(declstartpos, j + 1)\n     self.error(\"unexpected char in internal subset (in %r)\" % s)\n    if (j + 2) == n:\n    \n     return -1\n    if (j + 4) > n:\n    \n     return -1\n    if rawdata[j:j+4] == \"<!--\":\n     j = self.parse_comment(j, report=0)\n     if j < 0:\n      return j\n     continue\n    name, j = self._scan_name(j + 2, declstartpos)\n    if j == -1:\n     return -1\n    if name not in {\"attlist\", \"element\", \"entity\", \"notation\"}:\n     self.updatepos(declstartpos, j + 2)\n     self.error(\n     \"unknown declaration %r in internal subset\" % name)\n     \n    meth = getattr(self, \"_parse_doctype_\" + name)\n    j = meth(j, declstartpos)\n    if j < 0:\n     return j\n   elif c == \"%\":\n   \n    if (j + 1) == n:\n    \n     return -1\n    s, j = self._scan_name(j + 1, declstartpos)\n    if j < 0:\n     return j\n    if rawdata[j] == \";\":\n     j = j + 1\n   elif c == \"]\":\n    j = j + 1\n    while j < n and rawdata[j].isspace():\n     j = j + 1\n    if j < n:\n     if rawdata[j] == \">\":\n      return j\n     self.updatepos(declstartpos, j)\n     self.error(\"unexpected char after internal subset\")\n    else:\n     return -1\n   elif c.isspace():\n    j = j + 1\n   else:\n    self.updatepos(declstartpos, j)\n    self.error(\"unexpected char %r in internal subset\" % c)\n    \n  return -1\n  \n  \n def _parse_doctype_element(self, i, declstartpos):\n  name, j = self._scan_name(i, declstartpos)\n  if j == -1:\n   return -1\n   \n  rawdata = self.rawdata\n  if '>' in rawdata[j:]:\n   return rawdata.find(\">\", j) + 1\n  return -1\n  \n  \n def _parse_doctype_attlist(self, i, declstartpos):\n  rawdata = self.rawdata\n  name, j = self._scan_name(i, declstartpos)\n  c = rawdata[j:j+1]\n  if c == \"\":\n   return -1\n  if c == \">\":\n   return j + 1\n  while 1:\n  \n  \n   name, j = self._scan_name(j, declstartpos)\n   if j < 0:\n    return j\n   c = rawdata[j:j+1]\n   if c == \"\":\n    return -1\n   if c == \"(\":\n   \n    if \")\" in rawdata[j:]:\n     j = rawdata.find(\")\", j) + 1\n    else:\n     return -1\n    while rawdata[j:j+1].isspace():\n     j = j + 1\n    if not rawdata[j:]:\n    \n     return -1\n   else:\n    name, j = self._scan_name(j, declstartpos)\n   c = rawdata[j:j+1]\n   if not c:\n    return -1\n   if c in \"'\\\"\":\n    m = _declstringlit_match(rawdata, j)\n    if m:\n     j = m.end()\n    else:\n     return -1\n    c = rawdata[j:j+1]\n    if not c:\n     return -1\n   if c == \"#\":\n    if rawdata[j:] == \"#\":\n    \n     return -1\n    name, j = self._scan_name(j + 1, declstartpos)\n    if j < 0:\n     return j\n    c = rawdata[j:j+1]\n    if not c:\n     return -1\n   if c == '>':\n   \n    return j + 1\n    \n    \n def _parse_doctype_notation(self, i, declstartpos):\n  name, j = self._scan_name(i, declstartpos)\n  if j < 0:\n   return j\n  rawdata = self.rawdata\n  while 1:\n   c = rawdata[j:j+1]\n   if not c:\n   \n    return -1\n   if c == '>':\n    return j + 1\n   if c in \"'\\\"\":\n    m = _declstringlit_match(rawdata, j)\n    if not m:\n     return -1\n    j = m.end()\n   else:\n    name, j = self._scan_name(j, declstartpos)\n    if j < 0:\n     return j\n     \n     \n def _parse_doctype_entity(self, i, declstartpos):\n  rawdata = self.rawdata\n  if rawdata[i:i+1] == \"%\":\n   j = i + 1\n   while 1:\n    c = rawdata[j:j+1]\n    if not c:\n     return -1\n    if c.isspace():\n     j = j + 1\n    else:\n     break\n  else:\n   j = i\n  name, j = self._scan_name(j, declstartpos)\n  if j < 0:\n   return j\n  while 1:\n   c = self.rawdata[j:j+1]\n   if not c:\n    return -1\n   if c in \"'\\\"\":\n    m = _declstringlit_match(rawdata, j)\n    if m:\n     j = m.end()\n    else:\n     return -1 \n   elif c == \">\":\n    return j + 1\n   else:\n    name, j = self._scan_name(j, declstartpos)\n    if j < 0:\n     return j\n     \n     \n     \n def _scan_name(self, i, declstartpos):\n  rawdata = self.rawdata\n  n = len(rawdata)\n  if i == n:\n   return None, -1\n  m = _declname_match(rawdata, i)\n  if m:\n   s = m.group()\n   name = s.strip()\n   if (i + len(s)) == n:\n    return None, -1 \n   return name.lower(), m.end()\n  else:\n   self.updatepos(declstartpos, i)\n   self.error(\"expected name token at %r\"\n   % rawdata[declstartpos:declstartpos+20])\n   \n   \n def unknown_decl(self, data):\n  pass\n"], "builtins": [".js", "var $module = (function(){\n    var obj = {__class__:__BRYTHON__.$ModuleDict,__name__:'builtins'}\n    var builtin_names = ['ArithmeticError', 'AssertionError', 'AttributeError', \n    'BaseException', 'BlockingIOError', 'BrokenPipeError', 'BufferError', \n    'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', \n    'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', \n    'DeprecationWarning', 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', \n    'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', \n    'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', \n    'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError',\n    'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError', \n    'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', \n    'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', \n    'ProcessLookupError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', \n    'RuntimeWarning', 'StopIteration', 'SyntaxError', 'SyntaxWarning', \n    'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', \n    'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', \n    'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', \n    'ValueError', 'Warning', 'WindowsError', 'ZeroDivisionError', '_', \n    '__build_class__', '__debug__', '__doc__', '__import__', '__name__', \n    '__package__', 'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'bytearray', \n    'bytes','callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', \n    'credits','delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', \n    'exit', 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', \n    'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', \n    'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', \n    'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', \n    'property', 'quit', 'range', 'repr', 'reversed', 'round', 'set', 'setattr', \n    'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', \n    'vars', 'zip']\n    for(var i=0;i<builtin_names.length;i++){\n        try{eval(\"obj['\"+builtin_names[i]+\"']=__BRYTHON__.builtins.\"+builtin_names[i])}\n        catch(err){if (__BRYTHON__.$debug) {console.log(err)}}\n    }\n    return obj\n})()\n"], "struct": [".py", "__all__ = [\n\n'calcsize', 'pack', 'pack_into', 'unpack', 'unpack_from',\n\n\n'Struct',\n\n\n'error'\n]\n\nfrom _struct import *\nfrom _struct import _clearcache\nfrom _struct import __doc__\n"], "re": [".py", "\n\n\n\n\n\n\n\"\"\nimport sys\nimport _jsre\n_pymdl = [None]\n\nif not _jsre._is_valid():\n from pyre import *\n \n \n__all__ = [ \"match\", \"search\", \"sub\", \"subn\", \"split\", \"findall\",\n\"compile\", \"purge\", \"template\", \"escape\", \"A\", \"I\", \"L\", \"M\", \"S\", \"X\",\n\"U\", \"ASCII\", \"IGNORECASE\", \"LOCALE\", \"MULTILINE\", \"DOTALL\", \"VERBOSE\",\n\"UNICODE\", \n\n\n]\n\n__version__ = \"2.2.1\"\n\n\nA = ASCII = _jsre.A \nI = IGNORECASE = _jsre.I \nL = LOCALE = _jsre.L \nU = UNICODE = _jsre.U \nM = MULTILINE = _jsre.M \nS = DOTALL = _jsre.S \nX = VERBOSE = _jsre.X \n\n\n\n\n\n\n\n\ndef _pyre():\n mdl = _pymdl[0]\n if mdl is None:\n  import pyre\n  _pymdl[0] = pyre\n  return pyre\n  \n return mdl\n \n \n \n \ndef match(pattern, string, flags=0):\n \"\"\n \n if not isinstance(pattern, str):\n  return pattern.match(string, flags)\n  \n if _jsre._is_valid(pattern):\n  return _jsre.match(pattern, string, flags)\n  \n return _pyre().match(pattern, string, flags)\n \ndef search(pattern, string, flags=0):\n \"\"\n \n if not isinstance(pattern, str):\n  return pattern.search(string, flags)\n  \n if _jsre._is_valid(pattern):\n  return _jsre.search(pattern, string, flags)\n  \n return _pyre().search(pattern, string, flags)\n \n \ndef sub(pattern, repl, string, count=0, flags=0):\n \"\"\n \n if not isinstance(pattern, str):\n  return pattern.sub(repl, string, count, flags)\n  \n if _jsre._is_valid(pattern):\n  return _jsre.sub(pattern, repl, string, count, flags)\n  \n return _pyre().sub(pattern, repl, string, count, flags)\n \ndef subn(pattern, repl, string, count=0, flags=0):\n \"\"\n \n if not isinstance(pattern, str):\n  return pattern.subn(repl, string, count, flags)\n  \n if _jsre._is_valid(pattern):\n  return _jsre.subn(pattern, repl, string, count, flags)\n  \n return _pyre().subn(pattern, repl, string, count, flags)\n \ndef split(pattern, string, maxsplit=0, flags=0):\n \"\"\n \n if not isinstance(pattern, str):\n  return pattern.split(string, maxsplit, flags)\n  \n if _jsre._is_valid(pattern):\n  return _jsre.split(pattern, string, maxsplit, flags)\n  \n return _pyre().split(pattern, string, maxsplit, flags)\n \ndef findall(pattern, string, flags=0):\n \"\"\n \n if not isinstance(pattern, str):\n  return pattern.findall(pattern, string, flags)\n  \n if _jsre._is_valid(pattern):\n  return _jsre.findall(pattern, string, flags)\n else:\n  return _pyre().findall(pattern, string, flags)\n  \ndef finditer(pattern, string, flags=0):\n \"\"\n \n return _pyre().finditer(pattern, string, flags)\n \ndef compile(pattern, flags=0):\n \"\"\n \n if _jsre._is_valid(pattern):\n  return _jsre.compile(pattern, flags)\n  \n return _pyre().compile(pattern, flags)\n \ndef purge():\n \"\"\n if _pymdl[0] is not None:\n  return _pymdl[0].purge()\n  \ndef template(pattern, flags=0):\n \"\"\n return _pyre().template(pattern, flags)\n \ndef escape(pattern):\n \"\"\n \n return _pyre().escape(pattern)\n"], "tempfile": [".py", "\"\"\n\n__all__ = [\n\"NamedTemporaryFile\", \"TemporaryFile\", \n\"SpooledTemporaryFile\", \"TemporaryDirectory\",\n\"mkstemp\", \"mkdtemp\", \n\"mktemp\", \n\"TMP_MAX\", \"gettempprefix\", \n\"tempdir\", \"gettempdir\"\n]\n\n\n\n\nimport warnings as _warnings\nimport sys as _sys\nimport io as _io\nimport os as _os\nimport errno as _errno\nfrom random import Random as _Random\n\ntry:\n import fcntl as _fcntl\nexcept ImportError:\n def _set_cloexec(fd):\n  pass\nelse:\n def _set_cloexec(fd):\n  try:\n   flags = _fcntl.fcntl(fd, _fcntl.F_GETFD, 0)\n  except OSError:\n   pass\n  else:\n  \n   flags |= _fcntl.FD_CLOEXEC\n   _fcntl.fcntl(fd, _fcntl.F_SETFD, flags)\n   \n   \ntry:\n import _thread\nexcept ImportError:\n import _dummy_thread as _thread\n_allocate_lock = _thread.allocate_lock\n\n_text_openflags = _os.O_RDWR | _os.O_CREAT | _os.O_EXCL\nif hasattr(_os, 'O_NOINHERIT'):\n _text_openflags |= _os.O_NOINHERIT\nif hasattr(_os, 'O_NOFOLLOW'):\n _text_openflags |= _os.O_NOFOLLOW\n \n_bin_openflags = _text_openflags\nif hasattr(_os, 'O_BINARY'):\n _bin_openflags |= _os.O_BINARY\n \nif hasattr(_os, 'TMP_MAX'):\n TMP_MAX = _os.TMP_MAX\nelse:\n TMP_MAX = 10000\n \n \n \ntemplate = \"tmp\"\n\n\n\n_once_lock = _allocate_lock()\n\nif hasattr(_os, \"lstat\"):\n _stat = _os.lstat\nelif hasattr(_os, \"stat\"):\n _stat = _os.stat\nelse:\n\n\n def _stat(fn):\n  f = open(fn)\n  f.close()\n  \ndef _exists(fn):\n try:\n  _stat(fn)\n except OSError:\n  return False\n else:\n  return True\n  \nclass _RandomNameSequence:\n \"\"\n \n characters = \"abcdefghijklmnopqrstuvwxyz0123456789_\"\n \n @property\n def rng(self):\n  cur_pid = _os.getpid()\n  if cur_pid != getattr(self, '_rng_pid', None):\n   self._rng = _Random()\n   self._rng_pid = cur_pid\n  return self._rng\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  c = self.characters\n  choose = self.rng.choice\n  letters = [choose(c) for dummy in \"123456\"]\n  return ''.join(letters)\n  \ndef _candidate_tempdir_list():\n \"\"\n \n dirlist = []\n \n \n for envname in 'TMPDIR', 'TEMP', 'TMP':\n  dirname = _os.getenv(envname)\n  if dirname: dirlist.append(dirname)\n  \n  \n if _os.name == 'nt':\n  dirlist.extend([ r'c:\\temp', r'c:\\tmp', r'\\temp', r'\\tmp' ])\n else:\n  dirlist.extend([ '/tmp', '/var/tmp', '/usr/tmp' ])\n  \n  \n try:\n  dirlist.append(_os.getcwd())\n except (AttributeError, OSError):\n  dirlist.append(_os.curdir)\n  \n return dirlist\n \ndef _get_default_tempdir():\n \"\"\n \n namer = _RandomNameSequence()\n dirlist = _candidate_tempdir_list()\n \n for dir in dirlist:\n  if dir != _os.curdir:\n   dir = _os.path.normcase(_os.path.abspath(dir))\n   \n  for seq in range(100):\n   name = next(namer)\n   filename = _os.path.join(dir, name)\n   try:\n    fd = _os.open(filename, _bin_openflags, 0o600)\n    try:\n     try:\n      with _io.open(fd, 'wb', closefd=False) as fp:\n       fp.write(b'blat')\n     finally:\n      _os.close(fd)\n    finally:\n     _os.unlink(filename)\n    return dir\n   except FileExistsError:\n    pass\n   except OSError:\n    break \n raise FileNotFoundError(_errno.ENOENT,\n \"No usable temporary directory found in %s\" %\n dirlist)\n \n_name_sequence = None\n\ndef _get_candidate_names():\n \"\"\n \n global _name_sequence\n if _name_sequence is None:\n  _once_lock.acquire()\n  try:\n   if _name_sequence is None:\n    _name_sequence = _RandomNameSequence()\n  finally:\n   _once_lock.release()\n return _name_sequence\n \n \ndef _mkstemp_inner(dir, pre, suf, flags):\n \"\"\n \n names = _get_candidate_names()\n \n for seq in range(TMP_MAX):\n  name = next(names)\n  file = _os.path.join(dir, pre + name + suf)\n  try:\n   fd = _os.open(file, flags, 0o600)\n   _set_cloexec(fd)\n   return (fd, _os.path.abspath(file))\n  except FileExistsError:\n   continue \n  except PermissionError:\n  \n  \n   if _os.name == 'nt':\n    continue\n   else:\n    raise\n    \n raise FileExistsError(_errno.EEXIST,\n \"No usable temporary file name found\")\n \n \n \n \ndef gettempprefix():\n \"\"\n return template\n \ntempdir = None\n\ndef gettempdir():\n \"\"\n global tempdir\n if tempdir is None:\n  _once_lock.acquire()\n  try:\n   if tempdir is None:\n    tempdir = _get_default_tempdir()\n  finally:\n   _once_lock.release()\n return tempdir\n \ndef mkstemp(suffix=\"\", prefix=template, dir=None, text=False):\n \"\"\n \n if dir is None:\n  dir = gettempdir()\n  \n if text:\n  flags = _text_openflags\n else:\n  flags = _bin_openflags\n  \n return _mkstemp_inner(dir, prefix, suffix, flags)\n \n \ndef mkdtemp(suffix=\"\", prefix=template, dir=None):\n \"\"\n \n if dir is None:\n  dir = gettempdir()\n  \n names = _get_candidate_names()\n \n for seq in range(TMP_MAX):\n  name = next(names)\n  file = _os.path.join(dir, prefix + name + suffix)\n  try:\n   _os.mkdir(file, 0o700)\n   return file\n  except FileExistsError:\n   continue \n   \n raise FileExistsError(_errno.EEXIST,\n \"No usable temporary directory name found\")\n \ndef mktemp(suffix=\"\", prefix=template, dir=None):\n \"\"\n \n \n \n \n \n if dir is None:\n  dir = gettempdir()\n  \n names = _get_candidate_names()\n for seq in range(TMP_MAX):\n  name = next(names)\n  file = _os.path.join(dir, prefix + name + suffix)\n  if not _exists(file):\n   return file\n   \n raise FileExistsError(_errno.EEXIST,\n \"No usable temporary filename found\")\n \n \nclass _TemporaryFileWrapper:\n \"\"\n \n def __init__(self, file, name, delete=True):\n  self.file = file\n  self.name = name\n  self.close_called = False\n  self.delete = delete\n  \n def __getattr__(self, name):\n \n \n \n  file = self.__dict__['file']\n  a = getattr(file, name)\n  if not isinstance(a, int):\n   setattr(self, name, a)\n  return a\n  \n  \n  \n def __enter__(self):\n  self.file.__enter__()\n  return self\n  \n  \n def __iter__(self):\n  return iter(self.file)\n  \n  \n  \n  \n if _os.name != 'nt':\n \n \n \n \n \n  unlink = _os.unlink\n  \n  def close(self):\n   if not self.close_called:\n    self.close_called = True\n    self.file.close()\n    if self.delete:\n     self.unlink(self.name)\n     \n  def __del__(self):\n   self.close()\n   \n   \n   \n  def __exit__(self, exc, value, tb):\n   result = self.file.__exit__(exc, value, tb)\n   self.close()\n   return result\n else:\n  def __exit__(self, exc, value, tb):\n   self.file.__exit__(exc, value, tb)\n   \n   \ndef NamedTemporaryFile(mode='w+b', buffering=-1, encoding=None,\nnewline=None, suffix=\"\", prefix=template,\ndir=None, delete=True):\n \"\"\n \n if dir is None:\n  dir = gettempdir()\n  \n flags = _bin_openflags\n \n \n \n if _os.name == 'nt' and delete:\n  flags |= _os.O_TEMPORARY\n  \n (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags)\n file = _io.open(fd, mode, buffering=buffering,\n newline=newline, encoding=encoding)\n \n return _TemporaryFileWrapper(file, name, delete)\n \nif _os.name != 'posix' or _os.sys.platform == 'cygwin':\n\n\n TemporaryFile = NamedTemporaryFile\n \nelse:\n def TemporaryFile(mode='w+b', buffering=-1, encoding=None,\n newline=None, suffix=\"\", prefix=template,\n dir=None):\n  \"\"\n  \n  if dir is None:\n   dir = gettempdir()\n   \n  flags = _bin_openflags\n  \n  (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags)\n  try:\n   _os.unlink(name)\n   return _io.open(fd, mode, buffering=buffering,\n   newline=newline, encoding=encoding)\n  except:\n   _os.close(fd)\n   raise\n   \nclass SpooledTemporaryFile:\n \"\"\n _rolled = False\n \n def __init__(self, max_size=0, mode='w+b', buffering=-1,\n encoding=None, newline=None,\n suffix=\"\", prefix=template, dir=None):\n  if 'b' in mode:\n   self._file = _io.BytesIO()\n  else:\n  \n  \n  \n   self._file = _io.StringIO(newline=\"\\n\")\n  self._max_size = max_size\n  self._rolled = False\n  self._TemporaryFileArgs = {'mode': mode, 'buffering': buffering,\n  'suffix': suffix, 'prefix': prefix,\n  'encoding': encoding, 'newline': newline,\n  'dir': dir}\n  \n def _check(self, file):\n  if self._rolled: return\n  max_size = self._max_size\n  if max_size and file.tell() > max_size:\n   self.rollover()\n   \n def rollover(self):\n  if self._rolled: return\n  file = self._file\n  newfile = self._file = TemporaryFile(**self._TemporaryFileArgs)\n  del self._TemporaryFileArgs\n  \n  newfile.write(file.getvalue())\n  newfile.seek(file.tell(), 0)\n  \n  self._rolled = True\n  \n  \n  \n  \n  \n  \n  \n def __enter__(self):\n  if self._file.closed:\n   raise ValueError(\"Cannot enter context with closed file\")\n  return self\n  \n def __exit__(self, exc, value, tb):\n  self._file.close()\n  \n  \n def __iter__(self):\n  return self._file.__iter__()\n  \n def close(self):\n  self._file.close()\n  \n @property\n def closed(self):\n  return self._file.closed\n  \n @property\n def encoding(self):\n  try:\n   return self._file.encoding\n  except AttributeError:\n   if 'b' in self._TemporaryFileArgs['mode']:\n    raise\n   return self._TemporaryFileArgs['encoding']\n   \n def fileno(self):\n  self.rollover()\n  return self._file.fileno()\n  \n def flush(self):\n  self._file.flush()\n  \n def isatty(self):\n  return self._file.isatty()\n  \n @property\n def mode(self):\n  try:\n   return self._file.mode\n  except AttributeError:\n   return self._TemporaryFileArgs['mode']\n   \n @property\n def name(self):\n  try:\n   return self._file.name\n  except AttributeError:\n   return None\n   \n @property\n def newlines(self):\n  try:\n   return self._file.newlines\n  except AttributeError:\n   if 'b' in self._TemporaryFileArgs['mode']:\n    raise\n   return self._TemporaryFileArgs['newline']\n   \n def read(self, *args):\n  return self._file.read(*args)\n  \n def readline(self, *args):\n  return self._file.readline(*args)\n  \n def readlines(self, *args):\n  return self._file.readlines(*args)\n  \n def seek(self, *args):\n  self._file.seek(*args)\n  \n @property\n def softspace(self):\n  return self._file.softspace\n  \n def tell(self):\n  return self._file.tell()\n  \n def truncate(self, size=None):\n  if size is None:\n   self._file.truncate()\n  else:\n   if size > self._max_size:\n    self.rollover()\n   self._file.truncate(size)\n   \n def write(self, s):\n  file = self._file\n  rv = file.write(s)\n  self._check(file)\n  return rv\n  \n def writelines(self, iterable):\n  file = self._file\n  rv = file.writelines(iterable)\n  self._check(file)\n  return rv\n  \n  \nclass TemporaryDirectory(object):\n \"\"\n \n def __init__(self, suffix=\"\", prefix=template, dir=None):\n  self._closed = False\n  self.name = None \n  self.name = mkdtemp(suffix, prefix, dir)\n  \n def __repr__(self):\n  return \"<{} {!r}>\".format(self.__class__.__name__, self.name)\n  \n def __enter__(self):\n  return self.name\n  \n def cleanup(self, _warn=False):\n  if self.name and not self._closed:\n   try:\n    self._rmtree(self.name)\n   except (TypeError, AttributeError) as ex:\n   \n   \n   \n    if \"None\" not in str(ex):\n     raise\n    print(\"ERROR: {!r} while cleaning up {!r}\".format(ex, self,),\n    file=_sys.stderr)\n    return\n   self._closed = True\n   if _warn:\n    self._warn(\"Implicitly cleaning up {!r}\".format(self),\n    ResourceWarning)\n    \n def __exit__(self, exc, value, tb):\n  self.cleanup()\n  \n def __del__(self):\n \n  self.cleanup(_warn=True)\n  \n  \n  \n  \n  \n _listdir = staticmethod(_os.listdir)\n _path_join = staticmethod(_os.path.join)\n _isdir = staticmethod(_os.path.isdir)\n _islink = staticmethod(_os.path.islink)\n _remove = staticmethod(_os.remove)\n _rmdir = staticmethod(_os.rmdir)\n _os_error = OSError\n _warn = _warnings.warn\n \n def _rmtree(self, path):\n \n \n  for name in self._listdir(path):\n   fullname = self._path_join(path, name)\n   try:\n    isdir = self._isdir(fullname) and not self._islink(fullname)\n   except self._os_error:\n    isdir = False\n   if isdir:\n    self._rmtree(fullname)\n   else:\n    try:\n     self._remove(fullname)\n    except self._os_error:\n     pass\n  try:\n   self._rmdir(path)\n  except self._os_error:\n   pass\n"], "base64": [".py", "\n\n\"\"\n\n\n\n\n\nimport re\nimport struct\nimport binascii\n\n\n__all__ = [\n\n'encode', 'decode', 'encodebytes', 'decodebytes',\n\n'b64encode', 'b64decode', 'b32encode', 'b32decode',\n'b16encode', 'b16decode',\n\n'standard_b64encode', 'standard_b64decode',\n\n\n\n\n'urlsafe_b64encode', 'urlsafe_b64decode',\n]\n\n\nbytes_types = (bytes, bytearray) \n\ndef _bytes_from_decode_data(s):\n if isinstance(s, str):\n  try:\n   return s.encode('ascii')\n  except UnicodeEncodeError:\n   raise ValueError('string argument should contain only ASCII characters')\n elif isinstance(s, bytes_types):\n  return s\n else:\n  raise TypeError(\"argument should be bytes or ASCII string, not %s\" % s.__class__.__name__)\n  \n  \n  \n  \n  \ndef b64encode(s, altchars=None):\n \"\"\n if not isinstance(s, bytes_types):\n  raise TypeError(\"expected bytes, not %s\" % s.__class__.__name__)\n  \n encoded = binascii.b2a_base64(s)[:-1]\n if altchars is not None:\n  if not isinstance(altchars, bytes_types):\n   raise TypeError(\"expected bytes, not %s\"\n   % altchars.__class__.__name__)\n  assert len(altchars) == 2, repr(altchars)\n  return encoded.translate(bytes.maketrans(b'+/', altchars))\n return encoded\n \n \ndef b64decode(s, altchars=None, validate=False):\n \"\"\n s = _bytes_from_decode_data(s)\n if altchars is not None:\n  altchars = _bytes_from_decode_data(altchars)\n  assert len(altchars) == 2, repr(altchars)\n  s = s.translate(bytes.maketrans(altchars, b'+/'))\n if validate and not re.match(b'^[A-Za-z0-9+/]*={0,2}$', s):\n  raise binascii.Error('Non-base64 digit found')\n return binascii.a2b_base64(s)\n \n \ndef standard_b64encode(s):\n \"\"\n return b64encode(s)\n \ndef standard_b64decode(s):\n \"\"\n return b64decode(s)\n \n \n_urlsafe_encode_translation = bytes.maketrans(b'+/', b'-_')\n_urlsafe_decode_translation = bytes.maketrans(b'-_', b'+/')\n\ndef urlsafe_b64encode(s):\n \"\"\n return b64encode(s).translate(_urlsafe_encode_translation)\n \ndef urlsafe_b64decode(s):\n \"\"\n s = _bytes_from_decode_data(s)\n s = s.translate(_urlsafe_decode_translation)\n return b64decode(s)\n \n \n \n \n_b32alphabet = {\n0: b'A', 9: b'J', 18: b'S', 27: b'3',\n1: b'B', 10: b'K', 19: b'T', 28: b'4',\n2: b'C', 11: b'L', 20: b'U', 29: b'5',\n3: b'D', 12: b'M', 21: b'V', 30: b'6',\n4: b'E', 13: b'N', 22: b'W', 31: b'7',\n5: b'F', 14: b'O', 23: b'X',\n6: b'G', 15: b'P', 24: b'Y',\n7: b'H', 16: b'Q', 25: b'Z',\n8: b'I', 17: b'R', 26: b'2',\n}\n\n_b32tab = [v[0] for k, v in sorted(_b32alphabet.items())]\n_b32rev = dict([(v[0], k) for k, v in _b32alphabet.items()])\n\n\ndef b32encode(s):\n \"\"\n if not isinstance(s, bytes_types):\n  raise TypeError(\"expected bytes, not %s\" % s.__class__.__name__)\n quanta, leftover = divmod(len(s), 5)\n \n if leftover:\n  s = s + bytes(5 - leftover) \n  quanta += 1\n encoded = bytearray()\n for i in range(quanta):\n \n \n \n \n \n  c1, c2, c3 = struct.unpack('!HHB', s[i*5:(i+1)*5])\n  c2 += (c1 & 1) << 16 \n  c3 += (c2 & 3) << 8 \n  encoded += bytes([_b32tab[c1 >> 11], \n  _b32tab[(c1 >> 6) & 0x1f], \n  _b32tab[(c1 >> 1) & 0x1f], \n  _b32tab[c2 >> 12], \n  _b32tab[(c2 >> 7) & 0x1f], \n  _b32tab[(c2 >> 2) & 0x1f], \n  _b32tab[c3 >> 5], \n  _b32tab[c3 & 0x1f], \n  ])\n  \n if leftover == 1:\n  encoded[-6:] = b'======'\n elif leftover == 2:\n  encoded[-4:] = b'===='\n elif leftover == 3:\n  encoded[-3:] = b'==='\n elif leftover == 4:\n  encoded[-1:] = b'='\n return bytes(encoded)\n \n \ndef b32decode(s, casefold=False, map01=None):\n \"\"\n s = _bytes_from_decode_data(s)\n quanta, leftover = divmod(len(s), 8)\n if leftover:\n  raise binascii.Error('Incorrect padding')\n  \n  \n  \n if map01 is not None:\n  map01 = _bytes_from_decode_data(map01)\n  assert len(map01) == 1, repr(map01)\n  s = s.translate(bytes.maketrans(b'01', b'O' + map01))\n if casefold:\n  s = s.upper()\n  \n  \n  \n padchars = 0\n mo = re.search(b'(?P<pad>[=]*)$', s)\n if mo:\n  padchars = len(mo.group('pad'))\n  if padchars > 0:\n   s = s[:-padchars]\n   \n parts = []\n acc = 0\n shift = 35\n for c in s:\n  val = _b32rev.get(c)\n  if val is None:\n   raise binascii.Error('Non-base32 digit found')\n  acc += _b32rev[c] << shift\n  shift -= 5\n  if shift < 0:\n   parts.append(binascii.unhexlify(bytes('%010x' % acc, \"ascii\")))\n   acc = 0\n   shift = 35\n   \n last = binascii.unhexlify(bytes('%010x' % acc, \"ascii\"))\n if padchars == 0:\n  last = b'' \n elif padchars == 1:\n  last = last[:-1]\n elif padchars == 3:\n  last = last[:-2]\n elif padchars == 4:\n  last = last[:-3]\n elif padchars == 6:\n  last = last[:-4]\n else:\n  raise binascii.Error('Incorrect padding')\n parts.append(last)\n return b''.join(parts)\n \n \n \n \n \n \ndef b16encode(s):\n \"\"\n if not isinstance(s, bytes_types):\n  raise TypeError(\"expected bytes, not %s\" % s.__class__.__name__)\n return binascii.hexlify(s).upper()\n \n \ndef b16decode(s, casefold=False):\n \"\"\n s = _bytes_from_decode_data(s)\n if casefold:\n  s = s.upper()\n if re.search(b'[^0-9A-F]', s):\n  raise binascii.Error('Non-base16 digit found')\n return binascii.unhexlify(s)\n \n \n \n \n \n \n \nMAXLINESIZE = 76 \nMAXBINSIZE = (MAXLINESIZE//4)*3\n\ndef encode(input, output):\n \"\"\n while True:\n  s = input.read(MAXBINSIZE)\n  if not s:\n   break\n  while len(s) < MAXBINSIZE:\n   ns = input.read(MAXBINSIZE-len(s))\n   if not ns:\n    break\n   s += ns\n  line = binascii.b2a_base64(s)\n  output.write(line)\n  \n  \ndef decode(input, output):\n \"\"\n while True:\n  line = input.readline()\n  if not line:\n   break\n  s = binascii.a2b_base64(line)\n  output.write(s)\n  \n  \ndef encodebytes(s):\n \"\"\n if not isinstance(s, bytes_types):\n  raise TypeError(\"expected bytes, not %s\" % s.__class__.__name__)\n pieces = []\n for i in range(0, len(s), MAXBINSIZE):\n  chunk = s[i : i + MAXBINSIZE]\n  pieces.append(binascii.b2a_base64(chunk))\n return b\"\".join(pieces)\n \ndef encodestring(s):\n \"\"\n import warnings\n warnings.warn(\"encodestring() is a deprecated alias, use encodebytes()\",\n DeprecationWarning, 2)\n return encodebytes(s)\n \n \ndef decodebytes(s):\n \"\"\n if not isinstance(s, bytes_types):\n  raise TypeError(\"expected bytes, not %s\" % s.__class__.__name__)\n return binascii.a2b_base64(s)\n \ndef decodestring(s):\n \"\"\n import warnings\n warnings.warn(\"decodestring() is a deprecated alias, use decodebytes()\",\n DeprecationWarning, 2)\n return decodebytes(s)\n \n \n \ndef main():\n \"\"\n import sys, getopt\n try:\n  opts, args = getopt.getopt(sys.argv[1:], 'deut')\n except getopt.error as msg:\n  sys.stdout = sys.stderr\n  print(msg)\n  print(\"\"\"usage: %s [-d|-e|-u|-t] [file|-]\n        -d, -u: decode\n        -e: encode (default)\n        -t: encode and decode string 'Aladdin:open sesame'\"\"\"  %sys.argv[0])\n  sys.exit(2)\n func = encode\n for o, a in opts:\n  if o == '-e': func = encode\n  if o == '-d': func = decode\n  if o == '-u': func = decode\n  if o == '-t': test(); return\n if args and args[0] != '-':\n  with open(args[0], 'rb') as f:\n   func(f, sys.stdout.buffer)\n else:\n  func(sys.stdin.buffer, sys.stdout.buffer)\n  \n  \ndef test():\n s0 = b\"Aladdin:open sesame\"\n print(repr(s0))\n s1 = encodebytes(s0)\n print(repr(s1))\n s2 = decodebytes(s1)\n print(repr(s2))\n assert s0 == s2\n \n \nif __name__ == '__main__':\n main()\n"], "platform": [".py", "\n\n\"\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n__copyright__ = \"\"\"\n    Copyright (c) 1999-2000, Marc-Andre Lemburg; mailto:mal@lemburg.com\n    Copyright (c) 2000-2010, eGenix.com Software GmbH; mailto:info@egenix.com\n\n    Permission to use, copy, modify, and distribute this software and its\n    documentation for any purpose and without fee or royalty is hereby granted,\n    provided that the above copyright notice appear in all copies and that\n    both that copyright notice and this permission notice appear in\n    supporting documentation or portions thereof, including modifications,\n    that you make.\n\n    EGENIX.COM SOFTWARE GMBH DISCLAIMS ALL WARRANTIES WITH REGARD TO\n    THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n    FITNESS, IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL,\n    INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING\n    FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,\n    NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION\n    WITH THE USE OR PERFORMANCE OF THIS SOFTWARE !\n\n\"\"\"\n\n__version__ = '1.0.7'\n\nimport collections\nimport sys, os, re, subprocess\n\n\n\n\ntry:\n DEV_NULL = os.devnull\nexcept AttributeError:\n\n\n if sys.platform in ('dos','win32','win16','os2'):\n \n  DEV_NULL = 'NUL'\n else:\n \n  DEV_NULL = '/dev/null'\n  \n  \n  \n_libc_search = re.compile(b'(__libc_init)'\nb'|'\nb'(GLIBC_([0-9.]+))'\nb'|'\nbr'(libc(_\\w+)?\\.so(?:\\.(\\d[0-9.]*))?)', re.ASCII)\n\ndef libc_ver(executable=sys.executable,lib='',version='',\n\nchunksize=16384):\n\n \"\"\n if hasattr(os.path, 'realpath'):\n \n \n \n  executable = os.path.realpath(executable)\n f = open(executable,'rb')\n binary = f.read(chunksize)\n pos = 0\n while 1:\n  if b'libc' in binary or b'GLIBC' in binary:\n   m = _libc_search.search(binary,pos)\n  else:\n   m = None\n  if not m:\n   binary = f.read(chunksize)\n   if not binary:\n    break\n   pos = 0\n   continue\n  libcinit,glibc,glibcversion,so,threads,soversion = [\n  s.decode('latin1') if s is not None else s\n  for s in m.groups()]\n  if libcinit and not lib:\n   lib = 'libc'\n  elif glibc:\n   if lib != 'glibc':\n    lib = 'glibc'\n    version = glibcversion\n   elif glibcversion > version:\n    version = glibcversion\n  elif so:\n   if lib != 'glibc':\n    lib = 'libc'\n    if soversion and soversion > version:\n     version = soversion\n    if threads and version[-len(threads):] != threads:\n     version = version + threads\n  pos = m.end()\n f.close()\n return lib,version\n \ndef _dist_try_harder(distname,version,id):\n\n \"\"\n if os.path.exists('/var/adm/inst-log/info'):\n \n  distname = 'SuSE'\n  for line in open('/var/adm/inst-log/info'):\n   tv = line.split()\n   if len(tv) == 2:\n    tag,value = tv\n   else:\n    continue\n   if tag == 'MIN_DIST_VERSION':\n    version = value.strip()\n   elif tag == 'DIST_IDENT':\n    values = value.split('-')\n    id = values[2]\n  return distname,version,id\n  \n if os.path.exists('/etc/.installed'):\n \n  for line in open('/etc/.installed'):\n   pkg = line.split('-')\n   if len(pkg) >= 2 and pkg[0] == 'OpenLinux':\n   \n   \n    return 'OpenLinux',pkg[1],id\n    \n if os.path.isdir('/usr/lib/setup'):\n \n  verfiles = os.listdir('/usr/lib/setup')\n  for n in range(len(verfiles)-1, -1, -1):\n   if verfiles[n][:14] != 'slack-version-':\n    del verfiles[n]\n  if verfiles:\n   verfiles.sort()\n   distname = 'slackware'\n   version = verfiles[-1][14:]\n   return distname,version,id\n   \n return distname,version,id\n \n_release_filename = re.compile(r'(\\w+)[-_](release|version)', re.ASCII)\n_lsb_release_version = re.compile(r'(.+)'\n' release '\n'([\\d.]+)'\n'[^(]*(?:\\((.+)\\))?', re.ASCII)\n_release_version = re.compile(r'([^0-9]+)'\n'(?: release )?'\n'([\\d.]+)'\n'[^(]*(?:\\((.+)\\))?', re.ASCII)\n\n\n\n\n\n\n_supported_dists = (\n'SuSE', 'debian', 'fedora', 'redhat', 'centos',\n'mandrake', 'mandriva', 'rocks', 'slackware', 'yellowdog', 'gentoo',\n'UnitedLinux', 'turbolinux', 'arch', 'mageia')\n\ndef _parse_release_file(firstline):\n\n\n\n\n version = ''\n id = ''\n \n \n m = _lsb_release_version.match(firstline)\n if m is not None:\n \n  return tuple(m.groups())\n  \n  \n m = _release_version.match(firstline)\n if m is not None:\n  return tuple(m.groups())\n  \n  \n l = firstline.strip().split()\n if l:\n  version = l[0]\n  if len(l) > 1:\n   id = l[1]\n return '', version, id\n \ndef linux_distribution(distname='', version='', id='',\n\nsupported_dists=_supported_dists,\nfull_distribution_name=1):\n\n \"\"\n try:\n  etc = os.listdir('/etc')\n except os.error:\n \n  return distname,version,id\n etc.sort()\n for file in etc:\n  m = _release_filename.match(file)\n  if m is not None:\n   _distname,dummy = m.groups()\n   if _distname in supported_dists:\n    distname = _distname\n    break\n else:\n  return _dist_try_harder(distname,version,id)\n  \n  \n with open('/etc/'+file, 'r') as f:\n  firstline = f.readline()\n _distname, _version, _id = _parse_release_file(firstline)\n \n if _distname and full_distribution_name:\n  distname = _distname\n if _version:\n  version = _version\n if _id:\n  id = _id\n return distname, version, id\n \n \n \ndef dist(distname='',version='',id='',\n\nsupported_dists=_supported_dists):\n\n \"\"\n return linux_distribution(distname, version, id,\n supported_dists=supported_dists,\n full_distribution_name=0)\n \ndef popen(cmd, mode='r', bufsize=-1):\n\n \"\"\n import warnings\n warnings.warn('use os.popen instead', DeprecationWarning, stacklevel=2)\n return os.popen(cmd, mode, bufsize)\n \ndef _norm_version(version, build=''):\n\n \"\"\n l = version.split('.')\n if build:\n  l.append(build)\n try:\n  ints = map(int,l)\n except ValueError:\n  strings = l\n else:\n  strings = list(map(str,ints))\n version = '.'.join(strings[:3])\n return version\n \n_ver_output = re.compile(r'(?:([\\w ]+) ([\\w.]+) '\n'.*'\n'\\[.* ([\\d.]+)\\])')\n\n\n\n\n\n\n\n\n\n\ndef _syscmd_ver(system='', release='', version='',\n\nsupported_platforms=('win32','win16','dos','os2')):\n\n \"\"\n if sys.platform not in supported_platforms:\n  return system,release,version\n  \n  \n for cmd in ('ver','command /c ver','cmd /c ver'):\n  try:\n   pipe = popen(cmd)\n   info = pipe.read()\n   if pipe.close():\n    raise os.error('command failed')\n    \n    \n  except os.error as why:\n  \n   continue\n  except IOError as why:\n  \n   continue\n  else:\n   break\n else:\n  return system,release,version\n  \n  \n info = info.strip()\n m = _ver_output.match(info)\n if m is not None:\n  system,release,version = m.groups()\n  \n  if release[-1] == '.':\n   release = release[:-1]\n  if version[-1] == '.':\n   version = version[:-1]\n   \n   \n  version = _norm_version(version)\n return system,release,version\n \ndef _win32_getvalue(key,name,default=''):\n\n \"\"\n try:\n \n  from win32api import RegQueryValueEx\n except ImportError:\n \n  import winreg\n  RegQueryValueEx = winreg.QueryValueEx\n try:\n  return RegQueryValueEx(key,name)\n except:\n  return default\n  \ndef win32_ver(release='',version='',csd='',ptype=''):\n\n \"\"\n \n \n \n \n \n \n \n \n \n try:\n  import win32api\n  from win32api import RegQueryValueEx, RegOpenKeyEx, RegCloseKey, GetVersionEx\n  from win32con import HKEY_LOCAL_MACHINE, VER_PLATFORM_WIN32_NT, VER_PLATFORM_WIN32_WINDOWS, VER_NT_WORKSTATION\n except ImportError:\n \n  try:\n   sys.getwindowsversion\n  except AttributeError:\n  \n   return release,version,csd,ptype\n  else:\n  \n  \n   import winreg\n   GetVersionEx = sys.getwindowsversion\n   RegQueryValueEx = winreg.QueryValueEx\n   RegOpenKeyEx = winreg.OpenKeyEx\n   RegCloseKey = winreg.CloseKey\n   HKEY_LOCAL_MACHINE = winreg.HKEY_LOCAL_MACHINE\n   VER_PLATFORM_WIN32_WINDOWS = 1\n   VER_PLATFORM_WIN32_NT = 2\n   VER_NT_WORKSTATION = 1\n   VER_NT_SERVER = 3\n   REG_SZ = 1\n   \n   \n winver = GetVersionEx()\n maj,min,buildno,plat,csd = winver\n version = '%i.%i.%i' % (maj,min,buildno & 0xFFFF)\n if hasattr(winver, \"service_pack\"):\n  if winver.service_pack != \"\":\n   csd = 'SP%s' % winver.service_pack_major\n else:\n  if csd[:13] == 'Service Pack ':\n   csd = 'SP' + csd[13:]\n   \n if plat == VER_PLATFORM_WIN32_WINDOWS:\n  regkey = 'SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion'\n  \n  if maj == 4:\n   if min == 0:\n    release = '95'\n   elif min == 10:\n    release = '98'\n   elif min == 90:\n    release = 'Me'\n   else:\n    release = 'postMe'\n  elif maj == 5:\n   release = '2000'\n   \n elif plat == VER_PLATFORM_WIN32_NT:\n  regkey = 'SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion'\n  if maj <= 4:\n   release = 'NT'\n  elif maj == 5:\n   if min == 0:\n    release = '2000'\n   elif min == 1:\n    release = 'XP'\n   elif min == 2:\n    release = '2003Server'\n   else:\n    release = 'post2003'\n  elif maj == 6:\n   if hasattr(winver, \"product_type\"):\n    product_type = winver.product_type\n   else:\n    product_type = VER_NT_WORKSTATION\n    \n    \n    \n    try:\n     key = RegOpenKeyEx(HKEY_LOCAL_MACHINE, regkey)\n     name, type = RegQueryValueEx(key, \"ProductName\")\n     \n     if type == REG_SZ and name.find(\"Server\") != -1:\n      product_type = VER_NT_SERVER\n    except WindowsError:\n    \n     pass\n     \n   if min == 0:\n    if product_type == VER_NT_WORKSTATION:\n     release = 'Vista'\n    else:\n     release = '2008Server'\n   elif min == 1:\n    if product_type == VER_NT_WORKSTATION:\n     release = '7'\n    else:\n     release = '2008ServerR2'\n   elif min == 2:\n    if product_type == VER_NT_WORKSTATION:\n     release = '8'\n    else:\n     release = '2012Server'\n   else:\n    release = 'post2012Server'\n    \n else:\n  if not release:\n  \n   release = '%i.%i' % (maj,min)\n  return release,version,csd,ptype\n  \n  \n try:\n  keyCurVer = RegOpenKeyEx(HKEY_LOCAL_MACHINE, regkey)\n  \n  RegQueryValueEx(keyCurVer, 'SystemRoot')\n except:\n  return release,version,csd,ptype\n  \n  \n  \n  \n  \n  \n  \n build = _win32_getvalue(keyCurVer,\n 'CurrentBuildNumber',\n ('',1))[0]\n ptype = _win32_getvalue(keyCurVer,\n 'CurrentType',\n (ptype,1))[0]\n \n \n version = _norm_version(version,build)\n \n \n RegCloseKey(keyCurVer)\n return release,version,csd,ptype\n \ndef _mac_ver_lookup(selectors,default=None):\n\n from _gestalt import gestalt\n l = []\n append = l.append\n for selector in selectors:\n  try:\n   append(gestalt(selector))\n  except (RuntimeError, OSError):\n   append(default)\n return l\n \ndef _bcd2str(bcd):\n\n return hex(bcd)[2:]\n \ndef _mac_ver_gestalt():\n \"\"\n \n try:\n  import _gestalt\n except ImportError:\n  return None\n  \n sysv, sysa = _mac_ver_lookup(('sysv','sysa'))\n \n if sysv:\n  major = (sysv & 0xFF00) >> 8\n  minor = (sysv & 0x00F0) >> 4\n  patch = (sysv & 0x000F)\n  \n  if (major, minor) >= (10, 4):\n  \n  \n  \n  \n  \n   major,minor,patch = _mac_ver_lookup(('sys1','sys2','sys3'))\n   release = '%i.%i.%i' %(major, minor, patch)\n  else:\n   release = '%s.%i.%i' % (_bcd2str(major),minor,patch)\n   \n if sysa:\n  machine = {0x1: '68k',\n  0x2: 'PowerPC',\n  0xa: 'i386'}.get(sysa,'')\n  \n versioninfo=('', '', '')\n return release,versioninfo,machine\n \ndef _mac_ver_xml():\n fn = '/System/Library/CoreServices/SystemVersion.plist'\n if not os.path.exists(fn):\n  return None\n  \n try:\n  import plistlib\n except ImportError:\n  return None\n  \n pl = plistlib.readPlist(fn)\n release = pl['ProductVersion']\n versioninfo=('', '', '')\n machine = os.uname().machine\n if machine in ('ppc', 'Power Macintosh'):\n \n  machine = 'PowerPC'\n  \n return release,versioninfo,machine\n \n \ndef mac_ver(release='',versioninfo=('','',''),machine=''):\n\n \"\"\n \n \n \n info = _mac_ver_xml()\n if info is not None:\n  return info\n  \n  \n  \n info = _mac_ver_gestalt()\n if info is not None:\n  return info\n  \n  \n return release,versioninfo,machine\n \ndef _java_getprop(name,default):\n\n from java.lang import System\n try:\n  value = System.getProperty(name)\n  if value is None:\n   return default\n  return value\n except AttributeError:\n  return default\n  \ndef java_ver(release='',vendor='',vminfo=('','',''),osinfo=('','','')):\n\n \"\"\n \n try:\n  import java.lang\n except ImportError:\n  return release,vendor,vminfo,osinfo\n  \n vendor = _java_getprop('java.vendor', vendor)\n release = _java_getprop('java.version', release)\n vm_name, vm_release, vm_vendor = vminfo\n vm_name = _java_getprop('java.vm.name', vm_name)\n vm_vendor = _java_getprop('java.vm.vendor', vm_vendor)\n vm_release = _java_getprop('java.vm.version', vm_release)\n vminfo = vm_name, vm_release, vm_vendor\n os_name, os_version, os_arch = osinfo\n os_arch = _java_getprop('java.os.arch', os_arch)\n os_name = _java_getprop('java.os.name', os_name)\n os_version = _java_getprop('java.os.version', os_version)\n osinfo = os_name, os_version, os_arch\n \n return release, vendor, vminfo, osinfo\n \n \n \ndef system_alias(system,release,version):\n\n \"\"\n if system == 'Rhapsody':\n \n \n  return 'MacOS X Server',system+release,version\n  \n elif system == 'SunOS':\n \n  if release < '5':\n  \n   return system,release,version\n   \n  l = release.split('.')\n  if l:\n   try:\n    major = int(l[0])\n   except ValueError:\n    pass\n   else:\n    major = major - 3\n    l[0] = str(major)\n    release = '.'.join(l)\n  if release < '6':\n   system = 'Solaris'\n  else:\n  \n   system = 'Solaris'\n   \n elif system == 'IRIX64':\n \n \n \n  system = 'IRIX'\n  if version:\n   version = version + ' (64bit)'\n  else:\n   version = '64bit'\n   \n elif system in ('win32','win16'):\n \n  system = 'Windows'\n  \n return system,release,version\n \n \n \ndef _platform(*args):\n\n \"\"\n \n platform = '-'.join(x.strip() for x in filter(len, args))\n \n \n platform = platform.replace(' ','_')\n platform = platform.replace('/','-')\n platform = platform.replace('\\\\','-')\n platform = platform.replace(':','-')\n platform = platform.replace(';','-')\n platform = platform.replace('\"','-')\n platform = platform.replace('(','-')\n platform = platform.replace(')','-')\n \n \n platform = platform.replace('unknown','')\n \n \n while 1:\n  cleaned = platform.replace('--','-')\n  if cleaned == platform:\n   break\n  platform = cleaned\n while platform[-1] == '-':\n  platform = platform[:-1]\n  \n return platform\n \ndef _node(default=''):\n\n \"\"\n try:\n  import socket\n except ImportError:\n \n  return default\n try:\n  return socket.gethostname()\n except socket.error:\n \n  return default\n  \ndef _follow_symlinks(filepath):\n\n \"\"\n filepath = os.path.abspath(filepath)\n while os.path.islink(filepath):\n  filepath = os.path.normpath(\n  os.path.join(os.path.dirname(filepath),os.readlink(filepath)))\n return filepath\n \ndef _syscmd_uname(option,default=''):\n\n \"\"\n if sys.platform in ('dos','win32','win16','os2'):\n \n  return default\n try:\n  f = os.popen('uname %s 2> %s' % (option, DEV_NULL))\n except (AttributeError,os.error):\n  return default\n output = f.read().strip()\n rc = f.close()\n if not output or rc:\n  return default\n else:\n  return output\n  \ndef _syscmd_file(target,default=''):\n\n \"\"\n if sys.platform in ('dos','win32','win16','os2'):\n \n  return default\n target = _follow_symlinks(target)\n try:\n  proc = subprocess.Popen(['file', target],\n  stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n  \n except (AttributeError,os.error):\n  return default\n output = proc.communicate()[0].decode('latin-1')\n rc = proc.wait()\n if not output or rc:\n  return default\n else:\n  return output\n  \n  \n  \n  \n  \n_default_architecture = {\n'win32': ('','WindowsPE'),\n'win16': ('','Windows'),\n'dos': ('','MSDOS'),\n}\n\ndef architecture(executable=sys.executable,bits='',linkage=''):\n\n \"\"\n \n \n if not bits:\n  import struct\n  try:\n   size = struct.calcsize('P')\n  except struct.error:\n  \n   size = struct.calcsize('l')\n  bits = str(size*8) + 'bit'\n  \n  \n if executable:\n  fileout = _syscmd_file(executable, '')\n else:\n  fileout = ''\n  \n if not fileout and executable == sys.executable:\n \n \n  if sys.platform in _default_architecture:\n   b,l = _default_architecture[sys.platform]\n   if b:\n    bits = b\n   if l:\n    linkage = l\n  return bits,linkage\n  \n if 'executable' not in fileout:\n \n  return bits,linkage\n  \n  \n if '32-bit' in fileout:\n  bits = '32bit'\n elif 'N32' in fileout:\n \n  bits = 'n32bit'\n elif '64-bit' in fileout:\n  bits = '64bit'\n  \n  \n if 'ELF' in fileout:\n  linkage = 'ELF'\n elif 'PE' in fileout:\n \n  if 'Windows' in fileout:\n   linkage = 'WindowsPE'\n  else:\n   linkage = 'PE'\n elif 'COFF' in fileout:\n  linkage = 'COFF'\n elif 'MS-DOS' in fileout:\n  linkage = 'MSDOS'\n else:\n \n  pass\n  \n return bits,linkage\n \n \n \nuname_result = collections.namedtuple(\"uname_result\",\n\"system node release version machine processor\")\n\n_uname_cache = None\n\ndef uname():\n\n \"\"\n global _uname_cache\n no_os_uname = 0\n \n if _uname_cache is not None:\n  return _uname_cache\n  \n processor = ''\n \n \n try:\n  system,node,release,version,machine = os.uname()\n except AttributeError:\n  no_os_uname = 1\n  \n if no_os_uname or not list(filter(None, (system, node, release, version, machine))):\n \n \n  if no_os_uname:\n   system = sys.platform\n   release = ''\n   version = ''\n   node = _node()\n   machine = ''\n   \n  use_syscmd_ver = 1\n  \n  \n  if system == 'win32':\n   release,version,csd,ptype = win32_ver()\n   if release and version:\n    use_syscmd_ver = 0\n    \n    \n    \n    \n   if not machine:\n   \n    if \"PROCESSOR_ARCHITEW6432\" in os.environ:\n     machine = os.environ.get(\"PROCESSOR_ARCHITEW6432\", '')\n    else:\n     machine = os.environ.get('PROCESSOR_ARCHITECTURE', '')\n   if not processor:\n    processor = os.environ.get('PROCESSOR_IDENTIFIER', machine)\n    \n    \n    \n  if use_syscmd_ver:\n   system,release,version = _syscmd_ver(system)\n   \n   \n   if system == 'Microsoft Windows':\n    system = 'Windows'\n   elif system == 'Microsoft' and release == 'Windows':\n   \n   \n   \n   \n    system = 'Windows'\n    if '6.0' == version[:3]:\n     release = 'Vista'\n    else:\n     release = ''\n     \n     \n     \n  if system in ('win32','win16'):\n   if not version:\n    if system == 'win32':\n     version = '32bit'\n    else:\n     version = '16bit'\n   system = 'Windows'\n   \n  elif system[:4] == 'java':\n   release,vendor,vminfo,osinfo = java_ver()\n   system = 'Java'\n   version = ', '.join(vminfo)\n   if not version:\n    version = vendor\n    \n    \n if system == 'OpenVMS':\n \n  if not release or release == '0':\n   release = version\n   version = ''\n   \n  try:\n   import vms_lib\n  except ImportError:\n   pass\n  else:\n   csid, cpu_number = vms_lib.getsyi('SYI$_CPU',0)\n   if (cpu_number >= 128):\n    processor = 'Alpha'\n   else:\n    processor = 'VAX'\n if not processor:\n \n  processor = _syscmd_uname('-p','')\n  \n  \n if system == 'unknown':\n  system = ''\n if node == 'unknown':\n  node = ''\n if release == 'unknown':\n  release = ''\n if version == 'unknown':\n  version = ''\n if machine == 'unknown':\n  machine = ''\n if processor == 'unknown':\n  processor = ''\n  \n  \n if system == 'Microsoft' and release == 'Windows':\n  system = 'Windows'\n  release = 'Vista'\n  \n _uname_cache = uname_result(system,node,release,version,machine,processor)\n return _uname_cache\n \n \n \ndef system():\n\n \"\"\n return uname().system\n \ndef node():\n\n \"\"\n return uname().node\n \ndef release():\n\n \"\"\n return uname().release\n \ndef version():\n\n \"\"\n return uname().version\n \ndef machine():\n\n \"\"\n return uname().machine\n \ndef processor():\n\n \"\"\n return uname().processor\n \n \n \n_sys_version_parser = re.compile(\nr'([\\w.+]+)\\s*'\n'\\(#?([^,]+),\\s*([\\w ]+),\\s*([\\w :]+)\\)\\s*'\n'\\[([^\\]]+)\\]?', re.ASCII)\n\n_ironpython_sys_version_parser = re.compile(\nr'IronPython\\s*'\n'([\\d\\.]+)'\n'(?: \\(([\\d\\.]+)\\))?'\n' on (.NET [\\d\\.]+)', re.ASCII)\n\n\n_ironpython26_sys_version_parser = re.compile(\nr'([\\d.]+)\\s*'\n'\\(IronPython\\s*'\n'[\\d.]+\\s*'\n'\\(([\\d.]+)\\) on ([\\w.]+ [\\d.]+(?: \\(\\d+-bit\\))?)\\)'\n)\n\n_pypy_sys_version_parser = re.compile(\nr'([\\w.+]+)\\s*'\n'\\(#?([^,]+),\\s*([\\w ]+),\\s*([\\w :]+)\\)\\s*'\n'\\[PyPy [^\\]]+\\]?')\n\n_sys_version_cache = {}\n\ndef _sys_version(sys_version=None):\n\n \"\"\n \n if sys_version is None:\n  sys_version = sys.version\n  \n  \n result = _sys_version_cache.get(sys_version, None)\n if result is not None:\n  return result\n  \n  \n if 'IronPython' in sys_version:\n \n  name = 'IronPython'\n  if sys_version.startswith('IronPython'):\n   match = _ironpython_sys_version_parser.match(sys_version)\n  else:\n   match = _ironpython26_sys_version_parser.match(sys_version)\n   \n  if match is None:\n   raise ValueError(\n   'failed to parse IronPython sys.version: %s' %\n   repr(sys_version))\n   \n  version, alt_version, compiler = match.groups()\n  buildno = ''\n  builddate = ''\n  \n elif sys.platform.startswith('java'):\n \n  name = 'Jython'\n  match = _sys_version_parser.match(sys_version)\n  if match is None:\n   raise ValueError(\n   'failed to parse Jython sys.version: %s' %\n   repr(sys_version))\n  version, buildno, builddate, buildtime, _ = match.groups()\n  compiler = sys.platform\n  \n elif \"PyPy\" in sys_version:\n \n  name = \"PyPy\"\n  match = _pypy_sys_version_parser.match(sys_version)\n  if match is None:\n   raise ValueError(\"failed to parse PyPy sys.version: %s\" %\n   repr(sys_version))\n  version, buildno, builddate, buildtime = match.groups()\n  compiler = \"\"\n  \n else:\n \n  match = _sys_version_parser.match(sys_version)\n  if match is None:\n   raise ValueError(\n   'failed to parse CPython sys.version: %s' %\n   repr(sys_version))\n  version, buildno, builddate, buildtime, compiler = match.groups()\n  name = 'CPython'\n  builddate = builddate + ' ' + buildtime\n  \n if hasattr(sys, '_mercurial'):\n  _, branch, revision = sys._mercurial\n elif hasattr(sys, 'subversion'):\n \n  _, branch, revision = sys.subversion\n else:\n  branch = ''\n  revision = ''\n  \n  \n l = version.split('.')\n if len(l) == 2:\n  l.append('0')\n  version = '.'.join(l)\n  \n  \n result = (name, version, branch, revision, buildno, builddate, compiler)\n _sys_version_cache[sys_version] = result\n return result\n \ndef python_implementation():\n\n \"\"\n return _sys_version()[0]\n \ndef python_version():\n\n \"\"\n return _sys_version()[1]\n \ndef python_version_tuple():\n\n \"\"\n return tuple(_sys_version()[1].split('.'))\n \ndef python_branch():\n\n \"\"\n \n return _sys_version()[2]\n \ndef python_revision():\n\n \"\"\n return _sys_version()[3]\n \ndef python_build():\n\n \"\"\n return _sys_version()[4:6]\n \ndef python_compiler():\n\n \"\"\n return _sys_version()[6]\n \n \n \n_platform_cache = {}\n\ndef platform(aliased=0, terse=0):\n\n \"\"\n result = _platform_cache.get((aliased, terse), None)\n if result is not None:\n  return result\n  \n  \n  \n system,node,release,version,machine,processor = uname()\n if machine == processor:\n  processor = ''\n if aliased:\n  system,release,version = system_alias(system,release,version)\n  \n if system == 'Windows':\n \n  rel,vers,csd,ptype = win32_ver(version)\n  if terse:\n   platform = _platform(system,release)\n  else:\n   platform = _platform(system,release,version,csd)\n   \n elif system in ('Linux',):\n \n  distname,distversion,distid = dist('')\n  if distname and not terse:\n   platform = _platform(system,release,machine,processor,\n   'with',\n   distname,distversion,distid)\n  else:\n  \n   libcname,libcversion = libc_ver(sys.executable)\n   platform = _platform(system,release,machine,processor,\n   'with',\n   libcname+libcversion)\n elif system == 'Java':\n \n  r,v,vminfo,(os_name,os_version,os_arch) = java_ver()\n  if terse or not os_name:\n   platform = _platform(system,release,version)\n  else:\n   platform = _platform(system,release,version,\n   'on',\n   os_name,os_version,os_arch)\n   \n elif system == 'MacOS':\n \n  if terse:\n   platform = _platform(system,release)\n  else:\n   platform = _platform(system,release,machine)\n   \n else:\n \n  if terse:\n   platform = _platform(system,release)\n  else:\n   bits,linkage = architecture(sys.executable)\n   platform = _platform(system,release,machine,processor,bits,linkage)\n   \n _platform_cache[(aliased, terse)] = platform\n return platform\n \n \n \nif __name__ == '__main__':\n\n terse = ('terse' in sys.argv or '--terse' in sys.argv)\n aliased = (not 'nonaliased' in sys.argv and not '--nonaliased' in sys.argv)\n print(platform(aliased,terse))\n sys.exit(0)\n"], "html": [".py", "\"\"\n\n\n_escape_map = {ord('&'): '&amp;', ord('<'): '&lt;', ord('>'): '&gt;'}\n_escape_map_full = {ord('&'): '&amp;', ord('<'): '&lt;', ord('>'): '&gt;',\nord('\"'): '&quot;', ord('\\''): '&#x27;'}\n\n\n\ndef escape(s, quote=True):\n \"\"\n if quote:\n  return s.translate(_escape_map_full)\n return s.translate(_escape_map)\n", 1], "collections": [".py", "\n\nfrom _collections import deque, defaultdict\n\n\n\n__all__ = ['deque', 'defaultdict', 'namedtuple', 'UserDict', 'UserList',\n'UserString', 'Counter', 'OrderedDict']\n\n\n\n\n\n\nfrom _abcoll import MutableMapping\n\n\n\nfrom collections.abc import *\nimport collections.abc\n__all__ += collections.abc.__all__\n\nfrom _collections import deque, defaultdict, namedtuple\nfrom operator import itemgetter as _itemgetter\nfrom keyword import iskeyword as _iskeyword\nimport sys as _sys\nimport heapq as _heapq\n\n\nfrom itertools import repeat as _repeat, chain as _chain, starmap as _starmap\nfrom reprlib import recursive_repr as _recursive_repr\n\nclass Set(set):\n pass\n \nclass Sequence(list):\n pass\n \ndef _proxy(obj):\n return obj\n \n \n \n \n \nclass _Link(object):\n __slots__ = 'prev', 'next', 'key', '__weakref__'\n \nclass OrderedDict(dict):\n \"\"\n \n \n \n \n \n \n \n \n \n \n \n \n \n def __init__(self, *args, **kwds):\n  \"\"\n  if len(args) > 1:\n   raise TypeError('expected at most 1 arguments, got %d' % len(args))\n  try:\n   self.__root\n  except AttributeError:\n   self.__hardroot = _Link()\n   self.__root = root = _proxy(self.__hardroot)\n   root.prev = root.next = root\n   self.__map = {}\n  self.__update(*args, **kwds)\n  \n def __setitem__(self, key, value,\n dict_setitem=dict.__setitem__, proxy=_proxy, Link=_Link):\n  \"\"\n  \n  \n  if key not in self:\n   self.__map[key] = link = Link()\n   root = self.__root\n   last = root.prev\n   link.prev, link.next, link.key = last, root, key\n   last.next = link\n   root.prev = proxy(link)\n  dict_setitem(self, key, value)\n  \n def __delitem__(self, key, dict_delitem=dict.__delitem__):\n  \"\"\n  \n  \n  dict_delitem(self, key)\n  link = self.__map.pop(key)\n  link_prev = link.prev\n  link_next = link.next\n  link_prev.next = link_next\n  link_next.prev = link_prev\n  \n def __iter__(self):\n  \"\"\n  \n  root = self.__root\n  curr = root.next\n  while curr is not root:\n   yield curr.key\n   curr = curr.next\n   \n def __reversed__(self):\n  \"\"\n  \n  root = self.__root\n  curr = root.prev\n  while curr is not root:\n   yield curr.key\n   curr = curr.prev\n   \n def clear(self):\n  \"\"\n  root = self.__root\n  root.prev = root.next = root\n  self.__map.clear()\n  dict.clear(self)\n  \n def popitem(self, last=True):\n  \"\"\n  if not self:\n   raise KeyError('dictionary is empty')\n  root = self.__root\n  if last:\n   link = root.prev\n   link_prev = link.prev\n   link_prev.next = root\n   root.prev = link_prev\n  else:\n   link = root.next\n   link_next = link.next\n   root.next = link_next\n   link_next.prev = root\n  key = link.key\n  del self.__map[key]\n  value = dict.pop(self, key)\n  return key, value\n  \n def move_to_end(self, key, last=True):\n  \"\"\n  link = self.__map[key]\n  link_prev = link.prev\n  link_next = link.next\n  link_prev.next = link_next\n  link_next.prev = link_prev\n  root = self.__root\n  if last:\n   last = root.prev\n   link.prev = last\n   link.next = root\n   last.next = root.prev = link\n  else:\n   first = root.next\n   link.prev = root\n   link.next = first\n   root.next = first.prev = link\n   \n def __sizeof__(self):\n  sizeof = _sys.getsizeof\n  n = len(self) + 1 \n  size = sizeof(self.__dict__) \n  size += sizeof(self.__map) * 2 \n  size += sizeof(self.__hardroot) * n \n  size += sizeof(self.__root) * n \n  return size\n  \n  \n update = __update = MutableMapping.update\n keys = MutableMapping.keys\n values = MutableMapping.values\n items = MutableMapping.items\n __ne__ = MutableMapping.__ne__\n \n __marker = object()\n \n def pop(self, key, default=__marker):\n  \"\"\n  if key in self:\n   result = self[key]\n   del self[key]\n   return result\n  if default is self.__marker:\n   raise KeyError(key)\n  return default\n  \n def setdefault(self, key, default=None):\n  \"\"\n  if key in self:\n   return self[key]\n  self[key] = default\n  return default\n  \n  \n  \n def __repr__(self):\n  \"\"\n  if not self:\n   return '%s()' % (self.__class__.__name__,)\n  return '%s(%r)' % (self.__class__.__name__, list(self.items()))\n  \n def __reduce__(self):\n  \"\"\n  items = [[k, self[k]] for k in self]\n  inst_dict = vars(self).copy()\n  for k in vars(OrderedDict()):\n   inst_dict.pop(k, None)\n  if inst_dict:\n   return (self.__class__, (items,), inst_dict)\n  return self.__class__, (items,)\n  \n def copy(self):\n  \"\"\n  return self.__class__(self)\n  \n @classmethod\n def fromkeys(cls, iterable, value=None):\n  \"\"\n  self = cls()\n  for key in iterable:\n   self[key] = value\n  return self\n  \n def __eq__(self, other):\n  \"\"\n  if isinstance(other, OrderedDict):\n   return len(self)==len(other) and all(p==q for p, q in zip(self.items(), other.items()))\n  return dict.__eq__(self, other)\n  \n  \n  \n  \n  \n  \n  \ndef _count_elements(mapping, iterable):\n \"\"\n mapping_get = mapping.get\n for elem in iterable:\n  mapping[elem] = mapping_get(elem, 0) + 1\n  \n  \n  \n  \n  \n  \nclass Counter(dict):\n \"\"\n \n \n \n \n \n \n \n def __init__(self, iterable=None, **kwds):\n  \"\"\n  \n  dict.__init__(self)\n  self.update(iterable, **kwds)\n  \n def __missing__(self, key):\n  \"\"\n  \n  return 0\n  \n def most_common(self, n=None):\n  \"\"\n  \n  if n is None:\n   return sorted(self.items(), key=_itemgetter(1), reverse=True)\n  return _heapq.nlargest(n, self.items(), key=_itemgetter(1))\n  \n def elements(self):\n  \"\"\n  \n  return _chain.from_iterable(_starmap(_repeat, self.items()))\n  \n  \n  \n @classmethod\n def fromkeys(cls, iterable, v=None):\n \n \n  raise NotImplementedError(\n  'Counter.fromkeys() is undefined.  Use Counter(iterable) instead.')\n  \n def update(self, iterable=None, **kwds):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  if iterable is not None:\n   if isinstance(iterable, Mapping):\n    if self:\n     self_get = self.get\n     for elem, count in iterable.items():\n      self[elem] = count + self_get(elem, 0)\n    else:\n     super().update(iterable) \n   else:\n    _count_elements(self, iterable)\n  if kwds:\n   self.update(kwds)\n   \n def subtract(self, iterable=None, **kwds):\n  \"\"\n  if iterable is not None:\n   self_get = self.get\n   if isinstance(iterable, Mapping):\n    for elem, count in iterable.items():\n     self[elem] = self_get(elem, 0) - count\n   else:\n    for elem in iterable:\n     self[elem] = self_get(elem, 0) - 1\n  if kwds:\n   self.subtract(kwds)\n   \n def copy(self):\n  \"\"\n  return self.__class__(self)\n  \n def __reduce__(self):\n  return self.__class__, (dict(self),)\n  \n def __delitem__(self, elem):\n  \"\"\n  if elem in self:\n   super().__delitem__(elem)\n   \n def __repr__(self):\n  if not self:\n   return '%s()' % self.__class__.__name__\n  try:\n   items = ', '.join(map('%r: %r'.__mod__, self.most_common()))\n   return '%s({%s})' % (self.__class__.__name__, items)\n  except TypeError:\n  \n   return '{0}({1!r})'.format(self.__class__.__name__, dict(self))\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n def __add__(self, other):\n  \"\"\n  if not isinstance(other, Counter):\n   return NotImplemented\n  result = Counter()\n  for elem, count in self.items():\n   newcount = count + other[elem]\n   if newcount > 0:\n    result[elem] = newcount\n  for elem, count in other.items():\n   if elem not in self and count > 0:\n    result[elem] = count\n  return result\n  \n def __sub__(self, other):\n  \"\"\n  if not isinstance(other, Counter):\n   return NotImplemented\n  result = Counter()\n  for elem, count in self.items():\n   newcount = count - other[elem]\n   if newcount > 0:\n    result[elem] = newcount\n  for elem, count in other.items():\n   if elem not in self and count < 0:\n    result[elem] = 0 - count\n  return result\n  \n def __or__(self, other):\n  \"\"\n  if not isinstance(other, Counter):\n   return NotImplemented\n  result = Counter()\n  for elem, count in self.items():\n   other_count = other[elem]\n   newcount = other_count if count < other_count else count\n   if newcount > 0:\n    result[elem] = newcount\n  for elem, count in other.items():\n   if elem not in self and count > 0:\n    result[elem] = count\n  return result\n  \n def __and__(self, other):\n  \"\"\n  if not isinstance(other, Counter):\n   return NotImplemented\n  result = Counter()\n  for elem, count in self.items():\n   other_count = other[elem]\n   newcount = count if count < other_count else other_count\n   if newcount > 0:\n    result[elem] = newcount\n  return result\n  \n  \n  \n  \n  \n  \nclass ChainMap(MutableMapping):\n \"\"\n \n def __init__(self, *maps):\n  \"\"\n  self.maps = list(maps) or [{}] \n  \n def __missing__(self, key):\n  raise KeyError(key)\n  \n def __getitem__(self, key):\n  for mapping in self.maps:\n   try:\n    return mapping[key] \n   except KeyError:\n    pass\n  return self.__missing__(key) \n  \n def get(self, key, default=None):\n  return self[key] if key in self else default\n  \n def __len__(self):\n  return len(set().union(*self.maps)) \n  \n def __iter__(self):\n  return iter(set().union(*self.maps))\n  \n def __contains__(self, key):\n  return any(key in m for m in self.maps)\n  \n def __bool__(self):\n  return any(self.maps)\n  \n  \n  \n def __repr__(self):\n  return '{0.__class__.__name__}({1})'.format(\n  self, ', '.join(map(repr, self.maps)))\n  \n def __repr__(self):\n  return ','.join(str(_map) for _map in self.maps)\n  \n @classmethod\n def fromkeys(cls, iterable, *args):\n  \"\"\n  return cls(dict.fromkeys(iterable, *args))\n  \n def copy(self):\n  \"\"\n  return self.__class__(self.maps[0].copy(), *self.maps[1:])\n  \n __copy__ = copy\n \n def new_child(self): \n  \"\"\n  return self.__class__({}, *self.maps)\n  \n @property\n def parents(self): \n  \"\"\n  return self.__class__(*self.maps[1:])\n  \n def __setitem__(self, key, value):\n  self.maps[0][key] = value\n  \n def __delitem__(self, key):\n  try:\n   del self.maps[0][key]\n  except KeyError:\n   raise KeyError('Key not found in the first mapping: {!r}'.format(key))\n   \n def popitem(self):\n  \"\"\n  try:\n   return self.maps[0].popitem()\n  except KeyError:\n   raise KeyError('No keys found in the first mapping.')\n   \n def pop(self, key, *args):\n  \"\"\n  try:\n   return self.maps[0].pop(key, *args)\n  except KeyError:\n  \n   raise KeyError('Key not found in the first mapping: %s' % key)\n   \n def clear(self):\n  \"\"\n  self.maps[0].clear()\n  \n  \n  \n  \n  \n  \nclass UserDict(MutableMapping):\n\n\n def __init__(self, dict=None, **kwargs):\n  self.data = {}\n  if dict is not None:\n   self.update(dict)\n  if len(kwargs):\n   self.update(kwargs)\n def __len__(self): return len(self.data)\n def __getitem__(self, key):\n  if key in self.data:\n   return self.data[key]\n  if hasattr(self.__class__, \"__missing__\"):\n   return self.__class__.__missing__(self, key)\n  raise KeyError(key)\n def __setitem__(self, key, item): self.data[key] = item\n def __delitem__(self, key): del self.data[key]\n def __iter__(self):\n  return iter(self.data)\n  \n  \n def __contains__(self, key):\n  return key in self.data\n  \n  \n def __repr__(self): return repr(self.data)\n def copy(self):\n  if self.__class__ is UserDict:\n   return UserDict(self.data.copy())\n  import copy\n  data = self.data\n  try:\n   self.data = {}\n   c = copy.copy(self)\n  finally:\n   self.data = data\n  c.update(self)\n  return c\n @classmethod\n def fromkeys(cls, iterable, value=None):\n  d = cls()\n  for key in iterable:\n   d[key] = value\n  return d\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n", 1], "browser.html": [".py", "from _html import *"], "unittest.main": [".py", "\"\"\n\nimport sys\nimport optparse\nimport os\n\nfrom . import loader, runner\nfrom .signals import installHandler\n\n__unittest = True\n\nFAILFAST = \"  -f, --failfast   Stop on first failure\\n\"\nCATCHBREAK = \"  -c, --catch      Catch control-C and display results\\n\"\nBUFFEROUTPUT = \"  -b, --buffer     Buffer stdout and stderr during test runs\\n\"\n\nUSAGE_AS_MAIN = \"\"\"\\\nUsage: %(progName)s [options] [tests]\n\nOptions:\n  -h, --help       Show this message\n  -v, --verbose    Verbose output\n  -q, --quiet      Minimal output\n%(failfast)s%(catchbreak)s%(buffer)s\nExamples:\n  %(progName)s test_module               - run tests from test_module\n  %(progName)s module.TestClass          - run tests from module.TestClass\n  %(progName)s module.Class.test_method  - run specified test method\n\n[tests] can be a list of any number of test modules, classes and test\nmethods.\n\nAlternative Usage: %(progName)s discover [options]\n\nOptions:\n  -v, --verbose    Verbose output\n%(failfast)s%(catchbreak)s%(buffer)s  -s directory     Directory to start discovery ('.' default)\n  -p pattern       Pattern to match test files ('test*.py' default)\n  -t directory     Top level directory of project (default to\n                   start directory)\n\nFor test discovery all test modules must be importable from the top\nlevel directory of the project.\n\"\"\"\n\nUSAGE_FROM_MODULE = \"\"\"\\\nUsage: %(progName)s [options] [test] [...]\n\nOptions:\n  -h, --help       Show this message\n  -v, --verbose    Verbose output\n  -q, --quiet      Minimal output\n%(failfast)s%(catchbreak)s%(buffer)s\nExamples:\n  %(progName)s                               - run default set of tests\n  %(progName)s MyTestSuite                   - run suite 'MyTestSuite'\n  %(progName)s MyTestCase.testSomething      - run MyTestCase.testSomething\n  %(progName)s MyTestCase                    - run all 'test*' test methods\n                                               in MyTestCase\n\"\"\"\n\ndef _convert_name(name):\n\n\n\n\n if os.path.isfile(name) and name.lower().endswith('.py'):\n  if os.path.isabs(name):\n   rel_path = os.path.relpath(name, os.getcwd())\n   if os.path.isabs(rel_path) or rel_path.startswith(os.pardir):\n    return name\n   name = rel_path\n   \n   \n  return name[:-3].replace('\\\\', '.').replace('/', '.')\n return name\n \ndef _convert_names(names):\n return [_convert_name(name) for name in names]\n \n \nclass TestProgram(object):\n \"\"\n USAGE = USAGE_FROM_MODULE\n \n \n failfast = catchbreak = buffer = progName = warnings = None\n \n def __init__(self, module='__main__', defaultTest=None, argv=None,\n testRunner=None, testLoader=loader.defaultTestLoader,\n exit=True, verbosity=1, failfast=None, catchbreak=None,\n buffer=None, warnings=None):\n  if isinstance(module, str):\n   self.module = __import__(module)\n   for part in module.split('.')[1:]:\n    self.module = getattr(self.module, part)\n  else:\n   self.module = module\n  if argv is None:\n   argv = sys.argv\n   \n  self.exit = exit\n  self.failfast = failfast\n  self.catchbreak = catchbreak\n  self.verbosity = verbosity\n  self.buffer = buffer\n  if warnings is None and not sys.warnoptions:\n  \n  \n  \n   self.warnings = 'default'\n  else:\n  \n  \n  \n  \n  \n   self.warnings = warnings\n  self.defaultTest = defaultTest\n  self.testRunner = testRunner\n  self.testLoader = testLoader\n  self.progName = os.path.basename(argv[0])\n  self.parseArgs(argv)\n  self.runTests()\n  \n def usageExit(self, msg=None):\n  if msg:\n   print(msg)\n  usage = {'progName': self.progName, 'catchbreak': '', 'failfast': '',\n  'buffer': ''}\n  if self.failfast != False:\n   usage['failfast'] = FAILFAST\n  if self.catchbreak != False:\n   usage['catchbreak'] = CATCHBREAK\n  if self.buffer != False:\n   usage['buffer'] = BUFFEROUTPUT\n  print(self.USAGE % usage)\n  sys.exit(2)\n  \n def parseArgs(self, argv):\n  if ((len(argv) > 1 and argv[1].lower() == 'discover') or\n  (len(argv) == 1 and self.module is None)):\n   self._do_discovery(argv[2:])\n   return\n   \n  parser = self._getOptParser()\n  options, args = parser.parse_args(argv[1:])\n  self._setAttributesFromOptions(options)\n  \n  if len(args) == 0 and self.module is None:\n  \n  \n  \n   self._do_discovery(argv[1:])\n   return\n   \n  if len(args) == 0 and self.defaultTest is None:\n  \n   self.testNames = None\n  elif len(args) > 0:\n   self.testNames = _convert_names(args)\n   if __name__ == '__main__':\n   \n    self.module = None\n  else:\n   self.testNames = (self.defaultTest,)\n  self.createTests()\n  \n def createTests(self):\n  if self.testNames is None:\n   self.test = self.testLoader.loadTestsFromModule(self.module)\n  else:\n   self.test = self.testLoader.loadTestsFromNames(self.testNames,\n   self.module)\n   \n def _getOptParser(self):\n  import optparse\n  parser = optparse.OptionParser()\n  parser.prog = self.progName\n  parser.add_option('-v', '--verbose', dest='verbose', default=False,\n  help='Verbose output', action='store_true')\n  parser.add_option('-q', '--quiet', dest='quiet', default=False,\n  help='Quiet output', action='store_true')\n  \n  if self.failfast != False:\n   parser.add_option('-f', '--failfast', dest='failfast', default=False,\n   help='Stop on first fail or error',\n   action='store_true')\n  if self.catchbreak != False:\n   parser.add_option('-c', '--catch', dest='catchbreak', default=False,\n   help='Catch ctrl-C and display results so far',\n   action='store_true')\n  if self.buffer != False:\n   parser.add_option('-b', '--buffer', dest='buffer', default=False,\n   help='Buffer stdout and stderr during tests',\n   action='store_true')\n  return parser\n  \n def _setAttributesFromOptions(self, options):\n \n \n  if self.failfast is None:\n   self.failfast = options.failfast\n  if self.catchbreak is None:\n   self.catchbreak = options.catchbreak\n  if self.buffer is None:\n   self.buffer = options.buffer\n   \n  if options.verbose:\n   self.verbosity = 2\n  elif options.quiet:\n   self.verbosity = 0\n   \n def _addDiscoveryOptions(self, parser):\n  parser.add_option('-s', '--start-directory', dest='start', default='.',\n  help=\"Directory to start discovery ('.' default)\")\n  parser.add_option('-p', '--pattern', dest='pattern', default='test*.py',\n  help=\"Pattern to match tests ('test*.py' default)\")\n  parser.add_option('-t', '--top-level-directory', dest='top', default=None,\n  help='Top level directory of project (defaults to start directory)')\n  \n def _do_discovery(self, argv, Loader=None):\n  if Loader is None:\n   Loader = lambda: self.testLoader\n   \n   \n  self.progName = '%s discover' % self.progName\n  parser = self._getOptParser()\n  self._addDiscoveryOptions(parser)\n  \n  options, args = parser.parse_args(argv)\n  if len(args) > 3:\n   self.usageExit()\n   \n  for name, value in zip(('start', 'pattern', 'top'), args):\n   setattr(options, name, value)\n   \n  self._setAttributesFromOptions(options)\n  \n  start_dir = options.start\n  pattern = options.pattern\n  top_level_dir = options.top\n  \n  loader = Loader()\n  self.test = loader.discover(start_dir, pattern, top_level_dir)\n  \n def runTests(self):\n  if self.catchbreak:\n   installHandler()\n  if self.testRunner is None:\n   self.testRunner = runner.TextTestRunner\n  if isinstance(self.testRunner, type):\n   try:\n    testRunner = self.testRunner(verbosity=self.verbosity,\n    failfast=self.failfast,\n    buffer=self.buffer,\n    warnings=self.warnings)\n   except TypeError:\n   \n    testRunner = self.testRunner()\n  else:\n  \n   testRunner = self.testRunner\n  self.result = testRunner.run(self.test)\n  if self.exit:\n   sys.exit(not self.result.wasSuccessful())\n   \nmain = TestProgram\n"], "ui.progressbar": [".py", "from . import widget\nfrom browser import html\n\nclass ProgressBar(widget.Widget):\n def __init__(self, id=None, label=False):\n  self._div_shell=html.DIV(Class=\"ui-progressbar ui-widget ui-widget-content ui-corner-all\")\n  widget.Widget.__init__(self, self._div_shell, 'progressbar', id)\n  \n  self._show_label=label\n  if label:\n   self._label=html.DIV(Class='progress-label')\n   self._div_shell <= self._label\n   \n  self._bar=html.DIV(Class=\"ui-progressbar-value ui-widget-header ui-corner-left\",\n  style={'width': '0px'})\n  self._div_shell <= self._bar\n  \n def set_progress(self, percent):\n  self._bar.style.width='%s%%' % percent\n  if self._show_label:\n   self._label.text='%s%%' % percent\n"], "unittest.test.testmock.testsentinel": [".py", "import unittest\nfrom unittest.mock import sentinel, DEFAULT\n\n\nclass SentinelTest(unittest.TestCase):\n\n def testSentinels(self):\n  self.assertEqual(sentinel.whatever, sentinel.whatever,\n  'sentinel not stored')\n  self.assertNotEqual(sentinel.whatever, sentinel.whateverelse,\n  'sentinel should be unique')\n  \n  \n def testSentinelName(self):\n  self.assertEqual(str(sentinel.whatever), 'sentinel.whatever',\n  'sentinel name incorrect')\n  \n  \n def testDEFAULT(self):\n  self.assertTrue(DEFAULT is sentinel.DEFAULT)\n  \n def testBases(self):\n \n  self.assertRaises(AttributeError, lambda: sentinel.__bases__)\n  \n  \nif __name__ == '__main__':\n unittest.main()\n"], "unittest.test.test_setups": [".py", "import io\nimport sys\n\nimport unittest\n\n\ndef resultFactory(*_):\n return unittest.TestResult()\n \n \nclass TestSetups(unittest.TestCase):\n\n def getRunner(self):\n  return unittest.TextTestRunner(resultclass=resultFactory,\n  stream=io.StringIO())\n def runTests(self, *cases):\n  suite = unittest.TestSuite()\n  for case in cases:\n   tests = unittest.defaultTestLoader.loadTestsFromTestCase(case)\n   suite.addTests(tests)\n   \n  runner = self.getRunner()\n  \n  \n  realSuite = unittest.TestSuite()\n  realSuite.addTest(suite)\n  \n  suite.addTest(unittest.TestSuite())\n  realSuite.addTest(unittest.TestSuite())\n  return runner.run(realSuite)\n  \n def test_setup_class(self):\n  class Test(unittest.TestCase):\n   setUpCalled = 0\n   @classmethod\n   def setUpClass(cls):\n    Test.setUpCalled += 1\n    unittest.TestCase.setUpClass()\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  result = self.runTests(Test)\n  \n  self.assertEqual(Test.setUpCalled, 1)\n  self.assertEqual(result.testsRun, 2)\n  self.assertEqual(len(result.errors), 0)\n  \n def test_teardown_class(self):\n  class Test(unittest.TestCase):\n   tearDownCalled = 0\n   @classmethod\n   def tearDownClass(cls):\n    Test.tearDownCalled += 1\n    unittest.TestCase.tearDownClass()\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  result = self.runTests(Test)\n  \n  self.assertEqual(Test.tearDownCalled, 1)\n  self.assertEqual(result.testsRun, 2)\n  self.assertEqual(len(result.errors), 0)\n  \n def test_teardown_class_two_classes(self):\n  class Test(unittest.TestCase):\n   tearDownCalled = 0\n   @classmethod\n   def tearDownClass(cls):\n    Test.tearDownCalled += 1\n    unittest.TestCase.tearDownClass()\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  class Test2(unittest.TestCase):\n   tearDownCalled = 0\n   @classmethod\n   def tearDownClass(cls):\n    Test2.tearDownCalled += 1\n    unittest.TestCase.tearDownClass()\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  result = self.runTests(Test, Test2)\n  \n  self.assertEqual(Test.tearDownCalled, 1)\n  self.assertEqual(Test2.tearDownCalled, 1)\n  self.assertEqual(result.testsRun, 4)\n  self.assertEqual(len(result.errors), 0)\n  \n def test_error_in_setupclass(self):\n  class BrokenTest(unittest.TestCase):\n   @classmethod\n   def setUpClass(cls):\n    raise TypeError('foo')\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  result = self.runTests(BrokenTest)\n  \n  self.assertEqual(result.testsRun, 0)\n  self.assertEqual(len(result.errors), 1)\n  error, _ = result.errors[0]\n  self.assertEqual(str(error),\n  'setUpClass (%s.BrokenTest)' % __name__)\n  \n def test_error_in_teardown_class(self):\n  class Test(unittest.TestCase):\n   tornDown = 0\n   @classmethod\n   def tearDownClass(cls):\n    Test.tornDown += 1\n    raise TypeError('foo')\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  class Test2(unittest.TestCase):\n   tornDown = 0\n   @classmethod\n   def tearDownClass(cls):\n    Test2.tornDown += 1\n    raise TypeError('foo')\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  result = self.runTests(Test, Test2)\n  self.assertEqual(result.testsRun, 4)\n  self.assertEqual(len(result.errors), 2)\n  self.assertEqual(Test.tornDown, 1)\n  self.assertEqual(Test2.tornDown, 1)\n  \n  error, _ = result.errors[0]\n  self.assertEqual(str(error),\n  'tearDownClass (%s.Test)' % __name__)\n  \n def test_class_not_torndown_when_setup_fails(self):\n  class Test(unittest.TestCase):\n   tornDown = False\n   @classmethod\n   def setUpClass(cls):\n    raise TypeError\n   @classmethod\n   def tearDownClass(cls):\n    Test.tornDown = True\n    raise TypeError('foo')\n   def test_one(self):\n    pass\n    \n  self.runTests(Test)\n  self.assertFalse(Test.tornDown)\n  \n def test_class_not_setup_or_torndown_when_skipped(self):\n  class Test(unittest.TestCase):\n   classSetUp = False\n   tornDown = False\n   @classmethod\n   def setUpClass(cls):\n    Test.classSetUp = True\n   @classmethod\n   def tearDownClass(cls):\n    Test.tornDown = True\n   def test_one(self):\n    pass\n    \n  Test = unittest.skip(\"hop\")(Test)\n  self.runTests(Test)\n  self.assertFalse(Test.classSetUp)\n  self.assertFalse(Test.tornDown)\n  \n def test_setup_teardown_order_with_pathological_suite(self):\n  results = []\n  \n  class Module1(object):\n   @staticmethod\n   def setUpModule():\n    results.append('Module1.setUpModule')\n   @staticmethod\n   def tearDownModule():\n    results.append('Module1.tearDownModule')\n    \n  class Module2(object):\n   @staticmethod\n   def setUpModule():\n    results.append('Module2.setUpModule')\n   @staticmethod\n   def tearDownModule():\n    results.append('Module2.tearDownModule')\n    \n  class Test1(unittest.TestCase):\n   @classmethod\n   def setUpClass(cls):\n    results.append('setup 1')\n   @classmethod\n   def tearDownClass(cls):\n    results.append('teardown 1')\n   def testOne(self):\n    results.append('Test1.testOne')\n   def testTwo(self):\n    results.append('Test1.testTwo')\n    \n  class Test2(unittest.TestCase):\n   @classmethod\n   def setUpClass(cls):\n    results.append('setup 2')\n   @classmethod\n   def tearDownClass(cls):\n    results.append('teardown 2')\n   def testOne(self):\n    results.append('Test2.testOne')\n   def testTwo(self):\n    results.append('Test2.testTwo')\n    \n  class Test3(unittest.TestCase):\n   @classmethod\n   def setUpClass(cls):\n    results.append('setup 3')\n   @classmethod\n   def tearDownClass(cls):\n    results.append('teardown 3')\n   def testOne(self):\n    results.append('Test3.testOne')\n   def testTwo(self):\n    results.append('Test3.testTwo')\n    \n  Test1.__module__ = Test2.__module__ = 'Module'\n  Test3.__module__ = 'Module2'\n  sys.modules['Module'] = Module1\n  sys.modules['Module2'] = Module2\n  \n  first = unittest.TestSuite((Test1('testOne'),))\n  second = unittest.TestSuite((Test1('testTwo'),))\n  third = unittest.TestSuite((Test2('testOne'),))\n  fourth = unittest.TestSuite((Test2('testTwo'),))\n  fifth = unittest.TestSuite((Test3('testOne'),))\n  sixth = unittest.TestSuite((Test3('testTwo'),))\n  suite = unittest.TestSuite((first, second, third, fourth, fifth, sixth))\n  \n  runner = self.getRunner()\n  result = runner.run(suite)\n  self.assertEqual(result.testsRun, 6)\n  self.assertEqual(len(result.errors), 0)\n  \n  self.assertEqual(results,\n  ['Module1.setUpModule', 'setup 1',\n  'Test1.testOne', 'Test1.testTwo', 'teardown 1',\n  'setup 2', 'Test2.testOne', 'Test2.testTwo',\n  'teardown 2', 'Module1.tearDownModule',\n  'Module2.setUpModule', 'setup 3',\n  'Test3.testOne', 'Test3.testTwo',\n  'teardown 3', 'Module2.tearDownModule'])\n  \n def test_setup_module(self):\n  class Module(object):\n   moduleSetup = 0\n   @staticmethod\n   def setUpModule():\n    Module.moduleSetup += 1\n    \n  class Test(unittest.TestCase):\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n  Test.__module__ = 'Module'\n  sys.modules['Module'] = Module\n  \n  result = self.runTests(Test)\n  self.assertEqual(Module.moduleSetup, 1)\n  self.assertEqual(result.testsRun, 2)\n  self.assertEqual(len(result.errors), 0)\n  \n def test_error_in_setup_module(self):\n  class Module(object):\n   moduleSetup = 0\n   moduleTornDown = 0\n   @staticmethod\n   def setUpModule():\n    Module.moduleSetup += 1\n    raise TypeError('foo')\n   @staticmethod\n   def tearDownModule():\n    Module.moduleTornDown += 1\n    \n  class Test(unittest.TestCase):\n   classSetUp = False\n   classTornDown = False\n   @classmethod\n   def setUpClass(cls):\n    Test.classSetUp = True\n   @classmethod\n   def tearDownClass(cls):\n    Test.classTornDown = True\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  class Test2(unittest.TestCase):\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n  Test.__module__ = 'Module'\n  Test2.__module__ = 'Module'\n  sys.modules['Module'] = Module\n  \n  result = self.runTests(Test, Test2)\n  self.assertEqual(Module.moduleSetup, 1)\n  self.assertEqual(Module.moduleTornDown, 0)\n  self.assertEqual(result.testsRun, 0)\n  self.assertFalse(Test.classSetUp)\n  self.assertFalse(Test.classTornDown)\n  self.assertEqual(len(result.errors), 1)\n  error, _ = result.errors[0]\n  self.assertEqual(str(error), 'setUpModule (Module)')\n  \n def test_testcase_with_missing_module(self):\n  class Test(unittest.TestCase):\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n  Test.__module__ = 'Module'\n  sys.modules.pop('Module', None)\n  \n  result = self.runTests(Test)\n  self.assertEqual(result.testsRun, 2)\n  \n def test_teardown_module(self):\n  class Module(object):\n   moduleTornDown = 0\n   @staticmethod\n   def tearDownModule():\n    Module.moduleTornDown += 1\n    \n  class Test(unittest.TestCase):\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n  Test.__module__ = 'Module'\n  sys.modules['Module'] = Module\n  \n  result = self.runTests(Test)\n  self.assertEqual(Module.moduleTornDown, 1)\n  self.assertEqual(result.testsRun, 2)\n  self.assertEqual(len(result.errors), 0)\n  \n def test_error_in_teardown_module(self):\n  class Module(object):\n   moduleTornDown = 0\n   @staticmethod\n   def tearDownModule():\n    Module.moduleTornDown += 1\n    raise TypeError('foo')\n    \n  class Test(unittest.TestCase):\n   classSetUp = False\n   classTornDown = False\n   @classmethod\n   def setUpClass(cls):\n    Test.classSetUp = True\n   @classmethod\n   def tearDownClass(cls):\n    Test.classTornDown = True\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  class Test2(unittest.TestCase):\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n  Test.__module__ = 'Module'\n  Test2.__module__ = 'Module'\n  sys.modules['Module'] = Module\n  \n  result = self.runTests(Test, Test2)\n  self.assertEqual(Module.moduleTornDown, 1)\n  self.assertEqual(result.testsRun, 4)\n  self.assertTrue(Test.classSetUp)\n  self.assertTrue(Test.classTornDown)\n  self.assertEqual(len(result.errors), 1)\n  error, _ = result.errors[0]\n  self.assertEqual(str(error), 'tearDownModule (Module)')\n  \n def test_skiptest_in_setupclass(self):\n  class Test(unittest.TestCase):\n   @classmethod\n   def setUpClass(cls):\n    raise unittest.SkipTest('foo')\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  result = self.runTests(Test)\n  self.assertEqual(result.testsRun, 0)\n  self.assertEqual(len(result.errors), 0)\n  self.assertEqual(len(result.skipped), 1)\n  skipped = result.skipped[0][0]\n  self.assertEqual(str(skipped), 'setUpClass (%s.Test)' % __name__)\n  \n def test_skiptest_in_setupmodule(self):\n  class Test(unittest.TestCase):\n   def test_one(self):\n    pass\n   def test_two(self):\n    pass\n    \n  class Module(object):\n   @staticmethod\n   def setUpModule():\n    raise unittest.SkipTest('foo')\n    \n  Test.__module__ = 'Module'\n  sys.modules['Module'] = Module\n  \n  result = self.runTests(Test)\n  self.assertEqual(result.testsRun, 0)\n  self.assertEqual(len(result.errors), 0)\n  self.assertEqual(len(result.skipped), 1)\n  skipped = result.skipped[0][0]\n  self.assertEqual(str(skipped), 'setUpModule (Module)')\n  \n def test_suite_debug_executes_setups_and_teardowns(self):\n  ordering = []\n  \n  class Module(object):\n   @staticmethod\n   def setUpModule():\n    ordering.append('setUpModule')\n   @staticmethod\n   def tearDownModule():\n    ordering.append('tearDownModule')\n    \n  class Test(unittest.TestCase):\n   @classmethod\n   def setUpClass(cls):\n    ordering.append('setUpClass')\n   @classmethod\n   def tearDownClass(cls):\n    ordering.append('tearDownClass')\n   def test_something(self):\n    ordering.append('test_something')\n    \n  Test.__module__ = 'Module'\n  sys.modules['Module'] = Module\n  \n  suite = unittest.defaultTestLoader.loadTestsFromTestCase(Test)\n  suite.debug()\n  expectedOrder = ['setUpModule', 'setUpClass', 'test_something', 'tearDownClass', 'tearDownModule']\n  self.assertEqual(ordering, expectedOrder)\n  \n def test_suite_debug_propagates_exceptions(self):\n  class Module(object):\n   @staticmethod\n   def setUpModule():\n    if phase == 0:\n     raise Exception('setUpModule')\n   @staticmethod\n   def tearDownModule():\n    if phase == 1:\n     raise Exception('tearDownModule')\n     \n  class Test(unittest.TestCase):\n   @classmethod\n   def setUpClass(cls):\n    if phase == 2:\n     raise Exception('setUpClass')\n   @classmethod\n   def tearDownClass(cls):\n    if phase == 3:\n     raise Exception('tearDownClass')\n   def test_something(self):\n    if phase == 4:\n     raise Exception('test_something')\n     \n  Test.__module__ = 'Module'\n  sys.modules['Module'] = Module\n  \n  _suite = unittest.defaultTestLoader.loadTestsFromTestCase(Test)\n  suite = unittest.TestSuite()\n  suite.addTest(_suite)\n  \n  messages = ('setUpModule', 'tearDownModule', 'setUpClass', 'tearDownClass', 'test_something')\n  for phase, msg in enumerate(messages):\n   with self.assertRaisesRegex(Exception, msg):\n    suite.debug()\n    \nif __name__ == '__main__':\n unittest.main()\n"], "browser.object_storage": [".py", "import pickle\n\nclass __UnProvided():\n pass\n \n \nclass Object_Storage():\n\n def __init__(self, storage):\n  self.storage = storage\n  \n def __delitem__(self, key):\n  del self.storage[pickle.dumps(key)]\n  \n def __getitem__(self, key):\n  return pickle.loads(self.storage[pickle.dumps(key)])\n  \n def __setitem__(self, key, value):\n  self.storage[pickle.dumps(key)] = pickle.dumps(value)\n  \n def __contains__(self, key):\n  return pickle.dumps(key) in self.storage\n  \n def get(self, key, default=None):\n  if pickle.dumps(key) in self.storage:\n   return self.storage[pickle.dumps(key)]\n  return default\n  \n def pop(self, key, default=__UnProvided()):\n  if type(default) is __UnProvided or pickle.dumps(key) in self.storage:\n   return pickle.loads(self.storage.pop(pickle.dumps(key)))\n  return default\n  \n def __iter__(self):\n  keys = self.keys()\n  return keys.__iter__()\n  \n def keys(self):\n  return [pickle.loads(key) for key in self.storage.keys()]\n  \n def values(self):\n  return [pickle.loads(val) for val in self.storage.values()]\n  \n def items(self):\n  return list(zip(self.keys(), self.values()))\n  \n def clear(self):\n  self.storage.clear()\n  \n def __len__(self):\n  return len(self.storage)\n"], "string": [".py", "\"\"\n\nimport _string\n\n\nwhitespace = ' \\t\\n\\r\\v\\f'\nascii_lowercase = 'abcdefghijklmnopqrstuvwxyz'\nascii_uppercase = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\nascii_letters = ascii_lowercase + ascii_uppercase\ndigits = '0123456789'\nhexdigits = digits + 'abcdef' + 'ABCDEF'\noctdigits = '01234567'\npunctuation = \"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"\nprintable = digits + ascii_letters + punctuation + whitespace\n\n\n\n\ndef capwords(s, sep=None):\n \"\"\n return (sep or ' ').join(x.capitalize() for x in s.split(sep))\n \n \n \nimport re as _re\nfrom collections import ChainMap\n\nclass _TemplateMetaclass(type):\n pattern = r\"\"\"\n    %(delim)s(?:\n      (?P<escaped>%(delim)s) |   # Escape sequence of two delimiters\n      (?P<named>%(id)s)      |   # delimiter and a Python identifier\n      {(?P<braced>%(id)s)}   |   # delimiter and a braced identifier\n      (?P<invalid>)              # Other ill-formed delimiter exprs\n    )\n    \"\"\" \n \n def __init__(cls, name, bases, dct):\n  super(_TemplateMetaclass, cls).__init__(name, bases, dct)\n  if 'pattern' in dct:\n   pattern = cls.pattern\n  else:\n   pattern = _TemplateMetaclass.pattern % {\n   'delim' : _re.escape(cls.delimiter),\n   'id' : cls.idpattern,\n   }\n  cls.pattern = _re.compile(pattern, cls.flags | _re.VERBOSE)\n  \n  \nclass Template(metaclass=_TemplateMetaclass):\n \"\"\n \n delimiter = '$'\n idpattern = r'[_a-z][_a-z0-9]*'\n flags = _re.IGNORECASE\n \n def __init__(self, template):\n  self.template = template\n  \n  \n  \n def _invalid(self, mo):\n  i = mo.start('invalid')\n  lines = self.template[:i].splitlines(keepends=True)\n  if not lines:\n   colno = 1\n   lineno = 1\n  else:\n   colno = i - len(''.join(lines[:-1]))\n   lineno = len(lines)\n  raise ValueError('Invalid placeholder in string: line %d, col %d' %\n  (lineno, colno))\n  \n def substitute(self, *args, **kws):\n  if len(args) > 1:\n   raise TypeError('Too many positional arguments')\n  if not args:\n   mapping = kws\n  elif kws:\n   mapping = ChainMap(kws, args[0])\n  else:\n   mapping = args[0]\n   \n  def convert(mo):\n  \n   named = mo.group('named') or mo.group('braced')\n   if named is not None:\n    val = mapping[named]\n    \n    \n    return '%s' % (val,)\n   if mo.group('escaped') is not None:\n    return self.delimiter\n   if mo.group('invalid') is not None:\n    self._invalid(mo)\n   raise ValueError('Unrecognized named group in pattern',\n   self.pattern)\n  return self.pattern.sub(convert, self.template)\n  \n def safe_substitute(self, *args, **kws):\n  if len(args) > 1:\n   raise TypeError('Too many positional arguments')\n  if not args:\n   mapping = kws\n  elif kws:\n   mapping = ChainMap(kws, args[0])\n  else:\n   mapping = args[0]\n   \n  def convert(mo):\n   named = mo.group('named') or mo.group('braced')\n   if named is not None:\n    try:\n    \n    \n     return '%s' % (mapping[named],)\n    except KeyError:\n     return mo.group()\n   if mo.group('escaped') is not None:\n    return self.delimiter\n   if mo.group('invalid') is not None:\n    return mo.group()\n   raise ValueError('Unrecognized named group in pattern',\n   self.pattern)\n  return self.pattern.sub(convert, self.template)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \nclass Formatter:\n def format(self, format_string, *args, **kwargs):\n  return self.vformat(format_string, args, kwargs)\n  \n def vformat(self, format_string, args, kwargs):\n  used_args = set()\n  result = self._vformat(format_string, args, kwargs, used_args, 2)\n  self.check_unused_args(used_args, args, kwargs)\n  return result\n  \n def _vformat(self, format_string, args, kwargs, used_args, recursion_depth):\n  if recursion_depth < 0:\n   raise ValueError('Max string recursion exceeded')\n  result = []\n  for literal_text, field_name, format_spec, conversion in self.parse(format_string):\n  \n  \n   if literal_text:\n    result.append(literal_text)\n    \n    \n   if field_name is not None:\n   \n   \n   \n   \n   \n    obj, arg_used = self.get_field(field_name, args, kwargs)\n    used_args.add(arg_used)\n    \n    \n    obj = self.convert_field(obj, conversion)\n    \n    \n    format_spec = self._vformat(format_spec, args, kwargs,\n    used_args, recursion_depth-1)\n    \n    \n    result.append(self.format_field(obj, format_spec))\n    \n  return ''.join(result)\n  \n  \n def get_value(self, key, args, kwargs):\n  if isinstance(key, int):\n   return args[key]\n  else:\n   return kwargs[key]\n   \n   \n def check_unused_args(self, used_args, args, kwargs):\n  pass\n  \n  \n def format_field(self, value, format_spec):\n  return format(value, format_spec)\n  \n  \n def convert_field(self, value, conversion):\n \n  if conversion is None:\n   return value\n  elif conversion == 's':\n   return str(value)\n  elif conversion == 'r':\n   return repr(value)\n  elif conversion == 'a':\n   return ascii(value)\n  raise ValueError(\"Unknown conversion specifier {0!s}\".format(conversion))\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def parse(self, format_string):\n  return _string.formatter_parser(format_string)\n  \n  \n  \n  \n  \n  \n  \n def get_field(self, field_name, args, kwargs):\n  first, rest = _string.formatter_field_name_split(field_name)\n  \n  obj = self.get_value(first, args, kwargs)\n  \n  \n  \n  for is_attr, i in rest:\n   if is_attr:\n    obj = getattr(obj, i)\n   else:\n    obj = obj[i]\n    \n  return obj, first\n"], "browser.local_storage": [".py", "\n\nfrom javascript import JSObject\n\nclass __UnProvided():\n pass\n \nclass Local_Storage():\n storage_type = \"local_storage\"\n \n def __init__(self):\n  self.store = JSObject(__BRYTHON__.local_storage)\n  \n def __delitem__(self, key):\n  if (not isinstance(key, str)):\n   raise TypeError(\"key must be string\")\n  if key not in self:\n   raise KeyError(key)\n  self.store.removeItem(key)\n  \n def __getitem__(self, key):\n  if (not isinstance(key, str)):\n   raise TypeError(\"key must be string\")\n  res = __BRYTHON__.JSObject(self.store.getItem(key))\n  if res:\n   return res\n  raise KeyError(key)\n  \n def __setitem__(self, key, value):\n  if (not isinstance(key, str)):\n   raise TypeError(\"key must be string\")\n  if (not isinstance(value, str)):\n   raise TypeError(\"value must be string\")\n  self.store.setItem(key, value)\n  \n  \n def __contains__(self, key):\n  if (not isinstance(key, str)):\n   raise TypeError(\"key must be string\")\n  res = __BRYTHON__.JSObject(self.store.getItem(key))\n  if res is None:\n   return False\n  return True\n  \n def __iter__(self):\n  keys = self.keys()\n  return keys.__iter__()\n  \n def get(self, key, default=None):\n  if (not isinstance(key, str)):\n   raise TypeError(\"key must be string\")\n  return __BRYTHON__.JSObject(self.store.getItem(key)) or default\n  \n def pop(self, key, default=__UnProvided()):\n  if (not isinstance(key, str)):\n   raise TypeError(\"key must be string\")\n  if type(default) is __UnProvided:\n   ret = self.get(key)\n   del self[key] \n   return ret\n  else:\n   if key in self:\n    ret = self.get(key)\n    del self[key]\n    return ret\n   else:\n    return default\n    \n    \n    \n def keys(self):\n  return [__BRYTHON__.JSObject(self.store.key(i)) for i in range(self.store.length)]\n  \n def values(self):\n  return [__BRYTHON__.JSObject(self.__getitem__(k)) for k in self.keys()]\n  \n def items(self):\n  return list(zip(self.keys(), self.values()))\n  \n def clear(self):\n  self.store.clear()\n  \n def __len__(self):\n  return self.store.length\n  \nstorage = Local_Storage()\n"], "multiprocessing.dummy": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n__all__ = [\n'Process', 'current_process', 'active_children', 'freeze_support',\n'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Condition',\n'Event', 'Barrier', 'Queue', 'Manager', 'Pipe', 'Pool', 'JoinableQueue'\n]\n\n\n\n\n\nimport threading\nimport sys\nimport weakref\n\n\n\nfrom multiprocessing.dummy.connection import Pipe\nfrom threading import Lock, RLock, Semaphore, BoundedSemaphore\nfrom threading import Event, Condition, Barrier\nfrom queue import Queue\n\n\n\n\n\nclass DummyProcess(threading.Thread):\n\n def __init__(self, group=None, target=None, name=None, args=(), kwargs={}):\n  threading.Thread.__init__(self, group, target, name, args, kwargs)\n  self._pid = None\n  self._children = weakref.WeakKeyDictionary()\n  self._start_called = False\n  self._parent = current_process()\n  \n def start(self):\n  assert self._parent is current_process()\n  self._start_called = True\n  if hasattr(self._parent, '_children'):\n   self._parent._children[self] = None\n  threading.Thread.start(self)\n  \n @property\n def exitcode(self):\n  if self._start_called and not self.is_alive():\n   return 0\n  else:\n   return None\n   \n   \n   \n   \n   \nProcess = DummyProcess\ncurrent_process = threading.current_thread\ncurrent_process()._children = weakref.WeakKeyDictionary()\n\ndef active_children():\n children = current_process()._children\n for p in list(children):\n  if not p.is_alive():\n   children.pop(p, None)\n return list(children)\n \ndef freeze_support():\n pass\n \n \n \n \n \nclass Namespace(object):\n def __init__(self, **kwds):\n  self.__dict__.update(kwds)\n def __repr__(self):\n  items = list(self.__dict__.items())\n  temp = []\n  for name, value in items:\n   if not name.startswith('_'):\n    temp.append('%s=%r' % (name, value))\n  temp.sort()\n  return 'Namespace(%s)' % str.join(', ', temp)\n  \ndict = dict\nlist = list\n\n\n\n\n\nclass Value(object):\n def __init__(self, typecode, value, lock=True):\n  self._typecode = typecode\n  self._value = value\n def _get(self):\n  return self._value\n def _set(self, value):\n  self._value = value\n value = property(_get, _set)\n def __repr__(self):\n  return '<%r(%r, %r)>'%(type(self).__name__,self._typecode,self._value)\n  \ndef Manager():\n return sys.modules[__name__]\n \ndef shutdown():\n pass\n \ndef Pool(processes=None, initializer=None, initargs=()):\n from multiprocessing.pool import ThreadPool\n return ThreadPool(processes, initializer, initargs)\n \nJoinableQueue = Queue\n", 1], "xml.dom.expatbuilder": [".py", "\"\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom xml.dom import xmlbuilder, minidom, Node\nfrom xml.dom import EMPTY_NAMESPACE, EMPTY_PREFIX, XMLNS_NAMESPACE\nfrom xml.parsers import expat\nfrom xml.dom.minidom import _append_child, _set_attribute_node\nfrom xml.dom.NodeFilter import NodeFilter\n\nTEXT_NODE = Node.TEXT_NODE\nCDATA_SECTION_NODE = Node.CDATA_SECTION_NODE\nDOCUMENT_NODE = Node.DOCUMENT_NODE\n\nFILTER_ACCEPT = xmlbuilder.DOMBuilderFilter.FILTER_ACCEPT\nFILTER_REJECT = xmlbuilder.DOMBuilderFilter.FILTER_REJECT\nFILTER_SKIP = xmlbuilder.DOMBuilderFilter.FILTER_SKIP\nFILTER_INTERRUPT = xmlbuilder.DOMBuilderFilter.FILTER_INTERRUPT\n\ntheDOMImplementation = minidom.getDOMImplementation()\n\n\n_typeinfo_map = {\n\"CDATA\": minidom.TypeInfo(None, \"cdata\"),\n\"ENUM\": minidom.TypeInfo(None, \"enumeration\"),\n\"ENTITY\": minidom.TypeInfo(None, \"entity\"),\n\"ENTITIES\": minidom.TypeInfo(None, \"entities\"),\n\"ID\": minidom.TypeInfo(None, \"id\"),\n\"IDREF\": minidom.TypeInfo(None, \"idref\"),\n\"IDREFS\": minidom.TypeInfo(None, \"idrefs\"),\n\"NMTOKEN\": minidom.TypeInfo(None, \"nmtoken\"),\n\"NMTOKENS\": minidom.TypeInfo(None, \"nmtokens\"),\n}\n\nclass ElementInfo(object):\n __slots__ = '_attr_info', '_model', 'tagName'\n \n def __init__(self, tagName, model=None):\n  self.tagName = tagName\n  self._attr_info = []\n  self._model = model\n  \n def __getstate__(self):\n  return self._attr_info, self._model, self.tagName\n  \n def __setstate__(self, state):\n  self._attr_info, self._model, self.tagName = state\n  \n def getAttributeType(self, aname):\n  for info in self._attr_info:\n   if info[1] == aname:\n    t = info[-2]\n    if t[0] == \"(\":\n     return _typeinfo_map[\"ENUM\"]\n    else:\n     return _typeinfo_map[info[-2]]\n  return minidom._no_type\n  \n def getAttributeTypeNS(self, namespaceURI, localName):\n  return minidom._no_type\n  \n def isElementContent(self):\n  if self._model:\n   type = self._model[0]\n   return type not in (expat.model.XML_CTYPE_ANY,\n   expat.model.XML_CTYPE_MIXED)\n  else:\n   return False\n   \n def isEmpty(self):\n  if self._model:\n   return self._model[0] == expat.model.XML_CTYPE_EMPTY\n  else:\n   return False\n   \n def isId(self, aname):\n  for info in self._attr_info:\n   if info[1] == aname:\n    return info[-2] == \"ID\"\n  return False\n  \n def isIdNS(self, euri, ename, auri, aname):\n \n  return self.isId((auri, aname))\n  \ndef _intern(builder, s):\n return builder._intern_setdefault(s, s)\n \ndef _parse_ns_name(builder, name):\n assert ' ' in name\n parts = name.split(' ')\n intern = builder._intern_setdefault\n if len(parts) == 3:\n  uri, localname, prefix = parts\n  prefix = intern(prefix, prefix)\n  qname = \"%s:%s\" % (prefix, localname)\n  qname = intern(qname, qname)\n  localname = intern(localname, localname)\n else:\n  uri, localname = parts\n  prefix = EMPTY_PREFIX\n  qname = localname = intern(localname, localname)\n return intern(uri, uri), localname, prefix, qname\n \n \nclass ExpatBuilder:\n \"\"\n \n def __init__(self, options=None):\n  if options is None:\n   options = xmlbuilder.Options()\n  self._options = options\n  if self._options.filter is not None:\n   self._filter = FilterVisibilityController(self._options.filter)\n  else:\n   self._filter = None\n   \n   \n   self._finish_start_element = id\n  self._parser = None\n  self.reset()\n  \n def createParser(self):\n  \"\"\n  return expat.ParserCreate()\n  \n def getParser(self):\n  \"\"\n  if not self._parser:\n   self._parser = self.createParser()\n   self._intern_setdefault = self._parser.intern.setdefault\n   self._parser.buffer_text = True\n   self._parser.ordered_attributes = True\n   self._parser.specified_attributes = True\n   self.install(self._parser)\n  return self._parser\n  \n def reset(self):\n  \"\"\n  self.document = theDOMImplementation.createDocument(\n  EMPTY_NAMESPACE, None, None)\n  self.curNode = self.document\n  self._elem_info = self.document._elem_info\n  self._cdata = False\n  \n def install(self, parser):\n  \"\"\n  \n  parser.StartDoctypeDeclHandler = self.start_doctype_decl_handler\n  parser.StartElementHandler = self.first_element_handler\n  parser.EndElementHandler = self.end_element_handler\n  parser.ProcessingInstructionHandler = self.pi_handler\n  if self._options.entities:\n   parser.EntityDeclHandler = self.entity_decl_handler\n  parser.NotationDeclHandler = self.notation_decl_handler\n  if self._options.comments:\n   parser.CommentHandler = self.comment_handler\n  if self._options.cdata_sections:\n   parser.StartCdataSectionHandler = self.start_cdata_section_handler\n   parser.EndCdataSectionHandler = self.end_cdata_section_handler\n   parser.CharacterDataHandler = self.character_data_handler_cdata\n  else:\n   parser.CharacterDataHandler = self.character_data_handler\n  parser.ExternalEntityRefHandler = self.external_entity_ref_handler\n  parser.XmlDeclHandler = self.xml_decl_handler\n  parser.ElementDeclHandler = self.element_decl_handler\n  parser.AttlistDeclHandler = self.attlist_decl_handler\n  \n def parseFile(self, file):\n  \"\"\n  parser = self.getParser()\n  first_buffer = True\n  try:\n   while 1:\n    buffer = file.read(16*1024)\n    if not buffer:\n     break\n    parser.Parse(buffer, 0)\n    if first_buffer and self.document.documentElement:\n     self._setup_subset(buffer)\n    first_buffer = False\n   parser.Parse(\"\", True)\n  except ParseEscape:\n   pass\n  doc = self.document\n  self.reset()\n  self._parser = None\n  return doc\n  \n def parseString(self, string):\n  \"\"\n  parser = self.getParser()\n  try:\n   parser.Parse(string, True)\n   self._setup_subset(string)\n  except ParseEscape:\n   pass\n  doc = self.document\n  self.reset()\n  self._parser = None\n  return doc\n  \n def _setup_subset(self, buffer):\n  \"\"\n  if self.document.doctype:\n   extractor = InternalSubsetExtractor()\n   extractor.parseString(buffer)\n   subset = extractor.getSubset()\n   self.document.doctype.internalSubset = subset\n   \n def start_doctype_decl_handler(self, doctypeName, systemId, publicId,\n has_internal_subset):\n  doctype = self.document.implementation.createDocumentType(\n  doctypeName, publicId, systemId)\n  doctype.ownerDocument = self.document\n  _append_child(self.document, doctype)\n  self.document.doctype = doctype\n  if self._filter and self._filter.acceptNode(doctype) == FILTER_REJECT:\n   self.document.doctype = None\n   del self.document.childNodes[-1]\n   doctype = None\n   self._parser.EntityDeclHandler = None\n   self._parser.NotationDeclHandler = None\n  if has_internal_subset:\n   if doctype is not None:\n    doctype.entities._seq = []\n    doctype.notations._seq = []\n   self._parser.CommentHandler = None\n   self._parser.ProcessingInstructionHandler = None\n   self._parser.EndDoctypeDeclHandler = self.end_doctype_decl_handler\n   \n def end_doctype_decl_handler(self):\n  if self._options.comments:\n   self._parser.CommentHandler = self.comment_handler\n  self._parser.ProcessingInstructionHandler = self.pi_handler\n  if not (self._elem_info or self._filter):\n   self._finish_end_element = id\n   \n def pi_handler(self, target, data):\n  node = self.document.createProcessingInstruction(target, data)\n  _append_child(self.curNode, node)\n  if self._filter and self._filter.acceptNode(node) == FILTER_REJECT:\n   self.curNode.removeChild(node)\n   \n def character_data_handler_cdata(self, data):\n  childNodes = self.curNode.childNodes\n  if self._cdata:\n   if ( self._cdata_continue\n   and childNodes[-1].nodeType == CDATA_SECTION_NODE):\n    childNodes[-1].appendData(data)\n    return\n   node = self.document.createCDATASection(data)\n   self._cdata_continue = True\n  elif childNodes and childNodes[-1].nodeType == TEXT_NODE:\n   node = childNodes[-1]\n   value = node.data + data\n   node.data = value\n   return\n  else:\n   node = minidom.Text()\n   node.data = data\n   node.ownerDocument = self.document\n  _append_child(self.curNode, node)\n  \n def character_data_handler(self, data):\n  childNodes = self.curNode.childNodes\n  if childNodes and childNodes[-1].nodeType == TEXT_NODE:\n   node = childNodes[-1]\n   node.data = node.data + data\n   return\n  node = minidom.Text()\n  node.data = node.data + data\n  node.ownerDocument = self.document\n  _append_child(self.curNode, node)\n  \n def entity_decl_handler(self, entityName, is_parameter_entity, value,\n base, systemId, publicId, notationName):\n  if is_parameter_entity:\n  \n   return\n  if not self._options.entities:\n   return\n  node = self.document._create_entity(entityName, publicId,\n  systemId, notationName)\n  if value is not None:\n  \n  \n   child = self.document.createTextNode(value)\n   node.childNodes.append(child)\n  self.document.doctype.entities._seq.append(node)\n  if self._filter and self._filter.acceptNode(node) == FILTER_REJECT:\n   del self.document.doctype.entities._seq[-1]\n   \n def notation_decl_handler(self, notationName, base, systemId, publicId):\n  node = self.document._create_notation(notationName, publicId, systemId)\n  self.document.doctype.notations._seq.append(node)\n  if self._filter and self._filter.acceptNode(node) == FILTER_ACCEPT:\n   del self.document.doctype.notations._seq[-1]\n   \n def comment_handler(self, data):\n  node = self.document.createComment(data)\n  _append_child(self.curNode, node)\n  if self._filter and self._filter.acceptNode(node) == FILTER_REJECT:\n   self.curNode.removeChild(node)\n   \n def start_cdata_section_handler(self):\n  self._cdata = True\n  self._cdata_continue = False\n  \n def end_cdata_section_handler(self):\n  self._cdata = False\n  self._cdata_continue = False\n  \n def external_entity_ref_handler(self, context, base, systemId, publicId):\n  return 1\n  \n def first_element_handler(self, name, attributes):\n  if self._filter is None and not self._elem_info:\n   self._finish_end_element = id\n  self.getParser().StartElementHandler = self.start_element_handler\n  self.start_element_handler(name, attributes)\n  \n def start_element_handler(self, name, attributes):\n  node = self.document.createElement(name)\n  _append_child(self.curNode, node)\n  self.curNode = node\n  \n  if attributes:\n   for i in range(0, len(attributes), 2):\n    a = minidom.Attr(attributes[i], EMPTY_NAMESPACE,\n    None, EMPTY_PREFIX)\n    value = attributes[i+1]\n    a.value = value\n    a.ownerDocument = self.document\n    _set_attribute_node(node, a)\n    \n  if node is not self.document.documentElement:\n   self._finish_start_element(node)\n   \n def _finish_start_element(self, node):\n  if self._filter:\n  \n  \n   if node is self.document.documentElement:\n    return\n   filt = self._filter.startContainer(node)\n   if filt == FILTER_REJECT:\n   \n    Rejecter(self)\n   elif filt == FILTER_SKIP:\n   \n   \n    Skipper(self)\n   else:\n    return\n   self.curNode = node.parentNode\n   node.parentNode.removeChild(node)\n   node.unlink()\n   \n   \n   \n   \n def end_element_handler(self, name):\n  curNode = self.curNode\n  self.curNode = curNode.parentNode\n  self._finish_end_element(curNode)\n  \n def _finish_end_element(self, curNode):\n  info = self._elem_info.get(curNode.tagName)\n  if info:\n   self._handle_white_text_nodes(curNode, info)\n  if self._filter:\n   if curNode is self.document.documentElement:\n    return\n   if self._filter.acceptNode(curNode) == FILTER_REJECT:\n    self.curNode.removeChild(curNode)\n    curNode.unlink()\n    \n def _handle_white_text_nodes(self, node, info):\n  if (self._options.whitespace_in_element_content\n  or not info.isElementContent()):\n   return\n   \n   \n   \n   \n  L = []\n  for child in node.childNodes:\n   if child.nodeType == TEXT_NODE and not child.data.strip():\n    L.append(child)\n    \n    \n  for child in L:\n   node.removeChild(child)\n   \n def element_decl_handler(self, name, model):\n  info = self._elem_info.get(name)\n  if info is None:\n   self._elem_info[name] = ElementInfo(name, model)\n  else:\n   assert info._model is None\n   info._model = model\n   \n def attlist_decl_handler(self, elem, name, type, default, required):\n  info = self._elem_info.get(elem)\n  if info is None:\n   info = ElementInfo(elem)\n   self._elem_info[elem] = info\n  info._attr_info.append(\n  [None, name, None, None, default, 0, type, required])\n  \n def xml_decl_handler(self, version, encoding, standalone):\n  self.document.version = version\n  self.document.encoding = encoding\n  \n  if standalone >= 0:\n   if standalone:\n    self.document.standalone = True\n   else:\n    self.document.standalone = False\n    \n    \n    \n    \n_ALLOWED_FILTER_RETURNS = (FILTER_ACCEPT, FILTER_REJECT, FILTER_SKIP)\n\nclass FilterVisibilityController(object):\n \"\"\n \n __slots__ = 'filter',\n \n def __init__(self, filter):\n  self.filter = filter\n  \n def startContainer(self, node):\n  mask = self._nodetype_mask[node.nodeType]\n  if self.filter.whatToShow & mask:\n   val = self.filter.startContainer(node)\n   if val == FILTER_INTERRUPT:\n    raise ParseEscape\n   if val not in _ALLOWED_FILTER_RETURNS:\n    raise ValueError(\n    \"startContainer() returned illegal value: \" + repr(val))\n   return val\n  else:\n   return FILTER_ACCEPT\n   \n def acceptNode(self, node):\n  mask = self._nodetype_mask[node.nodeType]\n  if self.filter.whatToShow & mask:\n   val = self.filter.acceptNode(node)\n   if val == FILTER_INTERRUPT:\n    raise ParseEscape\n   if val == FILTER_SKIP:\n   \n    parent = node.parentNode\n    for child in node.childNodes[:]:\n     parent.appendChild(child)\n     \n    return FILTER_REJECT\n   if val not in _ALLOWED_FILTER_RETURNS:\n    raise ValueError(\n    \"acceptNode() returned illegal value: \" + repr(val))\n   return val\n  else:\n   return FILTER_ACCEPT\n   \n _nodetype_mask = {\n Node.ELEMENT_NODE: NodeFilter.SHOW_ELEMENT,\n Node.ATTRIBUTE_NODE: NodeFilter.SHOW_ATTRIBUTE,\n Node.TEXT_NODE: NodeFilter.SHOW_TEXT,\n Node.CDATA_SECTION_NODE: NodeFilter.SHOW_CDATA_SECTION,\n Node.ENTITY_REFERENCE_NODE: NodeFilter.SHOW_ENTITY_REFERENCE,\n Node.ENTITY_NODE: NodeFilter.SHOW_ENTITY,\n Node.PROCESSING_INSTRUCTION_NODE: NodeFilter.SHOW_PROCESSING_INSTRUCTION,\n Node.COMMENT_NODE: NodeFilter.SHOW_COMMENT,\n Node.DOCUMENT_NODE: NodeFilter.SHOW_DOCUMENT,\n Node.DOCUMENT_TYPE_NODE: NodeFilter.SHOW_DOCUMENT_TYPE,\n Node.DOCUMENT_FRAGMENT_NODE: NodeFilter.SHOW_DOCUMENT_FRAGMENT,\n Node.NOTATION_NODE: NodeFilter.SHOW_NOTATION,\n }\n \n \nclass FilterCrutch(object):\n __slots__ = '_builder', '_level', '_old_start', '_old_end'\n \n def __init__(self, builder):\n  self._level = 0\n  self._builder = builder\n  parser = builder._parser\n  self._old_start = parser.StartElementHandler\n  self._old_end = parser.EndElementHandler\n  parser.StartElementHandler = self.start_element_handler\n  parser.EndElementHandler = self.end_element_handler\n  \nclass Rejecter(FilterCrutch):\n __slots__ = ()\n \n def __init__(self, builder):\n  FilterCrutch.__init__(self, builder)\n  parser = builder._parser\n  for name in (\"ProcessingInstructionHandler\",\n  \"CommentHandler\",\n  \"CharacterDataHandler\",\n  \"StartCdataSectionHandler\",\n  \"EndCdataSectionHandler\",\n  \"ExternalEntityRefHandler\",\n  ):\n   setattr(parser, name, None)\n   \n def start_element_handler(self, *args):\n  self._level = self._level + 1\n  \n def end_element_handler(self, *args):\n  if self._level == 0:\n  \n   parser = self._builder._parser\n   self._builder.install(parser)\n   parser.StartElementHandler = self._old_start\n   parser.EndElementHandler = self._old_end\n  else:\n   self._level = self._level - 1\n   \nclass Skipper(FilterCrutch):\n __slots__ = ()\n \n def start_element_handler(self, *args):\n  node = self._builder.curNode\n  self._old_start(*args)\n  if self._builder.curNode is not node:\n   self._level = self._level + 1\n   \n def end_element_handler(self, *args):\n  if self._level == 0:\n  \n  \n   self._builder._parser.StartElementHandler = self._old_start\n   self._builder._parser.EndElementHandler = self._old_end\n   self._builder = None\n  else:\n   self._level = self._level - 1\n   self._old_end(*args)\n   \n   \n   \n   \n   \n_FRAGMENT_BUILDER_INTERNAL_SYSTEM_ID = \"http://xml.python.org/entities/fragment-builder/internal\"\n\n_FRAGMENT_BUILDER_TEMPLATE = (\n'''\\\n<!DOCTYPE wrapper\n  %%s [\n  <!ENTITY fragment-builder-internal\n    SYSTEM \"%s\">\n%%s\n]>\n<wrapper %%s\n>&fragment-builder-internal;</wrapper>'''\n% _FRAGMENT_BUILDER_INTERNAL_SYSTEM_ID)\n\n\nclass FragmentBuilder(ExpatBuilder):\n \"\"\n \n def __init__(self, context, options=None):\n  if context.nodeType == DOCUMENT_NODE:\n   self.originalDocument = context\n   self.context = context\n  else:\n   self.originalDocument = context.ownerDocument\n   self.context = context\n  ExpatBuilder.__init__(self, options)\n  \n def reset(self):\n  ExpatBuilder.reset(self)\n  self.fragment = None\n  \n def parseFile(self, file):\n  \"\"\n  return self.parseString(file.read())\n  \n def parseString(self, string):\n  \"\"\n  self._source = string\n  parser = self.getParser()\n  doctype = self.originalDocument.doctype\n  ident = \"\"\n  if doctype:\n   subset = doctype.internalSubset or self._getDeclarations()\n   if doctype.publicId:\n    ident = ('PUBLIC \"%s\" \"%s\"'\n    % (doctype.publicId, doctype.systemId))\n   elif doctype.systemId:\n    ident = 'SYSTEM \"%s\"' % doctype.systemId\n  else:\n   subset = \"\"\n  nsattrs = self._getNSattrs() \n  document = _FRAGMENT_BUILDER_TEMPLATE % (ident, subset, nsattrs)\n  try:\n   parser.Parse(document, 1)\n  except:\n   self.reset()\n   raise\n  fragment = self.fragment\n  self.reset()\n  \n  return fragment\n  \n def _getDeclarations(self):\n  \"\"\n  doctype = self.context.ownerDocument.doctype\n  s = \"\"\n  if doctype:\n   for i in range(doctype.notations.length):\n    notation = doctype.notations.item(i)\n    if s:\n     s = s + \"\\n  \"\n    s = \"%s<!NOTATION %s\" % (s, notation.nodeName)\n    if notation.publicId:\n     s = '%s PUBLIC \"%s\"\\n             \"%s\">' % (s, notation.publicId, notation.systemId)\n    else:\n     s = '%s SYSTEM \"%s\">' % (s, notation.systemId)\n   for i in range(doctype.entities.length):\n    entity = doctype.entities.item(i)\n    if s:\n     s = s + \"\\n  \"\n    s = \"%s<!ENTITY %s\" % (s, entity.nodeName)\n    if entity.publicId:\n     s = '%s PUBLIC \"%s\"\\n             \"%s\"' % (s, entity.publicId, entity.systemId)\n    elif entity.systemId:\n     s = '%s SYSTEM \"%s\"' % (s, entity.systemId)\n    else:\n     s = '%s \"%s\"' % (s, entity.firstChild.data)\n    if entity.notationName:\n     s = \"%s NOTATION %s\" % (s, entity.notationName)\n    s = s + \">\"\n  return s\n  \n def _getNSattrs(self):\n  return \"\"\n  \n def external_entity_ref_handler(self, context, base, systemId, publicId):\n  if systemId == _FRAGMENT_BUILDER_INTERNAL_SYSTEM_ID:\n  \n  \n   old_document = self.document\n   old_cur_node = self.curNode\n   parser = self._parser.ExternalEntityParserCreate(context)\n   \n   self.document = self.originalDocument\n   self.fragment = self.document.createDocumentFragment()\n   self.curNode = self.fragment\n   try:\n    parser.Parse(self._source, 1)\n   finally:\n    self.curNode = old_cur_node\n    self.document = old_document\n    self._source = None\n   return -1\n  else:\n   return ExpatBuilder.external_entity_ref_handler(\n   self, context, base, systemId, publicId)\n   \n   \nclass Namespaces:\n \"\"\n \n def _initNamespaces(self):\n \n \n  self._ns_ordered_prefixes = []\n  \n def createParser(self):\n  \"\"\n  parser = expat.ParserCreate(namespace_separator=\" \")\n  parser.namespace_prefixes = True\n  return parser\n  \n def install(self, parser):\n  \"\"\n  ExpatBuilder.install(self, parser)\n  if self._options.namespace_declarations:\n   parser.StartNamespaceDeclHandler = (\n   self.start_namespace_decl_handler)\n   \n def start_namespace_decl_handler(self, prefix, uri):\n  \"\"\n  self._ns_ordered_prefixes.append((prefix, uri))\n  \n def start_element_handler(self, name, attributes):\n  if ' ' in name:\n   uri, localname, prefix, qname = _parse_ns_name(self, name)\n  else:\n   uri = EMPTY_NAMESPACE\n   qname = name\n   localname = None\n   prefix = EMPTY_PREFIX\n  node = minidom.Element(qname, uri, prefix, localname)\n  node.ownerDocument = self.document\n  _append_child(self.curNode, node)\n  self.curNode = node\n  \n  if self._ns_ordered_prefixes:\n   for prefix, uri in self._ns_ordered_prefixes:\n    if prefix:\n     a = minidom.Attr(_intern(self, 'xmlns:' + prefix),\n     XMLNS_NAMESPACE, prefix, \"xmlns\")\n    else:\n     a = minidom.Attr(\"xmlns\", XMLNS_NAMESPACE,\n     \"xmlns\", EMPTY_PREFIX)\n    a.value = uri\n    a.ownerDocument = self.document\n    _set_attribute_node(node, a)\n   del self._ns_ordered_prefixes[:]\n   \n  if attributes:\n   node._ensure_attributes()\n   _attrs = node._attrs\n   _attrsNS = node._attrsNS\n   for i in range(0, len(attributes), 2):\n    aname = attributes[i]\n    value = attributes[i+1]\n    if ' ' in aname:\n     uri, localname, prefix, qname = _parse_ns_name(self, aname)\n     a = minidom.Attr(qname, uri, localname, prefix)\n     _attrs[qname] = a\n     _attrsNS[(uri, localname)] = a\n    else:\n     a = minidom.Attr(aname, EMPTY_NAMESPACE,\n     aname, EMPTY_PREFIX)\n     _attrs[aname] = a\n     _attrsNS[(EMPTY_NAMESPACE, aname)] = a\n    a.ownerDocument = self.document\n    a.value = value\n    a.ownerElement = node\n    \n if __debug__:\n \n \n \n \n \n  def end_element_handler(self, name):\n   curNode = self.curNode\n   if ' ' in name:\n    uri, localname, prefix, qname = _parse_ns_name(self, name)\n    assert (curNode.namespaceURI == uri\n    and curNode.localName == localname\n    and curNode.prefix == prefix), \"element stack messed up! (namespace)\"\n   else:\n    assert curNode.nodeName == name, \"element stack messed up - bad nodeName\"\n    assert curNode.namespaceURI == EMPTY_NAMESPACE, \"element stack messed up - bad namespaceURI\"\n   self.curNode = curNode.parentNode\n   self._finish_end_element(curNode)\n   \n   \nclass ExpatBuilderNS(Namespaces, ExpatBuilder):\n \"\"\n \n def reset(self):\n  ExpatBuilder.reset(self)\n  self._initNamespaces()\n  \n  \nclass FragmentBuilderNS(Namespaces, FragmentBuilder):\n \"\"\n \n def reset(self):\n  FragmentBuilder.reset(self)\n  self._initNamespaces()\n  \n def _getNSattrs(self):\n  \"\"\n  \n  \n  \n  \n  \n  attrs = \"\"\n  context = self.context\n  L = []\n  while context:\n   if hasattr(context, '_ns_prefix_uri'):\n    for prefix, uri in context._ns_prefix_uri.items():\n    \n     if prefix in L:\n      continue\n     L.append(prefix)\n     if prefix:\n      declname = \"xmlns:\" + prefix\n     else:\n      declname = \"xmlns\"\n     if attrs:\n      attrs = \"%s\\n    %s='%s'\" % (attrs, declname, uri)\n     else:\n      attrs = \" %s='%s'\" % (declname, uri)\n   context = context.parentNode\n  return attrs\n  \n  \nclass ParseEscape(Exception):\n \"\"\n pass\n \nclass InternalSubsetExtractor(ExpatBuilder):\n \"\"\n \n subset = None\n \n def getSubset(self):\n  \"\"\n  return self.subset\n  \n def parseFile(self, file):\n  try:\n   ExpatBuilder.parseFile(self, file)\n  except ParseEscape:\n   pass\n   \n def parseString(self, string):\n  try:\n   ExpatBuilder.parseString(self, string)\n  except ParseEscape:\n   pass\n   \n def install(self, parser):\n  parser.StartDoctypeDeclHandler = self.start_doctype_decl_handler\n  parser.StartElementHandler = self.start_element_handler\n  \n def start_doctype_decl_handler(self, name, publicId, systemId,\n has_internal_subset):\n  if has_internal_subset:\n   parser = self.getParser()\n   self.subset = []\n   parser.DefaultHandler = self.subset.append\n   parser.EndDoctypeDeclHandler = self.end_doctype_decl_handler\n  else:\n   raise ParseEscape()\n   \n def end_doctype_decl_handler(self):\n  s = ''.join(self.subset).replace('\\r\\n', '\\n').replace('\\r', '\\n')\n  self.subset = s\n  raise ParseEscape()\n  \n def start_element_handler(self, name, attrs):\n  raise ParseEscape()\n  \n  \ndef parse(file, namespaces=True):\n \"\"\n if namespaces:\n  builder = ExpatBuilderNS()\n else:\n  builder = ExpatBuilder()\n  \n if isinstance(file, str):\n  fp = open(file, 'rb')\n  try:\n   result = builder.parseFile(fp)\n  finally:\n   fp.close()\n else:\n  result = builder.parseFile(file)\n return result\n \n \ndef parseString(string, namespaces=True):\n \"\"\n if namespaces:\n  builder = ExpatBuilderNS()\n else:\n  builder = ExpatBuilder()\n return builder.parseString(string)\n \n \ndef parseFragment(file, context, namespaces=True):\n \"\"\n if namespaces:\n  builder = FragmentBuilderNS(context)\n else:\n  builder = FragmentBuilder(context)\n  \n if isinstance(file, str):\n  fp = open(file, 'rb')\n  try:\n   result = builder.parseFile(fp)\n  finally:\n   fp.close()\n else:\n  result = builder.parseFile(file)\n return result\n \n \ndef parseFragmentString(string, context, namespaces=True):\n \"\"\n if namespaces:\n  builder = FragmentBuilderNS(context)\n else:\n  builder = FragmentBuilder(context)\n return builder.parseString(string)\n \n \ndef makeBuilder(options):\n \"\"\n if options.namespaces:\n  return ExpatBuilderNS(options)\n else:\n  return ExpatBuilder(options)\n"], "unittest.test.testmock.testmock": [".py", "import copy\nimport sys\n\nimport unittest\nfrom unittest.test.testmock.support import is_instance\nfrom unittest import mock\nfrom unittest.mock import (\ncall, DEFAULT, patch, sentinel,\nMagicMock, Mock, NonCallableMock,\nNonCallableMagicMock, _CallList,\ncreate_autospec\n)\n\n\nclass Iter(object):\n def __init__(self):\n  self.thing = iter(['this', 'is', 'an', 'iter'])\n  \n def __iter__(self):\n  return self\n  \n def next(self):\n  return next(self.thing)\n  \n __next__ = next\n \n \n \nclass MockTest(unittest.TestCase):\n\n def test_all(self):\n \n \n \n  exec(\"from unittest.mock import *\")\n  \n  \n def test_constructor(self):\n  mock = Mock()\n  \n  self.assertFalse(mock.called, \"called not initialised correctly\")\n  self.assertEqual(mock.call_count, 0,\n  \"call_count not initialised correctly\")\n  self.assertTrue(is_instance(mock.return_value, Mock),\n  \"return_value not initialised correctly\")\n  \n  self.assertEqual(mock.call_args, None,\n  \"call_args not initialised correctly\")\n  self.assertEqual(mock.call_args_list, [],\n  \"call_args_list not initialised correctly\")\n  self.assertEqual(mock.method_calls, [],\n  \"method_calls not initialised correctly\")\n  \n  \n  self.assertFalse('_items' in mock.__dict__,\n  \"default mock should not have '_items' attribute\")\n  \n  self.assertIsNone(mock._mock_parent,\n  \"parent not initialised correctly\")\n  self.assertIsNone(mock._mock_methods,\n  \"methods not initialised correctly\")\n  self.assertEqual(mock._mock_children, {},\n  \"children not initialised incorrectly\")\n  \n  \n def test_return_value_in_constructor(self):\n  mock = Mock(return_value=None)\n  self.assertIsNone(mock.return_value,\n  \"return value in constructor not honoured\")\n  \n  \n def test_repr(self):\n  mock = Mock(name='foo')\n  self.assertIn('foo', repr(mock))\n  self.assertIn(\"'%s'\" % id(mock), repr(mock))\n  \n  mocks = [(Mock(), 'mock'), (Mock(name='bar'), 'bar')]\n  for mock, name in mocks:\n   self.assertIn('%s.bar' % name, repr(mock.bar))\n   self.assertIn('%s.foo()' % name, repr(mock.foo()))\n   self.assertIn('%s.foo().bing' % name, repr(mock.foo().bing))\n   self.assertIn('%s()' % name, repr(mock()))\n   self.assertIn('%s()()' % name, repr(mock()()))\n   self.assertIn('%s()().foo.bar.baz().bing' % name,\n   repr(mock()().foo.bar.baz().bing))\n   \n   \n def test_repr_with_spec(self):\n  class X(object):\n   pass\n   \n  mock = Mock(spec=X)\n  self.assertIn(\" spec='X' \", repr(mock))\n  \n  mock = Mock(spec=X())\n  self.assertIn(\" spec='X' \", repr(mock))\n  \n  mock = Mock(spec_set=X)\n  self.assertIn(\" spec_set='X' \", repr(mock))\n  \n  mock = Mock(spec_set=X())\n  self.assertIn(\" spec_set='X' \", repr(mock))\n  \n  mock = Mock(spec=X, name='foo')\n  self.assertIn(\" spec='X' \", repr(mock))\n  self.assertIn(\" name='foo' \", repr(mock))\n  \n  mock = Mock(name='foo')\n  self.assertNotIn(\"spec\", repr(mock))\n  \n  mock = Mock()\n  self.assertNotIn(\"spec\", repr(mock))\n  \n  mock = Mock(spec=['foo'])\n  self.assertNotIn(\"spec\", repr(mock))\n  \n  \n def test_side_effect(self):\n  mock = Mock()\n  \n  def effect(*args, **kwargs):\n   raise SystemError('kablooie')\n   \n  mock.side_effect = effect\n  self.assertRaises(SystemError, mock, 1, 2, fish=3)\n  mock.assert_called_with(1, 2, fish=3)\n  \n  results = [1, 2, 3]\n  def effect():\n   return results.pop()\n  mock.side_effect = effect\n  \n  self.assertEqual([mock(), mock(), mock()], [3, 2, 1],\n  \"side effect not used correctly\")\n  \n  mock = Mock(side_effect=sentinel.SideEffect)\n  self.assertEqual(mock.side_effect, sentinel.SideEffect,\n  \"side effect in constructor not used\")\n  \n  def side_effect():\n   return DEFAULT\n  mock = Mock(side_effect=side_effect, return_value=sentinel.RETURN)\n  self.assertEqual(mock(), sentinel.RETURN)\n  \n  \n @unittest.skipUnless('java' in sys.platform,\n 'This test only applies to Jython')\n def test_java_exception_side_effect(self):\n  import java\n  mock = Mock(side_effect=java.lang.RuntimeException(\"Boom!\"))\n  \n  \n  try:\n   mock(1, 2, fish=3)\n  except java.lang.RuntimeException:\n   pass\n  else:\n   self.fail('java exception not raised')\n  mock.assert_called_with(1,2, fish=3)\n  \n  \n def test_reset_mock(self):\n  parent = Mock()\n  spec = [\"something\"]\n  mock = Mock(name=\"child\", parent=parent, spec=spec)\n  mock(sentinel.Something, something=sentinel.SomethingElse)\n  something = mock.something\n  mock.something()\n  mock.side_effect = sentinel.SideEffect\n  return_value = mock.return_value\n  return_value()\n  \n  mock.reset_mock()\n  \n  self.assertEqual(mock._mock_name, \"child\",\n  \"name incorrectly reset\")\n  self.assertEqual(mock._mock_parent, parent,\n  \"parent incorrectly reset\")\n  self.assertEqual(mock._mock_methods, spec,\n  \"methods incorrectly reset\")\n  \n  self.assertFalse(mock.called, \"called not reset\")\n  self.assertEqual(mock.call_count, 0, \"call_count not reset\")\n  self.assertEqual(mock.call_args, None, \"call_args not reset\")\n  self.assertEqual(mock.call_args_list, [], \"call_args_list not reset\")\n  self.assertEqual(mock.method_calls, [],\n  \"method_calls not initialised correctly: %r != %r\" %\n  (mock.method_calls, []))\n  self.assertEqual(mock.mock_calls, [])\n  \n  self.assertEqual(mock.side_effect, sentinel.SideEffect,\n  \"side_effect incorrectly reset\")\n  self.assertEqual(mock.return_value, return_value,\n  \"return_value incorrectly reset\")\n  self.assertFalse(return_value.called, \"return value mock not reset\")\n  self.assertEqual(mock._mock_children, {'something': something},\n  \"children reset incorrectly\")\n  self.assertEqual(mock.something, something,\n  \"children incorrectly cleared\")\n  self.assertFalse(mock.something.called, \"child not reset\")\n  \n  \n def test_reset_mock_recursion(self):\n  mock = Mock()\n  mock.return_value = mock\n  \n  \n  mock.reset_mock()\n  \n  \n def test_call(self):\n  mock = Mock()\n  self.assertTrue(is_instance(mock.return_value, Mock),\n  \"Default return_value should be a Mock\")\n  \n  result = mock()\n  self.assertEqual(mock(), result,\n  \"different result from consecutive calls\")\n  mock.reset_mock()\n  \n  ret_val = mock(sentinel.Arg)\n  self.assertTrue(mock.called, \"called not set\")\n  self.assertEqual(mock.call_count, 1, \"call_count incoreect\")\n  self.assertEqual(mock.call_args, ((sentinel.Arg,), {}),\n  \"call_args not set\")\n  self.assertEqual(mock.call_args_list, [((sentinel.Arg,), {})],\n  \"call_args_list not initialised correctly\")\n  \n  mock.return_value = sentinel.ReturnValue\n  ret_val = mock(sentinel.Arg, key=sentinel.KeyArg)\n  self.assertEqual(ret_val, sentinel.ReturnValue,\n  \"incorrect return value\")\n  \n  self.assertEqual(mock.call_count, 2, \"call_count incorrect\")\n  self.assertEqual(mock.call_args,\n  ((sentinel.Arg,), {'key': sentinel.KeyArg}),\n  \"call_args not set\")\n  self.assertEqual(mock.call_args_list, [\n  ((sentinel.Arg,), {}),\n  ((sentinel.Arg,), {'key': sentinel.KeyArg})\n  ],\n  \"call_args_list not set\")\n  \n  \n def test_call_args_comparison(self):\n  mock = Mock()\n  mock()\n  mock(sentinel.Arg)\n  mock(kw=sentinel.Kwarg)\n  mock(sentinel.Arg, kw=sentinel.Kwarg)\n  self.assertEqual(mock.call_args_list, [\n  (),\n  ((sentinel.Arg,),),\n  ({\"kw\": sentinel.Kwarg},),\n  ((sentinel.Arg,), {\"kw\": sentinel.Kwarg})\n  ])\n  self.assertEqual(mock.call_args,\n  ((sentinel.Arg,), {\"kw\": sentinel.Kwarg}))\n  \n  \n def test_assert_called_with(self):\n  mock = Mock()\n  mock()\n  \n  \n  mock.assert_called_with()\n  self.assertRaises(AssertionError, mock.assert_called_with, 1)\n  \n  mock.reset_mock()\n  self.assertRaises(AssertionError, mock.assert_called_with)\n  \n  mock(1, 2, 3, a='fish', b='nothing')\n  mock.assert_called_with(1, 2, 3, a='fish', b='nothing')\n  \n  \n def test_assert_called_once_with(self):\n  mock = Mock()\n  mock()\n  \n  \n  mock.assert_called_once_with()\n  \n  mock()\n  self.assertRaises(AssertionError, mock.assert_called_once_with)\n  \n  mock.reset_mock()\n  self.assertRaises(AssertionError, mock.assert_called_once_with)\n  \n  mock('foo', 'bar', baz=2)\n  mock.assert_called_once_with('foo', 'bar', baz=2)\n  \n  mock.reset_mock()\n  mock('foo', 'bar', baz=2)\n  self.assertRaises(\n  AssertionError,\n  lambda: mock.assert_called_once_with('bob', 'bar', baz=2)\n  )\n  \n  \n def test_attribute_access_returns_mocks(self):\n  mock = Mock()\n  something = mock.something\n  self.assertTrue(is_instance(something, Mock), \"attribute isn't a mock\")\n  self.assertEqual(mock.something, something,\n  \"different attributes returned for same name\")\n  \n  \n  mock = Mock()\n  mock.something.return_value = 3\n  \n  self.assertEqual(mock.something(), 3, \"method returned wrong value\")\n  self.assertTrue(mock.something.called,\n  \"method didn't record being called\")\n  \n  \n def test_attributes_have_name_and_parent_set(self):\n  mock = Mock()\n  something = mock.something\n  \n  self.assertEqual(something._mock_name, \"something\",\n  \"attribute name not set correctly\")\n  self.assertEqual(something._mock_parent, mock,\n  \"attribute parent not set correctly\")\n  \n  \n def test_method_calls_recorded(self):\n  mock = Mock()\n  mock.something(3, fish=None)\n  mock.something_else.something(6, cake=sentinel.Cake)\n  \n  self.assertEqual(mock.something_else.method_calls,\n  [(\"something\", (6,), {'cake': sentinel.Cake})],\n  \"method calls not recorded correctly\")\n  self.assertEqual(mock.method_calls, [\n  (\"something\", (3,), {'fish': None}),\n  (\"something_else.something\", (6,), {'cake': sentinel.Cake})\n  ],\n  \"method calls not recorded correctly\")\n  \n  \n def test_method_calls_compare_easily(self):\n  mock = Mock()\n  mock.something()\n  self.assertEqual(mock.method_calls, [('something',)])\n  self.assertEqual(mock.method_calls, [('something', (), {})])\n  \n  mock = Mock()\n  mock.something('different')\n  self.assertEqual(mock.method_calls, [('something', ('different',))])\n  self.assertEqual(mock.method_calls,\n  [('something', ('different',), {})])\n  \n  mock = Mock()\n  mock.something(x=1)\n  self.assertEqual(mock.method_calls, [('something', {'x': 1})])\n  self.assertEqual(mock.method_calls, [('something', (), {'x': 1})])\n  \n  mock = Mock()\n  mock.something('different', some='more')\n  self.assertEqual(mock.method_calls, [\n  ('something', ('different',), {'some': 'more'})\n  ])\n  \n  \n def test_only_allowed_methods_exist(self):\n  for spec in ['something'], ('something',):\n   for arg in 'spec', 'spec_set':\n    mock = Mock(**{arg: spec})\n    \n    \n    mock.something\n    self.assertRaisesRegex(\n    AttributeError,\n    \"Mock object has no attribute 'something_else'\",\n    getattr, mock, 'something_else'\n    )\n    \n    \n def test_from_spec(self):\n  class Something(object):\n   x = 3\n   __something__ = None\n   def y(self):\n    pass\n    \n  def test_attributes(mock):\n  \n   mock.x\n   mock.y\n   mock.__something__\n   self.assertRaisesRegex(\n   AttributeError,\n   \"Mock object has no attribute 'z'\",\n   getattr, mock, 'z'\n   )\n   self.assertRaisesRegex(\n   AttributeError,\n   \"Mock object has no attribute '__foobar__'\",\n   getattr, mock, '__foobar__'\n   )\n   \n  test_attributes(Mock(spec=Something))\n  test_attributes(Mock(spec=Something()))\n  \n  \n def test_wraps_calls(self):\n  real = Mock()\n  \n  mock = Mock(wraps=real)\n  self.assertEqual(mock(), real())\n  \n  real.reset_mock()\n  \n  mock(1, 2, fish=3)\n  real.assert_called_with(1, 2, fish=3)\n  \n  \n def test_wraps_call_with_nondefault_return_value(self):\n  real = Mock()\n  \n  mock = Mock(wraps=real)\n  mock.return_value = 3\n  \n  self.assertEqual(mock(), 3)\n  self.assertFalse(real.called)\n  \n  \n def test_wraps_attributes(self):\n  class Real(object):\n   attribute = Mock()\n   \n  real = Real()\n  \n  mock = Mock(wraps=real)\n  self.assertEqual(mock.attribute(), real.attribute())\n  self.assertRaises(AttributeError, lambda: mock.fish)\n  \n  self.assertNotEqual(mock.attribute, real.attribute)\n  result = mock.attribute.frog(1, 2, fish=3)\n  Real.attribute.frog.assert_called_with(1, 2, fish=3)\n  self.assertEqual(result, Real.attribute.frog())\n  \n  \n def test_exceptional_side_effect(self):\n  mock = Mock(side_effect=AttributeError)\n  self.assertRaises(AttributeError, mock)\n  \n  mock = Mock(side_effect=AttributeError('foo'))\n  self.assertRaises(AttributeError, mock)\n  \n  \n def test_baseexceptional_side_effect(self):\n  mock = Mock(side_effect=KeyboardInterrupt)\n  self.assertRaises(KeyboardInterrupt, mock)\n  \n  mock = Mock(side_effect=KeyboardInterrupt('foo'))\n  self.assertRaises(KeyboardInterrupt, mock)\n  \n  \n def test_assert_called_with_message(self):\n  mock = Mock()\n  self.assertRaisesRegex(AssertionError, 'Not called',\n  mock.assert_called_with)\n  \n  \n def test__name__(self):\n  mock = Mock()\n  self.assertRaises(AttributeError, lambda: mock.__name__)\n  \n  mock.__name__ = 'foo'\n  self.assertEqual(mock.__name__, 'foo')\n  \n  \n def test_spec_list_subclass(self):\n  class Sub(list):\n   pass\n  mock = Mock(spec=Sub(['foo']))\n  \n  mock.append(3)\n  mock.append.assert_called_with(3)\n  self.assertRaises(AttributeError, getattr, mock, 'foo')\n  \n  \n def test_spec_class(self):\n  class X(object):\n   pass\n   \n  mock = Mock(spec=X)\n  self.assertTrue(isinstance(mock, X))\n  \n  mock = Mock(spec=X())\n  self.assertTrue(isinstance(mock, X))\n  \n  self.assertIs(mock.__class__, X)\n  self.assertEqual(Mock().__class__.__name__, 'Mock')\n  \n  mock = Mock(spec_set=X)\n  self.assertTrue(isinstance(mock, X))\n  \n  mock = Mock(spec_set=X())\n  self.assertTrue(isinstance(mock, X))\n  \n  \n def test_setting_attribute_with_spec_set(self):\n  class X(object):\n   y = 3\n   \n  mock = Mock(spec=X)\n  mock.x = 'foo'\n  \n  mock = Mock(spec_set=X)\n  def set_attr():\n   mock.x = 'foo'\n   \n  mock.y = 'foo'\n  self.assertRaises(AttributeError, set_attr)\n  \n  \n def test_copy(self):\n  current = sys.getrecursionlimit()\n  self.addCleanup(sys.setrecursionlimit, current)\n  \n  \n  sys.setrecursionlimit(int(10e8))\n  \n  copy.copy(Mock())\n  \n  \n def test_subclass_with_properties(self):\n  class SubClass(Mock):\n   def _get(self):\n    return 3\n   def _set(self, value):\n    raise NameError('strange error')\n   some_attribute = property(_get, _set)\n   \n  s = SubClass(spec_set=SubClass)\n  self.assertEqual(s.some_attribute, 3)\n  \n  def test():\n   s.some_attribute = 3\n  self.assertRaises(NameError, test)\n  \n  def test():\n   s.foo = 'bar'\n  self.assertRaises(AttributeError, test)\n  \n  \n def test_setting_call(self):\n  mock = Mock()\n  def __call__(self, a):\n   return self._mock_call(a)\n   \n  type(mock).__call__ = __call__\n  mock('one')\n  mock.assert_called_with('one')\n  \n  self.assertRaises(TypeError, mock, 'one', 'two')\n  \n  \n def test_dir(self):\n  mock = Mock()\n  attrs = set(dir(mock))\n  type_attrs = set([m for m in dir(Mock) if not m.startswith('_')])\n  \n  \n  self.assertEqual(set(), type_attrs - attrs)\n  \n  \n  mock.a, mock.b\n  self.assertIn('a', dir(mock))\n  self.assertIn('b', dir(mock))\n  \n  \n  mock.c = mock.d = None\n  self.assertIn('c', dir(mock))\n  self.assertIn('d', dir(mock))\n  \n  \n  mock.__iter__ = lambda s: iter([])\n  self.assertIn('__iter__', dir(mock))\n  \n  \n def test_dir_from_spec(self):\n  mock = Mock(spec=unittest.TestCase)\n  testcase_attrs = set(dir(unittest.TestCase))\n  attrs = set(dir(mock))\n  \n  \n  self.assertEqual(set(), testcase_attrs - attrs)\n  \n  \n  mock.version = 3\n  self.assertEqual(dir(mock).count('version'), 1)\n  \n  \n def test_filter_dir(self):\n  patcher = patch.object(mock, 'FILTER_DIR', False)\n  patcher.start()\n  try:\n   attrs = set(dir(Mock()))\n   type_attrs = set(dir(Mock))\n   \n   \n   self.assertEqual(set(), type_attrs - attrs)\n  finally:\n   patcher.stop()\n   \n   \n def test_configure_mock(self):\n  mock = Mock(foo='bar')\n  self.assertEqual(mock.foo, 'bar')\n  \n  mock = MagicMock(foo='bar')\n  self.assertEqual(mock.foo, 'bar')\n  \n  kwargs = {'side_effect': KeyError, 'foo.bar.return_value': 33,\n  'foo': MagicMock()}\n  mock = Mock(**kwargs)\n  self.assertRaises(KeyError, mock)\n  self.assertEqual(mock.foo.bar(), 33)\n  self.assertIsInstance(mock.foo, MagicMock)\n  \n  mock = Mock()\n  mock.configure_mock(**kwargs)\n  self.assertRaises(KeyError, mock)\n  self.assertEqual(mock.foo.bar(), 33)\n  self.assertIsInstance(mock.foo, MagicMock)\n  \n  \n def assertRaisesWithMsg(self, exception, message, func, *args, **kwargs):\n \n  try:\n   func(*args, **kwargs)\n  except:\n   instance = sys.exc_info()[1]\n   self.assertIsInstance(instance, exception)\n  else:\n   self.fail('Exception %r not raised' % (exception,))\n   \n  msg = str(instance)\n  self.assertEqual(msg, message)\n  \n  \n def test_assert_called_with_failure_message(self):\n  mock = NonCallableMock()\n  \n  expected = \"mock(1, '2', 3, bar='foo')\"\n  message = 'Expected call: %s\\nNot called'\n  self.assertRaisesWithMsg(\n  AssertionError, message % (expected,),\n  mock.assert_called_with, 1, '2', 3, bar='foo'\n  )\n  \n  mock.foo(1, '2', 3, foo='foo')\n  \n  \n  asserters = [\n  mock.foo.assert_called_with, mock.foo.assert_called_once_with\n  ]\n  for meth in asserters:\n   actual = \"foo(1, '2', 3, foo='foo')\"\n   expected = \"foo(1, '2', 3, bar='foo')\"\n   message = 'Expected call: %s\\nActual call: %s'\n   self.assertRaisesWithMsg(\n   AssertionError, message % (expected, actual),\n   meth, 1, '2', 3, bar='foo'\n   )\n   \n   \n  for meth in asserters:\n   actual = \"foo(1, '2', 3, foo='foo')\"\n   expected = \"foo(bar='foo')\"\n   message = 'Expected call: %s\\nActual call: %s'\n   self.assertRaisesWithMsg(\n   AssertionError, message % (expected, actual),\n   meth, bar='foo'\n   )\n   \n   \n  for meth in asserters:\n   actual = \"foo(1, '2', 3, foo='foo')\"\n   expected = \"foo(1, 2, 3)\"\n   message = 'Expected call: %s\\nActual call: %s'\n   self.assertRaisesWithMsg(\n   AssertionError, message % (expected, actual),\n   meth, 1, 2, 3\n   )\n   \n   \n  for meth in asserters:\n   actual = \"foo(1, '2', 3, foo='foo')\"\n   expected = \"foo()\"\n   message = 'Expected call: %s\\nActual call: %s'\n   self.assertRaisesWithMsg(\n   AssertionError, message % (expected, actual), meth\n   )\n   \n   \n def test_mock_calls(self):\n  mock = MagicMock()\n  \n  \n  \n  self.assertIs(mock.mock_calls == [], True)\n  \n  mock = MagicMock()\n  mock()\n  expected = [('', (), {})]\n  self.assertEqual(mock.mock_calls, expected)\n  \n  mock.foo()\n  expected.append(call.foo())\n  self.assertEqual(mock.mock_calls, expected)\n  \n  self.assertEqual(mock.foo.mock_calls, [('', (), {})])\n  \n  mock = MagicMock()\n  mock().foo(1, 2, 3, a=4, b=5)\n  expected = [\n  ('', (), {}), ('().foo', (1, 2, 3), dict(a=4, b=5))\n  ]\n  self.assertEqual(mock.mock_calls, expected)\n  self.assertEqual(mock.return_value.foo.mock_calls,\n  [('', (1, 2, 3), dict(a=4, b=5))])\n  self.assertEqual(mock.return_value.mock_calls,\n  [('foo', (1, 2, 3), dict(a=4, b=5))])\n  \n  mock = MagicMock()\n  mock().foo.bar().baz()\n  expected = [\n  ('', (), {}), ('().foo.bar', (), {}),\n  ('().foo.bar().baz', (), {})\n  ]\n  self.assertEqual(mock.mock_calls, expected)\n  self.assertEqual(mock().mock_calls,\n  call.foo.bar().baz().call_list())\n  \n  for kwargs in dict(), dict(name='bar'):\n   mock = MagicMock(**kwargs)\n   int(mock.foo)\n   expected = [('foo.__int__', (), {})]\n   self.assertEqual(mock.mock_calls, expected)\n   \n   mock = MagicMock(**kwargs)\n   mock.a()()\n   expected = [('a', (), {}), ('a()', (), {})]\n   self.assertEqual(mock.mock_calls, expected)\n   self.assertEqual(mock.a().mock_calls, [call()])\n   \n   mock = MagicMock(**kwargs)\n   mock(1)(2)(3)\n   self.assertEqual(mock.mock_calls, call(1)(2)(3).call_list())\n   self.assertEqual(mock().mock_calls, call(2)(3).call_list())\n   self.assertEqual(mock()().mock_calls, call(3).call_list())\n   \n   mock = MagicMock(**kwargs)\n   mock(1)(2)(3).a.b.c(4)\n   self.assertEqual(mock.mock_calls,\n   call(1)(2)(3).a.b.c(4).call_list())\n   self.assertEqual(mock().mock_calls,\n   call(2)(3).a.b.c(4).call_list())\n   self.assertEqual(mock()().mock_calls,\n   call(3).a.b.c(4).call_list())\n   \n   mock = MagicMock(**kwargs)\n   int(mock().foo.bar().baz())\n   last_call = ('().foo.bar().baz().__int__', (), {})\n   self.assertEqual(mock.mock_calls[-1], last_call)\n   self.assertEqual(mock().mock_calls,\n   call.foo.bar().baz().__int__().call_list())\n   self.assertEqual(mock().foo.bar().mock_calls,\n   call.baz().__int__().call_list())\n   self.assertEqual(mock().foo.bar().baz.mock_calls,\n   call().__int__().call_list())\n   \n   \n def test_subclassing(self):\n  class Subclass(Mock):\n   pass\n   \n  mock = Subclass()\n  self.assertIsInstance(mock.foo, Subclass)\n  self.assertIsInstance(mock(), Subclass)\n  \n  class Subclass(Mock):\n   def _get_child_mock(self, **kwargs):\n    return Mock(**kwargs)\n    \n  mock = Subclass()\n  self.assertNotIsInstance(mock.foo, Subclass)\n  self.assertNotIsInstance(mock(), Subclass)\n  \n  \n def test_arg_lists(self):\n  mocks = [\n  Mock(),\n  MagicMock(),\n  NonCallableMock(),\n  NonCallableMagicMock()\n  ]\n  \n  def assert_attrs(mock):\n   names = 'call_args_list', 'method_calls', 'mock_calls'\n   for name in names:\n    attr = getattr(mock, name)\n    self.assertIsInstance(attr, _CallList)\n    self.assertIsInstance(attr, list)\n    self.assertEqual(attr, [])\n    \n  for mock in mocks:\n   assert_attrs(mock)\n   \n   if callable(mock):\n    mock()\n    mock(1, 2)\n    mock(a=3)\n    \n    mock.reset_mock()\n    assert_attrs(mock)\n    \n   mock.foo()\n   mock.foo.bar(1, a=3)\n   mock.foo(1).bar().baz(3)\n   \n   mock.reset_mock()\n   assert_attrs(mock)\n   \n   \n def test_call_args_two_tuple(self):\n  mock = Mock()\n  mock(1, a=3)\n  mock(2, b=4)\n  \n  self.assertEqual(len(mock.call_args), 2)\n  args, kwargs = mock.call_args\n  self.assertEqual(args, (2,))\n  self.assertEqual(kwargs, dict(b=4))\n  \n  expected_list = [((1,), dict(a=3)), ((2,), dict(b=4))]\n  for expected, call_args in zip(expected_list, mock.call_args_list):\n   self.assertEqual(len(call_args), 2)\n   self.assertEqual(expected[0], call_args[0])\n   self.assertEqual(expected[1], call_args[1])\n   \n   \n def test_side_effect_iterator(self):\n  mock = Mock(side_effect=iter([1, 2, 3]))\n  self.assertEqual([mock(), mock(), mock()], [1, 2, 3])\n  self.assertRaises(StopIteration, mock)\n  \n  mock = MagicMock(side_effect=['a', 'b', 'c'])\n  self.assertEqual([mock(), mock(), mock()], ['a', 'b', 'c'])\n  self.assertRaises(StopIteration, mock)\n  \n  mock = Mock(side_effect='ghi')\n  self.assertEqual([mock(), mock(), mock()], ['g', 'h', 'i'])\n  self.assertRaises(StopIteration, mock)\n  \n  class Foo(object):\n   pass\n  mock = MagicMock(side_effect=Foo)\n  self.assertIsInstance(mock(), Foo)\n  \n  mock = Mock(side_effect=Iter())\n  self.assertEqual([mock(), mock(), mock(), mock()],\n  ['this', 'is', 'an', 'iter'])\n  self.assertRaises(StopIteration, mock)\n  \n  \n def test_side_effect_iterator_exceptions(self):\n  for Klass in Mock, MagicMock:\n   iterable = (ValueError, 3, KeyError, 6)\n   m = Klass(side_effect=iterable)\n   self.assertRaises(ValueError, m)\n   self.assertEqual(m(), 3)\n   self.assertRaises(KeyError, m)\n   self.assertEqual(m(), 6)\n   \n   \n def test_side_effect_setting_iterator(self):\n  mock = Mock()\n  mock.side_effect = iter([1, 2, 3])\n  self.assertEqual([mock(), mock(), mock()], [1, 2, 3])\n  self.assertRaises(StopIteration, mock)\n  side_effect = mock.side_effect\n  self.assertIsInstance(side_effect, type(iter([])))\n  \n  mock.side_effect = ['a', 'b', 'c']\n  self.assertEqual([mock(), mock(), mock()], ['a', 'b', 'c'])\n  self.assertRaises(StopIteration, mock)\n  side_effect = mock.side_effect\n  self.assertIsInstance(side_effect, type(iter([])))\n  \n  this_iter = Iter()\n  mock.side_effect = this_iter\n  self.assertEqual([mock(), mock(), mock(), mock()],\n  ['this', 'is', 'an', 'iter'])\n  self.assertRaises(StopIteration, mock)\n  self.assertIs(mock.side_effect, this_iter)\n  \n  \n def test_assert_has_calls_any_order(self):\n  mock = Mock()\n  mock(1, 2)\n  mock(a=3)\n  mock(3, 4)\n  mock(b=6)\n  mock(b=6)\n  \n  kalls = [\n  call(1, 2), ({'a': 3},),\n  ((3, 4),), ((), {'a': 3}),\n  ('', (1, 2)), ('', {'a': 3}),\n  ('', (1, 2), {}), ('', (), {'a': 3})\n  ]\n  for kall in kalls:\n   mock.assert_has_calls([kall], any_order=True)\n   \n  for kall in call(1, '2'), call(b=3), call(), 3, None, 'foo':\n   self.assertRaises(\n   AssertionError, mock.assert_has_calls,\n   [kall], any_order=True\n   )\n   \n  kall_lists = [\n  [call(1, 2), call(b=6)],\n  [call(3, 4), call(1, 2)],\n  [call(b=6), call(b=6)],\n  ]\n  \n  for kall_list in kall_lists:\n   mock.assert_has_calls(kall_list, any_order=True)\n   \n  kall_lists = [\n  [call(b=6), call(b=6), call(b=6)],\n  [call(1, 2), call(1, 2)],\n  [call(3, 4), call(1, 2), call(5, 7)],\n  [call(b=6), call(3, 4), call(b=6), call(1, 2), call(b=6)],\n  ]\n  for kall_list in kall_lists:\n   self.assertRaises(\n   AssertionError, mock.assert_has_calls,\n   kall_list, any_order=True\n   )\n   \n def test_assert_has_calls(self):\n  kalls1 = [\n  call(1, 2), ({'a': 3},),\n  ((3, 4),), call(b=6),\n  ('', (1,), {'b': 6}),\n  ]\n  kalls2 = [call.foo(), call.bar(1)]\n  kalls2.extend(call.spam().baz(a=3).call_list())\n  kalls2.extend(call.bam(set(), foo={}).fish([1]).call_list())\n  \n  mocks = []\n  for mock in Mock(), MagicMock():\n   mock(1, 2)\n   mock(a=3)\n   mock(3, 4)\n   mock(b=6)\n   mock(1, b=6)\n   mocks.append((mock, kalls1))\n   \n  mock = Mock()\n  mock.foo()\n  mock.bar(1)\n  mock.spam().baz(a=3)\n  mock.bam(set(), foo={}).fish([1])\n  mocks.append((mock, kalls2))\n  \n  for mock, kalls in mocks:\n   for i in range(len(kalls)):\n    for step in 1, 2, 3:\n     these = kalls[i:i+step]\n     mock.assert_has_calls(these)\n     \n     if len(these) > 1:\n      self.assertRaises(\n      AssertionError,\n      mock.assert_has_calls,\n      list(reversed(these))\n      )\n      \n      \n def test_assert_any_call(self):\n  mock = Mock()\n  mock(1, 2)\n  mock(a=3)\n  mock(1, b=6)\n  \n  mock.assert_any_call(1, 2)\n  mock.assert_any_call(a=3)\n  mock.assert_any_call(1, b=6)\n  \n  self.assertRaises(\n  AssertionError,\n  mock.assert_any_call\n  )\n  self.assertRaises(\n  AssertionError,\n  mock.assert_any_call,\n  1, 3\n  )\n  self.assertRaises(\n  AssertionError,\n  mock.assert_any_call,\n  a=4\n  )\n  \n  \n def test_mock_calls_create_autospec(self):\n  def f(a, b):\n   pass\n  obj = Iter()\n  obj.f = f\n  \n  funcs = [\n  create_autospec(f),\n  create_autospec(obj).f\n  ]\n  for func in funcs:\n   func(1, 2)\n   func(3, 4)\n   \n   self.assertEqual(\n   func.mock_calls, [call(1, 2), call(3, 4)]\n   )\n   \n   \n def test_mock_add_spec(self):\n  class _One(object):\n   one = 1\n  class _Two(object):\n   two = 2\n  class Anything(object):\n   one = two = three = 'four'\n   \n  klasses = [\n  Mock, MagicMock, NonCallableMock, NonCallableMagicMock\n  ]\n  for Klass in list(klasses):\n   klasses.append(lambda K=Klass: K(spec=Anything))\n   klasses.append(lambda K=Klass: K(spec_set=Anything))\n   \n  for Klass in klasses:\n   for kwargs in dict(), dict(spec_set=True):\n    mock = Klass()\n    \n    mock.one, mock.two, mock.three\n    \n    for One, Two in [(_One, _Two), (['one'], ['two'])]:\n     for kwargs in dict(), dict(spec_set=True):\n      mock.mock_add_spec(One, **kwargs)\n      \n      mock.one\n      self.assertRaises(\n      AttributeError, getattr, mock, 'two'\n      )\n      self.assertRaises(\n      AttributeError, getattr, mock, 'three'\n      )\n      if 'spec_set' in kwargs:\n       self.assertRaises(\n       AttributeError, setattr, mock, 'three', None\n       )\n       \n      mock.mock_add_spec(Two, **kwargs)\n      self.assertRaises(\n      AttributeError, getattr, mock, 'one'\n      )\n      mock.two\n      self.assertRaises(\n      AttributeError, getattr, mock, 'three'\n      )\n      if 'spec_set' in kwargs:\n       self.assertRaises(\n       AttributeError, setattr, mock, 'three', None\n       )\n       \n       \n       \n       \n def test_mock_add_spec_magic_methods(self):\n  for Klass in MagicMock, NonCallableMagicMock:\n   mock = Klass()\n   int(mock)\n   \n   mock.mock_add_spec(object)\n   self.assertRaises(TypeError, int, mock)\n   \n   mock = Klass()\n   mock['foo']\n   mock.__int__.return_value =4\n   \n   mock.mock_add_spec(int)\n   self.assertEqual(int(mock), 4)\n   self.assertRaises(TypeError, lambda: mock['foo'])\n   \n   \n def test_adding_child_mock(self):\n  for Klass in NonCallableMock, Mock, MagicMock, NonCallableMagicMock:\n   mock = Klass()\n   \n   mock.foo = Mock()\n   mock.foo()\n   \n   self.assertEqual(mock.method_calls, [call.foo()])\n   self.assertEqual(mock.mock_calls, [call.foo()])\n   \n   mock = Klass()\n   mock.bar = Mock(name='name')\n   mock.bar()\n   self.assertEqual(mock.method_calls, [])\n   self.assertEqual(mock.mock_calls, [])\n   \n   \n   mock = Klass()\n   mock.baz = MagicMock()()\n   mock.baz()\n   self.assertEqual(mock.method_calls, [])\n   self.assertEqual(mock.mock_calls, [])\n   \n   \n def test_adding_return_value_mock(self):\n  for Klass in Mock, MagicMock:\n   mock = Klass()\n   mock.return_value = MagicMock()\n   \n   mock()()\n   self.assertEqual(mock.mock_calls, [call(), call()()])\n   \n   \n def test_manager_mock(self):\n  class Foo(object):\n   one = 'one'\n   two = 'two'\n  manager = Mock()\n  p1 = patch.object(Foo, 'one')\n  p2 = patch.object(Foo, 'two')\n  \n  mock_one = p1.start()\n  self.addCleanup(p1.stop)\n  mock_two = p2.start()\n  self.addCleanup(p2.stop)\n  \n  manager.attach_mock(mock_one, 'one')\n  manager.attach_mock(mock_two, 'two')\n  \n  Foo.two()\n  Foo.one()\n  \n  self.assertEqual(manager.mock_calls, [call.two(), call.one()])\n  \n  \n def test_magic_methods_mock_calls(self):\n  for Klass in Mock, MagicMock:\n   m = Klass()\n   m.__int__ = Mock(return_value=3)\n   m.__float__ = MagicMock(return_value=3.0)\n   int(m)\n   float(m)\n   \n   self.assertEqual(m.mock_calls, [call.__int__(), call.__float__()])\n   self.assertEqual(m.method_calls, [])\n   \n   \n def test_attribute_deletion(self):\n \n  for Klass in Mock, MagicMock, NonCallableMagicMock, NonCallableMock:\n   m = Klass()\n   original = m.foo\n   m.foo = 3\n   del m.foo\n   self.assertEqual(m.foo, original)\n   \n   new = m.foo = Mock()\n   del m.foo\n   self.assertEqual(m.foo, new)\n   \n   \n def test_mock_parents(self):\n  for Klass in Mock, MagicMock:\n   m = Klass()\n   original_repr = repr(m)\n   m.return_value = m\n   self.assertIs(m(), m)\n   self.assertEqual(repr(m), original_repr)\n   \n   m.reset_mock()\n   self.assertIs(m(), m)\n   self.assertEqual(repr(m), original_repr)\n   \n   m = Klass()\n   m.b = m.a\n   self.assertIn(\"name='mock.a'\", repr(m.b))\n   self.assertIn(\"name='mock.a'\", repr(m.a))\n   m.reset_mock()\n   self.assertIn(\"name='mock.a'\", repr(m.b))\n   self.assertIn(\"name='mock.a'\", repr(m.a))\n   \n   m = Klass()\n   original_repr = repr(m)\n   m.a = m()\n   m.a.return_value = m\n   \n   self.assertEqual(repr(m), original_repr)\n   self.assertEqual(repr(m.a()), original_repr)\n   \n   \n def test_attach_mock(self):\n  classes = Mock, MagicMock, NonCallableMagicMock, NonCallableMock\n  for Klass in classes:\n   for Klass2 in classes:\n    m = Klass()\n    \n    m2 = Klass2(name='foo')\n    m.attach_mock(m2, 'bar')\n    \n    self.assertIs(m.bar, m2)\n    self.assertIn(\"name='mock.bar'\", repr(m2))\n    \n    m.bar.baz(1)\n    self.assertEqual(m.mock_calls, [call.bar.baz(1)])\n    self.assertEqual(m.method_calls, [call.bar.baz(1)])\n    \n    \n def test_attach_mock_return_value(self):\n  classes = Mock, MagicMock, NonCallableMagicMock, NonCallableMock\n  for Klass in Mock, MagicMock:\n   for Klass2 in classes:\n    m = Klass()\n    \n    m2 = Klass2(name='foo')\n    m.attach_mock(m2, 'return_value')\n    \n    self.assertIs(m(), m2)\n    self.assertIn(\"name='mock()'\", repr(m2))\n    \n    m2.foo()\n    self.assertEqual(m.mock_calls, call().foo().call_list())\n    \n    \n def test_attribute_deletion(self):\n  for mock in Mock(), MagicMock():\n   self.assertTrue(hasattr(mock, 'm'))\n   \n   del mock.m\n   self.assertFalse(hasattr(mock, 'm'))\n   \n   del mock.f\n   self.assertFalse(hasattr(mock, 'f'))\n   self.assertRaises(AttributeError, getattr, mock, 'f')\n   \n   \n def test_class_assignable(self):\n  for mock in Mock(), MagicMock():\n   self.assertNotIsInstance(mock, int)\n   \n   mock.__class__ = int\n   self.assertIsInstance(mock, int)\n   mock.foo\n   \n   \n   \nif __name__ == '__main__':\n unittest.main()\n"], "textwrap": [".py", "\"\"\n\n\n\n\n\nimport re\n\n__all__ = ['TextWrapper', 'wrap', 'fill', 'dedent', 'indent']\n\n\n\n\n\n\n\n\n\n_whitespace = '\\t\\n\\x0b\\x0c\\r '\n\nclass TextWrapper:\n \"\"\n \n unicode_whitespace_trans = {}\n uspace = ord(' ')\n for x in _whitespace:\n  unicode_whitespace_trans[ord(x)] = uspace\n  \n  \n  \n  \n  \n  \n  \n wordsep_re = re.compile(\n r'(\\s+|' \n r'[^\\s\\w]*\\w+[^0-9\\W]-(?=\\w+[^0-9\\W])|' \n r'(?<=[\\w\\!\\\"\\'\\&\\.\\,\\?])-{2,}(?=\\w))') \n \n \n \n \n \n wordsep_simple_re = re.compile(r'(\\s+)')\n \n \n \n sentence_end_re = re.compile(r'[a-z]' \n r'[\\.\\!\\?]' \n r'[\\\"\\']?' \n r'\\Z') \n \n \n def __init__(self,\n width=70,\n initial_indent=\"\",\n subsequent_indent=\"\",\n expand_tabs=True,\n replace_whitespace=True,\n fix_sentence_endings=False,\n break_long_words=True,\n drop_whitespace=True,\n break_on_hyphens=True,\n tabsize=8):\n  self.width = width\n  self.initial_indent = initial_indent\n  self.subsequent_indent = subsequent_indent\n  self.expand_tabs = expand_tabs\n  self.replace_whitespace = replace_whitespace\n  self.fix_sentence_endings = fix_sentence_endings\n  self.break_long_words = break_long_words\n  self.drop_whitespace = drop_whitespace\n  self.break_on_hyphens = break_on_hyphens\n  self.tabsize = tabsize\n  \n  \n  \n  \n  \n def _munge_whitespace(self, text):\n  \"\"\n  if self.expand_tabs:\n   text = text.expandtabs(self.tabsize)\n  if self.replace_whitespace:\n   text = text.translate(self.unicode_whitespace_trans)\n  return text\n  \n  \n def _split(self, text):\n  \"\"\n  if self.break_on_hyphens is True:\n   chunks = self.wordsep_re.split(text)\n  else:\n   chunks = self.wordsep_simple_re.split(text)\n  chunks = [c for c in chunks if c]\n  return chunks\n  \n def _fix_sentence_endings(self, chunks):\n  \"\"\n  i = 0\n  patsearch = self.sentence_end_re.search\n  while i < len(chunks)-1:\n   if chunks[i+1] == \" \" and patsearch(chunks[i]):\n    chunks[i+1] = \"  \"\n    i += 2\n   else:\n    i += 1\n    \n def _handle_long_word(self, reversed_chunks, cur_line, cur_len, width):\n  \"\"\n  \n  \n  if width < 1:\n   space_left = 1\n  else:\n   space_left = width - cur_len\n   \n   \n   \n  if self.break_long_words:\n   cur_line.append(reversed_chunks[-1][:space_left])\n   reversed_chunks[-1] = reversed_chunks[-1][space_left:]\n   \n   \n   \n   \n  elif not cur_line:\n   cur_line.append(reversed_chunks.pop())\n   \n   \n   \n   \n   \n   \n   \n def _wrap_chunks(self, chunks):\n  \"\"\n  lines = []\n  if self.width <= 0:\n   raise ValueError(\"invalid width %r (must be > 0)\" % self.width)\n   \n   \n   \n  chunks.reverse()\n  \n  while chunks:\n  \n  \n  \n   cur_line = []\n   cur_len = 0\n   \n   \n   if lines:\n    indent = self.subsequent_indent\n   else:\n    indent = self.initial_indent\n    \n    \n   width = self.width - len(indent)\n   \n   \n   \n   if self.drop_whitespace and chunks[-1].strip() == '' and lines:\n    del chunks[-1]\n    \n   while chunks:\n    l = len(chunks[-1])\n    \n    \n    if cur_len + l <= width:\n     cur_line.append(chunks.pop())\n     cur_len += l\n     \n     \n    else:\n     break\n     \n     \n     \n   if chunks and len(chunks[-1]) > width:\n    self._handle_long_word(chunks, cur_line, cur_len, width)\n    \n    \n   if self.drop_whitespace and cur_line and cur_line[-1].strip() == '':\n    del cur_line[-1]\n    \n    \n    \n   if cur_line:\n    lines.append(indent + ''.join(cur_line))\n    \n  return lines\n  \n  \n  \n  \n def wrap(self, text):\n  \"\"\n  text = self._munge_whitespace(text)\n  chunks = self._split(text)\n  if self.fix_sentence_endings:\n   self._fix_sentence_endings(chunks)\n  return self._wrap_chunks(chunks)\n  \n def fill(self, text):\n  \"\"\n  return \"\\n\".join(self.wrap(text))\n  \n  \n  \n  \ndef wrap(text, width=70, **kwargs):\n \"\"\n w = TextWrapper(width=width, **kwargs)\n return w.wrap(text)\n \ndef fill(text, width=70, **kwargs):\n \"\"\n w = TextWrapper(width=width, **kwargs)\n return w.fill(text)\n \n \n \n \n_whitespace_only_re = re.compile('^[ \\t]+$', re.MULTILINE)\n_leading_whitespace_re = re.compile('(^[ \\t]*)(?:[^ \\t\\n])', re.MULTILINE)\n\ndef dedent(text):\n \"\"\n \n \n margin = None\n text = _whitespace_only_re.sub('', text)\n indents = _leading_whitespace_re.findall(text)\n for indent in indents:\n  if margin is None:\n   margin = indent\n   \n   \n   \n  elif indent.startswith(margin):\n   pass\n   \n   \n   \n  elif margin.startswith(indent):\n   margin = indent\n   \n   \n   \n  else:\n   margin = \"\"\n   break\n   \n   \n if 0 and margin:\n  for line in text.split(\"\\n\"):\n   assert not line or line.startswith(margin), \"line = %r, margin = %r\" % (line, margin)\n   \n if margin:\n  text = re.sub(r'(?m)^' + margin, '', text)\n return text\n \n \ndef indent(text, prefix, predicate=None):\n \"\"\n if predicate is None:\n  def predicate(line):\n   return line.strip()\n   \n def prefixed_lines():\n  for line in text.splitlines(True):\n   yield (prefix + line if predicate(line) else line)\n return ''.join(prefixed_lines())\n \n \nif __name__ == \"__main__\":\n\n\n print(dedent(\"Hello there.\\n  This is indented.\"))\n"], "antigravity": [".py", "\nimport webbrowser\nimport hashlib\n\nwebbrowser.open(\"http://xkcd.com/353/\")\n\ndef geohash(latitude, longitude, datedow):\n \"\"\n \n h = hashlib.md5(datedow).hexdigest()\n p, q = [('%f' % float.fromhex('0.' + x)) for x in (h[:16], h[16:32])]\n print('%d%s %d%s' % (latitude, p[1:], longitude, q[1:]))\n"], "collections.abc": [".py", "\n\n\n\"\"\n\nfrom abc import ABCMeta, abstractmethod\nimport sys\n\n__all__ = [\"Hashable\", \"Iterable\", \"Iterator\",\n\"Sized\", \"Container\", \"Callable\",\n\"Set\", \"MutableSet\",\n\"Mapping\", \"MutableMapping\",\n\"MappingView\", \"KeysView\", \"ItemsView\", \"ValuesView\",\n\"Sequence\", \"MutableSequence\",\n\"ByteString\",\n]\n\n\n\n\n\n\n\n\nbytes_iterator = type(iter(b''))\nbytearray_iterator = type(iter(bytearray()))\n\ndict_keyiterator = type(iter({}.keys()))\ndict_valueiterator = type(iter({}.values()))\ndict_itemiterator = type(iter({}.items()))\nlist_iterator = type(iter([]))\nlist_reverseiterator = type(iter(reversed([])))\nrange_iterator = type(iter(range(0)))\nset_iterator = type(iter(set()))\nstr_iterator = type(iter(\"\"))\ntuple_iterator = type(iter(()))\nzip_iterator = type(iter(zip()))\n\ndict_keys = type({}.keys())\ndict_values = type({}.values())\ndict_items = type({}.items())\n\nmappingproxy = type(type.__dict__)\n\n\n\n\nclass Hashable(metaclass=ABCMeta):\n\n __slots__ = ()\n \n @abstractmethod\n def __hash__(self):\n  return 0\n  \n @classmethod\n def __subclasshook__(cls, C):\n  if cls is Hashable:\n   for B in C.__mro__:\n    if \"__hash__\" in B.__dict__:\n     if B.__dict__[\"__hash__\"]:\n      return True\n     break\n  return NotImplemented\n  \n  \nclass Iterable(metaclass=ABCMeta):\n\n __slots__ = ()\n \n @abstractmethod\n def __iter__(self):\n  while False:\n   yield None\n   \n @classmethod\n def __subclasshook__(cls, C):\n  if cls is Iterable:\n   if any(\"__iter__\" in B.__dict__ for B in C.__mro__):\n    return True\n  return NotImplemented\n  \n  \nclass Iterator(Iterable):\n\n __slots__ = ()\n \n @abstractmethod\n def __next__(self):\n  raise StopIteration\n  \n def __iter__(self):\n  return self\n  \n @classmethod\n def __subclasshook__(cls, C):\n  if cls is Iterator:\n   if (any(\"__next__\" in B.__dict__ for B in C.__mro__) and\n   any(\"__iter__\" in B.__dict__ for B in C.__mro__)):\n    return True\n  return NotImplemented\n  \nIterator.register(bytes_iterator)\nIterator.register(bytearray_iterator)\n\nIterator.register(dict_keyiterator)\nIterator.register(dict_valueiterator)\nIterator.register(dict_itemiterator)\nIterator.register(list_iterator)\nIterator.register(list_reverseiterator)\nIterator.register(range_iterator)\nIterator.register(set_iterator)\nIterator.register(str_iterator)\nIterator.register(tuple_iterator)\nIterator.register(zip_iterator)\n\nclass Sized(metaclass=ABCMeta):\n\n __slots__ = ()\n \n @abstractmethod\n def __len__(self):\n  return 0\n  \n @classmethod\n def __subclasshook__(cls, C):\n  if cls is Sized:\n   if any(\"__len__\" in B.__dict__ for B in C.__mro__):\n    return True\n  return NotImplemented\n  \n  \nclass Container(metaclass=ABCMeta):\n\n __slots__ = ()\n \n @abstractmethod\n def __contains__(self, x):\n  return False\n  \n @classmethod\n def __subclasshook__(cls, C):\n  if cls is Container:\n   if any(\"__contains__\" in B.__dict__ for B in C.__mro__):\n    return True\n  return NotImplemented\n  \n  \nclass Callable(metaclass=ABCMeta):\n\n __slots__ = ()\n \n @abstractmethod\n def __call__(self, *args, **kwds):\n  return False\n  \n @classmethod\n def __subclasshook__(cls, C):\n  if cls is Callable:\n   if any(\"__call__\" in B.__dict__ for B in C.__mro__):\n    return True\n  return NotImplemented\n  \n  \n  \n  \n  \nclass Set(Sized, Iterable, Container):\n\n \"\"\n \n __slots__ = ()\n \n def __le__(self, other):\n  if not isinstance(other, Set):\n   return NotImplemented\n  if len(self) > len(other):\n   return False\n  for elem in self:\n   if elem not in other:\n    return False\n  return True\n  \n def __lt__(self, other):\n  if not isinstance(other, Set):\n   return NotImplemented\n  return len(self) < len(other) and self.__le__(other)\n  \n def __gt__(self, other):\n  if not isinstance(other, Set):\n   return NotImplemented\n  return other < self\n  \n def __ge__(self, other):\n  if not isinstance(other, Set):\n   return NotImplemented\n  return other <= self\n  \n def __eq__(self, other):\n  if not isinstance(other, Set):\n   return NotImplemented\n  return len(self) == len(other) and self.__le__(other)\n  \n def __ne__(self, other):\n  return not (self == other)\n  \n @classmethod\n def _from_iterable(cls, it):\n  \"\"\n  return cls(it)\n  \n def __and__(self, other):\n  if not isinstance(other, Iterable):\n   return NotImplemented\n  return self._from_iterable(value for value in other if value in self)\n  \n def isdisjoint(self, other):\n  for value in other:\n   if value in self:\n    return False\n  return True\n  \n def __or__(self, other):\n  if not isinstance(other, Iterable):\n   return NotImplemented\n  chain = (e for s in (self, other) for e in s)\n  return self._from_iterable(chain)\n  \n def __sub__(self, other):\n  if not isinstance(other, Set):\n   if not isinstance(other, Iterable):\n    return NotImplemented\n   other = self._from_iterable(other)\n  return self._from_iterable(value for value in self\n  if value not in other)\n  \n def __xor__(self, other):\n  if not isinstance(other, Set):\n   if not isinstance(other, Iterable):\n    return NotImplemented\n   other = self._from_iterable(other)\n  return (self - other) | (other - self)\n  \n def _hash(self):\n  \"\"\n  MAX = sys.maxsize\n  MASK = 2 * MAX + 1\n  n = len(self)\n  h = 1927868237 * (n + 1)\n  h &= MASK\n  for x in self:\n   hx = hash(x)\n   h ^= (hx ^ (hx << 16) ^ 89869747) * 3644798167\n   h &= MASK\n  h = h * 69069 + 907133923\n  h &= MASK\n  if h > MAX:\n   h -= MASK + 1\n  if h == -1:\n   h = 590923713\n  return h\n  \nSet.register(frozenset)\n\n\nclass MutableSet(Set):\n\n __slots__ = ()\n \n @abstractmethod\n def add(self, value):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def discard(self, value):\n  \"\"\n  raise NotImplementedError\n  \n def remove(self, value):\n  \"\"\n  if value not in self:\n   raise KeyError(value)\n  self.discard(value)\n  \n def pop(self):\n  \"\"\n  it = iter(self)\n  try:\n   value = next(it)\n  except StopIteration:\n   raise KeyError\n  self.discard(value)\n  return value\n  \n def clear(self):\n  \"\"\n  try:\n   while True:\n    self.pop()\n  except KeyError:\n   pass\n   \n def __ior__(self, it):\n  for value in it:\n   self.add(value)\n  return self\n  \n def __iand__(self, it):\n  for value in (self - it):\n   self.discard(value)\n  return self\n  \n def __ixor__(self, it):\n  if it is self:\n   self.clear()\n  else:\n   if not isinstance(it, Set):\n    it = self._from_iterable(it)\n   for value in it:\n    if value in self:\n     self.discard(value)\n    else:\n     self.add(value)\n  return self\n  \n def __isub__(self, it):\n  if it is self:\n   self.clear()\n  else:\n   for value in it:\n    self.discard(value)\n  return self\n  \nMutableSet.register(set)\n\n\n\n\n\nclass Mapping(Sized, Iterable, Container):\n\n __slots__ = ()\n \n @abstractmethod\n def __getitem__(self, key):\n  raise KeyError\n  \n def get(self, key, default=None):\n  try:\n   return self[key]\n  except KeyError:\n   return default\n   \n def __contains__(self, key):\n  try:\n   self[key]\n  except KeyError:\n   return False\n  else:\n   return True\n   \n def keys(self):\n  return KeysView(self)\n  \n def items(self):\n  return ItemsView(self)\n  \n def values(self):\n  return ValuesView(self)\n  \n def __eq__(self, other):\n  if not isinstance(other, Mapping):\n   return NotImplemented\n  return dict(self.items()) == dict(other.items())\n  \n def __ne__(self, other):\n  return not (self == other)\n  \nMapping.register(mappingproxy)\n\n\nclass MappingView(Sized):\n\n def __init__(self, mapping):\n  self._mapping = mapping\n  \n def __len__(self):\n  return len(self._mapping)\n  \n def __repr__(self):\n  return '{0.__class__.__name__}({0._mapping!r})'.format(self)\n  \n  \nclass KeysView(MappingView, Set):\n\n @classmethod\n def _from_iterable(self, it):\n  return set(it)\n  \n def __contains__(self, key):\n  return key in self._mapping\n  \n def __iter__(self):\n  for key in self._mapping:\n   yield key\n   \nKeysView.register(dict_keys)\n\n\nclass ItemsView(MappingView, Set):\n\n @classmethod\n def _from_iterable(self, it):\n  return set(it)\n  \n def __contains__(self, item):\n  key, value = item\n  try:\n   v = self._mapping[key]\n  except KeyError:\n   return False\n  else:\n   return v == value\n   \n def __iter__(self):\n  for key in self._mapping:\n   yield (key, self._mapping[key])\n   \nItemsView.register(dict_items)\n\n\nclass ValuesView(MappingView):\n\n def __contains__(self, value):\n  for key in self._mapping:\n   if value == self._mapping[key]:\n    return True\n  return False\n  \n def __iter__(self):\n  for key in self._mapping:\n   yield self._mapping[key]\n   \nValuesView.register(dict_values)\n\n\nclass MutableMapping(Mapping):\n\n __slots__ = ()\n \n @abstractmethod\n def __setitem__(self, key, value):\n  raise KeyError\n  \n @abstractmethod\n def __delitem__(self, key):\n  raise KeyError\n  \n __marker = object()\n \n def pop(self, key, default=__marker):\n  try:\n   value = self[key]\n  except KeyError:\n   if default is self.__marker:\n    raise\n   return default\n  else:\n   del self[key]\n   return value\n   \n def popitem(self):\n  try:\n   key = next(iter(self))\n  except StopIteration:\n   raise KeyError\n  value = self[key]\n  del self[key]\n  return key, value\n  \n def clear(self):\n  try:\n   while True:\n    self.popitem()\n  except KeyError:\n   pass\n   \n def update(*args, **kwds):\n  if len(args) > 2:\n   raise TypeError(\"update() takes at most 2 positional \"\n   \"arguments ({} given)\".format(len(args)))\n  elif not args:\n   raise TypeError(\"update() takes at least 1 argument (0 given)\")\n  self = args[0]\n  other = args[1] if len(args) >= 2 else ()\n  \n  if isinstance(other, Mapping):\n   for key in other:\n    self[key] = other[key]\n  elif hasattr(other, \"keys\"):\n   for key in other.keys():\n    self[key] = other[key]\n  else:\n   for key, value in other:\n    self[key] = value\n  for key, value in kwds.items():\n   self[key] = value\n   \n def setdefault(self, key, default=None):\n  try:\n   return self[key]\n  except KeyError:\n   self[key] = default\n  return default\n  \nMutableMapping.register(dict)\n\n\n\n\n\nclass Sequence(Sized, Iterable, Container):\n\n \"\"\n \n __slots__ = ()\n \n @abstractmethod\n def __getitem__(self, index):\n  raise IndexError\n  \n def __iter__(self):\n  i = 0\n  try:\n   while True:\n    v = self[i]\n    yield v\n    i += 1\n  except IndexError:\n   return\n   \n def __contains__(self, value):\n  for v in self:\n   if v == value:\n    return True\n  return False\n  \n def __reversed__(self):\n  for i in reversed(range(len(self))):\n   yield self[i]\n   \n def index(self, value):\n  for i, v in enumerate(self):\n   if v == value:\n    return i\n  raise ValueError\n  \n def count(self, value):\n  return sum(1 for v in self if v == value)\n  \nSequence.register(tuple)\nSequence.register(str)\nSequence.register(range)\n\n\nclass ByteString(Sequence):\n\n \"\"\n \n __slots__ = ()\n \nByteString.register(bytes)\nByteString.register(bytearray)\n\n\nclass MutableSequence(Sequence):\n\n __slots__ = ()\n \n @abstractmethod\n def __setitem__(self, index, value):\n  raise IndexError\n  \n @abstractmethod\n def __delitem__(self, index):\n  raise IndexError\n  \n @abstractmethod\n def insert(self, index, value):\n  raise IndexError\n  \n def append(self, value):\n  self.insert(len(self), value)\n  \n def clear(self):\n  try:\n   while True:\n    self.pop()\n  except IndexError:\n   pass\n   \n def reverse(self):\n  n = len(self)\n  for i in range(n//2):\n   self[i], self[n-i-1] = self[n-i-1], self[i]\n   \n def extend(self, values):\n  for v in values:\n   self.append(v)\n   \n def pop(self, index=-1):\n  v = self[index]\n  del self[index]\n  return v\n  \n def remove(self, value):\n  del self[self.index(value)]\n  \n def __iadd__(self, values):\n  self.extend(values)\n  return self\n  \nMutableSequence.register(list)\nMutableSequence.register(bytearray) \n"], "importlib.abc": [".py", "\"\"\nfrom . import _bootstrap\nfrom . import machinery\ntry:\n import _frozen_importlib\nexcept ImportError as exc:\n if exc.name != '_frozen_importlib':\n  raise\n _frozen_importlib = None\nimport abc\nimport imp\nimport marshal\nimport sys\nimport tokenize\nimport warnings\n\n\ndef _register(abstract_cls, *classes):\n for cls in classes:\n  abstract_cls.register(cls)\n  if _frozen_importlib is not None:\n   frozen_cls = getattr(_frozen_importlib, cls.__name__)\n   abstract_cls.register(frozen_cls)\n   \n   \nclass Finder(metaclass=abc.ABCMeta):\n\n \"\"\n \n @abc.abstractmethod\n def find_module(self, fullname, path=None):\n  \"\"\n  raise NotImplementedError\n  \n  \nclass MetaPathFinder(Finder):\n\n \"\"\n \n @abc.abstractmethod\n def find_module(self, fullname, path):\n  \"\"\n  raise NotImplementedError\n  \n def invalidate_caches(self):\n  \"\"\n  return NotImplemented\n  \n_register(MetaPathFinder, machinery.BuiltinImporter, machinery.FrozenImporter,\nmachinery.PathFinder, machinery.WindowsRegistryFinder)\n\n\nclass PathEntryFinder(Finder):\n\n \"\"\n \n @abc.abstractmethod\n def find_loader(self, fullname):\n  \"\"\n  raise NotImplementedError\n  \n find_module = _bootstrap._find_module_shim\n \n def invalidate_caches(self):\n  \"\"\n  return NotImplemented\n  \n_register(PathEntryFinder, machinery.FileFinder)\n\n\nclass Loader(metaclass=abc.ABCMeta):\n\n \"\"\n \n @abc.abstractmethod\n def load_module(self, fullname):\n  \"\"\n  raise NotImplementedError\n  \n @abc.abstractmethod\n def module_repr(self, module):\n  \"\"\n  raise NotImplementedError\n  \n  \nclass ResourceLoader(Loader):\n\n \"\"\n \n @abc.abstractmethod\n def get_data(self, path):\n  \"\"\n  raise NotImplementedError\n  \n  \nclass InspectLoader(Loader):\n\n \"\"\n \n @abc.abstractmethod\n def is_package(self, fullname):\n  \"\"\n  raise NotImplementedError\n  \n @abc.abstractmethod\n def get_code(self, fullname):\n  \"\"\n  raise NotImplementedError\n  \n @abc.abstractmethod\n def get_source(self, fullname):\n  \"\"\n  raise NotImplementedError\n  \n_register(InspectLoader, machinery.BuiltinImporter, machinery.FrozenImporter,\nmachinery.ExtensionFileLoader)\n\n\nclass ExecutionLoader(InspectLoader):\n\n \"\"\n \n @abc.abstractmethod\n def get_filename(self, fullname):\n  \"\"\n  raise NotImplementedError\n  \n  \nclass FileLoader(_bootstrap.FileLoader, ResourceLoader, ExecutionLoader):\n\n \"\"\n \n_register(FileLoader, machinery.SourceFileLoader,\nmachinery.SourcelessFileLoader)\n\n\nclass SourceLoader(_bootstrap.SourceLoader, ResourceLoader, ExecutionLoader):\n\n \"\"\n \n def path_mtime(self, path):\n  \"\"\n  if self.path_stats.__func__ is SourceLoader.path_stats:\n   raise NotImplementedError\n  return int(self.path_stats(path)['mtime'])\n  \n def path_stats(self, path):\n  \"\"\n  if self.path_mtime.__func__ is SourceLoader.path_mtime:\n   raise NotImplementedError\n  return {'mtime': self.path_mtime(path)}\n  \n def set_data(self, path, data):\n  \"\"\n  raise NotImplementedError\n  \n_register(SourceLoader, machinery.SourceFileLoader)\n\nclass PyLoader(SourceLoader):\n\n \"\"\n \n @abc.abstractmethod\n def is_package(self, fullname):\n  raise NotImplementedError\n  \n @abc.abstractmethod\n def source_path(self, fullname):\n  \"\"\n  raise NotImplementedError\n  \n def get_filename(self, fullname):\n  \"\"\n  warnings.warn(\"importlib.abc.PyLoader is deprecated and is \"\n  \"slated for removal in Python 3.4; \"\n  \"use SourceLoader instead. \"\n  \"See the importlib documentation on how to be \"\n  \"compatible with Python 3.1 onwards.\",\n  DeprecationWarning)\n  path = self.source_path(fullname)\n  if path is None:\n   raise ImportError(name=fullname)\n  else:\n   return path\n   \n   \nclass PyPycLoader(PyLoader):\n\n \"\"\n \n def get_filename(self, fullname):\n  \"\"\n  path = self.source_path(fullname)\n  if path is not None:\n   return path\n  path = self.bytecode_path(fullname)\n  if path is not None:\n   return path\n  raise ImportError(\"no source or bytecode path available for \"\n  \"{0!r}\".format(fullname), name=fullname)\n  \n def get_code(self, fullname):\n  \"\"\n  warnings.warn(\"importlib.abc.PyPycLoader is deprecated and slated for \"\n  \"removal in Python 3.4; use SourceLoader instead. \"\n  \"If Python 3.1 compatibility is required, see the \"\n  \"latest documentation for PyLoader.\",\n  DeprecationWarning)\n  source_timestamp = self.source_mtime(fullname)\n  \n  bytecode_path = self.bytecode_path(fullname)\n  if bytecode_path:\n   data = self.get_data(bytecode_path)\n   try:\n    magic = data[:4]\n    if len(magic) < 4:\n     raise ImportError(\n     \"bad magic number in {}\".format(fullname),\n     name=fullname, path=bytecode_path)\n    raw_timestamp = data[4:8]\n    if len(raw_timestamp) < 4:\n     raise EOFError(\"bad timestamp in {}\".format(fullname))\n    pyc_timestamp = _bootstrap._r_long(raw_timestamp)\n    raw_source_size = data[8:12]\n    if len(raw_source_size) != 4:\n     raise EOFError(\"bad file size in {}\".format(fullname))\n     \n     \n    bytecode = data[12:]\n    \n    if imp.get_magic() != magic:\n     raise ImportError(\n     \"bad magic number in {}\".format(fullname),\n     name=fullname, path=bytecode_path)\n     \n     \n    if source_timestamp:\n     if pyc_timestamp < source_timestamp:\n      raise ImportError(\"bytecode is stale\", name=fullname,\n      path=bytecode_path)\n   except (ImportError, EOFError):\n   \n    if source_timestamp is not None:\n     pass\n    else:\n     raise\n   else:\n   \n    return marshal.loads(bytecode)\n  elif source_timestamp is None:\n   raise ImportError(\"no source or bytecode available to create code \"\n   \"object for {0!r}\".format(fullname),\n   name=fullname)\n   \n  source_path = self.source_path(fullname)\n  if source_path is None:\n   message = \"a source path must exist to load {0}\".format(fullname)\n   raise ImportError(message, name=fullname)\n  source = self.get_data(source_path)\n  code_object = compile(source, source_path, 'exec', dont_inherit=True)\n  \n  if not sys.dont_write_bytecode:\n   data = bytearray(imp.get_magic())\n   data.extend(_bootstrap._w_long(source_timestamp))\n   data.extend(_bootstrap._w_long(len(source) & 0xFFFFFFFF))\n   data.extend(marshal.dumps(code_object))\n   self.write_bytecode(fullname, data)\n  return code_object\n  \n @abc.abstractmethod\n def source_mtime(self, fullname):\n  \"\"\n  raise NotImplementedError\n  \n @abc.abstractmethod\n def bytecode_path(self, fullname):\n  \"\"\n  raise NotImplementedError\n  \n @abc.abstractmethod\n def write_bytecode(self, fullname, bytecode):\n  \"\"\n  raise NotImplementedError\n"], "xml.sax._exceptions": [".py", "\"\"\nimport sys\nif sys.platform[:4] == \"java\":\n from java.lang import Exception\ndel sys\n\n\n\nclass SAXException(Exception):\n \"\"\n \n def __init__(self, msg, exception=None):\n  \"\"\n  self._msg = msg\n  self._exception = exception\n  Exception.__init__(self, msg)\n  \n def getMessage(self):\n  \"\"\n  return self._msg\n  \n def getException(self):\n  \"\"\n  return self._exception\n  \n def __str__(self):\n  \"\"\n  return self._msg\n  \n def __getitem__(self, ix):\n  \"\"\n  raise AttributeError(\"__getitem__\")\n  \n  \n  \n  \nclass SAXParseException(SAXException):\n \"\"\n \n def __init__(self, msg, exception, locator):\n  \"\"\n  SAXException.__init__(self, msg, exception)\n  self._locator = locator\n  \n  \n  \n  \n  \n  self._systemId = self._locator.getSystemId()\n  self._colnum = self._locator.getColumnNumber()\n  self._linenum = self._locator.getLineNumber()\n  \n def getColumnNumber(self):\n  \"\"\n  return self._colnum\n  \n def getLineNumber(self):\n  \"\"\n  return self._linenum\n  \n def getPublicId(self):\n  \"\"\n  return self._locator.getPublicId()\n  \n def getSystemId(self):\n  \"\"\n  return self._systemId\n  \n def __str__(self):\n  \"\"\n  sysid = self.getSystemId()\n  if sysid is None:\n   sysid = \"<unknown>\"\n  linenum = self.getLineNumber()\n  if linenum is None:\n   linenum = \"?\"\n  colnum = self.getColumnNumber()\n  if colnum is None:\n   colnum = \"?\"\n  return \"%s:%s:%s: %s\" % (sysid, linenum, colnum, self._msg)\n  \n  \n  \n  \nclass SAXNotRecognizedException(SAXException):\n \"\"\n pass\n \n \n \n \nclass SAXNotSupportedException(SAXException):\n \"\"\n \n pass\n \n \nclass SAXReaderNotAvailable(SAXNotSupportedException):\n \"\"\n \n pass\n"], "ui": [".py", "from browser import html, document\nfrom .dialog import *\nfrom .progressbar import *\nfrom .slider import *\n\ndef add_stylesheet():\n _link=html.LINK(Href='/src/Lib/ui/css/smoothness/jquery-ui-1.10.3.custom.min.css')\n _link.rel='stylesheet'\n \n document <= _link\n", 1], "xml.dom.domreg": [".py", "\"\"\n\n\n\n\n\nwell_known_implementations = {\n'minidom':'xml.dom.minidom',\n'4DOM': 'xml.dom.DOMImplementation',\n}\n\n\n\n\nregistered = {}\n\ndef registerDOMImplementation(name, factory):\n \"\"\n \n registered[name] = factory\n \ndef _good_enough(dom, features):\n \"\"\n for f,v in features:\n  if not dom.hasFeature(f,v):\n   return 0\n return 1\n \ndef getDOMImplementation(name=None, features=()):\n \"\"\n \n import os\n creator = None\n mod = well_known_implementations.get(name)\n if mod:\n  mod = __import__(mod, {}, {}, ['getDOMImplementation'])\n  return mod.getDOMImplementation()\n elif name:\n  return registered[name]()\n elif \"PYTHON_DOM\" in os.environ:\n  return getDOMImplementation(name = os.environ[\"PYTHON_DOM\"])\n  \n  \n  \n if isinstance(features, str):\n  features = _parse_feature_string(features)\n for creator in registered.values():\n  dom = creator()\n  if _good_enough(dom, features):\n   return dom\n   \n for creator in well_known_implementations.keys():\n  try:\n   dom = getDOMImplementation(name = creator)\n  except Exception: \n   continue\n  if _good_enough(dom, features):\n   return dom\n   \n raise ImportError(\"no suitable DOM implementation found\")\n \ndef _parse_feature_string(s):\n features = []\n parts = s.split()\n i = 0\n length = len(parts)\n while i < length:\n  feature = parts[i]\n  if feature[0] in \"0123456789\":\n   raise ValueError(\"bad feature name: %r\" % (feature,))\n  i = i + 1\n  version = None\n  if i < length:\n   v = parts[i]\n   if v[0] in \"0123456789\":\n    i = i + 1\n    version = v\n  features.append((feature, version))\n return tuple(features)\n"], "subprocess": [".py", "\n\n\n\n\n\n\n\n\n\"\"\n\nimport sys\nmswindows = (sys.platform == \"win32\")\n\nimport io\nimport os\nimport time\nimport traceback\nimport gc\nimport signal\nimport builtins\nimport warnings\nimport errno\ntry:\n from time import monotonic as _time\nexcept ImportError:\n from time import time as _time\n \n \nclass SubprocessError(Exception): pass\n\n\nclass CalledProcessError(SubprocessError):\n \"\"\n def __init__(self, returncode, cmd, output=None):\n  self.returncode = returncode\n  self.cmd = cmd\n  self.output = output\n def __str__(self):\n  return \"Command '%s' returned non-zero exit status %d\" % (self.cmd, self.returncode)\n  \n  \nclass TimeoutExpired(SubprocessError):\n \"\"\n def __init__(self, cmd, timeout, output=None):\n  self.cmd = cmd\n  self.timeout = timeout\n  self.output = output\n  \n def __str__(self):\n  return (\"Command '%s' timed out after %s seconds\" %\n  (self.cmd, self.timeout))\n  \n  \nif mswindows:\n import threading\n import msvcrt\n import _winapi\n class STARTUPINFO:\n  dwFlags = 0\n  hStdInput = None\n  hStdOutput = None\n  hStdError = None\n  wShowWindow = 0\n class pywintypes:\n  error = IOError\nelse:\n import select\n _has_poll = hasattr(select, 'poll')\n import _posixsubprocess\n _create_pipe = _posixsubprocess.cloexec_pipe\n \n \n \n \n _PIPE_BUF = getattr(select, 'PIPE_BUF', 512)\n \n \n__all__ = [\"Popen\", \"PIPE\", \"STDOUT\", \"call\", \"check_call\", \"getstatusoutput\",\n\"getoutput\", \"check_output\", \"CalledProcessError\", \"DEVNULL\"]\n\nif mswindows:\n from _winapi import (CREATE_NEW_CONSOLE, CREATE_NEW_PROCESS_GROUP,\n STD_INPUT_HANDLE, STD_OUTPUT_HANDLE,\n STD_ERROR_HANDLE, SW_HIDE,\n STARTF_USESTDHANDLES, STARTF_USESHOWWINDOW)\n \n __all__.extend([\"CREATE_NEW_CONSOLE\", \"CREATE_NEW_PROCESS_GROUP\",\n \"STD_INPUT_HANDLE\", \"STD_OUTPUT_HANDLE\",\n \"STD_ERROR_HANDLE\", \"SW_HIDE\",\n \"STARTF_USESTDHANDLES\", \"STARTF_USESHOWWINDOW\"])\n \n class Handle(int):\n  closed = False\n  \n  def Close(self, CloseHandle=_winapi.CloseHandle):\n   if not self.closed:\n    self.closed = True\n    CloseHandle(self)\n    \n  def Detach(self):\n   if not self.closed:\n    self.closed = True\n    return int(self)\n   raise ValueError(\"already closed\")\n   \n  def __repr__(self):\n   return \"Handle(%d)\" % int(self)\n   \n  __del__ = Close\n  __str__ = __repr__\n  \ntry:\n MAXFD = os.sysconf(\"SC_OPEN_MAX\")\nexcept:\n MAXFD = 256\n \n \n \n \n \n_active = []\n\ndef _cleanup():\n for inst in _active[:]:\n  res = inst._internal_poll(_deadstate=sys.maxsize)\n  if res is not None:\n   try:\n    _active.remove(inst)\n   except ValueError:\n   \n   \n    pass\n    \nPIPE = -1\nSTDOUT = -2\nDEVNULL = -3\n\n\ndef _eintr_retry_call(func, *args):\n while True:\n  try:\n   return func(*args)\n  except InterruptedError:\n   continue\n   \n   \n   \n   \n   \n   \ndef _args_from_interpreter_flags():\n \"\"\n flag_opt_map = {\n 'debug': 'd',\n \n \n 'optimize': 'O',\n 'dont_write_bytecode': 'B',\n 'no_user_site': 's',\n 'no_site': 'S',\n 'ignore_environment': 'E',\n 'verbose': 'v',\n 'bytes_warning': 'b',\n 'quiet': 'q',\n 'hash_randomization': 'R',\n }\n args = []\n for flag, opt in flag_opt_map.items():\n  v = getattr(sys.flags, flag)\n  if v > 0:\n   args.append('-' + opt * v)\n for opt in sys.warnoptions:\n  args.append('-W' + opt)\n return args\n \n \ndef call(*popenargs, timeout=None, **kwargs):\n \"\"\n with Popen(*popenargs, **kwargs) as p:\n  try:\n   return p.wait(timeout=timeout)\n  except:\n   p.kill()\n   p.wait()\n   raise\n   \n   \ndef check_call(*popenargs, **kwargs):\n \"\"\n retcode = call(*popenargs, **kwargs)\n if retcode:\n  cmd = kwargs.get(\"args\")\n  if cmd is None:\n   cmd = popenargs[0]\n  raise CalledProcessError(retcode, cmd)\n return 0\n \n \ndef check_output(*popenargs, timeout=None, **kwargs):\n \"\"\n if 'stdout' in kwargs:\n  raise ValueError('stdout argument not allowed, it will be overridden.')\n with Popen(*popenargs, stdout=PIPE, **kwargs) as process:\n  try:\n   output, unused_err = process.communicate(timeout=timeout)\n  except TimeoutExpired:\n   process.kill()\n   output, unused_err = process.communicate()\n   raise TimeoutExpired(process.args, timeout, output=output)\n  except:\n   process.kill()\n   process.wait()\n   raise\n  retcode = process.poll()\n  if retcode:\n   raise CalledProcessError(retcode, process.args, output=output)\n return output\n \n \ndef list2cmdline(seq):\n \"\"\n \n \n \n \n \n result = []\n needquote = False\n for arg in seq:\n  bs_buf = []\n  \n  \n  if result:\n   result.append(' ')\n   \n  needquote = (\" \" in arg) or (\"\\t\" in arg) or not arg\n  if needquote:\n   result.append('\"')\n   \n  for c in arg:\n   if c == '\\\\':\n   \n    bs_buf.append(c)\n   elif c == '\"':\n   \n    result.append('\\\\' * len(bs_buf)*2)\n    bs_buf = []\n    result.append('\\\\\"')\n   else:\n   \n    if bs_buf:\n     result.extend(bs_buf)\n     bs_buf = []\n    result.append(c)\n    \n    \n  if bs_buf:\n   result.extend(bs_buf)\n   \n  if needquote:\n   result.extend(bs_buf)\n   result.append('\"')\n   \n return ''.join(result)\n \n \n \n \n \n \ndef getstatusoutput(cmd):\n \"\"\n with os.popen('{ ' + cmd + '; } 2>&1', 'r') as pipe:\n  try:\n   text = pipe.read()\n   sts = pipe.close()\n  except:\n   process = pipe._proc\n   process.kill()\n   process.wait()\n   raise\n if sts is None:\n  sts = 0\n if text[-1:] == '\\n':\n  text = text[:-1]\n return sts, text\n \n \ndef getoutput(cmd):\n \"\"\n return getstatusoutput(cmd)[1]\n \n \n_PLATFORM_DEFAULT_CLOSE_FDS = object()\n\n\nclass Popen(object):\n def __init__(self, args, bufsize=-1, executable=None,\n stdin=None, stdout=None, stderr=None,\n preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,\n shell=False, cwd=None, env=None, universal_newlines=False,\n startupinfo=None, creationflags=0,\n restore_signals=True, start_new_session=False,\n pass_fds=()):\n  \"\"\n  _cleanup()\n  \n  self._child_created = False\n  self._input = None\n  self._communication_started = False\n  if bufsize is None:\n   bufsize = -1 \n  if not isinstance(bufsize, int):\n   raise TypeError(\"bufsize must be an integer\")\n   \n  if mswindows:\n   if preexec_fn is not None:\n    raise ValueError(\"preexec_fn is not supported on Windows \"\n    \"platforms\")\n   any_stdio_set = (stdin is not None or stdout is not None or\n   stderr is not None)\n   if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:\n    if any_stdio_set:\n     close_fds = False\n    else:\n     close_fds = True\n   elif close_fds and any_stdio_set:\n    raise ValueError(\n    \"close_fds is not supported on Windows platforms\"\n    \" if you redirect stdin/stdout/stderr\")\n  else:\n  \n   if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:\n    close_fds = True\n   if pass_fds and not close_fds:\n    warnings.warn(\"pass_fds overriding close_fds.\", RuntimeWarning)\n    close_fds = True\n   if startupinfo is not None:\n    raise ValueError(\"startupinfo is only supported on Windows \"\n    \"platforms\")\n   if creationflags != 0:\n    raise ValueError(\"creationflags is only supported on Windows \"\n    \"platforms\")\n    \n  self.args = args\n  self.stdin = None\n  self.stdout = None\n  self.stderr = None\n  self.pid = None\n  self.returncode = None\n  self.universal_newlines = universal_newlines\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  (p2cread, p2cwrite,\n  c2pread, c2pwrite,\n  errread, errwrite) = self._get_handles(stdin, stdout, stderr)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  if p2cwrite != -1:\n   self.stdin = io.open(p2cwrite, 'wb', bufsize)\n   if universal_newlines:\n    self.stdin = io.TextIOWrapper(self.stdin, write_through=True)\n  if c2pread != -1:\n   self.stdout = io.open(c2pread, 'rb', bufsize)\n   if universal_newlines:\n    self.stdout = io.TextIOWrapper(self.stdout)\n  if errread != -1:\n   self.stderr = io.open(errread, 'rb', bufsize)\n   if universal_newlines:\n    self.stderr = io.TextIOWrapper(self.stderr)\n    \n  self._closed_child_pipe_fds = False\n  try:\n   self._execute_child(args, executable, preexec_fn, close_fds,\n   pass_fds, cwd, env,\n   startupinfo, creationflags, shell,\n   p2cread, p2cwrite,\n   c2pread, c2pwrite,\n   errread, errwrite,\n   restore_signals, start_new_session)\n  except:\n  \n   for f in filter(None, (self.stdin, self.stdout, self.stderr)):\n    try:\n     f.close()\n    except EnvironmentError:\n     pass \n     \n   if not self._closed_child_pipe_fds:\n    to_close = []\n    if stdin == PIPE:\n     to_close.append(p2cread)\n    if stdout == PIPE:\n     to_close.append(c2pwrite)\n    if stderr == PIPE:\n     to_close.append(errwrite)\n    if hasattr(self, '_devnull'):\n     to_close.append(self._devnull)\n    for fd in to_close:\n     try:\n      os.close(fd)\n     except EnvironmentError:\n      pass\n      \n   raise\n   \n   \n def _translate_newlines(self, data, encoding):\n  data = data.decode(encoding)\n  return data.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, type, value, traceback):\n  if self.stdout:\n   self.stdout.close()\n  if self.stderr:\n   self.stderr.close()\n  if self.stdin:\n   self.stdin.close()\n   \n  self.wait()\n  \n def __del__(self, _maxsize=sys.maxsize, _active=_active):\n \n \n \n  if not getattr(self, '_child_created', False):\n  \n   return\n   \n  self._internal_poll(_deadstate=_maxsize)\n  if self.returncode is None and _active is not None:\n  \n   _active.append(self)\n   \n def _get_devnull(self):\n  if not hasattr(self, '_devnull'):\n   self._devnull = os.open(os.devnull, os.O_RDWR)\n  return self._devnull\n  \n def communicate(self, input=None, timeout=None):\n  \"\"\n  \n  if self._communication_started and input:\n   raise ValueError(\"Cannot send input after starting communication\")\n   \n   \n   \n   \n  if (timeout is None and not self._communication_started and\n  [self.stdin, self.stdout, self.stderr].count(None) >= 2):\n   stdout = None\n   stderr = None\n   if self.stdin:\n    if input:\n     try:\n      self.stdin.write(input)\n     except IOError as e:\n      if e.errno != errno.EPIPE and e.errno != errno.EINVAL:\n       raise\n    self.stdin.close()\n   elif self.stdout:\n    stdout = _eintr_retry_call(self.stdout.read)\n    self.stdout.close()\n   elif self.stderr:\n    stderr = _eintr_retry_call(self.stderr.read)\n    self.stderr.close()\n   self.wait()\n  else:\n   if timeout is not None:\n    endtime = _time() + timeout\n   else:\n    endtime = None\n    \n   try:\n    stdout, stderr = self._communicate(input, endtime, timeout)\n   finally:\n    self._communication_started = True\n    \n   sts = self.wait(timeout=self._remaining_time(endtime))\n   \n  return (stdout, stderr)\n  \n  \n def poll(self):\n  return self._internal_poll()\n  \n  \n def _remaining_time(self, endtime):\n  \"\"\n  if endtime is None:\n   return None\n  else:\n   return endtime - _time()\n   \n   \n def _check_timeout(self, endtime, orig_timeout):\n  \"\"\n  if endtime is None:\n   return\n  if _time() > endtime:\n   raise TimeoutExpired(self.args, orig_timeout)\n   \n   \n if mswindows:\n \n \n \n  def _get_handles(self, stdin, stdout, stderr):\n   \"\"\n   if stdin is None and stdout is None and stderr is None:\n    return (-1, -1, -1, -1, -1, -1)\n    \n   p2cread, p2cwrite = -1, -1\n   c2pread, c2pwrite = -1, -1\n   errread, errwrite = -1, -1\n   \n   if stdin is None:\n    p2cread = _winapi.GetStdHandle(_winapi.STD_INPUT_HANDLE)\n    if p2cread is None:\n     p2cread, _ = _winapi.CreatePipe(None, 0)\n     p2cread = Handle(p2cread)\n     _winapi.CloseHandle(_)\n   elif stdin == PIPE:\n    p2cread, p2cwrite = _winapi.CreatePipe(None, 0)\n    p2cread, p2cwrite = Handle(p2cread), Handle(p2cwrite)\n   elif stdin == DEVNULL:\n    p2cread = msvcrt.get_osfhandle(self._get_devnull())\n   elif isinstance(stdin, int):\n    p2cread = msvcrt.get_osfhandle(stdin)\n   else:\n   \n    p2cread = msvcrt.get_osfhandle(stdin.fileno())\n   p2cread = self._make_inheritable(p2cread)\n   \n   if stdout is None:\n    c2pwrite = _winapi.GetStdHandle(_winapi.STD_OUTPUT_HANDLE)\n    if c2pwrite is None:\n     _, c2pwrite = _winapi.CreatePipe(None, 0)\n     c2pwrite = Handle(c2pwrite)\n     _winapi.CloseHandle(_)\n   elif stdout == PIPE:\n    c2pread, c2pwrite = _winapi.CreatePipe(None, 0)\n    c2pread, c2pwrite = Handle(c2pread), Handle(c2pwrite)\n   elif stdout == DEVNULL:\n    c2pwrite = msvcrt.get_osfhandle(self._get_devnull())\n   elif isinstance(stdout, int):\n    c2pwrite = msvcrt.get_osfhandle(stdout)\n   else:\n   \n    c2pwrite = msvcrt.get_osfhandle(stdout.fileno())\n   c2pwrite = self._make_inheritable(c2pwrite)\n   \n   if stderr is None:\n    errwrite = _winapi.GetStdHandle(_winapi.STD_ERROR_HANDLE)\n    if errwrite is None:\n     _, errwrite = _winapi.CreatePipe(None, 0)\n     errwrite = Handle(errwrite)\n     _winapi.CloseHandle(_)\n   elif stderr == PIPE:\n    errread, errwrite = _winapi.CreatePipe(None, 0)\n    errread, errwrite = Handle(errread), Handle(errwrite)\n   elif stderr == STDOUT:\n    errwrite = c2pwrite\n   elif stderr == DEVNULL:\n    errwrite = msvcrt.get_osfhandle(self._get_devnull())\n   elif isinstance(stderr, int):\n    errwrite = msvcrt.get_osfhandle(stderr)\n   else:\n   \n    errwrite = msvcrt.get_osfhandle(stderr.fileno())\n   errwrite = self._make_inheritable(errwrite)\n   \n   return (p2cread, p2cwrite,\n   c2pread, c2pwrite,\n   errread, errwrite)\n   \n   \n  def _make_inheritable(self, handle):\n   \"\"\n   h = _winapi.DuplicateHandle(\n   _winapi.GetCurrentProcess(), handle,\n   _winapi.GetCurrentProcess(), 0, 1,\n   _winapi.DUPLICATE_SAME_ACCESS)\n   return Handle(h)\n   \n   \n  def _find_w9xpopen(self):\n   \"\"\n   w9xpopen = os.path.join(\n   os.path.dirname(_winapi.GetModuleFileName(0)),\n   \"w9xpopen.exe\")\n   if not os.path.exists(w9xpopen):\n   \n   \n    w9xpopen = os.path.join(os.path.dirname(sys.base_exec_prefix),\n    \"w9xpopen.exe\")\n    if not os.path.exists(w9xpopen):\n     raise RuntimeError(\"Cannot locate w9xpopen.exe, which is \"\n     \"needed for Popen to work with your \"\n     \"shell or platform.\")\n   return w9xpopen\n   \n   \n  def _execute_child(self, args, executable, preexec_fn, close_fds,\n  pass_fds, cwd, env,\n  startupinfo, creationflags, shell,\n  p2cread, p2cwrite,\n  c2pread, c2pwrite,\n  errread, errwrite,\n  unused_restore_signals, unused_start_new_session):\n   \"\"\n   \n   assert not pass_fds, \"pass_fds not supported on Windows.\"\n   \n   if not isinstance(args, str):\n    args = list2cmdline(args)\n    \n    \n   if startupinfo is None:\n    startupinfo = STARTUPINFO()\n   if -1 not in (p2cread, c2pwrite, errwrite):\n    startupinfo.dwFlags |= _winapi.STARTF_USESTDHANDLES\n    startupinfo.hStdInput = p2cread\n    startupinfo.hStdOutput = c2pwrite\n    startupinfo.hStdError = errwrite\n    \n   if shell:\n    startupinfo.dwFlags |= _winapi.STARTF_USESHOWWINDOW\n    startupinfo.wShowWindow = _winapi.SW_HIDE\n    comspec = os.environ.get(\"COMSPEC\", \"cmd.exe\")\n    args = '{} /c \"{}\"'.format (comspec, args)\n    if (_winapi.GetVersion() >= 0x80000000 or\n    os.path.basename(comspec).lower() == \"command.com\"):\n    \n    \n    \n    \n     w9xpopen = self._find_w9xpopen()\n     args = '\"%s\" %s' % (w9xpopen, args)\n     \n     \n     \n     \n     \n     \n     creationflags |= _winapi.CREATE_NEW_CONSOLE\n     \n     \n   try:\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n    \n    None, None,\n    int(not close_fds),\n    creationflags,\n    env,\n    cwd,\n    startupinfo)\n   except pywintypes.error as e:\n   \n   \n   \n   \n    raise WindowsError(*e.args)\n   finally:\n   \n   \n   \n   \n   \n   \n    if p2cread != -1:\n     p2cread.Close()\n    if c2pwrite != -1:\n     c2pwrite.Close()\n    if errwrite != -1:\n     errwrite.Close()\n    if hasattr(self, '_devnull'):\n     os.close(self._devnull)\n     \n     \n   self._child_created = True\n   self._handle = Handle(hp)\n   self.pid = pid\n   _winapi.CloseHandle(ht)\n   \n  def _internal_poll(self, _deadstate=None,\n  _WaitForSingleObject=_winapi.WaitForSingleObject,\n  _WAIT_OBJECT_0=_winapi.WAIT_OBJECT_0,\n  _GetExitCodeProcess=_winapi.GetExitCodeProcess):\n   \"\"\n   if self.returncode is None:\n    if _WaitForSingleObject(self._handle, 0) == _WAIT_OBJECT_0:\n     self.returncode = _GetExitCodeProcess(self._handle)\n   return self.returncode\n   \n   \n  def wait(self, timeout=None, endtime=None):\n   \"\"\n   if endtime is not None:\n    timeout = self._remaining_time(endtime)\n   if timeout is None:\n    timeout_millis = _winapi.INFINITE\n   else:\n    timeout_millis = int(timeout * 1000)\n   if self.returncode is None:\n    result = _winapi.WaitForSingleObject(self._handle,\n    timeout_millis)\n    if result == _winapi.WAIT_TIMEOUT:\n     raise TimeoutExpired(self.args, timeout)\n    self.returncode = _winapi.GetExitCodeProcess(self._handle)\n   return self.returncode\n   \n   \n  def _readerthread(self, fh, buffer):\n   buffer.append(fh.read())\n   fh.close()\n   \n   \n  def _communicate(self, input, endtime, orig_timeout):\n  \n  \n   if self.stdout and not hasattr(self, \"_stdout_buff\"):\n    self._stdout_buff = []\n    self.stdout_thread = threading.Thread(target=self._readerthread,\n    args=(self.stdout, self._stdout_buff))\n    self.stdout_thread.daemon = True\n    self.stdout_thread.start()\n   if self.stderr and not hasattr(self, \"_stderr_buff\"):\n    self._stderr_buff = []\n    self.stderr_thread = threading.Thread(target=self._readerthread,\n    args=(self.stderr, self._stderr_buff))\n    self.stderr_thread.daemon = True\n    self.stderr_thread.start()\n    \n   if self.stdin:\n    if input is not None:\n     try:\n      self.stdin.write(input)\n     except IOError as e:\n      if e.errno != errno.EPIPE:\n       raise\n    self.stdin.close()\n    \n    \n    \n    \n   if self.stdout is not None:\n    self.stdout_thread.join(self._remaining_time(endtime))\n    if self.stdout_thread.is_alive():\n     raise TimeoutExpired(self.args, orig_timeout)\n   if self.stderr is not None:\n    self.stderr_thread.join(self._remaining_time(endtime))\n    if self.stderr_thread.is_alive():\n     raise TimeoutExpired(self.args, orig_timeout)\n     \n     \n     \n   stdout = None\n   stderr = None\n   if self.stdout:\n    stdout = self._stdout_buff\n    self.stdout.close()\n   if self.stderr:\n    stderr = self._stderr_buff\n    self.stderr.close()\n    \n    \n   if stdout is not None:\n    stdout = stdout[0]\n   if stderr is not None:\n    stderr = stderr[0]\n    \n   return (stdout, stderr)\n   \n  def send_signal(self, sig):\n   \"\"\n   if sig == signal.SIGTERM:\n    self.terminate()\n   elif sig == signal.CTRL_C_EVENT:\n    os.kill(self.pid, signal.CTRL_C_EVENT)\n   elif sig == signal.CTRL_BREAK_EVENT:\n    os.kill(self.pid, signal.CTRL_BREAK_EVENT)\n   else:\n    raise ValueError(\"Unsupported signal: {}\".format(sig))\n    \n  def terminate(self):\n   \"\"\n   try:\n    _winapi.TerminateProcess(self._handle, 1)\n   except PermissionError:\n   \n   \n    rc = _winapi.GetExitCodeProcess(self._handle)\n    if rc == _winapi.STILL_ACTIVE:\n     raise\n    self.returncode = rc\n    \n  kill = terminate\n  \n else:\n \n \n \n  def _get_handles(self, stdin, stdout, stderr):\n   \"\"\n   p2cread, p2cwrite = -1, -1\n   c2pread, c2pwrite = -1, -1\n   errread, errwrite = -1, -1\n   \n   if stdin is None:\n    pass\n   elif stdin == PIPE:\n    p2cread, p2cwrite = _create_pipe()\n   elif stdin == DEVNULL:\n    p2cread = self._get_devnull()\n   elif isinstance(stdin, int):\n    p2cread = stdin\n   else:\n   \n    p2cread = stdin.fileno()\n    \n   if stdout is None:\n    pass\n   elif stdout == PIPE:\n    c2pread, c2pwrite = _create_pipe()\n   elif stdout == DEVNULL:\n    c2pwrite = self._get_devnull()\n   elif isinstance(stdout, int):\n    c2pwrite = stdout\n   else:\n   \n    c2pwrite = stdout.fileno()\n    \n   if stderr is None:\n    pass\n   elif stderr == PIPE:\n    errread, errwrite = _create_pipe()\n   elif stderr == STDOUT:\n    errwrite = c2pwrite\n   elif stderr == DEVNULL:\n    errwrite = self._get_devnull()\n   elif isinstance(stderr, int):\n    errwrite = stderr\n   else:\n   \n    errwrite = stderr.fileno()\n    \n   return (p2cread, p2cwrite,\n   c2pread, c2pwrite,\n   errread, errwrite)\n   \n   \n  def _close_fds(self, fds_to_keep):\n   start_fd = 3\n   for fd in sorted(fds_to_keep):\n    if fd >= start_fd:\n     os.closerange(start_fd, fd)\n     start_fd = fd + 1\n   if start_fd <= MAXFD:\n    os.closerange(start_fd, MAXFD)\n    \n    \n  def _execute_child(self, args, executable, preexec_fn, close_fds,\n  pass_fds, cwd, env,\n  startupinfo, creationflags, shell,\n  p2cread, p2cwrite,\n  c2pread, c2pwrite,\n  errread, errwrite,\n  restore_signals, start_new_session):\n   \"\"\n   \n   if isinstance(args, (str, bytes)):\n    args = [args]\n   else:\n    args = list(args)\n    \n   if shell:\n    args = [\"/bin/sh\", \"-c\"] + args\n    if executable:\n     args[0] = executable\n     \n   if executable is None:\n    executable = args[0]\n   orig_executable = executable\n   \n   \n   \n   \n   errpipe_read, errpipe_write = _create_pipe()\n   try:\n    try:\n    \n    \n    \n    \n    \n     if env is not None:\n      env_list = [os.fsencode(k) + b'=' + os.fsencode(v)\n      for k, v in env.items()]\n     else:\n      env_list = None \n     executable = os.fsencode(executable)\n     if os.path.dirname(executable):\n      executable_list = (executable,)\n     else:\n     \n      executable_list = tuple(\n      os.path.join(os.fsencode(dir), executable)\n      for dir in os.get_exec_path(env))\n     fds_to_keep = set(pass_fds)\n     fds_to_keep.add(errpipe_write)\n     self.pid = _posixsubprocess.fork_exec(\n     args, executable_list,\n     close_fds, sorted(fds_to_keep), cwd, env_list,\n     p2cread, p2cwrite, c2pread, c2pwrite,\n     errread, errwrite,\n     errpipe_read, errpipe_write,\n     restore_signals, start_new_session, preexec_fn)\n     self._child_created = True\n    finally:\n    \n     os.close(errpipe_write)\n     \n     \n    devnull_fd = getattr(self, '_devnull', None)\n    if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:\n     os.close(p2cread)\n    if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:\n     os.close(c2pwrite)\n    if errwrite != -1 and errread != -1 and errwrite != devnull_fd:\n     os.close(errwrite)\n    if devnull_fd is not None:\n     os.close(devnull_fd)\n     \n    self._closed_child_pipe_fds = True\n    \n    \n    \n    errpipe_data = bytearray()\n    while True:\n     part = _eintr_retry_call(os.read, errpipe_read, 50000)\n     errpipe_data += part\n     if not part or len(errpipe_data) > 50000:\n      break\n   finally:\n   \n    os.close(errpipe_read)\n    \n   if errpipe_data:\n    try:\n     _eintr_retry_call(os.waitpid, self.pid, 0)\n    except OSError as e:\n     if e.errno != errno.ECHILD:\n      raise\n    try:\n     exception_name, hex_errno, err_msg = (\n     errpipe_data.split(b':', 2))\n    except ValueError:\n     exception_name = b'RuntimeError'\n     hex_errno = b'0'\n     err_msg = (b'Bad exception data from child: ' +\n     repr(errpipe_data))\n    child_exception_type = getattr(\n    builtins, exception_name.decode('ascii'),\n    RuntimeError)\n    err_msg = err_msg.decode(errors=\"surrogatepass\")\n    if issubclass(child_exception_type, OSError) and hex_errno:\n     errno_num = int(hex_errno, 16)\n     child_exec_never_called = (err_msg == \"noexec\")\n     if child_exec_never_called:\n      err_msg = \"\"\n     if errno_num != 0:\n      err_msg = os.strerror(errno_num)\n      if errno_num == errno.ENOENT:\n       if child_exec_never_called:\n       \n        err_msg += ': ' + repr(cwd)\n       else:\n        err_msg += ': ' + repr(orig_executable)\n     raise child_exception_type(errno_num, err_msg)\n    raise child_exception_type(err_msg)\n    \n    \n  def _handle_exitstatus(self, sts, _WIFSIGNALED=os.WIFSIGNALED,\n  _WTERMSIG=os.WTERMSIG, _WIFEXITED=os.WIFEXITED,\n  _WEXITSTATUS=os.WEXITSTATUS):\n  \n  \n   if _WIFSIGNALED(sts):\n    self.returncode = -_WTERMSIG(sts)\n   elif _WIFEXITED(sts):\n    self.returncode = _WEXITSTATUS(sts)\n   else:\n   \n    raise RuntimeError(\"Unknown child exit status!\")\n    \n    \n  def _internal_poll(self, _deadstate=None, _waitpid=os.waitpid,\n  _WNOHANG=os.WNOHANG, _os_error=os.error, _ECHILD=errno.ECHILD):\n   \"\"\n   if self.returncode is None:\n    try:\n     pid, sts = _waitpid(self.pid, _WNOHANG)\n     if pid == self.pid:\n      self._handle_exitstatus(sts)\n    except _os_error as e:\n     if _deadstate is not None:\n      self.returncode = _deadstate\n     elif e.errno == _ECHILD:\n     \n     \n     \n     \n     \n      self.returncode = 0\n   return self.returncode\n   \n   \n  def _try_wait(self, wait_flags):\n   try:\n    (pid, sts) = _eintr_retry_call(os.waitpid, self.pid, wait_flags)\n   except OSError as e:\n    if e.errno != errno.ECHILD:\n     raise\n     \n     \n     \n    pid = self.pid\n    sts = 0\n   return (pid, sts)\n   \n   \n  def wait(self, timeout=None, endtime=None):\n   \"\"\n   if self.returncode is not None:\n    return self.returncode\n    \n    \n    \n   if endtime is not None or timeout is not None:\n    if endtime is None:\n     endtime = _time() + timeout\n    elif timeout is None:\n     timeout = self._remaining_time(endtime)\n     \n   if endtime is not None:\n   \n   \n    delay = 0.0005 \n    while True:\n     (pid, sts) = self._try_wait(os.WNOHANG)\n     assert pid == self.pid or pid == 0\n     if pid == self.pid:\n      self._handle_exitstatus(sts)\n      break\n     remaining = self._remaining_time(endtime)\n     if remaining <= 0:\n      raise TimeoutExpired(self.args, timeout)\n     delay = min(delay * 2, remaining, .05)\n     time.sleep(delay)\n   else:\n    while self.returncode is None:\n     (pid, sts) = self._try_wait(0)\n     \n     \n     if pid == self.pid:\n      self._handle_exitstatus(sts)\n   return self.returncode\n   \n   \n  def _communicate(self, input, endtime, orig_timeout):\n   if self.stdin and not self._communication_started:\n   \n   \n    self.stdin.flush()\n    if not input:\n     self.stdin.close()\n     \n   if _has_poll:\n    stdout, stderr = self._communicate_with_poll(input, endtime,\n    orig_timeout)\n   else:\n    stdout, stderr = self._communicate_with_select(input, endtime,\n    orig_timeout)\n    \n   self.wait(timeout=self._remaining_time(endtime))\n   \n   \n   if stdout is not None:\n    stdout = b''.join(stdout)\n   if stderr is not None:\n    stderr = b''.join(stderr)\n    \n    \n    \n   if self.universal_newlines:\n    if stdout is not None:\n     stdout = self._translate_newlines(stdout,\n     self.stdout.encoding)\n    if stderr is not None:\n     stderr = self._translate_newlines(stderr,\n     self.stderr.encoding)\n     \n   return (stdout, stderr)\n   \n   \n  def _save_input(self, input):\n  \n  \n  \n   if self.stdin and self._input is None:\n    self._input_offset = 0\n    self._input = input\n    if self.universal_newlines and input is not None:\n     self._input = self._input.encode(self.stdin.encoding)\n     \n     \n  def _communicate_with_poll(self, input, endtime, orig_timeout):\n   stdout = None \n   stderr = None \n   \n   if not self._communication_started:\n    self._fd2file = {}\n    \n   poller = select.poll()\n   def register_and_append(file_obj, eventmask):\n    poller.register(file_obj.fileno(), eventmask)\n    self._fd2file[file_obj.fileno()] = file_obj\n    \n   def close_unregister_and_remove(fd):\n    poller.unregister(fd)\n    self._fd2file[fd].close()\n    self._fd2file.pop(fd)\n    \n   if self.stdin and input:\n    register_and_append(self.stdin, select.POLLOUT)\n    \n    \n   if not self._communication_started:\n    self._fd2output = {}\n    if self.stdout:\n     self._fd2output[self.stdout.fileno()] = []\n    if self.stderr:\n     self._fd2output[self.stderr.fileno()] = []\n     \n   select_POLLIN_POLLPRI = select.POLLIN | select.POLLPRI\n   if self.stdout:\n    register_and_append(self.stdout, select_POLLIN_POLLPRI)\n    stdout = self._fd2output[self.stdout.fileno()]\n   if self.stderr:\n    register_and_append(self.stderr, select_POLLIN_POLLPRI)\n    stderr = self._fd2output[self.stderr.fileno()]\n    \n   self._save_input(input)\n   \n   while self._fd2file:\n    timeout = self._remaining_time(endtime)\n    if timeout is not None and timeout < 0:\n     raise TimeoutExpired(self.args, orig_timeout)\n    try:\n     ready = poller.poll(timeout)\n    except select.error as e:\n     if e.args[0] == errno.EINTR:\n      continue\n     raise\n    self._check_timeout(endtime, orig_timeout)\n    \n    \n    \n    \n    for fd, mode in ready:\n     if mode & select.POLLOUT:\n      chunk = self._input[self._input_offset :\n      self._input_offset + _PIPE_BUF]\n      try:\n       self._input_offset += os.write(fd, chunk)\n      except OSError as e:\n       if e.errno == errno.EPIPE:\n        close_unregister_and_remove(fd)\n       else:\n        raise\n      else:\n       if self._input_offset >= len(self._input):\n        close_unregister_and_remove(fd)\n     elif mode & select_POLLIN_POLLPRI:\n      data = os.read(fd, 4096)\n      if not data:\n       close_unregister_and_remove(fd)\n      self._fd2output[fd].append(data)\n     else:\n     \n      close_unregister_and_remove(fd)\n      \n   return (stdout, stderr)\n   \n   \n  def _communicate_with_select(self, input, endtime, orig_timeout):\n   if not self._communication_started:\n    self._read_set = []\n    self._write_set = []\n    if self.stdin and input:\n     self._write_set.append(self.stdin)\n    if self.stdout:\n     self._read_set.append(self.stdout)\n    if self.stderr:\n     self._read_set.append(self.stderr)\n     \n   self._save_input(input)\n   \n   stdout = None \n   stderr = None \n   \n   if self.stdout:\n    if not self._communication_started:\n     self._stdout_buff = []\n    stdout = self._stdout_buff\n   if self.stderr:\n    if not self._communication_started:\n     self._stderr_buff = []\n    stderr = self._stderr_buff\n    \n   while self._read_set or self._write_set:\n    timeout = self._remaining_time(endtime)\n    if timeout is not None and timeout < 0:\n     raise TimeoutExpired(self.args, orig_timeout)\n    try:\n     (rlist, wlist, xlist) = select.select(self._read_set, self._write_set, [],\n     timeout)\n    except select.error as e:\n     if e.args[0] == errno.EINTR:\n      continue\n     raise\n     \n     \n     \n    if not (rlist or wlist or xlist):\n     raise TimeoutExpired(self.args, orig_timeout)\n     \n    self._check_timeout(endtime, orig_timeout)\n    \n    \n    \n    \n    if self.stdin in wlist:\n     chunk = self._input[self._input_offset :\n     self._input_offset + _PIPE_BUF]\n     try:\n      bytes_written = os.write(self.stdin.fileno(), chunk)\n     except OSError as e:\n      if e.errno == errno.EPIPE:\n       self.stdin.close()\n       self._write_set.remove(self.stdin)\n      else:\n       raise\n     else:\n      self._input_offset += bytes_written\n      if self._input_offset >= len(self._input):\n       self.stdin.close()\n       self._write_set.remove(self.stdin)\n       \n    if self.stdout in rlist:\n     data = os.read(self.stdout.fileno(), 1024)\n     if not data:\n      self.stdout.close()\n      self._read_set.remove(self.stdout)\n     stdout.append(data)\n     \n    if self.stderr in rlist:\n     data = os.read(self.stderr.fileno(), 1024)\n     if not data:\n      self.stderr.close()\n      self._read_set.remove(self.stderr)\n     stderr.append(data)\n     \n   return (stdout, stderr)\n   \n   \n  def send_signal(self, sig):\n   \"\"\n   os.kill(self.pid, sig)\n   \n  def terminate(self):\n   \"\"\n   self.send_signal(signal.SIGTERM)\n   \n  def kill(self):\n   \"\"\n   self.send_signal(signal.SIGKILL)\n"], "urllib.parse": [".py", "\"\"\n\nimport re\nimport sys\nimport collections\n\n__all__ = [\"urlparse\", \"urlunparse\", \"urljoin\", \"urldefrag\",\n\"urlsplit\", \"urlunsplit\", \"urlencode\", \"parse_qs\",\n\"parse_qsl\", \"quote\", \"quote_plus\", \"quote_from_bytes\",\n\"unquote\", \"unquote_plus\", \"unquote_to_bytes\"]\n\n\nuses_relative = ['ftp', 'http', 'gopher', 'nntp', 'imap',\n'wais', 'file', 'https', 'shttp', 'mms',\n'prospero', 'rtsp', 'rtspu', '', 'sftp',\n'svn', 'svn+ssh']\nuses_netloc = ['ftp', 'http', 'gopher', 'nntp', 'telnet',\n'imap', 'wais', 'file', 'mms', 'https', 'shttp',\n'snews', 'prospero', 'rtsp', 'rtspu', 'rsync', '',\n'svn', 'svn+ssh', 'sftp', 'nfs', 'git', 'git+ssh']\nuses_params = ['ftp', 'hdl', 'prospero', 'http', 'imap',\n'https', 'shttp', 'rtsp', 'rtspu', 'sip', 'sips',\n'mms', '', 'sftp', 'tel']\n\n\n\nnon_hierarchical = ['gopher', 'hdl', 'mailto', 'news',\n'telnet', 'wais', 'imap', 'snews', 'sip', 'sips']\nuses_query = ['http', 'wais', 'imap', 'https', 'shttp', 'mms',\n'gopher', 'rtsp', 'rtspu', 'sip', 'sips', '']\nuses_fragment = ['ftp', 'hdl', 'http', 'gopher', 'news',\n'nntp', 'wais', 'https', 'shttp', 'snews',\n'file', 'prospero', '']\n\n\nscheme_chars = ('abcdefghijklmnopqrstuvwxyz'\n'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n'0123456789'\n'+-.')\n\n\nMAX_CACHE_SIZE = 20\n_parse_cache = {}\n\ndef clear_cache():\n \"\"\n _parse_cache.clear()\n _safe_quoters.clear()\n \n \n \n \n \n \n \n \n_implicit_encoding = 'ascii'\n_implicit_errors = 'strict'\n\ndef _noop(obj):\n return obj\n \ndef _encode_result(obj, encoding=_implicit_encoding,\nerrors=_implicit_errors):\n return obj.encode(encoding, errors)\n \ndef _decode_args(args, encoding=_implicit_encoding,\nerrors=_implicit_errors):\n return tuple(x.decode(encoding, errors) if x else '' for x in args)\n \ndef _coerce_args(*args):\n\n\n\n\n\n str_input = isinstance(args[0], str)\n for arg in args[1:]:\n \n \n  if arg and isinstance(arg, str) != str_input:\n   raise TypeError(\"Cannot mix str and non-str arguments\")\n if str_input:\n  return args + (_noop,)\n return _decode_args(args) + (_encode_result,)\n \n \nclass _ResultMixinStr(object):\n \"\"\n __slots__ = ()\n \n def encode(self, encoding='ascii', errors='strict'):\n  return self._encoded_counterpart(*(x.encode(encoding, errors) for x in self))\n  \n  \nclass _ResultMixinBytes(object):\n \"\"\n __slots__ = ()\n \n def decode(self, encoding='ascii', errors='strict'):\n  return self._decoded_counterpart(*(x.decode(encoding, errors) for x in self))\n  \n  \nclass _NetlocResultMixinBase(object):\n \"\"\n __slots__ = ()\n \n @property\n def username(self):\n  return self._userinfo[0]\n  \n @property\n def password(self):\n  return self._userinfo[1]\n  \n @property\n def hostname(self):\n  hostname = self._hostinfo[0]\n  if not hostname:\n   hostname = None\n  elif hostname is not None:\n   hostname = hostname.lower()\n  return hostname\n  \n @property\n def port(self):\n  port = self._hostinfo[1]\n  if port is not None:\n   port = int(port, 10)\n   \n   if not ( 0 <= port <= 65535):\n    return None\n  return port\n  \n  \nclass _NetlocResultMixinStr(_NetlocResultMixinBase, _ResultMixinStr):\n __slots__ = ()\n \n @property\n def _userinfo(self):\n  netloc = self.netloc\n  userinfo, have_info, hostinfo = netloc.rpartition('@')\n  if have_info:\n   username, have_password, password = userinfo.partition(':')\n   if not have_password:\n    password = None\n  else:\n   username = password = None\n  return username, password\n  \n @property\n def _hostinfo(self):\n  netloc = self.netloc\n  _, _, hostinfo = netloc.rpartition('@')\n  _, have_open_br, bracketed = hostinfo.partition('[')\n  if have_open_br:\n   hostname, _, port = bracketed.partition(']')\n   _, have_port, port = port.partition(':')\n  else:\n   hostname, have_port, port = hostinfo.partition(':')\n  if not have_port:\n   port = None\n  return hostname, port\n  \n  \nclass _NetlocResultMixinBytes(_NetlocResultMixinBase, _ResultMixinBytes):\n __slots__ = ()\n \n @property\n def _userinfo(self):\n  netloc = self.netloc\n  userinfo, have_info, hostinfo = netloc.rpartition(b'@')\n  if have_info:\n   username, have_password, password = userinfo.partition(b':')\n   if not have_password:\n    password = None\n  else:\n   username = password = None\n  return username, password\n  \n @property\n def _hostinfo(self):\n  netloc = self.netloc\n  _, _, hostinfo = netloc.rpartition(b'@')\n  _, have_open_br, bracketed = hostinfo.partition(b'[')\n  if have_open_br:\n   hostname, _, port = bracketed.partition(b']')\n   _, have_port, port = port.partition(b':')\n  else:\n   hostname, have_port, port = hostinfo.partition(b':')\n  if not have_port:\n   port = None\n  return hostname, port\n  \n  \nfrom collections import namedtuple\n\n_DefragResultBase = namedtuple('DefragResult', 'url fragment')\n_SplitResultBase = namedtuple('SplitResult', 'scheme netloc path query fragment')\n_ParseResultBase = namedtuple('ParseResult', 'scheme netloc path params query fragment')\n\n\n\n\nResultBase = _NetlocResultMixinStr\n\n\nclass DefragResult(_DefragResultBase, _ResultMixinStr):\n __slots__ = ()\n def geturl(self):\n  if self.fragment:\n   return self.url + '#' + self.fragment\n  else:\n   return self.url\n   \nclass SplitResult(_SplitResultBase, _NetlocResultMixinStr):\n __slots__ = ()\n def geturl(self):\n  return urlunsplit(self)\n  \nclass ParseResult(_ParseResultBase, _NetlocResultMixinStr):\n __slots__ = ()\n def geturl(self):\n  return urlunparse(self)\n  \n  \nclass DefragResultBytes(_DefragResultBase, _ResultMixinBytes):\n __slots__ = ()\n def geturl(self):\n  if self.fragment:\n   return self.url + b'#' + self.fragment\n  else:\n   return self.url\n   \nclass SplitResultBytes(_SplitResultBase, _NetlocResultMixinBytes):\n __slots__ = ()\n def geturl(self):\n  return urlunsplit(self)\n  \nclass ParseResultBytes(_ParseResultBase, _NetlocResultMixinBytes):\n __slots__ = ()\n def geturl(self):\n  return urlunparse(self)\n  \n  \ndef _fix_result_transcoding():\n _result_pairs = (\n (DefragResult, DefragResultBytes),\n (SplitResult, SplitResultBytes),\n (ParseResult, ParseResultBytes),\n )\n for _decoded, _encoded in _result_pairs:\n  _decoded._encoded_counterpart = _encoded\n  _encoded._decoded_counterpart = _decoded\n  \n_fix_result_transcoding()\ndel _fix_result_transcoding\n\ndef urlparse(url, scheme='', allow_fragments=True):\n \"\"\n url, scheme, _coerce_result = _coerce_args(url, scheme)\n splitresult = urlsplit(url, scheme, allow_fragments)\n scheme, netloc, url, query, fragment = splitresult\n if scheme in uses_params and ';' in url:\n  url, params = _splitparams(url)\n else:\n  params = ''\n result = ParseResult(scheme, netloc, url, params, query, fragment)\n return _coerce_result(result)\n \ndef _splitparams(url):\n if '/' in url:\n  i = url.find(';', url.rfind('/'))\n  if i < 0:\n   return url, ''\n else:\n  i = url.find(';')\n return url[:i], url[i+1:]\n \ndef _splitnetloc(url, start=0):\n delim = len(url) \n for c in '/?#': \n  wdelim = url.find(c, start) \n  if wdelim >= 0: \n   delim = min(delim, wdelim) \n return url[start:delim], url[delim:] \n \ndef urlsplit(url, scheme='', allow_fragments=True):\n \"\"\n url, scheme, _coerce_result = _coerce_args(url, scheme)\n allow_fragments = bool(allow_fragments)\n key = url, scheme, allow_fragments, type(url), type(scheme)\n cached = _parse_cache.get(key, None)\n if cached:\n  return _coerce_result(cached)\n if len(_parse_cache) >= MAX_CACHE_SIZE: \n  clear_cache()\n netloc = query = fragment = ''\n i = url.find(':')\n if i > 0:\n  if url[:i] == 'http': \n   scheme = url[:i].lower()\n   url = url[i+1:]\n   if url[:2] == '//':\n    netloc, url = _splitnetloc(url, 2)\n    if (('[' in netloc and ']' not in netloc) or\n    (']' in netloc and '[' not in netloc)):\n     raise ValueError(\"Invalid IPv6 URL\")\n   if allow_fragments and '#' in url:\n    url, fragment = url.split('#', 1)\n   if '?' in url:\n    url, query = url.split('?', 1)\n   v = SplitResult(scheme, netloc, url, query, fragment)\n   _parse_cache[key] = v\n   return _coerce_result(v)\n  for c in url[:i]:\n   if c not in scheme_chars:\n    break\n  else:\n  \n  \n   rest = url[i+1:]\n   if not rest or any(c not in '0123456789' for c in rest):\n   \n    scheme, url = url[:i].lower(), rest\n    \n if url[:2] == '//':\n  netloc, url = _splitnetloc(url, 2)\n  if (('[' in netloc and ']' not in netloc) or\n  (']' in netloc and '[' not in netloc)):\n   raise ValueError(\"Invalid IPv6 URL\")\n if allow_fragments and '#' in url:\n  url, fragment = url.split('#', 1)\n if '?' in url:\n  url, query = url.split('?', 1)\n v = SplitResult(scheme, netloc, url, query, fragment)\n _parse_cache[key] = v\n return _coerce_result(v)\n \ndef urlunparse(components):\n \"\"\n scheme, netloc, url, params, query, fragment, _coerce_result = (\n _coerce_args(*components))\n if params:\n  url = \"%s;%s\" % (url, params)\n return _coerce_result(urlunsplit((scheme, netloc, url, query, fragment)))\n \ndef urlunsplit(components):\n \"\"\n scheme, netloc, url, query, fragment, _coerce_result = (\n _coerce_args(*components))\n if netloc or (scheme and scheme in uses_netloc and url[:2] != '//'):\n  if url and url[:1] != '/': url = '/' + url\n  url = '//' + (netloc or '') + url\n if scheme:\n  url = scheme + ':' + url\n if query:\n  url = url + '?' + query\n if fragment:\n  url = url + '#' + fragment\n return _coerce_result(url)\n \ndef urljoin(base, url, allow_fragments=True):\n \"\"\n if not base:\n  return url\n if not url:\n  return base\n base, url, _coerce_result = _coerce_args(base, url)\n bscheme, bnetloc, bpath, bparams, bquery, bfragment = urlparse(base, '', allow_fragments)\n scheme, netloc, path, params, query, fragment = urlparse(url, bscheme, allow_fragments)\n if scheme != bscheme or scheme not in uses_relative:\n  return _coerce_result(url)\n if scheme in uses_netloc:\n  if netloc:\n   return _coerce_result(urlunparse((scheme, netloc, path,\n   params, query, fragment)))\n  netloc = bnetloc\n if path[:1] == '/':\n  return _coerce_result(urlunparse((scheme, netloc, path,\n  params, query, fragment)))\n if not path and not params:\n  path = bpath\n  params = bparams\n  if not query:\n   query = bquery\n  return _coerce_result(urlunparse((scheme, netloc, path,\n  params, query, fragment)))\n segments = bpath.split('/')[:-1] + path.split('/')\n \n if segments[-1] == '.':\n  segments[-1] = ''\n while '.' in segments:\n  segments.remove('.')\n while 1:\n  i = 1\n  n = len(segments) - 1\n  while i < n:\n   if (segments[i] == '..'\n   and segments[i-1] not in ('', '..')):\n    del segments[i-1:i+1]\n    break\n   i = i+1\n  else:\n   break\n if segments == ['', '..']:\n  segments[-1] = ''\n elif len(segments) >= 2 and segments[-1] == '..':\n  segments[-2:] = ['']\n return _coerce_result(urlunparse((scheme, netloc, '/'.join(segments),\n params, query, fragment)))\n \ndef urldefrag(url):\n \"\"\n url, _coerce_result = _coerce_args(url)\n if '#' in url:\n  s, n, p, a, q, frag = urlparse(url)\n  defrag = urlunparse((s, n, p, a, q, ''))\n else:\n  frag = ''\n  defrag = url\n return _coerce_result(DefragResult(defrag, frag))\n \n_hexdig = '0123456789ABCDEFabcdef'\n_hextobyte = {(a + b).encode(): bytes([int(a + b, 16)])\nfor a in _hexdig for b in _hexdig}\n\ndef unquote_to_bytes(string):\n \"\"\n \n \n if not string:\n \n  string.split\n  return b''\n if isinstance(string, str):\n  string = string.encode('utf-8')\n bits = string.split(b'%')\n if len(bits) == 1:\n  return string\n res = [bits[0]]\n append = res.append\n for item in bits[1:]:\n  try:\n   append(_hextobyte[item[:2]])\n   append(item[2:])\n  except KeyError:\n   append(b'%')\n   append(item)\n return b''.join(res)\n \n_asciire = re.compile('([\\x00-\\x7f]+)')\n\ndef unquote(string, encoding='utf-8', errors='replace'):\n \"\"\n if '%' not in string:\n  string.split\n  return string\n if encoding is None:\n  encoding = 'utf-8'\n if errors is None:\n  errors = 'replace'\n bits = _asciire.split(string)\n res = [bits[0]]\n append = res.append\n for i in range(1, len(bits), 2):\n  append(unquote_to_bytes(bits[i]).decode(encoding, errors))\n  append(bits[i + 1])\n return ''.join(res)\n \ndef parse_qs(qs, keep_blank_values=False, strict_parsing=False,\nencoding='utf-8', errors='replace'):\n \"\"\n parsed_result = {}\n pairs = parse_qsl(qs, keep_blank_values, strict_parsing,\n encoding=encoding, errors=errors)\n for name, value in pairs:\n  if name in parsed_result:\n   parsed_result[name].append(value)\n  else:\n   parsed_result[name] = [value]\n return parsed_result\n \ndef parse_qsl(qs, keep_blank_values=False, strict_parsing=False,\nencoding='utf-8', errors='replace'):\n \"\"\n qs, _coerce_result = _coerce_args(qs)\n pairs = [s2 for s1 in qs.split('&') for s2 in s1.split(';')]\n r = []\n for name_value in pairs:\n  if not name_value and not strict_parsing:\n   continue\n  nv = name_value.split('=', 1)\n  if len(nv) != 2:\n   if strict_parsing:\n    raise ValueError(\"bad query field: %r\" % (name_value,))\n    \n   if keep_blank_values:\n    nv.append('')\n   else:\n    continue\n  if len(nv[1]) or keep_blank_values:\n   name = nv[0].replace('+', ' ')\n   name = unquote(name, encoding=encoding, errors=errors)\n   name = _coerce_result(name)\n   value = nv[1].replace('+', ' ')\n   value = unquote(value, encoding=encoding, errors=errors)\n   value = _coerce_result(value)\n   r.append((name, value))\n return r\n \ndef unquote_plus(string, encoding='utf-8', errors='replace'):\n \"\"\n string = string.replace('+', ' ')\n return unquote(string, encoding, errors)\n \n_ALWAYS_SAFE = frozenset(b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\nb'abcdefghijklmnopqrstuvwxyz'\nb'0123456789'\nb'_.-')\n_ALWAYS_SAFE_BYTES = bytes(_ALWAYS_SAFE)\n_safe_quoters = {}\n\nclass Quoter(collections.defaultdict):\n \"\"\n \n \n def __init__(self, safe):\n  \"\"\n  self.safe = _ALWAYS_SAFE.union(safe)\n  \n def __repr__(self):\n \n  return \"<Quoter %r>\" % dict(self)\n  \n def __missing__(self, b):\n \n  res = chr(b) if b in self.safe else '%{:02X}'.format(b)\n  self[b] = res\n  return res\n  \ndef quote(string, safe='/', encoding=None, errors=None):\n \"\"\n if isinstance(string, str):\n  if not string:\n   return string\n  if encoding is None:\n   encoding = 'utf-8'\n  if errors is None:\n   errors = 'strict'\n  string = string.encode(encoding, errors)\n else:\n  if encoding is not None:\n   raise TypeError(\"quote() doesn't support 'encoding' for bytes\")\n  if errors is not None:\n   raise TypeError(\"quote() doesn't support 'errors' for bytes\")\n return quote_from_bytes(string, safe)\n \ndef quote_plus(string, safe='', encoding=None, errors=None):\n \"\"\n \n \n if ((isinstance(string, str) and ' ' not in string) or\n (isinstance(string, bytes) and b' ' not in string)):\n  return quote(string, safe, encoding, errors)\n if isinstance(safe, str):\n  space = ' '\n else:\n  space = b' '\n string = quote(string, safe + space, encoding, errors)\n return string.replace(' ', '+')\n \ndef quote_from_bytes(bs, safe='/'):\n \"\"\n if not isinstance(bs, (bytes, bytearray)):\n  raise TypeError(\"quote_from_bytes() expected bytes\")\n if not bs:\n  return ''\n if isinstance(safe, str):\n \n  safe = safe.encode('ascii', 'ignore')\n else:\n  safe = bytes([c for c in safe if c < 128])\n if not bs.rstrip(_ALWAYS_SAFE_BYTES + safe):\n  return bs.decode()\n try:\n  quoter = _safe_quoters[safe]\n except KeyError:\n  _safe_quoters[safe] = quoter = Quoter(safe).__getitem__\n return ''.join([quoter(char) for char in bs])\n \ndef urlencode(query, doseq=False, safe='', encoding=None, errors=None):\n \"\"\n \n if hasattr(query, \"items\"):\n  query = query.items()\n else:\n \n \n  try:\n  \n  \n   if len(query) and not isinstance(query[0], tuple):\n    raise TypeError\n    \n    \n    \n    \n  except TypeError:\n   ty, va, tb = sys.exc_info()\n   raise TypeError(\"not a valid non-string sequence \"\n   \"or mapping object\").with_traceback(tb)\n   \n l = []\n if not doseq:\n  for k, v in query:\n   if isinstance(k, bytes):\n    k = quote_plus(k, safe)\n   else:\n    k = quote_plus(str(k), safe, encoding, errors)\n    \n   if isinstance(v, bytes):\n    v = quote_plus(v, safe)\n   else:\n    v = quote_plus(str(v), safe, encoding, errors)\n   l.append(k + '=' + v)\n else:\n  for k, v in query:\n   if isinstance(k, bytes):\n    k = quote_plus(k, safe)\n   else:\n    k = quote_plus(str(k), safe, encoding, errors)\n    \n   if isinstance(v, bytes):\n    v = quote_plus(v, safe)\n    l.append(k + '=' + v)\n   elif isinstance(v, str):\n    v = quote_plus(v, safe, encoding, errors)\n    l.append(k + '=' + v)\n   else:\n    try:\n    \n     x = len(v)\n    except TypeError:\n    \n     v = quote_plus(str(v), safe, encoding, errors)\n     l.append(k + '=' + v)\n    else:\n    \n     for elt in v:\n      if isinstance(elt, bytes):\n       elt = quote_plus(elt, safe)\n      else:\n       elt = quote_plus(str(elt), safe, encoding, errors)\n      l.append(k + '=' + elt)\n return '&'.join(l)\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \ndef to_bytes(url):\n \"\"\n \n \n \n if isinstance(url, str):\n  try:\n   url = url.encode(\"ASCII\").decode()\n  except UnicodeError:\n   raise UnicodeError(\"URL \" + repr(url) +\n   \" contains non-ASCII characters\")\n return url\n \ndef unwrap(url):\n \"\"\n url = str(url).strip()\n if url[:1] == '<' and url[-1:] == '>':\n  url = url[1:-1].strip()\n if url[:4] == 'URL:': url = url[4:].strip()\n return url\n \n_typeprog = None\ndef splittype(url):\n \"\"\n global _typeprog\n if _typeprog is None:\n  import re\n  _typeprog = re.compile('^([^/:]+):')\n  \n match = _typeprog.match(url)\n if match:\n  scheme = match.group(1)\n  return scheme.lower(), url[len(scheme) + 1:]\n return None, url\n \n_hostprog = None\ndef splithost(url):\n \"\"\n global _hostprog\n if _hostprog is None:\n  import re\n  _hostprog = re.compile('^//([^/?]*)(.*)$')\n  \n match = _hostprog.match(url)\n if match:\n  host_port = match.group(1)\n  path = match.group(2)\n  if path and not path.startswith('/'):\n   path = '/' + path\n  return host_port, path\n return None, url\n \n_userprog = None\ndef splituser(host):\n \"\"\n global _userprog\n if _userprog is None:\n  import re\n  _userprog = re.compile('^(.*)@(.*)$')\n  \n match = _userprog.match(host)\n if match: return match.group(1, 2)\n return None, host\n \n_passwdprog = None\ndef splitpasswd(user):\n \"\"\n global _passwdprog\n if _passwdprog is None:\n  import re\n  _passwdprog = re.compile('^([^:]*):(.*)$',re.S)\n  \n match = _passwdprog.match(user)\n if match: return match.group(1, 2)\n return user, None\n \n \n_portprog = None\ndef splitport(host):\n \"\"\n global _portprog\n if _portprog is None:\n  import re\n  _portprog = re.compile('^(.*):([0-9]+)$')\n  \n match = _portprog.match(host)\n if match: return match.group(1, 2)\n return host, None\n \n_nportprog = None\ndef splitnport(host, defport=-1):\n \"\"\n global _nportprog\n if _nportprog is None:\n  import re\n  _nportprog = re.compile('^(.*):(.*)$')\n  \n match = _nportprog.match(host)\n if match:\n  host, port = match.group(1, 2)\n  try:\n   if not port: raise ValueError(\"no digits\")\n   nport = int(port)\n  except ValueError:\n   nport = None\n  return host, nport\n return host, defport\n \n_queryprog = None\ndef splitquery(url):\n \"\"\n global _queryprog\n if _queryprog is None:\n  import re\n  _queryprog = re.compile('^(.*)\\?([^?]*)$')\n  \n match = _queryprog.match(url)\n if match: return match.group(1, 2)\n return url, None\n \n_tagprog = None\ndef splittag(url):\n \"\"\n global _tagprog\n if _tagprog is None:\n  import re\n  _tagprog = re.compile('^(.*)#([^#]*)$')\n  \n match = _tagprog.match(url)\n if match: return match.group(1, 2)\n return url, None\n \ndef splitattr(url):\n \"\"\n words = url.split(';')\n return words[0], words[1:]\n \n_valueprog = None\ndef splitvalue(attr):\n \"\"\n global _valueprog\n if _valueprog is None:\n  import re\n  _valueprog = re.compile('^([^=]*)=(.*)$')\n  \n match = _valueprog.match(attr)\n if match: return match.group(1, 2)\n return attr, None\n"], "unittest.mock": [".py", "\n\n\n\n\n\n__all__ = (\n'Mock',\n'MagicMock',\n'patch',\n'sentinel',\n'DEFAULT',\n'ANY',\n'call',\n'create_autospec',\n'FILTER_DIR',\n'NonCallableMock',\n'NonCallableMagicMock',\n'mock_open',\n'PropertyMock',\n)\n\n\n__version__ = '1.0'\n\n\nimport inspect\nimport pprint\nimport sys\nfrom functools import wraps\n\n\nBaseExceptions = (BaseException,)\nif 'java' in sys.platform:\n\n import java\n BaseExceptions = (BaseException, java.lang.Throwable)\n \n \nFILTER_DIR = True\n\n\n\n_safe_super = super\n\ndef _is_instance_mock(obj):\n\n\n return issubclass(type(obj), NonCallableMock)\n \n \ndef _is_exception(obj):\n return (\n isinstance(obj, BaseExceptions) or\n isinstance(obj, type) and issubclass(obj, BaseExceptions)\n )\n \n \nclass _slotted(object):\n __slots__ = ['a']\n \n \nDescriptorTypes = (\ntype(_slotted.a),\nproperty,\n)\n\n\ndef _getsignature(func, skipfirst, instance=False):\n if isinstance(func, type) and not instance:\n  try:\n   func = func.__init__\n  except AttributeError:\n   return\n  skipfirst = True\n elif not isinstance(func, FunctionTypes):\n \n  try:\n   func = func.__call__\n  except AttributeError:\n   return\n   \n try:\n  argspec = inspect.getfullargspec(func)\n except TypeError:\n \n  return\n  \n regargs, varargs, varkw, defaults, kwonly, kwonlydef, ann = argspec\n \n \n \n if getattr(func, '__self__', None) is not None:\n  regargs = regargs[1:]\n if skipfirst:\n \n  regargs = regargs[1:]\n  \n signature = inspect.formatargspec(\n regargs, varargs, varkw, defaults,\n kwonly, kwonlydef, ann, formatvalue=lambda value: \"\")\n return signature[1:-1], func\n \n \ndef _check_signature(func, mock, skipfirst, instance=False):\n if not _callable(func):\n  return\n  \n result = _getsignature(func, skipfirst, instance)\n if result is None:\n  return\n signature, func = result\n \n \n \n src = \"lambda _mock_self, %s: None\" % signature\n checksig = eval(src, {})\n _copy_func_details(func, checksig)\n type(mock)._mock_check_sig = checksig\n \n \ndef _copy_func_details(func, funcopy):\n funcopy.__name__ = func.__name__\n funcopy.__doc__ = func.__doc__\n \n \n funcopy.__module__ = func.__module__\n funcopy.__defaults__ = func.__defaults__\n funcopy.__kwdefaults__ = func.__kwdefaults__\n \n \ndef _callable(obj):\n if isinstance(obj, type):\n  return True\n if getattr(obj, '__call__', None) is not None:\n  return True\n return False\n \n \ndef _is_list(obj):\n\n\n return type(obj) in (list, tuple)\n \n \ndef _instance_callable(obj):\n \"\"\n if not isinstance(obj, type):\n \n  return getattr(obj, '__call__', None) is not None\n  \n  \n  \n for base in (obj,) + obj.__mro__:\n  if base.__dict__.get('__call__') is not None:\n   return True\n return False\n \n \ndef _set_signature(mock, original, instance=False):\n\n\n\n if not _callable(original):\n  return\n  \n skipfirst = isinstance(original, type)\n result = _getsignature(original, skipfirst, instance)\n if result is None:\n \n  return\n  \n signature, func = result\n \n src = \"lambda %s: None\" % signature\n checksig = eval(src, {})\n _copy_func_details(func, checksig)\n \n name = original.__name__\n if not name.isidentifier():\n  name = 'funcopy'\n context = {'_checksig_': checksig, 'mock': mock}\n src = \"\"\"def %s(*args, **kwargs):\n    _checksig_(*args, **kwargs)\n    return mock(*args, **kwargs)\"\"\" % name\n exec (src, context)\n funcopy = context[name]\n _setup_func(funcopy, mock)\n return funcopy\n \n \ndef _setup_func(funcopy, mock):\n funcopy.mock = mock\n \n \n if not _is_instance_mock(mock):\n  return\n  \n def assert_called_with(*args, **kwargs):\n  return mock.assert_called_with(*args, **kwargs)\n def assert_called_once_with(*args, **kwargs):\n  return mock.assert_called_once_with(*args, **kwargs)\n def assert_has_calls(*args, **kwargs):\n  return mock.assert_has_calls(*args, **kwargs)\n def assert_any_call(*args, **kwargs):\n  return mock.assert_any_call(*args, **kwargs)\n def reset_mock():\n  funcopy.method_calls = _CallList()\n  funcopy.mock_calls = _CallList()\n  mock.reset_mock()\n  ret = funcopy.return_value\n  if _is_instance_mock(ret) and not ret is mock:\n   ret.reset_mock()\n   \n funcopy.called = False\n funcopy.call_count = 0\n funcopy.call_args = None\n funcopy.call_args_list = _CallList()\n funcopy.method_calls = _CallList()\n funcopy.mock_calls = _CallList()\n \n funcopy.return_value = mock.return_value\n funcopy.side_effect = mock.side_effect\n funcopy._mock_children = mock._mock_children\n \n funcopy.assert_called_with = assert_called_with\n funcopy.assert_called_once_with = assert_called_once_with\n funcopy.assert_has_calls = assert_has_calls\n funcopy.assert_any_call = assert_any_call\n funcopy.reset_mock = reset_mock\n \n mock._mock_delegate = funcopy\n \n \ndef _is_magic(name):\n return '__%s__' % name[2:-2] == name\n \n \nclass _SentinelObject(object):\n \"\"\n def __init__(self, name):\n  self.name = name\n  \n def __repr__(self):\n  return 'sentinel.%s' % self.name\n  \n  \nclass _Sentinel(object):\n \"\"\n def __init__(self):\n  self._sentinels = {}\n  \n def __getattr__(self, name):\n  if name == '__bases__':\n  \n   raise AttributeError\n  return self._sentinels.setdefault(name, _SentinelObject(name))\n  \n  \nsentinel = _Sentinel()\n\nDEFAULT = sentinel.DEFAULT\n_missing = sentinel.MISSING\n_deleted = sentinel.DELETED\n\n\ndef _copy(value):\n if type(value) in (dict, list, tuple, set):\n  return type(value)(value)\n return value\n \n \n_allowed_names = set(\n[\n'return_value', '_mock_return_value', 'side_effect',\n'_mock_side_effect', '_mock_parent', '_mock_new_parent',\n'_mock_name', '_mock_new_name'\n]\n)\n\n\ndef _delegating_property(name):\n _allowed_names.add(name)\n _the_name = '_mock_' + name\n def _get(self, name=name, _the_name=_the_name):\n  sig = self._mock_delegate\n  if sig is None:\n   return getattr(self, _the_name)\n  return getattr(sig, name)\n def _set(self, value, name=name, _the_name=_the_name):\n  sig = self._mock_delegate\n  if sig is None:\n   self.__dict__[_the_name] = value\n  else:\n   setattr(sig, name, value)\n   \n return property(_get, _set)\n \n \n \nclass _CallList(list):\n\n def __contains__(self, value):\n  if not isinstance(value, list):\n   return list.__contains__(self, value)\n  len_value = len(value)\n  len_self = len(self)\n  if len_value > len_self:\n   return False\n   \n  for i in range(0, len_self - len_value + 1):\n   sub_list = self[i:i+len_value]\n   if sub_list == value:\n    return True\n  return False\n  \n def __repr__(self):\n  return pprint.pformat(list(self))\n  \n  \ndef _check_and_set_parent(parent, value, name, new_name):\n if not _is_instance_mock(value):\n  return False\n if ((value._mock_name or value._mock_new_name) or\n (value._mock_parent is not None) or\n (value._mock_new_parent is not None)):\n  return False\n  \n _parent = parent\n while _parent is not None:\n \n \n  if _parent is value:\n   return False\n  _parent = _parent._mock_new_parent\n  \n if new_name:\n  value._mock_new_parent = parent\n  value._mock_new_name = new_name\n if name:\n  value._mock_parent = parent\n  value._mock_name = name\n return True\n \n \n \nclass Base(object):\n _mock_return_value = DEFAULT\n _mock_side_effect = None\n def __init__(self, *args, **kwargs):\n  pass\n  \n  \n  \nclass NonCallableMock(Base):\n \"\"\n \n def __new__(cls, *args, **kw):\n \n \n \n  new = type(cls.__name__, (cls,), {'__doc__': cls.__doc__})\n  instance = object.__new__(new)\n  return instance\n  \n  \n def __init__(\n self, spec=None, wraps=None, name=None, spec_set=None,\n parent=None, _spec_state=None, _new_name='', _new_parent=None,\n **kwargs\n ):\n  if _new_parent is None:\n   _new_parent = parent\n   \n  __dict__ = self.__dict__\n  __dict__['_mock_parent'] = parent\n  __dict__['_mock_name'] = name\n  __dict__['_mock_new_name'] = _new_name\n  __dict__['_mock_new_parent'] = _new_parent\n  \n  if spec_set is not None:\n   spec = spec_set\n   spec_set = True\n   \n  self._mock_add_spec(spec, spec_set)\n  \n  __dict__['_mock_children'] = {}\n  __dict__['_mock_wraps'] = wraps\n  __dict__['_mock_delegate'] = None\n  \n  __dict__['_mock_called'] = False\n  __dict__['_mock_call_args'] = None\n  __dict__['_mock_call_count'] = 0\n  __dict__['_mock_call_args_list'] = _CallList()\n  __dict__['_mock_mock_calls'] = _CallList()\n  \n  __dict__['method_calls'] = _CallList()\n  \n  if kwargs:\n   self.configure_mock(**kwargs)\n   \n  _safe_super(NonCallableMock, self).__init__(\n  spec, wraps, name, spec_set, parent,\n  _spec_state\n  )\n  \n  \n def attach_mock(self, mock, attribute):\n  \"\"\n  mock._mock_parent = None\n  mock._mock_new_parent = None\n  mock._mock_name = ''\n  mock._mock_new_name = None\n  \n  setattr(self, attribute, mock)\n  \n  \n def mock_add_spec(self, spec, spec_set=False):\n  \"\"\n  self._mock_add_spec(spec, spec_set)\n  \n  \n def _mock_add_spec(self, spec, spec_set):\n  _spec_class = None\n  \n  if spec is not None and not _is_list(spec):\n   if isinstance(spec, type):\n    _spec_class = spec\n   else:\n    _spec_class = _get_class(spec)\n    \n   spec = dir(spec)\n   \n  __dict__ = self.__dict__\n  __dict__['_spec_class'] = _spec_class\n  __dict__['_spec_set'] = spec_set\n  __dict__['_mock_methods'] = spec\n  \n  \n def __get_return_value(self):\n  ret = self._mock_return_value\n  if self._mock_delegate is not None:\n   ret = self._mock_delegate.return_value\n   \n  if ret is DEFAULT:\n   ret = self._get_child_mock(\n   _new_parent=self, _new_name='()'\n   )\n   self.return_value = ret\n  return ret\n  \n  \n def __set_return_value(self, value):\n  if self._mock_delegate is not None:\n   self._mock_delegate.return_value = value\n  else:\n   self._mock_return_value = value\n   _check_and_set_parent(self, value, None, '()')\n   \n __return_value_doc = \"The value to be returned when the mock is called.\"\n return_value = property(__get_return_value, __set_return_value,\n __return_value_doc)\n \n \n @property\n def __class__(self):\n  if self._spec_class is None:\n   return type(self)\n  return self._spec_class\n  \n called = _delegating_property('called')\n call_count = _delegating_property('call_count')\n call_args = _delegating_property('call_args')\n call_args_list = _delegating_property('call_args_list')\n mock_calls = _delegating_property('mock_calls')\n \n \n def __get_side_effect(self):\n  delegated = self._mock_delegate\n  if delegated is None:\n   return self._mock_side_effect\n  return delegated.side_effect\n  \n def __set_side_effect(self, value):\n  value = _try_iter(value)\n  delegated = self._mock_delegate\n  if delegated is None:\n   self._mock_side_effect = value\n  else:\n   delegated.side_effect = value\n   \n side_effect = property(__get_side_effect, __set_side_effect)\n \n \n def reset_mock(self):\n  \"\"\n  self.called = False\n  self.call_args = None\n  self.call_count = 0\n  self.mock_calls = _CallList()\n  self.call_args_list = _CallList()\n  self.method_calls = _CallList()\n  \n  for child in self._mock_children.values():\n   if isinstance(child, _SpecState):\n    continue\n   child.reset_mock()\n   \n  ret = self._mock_return_value\n  if _is_instance_mock(ret) and ret is not self:\n   ret.reset_mock()\n   \n   \n def configure_mock(self, **kwargs):\n  \"\"\n  for arg, val in sorted(kwargs.items(),\n  \n  \n  \n  key=lambda entry: entry[0].count('.')):\n   args = arg.split('.')\n   final = args.pop()\n   obj = self\n   for entry in args:\n    obj = getattr(obj, entry)\n   setattr(obj, final, val)\n   \n   \n def __getattr__(self, name):\n  if name == '_mock_methods':\n   raise AttributeError(name)\n  elif self._mock_methods is not None:\n   if name not in self._mock_methods or name in _all_magics:\n    raise AttributeError(\"Mock object has no attribute %r\" % name)\n  elif _is_magic(name):\n   raise AttributeError(name)\n   \n  result = self._mock_children.get(name)\n  if result is _deleted:\n   raise AttributeError(name)\n  elif result is None:\n   wraps = None\n   if self._mock_wraps is not None:\n   \n   \n    wraps = getattr(self._mock_wraps, name)\n    \n   result = self._get_child_mock(\n   parent=self, name=name, wraps=wraps, _new_name=name,\n   _new_parent=self\n   )\n   self._mock_children[name] = result\n   \n  elif isinstance(result, _SpecState):\n   result = create_autospec(\n   result.spec, result.spec_set, result.instance,\n   result.parent, result.name\n   )\n   self._mock_children[name] = result\n   \n  return result\n  \n  \n def __repr__(self):\n  _name_list = [self._mock_new_name]\n  _parent = self._mock_new_parent\n  last = self\n  \n  dot = '.'\n  if _name_list == ['()']:\n   dot = ''\n  seen = set()\n  while _parent is not None:\n   last = _parent\n   \n   _name_list.append(_parent._mock_new_name + dot)\n   dot = '.'\n   if _parent._mock_new_name == '()':\n    dot = ''\n    \n   _parent = _parent._mock_new_parent\n   \n   \n   if id(_parent) in seen:\n    break\n   seen.add(id(_parent))\n   \n  _name_list = list(reversed(_name_list))\n  _first = last._mock_name or 'mock'\n  if len(_name_list) > 1:\n   if _name_list[1] not in ('()', '().'):\n    _first += '.'\n  _name_list[0] = _first\n  name = ''.join(_name_list)\n  \n  name_string = ''\n  if name not in ('mock', 'mock.'):\n   name_string = ' name=%r' % name\n   \n  spec_string = ''\n  if self._spec_class is not None:\n   spec_string = ' spec=%r'\n   if self._spec_set:\n    spec_string = ' spec_set=%r'\n   spec_string = spec_string % self._spec_class.__name__\n  return \"<%s%s%s id='%s'>\" % (\n  type(self).__name__,\n  name_string,\n  spec_string,\n  id(self)\n  )\n  \n  \n def __dir__(self):\n  \"\"\n  if not FILTER_DIR:\n   return object.__dir__(self)\n   \n  extras = self._mock_methods or []\n  from_type = dir(type(self))\n  from_dict = list(self.__dict__)\n  \n  from_type = [e for e in from_type if not e.startswith('_')]\n  from_dict = [e for e in from_dict if not e.startswith('_') or\n  _is_magic(e)]\n  return sorted(set(extras + from_type + from_dict +\n  list(self._mock_children)))\n  \n  \n def __setattr__(self, name, value):\n  if name in _allowed_names:\n  \n   return object.__setattr__(self, name, value)\n  elif (self._spec_set and self._mock_methods is not None and\n  name not in self._mock_methods and\n  name not in self.__dict__):\n   raise AttributeError(\"Mock object has no attribute '%s'\" % name)\n  elif name in _unsupported_magics:\n   msg = 'Attempting to set unsupported magic method %r.' % name\n   raise AttributeError(msg)\n  elif name in _all_magics:\n   if self._mock_methods is not None and name not in self._mock_methods:\n    raise AttributeError(\"Mock object has no attribute '%s'\" % name)\n    \n   if not _is_instance_mock(value):\n    setattr(type(self), name, _get_method(name, value))\n    original = value\n    value = lambda *args, **kw: original(self, *args, **kw)\n   else:\n   \n   \n    _check_and_set_parent(self, value, None, name)\n    setattr(type(self), name, value)\n    self._mock_children[name] = value\n  elif name == '__class__':\n   self._spec_class = value\n   return\n  else:\n   if _check_and_set_parent(self, value, name, name):\n    self._mock_children[name] = value\n  return object.__setattr__(self, name, value)\n  \n  \n def __delattr__(self, name):\n  if name in _all_magics and name in type(self).__dict__:\n   delattr(type(self), name)\n   if name not in self.__dict__:\n   \n   \n    return\n    \n  if name in self.__dict__:\n   object.__delattr__(self, name)\n   \n  obj = self._mock_children.get(name, _missing)\n  if obj is _deleted:\n   raise AttributeError(name)\n  if obj is not _missing:\n   del self._mock_children[name]\n  self._mock_children[name] = _deleted\n  \n  \n  \n def _format_mock_call_signature(self, args, kwargs):\n  name = self._mock_name or 'mock'\n  return _format_call_signature(name, args, kwargs)\n  \n  \n def _format_mock_failure_message(self, args, kwargs):\n  message = 'Expected call: %s\\nActual call: %s'\n  expected_string = self._format_mock_call_signature(args, kwargs)\n  call_args = self.call_args\n  if len(call_args) == 3:\n   call_args = call_args[1:]\n  actual_string = self._format_mock_call_signature(*call_args)\n  return message % (expected_string, actual_string)\n  \n  \n def assert_called_with(_mock_self, *args, **kwargs):\n  \"\"\n  self = _mock_self\n  if self.call_args is None:\n   expected = self._format_mock_call_signature(args, kwargs)\n   raise AssertionError('Expected call: %s\\nNot called' % (expected,))\n   \n  if self.call_args != (args, kwargs):\n   msg = self._format_mock_failure_message(args, kwargs)\n   raise AssertionError(msg)\n   \n   \n def assert_called_once_with(_mock_self, *args, **kwargs):\n  \"\"\n  self = _mock_self\n  if not self.call_count == 1:\n   msg = (\"Expected '%s' to be called once. Called %s times.\" %\n   (self._mock_name or 'mock', self.call_count))\n   raise AssertionError(msg)\n  return self.assert_called_with(*args, **kwargs)\n  \n  \n def assert_has_calls(self, calls, any_order=False):\n  \"\"\n  if not any_order:\n   if calls not in self.mock_calls:\n    raise AssertionError(\n    'Calls not found.\\nExpected: %r\\n'\n    'Actual: %r' % (calls, self.mock_calls)\n    )\n   return\n   \n  all_calls = list(self.mock_calls)\n  \n  not_found = []\n  for kall in calls:\n   try:\n    all_calls.remove(kall)\n   except ValueError:\n    not_found.append(kall)\n  if not_found:\n   raise AssertionError(\n   '%r not all found in call list' % (tuple(not_found),)\n   )\n   \n   \n def assert_any_call(self, *args, **kwargs):\n  \"\"\n  kall = call(*args, **kwargs)\n  if kall not in self.call_args_list:\n   expected_string = self._format_mock_call_signature(args, kwargs)\n   raise AssertionError(\n   '%s call not found' % expected_string\n   )\n   \n   \n def _get_child_mock(self, **kw):\n  \"\"\n  _type = type(self)\n  if not issubclass(_type, CallableMixin):\n   if issubclass(_type, NonCallableMagicMock):\n    klass = MagicMock\n   elif issubclass(_type, NonCallableMock) :\n    klass = Mock\n  else:\n   klass = _type.__mro__[1]\n  return klass(**kw)\n  \n  \n  \ndef _try_iter(obj):\n if obj is None:\n  return obj\n if _is_exception(obj):\n  return obj\n if _callable(obj):\n  return obj\n try:\n  return iter(obj)\n except TypeError:\n \n \n  return obj\n  \n  \n  \nclass CallableMixin(Base):\n\n def __init__(self, spec=None, side_effect=None, return_value=DEFAULT,\n wraps=None, name=None, spec_set=None, parent=None,\n _spec_state=None, _new_name='', _new_parent=None, **kwargs):\n  self.__dict__['_mock_return_value'] = return_value\n  \n  _safe_super(CallableMixin, self).__init__(\n  spec, wraps, name, spec_set, parent,\n  _spec_state, _new_name, _new_parent, **kwargs\n  )\n  \n  self.side_effect = side_effect\n  \n  \n def _mock_check_sig(self, *args, **kwargs):\n \n  pass\n  \n  \n def __call__(_mock_self, *args, **kwargs):\n \n \n  _mock_self._mock_check_sig(*args, **kwargs)\n  return _mock_self._mock_call(*args, **kwargs)\n  \n  \n def _mock_call(_mock_self, *args, **kwargs):\n  self = _mock_self\n  self.called = True\n  self.call_count += 1\n  self.call_args = _Call((args, kwargs), two=True)\n  self.call_args_list.append(_Call((args, kwargs), two=True))\n  \n  _new_name = self._mock_new_name\n  _new_parent = self._mock_new_parent\n  self.mock_calls.append(_Call(('', args, kwargs)))\n  \n  seen = set()\n  skip_next_dot = _new_name == '()'\n  do_method_calls = self._mock_parent is not None\n  name = self._mock_name\n  while _new_parent is not None:\n   this_mock_call = _Call((_new_name, args, kwargs))\n   if _new_parent._mock_new_name:\n    dot = '.'\n    if skip_next_dot:\n     dot = ''\n     \n    skip_next_dot = False\n    if _new_parent._mock_new_name == '()':\n     skip_next_dot = True\n     \n    _new_name = _new_parent._mock_new_name + dot + _new_name\n    \n   if do_method_calls:\n    if _new_name == name:\n     this_method_call = this_mock_call\n    else:\n     this_method_call = _Call((name, args, kwargs))\n    _new_parent.method_calls.append(this_method_call)\n    \n    do_method_calls = _new_parent._mock_parent is not None\n    if do_method_calls:\n     name = _new_parent._mock_name + '.' + name\n     \n   _new_parent.mock_calls.append(this_mock_call)\n   _new_parent = _new_parent._mock_new_parent\n   \n   \n   _new_parent_id = id(_new_parent)\n   if _new_parent_id in seen:\n    break\n   seen.add(_new_parent_id)\n   \n  ret_val = DEFAULT\n  effect = self.side_effect\n  if effect is not None:\n   if _is_exception(effect):\n    raise effect\n    \n   if not _callable(effect):\n    result = next(effect)\n    if _is_exception(result):\n     raise result\n    if result is DEFAULT:\n     result = self.return_value\n    return result\n    \n   ret_val = effect(*args, **kwargs)\n   if ret_val is DEFAULT:\n    ret_val = self.return_value\n    \n  if (self._mock_wraps is not None and\n  self._mock_return_value is DEFAULT):\n   return self._mock_wraps(*args, **kwargs)\n  if ret_val is DEFAULT:\n   ret_val = self.return_value\n  return ret_val\n  \n  \n  \nclass Mock(CallableMixin, NonCallableMock):\n \"\"\n \n \n \ndef _dot_lookup(thing, comp, import_path):\n try:\n  return getattr(thing, comp)\n except AttributeError:\n  __import__(import_path)\n  return getattr(thing, comp)\n  \n  \ndef _importer(target):\n components = target.split('.')\n import_path = components.pop(0)\n thing = __import__(import_path)\n \n for comp in components:\n  import_path += \".%s\" % comp\n  thing = _dot_lookup(thing, comp, import_path)\n return thing\n \n \ndef _is_started(patcher):\n\n return hasattr(patcher, 'is_local')\n \n \nclass _patch(object):\n\n attribute_name = None\n _active_patches = set()\n \n def __init__(\n self, getter, attribute, new, spec, create,\n spec_set, autospec, new_callable, kwargs\n ):\n  if new_callable is not None:\n   if new is not DEFAULT:\n    raise ValueError(\n    \"Cannot use 'new' and 'new_callable' together\"\n    )\n   if autospec is not None:\n    raise ValueError(\n    \"Cannot use 'autospec' and 'new_callable' together\"\n    )\n    \n  self.getter = getter\n  self.attribute = attribute\n  self.new = new\n  self.new_callable = new_callable\n  self.spec = spec\n  self.create = create\n  self.has_local = False\n  self.spec_set = spec_set\n  self.autospec = autospec\n  self.kwargs = kwargs\n  self.additional_patchers = []\n  \n  \n def copy(self):\n  patcher = _patch(\n  self.getter, self.attribute, self.new, self.spec,\n  self.create, self.spec_set,\n  self.autospec, self.new_callable, self.kwargs\n  )\n  patcher.attribute_name = self.attribute_name\n  patcher.additional_patchers = [\n  p.copy() for p in self.additional_patchers\n  ]\n  return patcher\n  \n  \n def __call__(self, func):\n  if isinstance(func, type):\n   return self.decorate_class(func)\n  return self.decorate_callable(func)\n  \n  \n def decorate_class(self, klass):\n  for attr in dir(klass):\n   if not attr.startswith(patch.TEST_PREFIX):\n    continue\n    \n   attr_value = getattr(klass, attr)\n   if not hasattr(attr_value, \"__call__\"):\n    continue\n    \n   patcher = self.copy()\n   setattr(klass, attr, patcher(attr_value))\n  return klass\n  \n  \n def decorate_callable(self, func):\n  if hasattr(func, 'patchings'):\n   func.patchings.append(self)\n   return func\n   \n  @wraps(func)\n  def patched(*args, **keywargs):\n   extra_args = []\n   entered_patchers = []\n   \n   exc_info = tuple()\n   try:\n    for patching in patched.patchings:\n     arg = patching.__enter__()\n     entered_patchers.append(patching)\n     if patching.attribute_name is not None:\n      keywargs.update(arg)\n     elif patching.new is DEFAULT:\n      extra_args.append(arg)\n      \n    args += tuple(extra_args)\n    return func(*args, **keywargs)\n   except:\n    if (patching not in entered_patchers and\n    _is_started(patching)):\n    \n    \n     entered_patchers.append(patching)\n     \n    exc_info = sys.exc_info()\n    \n    raise\n   finally:\n    for patching in reversed(entered_patchers):\n     patching.__exit__(*exc_info)\n     \n  patched.patchings = [self]\n  return patched\n  \n  \n def get_original(self):\n  target = self.getter()\n  name = self.attribute\n  \n  original = DEFAULT\n  local = False\n  \n  try:\n   original = target.__dict__[name]\n  except (AttributeError, KeyError):\n   original = getattr(target, name, DEFAULT)\n  else:\n   local = True\n   \n  if not self.create and original is DEFAULT:\n   raise AttributeError(\n   \"%s does not have the attribute %r\" % (target, name)\n   )\n  return original, local\n  \n  \n def __enter__(self):\n  \"\"\n  new, spec, spec_set = self.new, self.spec, self.spec_set\n  autospec, kwargs = self.autospec, self.kwargs\n  new_callable = self.new_callable\n  self.target = self.getter()\n  \n  \n  if spec is False:\n   spec = None\n  if spec_set is False:\n   spec_set = None\n  if autospec is False:\n   autospec = None\n   \n  if spec is not None and autospec is not None:\n   raise TypeError(\"Can't specify spec and autospec\")\n  if ((spec is not None or autospec is not None) and\n  spec_set not in (True, None)):\n   raise TypeError(\"Can't provide explicit spec_set *and* spec or autospec\")\n   \n  original, local = self.get_original()\n  \n  if new is DEFAULT and autospec is None:\n   inherit = False\n   if spec is True:\n   \n    spec = original\n    if spec_set is True:\n     spec_set = original\n     spec = None\n   elif spec is not None:\n    if spec_set is True:\n     spec_set = spec\n     spec = None\n   elif spec_set is True:\n    spec_set = original\n    \n   if spec is not None or spec_set is not None:\n    if original is DEFAULT:\n     raise TypeError(\"Can't use 'spec' with create=True\")\n    if isinstance(original, type):\n    \n     inherit = True\n     \n   Klass = MagicMock\n   _kwargs = {}\n   if new_callable is not None:\n    Klass = new_callable\n   elif spec is not None or spec_set is not None:\n    this_spec = spec\n    if spec_set is not None:\n     this_spec = spec_set\n    if _is_list(this_spec):\n     not_callable = '__call__' not in this_spec\n    else:\n     not_callable = not callable(this_spec)\n    if not_callable:\n     Klass = NonCallableMagicMock\n     \n   if spec is not None:\n    _kwargs['spec'] = spec\n   if spec_set is not None:\n    _kwargs['spec_set'] = spec_set\n    \n    \n   if (isinstance(Klass, type) and\n   issubclass(Klass, NonCallableMock) and self.attribute):\n    _kwargs['name'] = self.attribute\n    \n   _kwargs.update(kwargs)\n   new = Klass(**_kwargs)\n   \n   if inherit and _is_instance_mock(new):\n   \n   \n    this_spec = spec\n    if spec_set is not None:\n     this_spec = spec_set\n    if (not _is_list(this_spec) and not\n    _instance_callable(this_spec)):\n     Klass = NonCallableMagicMock\n     \n    _kwargs.pop('name')\n    new.return_value = Klass(_new_parent=new, _new_name='()',\n    **_kwargs)\n  elif autospec is not None:\n  \n  \n  \n   if new is not DEFAULT:\n    raise TypeError(\n    \"autospec creates the mock for you. Can't specify \"\n    \"autospec and new.\"\n    )\n   if original is DEFAULT:\n    raise TypeError(\"Can't use 'autospec' with create=True\")\n   spec_set = bool(spec_set)\n   if autospec is True:\n    autospec = original\n    \n   new = create_autospec(autospec, spec_set=spec_set,\n   _name=self.attribute, **kwargs)\n  elif kwargs:\n  \n  \n   raise TypeError(\"Can't pass kwargs to a mock we aren't creating\")\n   \n  new_attr = new\n  \n  self.temp_original = original\n  self.is_local = local\n  setattr(self.target, self.attribute, new_attr)\n  if self.attribute_name is not None:\n   extra_args = {}\n   if self.new is DEFAULT:\n    extra_args[self.attribute_name] = new\n   for patching in self.additional_patchers:\n    arg = patching.__enter__()\n    if patching.new is DEFAULT:\n     extra_args.update(arg)\n   return extra_args\n   \n  return new\n  \n  \n def __exit__(self, *exc_info):\n  \"\"\n  if not _is_started(self):\n   raise RuntimeError('stop called on unstarted patcher')\n   \n  if self.is_local and self.temp_original is not DEFAULT:\n   setattr(self.target, self.attribute, self.temp_original)\n  else:\n   delattr(self.target, self.attribute)\n   if not self.create and not hasattr(self.target, self.attribute):\n   \n    setattr(self.target, self.attribute, self.temp_original)\n    \n  del self.temp_original\n  del self.is_local\n  del self.target\n  for patcher in reversed(self.additional_patchers):\n   if _is_started(patcher):\n    patcher.__exit__(*exc_info)\n    \n    \n def start(self):\n  \"\"\n  result = self.__enter__()\n  self._active_patches.add(self)\n  return result\n  \n  \n def stop(self):\n  \"\"\n  self._active_patches.discard(self)\n  return self.__exit__()\n  \n  \n  \ndef _get_target(target):\n try:\n  target, attribute = target.rsplit('.', 1)\n except (TypeError, ValueError):\n  raise TypeError(\"Need a valid target to patch. You supplied: %r\" %\n  (target,))\n getter = lambda: _importer(target)\n return getter, attribute\n \n \ndef _patch_object(\ntarget, attribute, new=DEFAULT, spec=None,\ncreate=False, spec_set=None, autospec=None,\nnew_callable=None, **kwargs\n):\n \"\"\n getter = lambda: target\n return _patch(\n getter, attribute, new, spec, create,\n spec_set, autospec, new_callable, kwargs\n )\n \n \ndef _patch_multiple(target, spec=None, create=False, spec_set=None,\nautospec=None, new_callable=None, **kwargs):\n \"\"\n if type(target) is str:\n  getter = lambda: _importer(target)\n else:\n  getter = lambda: target\n  \n if not kwargs:\n  raise ValueError(\n  'Must supply at least one keyword argument with patch.multiple'\n  )\n  \n items = list(kwargs.items())\n attribute, new = items[0]\n patcher = _patch(\n getter, attribute, new, spec, create, spec_set,\n autospec, new_callable, {}\n )\n patcher.attribute_name = attribute\n for attribute, new in items[1:]:\n  this_patcher = _patch(\n  getter, attribute, new, spec, create, spec_set,\n  autospec, new_callable, {}\n  )\n  this_patcher.attribute_name = attribute\n  patcher.additional_patchers.append(this_patcher)\n return patcher\n \n \ndef patch(\ntarget, new=DEFAULT, spec=None, create=False,\nspec_set=None, autospec=None, new_callable=None, **kwargs\n):\n \"\"\n getter, attribute = _get_target(target)\n return _patch(\n getter, attribute, new, spec, create,\n spec_set, autospec, new_callable, kwargs\n )\n \n \nclass _patch_dict(object):\n \"\"\n \n def __init__(self, in_dict, values=(), clear=False, **kwargs):\n  if isinstance(in_dict, str):\n   in_dict = _importer(in_dict)\n  self.in_dict = in_dict\n  \n  self.values = dict(values)\n  self.values.update(kwargs)\n  self.clear = clear\n  self._original = None\n  \n  \n def __call__(self, f):\n  if isinstance(f, type):\n   return self.decorate_class(f)\n  @wraps(f)\n  def _inner(*args, **kw):\n   self._patch_dict()\n   try:\n    return f(*args, **kw)\n   finally:\n    self._unpatch_dict()\n    \n  return _inner\n  \n  \n def decorate_class(self, klass):\n  for attr in dir(klass):\n   attr_value = getattr(klass, attr)\n   if (attr.startswith(patch.TEST_PREFIX) and\n   hasattr(attr_value, \"__call__\")):\n    decorator = _patch_dict(self.in_dict, self.values, self.clear)\n    decorated = decorator(attr_value)\n    setattr(klass, attr, decorated)\n  return klass\n  \n  \n def __enter__(self):\n  \"\"\n  self._patch_dict()\n  \n  \n def _patch_dict(self):\n  values = self.values\n  in_dict = self.in_dict\n  clear = self.clear\n  \n  try:\n   original = in_dict.copy()\n  except AttributeError:\n  \n  \n   original = {}\n   for key in in_dict:\n    original[key] = in_dict[key]\n  self._original = original\n  \n  if clear:\n   _clear_dict(in_dict)\n   \n  try:\n   in_dict.update(values)\n  except AttributeError:\n  \n   for key in values:\n    in_dict[key] = values[key]\n    \n    \n def _unpatch_dict(self):\n  in_dict = self.in_dict\n  original = self._original\n  \n  _clear_dict(in_dict)\n  \n  try:\n   in_dict.update(original)\n  except AttributeError:\n   for key in original:\n    in_dict[key] = original[key]\n    \n    \n def __exit__(self, *args):\n  \"\"\n  self._unpatch_dict()\n  return False\n  \n start = __enter__\n stop = __exit__\n \n \ndef _clear_dict(in_dict):\n try:\n  in_dict.clear()\n except AttributeError:\n  keys = list(in_dict)\n  for key in keys:\n   del in_dict[key]\n   \n   \ndef _patch_stopall():\n \"\"\n for patch in list(_patch._active_patches):\n  patch.stop()\n  \n  \npatch.object = _patch_object\npatch.dict = _patch_dict\npatch.multiple = _patch_multiple\npatch.stopall = _patch_stopall\npatch.TEST_PREFIX = 'test'\n\nmagic_methods = (\n\"lt le gt ge eq ne \"\n\"getitem setitem delitem \"\n\"len contains iter \"\n\"hash str sizeof \"\n\"enter exit \"\n\"divmod neg pos abs invert \"\n\"complex int float index \"\n\"trunc floor ceil \"\n\"bool next \"\n)\n\nnumerics = \"add sub mul div floordiv mod lshift rshift and xor or pow \"\ninplace = ' '.join('i%s' % n for n in numerics.split())\nright = ' '.join('r%s' % n for n in numerics.split())\n\n\n\n\n\n_non_defaults = set('__%s__' % method for method in [\n'get', 'set', 'delete', 'reversed', 'missing', 'reduce', 'reduce_ex',\n'getinitargs', 'getnewargs', 'getstate', 'setstate', 'getformat',\n'setformat', 'repr', 'dir', 'subclasses', 'format',\n])\n\n\ndef _get_method(name, func):\n \"\"\n def method(self, *args, **kw):\n  return func(self, *args, **kw)\n method.__name__ = name\n return method\n \n \n_magics = set(\n'__%s__' % method for method in\n' '.join([magic_methods, numerics, inplace, right]).split()\n)\n\n_all_magics = _magics | _non_defaults\n\n_unsupported_magics = set([\n'__getattr__', '__setattr__',\n'__init__', '__new__', '__prepare__'\n'__instancecheck__', '__subclasscheck__',\n'__del__'\n])\n\n_calculate_return_value = {\n'__hash__': lambda self: object.__hash__(self),\n'__str__': lambda self: object.__str__(self),\n'__sizeof__': lambda self: object.__sizeof__(self),\n}\n\n_return_values = {\n'__lt__': NotImplemented,\n'__gt__': NotImplemented,\n'__le__': NotImplemented,\n'__ge__': NotImplemented,\n'__int__': 1,\n'__contains__': False,\n'__len__': 0,\n'__exit__': False,\n'__complex__': 1j,\n'__float__': 1.0,\n'__bool__': True,\n'__index__': 1,\n}\n\n\ndef _get_eq(self):\n def __eq__(other):\n  ret_val = self.__eq__._mock_return_value\n  if ret_val is not DEFAULT:\n   return ret_val\n  return self is other\n return __eq__\n \ndef _get_ne(self):\n def __ne__(other):\n  if self.__ne__._mock_return_value is not DEFAULT:\n   return DEFAULT\n  return self is not other\n return __ne__\n \ndef _get_iter(self):\n def __iter__():\n  ret_val = self.__iter__._mock_return_value\n  if ret_val is DEFAULT:\n   return iter([])\n   \n   \n  return iter(ret_val)\n return __iter__\n \n_side_effect_methods = {\n'__eq__': _get_eq,\n'__ne__': _get_ne,\n'__iter__': _get_iter,\n}\n\n\n\ndef _set_return_value(mock, method, name):\n fixed = _return_values.get(name, DEFAULT)\n if fixed is not DEFAULT:\n  method.return_value = fixed\n  return\n  \n return_calulator = _calculate_return_value.get(name)\n if return_calulator is not None:\n  try:\n   return_value = return_calulator(mock)\n  except AttributeError:\n  \n  \n   return_value = AttributeError(name)\n  method.return_value = return_value\n  return\n  \n side_effector = _side_effect_methods.get(name)\n if side_effector is not None:\n  method.side_effect = side_effector(mock)\n  \n  \n  \nclass MagicMixin(object):\n def __init__(self, *args, **kw):\n  _safe_super(MagicMixin, self).__init__(*args, **kw)\n  self._mock_set_magics()\n  \n  \n def _mock_set_magics(self):\n  these_magics = _magics\n  \n  if self._mock_methods is not None:\n   these_magics = _magics.intersection(self._mock_methods)\n   \n   remove_magics = set()\n   remove_magics = _magics - these_magics\n   \n   for entry in remove_magics:\n    if entry in type(self).__dict__:\n    \n     delattr(self, entry)\n     \n     \n  these_magics = these_magics - set(type(self).__dict__)\n  \n  _type = type(self)\n  for entry in these_magics:\n   setattr(_type, entry, MagicProxy(entry, self))\n   \n   \n   \nclass NonCallableMagicMock(MagicMixin, NonCallableMock):\n \"\"\n def mock_add_spec(self, spec, spec_set=False):\n  \"\"\n  self._mock_add_spec(spec, spec_set)\n  self._mock_set_magics()\n  \n  \n  \nclass MagicMock(MagicMixin, Mock):\n \"\"\n def mock_add_spec(self, spec, spec_set=False):\n  \"\"\n  self._mock_add_spec(spec, spec_set)\n  self._mock_set_magics()\n  \n  \n  \nclass MagicProxy(object):\n def __init__(self, name, parent):\n  self.name = name\n  self.parent = parent\n  \n def __call__(self, *args, **kwargs):\n  m = self.create_mock()\n  return m(*args, **kwargs)\n  \n def create_mock(self):\n  entry = self.name\n  parent = self.parent\n  m = parent._get_child_mock(name=entry, _new_name=entry,\n  _new_parent=parent)\n  setattr(parent, entry, m)\n  _set_return_value(parent, m, entry)\n  return m\n  \n def __get__(self, obj, _type=None):\n  return self.create_mock()\n  \n  \n  \nclass _ANY(object):\n \"\"\n \n def __eq__(self, other):\n  return True\n  \n def __ne__(self, other):\n  return False\n  \n def __repr__(self):\n  return '<ANY>'\n  \nANY = _ANY()\n\n\n\ndef _format_call_signature(name, args, kwargs):\n message = '%s(%%s)' % name\n formatted_args = ''\n args_string = ', '.join([repr(arg) for arg in args])\n kwargs_string = ', '.join([\n '%s=%r' % (key, value) for key, value in kwargs.items()\n ])\n if args_string:\n  formatted_args = args_string\n if kwargs_string:\n  if formatted_args:\n   formatted_args += ', '\n  formatted_args += kwargs_string\n  \n return message % formatted_args\n \n \n \nclass _Call(tuple):\n \"\"\n def __new__(cls, value=(), name=None, parent=None, two=False,\n from_kall=True):\n  name = ''\n  args = ()\n  kwargs = {}\n  _len = len(value)\n  if _len == 3:\n   name, args, kwargs = value\n  elif _len == 2:\n   first, second = value\n   if isinstance(first, str):\n    name = first\n    if isinstance(second, tuple):\n     args = second\n    else:\n     kwargs = second\n   else:\n    args, kwargs = first, second\n  elif _len == 1:\n   value, = value\n   if isinstance(value, str):\n    name = value\n   elif isinstance(value, tuple):\n    args = value\n   else:\n    kwargs = value\n    \n  if two:\n   return tuple.__new__(cls, (args, kwargs))\n   \n  return tuple.__new__(cls, (name, args, kwargs))\n  \n  \n def __init__(self, value=(), name=None, parent=None, two=False,\n from_kall=True):\n  self.name = name\n  self.parent = parent\n  self.from_kall = from_kall\n  \n  \n def __eq__(self, other):\n  if other is ANY:\n   return True\n  try:\n   len_other = len(other)\n  except TypeError:\n   return False\n   \n  self_name = ''\n  if len(self) == 2:\n   self_args, self_kwargs = self\n  else:\n   self_name, self_args, self_kwargs = self\n   \n  other_name = ''\n  if len_other == 0:\n   other_args, other_kwargs = (), {}\n  elif len_other == 3:\n   other_name, other_args, other_kwargs = other\n  elif len_other == 1:\n   value, = other\n   if isinstance(value, tuple):\n    other_args = value\n    other_kwargs = {}\n   elif isinstance(value, str):\n    other_name = value\n    other_args, other_kwargs = (), {}\n   else:\n    other_args = ()\n    other_kwargs = value\n  else:\n  \n  \n   first, second = other\n   if isinstance(first, str):\n    other_name = first\n    if isinstance(second, tuple):\n     other_args, other_kwargs = second, {}\n    else:\n     other_args, other_kwargs = (), second\n   else:\n    other_args, other_kwargs = first, second\n    \n  if self_name and other_name != self_name:\n   return False\n   \n   \n  return (other_args, other_kwargs) == (self_args, self_kwargs)\n  \n  \n def __ne__(self, other):\n  return not self.__eq__(other)\n  \n  \n def __call__(self, *args, **kwargs):\n  if self.name is None:\n   return _Call(('', args, kwargs), name='()')\n   \n  name = self.name + '()'\n  return _Call((self.name, args, kwargs), name=name, parent=self)\n  \n  \n def __getattr__(self, attr):\n  if self.name is None:\n   return _Call(name=attr, from_kall=False)\n  name = '%s.%s' % (self.name, attr)\n  return _Call(name=name, parent=self, from_kall=False)\n  \n  \n def __repr__(self):\n  if not self.from_kall:\n   name = self.name or 'call'\n   if name.startswith('()'):\n    name = 'call%s' % name\n   return name\n   \n  if len(self) == 2:\n   name = 'call'\n   args, kwargs = self\n  else:\n   name, args, kwargs = self\n   if not name:\n    name = 'call'\n   elif not name.startswith('()'):\n    name = 'call.%s' % name\n   else:\n    name = 'call%s' % name\n  return _format_call_signature(name, args, kwargs)\n  \n  \n def call_list(self):\n  \"\"\n  vals = []\n  thing = self\n  while thing is not None:\n   if thing.from_kall:\n    vals.append(thing)\n   thing = thing.parent\n  return _CallList(reversed(vals))\n  \n  \ncall = _Call(from_kall=False)\n\n\n\ndef create_autospec(spec, spec_set=False, instance=False, _parent=None,\n_name=None, **kwargs):\n \"\"\n if _is_list(spec):\n \n \n  spec = type(spec)\n  \n is_type = isinstance(spec, type)\n \n _kwargs = {'spec': spec}\n if spec_set:\n  _kwargs = {'spec_set': spec}\n elif spec is None:\n \n  _kwargs = {}\n  \n _kwargs.update(kwargs)\n \n Klass = MagicMock\n if type(spec) in DescriptorTypes:\n \n \n  _kwargs = {}\n elif not _callable(spec):\n  Klass = NonCallableMagicMock\n elif is_type and instance and not _instance_callable(spec):\n  Klass = NonCallableMagicMock\n  \n _new_name = _name\n if _parent is None:\n \n  _new_name = ''\n  \n mock = Klass(parent=_parent, _new_parent=_parent, _new_name=_new_name,\n name=_name, **_kwargs)\n \n if isinstance(spec, FunctionTypes):\n \n \n  mock = _set_signature(mock, spec)\n else:\n  _check_signature(spec, mock, is_type, instance)\n  \n if _parent is not None and not instance:\n  _parent._mock_children[_name] = mock\n  \n if is_type and not instance and 'return_value' not in kwargs:\n  mock.return_value = create_autospec(spec, spec_set, instance=True,\n  _name='()', _parent=mock)\n  \n for entry in dir(spec):\n  if _is_magic(entry):\n  \n   continue\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n  try:\n   original = getattr(spec, entry)\n  except AttributeError:\n   continue\n   \n  kwargs = {'spec': original}\n  if spec_set:\n   kwargs = {'spec_set': original}\n   \n  if not isinstance(original, FunctionTypes):\n   new = _SpecState(original, spec_set, mock, entry, instance)\n   mock._mock_children[entry] = new\n  else:\n   parent = mock\n   if isinstance(spec, FunctionTypes):\n    parent = mock.mock\n    \n   new = MagicMock(parent=parent, name=entry, _new_name=entry,\n   _new_parent=parent, **kwargs)\n   mock._mock_children[entry] = new\n   skipfirst = _must_skip(spec, entry, is_type)\n   _check_signature(original, new, skipfirst=skipfirst)\n   \n   \n   \n   \n   \n  if isinstance(new, FunctionTypes):\n   setattr(mock, entry, new)\n   \n return mock\n \n \ndef _must_skip(spec, entry, is_type):\n if not isinstance(spec, type):\n  if entry in getattr(spec, '__dict__', {}):\n  \n   return False\n  spec = spec.__class__\n  \n for klass in spec.__mro__:\n  result = klass.__dict__.get(entry, DEFAULT)\n  if result is DEFAULT:\n   continue\n  if isinstance(result, (staticmethod, classmethod)):\n   return False\n  return is_type\n  \n  \n  \n return is_type\n \n \ndef _get_class(obj):\n try:\n  return obj.__class__\n except AttributeError:\n \n  return type(obj)\n  \n  \nclass _SpecState(object):\n\n def __init__(self, spec, spec_set=False, parent=None,\n name=None, ids=None, instance=False):\n  self.spec = spec\n  self.ids = ids\n  self.spec_set = spec_set\n  self.parent = parent\n  self.instance = instance\n  self.name = name\n  \n  \nFunctionTypes = (\n\ntype(create_autospec),\n\ntype(ANY.__eq__),\n)\n\n\nfile_spec = None\n\n\ndef mock_open(mock=None, read_data=''):\n \"\"\n global file_spec\n if file_spec is None:\n  import _io\n  file_spec = list(set(dir(_io.TextIOWrapper)).union(set(dir(_io.BytesIO))))\n  \n if mock is None:\n  mock = MagicMock(name='open', spec=open)\n  \n handle = MagicMock(spec=file_spec)\n handle.write.return_value = None\n handle.__enter__.return_value = handle\n handle.read.return_value = read_data\n \n mock.return_value = handle\n return mock\n \n \nclass PropertyMock(Mock):\n \"\"\n def _get_child_mock(self, **kwargs):\n  return MagicMock(**kwargs)\n  \n def __get__(self, obj, obj_type):\n  return self()\n def __set__(self, obj, val):\n  self(val)\n"], "test.test_int": [".py", "import sys\n\nimport unittest\nfrom test.support import run_unittest\n\nL = [\n('0', 0),\n('1', 1),\n('9', 9),\n('10', 10),\n('99', 99),\n('100', 100),\n('314', 314),\n(' 314', 314),\n('314 ', 314),\n('  \\t\\t  314  \\t\\t  ', 314),\n(repr(sys.maxsize), sys.maxsize),\n('  1x', ValueError),\n('  1  ', 1),\n('  1\\02  ', ValueError),\n('', ValueError),\n(' ', ValueError),\n('  \\t\\t  ', ValueError),\n(\"\\u0200\", ValueError)\n]\n\nclass IntTestCases(unittest.TestCase):\n\n def test_basic(self):\n  self.assertEqual(int(314), 314)\n  self.assertEqual(int(3.14), 3)\n  \n  self.assertEqual(int(-3.14), -3)\n  self.assertEqual(int(3.9), 3)\n  self.assertEqual(int(-3.9), -3)\n  self.assertEqual(int(3.5), 3)\n  self.assertEqual(int(-3.5), -3)\n  self.assertEqual(int(\"-3\"), -3)\n  self.assertEqual(int(\" -3 \"), -3)\n  self.assertEqual(int(\"\\N{EM SPACE}-3\\N{EN SPACE}\"), -3)\n  \n  self.assertEqual(int(\"10\",16), 16)\n  \n  for s, v in L:\n   for sign in \"\", \"+\", \"-\":\n    for prefix in \"\", \" \", \"\\t\", \"  \\t\\t  \":\n     ss = prefix + sign + s\n     vv = v\n     if sign == \"-\" and v is not ValueError:\n      vv = -v\n     try:\n      self.assertEqual(int(ss), vv)\n     except ValueError:\n      pass\n      \n  s = repr(-1-sys.maxsize)\n  x = int(s)\n  self.assertEqual(x+1, -sys.maxsize)\n  self.assertIsInstance(x, int)\n  \n  self.assertEqual(int(s[1:]), sys.maxsize+1)\n  \n  \n  x = int(1e100)\n  self.assertIsInstance(x, int)\n  x = int(-1e100)\n  self.assertIsInstance(x, int)\n  \n  \n  \n  \n  \n  x = -1-sys.maxsize\n  self.assertEqual(x >> 1, x//2)\n  \n  self.assertRaises(ValueError, int, '123\\0')\n  self.assertRaises(ValueError, int, '53', 40)\n  \n  \n  \n  self.assertRaises(ValueError, int, '123\\0', 10)\n  self.assertRaises(ValueError, int, '123\\x00 245', 20)\n  \n  x = int('1' * 600)\n  self.assertIsInstance(x, int)\n  \n  \n  self.assertRaises(TypeError, int, 1, 12)\n  \n  self.assertEqual(int('0o123', 0), 83)\n  self.assertEqual(int('0x123', 16), 291)\n  \n  \n  self.assertRaises(ValueError, int, \"0x\", 16)\n  self.assertRaises(ValueError, int, \"0x\", 0)\n  \n  self.assertRaises(ValueError, int, \"0o\", 8)\n  self.assertRaises(ValueError, int, \"0o\", 0)\n  \n  self.assertRaises(ValueError, int, \"0b\", 2)\n  self.assertRaises(ValueError, int, \"0b\", 0)\n  \n  \n  self.assertTrue(int(\"10\") is 10)\n  self.assertTrue(int(\"-1\") is -1)\n  \n  \n  \n  \n  \n  self.assertEqual(int('100000000000000000000000000000000', 2), 4294967296)\n  self.assertEqual(int('102002022201221111211', 3), 4294967296)\n  self.assertEqual(int('10000000000000000', 4), 4294967296)\n  self.assertEqual(int('32244002423141', 5), 4294967296)\n  self.assertEqual(int('1550104015504', 6), 4294967296)\n  self.assertEqual(int('211301422354', 7), 4294967296)\n  self.assertEqual(int('40000000000', 8), 4294967296)\n  self.assertEqual(int('12068657454', 9), 4294967296)\n  self.assertEqual(int('4294967296', 10), 4294967296)\n  self.assertEqual(int('1904440554', 11), 4294967296)\n  self.assertEqual(int('9ba461594', 12), 4294967296)\n  self.assertEqual(int('535a79889', 13), 4294967296)\n  self.assertEqual(int('2ca5b7464', 14), 4294967296)\n  self.assertEqual(int('1a20dcd81', 15), 4294967296)\n  self.assertEqual(int('100000000', 16), 4294967296)\n  self.assertEqual(int('a7ffda91', 17), 4294967296)\n  self.assertEqual(int('704he7g4', 18), 4294967296)\n  self.assertEqual(int('4f5aff66', 19), 4294967296)\n  self.assertEqual(int('3723ai4g', 20), 4294967296)\n  self.assertEqual(int('281d55i4', 21), 4294967296)\n  self.assertEqual(int('1fj8b184', 22), 4294967296)\n  self.assertEqual(int('1606k7ic', 23), 4294967296)\n  self.assertEqual(int('mb994ag', 24), 4294967296)\n  self.assertEqual(int('hek2mgl', 25), 4294967296)\n  self.assertEqual(int('dnchbnm', 26), 4294967296)\n  self.assertEqual(int('b28jpdm', 27), 4294967296)\n  self.assertEqual(int('8pfgih4', 28), 4294967296)\n  self.assertEqual(int('76beigg', 29), 4294967296)\n  self.assertEqual(int('5qmcpqg', 30), 4294967296)\n  self.assertEqual(int('4q0jto4', 31), 4294967296)\n  self.assertEqual(int('4000000', 32), 4294967296)\n  self.assertEqual(int('3aokq94', 33), 4294967296)\n  self.assertEqual(int('2qhxjli', 34), 4294967296)\n  self.assertEqual(int('2br45qb', 35), 4294967296)\n  self.assertEqual(int('1z141z4', 36), 4294967296)\n  \n  \n  \n  self.assertEqual(int(' 0o123  ', 0), 83)\n  self.assertEqual(int(' 0o123  ', 0), 83)\n  self.assertEqual(int('000', 0), 0)\n  self.assertEqual(int('0o123', 0), 83)\n  self.assertEqual(int('0x123', 0), 291)\n  self.assertEqual(int('0b100', 0), 4)\n  self.assertEqual(int(' 0O123   ', 0), 83)\n  self.assertEqual(int(' 0X123  ', 0), 291)\n  self.assertEqual(int(' 0B100 ', 0), 4)\n  \n  \n  self.assertEqual(int('0123'), 123)\n  self.assertEqual(int('0123', 10), 123)\n  \n  \n  self.assertEqual(int('0x123', 16), 291)\n  self.assertEqual(int('0o123', 8), 83)\n  self.assertEqual(int('0b100', 2), 4)\n  self.assertEqual(int('0X123', 16), 291)\n  self.assertEqual(int('0O123', 8), 83)\n  self.assertEqual(int('0B100', 2), 4)\n  \n  \n  \n  self.assertRaises(ValueError, int, '0b2', 2)\n  self.assertRaises(ValueError, int, '0b02', 2)\n  self.assertRaises(ValueError, int, '0B2', 2)\n  self.assertRaises(ValueError, int, '0B02', 2)\n  self.assertRaises(ValueError, int, '0o8', 8)\n  self.assertRaises(ValueError, int, '0o08', 8)\n  self.assertRaises(ValueError, int, '0O8', 8)\n  self.assertRaises(ValueError, int, '0O08', 8)\n  self.assertRaises(ValueError, int, '0xg', 16)\n  self.assertRaises(ValueError, int, '0x0g', 16)\n  self.assertRaises(ValueError, int, '0Xg', 16)\n  self.assertRaises(ValueError, int, '0X0g', 16)\n  \n  \n  \n  self.assertEqual(int('100000000000000000000000000000001', 2), 4294967297)\n  self.assertEqual(int('102002022201221111212', 3), 4294967297)\n  self.assertEqual(int('10000000000000001', 4), 4294967297)\n  self.assertEqual(int('32244002423142', 5), 4294967297)\n  self.assertEqual(int('1550104015505', 6), 4294967297)\n  self.assertEqual(int('211301422355', 7), 4294967297)\n  self.assertEqual(int('40000000001', 8), 4294967297)\n  self.assertEqual(int('12068657455', 9), 4294967297)\n  self.assertEqual(int('4294967297', 10), 4294967297)\n  self.assertEqual(int('1904440555', 11), 4294967297)\n  self.assertEqual(int('9ba461595', 12), 4294967297)\n  self.assertEqual(int('535a7988a', 13), 4294967297)\n  self.assertEqual(int('2ca5b7465', 14), 4294967297)\n  self.assertEqual(int('1a20dcd82', 15), 4294967297)\n  self.assertEqual(int('100000001', 16), 4294967297)\n  self.assertEqual(int('a7ffda92', 17), 4294967297)\n  self.assertEqual(int('704he7g5', 18), 4294967297)\n  self.assertEqual(int('4f5aff67', 19), 4294967297)\n  self.assertEqual(int('3723ai4h', 20), 4294967297)\n  self.assertEqual(int('281d55i5', 21), 4294967297)\n  self.assertEqual(int('1fj8b185', 22), 4294967297)\n  self.assertEqual(int('1606k7id', 23), 4294967297)\n  self.assertEqual(int('mb994ah', 24), 4294967297)\n  self.assertEqual(int('hek2mgm', 25), 4294967297)\n  self.assertEqual(int('dnchbnn', 26), 4294967297)\n  self.assertEqual(int('b28jpdn', 27), 4294967297)\n  self.assertEqual(int('8pfgih5', 28), 4294967297)\n  self.assertEqual(int('76beigh', 29), 4294967297)\n  self.assertEqual(int('5qmcpqh', 30), 4294967297)\n  self.assertEqual(int('4q0jto5', 31), 4294967297)\n  self.assertEqual(int('4000001', 32), 4294967297)\n  self.assertEqual(int('3aokq95', 33), 4294967297)\n  self.assertEqual(int('2qhxjlj', 34), 4294967297)\n  self.assertEqual(int('2br45qc', 35), 4294967297)\n  self.assertEqual(int('1z141z5', 36), 4294967297)\n  \n def test_intconversion(self):\n \n  class ClassicMissingMethods:\n   pass\n  self.assertRaises(TypeError, int, ClassicMissingMethods())\n  \n  class MissingMethods(object):\n   pass\n  self.assertRaises(TypeError, int, MissingMethods())\n  \n  class Foo0:\n   def __int__(self):\n    return 42\n    \n  class Foo1(object):\n   def __int__(self):\n    return 42\n    \n  class Foo2(int):\n   def __int__(self):\n    return 42\n    \n  class Foo3(int):\n   def __int__(self):\n    return self\n    \n  class Foo4(int):\n   def __int__(self):\n    return 42\n    \n  class Foo5(int):\n   def __int__(self):\n    return 42.\n    \n  self.assertEqual(int(Foo0()), 42)\n  self.assertEqual(int(Foo1()), 42)\n  self.assertEqual(int(Foo2()), 42)\n  self.assertEqual(int(Foo3()), 0)\n  self.assertEqual(int(Foo4()), 42)\n  self.assertRaises(TypeError, int, Foo5())\n  \n  class Classic:\n   pass\n  for base in (object, Classic):\n   class IntOverridesTrunc(base):\n    def __int__(self):\n     return 42\n    def __trunc__(self):\n     return -12\n   self.assertEqual(int(IntOverridesTrunc()), 42)\n   \n   class JustTrunc(base):\n    def __trunc__(self):\n     return 42\n   self.assertEqual(int(JustTrunc()), 42)\n   \n   for trunc_result_base in (object, Classic):\n    class Integral(trunc_result_base):\n     def __int__(self):\n      return 42\n      \n    class TruncReturnsNonInt(base):\n     def __trunc__(self):\n      return Integral()\n    self.assertEqual(int(TruncReturnsNonInt()), 42)\n    \n    class NonIntegral(trunc_result_base):\n     def __trunc__(self):\n     \n      return NonIntegral()\n      \n    class TruncReturnsNonIntegral(base):\n     def __trunc__(self):\n      return NonIntegral()\n    try:\n     int(TruncReturnsNonIntegral())\n    except TypeError as e:\n     self.assertEqual(str(e),\n     \"__trunc__ returned non-Integral\"\n     \" (type NonIntegral)\")\n    else:\n     self.fail(\"Failed to raise TypeError with %s\" %\n     ((base, trunc_result_base),))\n     \n def test_error_message(self):\n  testlist = ('\\xbd', '123\\xbd', '  123 456  ')\n  for s in testlist:\n   try:\n    int(s)\n   except ValueError as e:\n    self.assertIn(s.strip(), e.args[0])\n   else:\n    self.fail(\"Expected int(%r) to raise a ValueError\", s)\n    \ndef test_main():\n run_unittest(IntTestCases)\n \nif __name__ == \"__main__\":\n test_main()\n"], "_os": [".js", "var $module=(function($B){\n\n    var _b_ = $B.builtins\n    return {\n        random:function(){return _b_.float(Math.random())},\n        randint:function(a,b){return _b_.int(Math.floor(Math.random()*(b-a)+a))}\n    }\n})(__BRYTHON__)\n"], "browser.websocket": [".py", "from _websocket import *"], "_imp": [".py", "\"\"\n\n\nclass __loader__(object):pass\n\ndef _fix_co_filename(*args,**kw):\n raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:_fix_co_filename'))\n \ndef acquire_lock(*args,**kw):\n \"\"\n raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:acquire_lock'))\n \ndef extension_suffixes(*args,**kw):\n \"\"\n return ['.pyd']\n \ndef get_frozen_object(*args,**kw):\n raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:get_frozen_object'))\n \ndef init_builtin(module,*args,**kw):\n return __import__(module)\n \ndef init_frozen(*args,**kw):\n raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:init_frozen'))\n \ndef is_builtin(*args,**kw):\n raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:is_builtin'))\n \ndef is_frozen(*args,**kw):\n raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:is_frozen'))\n \ndef is_frozen_package(*args,**kw):\n raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:is_frozen_package'))\n \ndef load_dynamic(*args,**kw):\n raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:load_dynamic'))\n \ndef lock_held(*args,**kw):\n \"\"\n \n raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:lock_held'))\n \ndef release_lock(*args,**kw):\n \"\"\n \n raise NotImplementedError(\"%s:not implemented\" % ('_imp.py:release_lock'))\n"], "bisect": [".py", "\"\"\n\ndef insort_right(a, x, lo=0, hi=None):\n \"\"\n \n if lo < 0:\n  raise ValueError('lo must be non-negative')\n if hi is None:\n  hi = len(a)\n while lo < hi:\n  mid = (lo+hi)//2\n  if x < a[mid]: hi = mid\n  else: lo = mid+1\n a.insert(lo, x)\n \ninsort = insort_right \n\ndef bisect_right(a, x, lo=0, hi=None):\n \"\"\n \n if lo < 0:\n  raise ValueError('lo must be non-negative')\n if hi is None:\n  hi = len(a)\n while lo < hi:\n  mid = (lo+hi)//2\n  if x < a[mid]: hi = mid\n  else: lo = mid+1\n return lo\n \nbisect = bisect_right \n\ndef insort_left(a, x, lo=0, hi=None):\n \"\"\n \n if lo < 0:\n  raise ValueError('lo must be non-negative')\n if hi is None:\n  hi = len(a)\n while lo < hi:\n  mid = (lo+hi)//2\n  if a[mid] < x: lo = mid+1\n  else: hi = mid\n a.insert(lo, x)\n \n \ndef bisect_left(a, x, lo=0, hi=None):\n \"\"\n \n if lo < 0:\n  raise ValueError('lo must be non-negative')\n if hi is None:\n  hi = len(a)\n while lo < hi:\n  mid = (lo+hi)//2\n  if a[mid] < x: lo = mid+1\n  else: hi = mid\n return lo\n \n \ntry:\n from _bisect import *\nexcept ImportError:\n pass\n"], "signal": [".py", "\"\"\n\nCTRL_BREAK_EVENT=1\nCTRL_C_EVENT=0\nNSIG=23\nSIGABRT=22\nSIGBREAK=21\nSIGFPE=8\nSIGILL=4\nSIGINT=2\nSIGSEGV=11\nSIGTERM=15\nSIG_DFL=0\nSIG_IGN=1\n\ndef signal(signalnum, handler) :\n pass\n"], "_html": [".js", "// creation of an HTML element\nvar $module = (function($B){\n\nvar _b_ = $B.builtins\nvar $TagSumDict = $B.$TagSum.$dict\n\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\n//for(var $py_builtin in _b_) eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")\n\nfunction makeTagDict(tagName){\n    // return the dictionary for the class associated with tagName\n    var dict = {__class__:$B.$type,\n        __name__:tagName\n        }\n\n    dict.__init__ = function(){\n        var $ns=$B.$MakeArgs('pow',arguments,['self'],[],'args','kw')\n        var self = $ns['self']\n        var args = $ns['args']\n        if(args.length==1){\n            var first=args[0]\n            if(isinstance(first,[str,int,float])){\n                self.elt.appendChild(document.createTextNode(str(first)))\n            } else if(first.__class__===$TagSumDict){\n                for(var i=0;i<first.children.length;i++){\n                    self.elt.appendChild(first.children[i].elt)\n                }\n            } else { // argument is another DOMNode instance\n                try{self.elt.appendChild(first.elt)}\n                catch(err){throw ValueError('wrong element '+first)}\n            }\n        }\n\n        // attributes\n        try {\n            itr = $B.$dict_iterator($ns['kw'])\n            while (true) {\n                itm = itr.next()\n                var arg = itm[0]\n                var value = itm[1]\n                if(arg.toLowerCase().substr(0,2)===\"on\"){ \n                    // Event binding passed as argument \"onclick\", \"onfocus\"...\n                    // Better use method bind of DOMNode objects\n                    var js = '$B.DOMNode.bind(self,\"'\n                    js += arg.toLowerCase().substr(2)\n                    eval(js+'\",function(){'+value+'})')\n                }else if(arg.toLowerCase()==\"style\"){\n                    $B.DOMNode.set_style(self,value)\n                } else {\n                    if(value!==false){\n                        // option.selected=false sets it to true :-)\n                        try{\n                            arg = arg.toLowerCase()\n                            self.elt.setAttribute(arg,value)\n                            if(arg==\"class\"){ // for IE\n                                self.elt.setAttribute(\"className\",value)\n                            }\n                        }catch(err){\n                            throw ValueError(\"can't set attribute \"+arg)\n                        }\n                    }\n                }\n            }\n        } catch (err) {\n            if (err.__name__ !== \"StopIteration\") { throw err } else { $B.$pop_exc() }\n        }\n    }\n\n    dict.__mro__ = [dict,$B.DOMNode,$B.builtins.object.$dict]\n\n    dict.__new__ = function(cls){\n        // __new__ must be defined explicitely : it returns an instance of\n        // DOMNode for the specified tagName\n        var res = $B.$DOMNode(document.createElement(tagName))\n        res.__class__ = cls.$dict\n        return res\n    }\n\n    return dict\n}\n\n\n// the classes used for tag sums, $TagSum and $TagSumClass \n// are defined in py_dom.js\n\nfunction makeFactory(tagName){\n    var factory = function(){\n        var res = $B.$DOMNode(document.createElement(tagName))\n        res.__class__ = dicts[tagName]\n        // apply __init__\n        var args = [res]\n        for(var i=0;i<arguments.length;i++){args.push(arguments[i])}\n        dicts[tagName].__init__.apply(null,args)\n        return res\n    }\n    factory.__class__=$B.$factory\n    factory.$dict = dicts[tagName]\n    return factory\n}\n\n// All HTML 4, 5.x extracted from\n// https://w3c.github.io/elements-of-html/\n// HTML4.01 tags\nvar $tags = ['A','ABBR','ACRONYM','ADDRESS','APPLET','AREA','B','BASE',\n            'BASEFONT','BDO','BIG','BLOCKQUOTE','BODY','BR','BUTTON',\n            'CAPTION','CENTER','CITE','CODE','COL','COLGROUP','DD',\n            'DEL','DFN','DIR','DIV','DL','DT','EM','FIELDSET','FONT',\n            'FORM','FRAME','FRAMESET','H1','H2','H3','H4','H5','H6',\n            'HEAD','HR','HTML','I','IFRAME','IMG','INPUT','INS',\n            'ISINDEX','KBD','LABEL','LEGEND','LI','LINK','MAP','MENU',\n            'META','NOFRAMES','NOSCRIPT','OBJECT','OL','OPTGROUP',\n            'OPTION','P','PARAM','PRE','Q','S','SAMP','SCRIPT','SELECT',\n            'SMALL','SPAN','STRIKE','STRONG','STYLE','SUB','SUP',\n            'TABLE','TBODY','TD','TEXTAREA','TFOOT','TH','THEAD',\n            'TITLE','TR','TT','U','UL','VAR',\n            // HTML5 tags\n            'ARTICLE','ASIDE','AUDIO','BDI','CANVAS','COMMAND','DATA',\n            'DATALIST','EMBED','FIGCAPTION','FIGURE','FOOTER','HEADER',\n            'KEYGEN','MAIN','MARK','MATH','METER','NAV','OUTPUT',\n            'PROGRESS','RB','RP','RT','RTC','RUBY','SECTION','SOURCE',\n            'TEMPLATE','TIME','TRACK','VIDEO','WBR',\n             // HTML5.1 tags\n            'DETAILS','DIALOG','MENUITEM','PICTURE','SUMMARY']\n\n// create classes\nvar obj = new Object()\nvar dicts = {}\nfor(var i=0;i<$tags.length;i++){\n    var tag = $tags[i]\n    dicts[tag]=makeTagDict(tag)\n    obj[tag] = makeFactory(tag)\n    dicts[tag].$factory = obj[tag]\n}\nreturn obj\n})(__BRYTHON__)\n"], "_sys": [".js", "var $module=(function($B){\n\n    return {\n        modules :\n            {'__get__':function(){return $B.builtins.dict($B.JSObject($B.imported))},\n             '__set__':0 // data descriptor, to force use of __get__\n            },\n        stderr : $B.stderr,\n        stdout : $B.stdout,\n        stdin : $B.stdin,\n    }\n})(__BRYTHON__)\n"], "browser.session_storage": [".py", "\nfrom javascript import JSObject\nfrom .local_storage import Local_Storage\n\nclass Session_Storage(Local_Storage):\n\n storage_type = \"session_storage\"\n \n def __init__(self):\n  self.store = JSObject(__BRYTHON__.session_storage)\n  \nstorage = Session_Storage()"], "pydoc": [".py", "\n\"\"\n__all__ = ['help']\n__author__ = \"Ka-Ping Yee <ping@lfw.org>\"\n__date__ = \"26 February 2001\"\n\n__credits__ = \"\"\"Guido van Rossum, for an excellent programming language.\nTommy Burnette, the original creator of manpy.\nPaul Prescod, for all his work on onlinehelp.\nRichard Chamberlain, for the first implementation of textdoc.\n\"\"\"\n\n\n\n\n\n\n\n\n\nimport builtins\nimport imp\nimport importlib.machinery\n\nimport inspect\nimport io\nimport os\n\n\nimport platform\nimport re\nimport sys\nimport time\nimport tokenize\nimport warnings\nfrom collections import deque\nfrom reprlib import Repr\n\n\n\n\n\n\ndef pathdirs():\n \"\"\n dirs = []\n normdirs = []\n for dir in sys.path:\n  dir = os.path.abspath(dir or '.')\n  normdir = os.path.normcase(dir)\n  if normdir not in normdirs and os.path.isdir(dir):\n   dirs.append(dir)\n   normdirs.append(normdir)\n return dirs\n \ndef getdoc(object):\n \"\"\n result = inspect.getdoc(object) or inspect.getcomments(object)\n return result and re.sub('^ *\\n', '', result.rstrip()) or ''\n \ndef splitdoc(doc):\n \"\"\n lines = doc.strip().split('\\n')\n if len(lines) == 1:\n  return lines[0], ''\n elif len(lines) >= 2 and not lines[1].rstrip():\n  return lines[0], '\\n'.join(lines[2:])\n return '', '\\n'.join(lines)\n \ndef classname(object, modname):\n \"\"\n name = object.__name__\n if object.__module__ != modname:\n  name = object.__module__ + '.' + name\n return name\n \ndef isdata(object):\n \"\"\n return not (inspect.ismodule(object) or inspect.isclass(object) or\n inspect.isroutine(object) or inspect.isframe(object) or\n inspect.istraceback(object) or inspect.iscode(object))\n \ndef replace(text, *pairs):\n \"\"\n while pairs:\n  text = pairs[1].join(text.split(pairs[0]))\n  pairs = pairs[2:]\n return text\n \ndef cram(text, maxlen):\n \"\"\n if len(text) > maxlen:\n  pre = max(0, (maxlen-3)//2)\n  post = max(0, maxlen-3-pre)\n  return text[:pre] + '...' + text[len(text)-post:]\n return text\n \n_re_stripid = re.compile(r' at 0x[0-9a-f]{6,16}(>+)$', re.IGNORECASE)\ndef stripid(text):\n \"\"\n \n \n \n return text\n \ndef _is_some_method(obj):\n return (inspect.isfunction(obj) or\n inspect.ismethod(obj) or\n inspect.isbuiltin(obj) or\n inspect.ismethoddescriptor(obj))\n \ndef allmethods(cl):\n methods = {}\n for key, value in inspect.getmembers(cl, _is_some_method):\n  methods[key] = 1\n for base in cl.__bases__:\n  methods.update(allmethods(base)) \n for key in methods.keys():\n  methods[key] = getattr(cl, key)\n return methods\n \ndef _split_list(s, predicate):\n \"\"\n \n yes = []\n no = []\n for x in s:\n  if predicate(x):\n   yes.append(x)\n  else:\n   no.append(x)\n return yes, no\n \ndef visiblename(name, all=None, obj=None):\n \"\"\n \n if name in {'__author__', '__builtins__', '__cached__', '__credits__',\n '__date__', '__doc__', '__file__', '__initializing__',\n '__loader__', '__module__', '__name__', '__package__',\n '__path__', '__qualname__', '__slots__', '__version__'}:\n  return 0\n  \n if name.startswith('__') and name.endswith('__'): return 1\n \n if name.startswith('_') and hasattr(obj, '_fields'):\n  return True\n if all is not None:\n \n  return name in all\n else:\n  return not name.startswith('_')\n  \ndef classify_class_attrs(object):\n \"\"\n results = []\n for (name, kind, cls, value) in inspect.classify_class_attrs(object):\n  if inspect.isdatadescriptor(value):\n   kind = 'data descriptor'\n  results.append((name, kind, cls, value))\n return results\n \n \n \ndef ispackage(path):\n \"\"\n if os.path.isdir(path):\n  for ext in ('.py', '.pyc', '.pyo'):\n   if os.path.isfile(os.path.join(path, '__init__' + ext)):\n    return True\n return False\n \ndef source_synopsis(file):\n line = file.readline()\n while line[:1] == '#' or not line.strip():\n  line = file.readline()\n  if not line: break\n line = line.strip()\n if line[:4] == 'r\"\"\"': line = line[1:]\n if line[:3] == '\"\"\"':\n  line = line[3:]\n  if line[-1:] == '\\\\': line = line[:-1]\n  while not line.strip():\n   line = file.readline()\n   if not line: break\n  result = line.split('\"\"\"')[0].strip()\n else: result = None\n return result\n \ndef synopsis(filename, cache={}):\n \"\"\n mtime = os.stat(filename).st_mtime\n lastupdate, result = cache.get(filename, (None, None))\n if lastupdate is None or lastupdate < mtime:\n  try:\n   file = tokenize.open(filename)\n  except IOError:\n  \n   return None\n  binary_suffixes = importlib.machinery.BYTECODE_SUFFIXES[:]\n  binary_suffixes += importlib.machinery.EXTENSION_SUFFIXES[:]\n  if any(filename.endswith(x) for x in binary_suffixes):\n  \n   file.close()\n   if any(filename.endswith(x) for x in\n   importlib.machinery.BYTECODE_SUFFIXES):\n    loader = importlib.machinery.SourcelessFileLoader('__temp__',\n    filename)\n   else:\n    loader = importlib.machinery.ExtensionFileLoader('__temp__',\n    filename)\n   try:\n    module = loader.load_module('__temp__')\n   except:\n    return None\n   result = (module.__doc__ or '').splitlines()[0]\n   del sys.modules['__temp__']\n  else:\n  \n   result = source_synopsis(file)\n   file.close()\n   \n  cache[filename] = (mtime, result)\n return result\n \nclass ErrorDuringImport(Exception):\n \"\"\n def __init__(self, filename, exc_info):\n  self.filename = filename\n  self.exc, self.value, self.tb = exc_info\n  \n def __str__(self):\n  exc = self.exc.__name__\n  return 'problem in %s - %s: %s' % (self.filename, exc, self.value)\n  \ndef importfile(path):\n \"\"\n magic = imp.get_magic()\n with open(path, 'rb') as file:\n  if file.read(len(magic)) == magic:\n   kind = imp.PY_COMPILED\n  else:\n   kind = imp.PY_SOURCE\n  file.seek(0)\n  filename = os.path.basename(path)\n  name, ext = os.path.splitext(filename)\n  try:\n   module = imp.load_module(name, file, path, (ext, 'r', kind))\n  except:\n   raise ErrorDuringImport(path, sys.exc_info())\n return module\n \ndef safeimport(path, forceload=0, cache={}):\n \"\"\n try:\n \n \n \n \n  if forceload and path in sys.modules:\n   if path not in sys.builtin_module_names:\n   \n   \n   \n   \n   \n    subs = [m for m in sys.modules if m.startswith(path + '.')]\n    for key in [path] + subs:\n    \n     cache[key] = sys.modules[key]\n     del sys.modules[key]\n  module = __import__(path)\n except:\n \n  (exc, value, tb) = info = sys.exc_info()\n  if path in sys.modules:\n  \n   raise ErrorDuringImport(sys.modules[path].__file__, info)\n  elif exc is SyntaxError:\n  \n   raise ErrorDuringImport(value.filename, info)\n   \n   \n  elif exc is ImportError and str(value) == str(path):\n  \n   return None\n  else:\n  \n   raise ErrorDuringImport(path, sys.exc_info())\n for part in path.split('.')[1:]:\n  try: module = getattr(module, part)\n  except AttributeError: return None\n return module\n \n \n \nclass Doc:\n\n PYTHONDOCS = os.environ.get(\"PYTHONDOCS\",\n \"http://docs.python.org/%d.%d/library\"\n % sys.version_info[:2])\n \n def document(self, object, name=None, *args):\n  \"\"\n  args = (object, name) + args\n  \n  \n  \n  \n  if inspect.isgetsetdescriptor(object): return self.docdata(*args)\n  if inspect.ismemberdescriptor(object): return self.docdata(*args)\n  try:\n   if inspect.ismodule(object): return self.docmodule(*args)\n   if inspect.isclass(object): return self.docclass(*args)\n   if inspect.isroutine(object): return self.docroutine(*args)\n  except AttributeError:\n   pass\n  if isinstance(object, property): return self.docproperty(*args)\n  return self.docother(*args)\n  \n def fail(self, object, name=None, *args):\n  \"\"\n  message = \"don't know how to document object%s of type %s\" % (\n  name and ' ' + repr(name), type(object).__name__)\n  raise TypeError(message)\n  \n docmodule = docclass = docroutine = docother = docproperty = docdata = fail\n \n def getdocloc(self, object):\n  \"\"\n  \n  try:\n   file = inspect.getabsfile(object)\n  except TypeError:\n   file = '(built-in)'\n   \n  docloc = os.environ.get(\"PYTHONDOCS\", self.PYTHONDOCS)\n  \n  basedir = os.path.join(sys.base_exec_prefix, \"lib\",\n  \"python%d.%d\" % sys.version_info[:2])\n  if (isinstance(object, type(os)) and\n  (object.__name__ in ('errno', 'exceptions', 'gc', 'imp',\n  'marshal', 'posix', 'signal', 'sys',\n  '_thread', 'zipimport') or\n  (file.startswith(basedir) and\n  not file.startswith(os.path.join(basedir, 'site-packages')))) and\n  object.__name__ not in ('xml.etree', 'test.pydoc_mod')):\n   if docloc.startswith(\"http://\"):\n    docloc = \"%s/%s\" % (docloc.rstrip(\"/\"), object.__name__)\n   else:\n    docloc = os.path.join(docloc, object.__name__ + \".html\")\n  else:\n   docloc = None\n  return docloc\n  \n  \n  \nclass HTMLRepr(Repr):\n \"\"\n def __init__(self):\n  Repr.__init__(self)\n  self.maxlist = self.maxtuple = 20\n  self.maxdict = 10\n  self.maxstring = self.maxother = 100\n  \n def escape(self, text):\n  return replace(text, '&', '&amp;', '<', '&lt;', '>', '&gt;')\n  \n def repr(self, object):\n  return Repr.repr(self, object)\n  \n def repr1(self, x, level):\n  if hasattr(type(x), '__name__'):\n   methodname = 'repr_' + '_'.join(type(x).__name__.split())\n   if hasattr(self, methodname):\n    return getattr(self, methodname)(x, level)\n  return self.escape(cram(stripid(repr(x)), self.maxother))\n  \n def repr_string(self, x, level):\n  test = cram(x, self.maxstring)\n  testrepr = repr(test)\n  if '\\\\' in test and '\\\\' not in replace(testrepr, r'\\\\', ''):\n  \n  \n   return 'r' + testrepr[0] + self.escape(test) + testrepr[0]\n  return re.sub(r'((\\\\[\\\\abfnrtv\\'\"]|\\\\[0-9]..|\\\\x..|\\\\u....)+)',\n  r'<font color=\"#c040c0\">\\1</font>',\n  self.escape(testrepr))\n  \n repr_str = repr_string\n \n def repr_instance(self, x, level):\n  try:\n   return self.escape(cram(stripid(repr(x)), self.maxstring))\n  except:\n   return self.escape('<%s instance>' % x.__class__.__name__)\n   \n repr_unicode = repr_string\n \nclass HTMLDoc(Doc):\n \"\"\n \n \n \n _repr_instance = HTMLRepr()\n repr = _repr_instance.repr\n escape = _repr_instance.escape\n \n def page(self, title, contents):\n  \"\"\n  return '''\\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<html><head><title>Python: %s</title>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n</head><body bgcolor=\"#f0f0f8\">\n%s\n</body></html>'''  % (title, contents)\n  \n def heading(self, title, fgcol, bgcol, extras=''):\n  \"\"\n  return '''\n<table width=\"100%%\" cellspacing=0 cellpadding=2 border=0 summary=\"heading\">\n<tr bgcolor=\"%s\">\n<td valign=bottom>&nbsp;<br>\n<font color=\"%s\" face=\"helvetica, arial\">&nbsp;<br>%s</font></td\n><td align=right valign=bottom\n><font color=\"%s\" face=\"helvetica, arial\">%s</font></td></tr></table>\n    '''  % (bgcol, fgcol, title, fgcol, extras or '&nbsp;')\n  \n def section(self, title, fgcol, bgcol, contents, width=6,\n prelude='', marginalia=None, gap='&nbsp;'):\n  \"\"\n  if marginalia is None:\n   marginalia = '<tt>' + '&nbsp;' * width + '</tt>'\n  result = '''<p>\n<table width=\"100%%\" cellspacing=0 cellpadding=2 border=0 summary=\"section\">\n<tr bgcolor=\"%s\">\n<td colspan=3 valign=bottom>&nbsp;<br>\n<font color=\"%s\" face=\"helvetica, arial\">%s</font></td></tr>\n    '''  % (bgcol, fgcol, title)\n  if prelude:\n   result = result + '''\n<tr bgcolor=\"%s\"><td rowspan=2>%s</td>\n<td colspan=2>%s</td></tr>\n<tr><td>%s</td>'''   % (bgcol, marginalia, prelude, gap)\n  else:\n   result = result + '''\n<tr><td bgcolor=\"%s\">%s</td><td>%s</td>'''   % (bgcol, marginalia, gap)\n   \n  return result + '\\n<td width=\"100%%\">%s</td></tr></table>' % contents\n  \n def bigsection(self, title, *args):\n  \"\"\n  title = '<big><strong>%s</strong></big>' % title\n  return self.section(title, *args)\n  \n def preformat(self, text):\n  \"\"\n  text = self.escape(text.expandtabs())\n  return replace(text, '\\n\\n', '\\n \\n', '\\n\\n', '\\n \\n',\n  ' ', '&nbsp;', '\\n', '<br>\\n')\n  \n def multicolumn(self, list, format, cols=4):\n  \"\"\n  result = ''\n  rows = (len(list)+cols-1)//cols\n  for col in range(cols):\n   result = result + '<td width=\"%d%%\" valign=top>' % (100//cols)\n   for i in range(rows*col, rows*col+rows):\n    if i < len(list):\n     result = result + format(list[i]) + '<br>\\n'\n   result = result + '</td>'\n  return '<table width=\"100%%\" summary=\"list\"><tr>%s</tr></table>' % result\n  \n def grey(self, text): return '<font color=\"#909090\">%s</font>' % text\n \n def namelink(self, name, *dicts):\n  \"\"\n  for dict in dicts:\n   if name in dict:\n    return '<a href=\"%s\">%s</a>' % (dict[name], name)\n  return name\n  \n def classlink(self, object, modname):\n  \"\"\n  name, module = object.__name__, sys.modules.get(object.__module__)\n  if hasattr(module, name) and getattr(module, name) is object:\n   return '<a href=\"%s.html#%s\">%s</a>' % (\n   module.__name__, name, classname(object, modname))\n  return classname(object, modname)\n  \n def modulelink(self, object):\n  \"\"\n  return '<a href=\"%s.html\">%s</a>' % (object.__name__, object.__name__)\n  \n def modpkglink(self, modpkginfo):\n  \"\"\n  name, path, ispackage, shadowed = modpkginfo\n  if shadowed:\n   return self.grey(name)\n  if path:\n   url = '%s.%s.html' % (path, name)\n  else:\n   url = '%s.html' % name\n  if ispackage:\n   text = '<strong>%s</strong>&nbsp;(package)' % name\n  else:\n   text = name\n  return '<a href=\"%s\">%s</a>' % (url, text)\n  \n def filelink(self, url, path):\n  \"\"\n  return '<a href=\"file:%s\">%s</a>' % (url, path)\n  \n def markup(self, text, escape=None, funcs={}, classes={}, methods={}):\n  \"\"\n  escape = escape or self.escape\n  results = []\n  here = 0\n  pattern = re.compile(r'\\b((http|ftp)://\\S+[\\w/]|'\n  r'RFC[- ]?(\\d+)|'\n  r'PEP[- ]?(\\d+)|'\n  r'(self\\.)?(\\w+))')\n  while True:\n   match = pattern.search(text, here)\n   if not match: break\n   start, end = match.span()\n   results.append(escape(text[here:start]))\n   \n   all, scheme, rfc, pep, selfdot, name = match.groups()\n   if scheme:\n    url = escape(all).replace('\"', '&quot;')\n    results.append('<a href=\"%s\">%s</a>' % (url, url))\n   elif rfc:\n    url = 'http://www.rfc-editor.org/rfc/rfc%d.txt' % int(rfc)\n    results.append('<a href=\"%s\">%s</a>' % (url, escape(all)))\n   elif pep:\n    url = 'http://www.python.org/dev/peps/pep-%04d/' % int(pep)\n    results.append('<a href=\"%s\">%s</a>' % (url, escape(all)))\n   elif text[end:end+1] == '(':\n    results.append(self.namelink(name, methods, funcs, classes))\n   elif selfdot:\n    results.append('self.<strong>%s</strong>' % name)\n   else:\n    results.append(self.namelink(name, classes))\n   here = end\n  results.append(escape(text[here:]))\n  return ''.join(results)\n  \n  \n  \n def formattree(self, tree, modname, parent=None):\n  \"\"\n  result = ''\n  for entry in tree:\n   if type(entry) is type(()):\n    c, bases = entry\n    result = result + '<dt><font face=\"helvetica, arial\">'\n    result = result + self.classlink(c, modname)\n    if bases and bases != (parent,):\n     parents = []\n     for base in bases:\n      parents.append(self.classlink(base, modname))\n     result = result + '(' + ', '.join(parents) + ')'\n    result = result + '\\n</font></dt>'\n   elif type(entry) is type([]):\n    result = result + '<dd>\\n%s</dd>\\n' % self.formattree(\n    entry, modname, c)\n  return '<dl>\\n%s</dl>\\n' % result\n  \n def docmodule(self, object, name=None, mod=None, *ignored):\n  \"\"\n  name = object.__name__ \n  try:\n   all = object.__all__\n  except AttributeError:\n   all = None\n  parts = name.split('.')\n  links = []\n  for i in range(len(parts)-1):\n   links.append(\n   '<a href=\"%s.html\"><font color=\"#ffffff\">%s</font></a>' %\n   ('.'.join(parts[:i+1]), parts[i]))\n  linkedname = '.'.join(links + parts[-1:])\n  head = '<big><big><strong>%s</strong></big></big>' % linkedname\n  try:\n   path = inspect.getabsfile(object)\n   url = path\n   if sys.platform == 'win32':\n    import nturl2path\n    url = nturl2path.pathname2url(path)\n   filelink = self.filelink(url, path)\n  except TypeError:\n   filelink = '(built-in)'\n  info = []\n  if hasattr(object, '__version__'):\n   version = str(object.__version__)\n   if version[:11] == '$' + 'Revision: ' and version[-1:] == '$':\n    version = version[11:-1].strip()\n   info.append('version %s' % self.escape(version))\n  if hasattr(object, '__date__'):\n   info.append(self.escape(str(object.__date__)))\n  if info:\n   head = head + ' (%s)' % ', '.join(info)\n  docloc = self.getdocloc(object)\n  if docloc is not None:\n   docloc = '<br><a href=\"%(docloc)s\">Module Reference</a>' % locals()\n  else:\n   docloc = ''\n  result = self.heading(\n  head, '#ffffff', '#7799ee',\n  '<a href=\".\">index</a><br>' + filelink + docloc)\n  \n  modules = inspect.getmembers(object, inspect.ismodule)\n  \n  classes, cdict = [], {}\n  for key, value in inspect.getmembers(object, inspect.isclass):\n  \n   if (all is not None or\n   (inspect.getmodule(value) or object) is object):\n    if visiblename(key, all, object):\n     classes.append((key, value))\n     cdict[key] = cdict[value] = '#' + key\n  for key, value in classes:\n   for base in value.__bases__:\n    key, modname = base.__name__, base.__module__\n    module = sys.modules.get(modname)\n    if modname != name and module and hasattr(module, key):\n     if getattr(module, key) is base:\n      if not key in cdict:\n       cdict[key] = cdict[base] = modname + '.html#' + key\n  funcs, fdict = [], {}\n  for key, value in inspect.getmembers(object, inspect.isroutine):\n  \n   if (all is not None or\n   inspect.isbuiltin(value) or inspect.getmodule(value) is object):\n    if visiblename(key, all, object):\n     funcs.append((key, value))\n     fdict[key] = '#-' + key\n     if inspect.isfunction(value): fdict[value] = fdict[key]\n  data = []\n  for key, value in inspect.getmembers(object, isdata):\n   if visiblename(key, all, object):\n    data.append((key, value))\n    \n  doc = self.markup(getdoc(object), self.preformat, fdict, cdict)\n  doc = doc and '<tt>%s</tt>' % doc\n  result = result + '<p>%s</p>\\n' % doc\n  \n  if hasattr(object, '__path__'):\n   modpkgs = []\n   for importer, modname, ispkg in pkgutil.iter_modules(object.__path__):\n    modpkgs.append((modname, name, ispkg, 0))\n   modpkgs.sort()\n   contents = self.multicolumn(modpkgs, self.modpkglink)\n   result = result + self.bigsection(\n   'Package Contents', '#ffffff', '#aa55cc', contents)\n  elif modules:\n   contents = self.multicolumn(\n   modules, lambda t: self.modulelink(t[1]))\n   result = result + self.bigsection(\n   'Modules', '#ffffff', '#aa55cc', contents)\n   \n  if classes:\n   classlist = [value for (key, value) in classes]\n   contents = [\n   self.formattree(inspect.getclasstree(classlist, 1), name)]\n   for key, value in classes:\n    contents.append(self.document(value, key, name, fdict, cdict))\n   result = result + self.bigsection(\n   'Classes', '#ffffff', '#ee77aa', ' '.join(contents))\n  if funcs:\n   contents = []\n   for key, value in funcs:\n    contents.append(self.document(value, key, name, fdict, cdict))\n   result = result + self.bigsection(\n   'Functions', '#ffffff', '#eeaa77', ' '.join(contents))\n  if data:\n   contents = []\n   for key, value in data:\n    contents.append(self.document(value, key))\n   result = result + self.bigsection(\n   'Data', '#ffffff', '#55aa55', '<br>\\n'.join(contents))\n  if hasattr(object, '__author__'):\n   contents = self.markup(str(object.__author__), self.preformat)\n   result = result + self.bigsection(\n   'Author', '#ffffff', '#7799ee', contents)\n  if hasattr(object, '__credits__'):\n   contents = self.markup(str(object.__credits__), self.preformat)\n   result = result + self.bigsection(\n   'Credits', '#ffffff', '#7799ee', contents)\n   \n  return result\n  \n def docclass(self, object, name=None, mod=None, funcs={}, classes={},\n *ignored):\n  \"\"\n  print('docclass')\n  realname = object.__name__\n  name = name or realname\n  bases = object.__bases__\n  \n  contents = []\n  push = contents.append\n  \n  \n  class HorizontalRule:\n   def __init__(self):\n    self.needone = 0\n   def maybe(self):\n    if self.needone:\n     push('<hr>\\n')\n    self.needone = 1\n  hr = HorizontalRule()\n  \n  \n  mro = deque(inspect.getmro(object))\n  if len(mro) > 2:\n   hr.maybe()\n   push('<dl><dt>Method resolution order:</dt>\\n')\n   for base in mro:\n    push('<dd>%s</dd>\\n' % self.classlink(base,\n    object.__module__))\n   push('</dl>\\n')\n   \n  def spill(msg, attrs, predicate):\n   ok, attrs = _split_list(attrs, predicate)\n   if ok:\n    hr.maybe()\n    push(msg)\n    for name, kind, homecls, value in ok:\n     try:\n      value = getattr(object, name)\n     except Exception:\n     \n     \n      push(self._docdescriptor(name, value, mod))\n     else:\n      push(self.document(value, name, mod,\n      funcs, classes, mdict, object))\n     push('\\n')\n   return attrs\n   \n  def spilldescriptors(msg, attrs, predicate):\n   ok, attrs = _split_list(attrs, predicate)\n   if ok:\n    hr.maybe()\n    push(msg)\n    for name, kind, homecls, value in ok:\n     push(self._docdescriptor(name, value, mod))\n   return attrs\n   \n  def spilldata(msg, attrs, predicate):\n   ok, attrs = _split_list(attrs, predicate)\n   if ok:\n    hr.maybe()\n    push(msg)\n    for name, kind, homecls, value in ok:\n     base = self.docother(getattr(object, name), name, mod)\n     if callable(value) or inspect.isdatadescriptor(value):\n      doc = getattr(value, \"__doc__\", None)\n     else:\n      doc = None\n     if doc is None:\n      push('<dl><dt>%s</dl>\\n' % base)\n     else:\n      doc = self.markup(getdoc(value), self.preformat,\n      funcs, classes, mdict)\n      doc = '<dd><tt>%s</tt>' % doc\n      push('<dl><dt>%s%s</dl>\\n' % (base, doc))\n     push('\\n')\n   return attrs\n   \n  attrs = [(name, kind, cls, value)\n  for name, kind, cls, value in classify_class_attrs(object)\n  if visiblename(name, obj=object)]\n  \n  mdict = {}\n  for key, kind, homecls, value in attrs:\n   mdict[key] = anchor = '#' + name + '-' + key\n   try:\n    value = getattr(object, name)\n   except Exception:\n   \n   \n    pass\n   try:\n   \n   \n    mdict[value] = anchor\n   except TypeError:\n    pass\n    \n  while attrs:\n   if mro:\n    thisclass = mro.popleft()\n   else:\n    thisclass = attrs[0][2]\n   attrs, inherited = _split_list(attrs, lambda t: t[2] is thisclass)\n   \n   if thisclass is builtins.object:\n    attrs = inherited\n    continue\n   elif thisclass is object:\n    tag = 'defined here'\n   else:\n    tag = 'inherited from %s' % self.classlink(thisclass,\n    object.__module__)\n   tag += ':<br>\\n'\n   \n   \n   attrs.sort(key=lambda t: t[0])\n   \n   \n   attrs = spill('Methods %s' % tag, attrs,\n   lambda t: t[1] == 'method')\n   attrs = spill('Class methods %s' % tag, attrs,\n   lambda t: t[1] == 'class method')\n   attrs = spill('Static methods %s' % tag, attrs,\n   lambda t: t[1] == 'static method')\n   attrs = spilldescriptors('Data descriptors %s' % tag, attrs,\n   lambda t: t[1] == 'data descriptor')\n   attrs = spilldata('Data and other attributes %s' % tag, attrs,\n   lambda t: t[1] == 'data')\n   assert attrs == []\n   attrs = inherited\n   \n  contents = ''.join(contents)\n  \n  if name == realname:\n   title = '<a name=\"%s\">class <strong>%s</strong></a>' % (\n   name, realname)\n  else:\n   title = '<strong>%s</strong> = <a name=\"%s\">class %s</a>' % (\n   name, name, realname)\n  if bases:\n   parents = []\n   for base in bases:\n    parents.append(self.classlink(base, object.__module__))\n   title = title + '(%s)' % ', '.join(parents)\n  doc = self.markup(getdoc(object), self.preformat, funcs, classes, mdict)\n  doc = doc and '<tt>%s<br>&nbsp;</tt>' % doc\n  \n  return self.section(title, '#000000', '#ffc8d8', contents, 3, doc)\n  \n def formatvalue(self, object):\n  \"\"\n  return self.grey('=' + self.repr(object))\n  \n def docroutine(self, object, name=None, mod=None,\n funcs={}, classes={}, methods={}, cl=None):\n  \"\"\n  realname = object.__name__\n  name = name or realname\n  anchor = (cl and cl.__name__ or '') + '-' + name\n  note = ''\n  skipdocs = 0\n  if inspect.ismethod(object):\n   imclass = object.__self__.__class__\n   if cl:\n    if imclass is not cl:\n     note = ' from ' + self.classlink(imclass, mod)\n   else:\n    if object.__self__ is not None:\n     note = ' method of %s instance' % self.classlink(\n     object.__self__.__class__, mod)\n    else:\n     note = ' unbound %s method' % self.classlink(imclass,mod)\n   object = object.__func__\n   \n  if name == realname:\n   title = '<a name=\"%s\"><strong>%s</strong></a>' % (anchor, realname)\n  else:\n   if (cl and realname in cl.__dict__ and\n   cl.__dict__[realname] is object):\n    reallink = '<a href=\"#%s\">%s</a>' % (\n    cl.__name__ + '-' + realname, realname)\n    skipdocs = 1\n   else:\n    reallink = realname\n   title = '<a name=\"%s\"><strong>%s</strong></a> = %s' % (\n   anchor, name, reallink)\n  if inspect.isfunction(object):\n   args, varargs, kwonlyargs, kwdefaults, varkw, defaults, ann = inspect.getfullargspec(object)\n   argspec = inspect.formatargspec(\n   args, varargs, kwonlyargs, kwdefaults, varkw, defaults, ann,\n   formatvalue=self.formatvalue,\n   formatannotation=inspect.formatannotationrelativeto(object))\n   if realname == '<lambda>':\n    title = '<strong>%s</strong> <em>lambda</em> ' % name\n    \n    \n    \n    argspec = argspec[1:-1] \n  else:\n   argspec = '(...)'\n   \n  decl = title + argspec + (note and self.grey(\n  '<font face=\"helvetica, arial\">%s</font>' % note))\n  \n  if skipdocs:\n   return '<dl><dt>%s</dt></dl>\\n' % decl\n  else:\n   doc = self.markup(\n   getdoc(object), self.preformat, funcs, classes, methods)\n   doc = doc and '<dd><tt>%s</tt></dd>' % doc\n   return '<dl><dt>%s</dt>%s</dl>\\n' % (decl, doc)\n   \n def _docdescriptor(self, name, value, mod):\n  results = []\n  push = results.append\n  \n  if name:\n   push('<dl><dt><strong>%s</strong></dt>\\n' % name)\n  if value.__doc__ is not None:\n   doc = self.markup(getdoc(value), self.preformat)\n   push('<dd><tt>%s</tt></dd>\\n' % doc)\n  push('</dl>\\n')\n  \n  return ''.join(results)\n  \n def docproperty(self, object, name=None, mod=None, cl=None):\n  \"\"\n  return self._docdescriptor(name, object, mod)\n  \n def docother(self, object, name=None, mod=None, *ignored):\n  \"\"\n  lhs = name and '<strong>%s</strong> = ' % name or ''\n  return lhs + self.repr(object)\n  \n def docdata(self, object, name=None, mod=None, cl=None):\n  \"\"\n  return self._docdescriptor(name, object, mod)\n  \n def index(self, dir, shadowed=None):\n  \"\"\n  modpkgs = []\n  if shadowed is None: shadowed = {}\n  for importer, name, ispkg in pkgutil.iter_modules([dir]):\n   if any((0xD800 <= ord(ch) <= 0xDFFF) for ch in name):\n   \n    continue\n   modpkgs.append((name, '', ispkg, name in shadowed))\n   shadowed[name] = 1\n   \n  modpkgs.sort()\n  contents = self.multicolumn(modpkgs, self.modpkglink)\n  return self.bigsection(dir, '#ffffff', '#ee77aa', contents)\n  \n  \n  \nclass TextRepr(Repr):\n \"\"\n def __init__(self):\n  Repr.__init__(self)\n  self.maxlist = self.maxtuple = 20\n  self.maxdict = 10\n  self.maxstring = self.maxother = 100\n  \n  \n  \n  \n  \n  \n  \n  \n def repr_string(self, x, level):\n  test = cram(x, self.maxstring)\n  testrepr = repr(test)\n  if '\\\\' in test and '\\\\' not in replace(testrepr, r'\\\\', ''):\n  \n  \n   return 'r' + testrepr[0] + test + testrepr[0]\n  return testrepr\n  \n repr_str = repr_string\n \n def repr_instance(self, x, level):\n  try:\n   return cram(stripid(repr(x)), self.maxstring)\n  except:\n   return '<%s instance>' % x.__class__.__name__\n   \nclass TextDoc(Doc):\n \"\"\n \n \n \n _repr_instance = TextRepr()\n repr = _repr_instance.repr\n \n def bold(self, text):\n  \"\"\n  return ''.join(ch + '\\b' + ch for ch in text)\n  \n def indent(self, text, prefix='    '):\n  \"\"\n  if not text: return ''\n  lines = [prefix + line for line in text.split('\\n')]\n  if lines: lines[-1] = lines[-1].rstrip()\n  return '\\n'.join(lines)\n  \n def section(self, title, contents):\n  \"\"\n  clean_contents = self.indent(contents).rstrip()\n  return self.bold(title) + '\\n' + clean_contents + '\\n\\n'\n  \n  \n  \n def formattree(self, tree, modname, parent=None, prefix=''):\n  \"\"\n  result = ''\n  for entry in tree:\n   if type(entry) is type(()):\n    c, bases = entry\n    result = result + prefix + classname(c, modname)\n    if bases and bases != (parent,):\n     parents = (classname(c, modname) for c in bases)\n     result = result + '(%s)' % ', '.join(parents)\n    result = result + '\\n'\n   elif type(entry) is type([]):\n    result = result + self.formattree(\n    entry, modname, c, prefix + '    ')\n  return result\n  \n def docmodule(self, object, name=None, mod=None):\n  \"\"\n  name = object.__name__ \n  synop, desc = splitdoc(getdoc(object))\n  result = self.section('NAME', name + (synop and ' - ' + synop))\n  all = getattr(object, '__all__', None)\n  docloc = self.getdocloc(object)\n  if docloc is not None:\n   result = result + self.section('MODULE REFERENCE', docloc + \"\"\"\n\nThe following documentation is automatically generated from the Python\nsource files.  It may be incomplete, incorrect or include features that\nare considered implementation detail and may vary between Python\nimplementations.  When in doubt, consult the module reference at the\nlocation listed above.\n\"\"\"   )\n   \n  if desc:\n   result = result + self.section('DESCRIPTION', desc)\n   \n  classes = []\n  for key, value in inspect.getmembers(object, inspect.isclass):\n  \n   if (all is not None\n   or (inspect.getmodule(value) or object) is object):\n    if visiblename(key, all, object):\n     classes.append((key, value))\n  funcs = []\n  for key, value in inspect.getmembers(object, inspect.isroutine):\n  \n   if (all is not None or\n   inspect.isbuiltin(value) or inspect.getmodule(value) is object):\n    if visiblename(key, all, object):\n     funcs.append((key, value))\n  data = []\n  for key, value in inspect.getmembers(object, isdata):\n   if visiblename(key, all, object):\n    data.append((key, value))\n    \n  modpkgs = []\n  modpkgs_names = set()\n  if hasattr(object, '__path__'):\n   for importer, modname, ispkg in pkgutil.iter_modules(object.__path__):\n    modpkgs_names.add(modname)\n    if ispkg:\n     modpkgs.append(modname + ' (package)')\n    else:\n     modpkgs.append(modname)\n     \n   modpkgs.sort()\n   result = result + self.section(\n   'PACKAGE CONTENTS', '\\n'.join(modpkgs))\n   \n   \n  submodules = []\n  for key, value in inspect.getmembers(object, inspect.ismodule):\n   if value.__name__.startswith(name + '.') and key not in modpkgs_names:\n    submodules.append(key)\n  if submodules:\n   submodules.sort()\n   result = result + self.section(\n   'SUBMODULES', '\\n'.join(submodules))\n   \n  if classes:\n   classlist = [value for key, value in classes]\n   contents = [self.formattree(\n   inspect.getclasstree(classlist, 1), name)]\n   for key, value in classes:\n    contents.append(self.document(value, key, name))\n   result = result + self.section('CLASSES', '\\n'.join(contents))\n   \n  if funcs:\n   contents = []\n   for key, value in funcs:\n    contents.append(self.document(value, key, name))\n   result = result + self.section('FUNCTIONS', '\\n'.join(contents))\n   \n  if data:\n   contents = []\n   for key, value in data:\n    contents.append(self.docother(value, key, name, maxlen=70))\n   result = result + self.section('DATA', '\\n'.join(contents))\n   \n  if hasattr(object, '__version__'):\n   version = str(object.__version__)\n   if version[:11] == '$' + 'Revision: ' and version[-1:] == '$':\n    version = version[11:-1].strip()\n   result = result + self.section('VERSION', version)\n  if hasattr(object, '__date__'):\n   result = result + self.section('DATE', str(object.__date__))\n  if hasattr(object, '__author__'):\n   result = result + self.section('AUTHOR', str(object.__author__))\n  if hasattr(object, '__credits__'):\n   result = result + self.section('CREDITS', str(object.__credits__))\n  try:\n   file = inspect.getabsfile(object)\n  except TypeError:\n   file = '(built-in)'\n  result = result + self.section('FILE', file)\n  return result\n  \n def docclass(self, object, name=None, mod=None, *ignored):\n  \"\"\n  realname = object.__name__\n  name = name or realname\n  bases = object.__bases__\n  \n  def makename(c, m=object.__module__):\n   return classname(c, m)\n   \n  if name == realname:\n   title = 'class ' + self.bold(realname)\n  else:\n   title = self.bold(name) + ' = class ' + realname\n  if bases:\n   parents = map(makename, bases)\n   title = title + '(%s)' % ', '.join(parents)\n   \n  doc = getdoc(object)\n  contents = doc and [doc + '\\n'] or []\n  push = contents.append\n  \n  \n  mro = deque(inspect.getmro(object))\n  if len(mro) > 2:\n   push(\"Method resolution order:\")\n   for base in mro:\n    push('    ' + makename(base))\n   push('')\n   \n   \n  class HorizontalRule:\n   def __init__(self):\n    self.needone = 0\n   def maybe(self):\n    if self.needone:\n     push('-' * 70)\n    self.needone = 1\n  hr = HorizontalRule()\n  \n  def spill(msg, attrs, predicate):\n   ok, attrs = _split_list(attrs, predicate)\n   if ok:\n    hr.maybe()\n    push(msg)\n    for name, kind, homecls, value in ok:\n     try:\n      value = getattr(object, name)\n     except Exception:\n     \n     \n      push(self._docdescriptor(name, value, mod))\n     else:\n      push(self.document(value,\n      name, mod, object))\n   return attrs\n   \n  def spilldescriptors(msg, attrs, predicate):\n   ok, attrs = _split_list(attrs, predicate)\n   if ok:\n    hr.maybe()\n    push(msg)\n    for name, kind, homecls, value in ok:\n     push(self._docdescriptor(name, value, mod))\n   return attrs\n   \n  def spilldata(msg, attrs, predicate):\n   ok, attrs = _split_list(attrs, predicate)\n   if ok:\n    hr.maybe()\n    push(msg)\n    for name, kind, homecls, value in ok:\n     if callable(value) or inspect.isdatadescriptor(value):\n      doc = getdoc(value)\n     else:\n      doc = None\n     push(self.docother(getattr(object, name),\n     name, mod, maxlen=70, doc=doc) + '\\n')\n   return attrs\n   \n  attrs = [(name, kind, cls, value)\n  for name, kind, cls, value in classify_class_attrs(object)\n  if visiblename(name, obj=object)]\n  \n  while attrs:\n   if mro:\n    thisclass = mro.popleft()\n   else:\n    thisclass = attrs[0][2]\n   attrs, inherited = _split_list(attrs, lambda t: t[2] is thisclass)\n   \n   if thisclass is builtins.object:\n    attrs = inherited\n    continue\n   elif thisclass is object:\n    tag = \"defined here\"\n   else:\n    tag = \"inherited from %s\" % classname(thisclass,\n    object.__module__)\n    \n    \n   attrs.sort()\n   \n   \n   attrs = spill(\"Methods %s:\\n\" % tag, attrs,\n   lambda t: t[1] == 'method')\n   attrs = spill(\"Class methods %s:\\n\" % tag, attrs,\n   lambda t: t[1] == 'class method')\n   attrs = spill(\"Static methods %s:\\n\" % tag, attrs,\n   lambda t: t[1] == 'static method')\n   attrs = spilldescriptors(\"Data descriptors %s:\\n\" % tag, attrs,\n   lambda t: t[1] == 'data descriptor')\n   attrs = spilldata(\"Data and other attributes %s:\\n\" % tag, attrs,\n   lambda t: t[1] == 'data')\n   assert attrs == []\n   attrs = inherited\n   \n  contents = '\\n'.join(contents)\n  if not contents:\n   return title + '\\n'\n  return title + '\\n' + self.indent(contents.rstrip(), ' |  ') + '\\n'\n  \n def formatvalue(self, object):\n  \"\"\n  return '=' + self.repr(object)\n  \n def docroutine(self, object, name=None, mod=None, cl=None):\n  \"\"\n  realname = object.__name__\n  name = name or realname\n  note = ''\n  skipdocs = 0\n  if inspect.ismethod(object):\n   imclass = object.__self__.__class__\n   if cl:\n    if imclass is not cl:\n     note = ' from ' + classname(imclass, mod)\n   else:\n    if object.__self__ is not None:\n     note = ' method of %s instance' % classname(\n     object.__self__.__class__, mod)\n    else:\n     note = ' unbound %s method' % classname(imclass,mod)\n   object = object.__func__\n   \n  if name == realname:\n   title = self.bold(realname)\n  else:\n   if (cl and realname in cl.__dict__ and\n   cl.__dict__[realname] is object):\n    skipdocs = 1\n   title = self.bold(name) + ' = ' + realname\n  if inspect.isfunction(object):\n   args, varargs, varkw, defaults, kwonlyargs, kwdefaults, ann = inspect.getfullargspec(object)\n   argspec = inspect.formatargspec(\n   args, varargs, varkw, defaults, kwonlyargs, kwdefaults, ann,\n   formatvalue=self.formatvalue,\n   formatannotation=inspect.formatannotationrelativeto(object))\n   if realname == '<lambda>':\n    title = self.bold(name) + ' lambda '\n    \n    \n    \n    argspec = argspec[1:-1] \n  else:\n   argspec = '(...)'\n  decl = title + argspec + note\n  \n  if skipdocs:\n   return decl + '\\n'\n  else:\n   doc = getdoc(object) or ''\n   return decl + '\\n' + (doc and self.indent(doc).rstrip() + '\\n')\n   \n def _docdescriptor(self, name, value, mod):\n  results = []\n  push = results.append\n  \n  if name:\n   push(self.bold(name))\n   push('\\n')\n  doc = getdoc(value) or ''\n  if doc:\n   push(self.indent(doc))\n   push('\\n')\n  return ''.join(results)\n  \n def docproperty(self, object, name=None, mod=None, cl=None):\n  \"\"\n  return self._docdescriptor(name, object, mod)\n  \n def docdata(self, object, name=None, mod=None, cl=None):\n  \"\"\n  return self._docdescriptor(name, object, mod)\n  \n def docother(self, object, name=None, mod=None, parent=None, maxlen=None, doc=None):\n  \"\"\n  repr = self.repr(object)\n  if maxlen:\n   line = (name and name + ' = ' or '') + repr\n   chop = maxlen - len(line)\n   if chop < 0: repr = repr[:chop] + '...'\n  line = (name and self.bold(name) + ' = ' or '') + repr\n  if doc is not None:\n   line += '\\n' + self.indent(str(doc))\n  return line\n  \nclass _PlainTextDoc(TextDoc):\n \"\"\n def bold(self, text):\n  return text\n  \n  \n  \ndef pager(text):\n \"\"\n global pager\n pager = getpager()\n pager(text)\n \ndef getpager():\n \"\"\n if not hasattr(sys.stdout, \"isatty\"):\n  return plainpager\n if not sys.stdin.isatty() or not sys.stdout.isatty():\n  return plainpager\n if 'PAGER' in os.environ:\n  if sys.platform == 'win32': \n   return lambda text: tempfilepager(plain(text), os.environ['PAGER'])\n  elif os.environ.get('TERM') in ('dumb', 'emacs'):\n   return lambda text: pipepager(plain(text), os.environ['PAGER'])\n  else:\n   return lambda text: pipepager(text, os.environ['PAGER'])\n if os.environ.get('TERM') in ('dumb', 'emacs'):\n  return plainpager\n if sys.platform == 'win32' or sys.platform.startswith('os2'):\n  return lambda text: tempfilepager(plain(text), 'more <')\n if hasattr(os, 'system') and os.system('(less) 2>/dev/null') == 0:\n  return lambda text: pipepager(text, 'less')\n  \n import tempfile\n (fd, filename) = tempfile.mkstemp()\n os.close(fd)\n try:\n  if hasattr(os, 'system') and os.system('more \"%s\"' % filename) == 0:\n   return lambda text: pipepager(text, 'more')\n  else:\n   return ttypager\n finally:\n  os.unlink(filename)\n  \ndef plain(text):\n \"\"\n return re.sub('.\\b', '', text)\n \ndef pipepager(text, cmd):\n \"\"\n pipe = os.popen(cmd, 'w')\n try:\n  pipe.write(text)\n  pipe.close()\n except IOError:\n  pass \n  \ndef tempfilepager(text, cmd):\n \"\"\n import tempfile\n filename = tempfile.mktemp()\n file = open(filename, 'w')\n file.write(text)\n file.close()\n try:\n  os.system(cmd + ' \"' + filename + '\"')\n finally:\n  os.unlink(filename)\n  \ndef ttypager(text):\n \"\"\n lines = plain(text).split('\\n')\n try:\n  import tty\n  fd = sys.stdin.fileno()\n  old = tty.tcgetattr(fd)\n  tty.setcbreak(fd)\n  getchar = lambda: sys.stdin.read(1)\n except (ImportError, AttributeError):\n  tty = None\n  getchar = lambda: sys.stdin.readline()[:-1][:1]\n  \n try:\n  r = inc = os.environ.get('LINES', 25) - 1\n  sys.stdout.write('\\n'.join(lines[:inc]) + '\\n')\n  while lines[r:]:\n   sys.stdout.write('-- more --')\n   sys.stdout.flush()\n   c = getchar()\n   \n   if c in ('q', 'Q'):\n    sys.stdout.write('\\r          \\r')\n    break\n   elif c in ('\\r', '\\n'):\n    sys.stdout.write('\\r          \\r' + lines[r] + '\\n')\n    r = r + 1\n    continue\n   if c in ('b', 'B', '\\x1b'):\n    r = r - inc - inc\n    if r < 0: r = 0\n   sys.stdout.write('\\n' + '\\n'.join(lines[r:r+inc]) + '\\n')\n   r = r + inc\n   \n finally:\n  if tty:\n   tty.tcsetattr(fd, tty.TCSAFLUSH, old)\n   \ndef plainpager(text):\n \"\"\n sys.stdout.write(plain(text))\n \ndef describe(thing):\n \"\"\n if inspect.ismodule(thing):\n  if thing.__name__ in sys.builtin_module_names:\n   return 'built-in module ' + thing.__name__\n  if hasattr(thing, '__path__'):\n   return 'package ' + thing.__name__\n  else:\n   return 'module ' + thing.__name__\n if inspect.isbuiltin(thing):\n  return 'built-in function ' + thing.__name__\n if inspect.isgetsetdescriptor(thing):\n  return 'getset descriptor %s.%s.%s' % (\n  thing.__objclass__.__module__, thing.__objclass__.__name__,\n  thing.__name__)\n if inspect.ismemberdescriptor(thing):\n  return 'member descriptor %s.%s.%s' % (\n  thing.__objclass__.__module__, thing.__objclass__.__name__,\n  thing.__name__)\n if inspect.isclass(thing):\n  return 'class ' + thing.__name__\n if inspect.isfunction(thing):\n  return 'function ' + thing.__name__\n if inspect.ismethod(thing):\n  return 'method ' + thing.__name__\n return type(thing).__name__\n \ndef locate(path, forceload=0):\n \"\"\n parts = [part for part in path.split('.') if part]\n module, n = None, 0\n while n < len(parts):\n  nextmodule = safeimport('.'.join(parts[:n+1]), forceload)\n  if nextmodule: module, n = nextmodule, n + 1\n  else: break\n if module:\n  object = module\n else:\n  object = builtins\n for part in parts[n:]:\n  try:\n   object = getattr(object, part)\n  except AttributeError:\n   return None\n return object\n \n \n \ntext = TextDoc()\nplaintext = _PlainTextDoc()\nhtml = HTMLDoc()\n\ndef resolve(thing, forceload=0):\n \"\"\n if isinstance(thing, str):\n  object = locate(thing, forceload)\n  if not object:\n   raise ImportError('no Python documentation found for %r' % thing)\n  return object, thing\n else:\n  name = getattr(thing, '__name__', None)\n  return thing, name if isinstance(name, str) else None\n  \ndef render_doc(thing, title='Python Library Documentation: %s', forceload=0,\nrenderer=None):\n \"\"\n if renderer is None:\n  renderer = text\n object, name = resolve(thing, forceload)\n desc = describe(object)\n module = inspect.getmodule(object)\n if name and '.' in name:\n  desc += ' in ' + name[:name.rfind('.')]\n elif module and module is not object:\n  desc += ' in module ' + module.__name__\n  \n if not (inspect.ismodule(object) or\n inspect.isclass(object) or\n inspect.isroutine(object) or\n inspect.isgetsetdescriptor(object) or\n inspect.ismemberdescriptor(object) or\n isinstance(object, property)):\n \n \n  object = type(object)\n  desc += ' object'\n return title % desc + '\\n\\n' + renderer.document(object, name)\n \ndef doc(thing, title='Python Library Documentation: %s', forceload=0,\noutput=None):\n \"\"\n try:\n  if output is None:\n   pager(render_doc(thing, title, forceload))\n  else:\n   output.write(render_doc(thing, title, forceload, plaintext))\n except (ImportError, ErrorDuringImport) as value:\n  print(value)\n  \ndef writedoc(thing, forceload=0):\n \"\"\n try:\n  object, name = resolve(thing, forceload)\n  page = html.page(describe(object), html.document(object, name))\n  file = open(name + '.html', 'w', encoding='utf-8')\n  file.write(page)\n  file.close()\n  print('wrote', name + '.html')\n except (ImportError, ErrorDuringImport) as value:\n  print(value)\n  \ndef writedocs(dir, pkgpath='', done=None):\n \"\"\n if done is None: done = {}\n for importer, modname, ispkg in pkgutil.walk_packages([dir], pkgpath):\n  writedoc(modname)\n return\n \nclass Helper:\n\n\n\n\n\n\n\n\n\n\n\n\n keywords = {\n 'False': '',\n 'None': '',\n 'True': '',\n 'and': 'BOOLEAN',\n 'as': 'with',\n 'assert': ('assert', ''),\n 'break': ('break', 'while for'),\n 'class': ('class', 'CLASSES SPECIALMETHODS'),\n 'continue': ('continue', 'while for'),\n 'def': ('function', ''),\n 'del': ('del', 'BASICMETHODS'),\n 'elif': 'if',\n 'else': ('else', 'while for'),\n 'except': 'try',\n 'finally': 'try',\n 'for': ('for', 'break continue while'),\n 'from': 'import',\n 'global': ('global', 'nonlocal NAMESPACES'),\n 'if': ('if', 'TRUTHVALUE'),\n 'import': ('import', 'MODULES'),\n 'in': ('in', 'SEQUENCEMETHODS'),\n 'is': 'COMPARISON',\n 'lambda': ('lambda', 'FUNCTIONS'),\n 'nonlocal': ('nonlocal', 'global NAMESPACES'),\n 'not': 'BOOLEAN',\n 'or': 'BOOLEAN',\n 'pass': ('pass', ''),\n 'raise': ('raise', 'EXCEPTIONS'),\n 'return': ('return', 'FUNCTIONS'),\n 'try': ('try', 'EXCEPTIONS'),\n 'while': ('while', 'break continue if TRUTHVALUE'),\n 'with': ('with', 'CONTEXTMANAGERS EXCEPTIONS yield'),\n 'yield': ('yield', ''),\n }\n \n \n _symbols_inverse = {\n 'STRINGS' : (\"'\", \"'''\", \"r'\", \"b'\", '\"\"\"', '\"', 'r\"', 'b\"'),\n 'OPERATORS' : ('+', '-', '*', '**', '/', '//', '%', '<<', '>>', '&',\n '|', '^', '~', '<', '>', '<=', '>=', '==', '!=', '<>'),\n 'COMPARISON' : ('<', '>', '<=', '>=', '==', '!=', '<>'),\n 'UNARY' : ('-', '~'),\n 'AUGMENTEDASSIGNMENT' : ('+=', '-=', '*=', '/=', '%=', '&=', '|=',\n '^=', '<<=', '>>=', '**=', '//='),\n 'BITWISE' : ('<<', '>>', '&', '|', '^', '~'),\n 'COMPLEX' : ('j', 'J')\n }\n symbols = {\n '%': 'OPERATORS FORMATTING',\n '**': 'POWER',\n ',': 'TUPLES LISTS FUNCTIONS',\n '.': 'ATTRIBUTES FLOAT MODULES OBJECTS',\n '...': 'ELLIPSIS',\n ':': 'SLICINGS DICTIONARYLITERALS',\n '@': 'def class',\n '\\\\': 'STRINGS',\n '_': 'PRIVATENAMES',\n '__': 'PRIVATENAMES SPECIALMETHODS',\n '`': 'BACKQUOTES',\n '(': 'TUPLES FUNCTIONS CALLS',\n ')': 'TUPLES FUNCTIONS CALLS',\n '[': 'LISTS SUBSCRIPTS SLICINGS',\n ']': 'LISTS SUBSCRIPTS SLICINGS'\n }\n for topic, symbols_ in _symbols_inverse.items():\n  for symbol in symbols_:\n   topics = symbols.get(symbol, topic)\n   if topic not in topics:\n    topics = topics + ' ' + topic\n   symbols[symbol] = topics\n   \n topics = {\n 'TYPES': ('types', 'STRINGS UNICODE NUMBERS SEQUENCES MAPPINGS '\n 'FUNCTIONS CLASSES MODULES FILES inspect'),\n 'STRINGS': ('strings', 'str UNICODE SEQUENCES STRINGMETHODS '\n 'FORMATTING TYPES'),\n 'STRINGMETHODS': ('string-methods', 'STRINGS FORMATTING'),\n 'FORMATTING': ('formatstrings', 'OPERATORS'),\n 'UNICODE': ('strings', 'encodings unicode SEQUENCES STRINGMETHODS '\n 'FORMATTING TYPES'),\n 'NUMBERS': ('numbers', 'INTEGER FLOAT COMPLEX TYPES'),\n 'INTEGER': ('integers', 'int range'),\n 'FLOAT': ('floating', 'float math'),\n 'COMPLEX': ('imaginary', 'complex cmath'),\n 'SEQUENCES': ('typesseq', 'STRINGMETHODS FORMATTING range LISTS'),\n 'MAPPINGS': 'DICTIONARIES',\n 'FUNCTIONS': ('typesfunctions', 'def TYPES'),\n 'METHODS': ('typesmethods', 'class def CLASSES TYPES'),\n 'CODEOBJECTS': ('bltin-code-objects', 'compile FUNCTIONS TYPES'),\n 'TYPEOBJECTS': ('bltin-type-objects', 'types TYPES'),\n 'FRAMEOBJECTS': 'TYPES',\n 'TRACEBACKS': 'TYPES',\n 'NONE': ('bltin-null-object', ''),\n 'ELLIPSIS': ('bltin-ellipsis-object', 'SLICINGS'),\n 'FILES': ('bltin-file-objects', ''),\n 'SPECIALATTRIBUTES': ('specialattrs', ''),\n 'CLASSES': ('types', 'class SPECIALMETHODS PRIVATENAMES'),\n 'MODULES': ('typesmodules', 'import'),\n 'PACKAGES': 'import',\n 'EXPRESSIONS': ('operator-summary', 'lambda or and not in is BOOLEAN '\n 'COMPARISON BITWISE SHIFTING BINARY FORMATTING POWER '\n 'UNARY ATTRIBUTES SUBSCRIPTS SLICINGS CALLS TUPLES '\n 'LISTS DICTIONARIES'),\n 'OPERATORS': 'EXPRESSIONS',\n 'PRECEDENCE': 'EXPRESSIONS',\n 'OBJECTS': ('objects', 'TYPES'),\n 'SPECIALMETHODS': ('specialnames', 'BASICMETHODS ATTRIBUTEMETHODS '\n 'CALLABLEMETHODS SEQUENCEMETHODS MAPPINGMETHODS '\n 'NUMBERMETHODS CLASSES'),\n 'BASICMETHODS': ('customization', 'hash repr str SPECIALMETHODS'),\n 'ATTRIBUTEMETHODS': ('attribute-access', 'ATTRIBUTES SPECIALMETHODS'),\n 'CALLABLEMETHODS': ('callable-types', 'CALLS SPECIALMETHODS'),\n 'SEQUENCEMETHODS': ('sequence-types', 'SEQUENCES SEQUENCEMETHODS '\n 'SPECIALMETHODS'),\n 'MAPPINGMETHODS': ('sequence-types', 'MAPPINGS SPECIALMETHODS'),\n 'NUMBERMETHODS': ('numeric-types', 'NUMBERS AUGMENTEDASSIGNMENT '\n 'SPECIALMETHODS'),\n 'EXECUTION': ('execmodel', 'NAMESPACES DYNAMICFEATURES EXCEPTIONS'),\n 'NAMESPACES': ('naming', 'global nonlocal ASSIGNMENT DELETION DYNAMICFEATURES'),\n 'DYNAMICFEATURES': ('dynamic-features', ''),\n 'SCOPING': 'NAMESPACES',\n 'FRAMES': 'NAMESPACES',\n 'EXCEPTIONS': ('exceptions', 'try except finally raise'),\n 'CONVERSIONS': ('conversions', ''),\n 'IDENTIFIERS': ('identifiers', 'keywords SPECIALIDENTIFIERS'),\n 'SPECIALIDENTIFIERS': ('id-classes', ''),\n 'PRIVATENAMES': ('atom-identifiers', ''),\n 'LITERALS': ('atom-literals', 'STRINGS NUMBERS TUPLELITERALS '\n 'LISTLITERALS DICTIONARYLITERALS'),\n 'TUPLES': 'SEQUENCES',\n 'TUPLELITERALS': ('exprlists', 'TUPLES LITERALS'),\n 'LISTS': ('typesseq-mutable', 'LISTLITERALS'),\n 'LISTLITERALS': ('lists', 'LISTS LITERALS'),\n 'DICTIONARIES': ('typesmapping', 'DICTIONARYLITERALS'),\n 'DICTIONARYLITERALS': ('dict', 'DICTIONARIES LITERALS'),\n 'ATTRIBUTES': ('attribute-references', 'getattr hasattr setattr ATTRIBUTEMETHODS'),\n 'SUBSCRIPTS': ('subscriptions', 'SEQUENCEMETHODS'),\n 'SLICINGS': ('slicings', 'SEQUENCEMETHODS'),\n 'CALLS': ('calls', 'EXPRESSIONS'),\n 'POWER': ('power', 'EXPRESSIONS'),\n 'UNARY': ('unary', 'EXPRESSIONS'),\n 'BINARY': ('binary', 'EXPRESSIONS'),\n 'SHIFTING': ('shifting', 'EXPRESSIONS'),\n 'BITWISE': ('bitwise', 'EXPRESSIONS'),\n 'COMPARISON': ('comparisons', 'EXPRESSIONS BASICMETHODS'),\n 'BOOLEAN': ('booleans', 'EXPRESSIONS TRUTHVALUE'),\n 'ASSERTION': 'assert',\n 'ASSIGNMENT': ('assignment', 'AUGMENTEDASSIGNMENT'),\n 'AUGMENTEDASSIGNMENT': ('augassign', 'NUMBERMETHODS'),\n 'DELETION': 'del',\n 'RETURNING': 'return',\n 'IMPORTING': 'import',\n 'CONDITIONAL': 'if',\n 'LOOPING': ('compound', 'for while break continue'),\n 'TRUTHVALUE': ('truth', 'if while and or not BASICMETHODS'),\n 'DEBUGGING': ('debugger', 'pdb'),\n 'CONTEXTMANAGERS': ('context-managers', 'with'),\n }\n \n def __init__(self, input=None, output=None):\n  self._input = input\n  self._output = output\n  \n  \n  self.input = self._input or sys.stdin \n  self.output = self._output or sys.stdout \n  \n  \n  \n  \n  \n def __repr__(self):\n  if inspect.stack()[1][3] == '?':\n   self()\n   return ''\n  return '<pydoc.Helper instance>'\n  \n _GoInteractive = object()\n def __call__(self, request=_GoInteractive):\n  if request is not self._GoInteractive:\n   self.help(request)\n  else:\n   self.intro()\n   self.interact()\n   self.output.write('''\nYou are now leaving help and returning to the Python interpreter.\nIf you want to ask for help on a particular object directly from the\ninterpreter, you can type \"help(object)\".  Executing \"help('string')\"\nhas the same effect as typing a particular string at the help> prompt.\n'''   )\n   \n def interact(self):\n  self.output.write('\\n')\n  while True:\n   try:\n    request = self.getline('help> ')\n    if not request: break\n   except (KeyboardInterrupt, EOFError):\n    break\n   request = replace(request, '\"', '', \"'\", '').strip()\n   if request.lower() in ('q', 'quit'): break\n   self.help(request)\n   \n def getline(self, prompt):\n  \"\"\n  if self.input is sys.stdin:\n   return input(prompt)\n  else:\n   self.output.write(prompt)\n   self.output.flush()\n   return self.input.readline()\n   \n def help(self, request):\n  if type(request) is type(''):\n   request = request.strip()\n   if request == 'help': self.intro()\n   elif request == 'keywords': self.listkeywords()\n   elif request == 'symbols': self.listsymbols()\n   elif request == 'topics': self.listtopics()\n   elif request == 'modules': self.listmodules()\n   elif request[:8] == 'modules ':\n    self.listmodules(request.split()[1])\n   elif request in self.symbols: self.showsymbol(request)\n   elif request in ['True', 'False', 'None']:\n   \n    doc(eval(request), 'Help on %s:')\n   elif request in self.keywords: self.showtopic(request)\n   elif request in self.topics: self.showtopic(request)\n   elif request: doc(request, 'Help on %s:', output=self._output)\n  elif isinstance(request, Helper): self()\n  else: doc(request, 'Help on %s:', output=self._output)\n  self.output.write('\\n')\n  \n def intro(self):\n  self.output.write('''\nWelcome to Python %s!  This is the interactive help utility.\n\nIf this is your first time using Python, you should definitely check out\nthe tutorial on the Internet at http://docs.python.org/%s/tutorial/.\n\nEnter the name of any module, keyword, or topic to get help on writing\nPython programs and using Python modules.  To quit this help utility and\nreturn to the interpreter, just type \"quit\".\n\nTo get a list of available modules, keywords, or topics, type \"modules\",\n\"keywords\", or \"topics\".  Each module also comes with a one-line summary\nof what it does; to list the modules whose summaries contain a given word\nsuch as \"spam\", type \"modules spam\".\n'''  % tuple([sys.version[:3]]*2))\n  \n def list(self, items, columns=4, width=80):\n  items = list(sorted(items))\n  colw = width // columns\n  rows = (len(items) + columns - 1) // columns\n  for row in range(rows):\n   for col in range(columns):\n    i = col * rows + row\n    if i < len(items):\n     self.output.write(items[i])\n     if col < columns - 1:\n      self.output.write(' ' + ' ' * (colw - 1 - len(items[i])))\n   self.output.write('\\n')\n   \n def listkeywords(self):\n  self.output.write('''\nHere is a list of the Python keywords.  Enter any keyword to get more help.\n\n'''  )\n  self.list(self.keywords.keys())\n  \n def listsymbols(self):\n  self.output.write('''\nHere is a list of the punctuation symbols which Python assigns special meaning\nto. Enter any symbol to get more help.\n\n'''  )\n  self.list(self.symbols.keys())\n  \n def listtopics(self):\n  self.output.write('''\nHere is a list of available topics.  Enter any topic name to get more help.\n\n'''  )\n  self.list(self.topics.keys())\n  \n def showtopic(self, topic, more_xrefs=''):\n  try:\n   import pydoc_data.topics\n  except ImportError:\n   self.output.write('''\nSorry, topic and keyword documentation is not available because the\nmodule \"pydoc_data.topics\" could not be found.\n'''   )\n   return\n  target = self.topics.get(topic, self.keywords.get(topic))\n  if not target:\n   self.output.write('no documentation found for %s\\n' % repr(topic))\n   return\n  if type(target) is type(''):\n   return self.showtopic(target, more_xrefs)\n   \n  label, xrefs = target\n  try:\n   doc = pydoc_data.topics.topics[label]\n  except KeyError:\n   self.output.write('no documentation found for %s\\n' % repr(topic))\n   return\n  pager(doc.strip() + '\\n')\n  if more_xrefs:\n   xrefs = (xrefs or '') + ' ' + more_xrefs\n  if xrefs:\n   import formatter\n   buffer = io.StringIO()\n   formatter.DumbWriter(buffer).send_flowing_data(\n   'Related help topics: ' + ', '.join(xrefs.split()) + '\\n')\n   self.output.write('\\n%s\\n' % buffer.getvalue())\n   \n def _gettopic(self, topic, more_xrefs=''):\n  \"\"\n  try:\n   import pydoc_data.topics\n  except ImportError:\n   return('''\nSorry, topic and keyword documentation is not available because the\nmodule \"pydoc_data.topics\" could not be found.\n'''   , '')\n  target = self.topics.get(topic, self.keywords.get(topic))\n  if not target:\n   raise ValueError('could not find topic')\n  if isinstance(target, str):\n   return self._gettopic(target, more_xrefs)\n  label, xrefs = target\n  doc = pydoc_data.topics.topics[label]\n  if more_xrefs:\n   xrefs = (xrefs or '') + ' ' + more_xrefs\n  return doc, xrefs\n  \n def showsymbol(self, symbol):\n  target = self.symbols[symbol]\n  topic, _, xrefs = target.partition(' ')\n  self.showtopic(topic, xrefs)\n  \n def listmodules(self, key=''):\n  if key:\n   self.output.write('''\nHere is a list of matching modules.  Enter any module name to get more help.\n\n'''   )\n   apropos(key)\n  else:\n   self.output.write('''\nPlease wait a moment while I gather a list of all available modules...\n\n'''   )\n   modules = {}\n   def callback(path, modname, desc, modules=modules):\n    if modname and modname[-9:] == '.__init__':\n     modname = modname[:-9] + ' (package)'\n    if modname.find('.') < 0:\n     modules[modname] = 1\n   def onerror(modname):\n    callback(None, modname, None)\n   ModuleScanner().run(callback, onerror=onerror)\n   self.list(modules.keys())\n   self.output.write('''\nEnter any module name to get more help.  Or, type \"modules spam\" to search\nfor modules whose descriptions contain the word \"spam\".\n'''   )\n   \nhelp = Helper()\n\nclass Scanner:\n \"\"\n def __init__(self, roots, children, descendp):\n  self.roots = roots[:]\n  self.state = []\n  self.children = children\n  self.descendp = descendp\n  \n def next(self):\n  if not self.state:\n   if not self.roots:\n    return None\n   root = self.roots.pop(0)\n   self.state = [(root, self.children(root))]\n  node, children = self.state[-1]\n  if not children:\n   self.state.pop()\n   return self.next()\n  child = children.pop(0)\n  if self.descendp(child):\n   self.state.append((child, self.children(child)))\n  return child\n  \n  \nclass ModuleScanner:\n \"\"\n \n def run(self, callback, key=None, completer=None, onerror=None):\n  if key: key = key.lower()\n  self.quit = False\n  seen = {}\n  \n  for modname in sys.builtin_module_names:\n   if modname != '__main__':\n    seen[modname] = 1\n    if key is None:\n     callback(None, modname, '')\n    else:\n     name = __import__(modname).__doc__ or ''\n     desc = name.split('\\n')[0]\n     name = modname + ' - ' + desc\n     if name.lower().find(key) >= 0:\n      callback(None, modname, desc)\n      \n  for importer, modname, ispkg in pkgutil.walk_packages(onerror=onerror):\n   if self.quit:\n    break\n    \n   if key is None:\n    callback(None, modname, '')\n   else:\n    try:\n     loader = importer.find_module(modname)\n    except SyntaxError:\n    \n     continue\n    if hasattr(loader, 'get_source'):\n     try:\n      source = loader.get_source(modname)\n     except Exception:\n      if onerror:\n       onerror(modname)\n      continue\n     desc = source_synopsis(io.StringIO(source)) or ''\n     if hasattr(loader, 'get_filename'):\n      path = loader.get_filename(modname)\n     else:\n      path = None\n    else:\n     try:\n      module = loader.load_module(modname)\n     except ImportError:\n      if onerror:\n       onerror(modname)\n      continue\n     desc = (module.__doc__ or '').splitlines()[0]\n     path = getattr(module,'__file__',None)\n    name = modname + ' - ' + desc\n    if name.lower().find(key) >= 0:\n     callback(path, modname, desc)\n     \n  if completer:\n   completer()\n   \ndef apropos(key):\n \"\"\n def callback(path, modname, desc):\n  if modname[-9:] == '.__init__':\n   modname = modname[:-9] + ' (package)'\n  print(modname, desc and '- ' + desc)\n def onerror(modname):\n  pass\n with warnings.catch_warnings():\n  warnings.filterwarnings('ignore') \n  ModuleScanner().run(callback, key, onerror=onerror)\n  \n  \n  \ndef _start_server(urlhandler, port):\n \"\"\n import http.server\n import email.message\n import select\n import threading\n \n class DocHandler(http.server.BaseHTTPRequestHandler):\n \n  def do_GET(self):\n   \"\"\n   if self.path.endswith('.css'):\n    content_type = 'text/css'\n   else:\n    content_type = 'text/html'\n   self.send_response(200)\n   self.send_header('Content-Type', '%s; charset=UTF-8' % content_type)\n   self.end_headers()\n   self.wfile.write(self.urlhandler(\n   self.path, content_type).encode('utf-8'))\n   \n  def log_message(self, *args):\n  \n   pass\n   \n class DocServer(http.server.HTTPServer):\n \n  def __init__(self, port, callback):\n   self.host = (sys.platform == 'mac') and '127.0.0.1' or 'localhost'\n   self.address = ('', port)\n   self.callback = callback\n   self.base.__init__(self, self.address, self.handler)\n   self.quit = False\n   \n  def serve_until_quit(self):\n   while not self.quit:\n    rd, wr, ex = select.select([self.socket.fileno()], [], [], 1)\n    if rd:\n     self.handle_request()\n   self.server_close()\n   \n  def server_activate(self):\n   self.base.server_activate(self)\n   if self.callback:\n    self.callback(self)\n    \n class ServerThread(threading.Thread):\n \n  def __init__(self, urlhandler, port):\n   self.urlhandler = urlhandler\n   self.port = int(port)\n   threading.Thread.__init__(self)\n   self.serving = False\n   self.error = None\n   \n  def run(self):\n   \"\"\n   try:\n    DocServer.base = http.server.HTTPServer\n    DocServer.handler = DocHandler\n    DocHandler.MessageClass = email.message.Message\n    DocHandler.urlhandler = staticmethod(self.urlhandler)\n    docsvr = DocServer(self.port, self.ready)\n    self.docserver = docsvr\n    docsvr.serve_until_quit()\n   except Exception as e:\n    self.error = e\n    \n  def ready(self, server):\n   self.serving = True\n   self.host = server.host\n   self.port = server.server_port\n   self.url = 'http://%s:%d/' % (self.host, self.port)\n   \n  def stop(self):\n   \"\"\n   self.docserver.quit = True\n   self.serving = False\n   self.url = None\n   \n thread = ServerThread(urlhandler, port)\n thread.start()\n \n \n while not thread.error and not thread.serving:\n  time.sleep(.01)\n return thread\n \n \ndef _url_handler(url, content_type=\"text/html\"):\n \"\"\n class _HTMLDoc(HTMLDoc):\n \n  def page(self, title, contents):\n   \"\"\n   css_path = \"pydoc_data/_pydoc.css\"\n   css_link = (\n   '<link rel=\"stylesheet\" type=\"text/css\" href=\"%s\">' %\n   css_path)\n   return '''\\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<html><head><title>Pydoc: %s</title>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n%s</head><body bgcolor=\"#f0f0f8\">%s<div style=\"clear:both;padding-top:.5em;\">%s</div>\n</body></html>'''   % (title, css_link, html_navbar(), contents)\n   \n  def filelink(self, url, path):\n   return '<a href=\"getfile?key=%s\">%s</a>' % (url, path)\n   \n   \n html = _HTMLDoc()\n \n def html_navbar():\n  version = html.escape(\"%s [%s, %s]\" % (platform.python_version(),\n  platform.python_build()[0],\n  platform.python_compiler()))\n  return \"\"\"\n            <div style='float:left'>\n                Python %s<br>%s\n            </div>\n            <div style='float:right'>\n                <div style='text-align:center'>\n                  <a href=\"index.html\">Module Index</a>\n                  : <a href=\"topics.html\">Topics</a>\n                  : <a href=\"keywords.html\">Keywords</a>\n                </div>\n                <div>\n                    <form action=\"get\" style='display:inline;'>\n                      <input type=text name=key size=15>\n                      <input type=submit value=\"Get\">\n                    </form>&nbsp;\n                    <form action=\"search\" style='display:inline;'>\n                      <input type=text name=key size=15>\n                      <input type=submit value=\"Search\">\n                    </form>\n                </div>\n            </div>\n            \"\"\"  % (version, html.escape(platform.platform(terse=True)))\n  \n def html_index():\n  \"\"\n  \n  def bltinlink(name):\n   return '<a href=\"%s.html\">%s</a>' % (name, name)\n   \n  heading = html.heading(\n  '<big><big><strong>Index of Modules</strong></big></big>',\n  '#ffffff', '#7799ee')\n  names = [name for name in sys.builtin_module_names\n  if name != '__main__']\n  contents = html.multicolumn(names, bltinlink)\n  contents = [heading, '<p>' + html.bigsection(\n  'Built-in Modules', '#ffffff', '#ee77aa', contents)]\n  \n  seen = {}\n  for dir in sys.path:\n   contents.append(html.index(dir, seen))\n   \n  contents.append(\n  '<p align=right><font color=\"#909090\" face=\"helvetica,'\n  'arial\"><strong>pydoc</strong> by Ka-Ping Yee'\n  '&lt;ping@lfw.org&gt;</font>')\n  return 'Index of Modules', ''.join(contents)\n  \n def html_search(key):\n  \"\"\n  \n  search_result = []\n  \n  def callback(path, modname, desc):\n   if modname[-9:] == '.__init__':\n    modname = modname[:-9] + ' (package)'\n   search_result.append((modname, desc and '- ' + desc))\n   \n  with warnings.catch_warnings():\n   warnings.filterwarnings('ignore') \n   ModuleScanner().run(callback, key)\n   \n   \n  def bltinlink(name):\n   return '<a href=\"%s.html\">%s</a>' % (name, name)\n   \n  results = []\n  heading = html.heading(\n  '<big><big><strong>Search Results</strong></big></big>',\n  '#ffffff', '#7799ee')\n  for name, desc in search_result:\n   results.append(bltinlink(name) + desc)\n  contents = heading + html.bigsection(\n  'key = %s' % key, '#ffffff', '#ee77aa', '<br>'.join(results))\n  return 'Search Results', contents\n  \n def html_getfile(path):\n  \"\"\n  path = path.replace('%20', ' ')\n  with tokenize.open(path) as fp:\n   lines = html.escape(fp.read())\n  body = '<pre>%s</pre>' % lines\n  heading = html.heading(\n  '<big><big><strong>File Listing</strong></big></big>',\n  '#ffffff', '#7799ee')\n  contents = heading + html.bigsection(\n  'File: %s' % path, '#ffffff', '#ee77aa', body)\n  return 'getfile %s' % path, contents\n  \n def html_topics():\n  \"\"\n  \n  def bltinlink(name):\n   return '<a href=\"topic?key=%s\">%s</a>' % (name, name)\n   \n  heading = html.heading(\n  '<big><big><strong>INDEX</strong></big></big>',\n  '#ffffff', '#7799ee')\n  names = sorted(Helper.topics.keys())\n  \n  contents = html.multicolumn(names, bltinlink)\n  contents = heading + html.bigsection(\n  'Topics', '#ffffff', '#ee77aa', contents)\n  return 'Topics', contents\n  \n def html_keywords():\n  \"\"\n  heading = html.heading(\n  '<big><big><strong>INDEX</strong></big></big>',\n  '#ffffff', '#7799ee')\n  names = sorted(Helper.keywords.keys())\n  \n  def bltinlink(name):\n   return '<a href=\"topic?key=%s\">%s</a>' % (name, name)\n   \n  contents = html.multicolumn(names, bltinlink)\n  contents = heading + html.bigsection(\n  'Keywords', '#ffffff', '#ee77aa', contents)\n  return 'Keywords', contents\n  \n def html_topicpage(topic):\n  \"\"\n  buf = io.StringIO()\n  htmlhelp = Helper(buf, buf)\n  contents, xrefs = htmlhelp._gettopic(topic)\n  if topic in htmlhelp.keywords:\n   title = 'KEYWORD'\n  else:\n   title = 'TOPIC'\n  heading = html.heading(\n  '<big><big><strong>%s</strong></big></big>' % title,\n  '#ffffff', '#7799ee')\n  contents = '<pre>%s</pre>' % html.markup(contents)\n  contents = html.bigsection(topic , '#ffffff','#ee77aa', contents)\n  if xrefs:\n   xrefs = sorted(xrefs.split())\n   \n   def bltinlink(name):\n    return '<a href=\"topic?key=%s\">%s</a>' % (name, name)\n    \n   xrefs = html.multicolumn(xrefs, bltinlink)\n   xrefs = html.section('Related help topics: ',\n   '#ffffff', '#ee77aa', xrefs)\n  return ('%s %s' % (title, topic),\n  ''.join((heading, contents, xrefs)))\n  \n def html_getobj(url):\n  obj = locate(url, forceload=1)\n  if obj is None and url != 'None':\n   raise ValueError('could not find object')\n  title = describe(obj)\n  content = html.document(obj, url)\n  return title, content\n  \n def html_error(url, exc):\n  heading = html.heading(\n  '<big><big><strong>Error</strong></big></big>',\n  '#ffffff', '#7799ee')\n  contents = '<br>'.join(html.escape(line) for line in\n  format_exception_only(type(exc), exc))\n  contents = heading + html.bigsection(url, '#ffffff', '#bb0000',\n  contents)\n  return \"Error - %s\" % url, contents\n  \n def get_html_page(url):\n  \"\"\n  complete_url = url\n  if url.endswith('.html'):\n   url = url[:-5]\n  try:\n   if url in (\"\", \"index\"):\n    title, content = html_index()\n   elif url == \"topics\":\n    title, content = html_topics()\n   elif url == \"keywords\":\n    title, content = html_keywords()\n   elif '=' in url:\n    op, _, url = url.partition('=')\n    if op == \"search?key\":\n     title, content = html_search(url)\n    elif op == \"getfile?key\":\n     title, content = html_getfile(url)\n    elif op == \"topic?key\":\n    \n     try:\n      title, content = html_topicpage(url)\n     except ValueError:\n      title, content = html_getobj(url)\n    elif op == \"get?key\":\n    \n     if url in (\"\", \"index\"):\n      title, content = html_index()\n     else:\n      try:\n       title, content = html_getobj(url)\n      except ValueError:\n       title, content = html_topicpage(url)\n    else:\n     raise ValueError('bad pydoc url')\n   else:\n    title, content = html_getobj(url)\n  except Exception as exc:\n  \n   title, content = html_error(complete_url, exc)\n  return html.page(title, content)\n  \n if url.startswith('/'):\n  url = url[1:]\n if content_type == 'text/css':\n  path_here = os.path.dirname(os.path.realpath(__file__))\n  css_path = os.path.join(path_here, url)\n  with open(css_path) as fp:\n   return ''.join(fp.readlines())\n elif content_type == 'text/html':\n  return get_html_page(url)\n  \n raise TypeError('unknown content type %r for url %s' % (content_type, url))\n \n \ndef browse(port=0, *, open_browser=True):\n \"\"\n import webbrowser\n serverthread = _start_server(_url_handler, port)\n if serverthread.error:\n  print(serverthread.error)\n  return\n if serverthread.serving:\n  server_help_msg = 'Server commands: [b]rowser, [q]uit'\n  if open_browser:\n   webbrowser.open(serverthread.url)\n  try:\n   print('Server ready at', serverthread.url)\n   print(server_help_msg)\n   while serverthread.serving:\n    cmd = input('server> ')\n    cmd = cmd.lower()\n    if cmd == 'q':\n     break\n    elif cmd == 'b':\n     webbrowser.open(serverthread.url)\n    else:\n     print(server_help_msg)\n  except (KeyboardInterrupt, EOFError):\n   print()\n  finally:\n   if serverthread.serving:\n    serverthread.stop()\n    print('Server stopped')\n    \n    \n    \n    \ndef ispath(x):\n return isinstance(x, str) and x.find(os.sep) >= 0\n \ndef cli():\n \"\"\n import getopt\n class BadUsage(Exception): pass\n \n \n \n if '' not in sys.path:\n  scriptdir = os.path.dirname(sys.argv[0])\n  if scriptdir in sys.path:\n   sys.path.remove(scriptdir)\n  sys.path.insert(0, '.')\n  \n try:\n  opts, args = getopt.getopt(sys.argv[1:], 'bk:p:w')\n  writing = False\n  start_server = False\n  open_browser = False\n  port = None\n  for opt, val in opts:\n   if opt == '-b':\n    start_server = True\n    open_browser = True\n   if opt == '-k':\n    apropos(val)\n    return\n   if opt == '-p':\n    start_server = True\n    port = val\n   if opt == '-w':\n    writing = True\n    \n  if start_server:\n   if port is None:\n    port = 0\n   browse(port, open_browser=open_browser)\n   return\n   \n  if not args: raise BadUsage\n  for arg in args:\n   if ispath(arg) and not os.path.exists(arg):\n    print('file %r does not exist' % arg)\n    break\n   try:\n    if ispath(arg) and os.path.isfile(arg):\n     arg = importfile(arg)\n    if writing:\n     if ispath(arg) and os.path.isdir(arg):\n      writedocs(arg)\n     else:\n      writedoc(arg)\n    else:\n     help.help(arg)\n   except ErrorDuringImport as value:\n    print(value)\n    \n except (getopt.error, BadUsage):\n  cmd = os.path.splitext(os.path.basename(sys.argv[0]))[0]\n  print(\"\"\"pydoc - the Python documentation tool\n\n{cmd} <name> ...\n    Show text documentation on something.  <name> may be the name of a\n    Python keyword, topic, function, module, or package, or a dotted\n    reference to a class or function within a module or module in a\n    package.  If <name> contains a '{sep}', it is used as the path to a\n    Python source file to document. If name is 'keywords', 'topics',\n    or 'modules', a listing of these things is displayed.\n\n{cmd} -k <keyword>\n    Search for a keyword in the synopsis lines of all available modules.\n\n{cmd} -p <port>\n    Start an HTTP server on the given port on the local machine.  Port\n    number 0 can be used to get an arbitrary unused port.\n\n{cmd} -b\n    Start an HTTP server on an arbitrary unused port and open a Web browser\n    to interactively browse documentation.  The -p option can be used with\n    the -b option to explicitly specify the server port.\n\n{cmd} -w <name> ...\n    Write out the HTML documentation for a module to a file in the current\n    directory.  If <name> contains a '{sep}', it is treated as a filename; if\n    it names a directory, documentation is written for all the contents.\n\"\"\"  .format(cmd=cmd, sep=os.sep))\n  \nif __name__ == '__main__':\n cli()\n"], "threading": [".py", "\"\"\n\nimport sys as _sys\nimport _thread\n\nfrom time import sleep as _sleep\ntry:\n from time import monotonic as _time\nexcept ImportError:\n from time import time as _time\nfrom traceback import format_exc as _format_exc\nfrom _weakrefset import WeakSet\n\n\n\n\n\n\n\n\n\n\n\n__all__ = ['active_count', 'Condition', 'current_thread', 'enumerate', 'Event',\n'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Thread', 'Barrier',\n'Timer', 'ThreadError', 'setprofile', 'settrace', 'local', 'stack_size']\n\n\n_start_new_thread = _thread.start_new_thread\n_allocate_lock = _thread.allocate_lock\nget_ident = _thread.get_ident\nThreadError = _thread.error\ntry:\n _CRLock = _thread.RLock\nexcept AttributeError:\n _CRLock = None\nTIMEOUT_MAX = _thread.TIMEOUT_MAX\ndel _thread\n\n\n\n\n_profile_hook = None\n_trace_hook = None\n\ndef setprofile(func):\n \"\"\n global _profile_hook\n _profile_hook = func\n \ndef settrace(func):\n \"\"\n global _trace_hook\n _trace_hook = func\n \n \n \nLock = _allocate_lock\n\ndef RLock(*args, **kwargs):\n \"\"\n if _CRLock is None:\n  return _PyRLock(*args, **kwargs)\n return _CRLock(*args, **kwargs)\n \nclass _RLock:\n \"\"\n \n def __init__(self):\n  self._block = _allocate_lock()\n  self._owner = None\n  self._count = 0\n  \n def __repr__(self):\n  owner = self._owner\n  try:\n   owner = _active[owner].name\n  except KeyError:\n   pass\n  return \"<%s owner=%r count=%d>\" % (\n  self.__class__.__name__, owner, self._count)\n  \n def acquire(self, blocking=True, timeout=-1):\n  \"\"\n  me = get_ident()\n  if self._owner == me:\n   self._count = self._count + 1\n   return 1\n  rc = self._block.acquire(blocking, timeout)\n  if rc:\n   self._owner = me\n   self._count = 1\n  return rc\n  \n __enter__ = acquire\n \n def release(self):\n  \"\"\n  if self._owner != get_ident():\n   raise RuntimeError(\"cannot release un-acquired lock\")\n  self._count = count = self._count - 1\n  if not count:\n   self._owner = None\n   self._block.release()\n   \n def __exit__(self, t, v, tb):\n  self.release()\n  \n  \n  \n def _acquire_restore(self, state):\n  self._block.acquire()\n  self._count, self._owner = state\n  \n def _release_save(self):\n  if self._count == 0:\n   raise RuntimeError(\"cannot release un-acquired lock\")\n  count = self._count\n  self._count = 0\n  owner = self._owner\n  self._owner = None\n  self._block.release()\n  return (count, owner)\n  \n def _is_owned(self):\n  return self._owner == get_ident()\n  \n_PyRLock = _RLock\n\n\nclass Condition:\n \"\"\n \n def __init__(self, lock=None):\n  if lock is None:\n   lock = RLock()\n  self._lock = lock\n  \n  self.acquire = lock.acquire\n  self.release = lock.release\n  \n  \n  \n  try:\n   self._release_save = lock._release_save\n  except AttributeError:\n   pass\n  try:\n   self._acquire_restore = lock._acquire_restore\n  except AttributeError:\n   pass\n  try:\n   self._is_owned = lock._is_owned\n  except AttributeError:\n   pass\n  self._waiters = []\n  \n def __enter__(self):\n  return self._lock.__enter__()\n  \n def __exit__(self, *args):\n  return self._lock.__exit__(*args)\n  \n def __repr__(self):\n  return \"<Condition(%s, %d)>\" % (self._lock, len(self._waiters))\n  \n def _release_save(self):\n  self._lock.release() \n  \n def _acquire_restore(self, x):\n  self._lock.acquire() \n  \n def _is_owned(self):\n \n \n  if self._lock.acquire(0):\n   self._lock.release()\n   return False\n  else:\n   return True\n   \n def wait(self, timeout=None):\n  \"\"\n  if not self._is_owned():\n   raise RuntimeError(\"cannot wait on un-acquired lock\")\n  waiter = _allocate_lock()\n  waiter.acquire()\n  self._waiters.append(waiter)\n  saved_state = self._release_save()\n  try: \n   if timeout is None:\n    waiter.acquire()\n    gotit = True\n   else:\n    if timeout > 0:\n     gotit = waiter.acquire(True, timeout)\n    else:\n     gotit = waiter.acquire(False)\n    if not gotit:\n     try:\n      self._waiters.remove(waiter)\n     except ValueError:\n      pass\n   return gotit\n  finally:\n   self._acquire_restore(saved_state)\n   \n def wait_for(self, predicate, timeout=None):\n  \"\"\n  endtime = None\n  waittime = timeout\n  result = predicate()\n  while not result:\n   if waittime is not None:\n    if endtime is None:\n     endtime = _time() + waittime\n    else:\n     waittime = endtime - _time()\n     if waittime <= 0:\n      break\n   self.wait(waittime)\n   result = predicate()\n  return result\n  \n def notify(self, n=1):\n  \"\"\n  if not self._is_owned():\n   raise RuntimeError(\"cannot notify on un-acquired lock\")\n  __waiters = self._waiters\n  waiters = __waiters[:n]\n  if not waiters:\n   return\n  for waiter in waiters:\n   waiter.release()\n   try:\n    __waiters.remove(waiter)\n   except ValueError:\n    pass\n    \n def notify_all(self):\n  \"\"\n  self.notify(len(self._waiters))\n  \n notifyAll = notify_all\n \n \nclass Semaphore:\n \"\"\n \n \n \n def __init__(self, value=1):\n  if value < 0:\n   raise ValueError(\"semaphore initial value must be >= 0\")\n  self._cond = Condition(Lock())\n  self._value = value\n  \n def acquire(self, blocking=True, timeout=None):\n  \"\"\n  if not blocking and timeout is not None:\n   raise ValueError(\"can't specify timeout for non-blocking acquire\")\n  rc = False\n  endtime = None\n  with self._cond:\n   while self._value == 0:\n    if not blocking:\n     break\n    if timeout is not None:\n     if endtime is None:\n      endtime = _time() + timeout\n     else:\n      timeout = endtime - _time()\n      if timeout <= 0:\n       break\n    self._cond.wait(timeout)\n   else:\n    self._value = self._value - 1\n    rc = True\n  return rc\n  \n __enter__ = acquire\n \n def release(self):\n  \"\"\n  with self._cond:\n   self._value = self._value + 1\n   self._cond.notify()\n   \n def __exit__(self, t, v, tb):\n  self.release()\n  \n  \nclass BoundedSemaphore(Semaphore):\n \"\"\n \n def __init__(self, value=1):\n  Semaphore.__init__(self, value)\n  self._initial_value = value\n  \n def release(self):\n  \"\"\n  with self._cond:\n   if self._value >= self._initial_value:\n    raise ValueError(\"Semaphore released too many times\")\n   self._value += 1\n   self._cond.notify()\n   \n   \nclass Event:\n \"\"\n \n \n \n def __init__(self):\n  self._cond = Condition(Lock())\n  self._flag = False\n  \n def _reset_internal_locks(self):\n \n  self._cond.__init__()\n  \n def is_set(self):\n  \"\"\n  return self._flag\n  \n isSet = is_set\n \n def set(self):\n  \"\"\n  self._cond.acquire()\n  try:\n   self._flag = True\n   self._cond.notify_all()\n  finally:\n   self._cond.release()\n   \n def clear(self):\n  \"\"\n  self._cond.acquire()\n  try:\n   self._flag = False\n  finally:\n   self._cond.release()\n   \n def wait(self, timeout=None):\n  \"\"\n  self._cond.acquire()\n  try:\n   signaled = self._flag\n   if not signaled:\n    signaled = self._cond.wait(timeout)\n   return signaled\n  finally:\n   self._cond.release()\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \nclass Barrier:\n \"\"\n \n def __init__(self, parties, action=None, timeout=None):\n  \"\"\n  self._cond = Condition(Lock())\n  self._action = action\n  self._timeout = timeout\n  self._parties = parties\n  self._state = 0 \n  self._count = 0\n  \n def wait(self, timeout=None):\n  \"\"\n  if timeout is None:\n   timeout = self._timeout\n  with self._cond:\n   self._enter() \n   index = self._count\n   self._count += 1\n   try:\n    if index + 1 == self._parties:\n    \n     self._release()\n    else:\n    \n     self._wait(timeout)\n    return index\n   finally:\n    self._count -= 1\n    \n    self._exit()\n    \n    \n    \n def _enter(self):\n  while self._state in (-1, 1):\n  \n   self._cond.wait()\n   \n  if self._state < 0:\n   raise BrokenBarrierError\n  assert self._state == 0\n  \n  \n  \n def _release(self):\n  try:\n   if self._action:\n    self._action()\n    \n   self._state = 1\n   self._cond.notify_all()\n  except:\n  \n   self._break()\n   raise\n   \n   \n   \n def _wait(self, timeout):\n  if not self._cond.wait_for(lambda : self._state != 0, timeout):\n  \n   self._break()\n   raise BrokenBarrierError\n  if self._state < 0:\n   raise BrokenBarrierError\n  assert self._state == 1\n  \n  \n  \n def _exit(self):\n  if self._count == 0:\n   if self._state in (-1, 1):\n   \n    self._state = 0\n    self._cond.notify_all()\n    \n def reset(self):\n  \"\"\n  with self._cond:\n   if self._count > 0:\n    if self._state == 0:\n    \n     self._state = -1\n    elif self._state == -2:\n    \n    \n     self._state = -1\n   else:\n    self._state = 0\n   self._cond.notify_all()\n   \n def abort(self):\n  \"\"\n  with self._cond:\n   self._break()\n   \n def _break(self):\n \n \n  self._state = -2\n  self._cond.notify_all()\n  \n @property\n def parties(self):\n  \"\"\n  return self._parties\n  \n @property\n def n_waiting(self):\n  \"\"\n  \n  \n  if self._state == 0:\n   return self._count\n  return 0\n  \n @property\n def broken(self):\n  \"\"\n  return self._state == -2\n  \n  \nclass BrokenBarrierError(RuntimeError):\n pass\n \n \n \n_counter = 0\ndef _newname(template=\"Thread-%d\"):\n global _counter\n _counter = _counter + 1\n return template % _counter\n \n \n_active_limbo_lock = _allocate_lock()\n_active = {} \n_limbo = {}\n\n\n_dangling = WeakSet()\n\n\n\nclass Thread:\n \"\"\n \n __initialized = False\n \n \n \n \n __exc_info = _sys.exc_info\n \n \n \n \n def __init__(self, group=None, target=None, name=None,\n args=(), kwargs=None, *, daemon=None):\n  \"\"\n  assert group is None, \"group argument must be None for now\"\n  if kwargs is None:\n   kwargs = {}\n  self._target = target\n  self._name = str(name or _newname())\n  self._args = args\n  self._kwargs = kwargs\n  if daemon is not None:\n   self._daemonic = daemon\n  else:\n   self._daemonic = current_thread().daemon\n  self._ident = None\n  self._started = Event()\n  self._stopped = False\n  self._block = Condition(Lock())\n  self._initialized = True\n  \n  \n  self._stderr = _sys.stderr\n  _dangling.add(self)\n  \n def _reset_internal_locks(self):\n \n \n  if hasattr(self, '_block'): \n   self._block.__init__()\n  self._started._reset_internal_locks()\n  \n def __repr__(self):\n  assert self._initialized, \"Thread.__init__() was not called\"\n  status = \"initial\"\n  if self._started.is_set():\n   status = \"started\"\n  if self._stopped:\n   status = \"stopped\"\n  if self._daemonic:\n   status += \" daemon\"\n  if self._ident is not None:\n   status += \" %s\" % self._ident\n  return \"<%s(%s, %s)>\" % (self.__class__.__name__, self._name, status)\n  \n def start(self):\n  \"\"\n  if not self._initialized:\n   raise RuntimeError(\"thread.__init__() not called\")\n   \n  if self._started.is_set():\n   raise RuntimeError(\"threads can only be started once\")\n  with _active_limbo_lock:\n   _limbo[self] = self\n  try:\n   _start_new_thread(self._bootstrap, ())\n  except Exception:\n   with _active_limbo_lock:\n    del _limbo[self]\n   raise\n  self._started.wait()\n  \n def run(self):\n  \"\"\n  try:\n   if self._target:\n    self._target(*self._args, **self._kwargs)\n  finally:\n  \n  \n   del self._target, self._args, self._kwargs\n   \n def _bootstrap(self):\n \n \n \n \n \n \n \n \n \n \n \n \n  try:\n   self._bootstrap_inner()\n  except:\n   if self._daemonic and _sys is None:\n    return\n   raise\n   \n def _set_ident(self):\n  self._ident = get_ident()\n  \n def _bootstrap_inner(self):\n  try:\n   self._set_ident()\n   self._started.set()\n   with _active_limbo_lock:\n    _active[self._ident] = self\n    del _limbo[self]\n    \n   if _trace_hook:\n    _sys.settrace(_trace_hook)\n   if _profile_hook:\n    _sys.setprofile(_profile_hook)\n    \n   try:\n    self.run()\n   except SystemExit:\n    pass\n   except:\n   \n   \n   \n   \n    if _sys:\n     _sys.stderr.write(\"Exception in thread %s:\\n%s\\n\" %\n     (self.name, _format_exc()))\n    else:\n    \n    \n    \n     exc_type, exc_value, exc_tb = self._exc_info()\n     try:\n      print((\n      \"Exception in thread \" + self.name +\n      \" (most likely raised during interpreter shutdown):\"), file=self._stderr)\n      print((\n      \"Traceback (most recent call last):\"), file=self._stderr)\n      while exc_tb:\n       print((\n       '  File \"%s\", line %s, in %s' %\n       (exc_tb.tb_frame.f_code.co_filename,\n       exc_tb.tb_lineno,\n       exc_tb.tb_frame.f_code.co_name)), file=self._stderr)\n       exc_tb = exc_tb.tb_next\n      print((\"%s: %s\" % (exc_type, exc_value)), file=self._stderr)\n      \n      \n     finally:\n      del exc_type, exc_value, exc_tb\n   finally:\n   \n   \n   \n   \n   \n    pass\n  finally:\n   with _active_limbo_lock:\n    self._stop()\n    try:\n    \n    \n     del _active[get_ident()]\n    except:\n     pass\n     \n def _stop(self):\n  self._block.acquire()\n  self._stopped = True\n  self._block.notify_all()\n  self._block.release()\n  \n def _delete(self):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  try:\n   with _active_limbo_lock:\n    del _active[get_ident()]\n    \n    \n    \n    \n  except KeyError:\n   if 'dummy_threading' not in _sys.modules:\n    raise\n    \n def join(self, timeout=None):\n  \"\"\n  if not self._initialized:\n   raise RuntimeError(\"Thread.__init__() not called\")\n  if not self._started.is_set():\n   raise RuntimeError(\"cannot join thread before it is started\")\n  if self is current_thread():\n   raise RuntimeError(\"cannot join current thread\")\n   \n  self._block.acquire()\n  try:\n   if timeout is None:\n    while not self._stopped:\n     self._block.wait()\n   else:\n    deadline = _time() + timeout\n    while not self._stopped:\n     delay = deadline - _time()\n     if delay <= 0:\n      break\n     self._block.wait(delay)\n  finally:\n   self._block.release()\n   \n @property\n def name(self):\n  \"\"\n  assert self._initialized, \"Thread.__init__() not called\"\n  return self._name\n  \n @name.setter\n def name(self, name):\n  assert self._initialized, \"Thread.__init__() not called\"\n  self._name = str(name)\n  \n @property\n def ident(self):\n  \"\"\n  assert self._initialized, \"Thread.__init__() not called\"\n  return self._ident\n  \n def is_alive(self):\n  \"\"\n  assert self._initialized, \"Thread.__init__() not called\"\n  return self._started.is_set() and not self._stopped\n  \n isAlive = is_alive\n \n @property\n def daemon(self):\n  \"\"\n  assert self._initialized, \"Thread.__init__() not called\"\n  return self._daemonic\n  \n @daemon.setter\n def daemon(self, daemonic):\n  if not self._initialized:\n   raise RuntimeError(\"Thread.__init__() not called\")\n  if self._started.is_set():\n   raise RuntimeError(\"cannot set daemon status of active thread\");\n  self._daemonic = daemonic\n  \n def isDaemon(self):\n  return self.daemon\n  \n def setDaemon(self, daemonic):\n  self.daemon = daemonic\n  \n def getName(self):\n  return self.name\n  \n def setName(self, name):\n  self.name = name\n  \n  \n  \nclass Timer(Thread):\n \"\"\n \n def __init__(self, interval, function, args=None, kwargs=None):\n  Thread.__init__(self)\n  self.interval = interval\n  self.function = function\n  self.args = args if args is not None else []\n  self.kwargs = kwargs if kwargs is not None else {}\n  self.finished = Event()\n  \n def cancel(self):\n  \"\"\n  self.finished.set()\n  \n def run(self):\n  self.finished.wait(self.interval)\n  if not self.finished.is_set():\n   self.function(*self.args, **self.kwargs)\n  self.finished.set()\n  \n  \n  \n  \nclass _MainThread(Thread):\n\n def __init__(self):\n  Thread.__init__(self, name=\"MainThread\", daemon=False)\n  self._started.set()\n  self._set_ident()\n  with _active_limbo_lock:\n   _active[self._ident] = self\n   \n def _exitfunc(self):\n  self._stop()\n  t = _pickSomeNonDaemonThread()\n  while t:\n   t.join()\n   t = _pickSomeNonDaemonThread()\n  self._delete()\n  \ndef _pickSomeNonDaemonThread():\n for t in enumerate():\n  if not t.daemon and t.is_alive():\n   return t\n return None\n \n \n \n \n \n \n \n \n \n \nclass _DummyThread(Thread):\n\n def __init__(self):\n  Thread.__init__(self, name=_newname(\"Dummy-%d\"), daemon=True)\n  \n  \n  \n  \n  del self._block\n  \n  self._started.set()\n  self._set_ident()\n  with _active_limbo_lock:\n   _active[self._ident] = self\n   \n def _stop(self):\n  pass\n  \n def join(self, timeout=None):\n  assert False, \"cannot join a dummy thread\"\n  \n  \n  \n  \ndef current_thread():\n \"\"\n try:\n  return _active[get_ident()]\n except KeyError:\n  return _DummyThread()\n  \ncurrentThread = current_thread\n\ndef active_count():\n \"\"\n with _active_limbo_lock:\n  return len(_active) + len(_limbo)\n  \nactiveCount = active_count\n\ndef _enumerate():\n\n return list(_active.values()) + list(_limbo.values())\n \ndef enumerate():\n \"\"\n with _active_limbo_lock:\n  return list(_active.values()) + list(_limbo.values())\n  \nfrom _thread import stack_size\n\n\n\n\n\n_shutdown = _MainThread()._exitfunc\n\n\n\n\ntry:\n from _thread import _local as local\nexcept ImportError:\n from _threading_local import local\n \n \ndef _after_fork():\n\n\n\n\n\n\n global _active_limbo_lock\n _active_limbo_lock = _allocate_lock()\n \n \n new_active = {}\n current = current_thread()\n with _active_limbo_lock:\n  for thread in _enumerate():\n  \n  \n   thread._reset_internal_locks()\n   if thread is current:\n   \n   \n    ident = get_ident()\n    thread._ident = ident\n    new_active[ident] = thread\n   else:\n   \n    thread._stop()\n    \n  _limbo.clear()\n  _active.clear()\n  _active.update(new_active)\n  assert len(_active) == 1\n"], "token": [".py", "\"\"\n\n__all__ = ['tok_name', 'ISTERMINAL', 'ISNONTERMINAL', 'ISEOF']\n\n\n\n\n\n\n\n\n\nENDMARKER = 0\nNAME = 1\nNUMBER = 2\nSTRING = 3\nNEWLINE = 4\nINDENT = 5\nDEDENT = 6\nLPAR = 7\nRPAR = 8\nLSQB = 9\nRSQB = 10\nCOLON = 11\nCOMMA = 12\nSEMI = 13\nPLUS = 14\nMINUS = 15\nSTAR = 16\nSLASH = 17\nVBAR = 18\nAMPER = 19\nLESS = 20\nGREATER = 21\nEQUAL = 22\nDOT = 23\nPERCENT = 24\nLBRACE = 25\nRBRACE = 26\nEQEQUAL = 27\nNOTEQUAL = 28\nLESSEQUAL = 29\nGREATEREQUAL = 30\nTILDE = 31\nCIRCUMFLEX = 32\nLEFTSHIFT = 33\nRIGHTSHIFT = 34\nDOUBLESTAR = 35\nPLUSEQUAL = 36\nMINEQUAL = 37\nSTAREQUAL = 38\nSLASHEQUAL = 39\nPERCENTEQUAL = 40\nAMPEREQUAL = 41\nVBAREQUAL = 42\nCIRCUMFLEXEQUAL = 43\nLEFTSHIFTEQUAL = 44\nRIGHTSHIFTEQUAL = 45\nDOUBLESTAREQUAL = 46\nDOUBLESLASH = 47\nDOUBLESLASHEQUAL = 48\nAT = 49\nRARROW = 50\nELLIPSIS = 51\nOP = 52\nERRORTOKEN = 53\nN_TOKENS = 54\nNT_OFFSET = 256\n\n\ntok_name = {value: name\nfor name, value in globals().items()\nif isinstance(value, int) and not name.startswith('_')}\n__all__.extend(tok_name.values())\n\ndef ISTERMINAL(x):\n return x < NT_OFFSET\n \ndef ISNONTERMINAL(x):\n return x >= NT_OFFSET\n \ndef ISEOF(x):\n return x == ENDMARKER\n \n \ndef _main():\n import re\n import sys\n args = sys.argv[1:]\n inFileName = args and args[0] or \"Include/token.h\"\n outFileName = \"Lib/token.py\"\n if len(args) > 1:\n  outFileName = args[1]\n try:\n  fp = open(inFileName)\n except IOError as err:\n  sys.stdout.write(\"I/O error: %s\\n\" % str(err))\n  sys.exit(1)\n lines = fp.read().split(\"\\n\")\n fp.close()\n prog = re.compile(\n \"#define[ \\t][ \\t]*([A-Z0-9][A-Z0-9_]*)[ \\t][ \\t]*([0-9][0-9]*)\",\n re.IGNORECASE)\n tokens = {}\n for line in lines:\n  match = prog.match(line)\n  if match:\n   name, val = match.group(1, 2)\n   val = int(val)\n   tokens[val] = name \n keys = sorted(tokens.keys())\n \n try:\n  fp = open(outFileName)\n except IOError as err:\n  sys.stderr.write(\"I/O error: %s\\n\" % str(err))\n  sys.exit(2)\n format = fp.read().split(\"\\n\")\n fp.close()\n try:\n  start = format.index(\"#--start constants--\") + 1\n  end = format.index(\"#--end constants--\")\n except ValueError:\n  sys.stderr.write(\"target does not contain format markers\")\n  sys.exit(3)\n lines = []\n for val in keys:\n  lines.append(\"%s = %d\" % (tokens[val], val))\n format[start:end] = lines\n try:\n  fp = open(outFileName, 'w')\n except IOError as err:\n  sys.stderr.write(\"I/O error: %s\\n\" % str(err))\n  sys.exit(4)\n fp.write(\"\\n\".join(format))\n fp.close()\n \n \nif __name__ == \"__main__\":\n _main()\n"], "multiprocessing.dummy.connection": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n__all__ = [ 'Client', 'Listener', 'Pipe' ]\n\nfrom queue import Queue\n\n\nfamilies = [None]\n\n\nclass Listener(object):\n\n def __init__(self, address=None, family=None, backlog=1):\n  self._backlog_queue = Queue(backlog)\n  \n def accept(self):\n  return Connection(*self._backlog_queue.get())\n  \n def close(self):\n  self._backlog_queue = None\n  \n address = property(lambda self: self._backlog_queue)\n \n def __enter__(self):\n  return self\n  \n def __exit__(self, exc_type, exc_value, exc_tb):\n  self.close()\n  \n  \ndef Client(address):\n _in, _out = Queue(), Queue()\n address.put((_out, _in))\n return Connection(_in, _out)\n \n \ndef Pipe(duplex=True):\n a, b = Queue(), Queue()\n return Connection(a, b), Connection(b, a)\n \n \nclass Connection(object):\n\n def __init__(self, _in, _out):\n  self._out = _out\n  self._in = _in\n  self.send = self.send_bytes = _out.put\n  self.recv = self.recv_bytes = _in.get\n  \n def poll(self, timeout=0.0):\n  if self._in.qsize() > 0:\n   return True\n  if timeout <= 0.0:\n   return False\n  self._in.not_empty.acquire()\n  self._in.not_empty.wait(timeout)\n  self._in.not_empty.release()\n  return self._in.qsize() > 0\n  \n def close(self):\n  pass\n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, exc_type, exc_value, exc_tb):\n  self.close()\n"], "multiprocessing.pool": [".py", "\n\n\n\n\n\n\n\n\n__all__ = ['Pool']\n\n\n\n\n\nimport threading\nimport queue\nimport itertools\nimport collections\nimport time\n\nfrom multiprocessing import Process, cpu_count, TimeoutError\nfrom multiprocessing.util import Finalize, debug\n\n\n\n\n\nRUN = 0\nCLOSE = 1\nTERMINATE = 2\n\n\n\n\n\njob_counter = itertools.count()\n\ndef mapstar(args):\n return list(map(*args))\n \ndef starmapstar(args):\n return list(itertools.starmap(args[0], args[1]))\n \n \n \n \n \nclass MaybeEncodingError(Exception):\n \"\"\n \n def __init__(self, exc, value):\n  self.exc = repr(exc)\n  self.value = repr(value)\n  super(MaybeEncodingError, self).__init__(self.exc, self.value)\n  \n def __str__(self):\n  return \"Error sending result: '%s'. Reason: '%s'\" % (self.value,\n  self.exc)\n  \n def __repr__(self):\n  return \"<MaybeEncodingError: %s>\" % str(self)\n  \n  \ndef worker(inqueue, outqueue, initializer=None, initargs=(), maxtasks=None):\n assert maxtasks is None or (type(maxtasks) == int and maxtasks > 0)\n put = outqueue.put\n get = inqueue.get\n if hasattr(inqueue, '_writer'):\n  inqueue._writer.close()\n  outqueue._reader.close()\n  \n if initializer is not None:\n  initializer(*initargs)\n  \n completed = 0\n while maxtasks is None or (maxtasks and completed < maxtasks):\n  try:\n   task = get()\n  except (EOFError, IOError):\n   debug('worker got EOFError or IOError -- exiting')\n   break\n   \n  if task is None:\n   debug('worker got sentinel -- exiting')\n   break\n   \n  job, i, func, args, kwds = task\n  try:\n   result = (True, func(*args, **kwds))\n  except Exception as e:\n   result = (False, e)\n  try:\n   put((job, i, result))\n  except Exception as e:\n   wrapped = MaybeEncodingError(e, result[1])\n   debug(\"Possible encoding error while sending result: %s\" % (\n   wrapped))\n   put((job, i, (False, wrapped)))\n  completed += 1\n debug('worker exiting after %d tasks' % completed)\n \n \n \n \n \nclass Pool(object):\n \"\"\n Process = Process\n \n def __init__(self, processes=None, initializer=None, initargs=(),\n maxtasksperchild=None):\n  self._setup_queues()\n  self._taskqueue = queue.Queue()\n  self._cache = {}\n  self._state = RUN\n  self._maxtasksperchild = maxtasksperchild\n  self._initializer = initializer\n  self._initargs = initargs\n  \n  if processes is None:\n   try:\n    processes = cpu_count()\n   except NotImplementedError:\n    processes = 1\n  if processes < 1:\n   raise ValueError(\"Number of processes must be at least 1\")\n   \n  if initializer is not None and not callable(initializer):\n   raise TypeError('initializer must be a callable')\n   \n  self._processes = processes\n  self._pool = []\n  self._repopulate_pool()\n  \n  self._worker_handler = threading.Thread(\n  target=Pool._handle_workers,\n  args=(self, )\n  )\n  self._worker_handler.daemon = True\n  self._worker_handler._state = RUN\n  self._worker_handler.start()\n  \n  \n  self._task_handler = threading.Thread(\n  target=Pool._handle_tasks,\n  args=(self._taskqueue, self._quick_put, self._outqueue, self._pool)\n  )\n  self._task_handler.daemon = True\n  self._task_handler._state = RUN\n  self._task_handler.start()\n  \n  self._result_handler = threading.Thread(\n  target=Pool._handle_results,\n  args=(self._outqueue, self._quick_get, self._cache)\n  )\n  self._result_handler.daemon = True\n  self._result_handler._state = RUN\n  self._result_handler.start()\n  \n  self._terminate = Finalize(\n  self, self._terminate_pool,\n  args=(self._taskqueue, self._inqueue, self._outqueue, self._pool,\n  self._worker_handler, self._task_handler,\n  self._result_handler, self._cache),\n  exitpriority=15\n  )\n  \n def _join_exited_workers(self):\n  \"\"\n  cleaned = False\n  for i in reversed(range(len(self._pool))):\n   worker = self._pool[i]\n   if worker.exitcode is not None:\n   \n    debug('cleaning up worker %d' % i)\n    worker.join()\n    cleaned = True\n    del self._pool[i]\n  return cleaned\n  \n def _repopulate_pool(self):\n  \"\"\n  for i in range(self._processes - len(self._pool)):\n   w = self.Process(target=worker,\n   args=(self._inqueue, self._outqueue,\n   self._initializer,\n   self._initargs, self._maxtasksperchild)\n   )\n   self._pool.append(w)\n   w.name = w.name.replace('Process', 'PoolWorker')\n   w.daemon = True\n   w.start()\n   debug('added worker')\n   \n def _maintain_pool(self):\n  \"\"\n  if self._join_exited_workers():\n   self._repopulate_pool()\n   \n def _setup_queues(self):\n  from .queues import SimpleQueue\n  self._inqueue = SimpleQueue()\n  self._outqueue = SimpleQueue()\n  self._quick_put = self._inqueue._writer.send\n  self._quick_get = self._outqueue._reader.recv\n  \n def apply(self, func, args=(), kwds={}):\n  \"\"\n  assert self._state == RUN\n  return self.apply_async(func, args, kwds).get()\n  \n def map(self, func, iterable, chunksize=None):\n  \"\"\n  return self._map_async(func, iterable, mapstar, chunksize).get()\n  \n def starmap(self, func, iterable, chunksize=None):\n  \"\"\n  return self._map_async(func, iterable, starmapstar, chunksize).get()\n  \n def starmap_async(self, func, iterable, chunksize=None, callback=None,\n error_callback=None):\n  \"\"\n  return self._map_async(func, iterable, starmapstar, chunksize,\n  callback, error_callback)\n  \n def imap(self, func, iterable, chunksize=1):\n  \"\"\n  if self._state != RUN:\n   raise ValueError(\"Pool not running\")\n  if chunksize == 1:\n   result = IMapIterator(self._cache)\n   self._taskqueue.put((((result._job, i, func, (x,), {})\n   for i, x in enumerate(iterable)), result._set_length))\n   return result\n  else:\n   assert chunksize > 1\n   task_batches = Pool._get_tasks(func, iterable, chunksize)\n   result = IMapIterator(self._cache)\n   self._taskqueue.put((((result._job, i, mapstar, (x,), {})\n   for i, x in enumerate(task_batches)), result._set_length))\n   return (item for chunk in result for item in chunk)\n   \n def imap_unordered(self, func, iterable, chunksize=1):\n  \"\"\n  if self._state != RUN:\n   raise ValueError(\"Pool not running\")\n  if chunksize == 1:\n   result = IMapUnorderedIterator(self._cache)\n   self._taskqueue.put((((result._job, i, func, (x,), {})\n   for i, x in enumerate(iterable)), result._set_length))\n   return result\n  else:\n   assert chunksize > 1\n   task_batches = Pool._get_tasks(func, iterable, chunksize)\n   result = IMapUnorderedIterator(self._cache)\n   self._taskqueue.put((((result._job, i, mapstar, (x,), {})\n   for i, x in enumerate(task_batches)), result._set_length))\n   return (item for chunk in result for item in chunk)\n   \n def apply_async(self, func, args=(), kwds={}, callback=None,\n error_callback=None):\n  \"\"\n  if self._state != RUN:\n   raise ValueError(\"Pool not running\")\n  result = ApplyResult(self._cache, callback, error_callback)\n  self._taskqueue.put(([(result._job, None, func, args, kwds)], None))\n  return result\n  \n def map_async(self, func, iterable, chunksize=None, callback=None,\n error_callback=None):\n  \"\"\n  return self._map_async(func, iterable, mapstar, chunksize, callback,\n  error_callback)\n  \n def _map_async(self, func, iterable, mapper, chunksize=None, callback=None,\n error_callback=None):\n  \"\"\n  if self._state != RUN:\n   raise ValueError(\"Pool not running\")\n  if not hasattr(iterable, '__len__'):\n   iterable = list(iterable)\n   \n  if chunksize is None:\n   chunksize, extra = divmod(len(iterable), len(self._pool) * 4)\n   if extra:\n    chunksize += 1\n  if len(iterable) == 0:\n   chunksize = 0\n   \n  task_batches = Pool._get_tasks(func, iterable, chunksize)\n  result = MapResult(self._cache, chunksize, len(iterable), callback,\n  error_callback=error_callback)\n  self._taskqueue.put((((result._job, i, mapper, (x,), {})\n  for i, x in enumerate(task_batches)), None))\n  return result\n  \n @staticmethod\n def _handle_workers(pool):\n  thread = threading.current_thread()\n  \n  \n  \n  while thread._state == RUN or (pool._cache and thread._state != TERMINATE):\n   pool._maintain_pool()\n   time.sleep(0.1)\n   \n  pool._taskqueue.put(None)\n  debug('worker handler exiting')\n  \n @staticmethod\n def _handle_tasks(taskqueue, put, outqueue, pool):\n  thread = threading.current_thread()\n  \n  for taskseq, set_length in iter(taskqueue.get, None):\n   i = -1\n   for i, task in enumerate(taskseq):\n    if thread._state:\n     debug('task handler found thread._state != RUN')\n     break\n    try:\n     put(task)\n    except IOError:\n     debug('could not put task on queue')\n     break\n   else:\n    if set_length:\n     debug('doing set_length()')\n     set_length(i+1)\n    continue\n   break\n  else:\n   debug('task handler got sentinel')\n   \n   \n  try:\n  \n   debug('task handler sending sentinel to result handler')\n   outqueue.put(None)\n   \n   \n   debug('task handler sending sentinel to workers')\n   for p in pool:\n    put(None)\n  except IOError:\n   debug('task handler got IOError when sending sentinels')\n   \n  debug('task handler exiting')\n  \n @staticmethod\n def _handle_results(outqueue, get, cache):\n  thread = threading.current_thread()\n  \n  while 1:\n   try:\n    task = get()\n   except (IOError, EOFError):\n    debug('result handler got EOFError/IOError -- exiting')\n    return\n    \n   if thread._state:\n    assert thread._state == TERMINATE\n    debug('result handler found thread._state=TERMINATE')\n    break\n    \n   if task is None:\n    debug('result handler got sentinel')\n    break\n    \n   job, i, obj = task\n   try:\n    cache[job]._set(i, obj)\n   except KeyError:\n    pass\n    \n  while cache and thread._state != TERMINATE:\n   try:\n    task = get()\n   except (IOError, EOFError):\n    debug('result handler got EOFError/IOError -- exiting')\n    return\n    \n   if task is None:\n    debug('result handler ignoring extra sentinel')\n    continue\n   job, i, obj = task\n   try:\n    cache[job]._set(i, obj)\n   except KeyError:\n    pass\n    \n  if hasattr(outqueue, '_reader'):\n   debug('ensuring that outqueue is not full')\n   \n   \n   \n   try:\n    for i in range(10):\n     if not outqueue._reader.poll():\n      break\n     get()\n   except (IOError, EOFError):\n    pass\n    \n  debug('result handler exiting: len(cache)=%s, thread._state=%s',\n  len(cache), thread._state)\n  \n @staticmethod\n def _get_tasks(func, it, size):\n  it = iter(it)\n  while 1:\n   x = tuple(itertools.islice(it, size))\n   if not x:\n    return\n   yield (func, x)\n   \n def __reduce__(self):\n  raise NotImplementedError(\n  'pool objects cannot be passed between processes or pickled'\n  )\n  \n def close(self):\n  debug('closing pool')\n  if self._state == RUN:\n   self._state = CLOSE\n   self._worker_handler._state = CLOSE\n   \n def terminate(self):\n  debug('terminating pool')\n  self._state = TERMINATE\n  self._worker_handler._state = TERMINATE\n  self._terminate()\n  \n def join(self):\n  debug('joining pool')\n  assert self._state in (CLOSE, TERMINATE)\n  self._worker_handler.join()\n  self._task_handler.join()\n  self._result_handler.join()\n  for p in self._pool:\n   p.join()\n   \n @staticmethod\n def _help_stuff_finish(inqueue, task_handler, size):\n \n  debug('removing tasks from inqueue until task handler finished')\n  inqueue._rlock.acquire()\n  while task_handler.is_alive() and inqueue._reader.poll():\n   inqueue._reader.recv()\n   time.sleep(0)\n   \n @classmethod\n def _terminate_pool(cls, taskqueue, inqueue, outqueue, pool,\n worker_handler, task_handler, result_handler, cache):\n \n  debug('finalizing pool')\n  \n  worker_handler._state = TERMINATE\n  task_handler._state = TERMINATE\n  \n  debug('helping task handler/workers to finish')\n  cls._help_stuff_finish(inqueue, task_handler, len(pool))\n  \n  assert result_handler.is_alive() or len(cache) == 0\n  \n  result_handler._state = TERMINATE\n  outqueue.put(None) \n  \n  \n  \n  debug('joining worker handler')\n  if threading.current_thread() is not worker_handler:\n   worker_handler.join()\n   \n   \n  if pool and hasattr(pool[0], 'terminate'):\n   debug('terminating workers')\n   for p in pool:\n    if p.exitcode is None:\n     p.terminate()\n     \n  debug('joining task handler')\n  if threading.current_thread() is not task_handler:\n   task_handler.join()\n   \n  debug('joining result handler')\n  if threading.current_thread() is not result_handler:\n   result_handler.join()\n   \n  if pool and hasattr(pool[0], 'terminate'):\n   debug('joining pool workers')\n   for p in pool:\n    if p.is_alive():\n    \n     debug('cleaning up worker %d' % p.pid)\n     p.join()\n     \n def __enter__(self):\n  return self\n  \n def __exit__(self, exc_type, exc_val, exc_tb):\n  self.terminate()\n  \n  \n  \n  \n  \nclass ApplyResult(object):\n\n def __init__(self, cache, callback, error_callback):\n  self._event = threading.Event()\n  self._job = next(job_counter)\n  self._cache = cache\n  self._callback = callback\n  self._error_callback = error_callback\n  cache[self._job] = self\n  \n def ready(self):\n  return self._event.is_set()\n  \n def successful(self):\n  assert self.ready()\n  return self._success\n  \n def wait(self, timeout=None):\n  self._event.wait(timeout)\n  \n def get(self, timeout=None):\n  self.wait(timeout)\n  if not self.ready():\n   raise TimeoutError\n  if self._success:\n   return self._value\n  else:\n   raise self._value\n   \n def _set(self, i, obj):\n  self._success, self._value = obj\n  if self._callback and self._success:\n   self._callback(self._value)\n  if self._error_callback and not self._success:\n   self._error_callback(self._value)\n  self._event.set()\n  del self._cache[self._job]\n  \nAsyncResult = ApplyResult \n\n\n\n\n\nclass MapResult(ApplyResult):\n\n def __init__(self, cache, chunksize, length, callback, error_callback):\n  ApplyResult.__init__(self, cache, callback,\n  error_callback=error_callback)\n  self._success = True\n  self._value = [None] * length\n  self._chunksize = chunksize\n  if chunksize <= 0:\n   self._number_left = 0\n   self._event.set()\n   del cache[self._job]\n  else:\n   self._number_left = length//chunksize + bool(length % chunksize)\n   \n def _set(self, i, success_result):\n  success, result = success_result\n  if success:\n   self._value[i*self._chunksize:(i+1)*self._chunksize] = result\n   self._number_left -= 1\n   if self._number_left == 0:\n    if self._callback:\n     self._callback(self._value)\n    del self._cache[self._job]\n    self._event.set()\n  else:\n   self._success = False\n   self._value = result\n   if self._error_callback:\n    self._error_callback(self._value)\n   del self._cache[self._job]\n   self._event.set()\n   \n   \n   \n   \n   \nclass IMapIterator(object):\n\n def __init__(self, cache):\n  self._cond = threading.Condition(threading.Lock())\n  self._job = next(job_counter)\n  self._cache = cache\n  self._items = collections.deque()\n  self._index = 0\n  self._length = None\n  self._unsorted = {}\n  cache[self._job] = self\n  \n def __iter__(self):\n  return self\n  \n def next(self, timeout=None):\n  self._cond.acquire()\n  try:\n   try:\n    item = self._items.popleft()\n   except IndexError:\n    if self._index == self._length:\n     raise StopIteration\n    self._cond.wait(timeout)\n    try:\n     item = self._items.popleft()\n    except IndexError:\n     if self._index == self._length:\n      raise StopIteration\n     raise TimeoutError\n  finally:\n   self._cond.release()\n   \n  success, value = item\n  if success:\n   return value\n  raise value\n  \n __next__ = next \n \n def _set(self, i, obj):\n  self._cond.acquire()\n  try:\n   if self._index == i:\n    self._items.append(obj)\n    self._index += 1\n    while self._index in self._unsorted:\n     obj = self._unsorted.pop(self._index)\n     self._items.append(obj)\n     self._index += 1\n    self._cond.notify()\n   else:\n    self._unsorted[i] = obj\n    \n   if self._index == self._length:\n    del self._cache[self._job]\n  finally:\n   self._cond.release()\n   \n def _set_length(self, length):\n  self._cond.acquire()\n  try:\n   self._length = length\n   if self._index == self._length:\n    self._cond.notify()\n    del self._cache[self._job]\n  finally:\n   self._cond.release()\n   \n   \n   \n   \n   \nclass IMapUnorderedIterator(IMapIterator):\n\n def _set(self, i, obj):\n  self._cond.acquire()\n  try:\n   self._items.append(obj)\n   self._index += 1\n   self._cond.notify()\n   if self._index == self._length:\n    del self._cache[self._job]\n  finally:\n   self._cond.release()\n   \n   \n   \n   \n   \nclass ThreadPool(Pool):\n\n from .dummy import Process\n \n def __init__(self, processes=None, initializer=None, initargs=()):\n  Pool.__init__(self, processes, initializer, initargs)\n  \n def _setup_queues(self):\n  self._inqueue = queue.Queue()\n  self._outqueue = queue.Queue()\n  self._quick_put = self._inqueue.put\n  self._quick_get = self._outqueue.get\n  \n @staticmethod\n def _help_stuff_finish(inqueue, task_handler, size):\n \n  inqueue.not_empty.acquire()\n  try:\n   inqueue.queue.clear()\n   inqueue.queue.extend([None] * size)\n   inqueue.not_empty.notify_all()\n  finally:\n   inqueue.not_empty.release()\n"], "decimal": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\n\n__all__ = [\n\n'Decimal', 'Context',\n\n\n'DefaultContext', 'BasicContext', 'ExtendedContext',\n\n\n'DecimalException', 'Clamped', 'InvalidOperation', 'DivisionByZero',\n'Inexact', 'Rounded', 'Subnormal', 'Overflow', 'Underflow',\n'FloatOperation',\n\n\n'ROUND_DOWN', 'ROUND_HALF_UP', 'ROUND_HALF_EVEN', 'ROUND_CEILING',\n'ROUND_FLOOR', 'ROUND_UP', 'ROUND_HALF_DOWN', 'ROUND_05UP',\n\n\n'setcontext', 'getcontext', 'localcontext',\n\n\n'MAX_PREC', 'MAX_EMAX', 'MIN_EMIN', 'MIN_ETINY',\n\n\n'HAVE_THREADS'\n]\n\n__version__ = '1.70' \n\n\nimport copy as _copy\nimport math as _math\nimport numbers as _numbers\nimport sys\n\ntry:\n from collections import namedtuple as _namedtuple\n DecimalTuple = _namedtuple('DecimalTuple', 'sign digits exponent')\nexcept ImportError:\n DecimalTuple = lambda *args: args\n \n \nROUND_DOWN = 'ROUND_DOWN'\nROUND_HALF_UP = 'ROUND_HALF_UP'\nROUND_HALF_EVEN = 'ROUND_HALF_EVEN'\nROUND_CEILING = 'ROUND_CEILING'\nROUND_FLOOR = 'ROUND_FLOOR'\nROUND_UP = 'ROUND_UP'\nROUND_HALF_DOWN = 'ROUND_HALF_DOWN'\nROUND_05UP = 'ROUND_05UP'\n\n\nHAVE_THREADS = True\nif sys.maxsize == 2**63-1:\n MAX_PREC = 999999999999999999\n MAX_EMAX = 999999999999999999\n MIN_EMIN = -999999999999999999\nelse:\n MAX_PREC = 425000000\n MAX_EMAX = 425000000\n MIN_EMIN = -425000000\n \nMIN_ETINY = MIN_EMIN - (MAX_PREC-1)\n\n\n\nclass DecimalException(ArithmeticError):\n \"\"\n def handle(self, context, *args):\n  pass\n  \n  \nclass Clamped(DecimalException):\n \"\"\n \n \n pass\n \nclass InvalidOperation(DecimalException):\n \"\"\n def handle(self, context, *args):\n  if args:\n   ans = _dec_from_triple(args[0]._sign, args[0]._int, 'n', True)\n   return ans._fix_nan(context)\n  return _NaN\n  \nclass ConversionSyntax(InvalidOperation):\n \"\"\n def handle(self, context, *args):\n  return _NaN\n  \nclass DivisionByZero(DecimalException, ZeroDivisionError):\n \"\"\n \n def handle(self, context, sign, *args):\n  return _SignedInfinity[sign]\n  \nclass DivisionImpossible(InvalidOperation):\n \"\"\n \n def handle(self, context, *args):\n  return _NaN\n  \nclass DivisionUndefined(InvalidOperation, ZeroDivisionError):\n \"\"\n \n def handle(self, context, *args):\n  return _NaN\n  \nclass Inexact(DecimalException):\n \"\"\n \n \n pass\n \nclass InvalidContext(InvalidOperation):\n \"\"\n \n def handle(self, context, *args):\n  return _NaN\n  \nclass Rounded(DecimalException):\n \"\"\n \n pass\n \nclass Subnormal(DecimalException):\n \"\"\n \n pass\n \nclass Overflow(Inexact, Rounded):\n \"\"\n \n def handle(self, context, sign, *args):\n  if context.rounding in (ROUND_HALF_UP, ROUND_HALF_EVEN,\n  ROUND_HALF_DOWN, ROUND_UP):\n   return _SignedInfinity[sign]\n  if sign == 0:\n   if context.rounding == ROUND_CEILING:\n    return _SignedInfinity[sign]\n   return _dec_from_triple(sign, '9'*context.prec,\n   context.Emax-context.prec+1)\n  if sign == 1:\n   if context.rounding == ROUND_FLOOR:\n    return _SignedInfinity[sign]\n   return _dec_from_triple(sign, '9'*context.prec,\n   context.Emax-context.prec+1)\n   \n   \nclass Underflow(Inexact, Rounded, Subnormal):\n \"\"\n \n pass\n \nclass FloatOperation(DecimalException, TypeError):\n \"\"\n \n pass\n \n \n_signals = [Clamped, DivisionByZero, Inexact, Overflow, Rounded,\nUnderflow, InvalidOperation, Subnormal, FloatOperation]\n\n\n_condition_map = {ConversionSyntax:InvalidOperation,\nDivisionImpossible:InvalidOperation,\nDivisionUndefined:InvalidOperation,\nInvalidContext:InvalidOperation}\n\n\n_rounding_modes = (ROUND_DOWN, ROUND_HALF_UP, ROUND_HALF_EVEN, ROUND_CEILING,\nROUND_FLOOR, ROUND_UP, ROUND_HALF_DOWN, ROUND_05UP)\n\n\n\n\n\n\n\n\n\ntry:\n import threading\nexcept ImportError:\n\n class MockThreading(object):\n  def local(self, sys=sys):\n   return sys.modules[__name__]\n threading = MockThreading()\n del MockThreading\n \ntry:\n threading.local\n \nexcept AttributeError:\n\n\n\n if hasattr(threading.current_thread(), '__decimal_context__'):\n  del threading.current_thread().__decimal_context__\n  \n def setcontext(context):\n  \"\"\n  if context in (DefaultContext, BasicContext, ExtendedContext):\n   context = context.copy()\n   context.clear_flags()\n  threading.current_thread().__decimal_context__ = context\n  \n def getcontext():\n  \"\"\n  try:\n   return threading.current_thread().__decimal_context__\n  except AttributeError:\n   context = Context()\n   threading.current_thread().__decimal_context__ = context\n   return context\n   \nelse:\n\n local = threading.local()\n if hasattr(local, '__decimal_context__'):\n  del local.__decimal_context__\n  \n def getcontext(_local=local):\n  \"\"\n  try:\n   return _local.__decimal_context__\n  except AttributeError:\n   context = Context()\n   _local.__decimal_context__ = context\n   return context\n   \n def setcontext(context, _local=local):\n  \"\"\n  if context in (DefaultContext, BasicContext, ExtendedContext):\n   context = context.copy()\n   context.clear_flags()\n  _local.__decimal_context__ = context\n  \n del threading, local \n \ndef localcontext(ctx=None):\n \"\"\n if ctx is None: ctx = getcontext()\n return _ContextManager(ctx)\n \n \n \n \n \n \n \n \nclass Decimal(object):\n \"\"\n \n __slots__ = ('_exp','_int','_sign', '_is_special')\n \n \n \n \n \n def __new__(cls, value=\"0\", context=None):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  self = object.__new__(cls)\n  \n  \n  \n  if isinstance(value, str):\n   m = _parser(value.strip())\n   if m is None:\n    if context is None:\n     context = getcontext()\n    return context._raise_error(ConversionSyntax,\n    \"Invalid literal for Decimal: %r\" % value)\n    \n   if m.group('sign') == \"-\":\n    self._sign = 1\n   else:\n    self._sign = 0\n   intpart = m.group('int')\n   if intpart is not None:\n   \n    fracpart = m.group('frac') or ''\n    exp = int(m.group('exp') or '0')\n    self._int = str(int(intpart+fracpart))\n    self._exp = exp - len(fracpart)\n    self._is_special = False\n   else:\n    diag = m.group('diag')\n    if diag is not None:\n    \n     self._int = str(int(diag or '0')).lstrip('0')\n     if m.group('signal'):\n      self._exp = 'N'\n     else:\n      self._exp = 'n'\n    else:\n    \n     self._int = '0'\n     self._exp = 'F'\n    self._is_special = True\n   return self\n   \n   \n  if isinstance(value, int):\n   if value >= 0:\n    self._sign = 0\n   else:\n    self._sign = 1\n   self._exp = 0\n   self._int = str(abs(value))\n   self._is_special = False\n   return self\n   \n   \n  if isinstance(value, Decimal):\n   self._exp = value._exp\n   self._sign = value._sign\n   self._int = value._int\n   self._is_special = value._is_special\n   return self\n   \n   \n  if isinstance(value, _WorkRep):\n   self._sign = value.sign\n   self._int = str(value.int)\n   self._exp = int(value.exp)\n   self._is_special = False\n   return self\n   \n   \n  if isinstance(value, (list,tuple)):\n   if len(value) != 3:\n    raise ValueError('Invalid tuple size in creation of Decimal '\n    'from list or tuple.  The list or tuple '\n    'should have exactly three elements.')\n    \n   if not (isinstance(value[0], int) and value[0] in (0,1)):\n    raise ValueError(\"Invalid sign.  The first value in the tuple \"\n    \"should be an integer; either 0 for a \"\n    \"positive number or 1 for a negative number.\")\n   self._sign = value[0]\n   if value[2] == 'F':\n   \n    self._int = '0'\n    self._exp = value[2]\n    self._is_special = True\n   else:\n   \n    digits = []\n    for digit in value[1]:\n     if isinstance(digit, int) and 0 <= digit <= 9:\n     \n      if digits or digit != 0:\n       digits.append(digit)\n     else:\n      raise ValueError(\"The second value in the tuple must \"\n      \"be composed of integers in the range \"\n      \"0 through 9.\")\n    if value[2] in ('n', 'N'):\n    \n     self._int = ''.join(map(str, digits))\n     self._exp = value[2]\n     self._is_special = True\n    elif isinstance(value[2], int):\n    \n     self._int = ''.join(map(str, digits or [0]))\n     self._exp = value[2]\n     self._is_special = False\n    else:\n     raise ValueError(\"The third value in the tuple must \"\n     \"be an integer, or one of the \"\n     \"strings 'F', 'n', 'N'.\")\n   return self\n   \n  if isinstance(value, float):\n   if context is None:\n    context = getcontext()\n   context._raise_error(FloatOperation,\n   \"strict semantics for mixing floats and Decimals are \"\n   \"enabled\")\n   value = Decimal.from_float(value)\n   self._exp = value._exp\n   self._sign = value._sign\n   self._int = value._int\n   self._is_special = value._is_special\n   return self\n   \n  raise TypeError(\"Cannot convert %r to Decimal\" % value)\n  \n  \n  \n def from_float(cls, f):\n  \"\"\n  if isinstance(f, int): \n   return cls(f)\n  if not isinstance(f, float):\n   raise TypeError(\"argument must be int or float.\")\n  if _math.isinf(f) or _math.isnan(f):\n   return cls(repr(f))\n  if _math.copysign(1.0, f) == 1.0:\n   sign = 0\n  else:\n   sign = 1\n  n, d = abs(f).as_integer_ratio()\n  k = d.bit_length() - 1\n  result = _dec_from_triple(sign, str(n*5**k), -k)\n  if cls is Decimal:\n   return result\n  else:\n   return cls(result)\n from_float = classmethod(from_float)\n \n def _isnan(self):\n  \"\"\n  if self._is_special:\n   exp = self._exp\n   if exp == 'n':\n    return 1\n   elif exp == 'N':\n    return 2\n  return 0\n  \n def _isinfinity(self):\n  \"\"\n  if self._exp == 'F':\n   if self._sign:\n    return -1\n   return 1\n  return 0\n  \n def _check_nans(self, other=None, context=None):\n  \"\"\n  \n  self_is_nan = self._isnan()\n  if other is None:\n   other_is_nan = False\n  else:\n   other_is_nan = other._isnan()\n   \n  if self_is_nan or other_is_nan:\n   if context is None:\n    context = getcontext()\n    \n   if self_is_nan == 2:\n    return context._raise_error(InvalidOperation, 'sNaN',\n    self)\n   if other_is_nan == 2:\n    return context._raise_error(InvalidOperation, 'sNaN',\n    other)\n   if self_is_nan:\n    return self._fix_nan(context)\n    \n   return other._fix_nan(context)\n  return 0\n  \n def _compare_check_nans(self, other, context):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  if self._is_special or other._is_special:\n   if self.is_snan():\n    return context._raise_error(InvalidOperation,\n    'comparison involving sNaN',\n    self)\n   elif other.is_snan():\n    return context._raise_error(InvalidOperation,\n    'comparison involving sNaN',\n    other)\n   elif self.is_qnan():\n    return context._raise_error(InvalidOperation,\n    'comparison involving NaN',\n    self)\n   elif other.is_qnan():\n    return context._raise_error(InvalidOperation,\n    'comparison involving NaN',\n    other)\n  return 0\n  \n def __bool__(self):\n  \"\"\n  return self._is_special or self._int != '0'\n  \n def _cmp(self, other):\n  \"\"\n  \n  if self._is_special or other._is_special:\n   self_inf = self._isinfinity()\n   other_inf = other._isinfinity()\n   if self_inf == other_inf:\n    return 0\n   elif self_inf < other_inf:\n    return -1\n   else:\n    return 1\n    \n    \n  if not self:\n   if not other:\n    return 0\n   else:\n    return -((-1)**other._sign)\n  if not other:\n   return (-1)**self._sign\n   \n   \n  if other._sign < self._sign:\n   return -1\n  if self._sign < other._sign:\n   return 1\n   \n  self_adjusted = self.adjusted()\n  other_adjusted = other.adjusted()\n  if self_adjusted == other_adjusted:\n   self_padded = self._int + '0'*(self._exp - other._exp)\n   other_padded = other._int + '0'*(other._exp - self._exp)\n   if self_padded == other_padded:\n    return 0\n   elif self_padded < other_padded:\n    return -(-1)**self._sign\n   else:\n    return (-1)**self._sign\n  elif self_adjusted > other_adjusted:\n   return (-1)**self._sign\n  else: \n   return -((-1)**self._sign)\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n def __eq__(self, other, context=None):\n  self, other = _convert_for_comparison(self, other, equality_op=True)\n  if other is NotImplemented:\n   return other\n  if self._check_nans(other, context):\n   return False\n  return self._cmp(other) == 0\n  \n def __ne__(self, other, context=None):\n  self, other = _convert_for_comparison(self, other, equality_op=True)\n  if other is NotImplemented:\n   return other\n  if self._check_nans(other, context):\n   return True\n  return self._cmp(other) != 0\n  \n  \n def __lt__(self, other, context=None):\n  self, other = _convert_for_comparison(self, other)\n  if other is NotImplemented:\n   return other\n  ans = self._compare_check_nans(other, context)\n  if ans:\n   return False\n  return self._cmp(other) < 0\n  \n def __le__(self, other, context=None):\n  self, other = _convert_for_comparison(self, other)\n  if other is NotImplemented:\n   return other\n  ans = self._compare_check_nans(other, context)\n  if ans:\n   return False\n  return self._cmp(other) <= 0\n  \n def __gt__(self, other, context=None):\n  self, other = _convert_for_comparison(self, other)\n  if other is NotImplemented:\n   return other\n  ans = self._compare_check_nans(other, context)\n  if ans:\n   return False\n  return self._cmp(other) > 0\n  \n def __ge__(self, other, context=None):\n  self, other = _convert_for_comparison(self, other)\n  if other is NotImplemented:\n   return other\n  ans = self._compare_check_nans(other, context)\n  if ans:\n   return False\n  return self._cmp(other) >= 0\n  \n def compare(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit=True)\n  \n  \n  if (self._is_special or other and other._is_special):\n   ans = self._check_nans(other, context)\n   if ans:\n    return ans\n    \n  return Decimal(self._cmp(other))\n  \n def __hash__(self):\n  \"\"\n  \n  \n  \n  \n  \n  if self._is_special:\n   if self.is_snan():\n    raise TypeError('Cannot hash a signaling NaN value.')\n   elif self.is_nan():\n    return _PyHASH_NAN\n   else:\n    if self._sign:\n     return -_PyHASH_INF\n    else:\n     return _PyHASH_INF\n     \n  if self._exp >= 0:\n   exp_hash = pow(10, self._exp, _PyHASH_MODULUS)\n  else:\n   exp_hash = pow(_PyHASH_10INV, -self._exp, _PyHASH_MODULUS)\n  hash_ = int(self._int) * exp_hash % _PyHASH_MODULUS\n  ans = hash_ if self >= 0 else -hash_\n  return -2 if ans == -1 else ans\n  \n def as_tuple(self):\n  \"\"\n  return DecimalTuple(self._sign, tuple(map(int, self._int)), self._exp)\n  \n def __repr__(self):\n  \"\"\n  \n  return \"Decimal('%s')\" % str(self)\n  \n def __str__(self, eng=False, context=None):\n  \"\"\n  \n  sign = ['', '-'][self._sign]\n  if self._is_special:\n   if self._exp == 'F':\n    return sign + 'Infinity'\n   elif self._exp == 'n':\n    return sign + 'NaN' + self._int\n   else: \n    return sign + 'sNaN' + self._int\n    \n    \n  leftdigits = self._exp + len(self._int)\n  \n  \n  \n  \n  if self._exp <= 0 and leftdigits > -6:\n  \n   dotplace = leftdigits\n  elif not eng:\n  \n   dotplace = 1\n  elif self._int == '0':\n  \n   dotplace = (leftdigits + 1) % 3 - 1\n  else:\n  \n   dotplace = (leftdigits - 1) % 3 + 1\n   \n  if dotplace <= 0:\n   intpart = '0'\n   fracpart = '.' + '0'*(-dotplace) + self._int\n  elif dotplace >= len(self._int):\n   intpart = self._int+'0'*(dotplace-len(self._int))\n   fracpart = ''\n  else:\n   intpart = self._int[:dotplace]\n   fracpart = '.' + self._int[dotplace:]\n  if leftdigits == dotplace:\n   exp = ''\n  else:\n   if context is None:\n    context = getcontext()\n   exp = ['e', 'E'][context.capitals] + \"%+d\" % (leftdigits-dotplace)\n   \n  return sign + intpart + fracpart + exp\n  \n def to_eng_string(self, context=None):\n  \"\"\n  return self.__str__(eng=True, context=context)\n  \n def __neg__(self, context=None):\n  \"\"\n  if self._is_special:\n   ans = self._check_nans(context=context)\n   if ans:\n    return ans\n    \n  if context is None:\n   context = getcontext()\n   \n  if not self and context.rounding != ROUND_FLOOR:\n  \n  \n   ans = self.copy_abs()\n  else:\n   ans = self.copy_negate()\n   \n  return ans._fix(context)\n  \n def __pos__(self, context=None):\n  \"\"\n  if self._is_special:\n   ans = self._check_nans(context=context)\n   if ans:\n    return ans\n    \n  if context is None:\n   context = getcontext()\n   \n  if not self and context.rounding != ROUND_FLOOR:\n  \n   ans = self.copy_abs()\n  else:\n   ans = Decimal(self)\n   \n  return ans._fix(context)\n  \n def __abs__(self, round=True, context=None):\n  \"\"\n  if not round:\n   return self.copy_abs()\n   \n  if self._is_special:\n   ans = self._check_nans(context=context)\n   if ans:\n    return ans\n    \n  if self._sign:\n   ans = self.__neg__(context=context)\n  else:\n   ans = self.__pos__(context=context)\n   \n  return ans\n  \n def __add__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n   \n  if context is None:\n   context = getcontext()\n   \n  if self._is_special or other._is_special:\n   ans = self._check_nans(other, context)\n   if ans:\n    return ans\n    \n   if self._isinfinity():\n   \n    if self._sign != other._sign and other._isinfinity():\n     return context._raise_error(InvalidOperation, '-INF + INF')\n    return Decimal(self)\n   if other._isinfinity():\n    return Decimal(other) \n    \n  exp = min(self._exp, other._exp)\n  negativezero = 0\n  if context.rounding == ROUND_FLOOR and self._sign != other._sign:\n  \n   negativezero = 1\n   \n  if not self and not other:\n   sign = min(self._sign, other._sign)\n   if negativezero:\n    sign = 1\n   ans = _dec_from_triple(sign, '0', exp)\n   ans = ans._fix(context)\n   return ans\n  if not self:\n   exp = max(exp, other._exp - context.prec-1)\n   ans = other._rescale(exp, context.rounding)\n   ans = ans._fix(context)\n   return ans\n  if not other:\n   exp = max(exp, self._exp - context.prec-1)\n   ans = self._rescale(exp, context.rounding)\n   ans = ans._fix(context)\n   return ans\n   \n  op1 = _WorkRep(self)\n  op2 = _WorkRep(other)\n  op1, op2 = _normalize(op1, op2, context.prec)\n  \n  result = _WorkRep()\n  if op1.sign != op2.sign:\n  \n   if op1.int == op2.int:\n    ans = _dec_from_triple(negativezero, '0', exp)\n    ans = ans._fix(context)\n    return ans\n   if op1.int < op2.int:\n    op1, op2 = op2, op1\n    \n   if op1.sign == 1:\n    result.sign = 1\n    op1.sign, op2.sign = op2.sign, op1.sign\n   else:\n    result.sign = 0\n    \n  elif op1.sign == 1:\n   result.sign = 1\n   op1.sign, op2.sign = (0, 0)\n  else:\n   result.sign = 0\n   \n   \n  if op2.sign == 0:\n   result.int = op1.int + op2.int\n  else:\n   result.int = op1.int - op2.int\n   \n  result.exp = op1.exp\n  ans = Decimal(result)\n  ans = ans._fix(context)\n  return ans\n  \n __radd__ = __add__\n \n def __sub__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n   \n  if self._is_special or other._is_special:\n   ans = self._check_nans(other, context=context)\n   if ans:\n    return ans\n    \n    \n  return self.__add__(other.copy_negate(), context=context)\n  \n def __rsub__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n   \n  return other.__sub__(self, context=context)\n  \n def __mul__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n   \n  if context is None:\n   context = getcontext()\n   \n  resultsign = self._sign ^ other._sign\n  \n  if self._is_special or other._is_special:\n   ans = self._check_nans(other, context)\n   if ans:\n    return ans\n    \n   if self._isinfinity():\n    if not other:\n     return context._raise_error(InvalidOperation, '(+-)INF * 0')\n    return _SignedInfinity[resultsign]\n    \n   if other._isinfinity():\n    if not self:\n     return context._raise_error(InvalidOperation, '0 * (+-)INF')\n    return _SignedInfinity[resultsign]\n    \n  resultexp = self._exp + other._exp\n  \n  \n  if not self or not other:\n   ans = _dec_from_triple(resultsign, '0', resultexp)\n   \n   ans = ans._fix(context)\n   return ans\n   \n   \n  if self._int == '1':\n   ans = _dec_from_triple(resultsign, other._int, resultexp)\n   ans = ans._fix(context)\n   return ans\n  if other._int == '1':\n   ans = _dec_from_triple(resultsign, self._int, resultexp)\n   ans = ans._fix(context)\n   return ans\n   \n  op1 = _WorkRep(self)\n  op2 = _WorkRep(other)\n  \n  ans = _dec_from_triple(resultsign, str(op1.int * op2.int), resultexp)\n  ans = ans._fix(context)\n  \n  return ans\n __rmul__ = __mul__\n \n def __truediv__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return NotImplemented\n   \n  if context is None:\n   context = getcontext()\n   \n  sign = self._sign ^ other._sign\n  \n  if self._is_special or other._is_special:\n   ans = self._check_nans(other, context)\n   if ans:\n    return ans\n    \n   if self._isinfinity() and other._isinfinity():\n    return context._raise_error(InvalidOperation, '(+-)INF/(+-)INF')\n    \n   if self._isinfinity():\n    return _SignedInfinity[sign]\n    \n   if other._isinfinity():\n    context._raise_error(Clamped, 'Division by infinity')\n    return _dec_from_triple(sign, '0', context.Etiny())\n    \n    \n  if not other:\n   if not self:\n    return context._raise_error(DivisionUndefined, '0 / 0')\n   return context._raise_error(DivisionByZero, 'x / 0', sign)\n   \n  if not self:\n   exp = self._exp - other._exp\n   coeff = 0\n  else:\n  \n   shift = len(other._int) - len(self._int) + context.prec + 1\n   exp = self._exp - other._exp - shift\n   op1 = _WorkRep(self)\n   op2 = _WorkRep(other)\n   if shift >= 0:\n    coeff, remainder = divmod(op1.int * 10**shift, op2.int)\n   else:\n    coeff, remainder = divmod(op1.int, op2.int * 10**-shift)\n   if remainder:\n   \n    if coeff % 5 == 0:\n     coeff += 1\n   else:\n   \n    ideal_exp = self._exp - other._exp\n    while exp < ideal_exp and coeff % 10 == 0:\n     coeff //= 10\n     exp += 1\n     \n  ans = _dec_from_triple(sign, str(coeff), exp)\n  return ans._fix(context)\n  \n def _divide(self, other, context):\n  \"\"\n  sign = self._sign ^ other._sign\n  if other._isinfinity():\n   ideal_exp = self._exp\n  else:\n   ideal_exp = min(self._exp, other._exp)\n   \n  expdiff = self.adjusted() - other.adjusted()\n  if not self or other._isinfinity() or expdiff <= -2:\n   return (_dec_from_triple(sign, '0', 0),\n   self._rescale(ideal_exp, context.rounding))\n  if expdiff <= context.prec:\n   op1 = _WorkRep(self)\n   op2 = _WorkRep(other)\n   if op1.exp >= op2.exp:\n    op1.int *= 10**(op1.exp - op2.exp)\n   else:\n    op2.int *= 10**(op2.exp - op1.exp)\n   q, r = divmod(op1.int, op2.int)\n   if q < 10**context.prec:\n    return (_dec_from_triple(sign, str(q), 0),\n    _dec_from_triple(self._sign, str(r), ideal_exp))\n    \n    \n  ans = context._raise_error(DivisionImpossible,\n  'quotient too large in //, % or divmod')\n  return ans, ans\n  \n def __rtruediv__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n  return other.__truediv__(self, context=context)\n  \n def __divmod__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n   \n  if context is None:\n   context = getcontext()\n   \n  ans = self._check_nans(other, context)\n  if ans:\n   return (ans, ans)\n   \n  sign = self._sign ^ other._sign\n  if self._isinfinity():\n   if other._isinfinity():\n    ans = context._raise_error(InvalidOperation, 'divmod(INF, INF)')\n    return ans, ans\n   else:\n    return (_SignedInfinity[sign],\n    context._raise_error(InvalidOperation, 'INF % x'))\n    \n  if not other:\n   if not self:\n    ans = context._raise_error(DivisionUndefined, 'divmod(0, 0)')\n    return ans, ans\n   else:\n    return (context._raise_error(DivisionByZero, 'x // 0', sign),\n    context._raise_error(InvalidOperation, 'x % 0'))\n    \n  quotient, remainder = self._divide(other, context)\n  remainder = remainder._fix(context)\n  return quotient, remainder\n  \n def __rdivmod__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n  return other.__divmod__(self, context=context)\n  \n def __mod__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n   \n  if context is None:\n   context = getcontext()\n   \n  ans = self._check_nans(other, context)\n  if ans:\n   return ans\n   \n  if self._isinfinity():\n   return context._raise_error(InvalidOperation, 'INF % x')\n  elif not other:\n   if self:\n    return context._raise_error(InvalidOperation, 'x % 0')\n   else:\n    return context._raise_error(DivisionUndefined, '0 % 0')\n    \n  remainder = self._divide(other, context)[1]\n  remainder = remainder._fix(context)\n  return remainder\n  \n def __rmod__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n  return other.__mod__(self, context=context)\n  \n def remainder_near(self, other, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  other = _convert_other(other, raiseit=True)\n  \n  ans = self._check_nans(other, context)\n  if ans:\n   return ans\n   \n   \n  if self._isinfinity():\n   return context._raise_error(InvalidOperation,\n   'remainder_near(infinity, x)')\n   \n   \n  if not other:\n   if self:\n    return context._raise_error(InvalidOperation,\n    'remainder_near(x, 0)')\n   else:\n    return context._raise_error(DivisionUndefined,\n    'remainder_near(0, 0)')\n    \n    \n  if other._isinfinity():\n   ans = Decimal(self)\n   return ans._fix(context)\n   \n   \n  ideal_exponent = min(self._exp, other._exp)\n  if not self:\n   ans = _dec_from_triple(self._sign, '0', ideal_exponent)\n   return ans._fix(context)\n   \n   \n  expdiff = self.adjusted() - other.adjusted()\n  if expdiff >= context.prec + 1:\n  \n   return context._raise_error(DivisionImpossible)\n  if expdiff <= -2:\n  \n   ans = self._rescale(ideal_exponent, context.rounding)\n   return ans._fix(context)\n   \n   \n  op1 = _WorkRep(self)\n  op2 = _WorkRep(other)\n  if op1.exp >= op2.exp:\n   op1.int *= 10**(op1.exp - op2.exp)\n  else:\n   op2.int *= 10**(op2.exp - op1.exp)\n  q, r = divmod(op1.int, op2.int)\n  \n  \n  \n  if 2*r + (q&1) > op2.int:\n   r -= op2.int\n   q += 1\n   \n  if q >= 10**context.prec:\n   return context._raise_error(DivisionImpossible)\n   \n   \n  sign = self._sign\n  if r < 0:\n   sign = 1-sign\n   r = -r\n   \n  ans = _dec_from_triple(sign, str(r), ideal_exponent)\n  return ans._fix(context)\n  \n def __floordiv__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n   \n  if context is None:\n   context = getcontext()\n   \n  ans = self._check_nans(other, context)\n  if ans:\n   return ans\n   \n  if self._isinfinity():\n   if other._isinfinity():\n    return context._raise_error(InvalidOperation, 'INF // INF')\n   else:\n    return _SignedInfinity[self._sign ^ other._sign]\n    \n  if not other:\n   if self:\n    return context._raise_error(DivisionByZero, 'x // 0',\n    self._sign ^ other._sign)\n   else:\n    return context._raise_error(DivisionUndefined, '0 // 0')\n    \n  return self._divide(other, context)[0]\n  \n def __rfloordiv__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n  return other.__floordiv__(self, context=context)\n  \n def __float__(self):\n  \"\"\n  if self._isnan():\n   if self.is_snan():\n    raise ValueError(\"Cannot convert signaling NaN to float\")\n   s = \"-nan\" if self._sign else \"nan\"\n  else:\n   s = str(self)\n  return float(s)\n  \n def __int__(self):\n  \"\"\n  if self._is_special:\n   if self._isnan():\n    raise ValueError(\"Cannot convert NaN to integer\")\n   elif self._isinfinity():\n    raise OverflowError(\"Cannot convert infinity to integer\")\n  s = (-1)**self._sign\n  if self._exp >= 0:\n   return s*int(self._int)*10**self._exp\n  else:\n   return s*int(self._int[:self._exp] or '0')\n   \n __trunc__ = __int__\n \n def real(self):\n  return self\n real = property(real)\n \n def imag(self):\n  return Decimal(0)\n imag = property(imag)\n \n def conjugate(self):\n  return self\n  \n def __complex__(self):\n  return complex(float(self))\n  \n def _fix_nan(self, context):\n  \"\"\n  payload = self._int\n  \n  \n  \n  max_payload_len = context.prec - context.clamp\n  if len(payload) > max_payload_len:\n   payload = payload[len(payload)-max_payload_len:].lstrip('0')\n   return _dec_from_triple(self._sign, payload, self._exp, True)\n  return Decimal(self)\n  \n def _fix(self, context):\n  \"\"\n  \n  if self._is_special:\n   if self._isnan():\n   \n    return self._fix_nan(context)\n   else:\n   \n    return Decimal(self)\n    \n    \n    \n  Etiny = context.Etiny()\n  Etop = context.Etop()\n  if not self:\n   exp_max = [context.Emax, Etop][context.clamp]\n   new_exp = min(max(self._exp, Etiny), exp_max)\n   if new_exp != self._exp:\n    context._raise_error(Clamped)\n    return _dec_from_triple(self._sign, '0', new_exp)\n   else:\n    return Decimal(self)\n    \n    \n    \n  exp_min = len(self._int) + self._exp - context.prec\n  if exp_min > Etop:\n  \n   ans = context._raise_error(Overflow, 'above Emax', self._sign)\n   context._raise_error(Inexact)\n   context._raise_error(Rounded)\n   return ans\n   \n  self_is_subnormal = exp_min < Etiny\n  if self_is_subnormal:\n   exp_min = Etiny\n   \n   \n  if self._exp < exp_min:\n   digits = len(self._int) + self._exp - exp_min\n   if digits < 0:\n    self = _dec_from_triple(self._sign, '1', exp_min-1)\n    digits = 0\n   rounding_method = self._pick_rounding_function[context.rounding]\n   changed = rounding_method(self, digits)\n   coeff = self._int[:digits] or '0'\n   if changed > 0:\n    coeff = str(int(coeff)+1)\n    if len(coeff) > context.prec:\n     coeff = coeff[:-1]\n     exp_min += 1\n     \n     \n   if exp_min > Etop:\n    ans = context._raise_error(Overflow, 'above Emax', self._sign)\n   else:\n    ans = _dec_from_triple(self._sign, coeff, exp_min)\n    \n    \n    \n   if changed and self_is_subnormal:\n    context._raise_error(Underflow)\n   if self_is_subnormal:\n    context._raise_error(Subnormal)\n   if changed:\n    context._raise_error(Inexact)\n   context._raise_error(Rounded)\n   if not ans:\n   \n    context._raise_error(Clamped)\n   return ans\n   \n  if self_is_subnormal:\n   context._raise_error(Subnormal)\n   \n   \n  if context.clamp == 1 and self._exp > Etop:\n   context._raise_error(Clamped)\n   self_padded = self._int + '0'*(self._exp - Etop)\n   return _dec_from_triple(self._sign, self_padded, Etop)\n   \n   \n  return Decimal(self)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def _round_down(self, prec):\n  \"\"\n  if _all_zeros(self._int, prec):\n   return 0\n  else:\n   return -1\n   \n def _round_up(self, prec):\n  \"\"\n  return -self._round_down(prec)\n  \n def _round_half_up(self, prec):\n  \"\"\n  if self._int[prec] in '56789':\n   return 1\n  elif _all_zeros(self._int, prec):\n   return 0\n  else:\n   return -1\n   \n def _round_half_down(self, prec):\n  \"\"\n  if _exact_half(self._int, prec):\n   return -1\n  else:\n   return self._round_half_up(prec)\n   \n def _round_half_even(self, prec):\n  \"\"\n  if _exact_half(self._int, prec) and (prec == 0 or self._int[prec-1] in '02468'):\n   return -1\n  else:\n   return self._round_half_up(prec)\n   \n def _round_ceiling(self, prec):\n  \"\"\n  if self._sign:\n   return self._round_down(prec)\n  else:\n   return -self._round_down(prec)\n   \n def _round_floor(self, prec):\n  \"\"\n  if not self._sign:\n   return self._round_down(prec)\n  else:\n   return -self._round_down(prec)\n   \n def _round_05up(self, prec):\n  \"\"\n  if prec and self._int[prec-1] not in '05':\n   return self._round_down(prec)\n  else:\n   return -self._round_down(prec)\n   \n _pick_rounding_function = dict(\n ROUND_DOWN = _round_down,\n ROUND_UP = _round_up,\n ROUND_HALF_UP = _round_half_up,\n ROUND_HALF_DOWN = _round_half_down,\n ROUND_HALF_EVEN = _round_half_even,\n ROUND_CEILING = _round_ceiling,\n ROUND_FLOOR = _round_floor,\n ROUND_05UP = _round_05up,\n )\n \n def __round__(self, n=None):\n  \"\"\n  if n is not None:\n  \n   if not isinstance(n, int):\n    raise TypeError('Second argument to round should be integral')\n   exp = _dec_from_triple(0, '1', -n)\n   return self.quantize(exp)\n   \n   \n  if self._is_special:\n   if self.is_nan():\n    raise ValueError(\"cannot round a NaN\")\n   else:\n    raise OverflowError(\"cannot round an infinity\")\n  return int(self._rescale(0, ROUND_HALF_EVEN))\n  \n def __floor__(self):\n  \"\"\n  if self._is_special:\n   if self.is_nan():\n    raise ValueError(\"cannot round a NaN\")\n   else:\n    raise OverflowError(\"cannot round an infinity\")\n  return int(self._rescale(0, ROUND_FLOOR))\n  \n def __ceil__(self):\n  \"\"\n  if self._is_special:\n   if self.is_nan():\n    raise ValueError(\"cannot round a NaN\")\n   else:\n    raise OverflowError(\"cannot round an infinity\")\n  return int(self._rescale(0, ROUND_CEILING))\n  \n def fma(self, other, third, context=None):\n  \"\"\n  \n  other = _convert_other(other, raiseit=True)\n  third = _convert_other(third, raiseit=True)\n  \n  \n  \n  if self._is_special or other._is_special:\n   if context is None:\n    context = getcontext()\n   if self._exp == 'N':\n    return context._raise_error(InvalidOperation, 'sNaN', self)\n   if other._exp == 'N':\n    return context._raise_error(InvalidOperation, 'sNaN', other)\n   if self._exp == 'n':\n    product = self\n   elif other._exp == 'n':\n    product = other\n   elif self._exp == 'F':\n    if not other:\n     return context._raise_error(InvalidOperation,\n     'INF * 0 in fma')\n    product = _SignedInfinity[self._sign ^ other._sign]\n   elif other._exp == 'F':\n    if not self:\n     return context._raise_error(InvalidOperation,\n     '0 * INF in fma')\n    product = _SignedInfinity[self._sign ^ other._sign]\n  else:\n   product = _dec_from_triple(self._sign ^ other._sign,\n   str(int(self._int) * int(other._int)),\n   self._exp + other._exp)\n   \n  return product.__add__(third, context)\n  \n def _power_modulo(self, other, modulo, context=None):\n  \"\"\n  \n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n  modulo = _convert_other(modulo)\n  if modulo is NotImplemented:\n   return modulo\n   \n  if context is None:\n   context = getcontext()\n   \n   \n   \n  self_is_nan = self._isnan()\n  other_is_nan = other._isnan()\n  modulo_is_nan = modulo._isnan()\n  if self_is_nan or other_is_nan or modulo_is_nan:\n   if self_is_nan == 2:\n    return context._raise_error(InvalidOperation, 'sNaN',\n    self)\n   if other_is_nan == 2:\n    return context._raise_error(InvalidOperation, 'sNaN',\n    other)\n   if modulo_is_nan == 2:\n    return context._raise_error(InvalidOperation, 'sNaN',\n    modulo)\n   if self_is_nan:\n    return self._fix_nan(context)\n   if other_is_nan:\n    return other._fix_nan(context)\n   return modulo._fix_nan(context)\n   \n   \n  if not (self._isinteger() and\n  other._isinteger() and\n  modulo._isinteger()):\n   return context._raise_error(InvalidOperation,\n   'pow() 3rd argument not allowed '\n   'unless all arguments are integers')\n  if other < 0:\n   return context._raise_error(InvalidOperation,\n   'pow() 2nd argument cannot be '\n   'negative when 3rd argument specified')\n  if not modulo:\n   return context._raise_error(InvalidOperation,\n   'pow() 3rd argument cannot be 0')\n   \n   \n   \n  if modulo.adjusted() >= context.prec:\n   return context._raise_error(InvalidOperation,\n   'insufficient precision: pow() 3rd '\n   'argument must not have more than '\n   'precision digits')\n   \n   \n   \n  if not other and not self:\n   return context._raise_error(InvalidOperation,\n   'at least one of pow() 1st argument '\n   'and 2nd argument must be nonzero ;'\n   '0**0 is not defined')\n   \n   \n  if other._iseven():\n   sign = 0\n  else:\n   sign = self._sign\n   \n   \n   \n  modulo = abs(int(modulo))\n  base = _WorkRep(self.to_integral_value())\n  exponent = _WorkRep(other.to_integral_value())\n  \n  \n  base = (base.int % modulo * pow(10, base.exp, modulo)) % modulo\n  for i in range(exponent.exp):\n   base = pow(base, 10, modulo)\n  base = pow(base, exponent.int, modulo)\n  \n  return _dec_from_triple(sign, str(base), 0)\n  \n def _power_exact(self, other, p):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  x = _WorkRep(self)\n  xc, xe = x.int, x.exp\n  while xc % 10 == 0:\n   xc //= 10\n   xe += 1\n   \n  y = _WorkRep(other)\n  yc, ye = y.int, y.exp\n  while yc % 10 == 0:\n   yc //= 10\n   ye += 1\n   \n   \n   \n  if xc == 1:\n   xe *= yc\n   \n   while xe % 10 == 0:\n    xe //= 10\n    ye += 1\n   if ye < 0:\n    return None\n   exponent = xe * 10**ye\n   if y.sign == 1:\n    exponent = -exponent\n    \n   if other._isinteger() and other._sign == 0:\n    ideal_exponent = self._exp*int(other)\n    zeros = min(exponent-ideal_exponent, p-1)\n   else:\n    zeros = 0\n   return _dec_from_triple(0, '1' + '0'*zeros, exponent-zeros)\n   \n   \n   \n  if y.sign == 1:\n   last_digit = xc % 10\n   if last_digit in (2,4,6,8):\n   \n    if xc & -xc != xc:\n     return None\n     \n    e = _nbits(xc)-1\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    emax = p*93//65\n    if ye >= len(str(emax)):\n     return None\n     \n     \n    e = _decimal_lshift_exact(e * yc, ye)\n    xe = _decimal_lshift_exact(xe * yc, ye)\n    if e is None or xe is None:\n     return None\n     \n    if e > emax:\n     return None\n    xc = 5**e\n    \n   elif last_digit == 5:\n   \n   \n    e = _nbits(xc)*28//65\n    xc, remainder = divmod(5**e, xc)\n    if remainder:\n     return None\n    while xc % 5 == 0:\n     xc //= 5\n     e -= 1\n     \n     \n     \n     \n    emax = p*10//3\n    if ye >= len(str(emax)):\n     return None\n     \n    e = _decimal_lshift_exact(e * yc, ye)\n    xe = _decimal_lshift_exact(xe * yc, ye)\n    if e is None or xe is None:\n     return None\n     \n    if e > emax:\n     return None\n    xc = 2**e\n   else:\n    return None\n    \n   if xc >= 10**p:\n    return None\n   xe = -e-xe\n   return _dec_from_triple(0, str(xc), xe)\n   \n   \n  if ye >= 0:\n   m, n = yc*10**ye, 1\n  else:\n   if xe != 0 and len(str(abs(yc*xe))) <= -ye:\n    return None\n   xc_bits = _nbits(xc)\n   if xc != 1 and len(str(abs(yc)*xc_bits)) <= -ye:\n    return None\n   m, n = yc, 10**(-ye)\n   while m % 2 == n % 2 == 0:\n    m //= 2\n    n //= 2\n   while m % 5 == n % 5 == 0:\n    m //= 5\n    n //= 5\n    \n    \n  if n > 1:\n  \n   if xc != 1 and xc_bits <= n:\n    return None\n    \n   xe, rem = divmod(xe, n)\n   if rem != 0:\n    return None\n    \n    \n   a = 1 << -(-_nbits(xc)//n) \n   while True:\n    q, r = divmod(xc, a**(n-1))\n    if a <= q:\n     break\n    else:\n     a = (a*(n-1) + q)//n\n   if not (a == q and r == 0):\n    return None\n   xc = a\n   \n   \n   \n   \n   \n   \n  if xc > 1 and m > p*100//_log10_lb(xc):\n   return None\n  xc = xc**m\n  xe *= m\n  if xc > 10**p:\n   return None\n   \n   \n   \n   \n  str_xc = str(xc)\n  if other._isinteger() and other._sign == 0:\n   ideal_exponent = self._exp*int(other)\n   zeros = min(xe-ideal_exponent, p-len(str_xc))\n  else:\n   zeros = 0\n  return _dec_from_triple(0, str_xc+'0'*zeros, xe-zeros)\n  \n def __pow__(self, other, modulo=None, context=None):\n  \"\"\n  \n  if modulo is not None:\n   return self._power_modulo(other, modulo, context)\n   \n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n   \n  if context is None:\n   context = getcontext()\n   \n   \n  ans = self._check_nans(other, context)\n  if ans:\n   return ans\n   \n   \n  if not other:\n   if not self:\n    return context._raise_error(InvalidOperation, '0 ** 0')\n   else:\n    return _One\n    \n    \n  result_sign = 0\n  if self._sign == 1:\n   if other._isinteger():\n    if not other._iseven():\n     result_sign = 1\n   else:\n   \n   \n    if self:\n     return context._raise_error(InvalidOperation,\n     'x ** y with x negative and y not an integer')\n     \n   self = self.copy_negate()\n   \n   \n  if not self:\n   if other._sign == 0:\n    return _dec_from_triple(result_sign, '0', 0)\n   else:\n    return _SignedInfinity[result_sign]\n    \n    \n  if self._isinfinity():\n   if other._sign == 0:\n    return _SignedInfinity[result_sign]\n   else:\n    return _dec_from_triple(result_sign, '0', 0)\n    \n    \n    \n    \n  if self == _One:\n   if other._isinteger():\n   \n   \n   \n   \n    if other._sign == 1:\n     multiplier = 0\n    elif other > context.prec:\n     multiplier = context.prec\n    else:\n     multiplier = int(other)\n     \n    exp = self._exp * multiplier\n    if exp < 1-context.prec:\n     exp = 1-context.prec\n     context._raise_error(Rounded)\n   else:\n    context._raise_error(Inexact)\n    context._raise_error(Rounded)\n    exp = 1-context.prec\n    \n   return _dec_from_triple(result_sign, '1'+'0'*-exp, exp)\n   \n   \n  self_adj = self.adjusted()\n  \n  \n  \n  if other._isinfinity():\n   if (other._sign == 0) == (self_adj < 0):\n    return _dec_from_triple(result_sign, '0', 0)\n   else:\n    return _SignedInfinity[result_sign]\n    \n    \n    \n  ans = None\n  exact = False\n  \n  \n  \n  \n  \n  \n  bound = self._log10_exp_bound() + other.adjusted()\n  if (self_adj >= 0) == (other._sign == 0):\n  \n  \n   if bound >= len(str(context.Emax)):\n    ans = _dec_from_triple(result_sign, '1', context.Emax+1)\n  else:\n  \n  \n   Etiny = context.Etiny()\n   if bound >= len(str(-Etiny)):\n    ans = _dec_from_triple(result_sign, '1', Etiny-1)\n    \n    \n  if ans is None:\n   ans = self._power_exact(other, context.prec + 1)\n   if ans is not None:\n    if result_sign == 1:\n     ans = _dec_from_triple(1, ans._int, ans._exp)\n    exact = True\n    \n    \n  if ans is None:\n   p = context.prec\n   x = _WorkRep(self)\n   xc, xe = x.int, x.exp\n   y = _WorkRep(other)\n   yc, ye = y.int, y.exp\n   if y.sign == 1:\n    yc = -yc\n    \n    \n    \n   extra = 3\n   while True:\n    coeff, exp = _dpower(xc, xe, yc, ye, p+extra)\n    if coeff % (5*10**(len(str(coeff))-p-1)):\n     break\n    extra += 3\n    \n   ans = _dec_from_triple(result_sign, str(coeff), exp)\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n  if exact and not other._isinteger():\n  \n  \n   if len(ans._int) <= context.prec:\n    expdiff = context.prec + 1 - len(ans._int)\n    ans = _dec_from_triple(ans._sign, ans._int+'0'*expdiff,\n    ans._exp-expdiff)\n    \n    \n   newcontext = context.copy()\n   newcontext.clear_flags()\n   for exception in _signals:\n    newcontext.traps[exception] = 0\n    \n    \n   ans = ans._fix(newcontext)\n   \n   \n   newcontext._raise_error(Inexact)\n   if newcontext.flags[Subnormal]:\n    newcontext._raise_error(Underflow)\n    \n    \n    \n    \n    \n    \n   if newcontext.flags[Overflow]:\n    context._raise_error(Overflow, 'above Emax', ans._sign)\n   for exception in Underflow, Subnormal, Inexact, Rounded, Clamped:\n    if newcontext.flags[exception]:\n     context._raise_error(exception)\n     \n  else:\n   ans = ans._fix(context)\n   \n  return ans\n  \n def __rpow__(self, other, context=None):\n  \"\"\n  other = _convert_other(other)\n  if other is NotImplemented:\n   return other\n  return other.__pow__(self, context=context)\n  \n def normalize(self, context=None):\n  \"\"\n  \n  if context is None:\n   context = getcontext()\n   \n  if self._is_special:\n   ans = self._check_nans(context=context)\n   if ans:\n    return ans\n    \n  dup = self._fix(context)\n  if dup._isinfinity():\n   return dup\n   \n  if not dup:\n   return _dec_from_triple(dup._sign, '0', 0)\n  exp_max = [context.Emax, context.Etop()][context.clamp]\n  end = len(dup._int)\n  exp = dup._exp\n  while dup._int[end-1] == '0' and exp < exp_max:\n   exp += 1\n   end -= 1\n  return _dec_from_triple(dup._sign, dup._int[:end], exp)\n  \n def quantize(self, exp, rounding=None, context=None, watchexp=True):\n  \"\"\n  exp = _convert_other(exp, raiseit=True)\n  \n  if context is None:\n   context = getcontext()\n  if rounding is None:\n   rounding = context.rounding\n   \n  if self._is_special or exp._is_special:\n   ans = self._check_nans(exp, context)\n   if ans:\n    return ans\n    \n   if exp._isinfinity() or self._isinfinity():\n    if exp._isinfinity() and self._isinfinity():\n     return Decimal(self) \n    return context._raise_error(InvalidOperation,\n    'quantize with one INF')\n    \n    \n  if not watchexp:\n   ans = self._rescale(exp._exp, rounding)\n   \n   if ans._exp > self._exp:\n    context._raise_error(Rounded)\n    if ans != self:\n     context._raise_error(Inexact)\n   return ans\n   \n   \n  if not (context.Etiny() <= exp._exp <= context.Emax):\n   return context._raise_error(InvalidOperation,\n   'target exponent out of bounds in quantize')\n   \n  if not self:\n   ans = _dec_from_triple(self._sign, '0', exp._exp)\n   return ans._fix(context)\n   \n  self_adjusted = self.adjusted()\n  if self_adjusted > context.Emax:\n   return context._raise_error(InvalidOperation,\n   'exponent of quantize result too large for current context')\n  if self_adjusted - exp._exp + 1 > context.prec:\n   return context._raise_error(InvalidOperation,\n   'quantize result has too many digits for current context')\n   \n  ans = self._rescale(exp._exp, rounding)\n  if ans.adjusted() > context.Emax:\n   return context._raise_error(InvalidOperation,\n   'exponent of quantize result too large for current context')\n  if len(ans._int) > context.prec:\n   return context._raise_error(InvalidOperation,\n   'quantize result has too many digits for current context')\n   \n   \n  if ans and ans.adjusted() < context.Emin:\n   context._raise_error(Subnormal)\n  if ans._exp > self._exp:\n   if ans != self:\n    context._raise_error(Inexact)\n   context._raise_error(Rounded)\n   \n   \n   \n  ans = ans._fix(context)\n  return ans\n  \n def same_quantum(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit=True)\n  if self._is_special or other._is_special:\n   return (self.is_nan() and other.is_nan() or\n   self.is_infinite() and other.is_infinite())\n  return self._exp == other._exp\n  \n def _rescale(self, exp, rounding):\n  \"\"\n  if self._is_special:\n   return Decimal(self)\n  if not self:\n   return _dec_from_triple(self._sign, '0', exp)\n   \n  if self._exp >= exp:\n  \n   return _dec_from_triple(self._sign,\n   self._int + '0'*(self._exp - exp), exp)\n   \n   \n   \n  digits = len(self._int) + self._exp - exp\n  if digits < 0:\n   self = _dec_from_triple(self._sign, '1', exp-1)\n   digits = 0\n  this_function = self._pick_rounding_function[rounding]\n  changed = this_function(self, digits)\n  coeff = self._int[:digits] or '0'\n  if changed == 1:\n   coeff = str(int(coeff)+1)\n  return _dec_from_triple(self._sign, coeff, exp)\n  \n def _round(self, places, rounding):\n  \"\"\n  if places <= 0:\n   raise ValueError(\"argument should be at least 1 in _round\")\n  if self._is_special or not self:\n   return Decimal(self)\n  ans = self._rescale(self.adjusted()+1-places, rounding)\n  \n  \n  \n  \n  if ans.adjusted() != self.adjusted():\n   ans = ans._rescale(ans.adjusted()+1-places, rounding)\n  return ans\n  \n def to_integral_exact(self, rounding=None, context=None):\n  \"\"\n  if self._is_special:\n   ans = self._check_nans(context=context)\n   if ans:\n    return ans\n   return Decimal(self)\n  if self._exp >= 0:\n   return Decimal(self)\n  if not self:\n   return _dec_from_triple(self._sign, '0', 0)\n  if context is None:\n   context = getcontext()\n  if rounding is None:\n   rounding = context.rounding\n  ans = self._rescale(0, rounding)\n  if ans != self:\n   context._raise_error(Inexact)\n  context._raise_error(Rounded)\n  return ans\n  \n def to_integral_value(self, rounding=None, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n  if rounding is None:\n   rounding = context.rounding\n  if self._is_special:\n   ans = self._check_nans(context=context)\n   if ans:\n    return ans\n   return Decimal(self)\n  if self._exp >= 0:\n   return Decimal(self)\n  else:\n   return self._rescale(0, rounding)\n   \n   \n to_integral = to_integral_value\n \n def sqrt(self, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  if self._is_special:\n   ans = self._check_nans(context=context)\n   if ans:\n    return ans\n    \n   if self._isinfinity() and self._sign == 0:\n    return Decimal(self)\n    \n  if not self:\n  \n   ans = _dec_from_triple(self._sign, '0', self._exp // 2)\n   return ans._fix(context)\n   \n  if self._sign == 1:\n   return context._raise_error(InvalidOperation, 'sqrt(-x), x > 0')\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n  prec = context.prec+1\n  \n  \n  \n  \n  \n  op = _WorkRep(self)\n  e = op.exp >> 1\n  if op.exp & 1:\n   c = op.int * 10\n   l = (len(self._int) >> 1) + 1\n  else:\n   c = op.int\n   l = len(self._int)+1 >> 1\n   \n   \n  shift = prec-l\n  if shift >= 0:\n   c *= 100**shift\n   exact = True\n  else:\n   c, remainder = divmod(c, 100**-shift)\n   exact = not remainder\n  e -= shift\n  \n  \n  n = 10**prec\n  while True:\n   q = c//n\n   if n <= q:\n    break\n   else:\n    n = n + q >> 1\n  exact = exact and n*n == c\n  \n  if exact:\n  \n   if shift >= 0:\n   \n    n //= 10**shift\n   else:\n    n *= 10**-shift\n   e += shift\n  else:\n  \n   if n % 5 == 0:\n    n += 1\n    \n  ans = _dec_from_triple(0, str(n), e)\n  \n  \n  context = context._shallow_copy()\n  rounding = context._set_rounding(ROUND_HALF_EVEN)\n  ans = ans._fix(context)\n  context.rounding = rounding\n  \n  return ans\n  \n def max(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit=True)\n  \n  if context is None:\n   context = getcontext()\n   \n  if self._is_special or other._is_special:\n  \n  \n   sn = self._isnan()\n   on = other._isnan()\n   if sn or on:\n    if on == 1 and sn == 0:\n     return self._fix(context)\n    if sn == 1 and on == 0:\n     return other._fix(context)\n    return self._check_nans(other, context)\n    \n  c = self._cmp(other)\n  if c == 0:\n  \n  \n  \n  \n  \n  \n  \n  \n   c = self.compare_total(other)\n   \n  if c == -1:\n   ans = other\n  else:\n   ans = self\n   \n  return ans._fix(context)\n  \n def min(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit=True)\n  \n  if context is None:\n   context = getcontext()\n   \n  if self._is_special or other._is_special:\n  \n  \n   sn = self._isnan()\n   on = other._isnan()\n   if sn or on:\n    if on == 1 and sn == 0:\n     return self._fix(context)\n    if sn == 1 and on == 0:\n     return other._fix(context)\n    return self._check_nans(other, context)\n    \n  c = self._cmp(other)\n  if c == 0:\n   c = self.compare_total(other)\n   \n  if c == -1:\n   ans = self\n  else:\n   ans = other\n   \n  return ans._fix(context)\n  \n def _isinteger(self):\n  \"\"\n  if self._is_special:\n   return False\n  if self._exp >= 0:\n   return True\n  rest = self._int[self._exp:]\n  return rest == '0'*len(rest)\n  \n def _iseven(self):\n  \"\"\n  if not self or self._exp > 0:\n   return True\n  return self._int[-1+self._exp] in '02468'\n  \n def adjusted(self):\n  \"\"\n  try:\n   return self._exp + len(self._int) - 1\n   \n  except TypeError:\n   return 0\n   \n def canonical(self):\n  \"\"\n  return self\n  \n def compare_signal(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit = True)\n  ans = self._compare_check_nans(other, context)\n  if ans:\n   return ans\n  return self.compare(other, context=context)\n  \n def compare_total(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit=True)\n  \n  \n  if self._sign and not other._sign:\n   return _NegativeOne\n  if not self._sign and other._sign:\n   return _One\n  sign = self._sign\n  \n  \n  self_nan = self._isnan()\n  other_nan = other._isnan()\n  if self_nan or other_nan:\n   if self_nan == other_nan:\n   \n    self_key = len(self._int), self._int\n    other_key = len(other._int), other._int\n    if self_key < other_key:\n     if sign:\n      return _One\n     else:\n      return _NegativeOne\n    if self_key > other_key:\n     if sign:\n      return _NegativeOne\n     else:\n      return _One\n    return _Zero\n    \n   if sign:\n    if self_nan == 1:\n     return _NegativeOne\n    if other_nan == 1:\n     return _One\n    if self_nan == 2:\n     return _NegativeOne\n    if other_nan == 2:\n     return _One\n   else:\n    if self_nan == 1:\n     return _One\n    if other_nan == 1:\n     return _NegativeOne\n    if self_nan == 2:\n     return _One\n    if other_nan == 2:\n     return _NegativeOne\n     \n  if self < other:\n   return _NegativeOne\n  if self > other:\n   return _One\n   \n  if self._exp < other._exp:\n   if sign:\n    return _One\n   else:\n    return _NegativeOne\n  if self._exp > other._exp:\n   if sign:\n    return _NegativeOne\n   else:\n    return _One\n  return _Zero\n  \n  \n def compare_total_mag(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit=True)\n  \n  s = self.copy_abs()\n  o = other.copy_abs()\n  return s.compare_total(o)\n  \n def copy_abs(self):\n  \"\"\n  return _dec_from_triple(0, self._int, self._exp, self._is_special)\n  \n def copy_negate(self):\n  \"\"\n  if self._sign:\n   return _dec_from_triple(0, self._int, self._exp, self._is_special)\n  else:\n   return _dec_from_triple(1, self._int, self._exp, self._is_special)\n   \n def copy_sign(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit=True)\n  return _dec_from_triple(other._sign, self._int,\n  self._exp, self._is_special)\n  \n def exp(self, context=None):\n  \"\"\n  \n  if context is None:\n   context = getcontext()\n   \n   \n  ans = self._check_nans(context=context)\n  if ans:\n   return ans\n   \n   \n  if self._isinfinity() == -1:\n   return _Zero\n   \n   \n  if not self:\n   return _One\n   \n   \n  if self._isinfinity() == 1:\n   return Decimal(self)\n   \n   \n   \n   \n   \n  p = context.prec\n  adj = self.adjusted()\n  \n  \n  \n  \n  \n  \n  if self._sign == 0 and adj > len(str((context.Emax+1)*3)):\n  \n   ans = _dec_from_triple(0, '1', context.Emax+1)\n  elif self._sign == 1 and adj > len(str((-context.Etiny()+1)*3)):\n  \n   ans = _dec_from_triple(0, '1', context.Etiny()-1)\n  elif self._sign == 0 and adj < -p:\n  \n   ans = _dec_from_triple(0, '1' + '0'*(p-1) + '1', -p)\n  elif self._sign == 1 and adj < -p-1:\n  \n   ans = _dec_from_triple(0, '9'*(p+1), -p-1)\n   \n  else:\n   op = _WorkRep(self)\n   c, e = op.int, op.exp\n   if op.sign == 1:\n    c = -c\n    \n    \n    \n    \n   extra = 3\n   while True:\n    coeff, exp = _dexp(c, e, p+extra)\n    if coeff % (5*10**(len(str(coeff))-p-1)):\n     break\n    extra += 3\n    \n   ans = _dec_from_triple(0, str(coeff), exp)\n   \n   \n   \n  context = context._shallow_copy()\n  rounding = context._set_rounding(ROUND_HALF_EVEN)\n  ans = ans._fix(context)\n  context.rounding = rounding\n  \n  return ans\n  \n def is_canonical(self):\n  \"\"\n  return True\n  \n def is_finite(self):\n  \"\"\n  return not self._is_special\n  \n def is_infinite(self):\n  \"\"\n  return self._exp == 'F'\n  \n def is_nan(self):\n  \"\"\n  return self._exp in ('n', 'N')\n  \n def is_normal(self, context=None):\n  \"\"\n  if self._is_special or not self:\n   return False\n  if context is None:\n   context = getcontext()\n  return context.Emin <= self.adjusted()\n  \n def is_qnan(self):\n  \"\"\n  return self._exp == 'n'\n  \n def is_signed(self):\n  \"\"\n  return self._sign == 1\n  \n def is_snan(self):\n  \"\"\n  return self._exp == 'N'\n  \n def is_subnormal(self, context=None):\n  \"\"\n  if self._is_special or not self:\n   return False\n  if context is None:\n   context = getcontext()\n  return self.adjusted() < context.Emin\n  \n def is_zero(self):\n  \"\"\n  return not self._is_special and self._int == '0'\n  \n def _ln_exp_bound(self):\n  \"\"\n  \n  \n  adj = self._exp + len(self._int) - 1\n  if adj >= 1:\n  \n   return len(str(adj*23//10)) - 1\n  if adj <= -2:\n  \n   return len(str((-1-adj)*23//10)) - 1\n  op = _WorkRep(self)\n  c, e = op.int, op.exp\n  if adj == 0:\n  \n   num = str(c-10**-e)\n   den = str(c)\n   return len(num) - len(den) - (num < den)\n   \n  return e + len(str(10**-e - c)) - 1\n  \n  \n def ln(self, context=None):\n  \"\"\n  \n  if context is None:\n   context = getcontext()\n   \n   \n  ans = self._check_nans(context=context)\n  if ans:\n   return ans\n   \n   \n  if not self:\n   return _NegativeInfinity\n   \n   \n  if self._isinfinity() == 1:\n   return _Infinity\n   \n   \n  if self == _One:\n   return _Zero\n   \n   \n  if self._sign == 1:\n   return context._raise_error(InvalidOperation,\n   'ln of a negative value')\n   \n   \n  op = _WorkRep(self)\n  c, e = op.int, op.exp\n  p = context.prec\n  \n  \n  \n  places = p - self._ln_exp_bound() + 2 \n  while True:\n   coeff = _dlog(c, e, places)\n   \n   if coeff % (5*10**(len(str(abs(coeff)))-p-1)):\n    break\n   places += 3\n  ans = _dec_from_triple(int(coeff<0), str(abs(coeff)), -places)\n  \n  context = context._shallow_copy()\n  rounding = context._set_rounding(ROUND_HALF_EVEN)\n  ans = ans._fix(context)\n  context.rounding = rounding\n  return ans\n  \n def _log10_exp_bound(self):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  adj = self._exp + len(self._int) - 1\n  if adj >= 1:\n  \n   return len(str(adj))-1\n  if adj <= -2:\n  \n   return len(str(-1-adj))-1\n  op = _WorkRep(self)\n  c, e = op.int, op.exp\n  if adj == 0:\n  \n   num = str(c-10**-e)\n   den = str(231*c)\n   return len(num) - len(den) - (num < den) + 2\n   \n  num = str(10**-e-c)\n  return len(num) + e - (num < \"231\") - 1\n  \n def log10(self, context=None):\n  \"\"\n  \n  if context is None:\n   context = getcontext()\n   \n   \n  ans = self._check_nans(context=context)\n  if ans:\n   return ans\n   \n   \n  if not self:\n   return _NegativeInfinity\n   \n   \n  if self._isinfinity() == 1:\n   return _Infinity\n   \n   \n  if self._sign == 1:\n   return context._raise_error(InvalidOperation,\n   'log10 of a negative value')\n   \n   \n  if self._int[0] == '1' and self._int[1:] == '0'*(len(self._int) - 1):\n  \n   ans = Decimal(self._exp + len(self._int) - 1)\n  else:\n  \n   op = _WorkRep(self)\n   c, e = op.int, op.exp\n   p = context.prec\n   \n   \n   \n   places = p-self._log10_exp_bound()+2\n   while True:\n    coeff = _dlog10(c, e, places)\n    \n    if coeff % (5*10**(len(str(abs(coeff)))-p-1)):\n     break\n    places += 3\n   ans = _dec_from_triple(int(coeff<0), str(abs(coeff)), -places)\n   \n  context = context._shallow_copy()\n  rounding = context._set_rounding(ROUND_HALF_EVEN)\n  ans = ans._fix(context)\n  context.rounding = rounding\n  return ans\n  \n def logb(self, context=None):\n  \"\"\n  \n  ans = self._check_nans(context=context)\n  if ans:\n   return ans\n   \n  if context is None:\n   context = getcontext()\n   \n   \n  if self._isinfinity():\n   return _Infinity\n   \n   \n  if not self:\n   return context._raise_error(DivisionByZero, 'logb(0)', 1)\n   \n   \n   \n   \n  ans = Decimal(self.adjusted())\n  return ans._fix(context)\n  \n def _islogical(self):\n  \"\"\n  if self._sign != 0 or self._exp != 0:\n   return False\n  for dig in self._int:\n   if dig not in '01':\n    return False\n  return True\n  \n def _fill_logical(self, context, opa, opb):\n  dif = context.prec - len(opa)\n  if dif > 0:\n   opa = '0'*dif + opa\n  elif dif < 0:\n   opa = opa[-context.prec:]\n  dif = context.prec - len(opb)\n  if dif > 0:\n   opb = '0'*dif + opb\n  elif dif < 0:\n   opb = opb[-context.prec:]\n  return opa, opb\n  \n def logical_and(self, other, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  other = _convert_other(other, raiseit=True)\n  \n  if not self._islogical() or not other._islogical():\n   return context._raise_error(InvalidOperation)\n   \n   \n  (opa, opb) = self._fill_logical(context, self._int, other._int)\n  \n  \n  result = \"\".join([str(int(a)&int(b)) for a,b in zip(opa,opb)])\n  return _dec_from_triple(0, result.lstrip('0') or '0', 0)\n  \n def logical_invert(self, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n  return self.logical_xor(_dec_from_triple(0,'1'*context.prec,0),\n  context)\n  \n def logical_or(self, other, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  other = _convert_other(other, raiseit=True)\n  \n  if not self._islogical() or not other._islogical():\n   return context._raise_error(InvalidOperation)\n   \n   \n  (opa, opb) = self._fill_logical(context, self._int, other._int)\n  \n  \n  result = \"\".join([str(int(a)|int(b)) for a,b in zip(opa,opb)])\n  return _dec_from_triple(0, result.lstrip('0') or '0', 0)\n  \n def logical_xor(self, other, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  other = _convert_other(other, raiseit=True)\n  \n  if not self._islogical() or not other._islogical():\n   return context._raise_error(InvalidOperation)\n   \n   \n  (opa, opb) = self._fill_logical(context, self._int, other._int)\n  \n  \n  result = \"\".join([str(int(a)^int(b)) for a,b in zip(opa,opb)])\n  return _dec_from_triple(0, result.lstrip('0') or '0', 0)\n  \n def max_mag(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit=True)\n  \n  if context is None:\n   context = getcontext()\n   \n  if self._is_special or other._is_special:\n  \n  \n   sn = self._isnan()\n   on = other._isnan()\n   if sn or on:\n    if on == 1 and sn == 0:\n     return self._fix(context)\n    if sn == 1 and on == 0:\n     return other._fix(context)\n    return self._check_nans(other, context)\n    \n  c = self.copy_abs()._cmp(other.copy_abs())\n  if c == 0:\n   c = self.compare_total(other)\n   \n  if c == -1:\n   ans = other\n  else:\n   ans = self\n   \n  return ans._fix(context)\n  \n def min_mag(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit=True)\n  \n  if context is None:\n   context = getcontext()\n   \n  if self._is_special or other._is_special:\n  \n  \n   sn = self._isnan()\n   on = other._isnan()\n   if sn or on:\n    if on == 1 and sn == 0:\n     return self._fix(context)\n    if sn == 1 and on == 0:\n     return other._fix(context)\n    return self._check_nans(other, context)\n    \n  c = self.copy_abs()._cmp(other.copy_abs())\n  if c == 0:\n   c = self.compare_total(other)\n   \n  if c == -1:\n   ans = self\n  else:\n   ans = other\n   \n  return ans._fix(context)\n  \n def next_minus(self, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  ans = self._check_nans(context=context)\n  if ans:\n   return ans\n   \n  if self._isinfinity() == -1:\n   return _NegativeInfinity\n  if self._isinfinity() == 1:\n   return _dec_from_triple(0, '9'*context.prec, context.Etop())\n   \n  context = context.copy()\n  context._set_rounding(ROUND_FLOOR)\n  context._ignore_all_flags()\n  new_self = self._fix(context)\n  if new_self != self:\n   return new_self\n  return self.__sub__(_dec_from_triple(0, '1', context.Etiny()-1),\n  context)\n  \n def next_plus(self, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  ans = self._check_nans(context=context)\n  if ans:\n   return ans\n   \n  if self._isinfinity() == 1:\n   return _Infinity\n  if self._isinfinity() == -1:\n   return _dec_from_triple(1, '9'*context.prec, context.Etop())\n   \n  context = context.copy()\n  context._set_rounding(ROUND_CEILING)\n  context._ignore_all_flags()\n  new_self = self._fix(context)\n  if new_self != self:\n   return new_self\n  return self.__add__(_dec_from_triple(0, '1', context.Etiny()-1),\n  context)\n  \n def next_toward(self, other, context=None):\n  \"\"\n  other = _convert_other(other, raiseit=True)\n  \n  if context is None:\n   context = getcontext()\n   \n  ans = self._check_nans(other, context)\n  if ans:\n   return ans\n   \n  comparison = self._cmp(other)\n  if comparison == 0:\n   return self.copy_sign(other)\n   \n  if comparison == -1:\n   ans = self.next_plus(context)\n  else: \n   ans = self.next_minus(context)\n   \n   \n  if ans._isinfinity():\n   context._raise_error(Overflow,\n   'Infinite result from next_toward',\n   ans._sign)\n   context._raise_error(Inexact)\n   context._raise_error(Rounded)\n  elif ans.adjusted() < context.Emin:\n   context._raise_error(Underflow)\n   context._raise_error(Subnormal)\n   context._raise_error(Inexact)\n   context._raise_error(Rounded)\n   \n   \n   if not ans:\n    context._raise_error(Clamped)\n    \n  return ans\n  \n def number_class(self, context=None):\n  \"\"\n  if self.is_snan():\n   return \"sNaN\"\n  if self.is_qnan():\n   return \"NaN\"\n  inf = self._isinfinity()\n  if inf == 1:\n   return \"+Infinity\"\n  if inf == -1:\n   return \"-Infinity\"\n  if self.is_zero():\n   if self._sign:\n    return \"-Zero\"\n   else:\n    return \"+Zero\"\n  if context is None:\n   context = getcontext()\n  if self.is_subnormal(context=context):\n   if self._sign:\n    return \"-Subnormal\"\n   else:\n    return \"+Subnormal\"\n    \n  if self._sign:\n   return \"-Normal\"\n  else:\n   return \"+Normal\"\n   \n def radix(self):\n  \"\"\n  return Decimal(10)\n  \n def rotate(self, other, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  other = _convert_other(other, raiseit=True)\n  \n  ans = self._check_nans(other, context)\n  if ans:\n   return ans\n   \n  if other._exp != 0:\n   return context._raise_error(InvalidOperation)\n  if not (-context.prec <= int(other) <= context.prec):\n   return context._raise_error(InvalidOperation)\n   \n  if self._isinfinity():\n   return Decimal(self)\n   \n   \n  torot = int(other)\n  rotdig = self._int\n  topad = context.prec - len(rotdig)\n  if topad > 0:\n   rotdig = '0'*topad + rotdig\n  elif topad < 0:\n   rotdig = rotdig[-topad:]\n   \n   \n  rotated = rotdig[torot:] + rotdig[:torot]\n  return _dec_from_triple(self._sign,\n  rotated.lstrip('0') or '0', self._exp)\n  \n def scaleb(self, other, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  other = _convert_other(other, raiseit=True)\n  \n  ans = self._check_nans(other, context)\n  if ans:\n   return ans\n   \n  if other._exp != 0:\n   return context._raise_error(InvalidOperation)\n  liminf = -2 * (context.Emax + context.prec)\n  limsup = 2 * (context.Emax + context.prec)\n  if not (liminf <= int(other) <= limsup):\n   return context._raise_error(InvalidOperation)\n   \n  if self._isinfinity():\n   return Decimal(self)\n   \n  d = _dec_from_triple(self._sign, self._int, self._exp + int(other))\n  d = d._fix(context)\n  return d\n  \n def shift(self, other, context=None):\n  \"\"\n  if context is None:\n   context = getcontext()\n   \n  other = _convert_other(other, raiseit=True)\n  \n  ans = self._check_nans(other, context)\n  if ans:\n   return ans\n   \n  if other._exp != 0:\n   return context._raise_error(InvalidOperation)\n  if not (-context.prec <= int(other) <= context.prec):\n   return context._raise_error(InvalidOperation)\n   \n  if self._isinfinity():\n   return Decimal(self)\n   \n   \n  torot = int(other)\n  rotdig = self._int\n  topad = context.prec - len(rotdig)\n  if topad > 0:\n   rotdig = '0'*topad + rotdig\n  elif topad < 0:\n   rotdig = rotdig[-topad:]\n   \n   \n  if torot < 0:\n   shifted = rotdig[:torot]\n  else:\n   shifted = rotdig + '0'*torot\n   shifted = shifted[-context.prec:]\n   \n  return _dec_from_triple(self._sign,\n  shifted.lstrip('0') or '0', self._exp)\n  \n  \n def __reduce__(self):\n  return (self.__class__, (str(self),))\n  \n def __copy__(self):\n  if type(self) is Decimal:\n   return self \n  return self.__class__(str(self))\n  \n def __deepcopy__(self, memo):\n  if type(self) is Decimal:\n   return self \n  return self.__class__(str(self))\n  \n  \n  \n def __format__(self, specifier, context=None, _localeconv=None):\n  \"\"\n  \n  \n  \n  \n  \n  \n  if context is None:\n   context = getcontext()\n   \n  spec = _parse_format_specifier(specifier, _localeconv=_localeconv)\n  \n  \n  if self._is_special:\n   sign = _format_sign(self._sign, spec)\n   body = str(self.copy_abs())\n   return _format_align(sign, body, spec)\n   \n   \n  if spec['type'] is None:\n   spec['type'] = ['g', 'G'][context.capitals]\n   \n   \n  if spec['type'] == '%':\n   self = _dec_from_triple(self._sign, self._int, self._exp+2)\n   \n   \n  rounding = context.rounding\n  precision = spec['precision']\n  if precision is not None:\n   if spec['type'] in 'eE':\n    self = self._round(precision+1, rounding)\n   elif spec['type'] in 'fF%':\n    self = self._rescale(-precision, rounding)\n   elif spec['type'] in 'gG' and len(self._int) > precision:\n    self = self._round(precision, rounding)\n    \n    \n  if not self and self._exp > 0 and spec['type'] in 'fF%':\n   self = self._rescale(0, rounding)\n   \n   \n  leftdigits = self._exp + len(self._int)\n  if spec['type'] in 'eE':\n   if not self and precision is not None:\n    dotplace = 1 - precision\n   else:\n    dotplace = 1\n  elif spec['type'] in 'fF%':\n   dotplace = leftdigits\n  elif spec['type'] in 'gG':\n   if self._exp <= 0 and leftdigits > -6:\n    dotplace = leftdigits\n   else:\n    dotplace = 1\n    \n    \n  if dotplace < 0:\n   intpart = '0'\n   fracpart = '0'*(-dotplace) + self._int\n  elif dotplace > len(self._int):\n   intpart = self._int + '0'*(dotplace-len(self._int))\n   fracpart = ''\n  else:\n   intpart = self._int[:dotplace] or '0'\n   fracpart = self._int[dotplace:]\n  exp = leftdigits-dotplace\n  \n  \n  \n  return _format_number(self._sign, intpart, fracpart, exp, spec)\n  \ndef _dec_from_triple(sign, coefficient, exponent, special=False):\n \"\"\n \n self = object.__new__(Decimal)\n self._sign = sign\n self._int = coefficient\n self._exp = exponent\n self._is_special = special\n \n return self\n \n \n \n \n_numbers.Number.register(Decimal)\n\n\n\n\nclass _ContextManager(object):\n \"\"\n def __init__(self, new_context):\n  self.new_context = new_context.copy()\n def __enter__(self):\n  self.saved_context = getcontext()\n  setcontext(self.new_context)\n  return self.new_context\n def __exit__(self, t, v, tb):\n  setcontext(self.saved_context)\n  \nclass Context(object):\n \"\"\n \n def __init__(self, prec=None, rounding=None, Emin=None, Emax=None,\n capitals=None, clamp=None, flags=None, traps=None,\n _ignored_flags=None):\n \n \n  try:\n   dc = DefaultContext\n  except NameError:\n   pass\n   \n  self.prec = prec if prec is not None else dc.prec\n  self.rounding = rounding if rounding is not None else dc.rounding\n  self.Emin = Emin if Emin is not None else dc.Emin\n  self.Emax = Emax if Emax is not None else dc.Emax\n  self.capitals = capitals if capitals is not None else dc.capitals\n  self.clamp = clamp if clamp is not None else dc.clamp\n  \n  if _ignored_flags is None:\n   self._ignored_flags = []\n  else:\n   self._ignored_flags = _ignored_flags\n   \n  if traps is None:\n   self.traps = dc.traps.copy()\n  elif not isinstance(traps, dict):\n   self.traps = dict((s, int(s in traps)) for s in _signals + traps)\n  else:\n   self.traps = traps\n   \n  if flags is None:\n   self.flags = dict.fromkeys(_signals, 0)\n  elif not isinstance(flags, dict):\n   self.flags = dict((s, int(s in flags)) for s in _signals + flags)\n  else:\n   self.flags = flags\n   \n def _set_integer_check(self, name, value, vmin, vmax):\n  if not isinstance(value, int):\n   raise TypeError(\"%s must be an integer\" % name)\n  if vmin == '-inf':\n   if value > vmax:\n    raise ValueError(\"%s must be in [%s, %d]. got: %s\" % (name, vmin, vmax, value))\n  elif vmax == 'inf':\n   if value < vmin:\n    raise ValueError(\"%s must be in [%d, %s]. got: %s\" % (name, vmin, vmax, value))\n  else:\n   if value < vmin or value > vmax:\n    raise ValueError(\"%s must be in [%d, %d]. got %s\" % (name, vmin, vmax, value))\n  return object.__setattr__(self, name, value)\n  \n def _set_signal_dict(self, name, d):\n  if not isinstance(d, dict):\n   raise TypeError(\"%s must be a signal dict\" % d)\n  for key in d:\n   if not key in _signals:\n    raise KeyError(\"%s is not a valid signal dict\" % d)\n  for key in _signals:\n   if not key in d:\n    raise KeyError(\"%s is not a valid signal dict\" % d)\n  return object.__setattr__(self, name, d)\n  \n def __setattr__(self, name, value):\n  if name == 'prec':\n   return self._set_integer_check(name, value, 1, 'inf')\n  elif name == 'Emin':\n   return self._set_integer_check(name, value, '-inf', 0)\n  elif name == 'Emax':\n   return self._set_integer_check(name, value, 0, 'inf')\n  elif name == 'capitals':\n   return self._set_integer_check(name, value, 0, 1)\n  elif name == 'clamp':\n   return self._set_integer_check(name, value, 0, 1)\n  elif name == 'rounding':\n   if not value in _rounding_modes:\n   \n   \n    raise TypeError(\"%s: invalid rounding mode\" % value)\n   return object.__setattr__(self, name, value)\n  elif name == 'flags' or name == 'traps':\n   return self._set_signal_dict(name, value)\n  elif name == '_ignored_flags':\n   return object.__setattr__(self, name, value)\n  else:\n   raise AttributeError(\n   \"'decimal.Context' object has no attribute '%s'\" % name)\n   \n def __delattr__(self, name):\n  raise AttributeError(\"%s cannot be deleted\" % name)\n  \n  \n def __reduce__(self):\n  flags = [sig for sig, v in self.flags.items() if v]\n  traps = [sig for sig, v in self.traps.items() if v]\n  return (self.__class__,\n  (self.prec, self.rounding, self.Emin, self.Emax,\n  self.capitals, self.clamp, flags, traps))\n  \n def __repr__(self):\n  \"\"\n  s = []\n  s.append('Context(prec=%(prec)d, rounding=%(rounding)s, '\n  'Emin=%(Emin)d, Emax=%(Emax)d, capitals=%(capitals)d, '\n  'clamp=%(clamp)d'\n  % vars(self))\n  names = [f.__name__ for f, v in self.flags.items() if v]\n  s.append('flags=[' + ', '.join(names) + ']')\n  names = [t.__name__ for t, v in self.traps.items() if v]\n  s.append('traps=[' + ', '.join(names) + ']')\n  return ', '.join(s) + ')'\n  \n def clear_flags(self):\n  \"\"\n  for flag in self.flags:\n   self.flags[flag] = 0\n   \n def clear_traps(self):\n  \"\"\n  for flag in self.traps:\n   self.traps[flag] = 0\n   \n def _shallow_copy(self):\n  \"\"\n  nc = Context(self.prec, self.rounding, self.Emin, self.Emax,\n  self.capitals, self.clamp, self.flags, self.traps,\n  self._ignored_flags)\n  return nc\n  \n def copy(self):\n  \"\"\n  nc = Context(self.prec, self.rounding, self.Emin, self.Emax,\n  self.capitals, self.clamp,\n  self.flags.copy(), self.traps.copy(),\n  self._ignored_flags)\n  return nc\n __copy__ = copy\n \n def _raise_error(self, condition, explanation = None, *args):\n  \"\"\n  error = _condition_map.get(condition, condition)\n  if error in self._ignored_flags:\n  \n   return error().handle(self, *args)\n   \n  self.flags[error] = 1\n  if not self.traps[error]:\n  \n   return condition().handle(self, *args)\n   \n   \n   \n  raise error(explanation)\n  \n def _ignore_all_flags(self):\n  \"\"\n  return self._ignore_flags(*_signals)\n  \n def _ignore_flags(self, *flags):\n  \"\"\n  \n  \n  self._ignored_flags = (self._ignored_flags + list(flags))\n  return list(flags)\n  \n def _regard_flags(self, *flags):\n  \"\"\n  if flags and isinstance(flags[0], (tuple,list)):\n   flags = flags[0]\n  for flag in flags:\n   self._ignored_flags.remove(flag)\n   \n   \n __hash__ = None\n \n def Etiny(self):\n  \"\"\n  return int(self.Emin - self.prec + 1)\n  \n def Etop(self):\n  \"\"\n  return int(self.Emax - self.prec + 1)\n  \n def _set_rounding(self, type):\n  \"\"\n  rounding = self.rounding\n  self.rounding= type\n  return rounding\n  \n def create_decimal(self, num='0'):\n  \"\"\n  \n  if isinstance(num, str) and num != num.strip():\n   return self._raise_error(ConversionSyntax,\n   \"no trailing or leading whitespace is \"\n   \"permitted.\")\n   \n  d = Decimal(num, context=self)\n  if d._isnan() and len(d._int) > self.prec - self.clamp:\n   return self._raise_error(ConversionSyntax,\n   \"diagnostic info too long in NaN\")\n  return d._fix(self)\n  \n def create_decimal_from_float(self, f):\n  \"\"\n  d = Decimal.from_float(f) \n  return d._fix(self) \n  \n  \n def abs(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.__abs__(context=self)\n  \n def add(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  r = a.__add__(b, context=self)\n  if r is NotImplemented:\n   raise TypeError(\"Unable to convert %s to Decimal\" % b)\n  else:\n   return r\n   \n def _apply(self, a):\n  return str(a._fix(self))\n  \n def canonical(self, a):\n  \"\"\n  if not isinstance(a, Decimal):\n   raise TypeError(\"canonical requires a Decimal as an argument.\")\n  return a.canonical()\n  \n def compare(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.compare(b, context=self)\n  \n def compare_signal(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.compare_signal(b, context=self)\n  \n def compare_total(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.compare_total(b)\n  \n def compare_total_mag(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.compare_total_mag(b)\n  \n def copy_abs(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.copy_abs()\n  \n def copy_decimal(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return Decimal(a)\n  \n def copy_negate(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.copy_negate()\n  \n def copy_sign(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.copy_sign(b)\n  \n def divide(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  r = a.__truediv__(b, context=self)\n  if r is NotImplemented:\n   raise TypeError(\"Unable to convert %s to Decimal\" % b)\n  else:\n   return r\n   \n def divide_int(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  r = a.__floordiv__(b, context=self)\n  if r is NotImplemented:\n   raise TypeError(\"Unable to convert %s to Decimal\" % b)\n  else:\n   return r\n   \n def divmod(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  r = a.__divmod__(b, context=self)\n  if r is NotImplemented:\n   raise TypeError(\"Unable to convert %s to Decimal\" % b)\n  else:\n   return r\n   \n def exp(self, a):\n  \"\"\n  a =_convert_other(a, raiseit=True)\n  return a.exp(context=self)\n  \n def fma(self, a, b, c):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.fma(b, c, context=self)\n  \n def is_canonical(self, a):\n  \"\"\n  if not isinstance(a, Decimal):\n   raise TypeError(\"is_canonical requires a Decimal as an argument.\")\n  return a.is_canonical()\n  \n def is_finite(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.is_finite()\n  \n def is_infinite(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.is_infinite()\n  \n def is_nan(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.is_nan()\n  \n def is_normal(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.is_normal(context=self)\n  \n def is_qnan(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.is_qnan()\n  \n def is_signed(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.is_signed()\n  \n def is_snan(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.is_snan()\n  \n def is_subnormal(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.is_subnormal(context=self)\n  \n def is_zero(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.is_zero()\n  \n def ln(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.ln(context=self)\n  \n def log10(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.log10(context=self)\n  \n def logb(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.logb(context=self)\n  \n def logical_and(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.logical_and(b, context=self)\n  \n def logical_invert(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.logical_invert(context=self)\n  \n def logical_or(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.logical_or(b, context=self)\n  \n def logical_xor(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.logical_xor(b, context=self)\n  \n def max(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.max(b, context=self)\n  \n def max_mag(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.max_mag(b, context=self)\n  \n def min(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.min(b, context=self)\n  \n def min_mag(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.min_mag(b, context=self)\n  \n def minus(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.__neg__(context=self)\n  \n def multiply(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  r = a.__mul__(b, context=self)\n  if r is NotImplemented:\n   raise TypeError(\"Unable to convert %s to Decimal\" % b)\n  else:\n   return r\n   \n def next_minus(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.next_minus(context=self)\n  \n def next_plus(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.next_plus(context=self)\n  \n def next_toward(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.next_toward(b, context=self)\n  \n def normalize(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.normalize(context=self)\n  \n def number_class(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.number_class(context=self)\n  \n def plus(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.__pos__(context=self)\n  \n def power(self, a, b, modulo=None):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  r = a.__pow__(b, modulo, context=self)\n  if r is NotImplemented:\n   raise TypeError(\"Unable to convert %s to Decimal\" % b)\n  else:\n   return r\n   \n def quantize(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.quantize(b, context=self)\n  \n def radix(self):\n  \"\"\n  return Decimal(10)\n  \n def remainder(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  r = a.__mod__(b, context=self)\n  if r is NotImplemented:\n   raise TypeError(\"Unable to convert %s to Decimal\" % b)\n  else:\n   return r\n   \n def remainder_near(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.remainder_near(b, context=self)\n  \n def rotate(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.rotate(b, context=self)\n  \n def same_quantum(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.same_quantum(b)\n  \n def scaleb (self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.scaleb(b, context=self)\n  \n def shift(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.shift(b, context=self)\n  \n def sqrt(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.sqrt(context=self)\n  \n def subtract(self, a, b):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  r = a.__sub__(b, context=self)\n  if r is NotImplemented:\n   raise TypeError(\"Unable to convert %s to Decimal\" % b)\n  else:\n   return r\n   \n def to_eng_string(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.to_eng_string(context=self)\n  \n def to_sci_string(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.__str__(context=self)\n  \n def to_integral_exact(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.to_integral_exact(context=self)\n  \n def to_integral_value(self, a):\n  \"\"\n  a = _convert_other(a, raiseit=True)\n  return a.to_integral_value(context=self)\n  \n  \n to_integral = to_integral_value\n \nclass _WorkRep(object):\n __slots__ = ('sign','int','exp')\n \n \n \n \n def __init__(self, value=None):\n  if value is None:\n   self.sign = None\n   self.int = 0\n   self.exp = None\n  elif isinstance(value, Decimal):\n   self.sign = value._sign\n   self.int = int(value._int)\n   self.exp = value._exp\n  else:\n  \n   self.sign = value[0]\n   self.int = value[1]\n   self.exp = value[2]\n   \n def __repr__(self):\n  return \"(%r, %r, %r)\" % (self.sign, self.int, self.exp)\n  \n __str__ = __repr__\n \n \n \ndef _normalize(op1, op2, prec = 0):\n \"\"\n if op1.exp < op2.exp:\n  tmp = op2\n  other = op1\n else:\n  tmp = op1\n  other = op2\n  \n  \n  \n  \n  \n  \n tmp_len = len(str(tmp.int))\n other_len = len(str(other.int))\n exp = tmp.exp + min(-1, tmp_len - prec - 2)\n if other_len + other.exp - 1 < exp:\n  other.int = 1\n  other.exp = exp\n  \n tmp.int *= 10 ** (tmp.exp - other.exp)\n tmp.exp = other.exp\n return op1, op2\n \n \n \n_nbits = int.bit_length\n\ndef _decimal_lshift_exact(n, e):\n \"\"\n if n == 0:\n  return 0\n elif e >= 0:\n  return n * 10**e\n else:\n \n  str_n = str(abs(n))\n  val_n = len(str_n) - len(str_n.rstrip('0'))\n  return None if val_n < -e else n // 10**-e\n  \ndef _sqrt_nearest(n, a):\n \"\"\n if n <= 0 or a <= 0:\n  raise ValueError(\"Both arguments to _sqrt_nearest should be positive.\")\n  \n b=0\n while a != b:\n  b, a = a, a--n//a>>1\n return a\n \ndef _rshift_nearest(x, shift):\n \"\"\n b, q = 1 << shift, x >> shift\n return q + (2*(x & (b-1)) + (q&1) > b)\n \ndef _div_nearest(a, b):\n \"\"\n q, r = divmod(a, b)\n return q + (2*r + (q&1) > b)\n \ndef _ilog(x, M, L = 8):\n \"\"\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n y = x-M\n \n R = 0\n while (R <= L and abs(y) << L-R >= M or\n R > L and abs(y) >> R-L >= M):\n  y = _div_nearest((M*y) << 1,\n  M + _sqrt_nearest(M*(M+_rshift_nearest(y, R)), M))\n  R += 1\n  \n  \n T = -int(-10*len(str(M))//(3*L))\n yshift = _rshift_nearest(y, R)\n w = _div_nearest(M, T)\n for k in range(T-1, 0, -1):\n  w = _div_nearest(M, k) - _div_nearest(yshift*w, M)\n  \n return _div_nearest(w*y, M)\n \ndef _dlog10(c, e, p):\n \"\"\n \n \n \n p += 2\n \n \n \n \n \n l = len(str(c))\n f = e+l - (e+l >= 1)\n \n if p > 0:\n  M = 10**p\n  k = e+p-f\n  if k >= 0:\n   c *= 10**k\n  else:\n   c = _div_nearest(c, 10**-k)\n   \n  log_d = _ilog(c, M) \n  log_10 = _log10_digits(p) \n  log_d = _div_nearest(log_d*M, log_10)\n  log_tenpower = f*M \n else:\n  log_d = 0 \n  log_tenpower = _div_nearest(f, 10**-p) \n  \n return _div_nearest(log_tenpower+log_d, 100)\n \ndef _dlog(c, e, p):\n \"\"\n \n \n \n p += 2\n \n \n \n \n l = len(str(c))\n f = e+l - (e+l >= 1)\n \n \n if p > 0:\n  k = e+p-f\n  if k >= 0:\n   c *= 10**k\n  else:\n   c = _div_nearest(c, 10**-k) \n   \n   \n  log_d = _ilog(c, 10**p) \n else:\n \n  log_d = 0\n  \n  \n if f:\n  extra = len(str(abs(f)))-1\n  if p + extra >= 0:\n  \n  \n   f_log_ten = _div_nearest(f*_log10_digits(p+extra), 10**extra)\n  else:\n   f_log_ten = 0\n else:\n  f_log_ten = 0\n  \n  \n return _div_nearest(f_log_ten + log_d, 100)\n \nclass _Log10Memoize(object):\n \"\"\n def __init__(self):\n  self.digits = \"23025850929940456840179914546843642076011014886\"\n  \n def getdigits(self, p):\n  \"\"\n  \n  \n  \n  \n  if p < 0:\n   raise ValueError(\"p should be nonnegative\")\n   \n  if p >= len(self.digits):\n  \n  \n   extra = 3\n   while True:\n   \n    M = 10**(p+extra+2)\n    digits = str(_div_nearest(_ilog(10*M, M), 100))\n    if digits[-extra:] != '0'*extra:\n     break\n    extra += 3\n    \n    \n   self.digits = digits.rstrip('0')[:-1]\n  return int(self.digits[:p+1])\n  \n_log10_digits = _Log10Memoize().getdigits\n\ndef _iexp(x, M, L=8):\n \"\"\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n R = _nbits((x<<L)//M)\n \n \n T = -int(-10*len(str(M))//(3*L))\n y = _div_nearest(x, T)\n Mshift = M<<R\n for i in range(T-1, 0, -1):\n  y = _div_nearest(x*(Mshift + y), Mshift * i)\n  \n  \n for k in range(R-1, -1, -1):\n  Mshift = M<<(k+2)\n  y = _div_nearest(y*(y+Mshift), Mshift)\n  \n return M+y\n \ndef _dexp(c, e, p):\n \"\"\n \n \n p += 2\n \n \n extra = max(0, e + len(str(c)) - 1)\n q = p + extra\n \n \n \n shift = e+q\n if shift >= 0:\n  cshift = c*10**shift\n else:\n  cshift = c//10**-shift\n quot, rem = divmod(cshift, _log10_digits(q))\n \n \n rem = _div_nearest(rem, 10**extra)\n \n \n return _div_nearest(_iexp(rem, 10**p), 1000), quot - p + 3\n \ndef _dpower(xc, xe, yc, ye, p):\n \"\"\n \n \n b = len(str(abs(yc))) + ye\n \n \n lxc = _dlog(xc, xe, p+b+1)\n \n \n shift = ye-b\n if shift >= 0:\n  pc = lxc*yc*10**shift\n else:\n  pc = _div_nearest(lxc*yc, 10**-shift)\n  \n if pc == 0:\n \n \n  if ((len(str(xc)) + xe >= 1) == (yc > 0)): \n   coeff, exp = 10**(p-1)+1, 1-p\n  else:\n   coeff, exp = 10**p-1, -p\n else:\n  coeff, exp = _dexp(pc, -(p+1), p+1)\n  coeff = _div_nearest(coeff, 10)\n  exp += 1\n  \n return coeff, exp\n \ndef _log10_lb(c, correction = {\n'1': 100, '2': 70, '3': 53, '4': 40, '5': 31,\n'6': 23, '7': 16, '8': 10, '9': 5}):\n \"\"\n if c <= 0:\n  raise ValueError(\"The argument to _log10_lb should be nonnegative.\")\n str_c = str(c)\n return 100*len(str_c) - correction[str_c[0]]\n \n \n \ndef _convert_other(other, raiseit=False, allow_float=False):\n \"\"\n if isinstance(other, Decimal):\n  return other\n if isinstance(other, int):\n  return Decimal(other)\n if allow_float and isinstance(other, float):\n  return Decimal.from_float(other)\n  \n if raiseit:\n  raise TypeError(\"Unable to convert %s to Decimal\" % other)\n return NotImplemented\n \ndef _convert_for_comparison(self, other, equality_op=False):\n \"\"\n if isinstance(other, Decimal):\n  return self, other\n  \n  \n  \n  \n  \n if isinstance(other, _numbers.Rational):\n  if not self._is_special:\n   self = _dec_from_triple(self._sign,\n   str(int(self._int) * other.denominator),\n   self._exp)\n  return self, Decimal(other.numerator)\n  \n  \n  \n  \n if equality_op and isinstance(other, _numbers.Complex) and other.imag == 0:\n  other = other.real\n if isinstance(other, float):\n  context = getcontext()\n  if equality_op:\n   context.flags[FloatOperation] = 1\n  else:\n   context._raise_error(FloatOperation,\n   \"strict semantics for mixing floats and Decimals are enabled\")\n  return self, Decimal.from_float(other)\n return NotImplemented, NotImplemented\n \n \n \n \n \n \n \nDefaultContext = Context(\nprec=17, rounding=ROUND_HALF_EVEN,\ntraps=[DivisionByZero, Overflow, InvalidOperation],\nflags=[],\nEmax=308,\nEmin=-324,\ncapitals=1,\nclamp=0\n)\n\n\n\n\n\n\nBasicContext = Context(\nprec=9, rounding=ROUND_HALF_UP,\ntraps=[DivisionByZero, Overflow, InvalidOperation, Clamped, Underflow],\nflags=[],\n)\n\nExtendedContext = Context(\nprec=9, rounding=ROUND_HALF_EVEN,\ntraps=[],\nflags=[],\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport re\n_parser = re.compile(r\"\"\"        # A numeric string consists of:\n#    \\s*\n    (?P<sign>[-+])?              # an optional sign, followed by either...\n    (\n        (?=\\d|\\.\\d)              # ...a number (with at least one digit)\n        (?P<int>\\d*)             # having a (possibly empty) integer part\n        (\\.(?P<frac>\\d*))?       # followed by an optional fractional part\n        (E(?P<exp>[-+]?\\d+))?    # followed by an optional exponent, or...\n    |\n        Inf(inity)?              # ...an infinity, or...\n    |\n        (?P<signal>s)?           # ...an (optionally signaling)\n        NaN                      # NaN\n        (?P<diag>\\d*)            # with (possibly empty) diagnostic info.\n    )\n#    \\s*\n    \\Z\n\"\"\", re.VERBOSE | re.IGNORECASE).match\n\n_all_zeros = re.compile('0*$').match\n_exact_half = re.compile('50*$').match\n\n\n\n\n\n\n\n\n\n\n_parse_format_specifier_regex = re.compile(r\"\"\"\\A\n(?:\n   (?P<fill>.)?\n   (?P<align>[<>=^])\n)?\n(?P<sign>[-+ ])?\n(?P<alt>\\#)?\n(?P<zeropad>0)?\n(?P<minimumwidth>(?!0)\\d+)?\n(?P<thousands_sep>,)?\n(?:\\.(?P<precision>0|(?!0)\\d+))?\n(?P<type>[eEfFgGn%])?\n\\Z\n\"\"\", re.VERBOSE|re.DOTALL)\n\ndel re\n\n\n\n\ntry:\n import locale as _locale\nexcept ImportError:\n pass\n \ndef _parse_format_specifier(format_spec, _localeconv=None):\n \"\"\n m = _parse_format_specifier_regex.match(format_spec)\n if m is None:\n  raise ValueError(\"Invalid format specifier: \" + format_spec)\n  \n  \n format_dict = m.groupdict()\n \n \n \n fill = format_dict['fill']\n align = format_dict['align']\n format_dict['zeropad'] = (format_dict['zeropad'] is not None)\n if format_dict['zeropad']:\n  if fill is not None:\n   raise ValueError(\"Fill character conflicts with '0'\"\n   \" in format specifier: \" + format_spec)\n  if align is not None:\n   raise ValueError(\"Alignment conflicts with '0' in \"\n   \"format specifier: \" + format_spec)\n format_dict['fill'] = fill or ' '\n \n \n \n format_dict['align'] = align or '>'\n \n \n if format_dict['sign'] is None:\n  format_dict['sign'] = '-'\n  \n  \n format_dict['minimumwidth'] = int(format_dict['minimumwidth'] or '0')\n if format_dict['precision'] is not None:\n  format_dict['precision'] = int(format_dict['precision'])\n  \n  \n  \n if format_dict['precision'] == 0:\n  if format_dict['type'] is None or format_dict['type'] in 'gGn':\n   format_dict['precision'] = 1\n   \n   \n   \n if format_dict['type'] == 'n':\n \n  format_dict['type'] = 'g'\n  if _localeconv is None:\n   _localeconv = _locale.localeconv()\n  if format_dict['thousands_sep'] is not None:\n   raise ValueError(\"Explicit thousands separator conflicts with \"\n   \"'n' type in format specifier: \" + format_spec)\n  format_dict['thousands_sep'] = _localeconv['thousands_sep']\n  format_dict['grouping'] = _localeconv['grouping']\n  format_dict['decimal_point'] = _localeconv['decimal_point']\n else:\n  if format_dict['thousands_sep'] is None:\n   format_dict['thousands_sep'] = ''\n  format_dict['grouping'] = [3, 0]\n  format_dict['decimal_point'] = '.'\n  \n return format_dict\n \ndef _format_align(sign, body, spec):\n \"\"\n \n minimumwidth = spec['minimumwidth']\n fill = spec['fill']\n padding = fill*(minimumwidth - len(sign) - len(body))\n \n align = spec['align']\n if align == '<':\n  result = sign + body + padding\n elif align == '>':\n  result = padding + sign + body\n elif align == '=':\n  result = sign + padding + body\n elif align == '^':\n  half = len(padding)//2\n  result = padding[:half] + sign + body + padding[half:]\n else:\n  raise ValueError('Unrecognised alignment field')\n  \n return result\n \ndef _group_lengths(grouping):\n \"\"\n \n \n \n \n \n \n \n \n from itertools import chain, repeat\n if not grouping:\n  return []\n elif grouping[-1] == 0 and len(grouping) >= 2:\n  return chain(grouping[:-1], repeat(grouping[-2]))\n elif grouping[-1] == _locale.CHAR_MAX:\n  return grouping[:-1]\n else:\n  raise ValueError('unrecognised format for grouping')\n  \ndef _insert_thousands_sep(digits, spec, min_width=1):\n \"\"\n \n sep = spec['thousands_sep']\n grouping = spec['grouping']\n \n groups = []\n for l in _group_lengths(grouping):\n  if l <= 0:\n   raise ValueError(\"group length should be positive\")\n   \n  l = min(max(len(digits), min_width, 1), l)\n  groups.append('0'*(l - len(digits)) + digits[-l:])\n  digits = digits[:-l]\n  min_width -= l\n  if not digits and min_width <= 0:\n   break\n  min_width -= len(sep)\n else:\n  l = max(len(digits), min_width, 1)\n  groups.append('0'*(l - len(digits)) + digits[-l:])\n return sep.join(reversed(groups))\n \ndef _format_sign(is_negative, spec):\n \"\"\n \n if is_negative:\n  return '-'\n elif spec['sign'] in ' +':\n  return spec['sign']\n else:\n  return ''\n  \ndef _format_number(is_negative, intpart, fracpart, exp, spec):\n \"\"\n \n sign = _format_sign(is_negative, spec)\n \n if fracpart or spec['alt']:\n  fracpart = spec['decimal_point'] + fracpart\n  \n if exp != 0 or spec['type'] in 'eE':\n  echar = {'E': 'E', 'e': 'e', 'G': 'E', 'g': 'e'}[spec['type']]\n  fracpart += \"{0}{1:+}\".format(echar, exp)\n if spec['type'] == '%':\n  fracpart += '%'\n  \n if spec['zeropad']:\n  min_width = spec['minimumwidth'] - len(fracpart) - len(sign)\n else:\n  min_width = 0\n intpart = _insert_thousands_sep(intpart, spec, min_width)\n \n return _format_align(sign, intpart+fracpart, spec)\n \n \n \n \n \n_Infinity = Decimal('Inf')\n_NegativeInfinity = Decimal('-Inf')\n_NaN = Decimal('NaN')\n_Zero = Decimal(0)\n_One = Decimal(1)\n_NegativeOne = Decimal(-1)\n\n\n_SignedInfinity = (_Infinity, _NegativeInfinity)\n\n\n\n_PyHASH_MODULUS = sys.hash_info.modulus\n\n_PyHASH_INF = sys.hash_info.inf\n_PyHASH_NAN = sys.hash_info.nan\n\n\n_PyHASH_10INV = pow(10, _PyHASH_MODULUS - 2, _PyHASH_MODULUS)\ndel sys\n\ntry:\n import _decimal\nexcept ImportError:\n pass\nelse:\n s1 = set(dir())\n s2 = set(dir(_decimal))\n for name in s1 - s2:\n  del globals()[name]\n del s1, s2, name\n from _decimal import *\n \nif __name__ == '__main__':\n import doctest, decimal\n doctest.testmod(decimal)\n"], "dis": [".js", "var $module=(function($B){\n\nvar mod = {\n    dis:function(src){\n        return __BRYTHON__.py2js(src,'__main__','__main__','__builtins__').to_js()\n    }\n}\nreturn mod\n\n})(__BRYTHON__)"], "xml.etree.cElementTree": [".py", "\n\nfrom xml.etree.ElementTree import *\n"], "locale": [".py", "def getdefaultlocale():\n return __BRYTHON__.language,None\n \ndef localeconv():\n \"\"\n \n return {'grouping': [127],\n 'currency_symbol': '',\n 'n_sign_posn': 127,\n 'p_cs_precedes': 127,\n 'n_cs_precedes': 127,\n 'mon_grouping': [],\n 'n_sep_by_space': 127,\n 'decimal_point': '.',\n 'negative_sign': '',\n 'positive_sign': '',\n 'p_sep_by_space': 127,\n 'decimal_point': '.',\n 'negative_sign': '',\n 'positive_sign': '',\n 'p_sep_by_space': 127,\n 'int_curr_symbol': '',\n 'p_sign_posn': 127,\n 'thousands_sep': '',\n 'mon_thousands_sep': '',\n 'frac_digits': 127,\n 'mon_decimal_point': '',\n 'int_frac_digits': 127}\n \ndef setlocale(category, value=None):\n \"\"\n if value not in (None, '', 'C'):\n  raise Error('_locale emulation only supports \"C\" locale')\n return 'C'\n \nCHAR_MAX = 127\nLC_ALL = 6\nLC_COLLATE = 3\nLC_CTYPE = 0\nLC_MESSAGES = 5\nLC_MONETARY = 4\nLC_NUMERIC = 1\nLC_TIME = 2\nError = ValueError\n\n\ndef getlocale(category=LC_CTYPE):\n\n \"\"\n return None, None\n"], "multiprocessing.process": [".py", "\n\n\n\n\n\n\n\n\n__all__ = ['Process', 'current_process', 'active_children']\n\n\n\n\n\nimport os\nimport sys\nimport signal\nimport itertools\nfrom _weakrefset import WeakSet\n\n\nfrom _multiprocessing import Process\n\n\n\n\ntry:\n ORIGINAL_DIR = os.path.abspath(os.getcwd())\nexcept OSError:\n ORIGINAL_DIR = None\n \n \n \n \n \ndef current_process():\n \"\"\n return _current_process\n \ndef active_children():\n \"\"\n _cleanup()\n return list(_current_process._children)\n \n \n \n \n \ndef _cleanup():\n\n for p in list(_current_process._children):\n  if p._popen.poll() is not None:\n   _current_process._children.discard(p)\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \nclass AuthenticationString(bytes):\n def __reduce__(self):\n  from .forking import Popen\n  if not Popen.thread_is_spawning():\n   raise TypeError(\n   'Pickling an AuthenticationString object is '\n   'disallowed for security reasons'\n   )\n  return AuthenticationString, (bytes(self),)\n  \n  \n  \n  \n  \nclass _MainProcess(Process):\n\n def __init__(self):\n  self._identity = ()\n  self._daemonic = False\n  self._name = 'MainProcess'\n  self._parent_pid = None\n  self._popen = None\n  self._counter = itertools.count(1)\n  self._children = set()\n  self._authkey = AuthenticationString(os.urandom(32))\n  self._tempdir = None\n  \n_current_process = _MainProcess()\ndel _MainProcess\n\n\n\n\n\n_exitcode_to_name = {}\n\nfor name, signum in list(signal.__dict__.items()):\n if name[:3]=='SIG' and '_' not in name:\n  _exitcode_to_name[-signum] = name\n  \n  \n_dangling = WeakSet()\n"], "atexit": [".py", "\"\"\n\n\nclass __loader__(object):\n pass\n \ndef _clear(*args,**kw):\n \"\"\n pass\n \ndef _run_exitfuncs(*args,**kw):\n \"\"\n pass\n \ndef register(*args,**kw):\n \"\"\n pass\n \ndef unregister(*args,**kw):\n \"\"\n pass\n"], "pydoc_data": [".py", "", 1], "unittest.test.testmock.support": [".py", "import sys\n\ndef is_instance(obj, klass):\n \"\"\n return issubclass(type(obj), klass)\n \n \nclass SomeClass(object):\n class_attribute = None\n \n def wibble(self):\n  pass\n  \n  \nclass X(object):\n pass\n \n \ndef examine_warnings(func):\n def wrapper():\n  with catch_warnings(record=True) as ws:\n   func(ws)\n return wrapper\n"], "encodings": [".py", "\"\"\n\nimport codecs\nfrom . import aliases\n\n_cache = {}\n_unknown = '--unknown--'\n_import_tail = ['*']\n_aliases = aliases.aliases\n\nclass CodecRegistryError(LookupError, SystemError):\n pass\n \ndef normalize_encoding(encoding):\n\n \"\"\n if isinstance(encoding, bytes):\n  encoding = str(encoding, \"ascii\")\n chars = []\n punct = False\n for c in encoding:\n  if c.isalnum() or c == '.':\n   if punct and chars:\n    chars.append('_')\n   chars.append(c)\n   punct = False\n  else:\n   punct = True\n return ''.join(chars)\n \ndef search_function(encoding):\n\n\n entry = _cache.get(encoding, _unknown)\n if entry is not _unknown:\n  return entry\n  \n  \n  \n  \n  \n  \n  \n  \n norm_encoding = normalize_encoding(encoding)\n aliased_encoding = _aliases.get(norm_encoding) or _aliases.get(norm_encoding.replace('.', '_'))\n if aliased_encoding is not None:\n  modnames = [aliased_encoding,\n  norm_encoding]\n else:\n  modnames = [norm_encoding]\n for modname in modnames:\n  if not modname or '.' in modname:\n   continue\n  try:\n  \n  \n   mod = __import__('encodings.' + modname, fromlist=_import_tail,\n   level=0)\n  except ImportError:\n   pass\n  else:\n   break\n else:\n  mod = None\n  \n try:\n  getregentry = mod.getregentry\n except AttributeError:\n \n  mod = None\n  \n if mod is None:\n \n  _cache[encoding] = None\n  return None\n  \n  \n entry = getregentry()\n if not isinstance(entry, codecs.CodecInfo):\n  if not 4 <= len(entry) <= 7:\n   raise CodecRegistryError('module \"%s\" (%s) failed to register'\n   % (mod.__name__, mod.__file__))\n  if not callable(entry[0]) or not callable(entry[1]) or (entry[2] is not None and not callable(entry[2])) or (entry[3] is not None and not callable(entry[3])) or (len(entry) > 4 and entry[4] is not None and not callable(entry[4])) or (len(entry) > 5 and entry[5] is not None and not callable(entry[5])):\n   raise CodecRegistryError('incompatible codecs in module \"%s\" (%s)'\n   % (mod.__name__, mod.__file__))\n  if len(entry)<7 or entry[6] is None:\n   entry += (None,)*(6-len(entry)) + (mod.__name__.split(\".\", 1)[1],)\n  entry = codecs.CodecInfo(*entry)\n  \n  \n _cache[encoding] = entry\n \n \n \n try:\n  codecaliases = mod.getaliases()\n except AttributeError:\n  pass\n else:\n  for alias in codecaliases:\n   if alias not in _aliases:\n    _aliases[alias] = modname\n    \n    \n return entry\n \n \ncodecs.register(search_function)\n", 1], "calendar": [".py", "\"\"\n\nimport sys\nimport datetime\nimport locale as _locale\n\n__all__ = [\"IllegalMonthError\", \"IllegalWeekdayError\", \"setfirstweekday\",\n\"firstweekday\", \"isleap\", \"leapdays\", \"weekday\", \"monthrange\",\n\"monthcalendar\", \"prmonth\", \"month\", \"prcal\", \"calendar\",\n\"timegm\", \"month_name\", \"month_abbr\", \"day_name\", \"day_abbr\"]\n\n\nerror = ValueError\n\n\nclass IllegalMonthError(ValueError):\n def __init__(self, month):\n  self.month = month\n def __str__(self):\n  return \"bad month number %r; must be 1-12\" % self.month\n  \n  \nclass IllegalWeekdayError(ValueError):\n def __init__(self, weekday):\n  self.weekday = weekday\n def __str__(self):\n  return \"bad weekday number %r; must be 0 (Monday) to 6 (Sunday)\" % self.weekday\n  \n  \n  \nJanuary = 1\nFebruary = 2\n\n\nmdays = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n\n\n\n\n\n\nclass _localized_month:\n\n _months = [datetime.date(2001, i+1, 1).strftime for i in range(12)]\n _months.insert(0, lambda x: \"\")\n \n def __init__(self, format):\n  self.format = format\n  \n def __getitem__(self, i):\n  funcs = self._months[i]\n  if isinstance(i, slice):\n   return [f(self.format) for f in funcs]\n  else:\n   return funcs(self.format)\n   \n def __len__(self):\n  return 13\n  \n  \nclass _localized_day:\n\n\n _days = [datetime.date(2001, 1, i+1).strftime for i in range(7)]\n \n def __init__(self, format):\n  self.format = format\n  \n def __getitem__(self, i):\n  funcs = self._days[i]\n  if isinstance(i, slice):\n   return [f(self.format) for f in funcs]\n  else:\n   return funcs(self.format)\n   \n def __len__(self):\n  return 7\n  \n  \n  \nday_name = _localized_day('%A')\nday_abbr = _localized_day('%a')\n\n\nmonth_name = _localized_month('%B')\nmonth_abbr = _localized_month('%b')\n\n\n(MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY) = range(7)\n\n\ndef isleap(year):\n \"\"\n return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n \n \ndef leapdays(y1, y2):\n \"\"\n y1 -= 1\n y2 -= 1\n return (y2//4 - y1//4) - (y2//100 - y1//100) + (y2//400 - y1//400)\n \n \ndef weekday(year, month, day):\n \"\"\n return datetime.date(year, month, day).weekday()\n \n \ndef monthrange(year, month):\n \"\"\n if not 1 <= month <= 12:\n  raise IllegalMonthError(month)\n day1 = weekday(year, month, 1)\n ndays = mdays[month] + (month == February and isleap(year))\n return day1, ndays\n \n \nclass Calendar(object):\n \"\"\n \n def __init__(self, firstweekday=0):\n  self.firstweekday = firstweekday \n  \n def getfirstweekday(self):\n  return self._firstweekday % 7\n  \n def setfirstweekday(self, firstweekday):\n  self._firstweekday = firstweekday\n  \n firstweekday = property(getfirstweekday, setfirstweekday)\n \n def iterweekdays(self):\n  \"\"\n  for i in range(self.firstweekday, self.firstweekday + 7):\n   yield i%7\n   \n def itermonthdates(self, year, month):\n  \"\"\n  date = datetime.date(year, month, 1)\n  \n  days = (date.weekday() - self.firstweekday) % 7\n  date -= datetime.timedelta(days=days)\n  oneday = datetime.timedelta(days=1)\n  while True:\n   yield date\n   try:\n    date += oneday\n   except OverflowError:\n   \n    break\n   if date.month != month and date.weekday() == self.firstweekday:\n    break\n    \n def itermonthdays2(self, year, month):\n  \"\"\n  for date in self.itermonthdates(year, month):\n   if date.month != month:\n    yield (0, date.weekday())\n   else:\n    yield (date.day, date.weekday())\n    \n def itermonthdays(self, year, month):\n  \"\"\n  for date in self.itermonthdates(year, month):\n   if date.month != month:\n    yield 0\n   else:\n    yield date.day\n    \n def monthdatescalendar(self, year, month):\n  \"\"\n  dates = list(self.itermonthdates(year, month))\n  return [ dates[i:i+7] for i in range(0, len(dates), 7) ]\n  \n def monthdays2calendar(self, year, month):\n  \"\"\n  days = list(self.itermonthdays2(year, month))\n  return [ days[i:i+7] for i in range(0, len(days), 7) ]\n  \n def monthdayscalendar(self, year, month):\n  \"\"\n  days = list(self.itermonthdays(year, month))\n  return [ days[i:i+7] for i in range(0, len(days), 7) ]\n  \n def yeardatescalendar(self, year, width=3):\n  \"\"\n  months = [\n  self.monthdatescalendar(year, i)\n  for i in range(January, January+12)\n  ]\n  return [months[i:i+width] for i in range(0, len(months), width) ]\n  \n def yeardays2calendar(self, year, width=3):\n  \"\"\n  months = [\n  self.monthdays2calendar(year, i)\n  for i in range(January, January+12)\n  ]\n  return [months[i:i+width] for i in range(0, len(months), width) ]\n  \n def yeardayscalendar(self, year, width=3):\n  \"\"\n  months = [\n  self.monthdayscalendar(year, i)\n  for i in range(January, January+12)\n  ]\n  return [months[i:i+width] for i in range(0, len(months), width) ]\n  \n  \nclass TextCalendar(Calendar):\n \"\"\n \n def prweek(self, theweek, width):\n  \"\"\n  print(self.formatweek(theweek, width), end=' ')\n  \n def formatday(self, day, weekday, width):\n  \"\"\n  if day == 0:\n   s = ''\n  else:\n   s = '%2i' % day \n  return s.center(width)\n  \n def formatweek(self, theweek, width):\n  \"\"\n  return ' '.join(self.formatday(d, wd, width) for (d, wd) in theweek)\n  \n def formatweekday(self, day, width):\n  \"\"\n  if width >= 9:\n   names = day_name\n  else:\n   names = day_abbr\n  return names[day][:width].center(width)\n  \n def formatweekheader(self, width):\n  \"\"\n  return ' '.join(self.formatweekday(i, width) for i in self.iterweekdays())\n  \n def formatmonthname(self, theyear, themonth, width, withyear=True):\n  \"\"\n  s = month_name[themonth]\n  if withyear:\n   s = \"%s %r\" % (s, theyear)\n  return s.center(width)\n  \n def prmonth(self, theyear, themonth, w=0, l=0):\n  \"\"\n  print(self.formatmonth(theyear, themonth, w, l), end=' ')\n  \n def formatmonth(self, theyear, themonth, w=0, l=0):\n  \"\"\n  w = max(2, w)\n  l = max(1, l)\n  s = self.formatmonthname(theyear, themonth, 7 * (w + 1) - 1)\n  s = s.rstrip()\n  s += '\\n' * l\n  s += self.formatweekheader(w).rstrip()\n  s += '\\n' * l\n  for week in self.monthdays2calendar(theyear, themonth):\n   s += self.formatweek(week, w).rstrip()\n   s += '\\n' * l\n  return s\n  \n def formatyear(self, theyear, w=2, l=1, c=6, m=3):\n  \"\"\n  w = max(2, w)\n  l = max(1, l)\n  c = max(2, c)\n  colwidth = (w + 1) * 7 - 1\n  v = []\n  a = v.append\n  a(repr(theyear).center(colwidth*m+c*(m-1)).rstrip())\n  a('\\n'*l)\n  header = self.formatweekheader(w)\n  for (i, row) in enumerate(self.yeardays2calendar(theyear, m)):\n  \n   months = range(m*i+1, min(m*(i+1)+1, 13))\n   a('\\n'*l)\n   names = (self.formatmonthname(theyear, k, colwidth, False)\n   for k in months)\n   a(formatstring(names, colwidth, c).rstrip())\n   a('\\n'*l)\n   headers = (header for k in months)\n   a(formatstring(headers, colwidth, c).rstrip())\n   a('\\n'*l)\n   \n   height = max(len(cal) for cal in row)\n   for j in range(height):\n    weeks = []\n    for cal in row:\n     if j >= len(cal):\n      weeks.append('')\n     else:\n      weeks.append(self.formatweek(cal[j], w))\n    a(formatstring(weeks, colwidth, c).rstrip())\n    a('\\n' * l)\n  return ''.join(v)\n  \n def pryear(self, theyear, w=0, l=0, c=6, m=3):\n  \"\"\n  print(self.formatyear(theyear, w, l, c, m))\n  \n  \nclass HTMLCalendar(Calendar):\n \"\"\n \n \n cssclasses = [\"mon\", \"tue\", \"wed\", \"thu\", \"fri\", \"sat\", \"sun\"]\n \n def formatday(self, day, weekday):\n  \"\"\n  if day == 0:\n   return '<td class=\"noday\">&nbsp;</td>' \n  else:\n   return '<td class=\"%s\">%d</td>' % (self.cssclasses[weekday], day)\n   \n def formatweek(self, theweek):\n  \"\"\n  s = ''.join(self.formatday(d, wd) for (d, wd) in theweek)\n  return '<tr>%s</tr>' % s\n  \n def formatweekday(self, day):\n  \"\"\n  return '<th class=\"%s\">%s</th>' % (self.cssclasses[day], day_abbr[day])\n  \n def formatweekheader(self):\n  \"\"\n  s = ''.join(self.formatweekday(i) for i in self.iterweekdays())\n  return '<tr>%s</tr>' % s\n  \n def formatmonthname(self, theyear, themonth, withyear=True):\n  \"\"\n  if withyear:\n   s = '%s %s' % (month_name[themonth], theyear)\n  else:\n   s = '%s' % month_name[themonth]\n  return '<tr><th colspan=\"7\" class=\"month\">%s</th></tr>' % s\n  \n def formatmonth(self, theyear, themonth, withyear=True):\n  \"\"\n  v = []\n  a = v.append\n  a('<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"month\">')\n  a('\\n')\n  a(self.formatmonthname(theyear, themonth, withyear=withyear))\n  a('\\n')\n  a(self.formatweekheader())\n  a('\\n')\n  for week in self.monthdays2calendar(theyear, themonth):\n   a(self.formatweek(week))\n   a('\\n')\n  a('</table>')\n  a('\\n')\n  return ''.join(v)\n  \n def formatyear(self, theyear, width=3):\n  \"\"\n  v = []\n  a = v.append\n  width = max(width, 1)\n  a('<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"year\">')\n  a('\\n')\n  a('<tr><th colspan=\"%d\" class=\"year\">%s</th></tr>' % (width, theyear))\n  for i in range(January, January+12, width):\n  \n   months = range(i, min(i+width, 13))\n   a('<tr>')\n   for m in months:\n    a('<td>')\n    a(self.formatmonth(theyear, m, withyear=False))\n    a('</td>')\n   a('</tr>')\n  a('</table>')\n  return ''.join(v)\n  \n def formatyearpage(self, theyear, width=3, css='calendar.css', encoding=None):\n  \"\"\n  if encoding is None:\n   encoding = sys.getdefaultencoding()\n  v = []\n  a = v.append\n  a('<?xml version=\"1.0\" encoding=\"%s\"?>\\n' % encoding)\n  a('<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\\n')\n  a('<html>\\n')\n  a('<head>\\n')\n  a('<meta http-equiv=\"Content-Type\" content=\"text/html; charset=%s\" />\\n' % encoding)\n  if css is not None:\n   a('<link rel=\"stylesheet\" type=\"text/css\" href=\"%s\" />\\n' % css)\n  a('<title>Calendar for %d</title>\\n' % theyear)\n  a('</head>\\n')\n  a('<body>\\n')\n  a(self.formatyear(theyear, width))\n  a('</body>\\n')\n  a('</html>\\n')\n  return ''.join(v).encode(encoding, \"xmlcharrefreplace\")\n  \n  \nclass different_locale:\n def __init__(self, locale):\n  self.locale = locale\n  \n def __enter__(self):\n  self.oldlocale = _locale.getlocale(_locale.LC_TIME)\n  _locale.setlocale(_locale.LC_TIME, self.locale)\n  \n def __exit__(self, *args):\n  _locale.setlocale(_locale.LC_TIME, self.oldlocale)\n  \n  \nclass LocaleTextCalendar(TextCalendar):\n \"\"\n \n def __init__(self, firstweekday=0, locale=None):\n  TextCalendar.__init__(self, firstweekday)\n  if locale is None:\n   locale = _locale.getdefaultlocale()\n  self.locale = locale\n  \n def formatweekday(self, day, width):\n  with different_locale(self.locale):\n   if width >= 9:\n    names = day_name\n   else:\n    names = day_abbr\n   name = names[day]\n   return name[:width].center(width)\n   \n def formatmonthname(self, theyear, themonth, width, withyear=True):\n  with different_locale(self.locale):\n   s = month_name[themonth]\n   if withyear:\n    s = \"%s %r\" % (s, theyear)\n   return s.center(width)\n   \n   \nclass LocaleHTMLCalendar(HTMLCalendar):\n \"\"\n def __init__(self, firstweekday=0, locale=None):\n  HTMLCalendar.__init__(self, firstweekday)\n  if locale is None:\n   locale = _locale.getdefaultlocale()\n  self.locale = locale\n  \n def formatweekday(self, day):\n  with different_locale(self.locale):\n   s = day_abbr[day]\n   return '<th class=\"%s\">%s</th>' % (self.cssclasses[day], s)\n   \n def formatmonthname(self, theyear, themonth, withyear=True):\n  with different_locale(self.locale):\n   s = month_name[themonth]\n   if withyear:\n    s = '%s %s' % (s, theyear)\n   return '<tr><th colspan=\"7\" class=\"month\">%s</th></tr>' % s\n   \n   \n   \nc = TextCalendar()\n\nfirstweekday = c.getfirstweekday\n\ndef setfirstweekday(firstweekday):\n if not MONDAY <= firstweekday <= SUNDAY:\n  raise IllegalWeekdayError(firstweekday)\n c.firstweekday = firstweekday\n \nmonthcalendar = c.monthdayscalendar\nprweek = c.prweek\nweek = c.formatweek\nweekheader = c.formatweekheader\nprmonth = c.prmonth\nmonth = c.formatmonth\ncalendar = c.formatyear\nprcal = c.pryear\n\n\n\n_colwidth = 7*3 - 1 \n_spacing = 6 \n\n\ndef format(cols, colwidth=_colwidth, spacing=_spacing):\n \"\"\n print(formatstring(cols, colwidth, spacing))\n \n \ndef formatstring(cols, colwidth=_colwidth, spacing=_spacing):\n \"\"\n spacing *= ' '\n return spacing.join(c.center(colwidth) for c in cols)\n \n \nEPOCH = 1970\n_EPOCH_ORD = datetime.date(EPOCH, 1, 1).toordinal()\n\n\ndef timegm(tuple):\n \"\"\n year, month, day, hour, minute, second = tuple[:6]\n days = datetime.date(year, month, 1).toordinal() - _EPOCH_ORD + day - 1\n hours = days*24 + hour\n minutes = hours*60 + minute\n seconds = minutes*60 + second\n return seconds\n \n \ndef main(args):\n import optparse\n parser = optparse.OptionParser(usage=\"usage: %prog [options] [year [month]]\")\n parser.add_option(\n \"-w\", \"--width\",\n dest=\"width\", type=\"int\", default=2,\n help=\"width of date column (default 2, text only)\"\n )\n parser.add_option(\n \"-l\", \"--lines\",\n dest=\"lines\", type=\"int\", default=1,\n help=\"number of lines for each week (default 1, text only)\"\n )\n parser.add_option(\n \"-s\", \"--spacing\",\n dest=\"spacing\", type=\"int\", default=6,\n help=\"spacing between months (default 6, text only)\"\n )\n parser.add_option(\n \"-m\", \"--months\",\n dest=\"months\", type=\"int\", default=3,\n help=\"months per row (default 3, text only)\"\n )\n parser.add_option(\n \"-c\", \"--css\",\n dest=\"css\", default=\"calendar.css\",\n help=\"CSS to use for page (html only)\"\n )\n parser.add_option(\n \"-L\", \"--locale\",\n dest=\"locale\", default=None,\n help=\"locale to be used from month and weekday names\"\n )\n parser.add_option(\n \"-e\", \"--encoding\",\n dest=\"encoding\", default=None,\n help=\"Encoding to use for output.\"\n )\n parser.add_option(\n \"-t\", \"--type\",\n dest=\"type\", default=\"text\",\n choices=(\"text\", \"html\"),\n help=\"output type (text or html)\"\n )\n \n (options, args) = parser.parse_args(args)\n \n if options.locale and not options.encoding:\n  parser.error(\"if --locale is specified --encoding is required\")\n  sys.exit(1)\n  \n locale = options.locale, options.encoding\n \n if options.type == \"html\":\n  if options.locale:\n   cal = LocaleHTMLCalendar(locale=locale)\n  else:\n   cal = HTMLCalendar()\n  encoding = options.encoding\n  if encoding is None:\n   encoding = sys.getdefaultencoding()\n  optdict = dict(encoding=encoding, css=options.css)\n  write = sys.stdout.buffer.write\n  if len(args) == 1:\n   write(cal.formatyearpage(datetime.date.today().year, **optdict))\n  elif len(args) == 2:\n   write(cal.formatyearpage(int(args[1]), **optdict))\n  else:\n   parser.error(\"incorrect number of arguments\")\n   sys.exit(1)\n else:\n  if options.locale:\n   cal = LocaleTextCalendar(locale=locale)\n  else:\n   cal = TextCalendar()\n  optdict = dict(w=options.width, l=options.lines)\n  if len(args) != 3:\n   optdict[\"c\"] = options.spacing\n   optdict[\"m\"] = options.months\n  if len(args) == 1:\n   result = cal.formatyear(datetime.date.today().year, **optdict)\n  elif len(args) == 2:\n   result = cal.formatyear(int(args[1]), **optdict)\n  elif len(args) == 3:\n   result = cal.formatmonth(int(args[1]), int(args[2]), **optdict)\n  else:\n   parser.error(\"incorrect number of arguments\")\n   sys.exit(1)\n  write = sys.stdout.write\n  if options.encoding:\n   result = result.encode(options.encoding)\n   write = sys.stdout.buffer.write\n  write(result)\n  \n  \nif __name__ == \"__main__\":\n main(sys.argv)\n"], "logging.handlers": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\n\nimport errno, logging, socket, os, pickle, struct, time, re\nfrom codecs import BOM_UTF8\nfrom stat import ST_DEV, ST_INO, ST_MTIME\nimport queue\ntry:\n import threading\nexcept ImportError: \n threading = None\n \n \n \n \n \nDEFAULT_TCP_LOGGING_PORT = 9020\nDEFAULT_UDP_LOGGING_PORT = 9021\nDEFAULT_HTTP_LOGGING_PORT = 9022\nDEFAULT_SOAP_LOGGING_PORT = 9023\nSYSLOG_UDP_PORT = 514\nSYSLOG_TCP_PORT = 514\n\n_MIDNIGHT = 24 * 60 * 60 \n\nclass BaseRotatingHandler(logging.FileHandler):\n \"\"\n def __init__(self, filename, mode, encoding=None, delay=False):\n  \"\"\n  logging.FileHandler.__init__(self, filename, mode, encoding, delay)\n  self.mode = mode\n  self.encoding = encoding\n  self.namer = None\n  self.rotator = None\n  \n def emit(self, record):\n  \"\"\n  try:\n   if self.shouldRollover(record):\n    self.doRollover()\n   logging.FileHandler.emit(self, record)\n  except (KeyboardInterrupt, SystemExit): \n   raise\n  except:\n   self.handleError(record)\n   \n def rotation_filename(self, default_name):\n  \"\"\n  if not callable(self.namer):\n   result = default_name\n  else:\n   result = self.namer(default_name)\n  return result\n  \n def rotate(self, source, dest):\n  \"\"\n  if not callable(self.rotator):\n  \n   if os.path.exists(source):\n    os.rename(source, dest)\n  else:\n   self.rotator(source, dest)\n   \nclass RotatingFileHandler(BaseRotatingHandler):\n \"\"\n def __init__(self, filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=False):\n  \"\"\n  \n  \n  \n  \n  \n  if maxBytes > 0:\n   mode = 'a'\n  BaseRotatingHandler.__init__(self, filename, mode, encoding, delay)\n  self.maxBytes = maxBytes\n  self.backupCount = backupCount\n  \n def doRollover(self):\n  \"\"\n  if self.stream:\n   self.stream.close()\n   self.stream = None\n  if self.backupCount > 0:\n   for i in range(self.backupCount - 1, 0, -1):\n    sfn = self.rotation_filename(\"%s.%d\" % (self.baseFilename, i))\n    dfn = self.rotation_filename(\"%s.%d\" % (self.baseFilename,\n    i + 1))\n    if os.path.exists(sfn):\n     if os.path.exists(dfn):\n      os.remove(dfn)\n     os.rename(sfn, dfn)\n   dfn = self.rotation_filename(self.baseFilename + \".1\")\n   if os.path.exists(dfn):\n    os.remove(dfn)\n   self.rotate(self.baseFilename, dfn)\n  if not self.delay:\n   self.stream = self._open()\n   \n def shouldRollover(self, record):\n  \"\"\n  if self.stream is None: \n   self.stream = self._open()\n  if self.maxBytes > 0: \n   msg = \"%s\\n\" % self.format(record)\n   self.stream.seek(0, 2) \n   if self.stream.tell() + len(msg) >= self.maxBytes:\n    return 1\n  return 0\n  \nclass TimedRotatingFileHandler(BaseRotatingHandler):\n \"\"\n def __init__(self, filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False):\n  BaseRotatingHandler.__init__(self, filename, 'a', encoding, delay)\n  self.when = when.upper()\n  self.backupCount = backupCount\n  self.utc = utc\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  if self.when == 'S':\n   self.interval = 1 \n   self.suffix = \"%Y-%m-%d_%H-%M-%S\"\n   self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}(\\.\\w+)?$\"\n  elif self.when == 'M':\n   self.interval = 60 \n   self.suffix = \"%Y-%m-%d_%H-%M\"\n   self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}(\\.\\w+)?$\"\n  elif self.when == 'H':\n   self.interval = 60 * 60 \n   self.suffix = \"%Y-%m-%d_%H\"\n   self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}_\\d{2}(\\.\\w+)?$\"\n  elif self.when == 'D' or self.when == 'MIDNIGHT':\n   self.interval = 60 * 60 * 24 \n   self.suffix = \"%Y-%m-%d\"\n   self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}(\\.\\w+)?$\"\n  elif self.when.startswith('W'):\n   self.interval = 60 * 60 * 24 * 7 \n   if len(self.when) != 2:\n    raise ValueError(\"You must specify a day for weekly rollover from 0 to 6 (0 is Monday): %s\" % self.when)\n   if self.when[1] < '0' or self.when[1] > '6':\n    raise ValueError(\"Invalid day specified for weekly rollover: %s\" % self.when)\n   self.dayOfWeek = int(self.when[1])\n   self.suffix = \"%Y-%m-%d\"\n   self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}(\\.\\w+)?$\"\n  else:\n   raise ValueError(\"Invalid rollover interval specified: %s\" % self.when)\n   \n  self.extMatch = re.compile(self.extMatch, re.ASCII)\n  self.interval = self.interval * interval \n  if os.path.exists(filename):\n   t = os.stat(filename)[ST_MTIME]\n  else:\n   t = int(time.time())\n  self.rolloverAt = self.computeRollover(t)\n  \n def computeRollover(self, currentTime):\n  \"\"\n  result = currentTime + self.interval\n  \n  \n  \n  \n  \n  \n  \n  if self.when == 'MIDNIGHT' or self.when.startswith('W'):\n  \n   if self.utc:\n    t = time.gmtime(currentTime)\n   else:\n    t = time.localtime(currentTime)\n   currentHour = t[3]\n   currentMinute = t[4]\n   currentSecond = t[5]\n   \n   r = _MIDNIGHT - ((currentHour * 60 + currentMinute) * 60 +\n   currentSecond)\n   result = currentTime + r\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   if self.when.startswith('W'):\n    day = t[6] \n    if day != self.dayOfWeek:\n     if day < self.dayOfWeek:\n      daysToWait = self.dayOfWeek - day\n     else:\n      daysToWait = 6 - day + self.dayOfWeek + 1\n     newRolloverAt = result + (daysToWait * (60 * 60 * 24))\n     if not self.utc:\n      dstNow = t[-1]\n      dstAtRollover = time.localtime(newRolloverAt)[-1]\n      if dstNow != dstAtRollover:\n       if not dstNow: \n        addend = -3600\n       else: \n        addend = 3600\n       newRolloverAt += addend\n     result = newRolloverAt\n  return result\n  \n def shouldRollover(self, record):\n  \"\"\n  t = int(time.time())\n  if t >= self.rolloverAt:\n   return 1\n  return 0\n  \n def getFilesToDelete(self):\n  \"\"\n  dirName, baseName = os.path.split(self.baseFilename)\n  fileNames = os.listdir(dirName)\n  result = []\n  prefix = baseName + \".\"\n  plen = len(prefix)\n  for fileName in fileNames:\n   if fileName[:plen] == prefix:\n    suffix = fileName[plen:]\n    if self.extMatch.match(suffix):\n     result.append(os.path.join(dirName, fileName))\n  result.sort()\n  if len(result) < self.backupCount:\n   result = []\n  else:\n   result = result[:len(result) - self.backupCount]\n  return result\n  \n def doRollover(self):\n  \"\"\n  if self.stream:\n   self.stream.close()\n   self.stream = None\n   \n  currentTime = int(time.time())\n  dstNow = time.localtime(currentTime)[-1]\n  t = self.rolloverAt - self.interval\n  if self.utc:\n   timeTuple = time.gmtime(t)\n  else:\n   timeTuple = time.localtime(t)\n   dstThen = timeTuple[-1]\n   if dstNow != dstThen:\n    if dstNow:\n     addend = 3600\n    else:\n     addend = -3600\n    timeTuple = time.localtime(t + addend)\n  dfn = self.rotation_filename(self.baseFilename + \".\" +\n  time.strftime(self.suffix, timeTuple))\n  if os.path.exists(dfn):\n   os.remove(dfn)\n  self.rotate(self.baseFilename, dfn)\n  if self.backupCount > 0:\n   for s in self.getFilesToDelete():\n    os.remove(s)\n  if not self.delay:\n   self.stream = self._open()\n  newRolloverAt = self.computeRollover(currentTime)\n  while newRolloverAt <= currentTime:\n   newRolloverAt = newRolloverAt + self.interval\n   \n  if (self.when == 'MIDNIGHT' or self.when.startswith('W')) and not self.utc:\n   dstAtRollover = time.localtime(newRolloverAt)[-1]\n   if dstNow != dstAtRollover:\n    if not dstNow: \n     addend = -3600\n    else: \n     addend = 3600\n    newRolloverAt += addend\n  self.rolloverAt = newRolloverAt\n  \nclass WatchedFileHandler(logging.FileHandler):\n \"\"\n def __init__(self, filename, mode='a', encoding=None, delay=False):\n  logging.FileHandler.__init__(self, filename, mode, encoding, delay)\n  self.dev, self.ino = -1, -1\n  self._statstream()\n  \n def _statstream(self):\n  if self.stream:\n   sres = os.fstat(self.stream.fileno())\n   self.dev, self.ino = sres[ST_DEV], sres[ST_INO]\n   \n def emit(self, record):\n  \"\"\n  \n  \n  \n  \n  try:\n  \n   sres = os.stat(self.baseFilename)\n  except OSError as err:\n   if err.errno == errno.ENOENT:\n    sres = None\n   else:\n    raise\n    \n  if not sres or sres[ST_DEV] != self.dev or sres[ST_INO] != self.ino:\n   if self.stream is not None:\n   \n    self.stream.flush()\n    self.stream.close()\n    \n    self.stream = self._open()\n    self._statstream()\n  logging.FileHandler.emit(self, record)\n  \n  \nclass SocketHandler(logging.Handler):\n \"\"\n \n def __init__(self, host, port):\n  \"\"\n  logging.Handler.__init__(self)\n  self.host = host\n  self.port = port\n  self.sock = None\n  self.closeOnError = False\n  self.retryTime = None\n  \n  \n  \n  self.retryStart = 1.0\n  self.retryMax = 30.0\n  self.retryFactor = 2.0\n  \n def makeSocket(self, timeout=1):\n  \"\"\n  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n  if hasattr(s, 'settimeout'):\n   s.settimeout(timeout)\n  try:\n   s.connect((self.host, self.port))\n   return s\n  except socket.error:\n   s.close()\n   raise\n   \n def createSocket(self):\n  \"\"\n  now = time.time()\n  \n  \n  \n  if self.retryTime is None:\n   attempt = True\n  else:\n   attempt = (now >= self.retryTime)\n  if attempt:\n   try:\n    self.sock = self.makeSocket()\n    self.retryTime = None \n   except socket.error:\n   \n    if self.retryTime is None:\n     self.retryPeriod = self.retryStart\n    else:\n     self.retryPeriod = self.retryPeriod * self.retryFactor\n     if self.retryPeriod > self.retryMax:\n      self.retryPeriod = self.retryMax\n    self.retryTime = now + self.retryPeriod\n    \n def send(self, s):\n  \"\"\n  if self.sock is None:\n   self.createSocket()\n   \n   \n   \n  if self.sock:\n   try:\n    if hasattr(self.sock, \"sendall\"):\n     self.sock.sendall(s)\n    else: \n     sentsofar = 0\n     left = len(s)\n     while left > 0:\n      sent = self.sock.send(s[sentsofar:])\n      sentsofar = sentsofar + sent\n      left = left - sent\n   except socket.error: \n    self.sock.close()\n    self.sock = None \n    \n def makePickle(self, record):\n  \"\"\n  ei = record.exc_info\n  if ei:\n  \n   dummy = self.format(record)\n   \n   \n   \n  d = dict(record.__dict__)\n  d['msg'] = record.getMessage()\n  d['args'] = None\n  d['exc_info'] = None\n  s = pickle.dumps(d, 1)\n  slen = struct.pack(\">L\", len(s))\n  return slen + s\n  \n def handleError(self, record):\n  \"\"\n  if self.closeOnError and self.sock:\n   self.sock.close()\n   self.sock = None \n  else:\n   logging.Handler.handleError(self, record)\n   \n def emit(self, record):\n  \"\"\n  try:\n   s = self.makePickle(record)\n   self.send(s)\n  except (KeyboardInterrupt, SystemExit): \n   raise\n  except:\n   self.handleError(record)\n   \n def close(self):\n  \"\"\n  self.acquire()\n  try:\n   if self.sock:\n    self.sock.close()\n    self.sock = None\n   logging.Handler.close(self)\n  finally:\n   self.release()\n   \nclass DatagramHandler(SocketHandler):\n \"\"\n def __init__(self, host, port):\n  \"\"\n  SocketHandler.__init__(self, host, port)\n  self.closeOnError = False\n  \n def makeSocket(self):\n  \"\"\n  s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n  return s\n  \n def send(self, s):\n  \"\"\n  if self.sock is None:\n   self.createSocket()\n  self.sock.sendto(s, (self.host, self.port))\n  \nclass SysLogHandler(logging.Handler):\n \"\"\n \n \n \n \n \n \n \n \n \n \n \n LOG_EMERG = 0 \n LOG_ALERT = 1 \n LOG_CRIT = 2 \n LOG_ERR = 3 \n LOG_WARNING = 4 \n LOG_NOTICE = 5 \n LOG_INFO = 6 \n LOG_DEBUG = 7 \n \n \n LOG_KERN = 0 \n LOG_USER = 1 \n LOG_MAIL = 2 \n LOG_DAEMON = 3 \n LOG_AUTH = 4 \n LOG_SYSLOG = 5 \n LOG_LPR = 6 \n LOG_NEWS = 7 \n LOG_UUCP = 8 \n LOG_CRON = 9 \n LOG_AUTHPRIV = 10 \n LOG_FTP = 11 \n \n \n LOG_LOCAL0 = 16 \n LOG_LOCAL1 = 17 \n LOG_LOCAL2 = 18 \n LOG_LOCAL3 = 19 \n LOG_LOCAL4 = 20 \n LOG_LOCAL5 = 21 \n LOG_LOCAL6 = 22 \n LOG_LOCAL7 = 23 \n \n priority_names = {\n \"alert\": LOG_ALERT,\n \"crit\": LOG_CRIT,\n \"critical\": LOG_CRIT,\n \"debug\": LOG_DEBUG,\n \"emerg\": LOG_EMERG,\n \"err\": LOG_ERR,\n \"error\": LOG_ERR, \n \"info\": LOG_INFO,\n \"notice\": LOG_NOTICE,\n \"panic\": LOG_EMERG, \n \"warn\": LOG_WARNING, \n \"warning\": LOG_WARNING,\n }\n \n facility_names = {\n \"auth\": LOG_AUTH,\n \"authpriv\": LOG_AUTHPRIV,\n \"cron\": LOG_CRON,\n \"daemon\": LOG_DAEMON,\n \"ftp\": LOG_FTP,\n \"kern\": LOG_KERN,\n \"lpr\": LOG_LPR,\n \"mail\": LOG_MAIL,\n \"news\": LOG_NEWS,\n \"security\": LOG_AUTH, \n \"syslog\": LOG_SYSLOG,\n \"user\": LOG_USER,\n \"uucp\": LOG_UUCP,\n \"local0\": LOG_LOCAL0,\n \"local1\": LOG_LOCAL1,\n \"local2\": LOG_LOCAL2,\n \"local3\": LOG_LOCAL3,\n \"local4\": LOG_LOCAL4,\n \"local5\": LOG_LOCAL5,\n \"local6\": LOG_LOCAL6,\n \"local7\": LOG_LOCAL7,\n }\n \n \n \n \n \n priority_map = {\n \"DEBUG\" : \"debug\",\n \"INFO\" : \"info\",\n \"WARNING\" : \"warning\",\n \"ERROR\" : \"error\",\n \"CRITICAL\" : \"critical\"\n }\n \n def __init__(self, address=('localhost', SYSLOG_UDP_PORT),\n facility=LOG_USER, socktype=None):\n  \"\"\n  logging.Handler.__init__(self)\n  \n  self.address = address\n  self.facility = facility\n  self.socktype = socktype\n  \n  if isinstance(address, str):\n   self.unixsocket = True\n   self._connect_unixsocket(address)\n  else:\n   self.unixsocket = False\n   if socktype is None:\n    socktype = socket.SOCK_DGRAM\n   self.socket = socket.socket(socket.AF_INET, socktype)\n   if socktype == socket.SOCK_STREAM:\n    self.socket.connect(address)\n   self.socktype = socktype\n  self.formatter = None\n  \n def _connect_unixsocket(self, address):\n  use_socktype = self.socktype\n  if use_socktype is None:\n   use_socktype = socket.SOCK_DGRAM\n  self.socket = socket.socket(socket.AF_UNIX, use_socktype)\n  try:\n   self.socket.connect(address)\n   \n   self.socktype = use_socktype\n  except socket.error:\n   self.socket.close()\n   if self.socktype is not None:\n   \n    raise\n   use_socktype = socket.SOCK_STREAM\n   self.socket = socket.socket(socket.AF_UNIX, use_socktype)\n   try:\n    self.socket.connect(address)\n    \n    self.socktype = use_socktype\n   except socket.error:\n    self.socket.close()\n    raise\n    \n def encodePriority(self, facility, priority):\n  \"\"\n  if isinstance(facility, str):\n   facility = self.facility_names[facility]\n  if isinstance(priority, str):\n   priority = self.priority_names[priority]\n  return (facility << 3) | priority\n  \n def close (self):\n  \"\"\n  self.acquire()\n  try:\n   self.socket.close()\n   logging.Handler.close(self)\n  finally:\n   self.release()\n   \n def mapPriority(self, levelName):\n  \"\"\n  return self.priority_map.get(levelName, \"warning\")\n  \n ident = '' \n append_nul = True \n \n def emit(self, record):\n  \"\"\n  msg = self.format(record)\n  if self.ident:\n   msg = self.ident + msg\n  if self.append_nul:\n   msg += '\\000'\n  \"\"\"\n        We need to convert record level to lowercase, maybe this will\n        change in the future.\n        \"\"\"  \n  prio = '<%d>' % self.encodePriority(self.facility,\n  self.mapPriority(record.levelname))\n  prio = prio.encode('utf-8')\n  \n  msg = msg.encode('utf-8')\n  msg = prio + msg\n  try:\n   if self.unixsocket:\n    try:\n     self.socket.send(msg)\n    except socket.error:\n     self.socket.close()\n     self._connect_unixsocket(self.address)\n     self.socket.send(msg)\n   elif self.socktype == socket.SOCK_DGRAM:\n    self.socket.sendto(msg, self.address)\n   else:\n    self.socket.sendall(msg)\n  except (KeyboardInterrupt, SystemExit): \n   raise\n  except:\n   self.handleError(record)\n   \nclass SMTPHandler(logging.Handler):\n \"\"\n def __init__(self, mailhost, fromaddr, toaddrs, subject,\n credentials=None, secure=None, timeout=5.0):\n  \"\"\n  logging.Handler.__init__(self)\n  if isinstance(mailhost, tuple):\n   self.mailhost, self.mailport = mailhost\n  else:\n   self.mailhost, self.mailport = mailhost, None\n  if isinstance(credentials, tuple):\n   self.username, self.password = credentials\n  else:\n   self.username = None\n  self.fromaddr = fromaddr\n  if isinstance(toaddrs, str):\n   toaddrs = [toaddrs]\n  self.toaddrs = toaddrs\n  self.subject = subject\n  self.secure = secure\n  self.timeout = timeout\n  \n def getSubject(self, record):\n  \"\"\n  return self.subject\n  \n def emit(self, record):\n  \"\"\n  try:\n   import smtplib\n   from email.utils import formatdate\n   port = self.mailport\n   if not port:\n    port = smtplib.SMTP_PORT\n   smtp = smtplib.SMTP(self.mailhost, port, timeout=self.timeout)\n   msg = self.format(record)\n   msg = \"From: %s\\r\\nTo: %s\\r\\nSubject: %s\\r\\nDate: %s\\r\\n\\r\\n%s\" % (\n   self.fromaddr,\n   \",\".join(self.toaddrs),\n   self.getSubject(record),\n   formatdate(), msg)\n   if self.username:\n    if self.secure is not None:\n     smtp.ehlo()\n     smtp.starttls(*self.secure)\n     smtp.ehlo()\n    smtp.login(self.username, self.password)\n   smtp.sendmail(self.fromaddr, self.toaddrs, msg)\n   smtp.quit()\n  except (KeyboardInterrupt, SystemExit): \n   raise\n  except:\n   self.handleError(record)\n   \nclass NTEventLogHandler(logging.Handler):\n \"\"\n def __init__(self, appname, dllname=None, logtype=\"Application\"):\n  logging.Handler.__init__(self)\n  try:\n   import win32evtlogutil, win32evtlog\n   self.appname = appname\n   self._welu = win32evtlogutil\n   if not dllname:\n    dllname = os.path.split(self._welu.__file__)\n    dllname = os.path.split(dllname[0])\n    dllname = os.path.join(dllname[0], r'win32service.pyd')\n   self.dllname = dllname\n   self.logtype = logtype\n   self._welu.AddSourceToRegistry(appname, dllname, logtype)\n   self.deftype = win32evtlog.EVENTLOG_ERROR_TYPE\n   self.typemap = {\n   logging.DEBUG : win32evtlog.EVENTLOG_INFORMATION_TYPE,\n   logging.INFO : win32evtlog.EVENTLOG_INFORMATION_TYPE,\n   logging.WARNING : win32evtlog.EVENTLOG_WARNING_TYPE,\n   logging.ERROR : win32evtlog.EVENTLOG_ERROR_TYPE,\n   logging.CRITICAL: win32evtlog.EVENTLOG_ERROR_TYPE,\n   }\n  except ImportError:\n   print(\"The Python Win32 extensions for NT (service, event \" \"logging) appear not to be available.\")\n   self._welu = None\n   \n def getMessageID(self, record):\n  \"\"\n  return 1\n  \n def getEventCategory(self, record):\n  \"\"\n  return 0\n  \n def getEventType(self, record):\n  \"\"\n  return self.typemap.get(record.levelno, self.deftype)\n  \n def emit(self, record):\n  \"\"\n  if self._welu:\n   try:\n    id = self.getMessageID(record)\n    cat = self.getEventCategory(record)\n    type = self.getEventType(record)\n    msg = self.format(record)\n    self._welu.ReportEvent(self.appname, id, cat, type, [msg])\n   except (KeyboardInterrupt, SystemExit): \n    raise\n   except:\n    self.handleError(record)\n    \n def close(self):\n  \"\"\n  \n  logging.Handler.close(self)\n  \nclass HTTPHandler(logging.Handler):\n \"\"\n def __init__(self, host, url, method=\"GET\", secure=False, credentials=None):\n  \"\"\n  logging.Handler.__init__(self)\n  method = method.upper()\n  if method not in [\"GET\", \"POST\"]:\n   raise ValueError(\"method must be GET or POST\")\n  self.host = host\n  self.url = url\n  self.method = method\n  self.secure = secure\n  self.credentials = credentials\n  \n def mapLogRecord(self, record):\n  \"\"\n  return record.__dict__\n  \n def emit(self, record):\n  \"\"\n  try:\n   import http.client, urllib.parse\n   host = self.host\n   if self.secure:\n    h = http.client.HTTPSConnection(host)\n   else:\n    h = http.client.HTTPConnection(host)\n   url = self.url\n   data = urllib.parse.urlencode(self.mapLogRecord(record))\n   if self.method == \"GET\":\n    if (url.find('?') >= 0):\n     sep = '&'\n    else:\n     sep = '?'\n    url = url + \"%c%s\" % (sep, data)\n   h.putrequest(self.method, url)\n   \n   \n   i = host.find(\":\")\n   if i >= 0:\n    host = host[:i]\n   h.putheader(\"Host\", host)\n   if self.method == \"POST\":\n    h.putheader(\"Content-type\",\n    \"application/x-www-form-urlencoded\")\n    h.putheader(\"Content-length\", str(len(data)))\n   if self.credentials:\n    import base64\n    s = ('u%s:%s' % self.credentials).encode('utf-8')\n    s = 'Basic ' + base64.b64encode(s).strip()\n    h.putheader('Authorization', s)\n   h.endheaders()\n   if self.method == \"POST\":\n    h.send(data.encode('utf-8'))\n   h.getresponse() \n  except (KeyboardInterrupt, SystemExit): \n   raise\n  except:\n   self.handleError(record)\n   \nclass BufferingHandler(logging.Handler):\n \"\"\n def __init__(self, capacity):\n  \"\"\n  logging.Handler.__init__(self)\n  self.capacity = capacity\n  self.buffer = []\n  \n def shouldFlush(self, record):\n  \"\"\n  return (len(self.buffer) >= self.capacity)\n  \n def emit(self, record):\n  \"\"\n  self.buffer.append(record)\n  if self.shouldFlush(record):\n   self.flush()\n   \n def flush(self):\n  \"\"\n  self.acquire()\n  try:\n   self.buffer = []\n  finally:\n   self.release()\n   \n def close(self):\n  \"\"\n  self.flush()\n  logging.Handler.close(self)\n  \nclass MemoryHandler(BufferingHandler):\n \"\"\n def __init__(self, capacity, flushLevel=logging.ERROR, target=None):\n  \"\"\n  BufferingHandler.__init__(self, capacity)\n  self.flushLevel = flushLevel\n  self.target = target\n  \n def shouldFlush(self, record):\n  \"\"\n  return (len(self.buffer) >= self.capacity) or (record.levelno >= self.flushLevel)\n  \n def setTarget(self, target):\n  \"\"\n  self.target = target\n  \n def flush(self):\n  \"\"\n  self.acquire()\n  try:\n   if self.target:\n    for record in self.buffer:\n     self.target.handle(record)\n    self.buffer = []\n  finally:\n   self.release()\n   \n def close(self):\n  \"\"\n  self.flush()\n  self.acquire()\n  try:\n   self.target = None\n   BufferingHandler.close(self)\n  finally:\n   self.release()\n   \n   \nclass QueueHandler(logging.Handler):\n \"\"\n \n def __init__(self, queue):\n  \"\"\n  logging.Handler.__init__(self)\n  self.queue = queue\n  \n def enqueue(self, record):\n  \"\"\n  self.queue.put_nowait(record)\n  \n def prepare(self, record):\n  \"\"\n  \n  \n  \n  \n  \n  \n  self.format(record)\n  record.msg = record.message\n  record.args = None\n  record.exc_info = None\n  return record\n  \n def emit(self, record):\n  \"\"\n  try:\n   self.enqueue(self.prepare(record))\n  except (KeyboardInterrupt, SystemExit): \n   raise\n  except:\n   self.handleError(record)\n   \nif threading:\n class QueueListener(object):\n  \"\"\n  _sentinel = None\n  \n  def __init__(self, queue, *handlers):\n   \"\"\n   self.queue = queue\n   self.handlers = handlers\n   self._stop = threading.Event()\n   self._thread = None\n   \n  def dequeue(self, block):\n   \"\"\n   return self.queue.get(block)\n   \n  def start(self):\n   \"\"\n   self._thread = t = threading.Thread(target=self._monitor)\n   t.setDaemon(True)\n   t.start()\n   \n  def prepare(self , record):\n   \"\"\n   return record\n   \n  def handle(self, record):\n   \"\"\n   record = self.prepare(record)\n   for handler in self.handlers:\n    handler.handle(record)\n    \n  def _monitor(self):\n   \"\"\n   q = self.queue\n   has_task_done = hasattr(q, 'task_done')\n   while not self._stop.isSet():\n    try:\n     record = self.dequeue(True)\n     if record is self._sentinel:\n      break\n     self.handle(record)\n     if has_task_done:\n      q.task_done()\n    except queue.Empty:\n     pass\n     \n   while True:\n    try:\n     record = self.dequeue(False)\n     if record is self._sentinel:\n      break\n     self.handle(record)\n     if has_task_done:\n      q.task_done()\n    except queue.Empty:\n     break\n     \n  def enqueue_sentinel(self):\n   \"\"\n   self.queue.put_nowait(self._sentinel)\n   \n  def stop(self):\n   \"\"\n   self._stop.set()\n   self.enqueue_sentinel()\n   self._thread.join()\n   self._thread = None\n"], "_websocket": [".js", "// websocket\nvar $module = (function($B){\n\n    var $WebSocketDict = {\n        __class__ :$B.$type,\n        __name__:'WebSocket'\n    }\n    \n    $WebSocketDict.bind = function(self,event,callback){\n        self.$ws['on'+event] = callback\n    }\n    \n    $WebSocketDict.send = function(self,data){\n        self.$ws.send(data)\n    }\n        \n    $WebSocketDict.close = function(self){\n        self.$ws.close()\n    }\n    \n    $WebSocketDict.__mro__ = [$WebSocketDict,$B.builtins.object.$dict]\n    \n    function websocket(host){\n        var $socket = new WebSocket(host);\n        var res = {\n            __class__:$WebSocketDict,\n            $ws : $socket\n        }\n        res.$websocket = $socket\n        return res\n    }\n    websocket.__class__ = $B.$factory\n    websocket.$dict = $WebSocketDict\n    \n    return {websocket:websocket}\n\n})(__BRYTHON__)\n"], "abc": [".py", "\n\n\n\"\"\n\nfrom _weakrefset import WeakSet\n\ndef abstractmethod(funcobj):\n \"\"\n funcobj.__isabstractmethod__ = True\n return funcobj\n \n \nclass abstractclassmethod(classmethod):\n \"\"\n \n __isabstractmethod__ = True\n \n def __init__(self, callable):\n  callable.__isabstractmethod__ = True\n  super().__init__(callable)\n  \n  \nclass abstractstaticmethod(staticmethod):\n \"\"\n \n __isabstractmethod__ = True\n \n def __init__(self, callable):\n  callable.__isabstractmethod__ = True\n  super().__init__(callable)\n  \n  \nclass abstractproperty(property):\n \"\"\n \n __isabstractmethod__ = True\n \n \nclass ABCMeta(type):\n\n \"\"\n \n \n \n \n _abc_invalidation_counter = 0\n \n def __new__(mcls, name, bases, namespace):\n  cls = super().__new__(mcls, name, bases, namespace)\n  \n  abstracts = {name\n  for name, value in namespace.items()\n  if getattr(value, \"__isabstractmethod__\", False)}\n  for base in bases:\n   for name in getattr(base, \"__abstractmethods__\", set()):\n    value = getattr(cls, name, None)\n    if getattr(value, \"__isabstractmethod__\", False):\n     abstracts.add(name)\n  cls.__abstractmethods__ = frozenset(abstracts)\n  \n  cls._abc_registry = WeakSet()\n  cls._abc_cache = WeakSet()\n  cls._abc_negative_cache = WeakSet()\n  cls._abc_negative_cache_version = ABCMeta._abc_invalidation_counter\n  return cls\n  \n def register(cls, subclass):\n  \"\"\n  if not isinstance(subclass, type):\n   raise TypeError(\"Can only register classes\")\n  if issubclass(subclass, cls):\n   return subclass \n   \n   \n  if issubclass(cls, subclass):\n  \n   raise RuntimeError(\"Refusing to create an inheritance cycle\")\n  cls._abc_registry.add(subclass)\n  ABCMeta._abc_invalidation_counter += 1 \n  return subclass\n  \n def _dump_registry(cls, file=None):\n  \"\"\n  print(\"Class: %s.%s\" % (cls.__module__, cls.__name__), file=file)\n  print(\"Inv.counter: %s\" % ABCMeta._abc_invalidation_counter, file=file)\n  for name in sorted(cls.__dict__.keys()):\n   if name.startswith(\"_abc_\"):\n    value = getattr(cls, name)\n    print(\"%s: %r\" % (name, value), file=file)\n    \n def __instancecheck__(cls, instance):\n  \"\"\n  \n  subclass = instance.__class__\n  if subclass in cls._abc_cache:\n   return True\n  subtype = type(instance)\n  if subtype is subclass:\n   if (cls._abc_negative_cache_version ==\n   ABCMeta._abc_invalidation_counter and\n   subclass in cls._abc_negative_cache):\n    return False\n    \n   return cls.__subclasscheck__(subclass)\n  return any(cls.__subclasscheck__(c) for c in {subclass, subtype})\n  \n def __subclasscheck__(cls, subclass):\n  \"\"\n  \n  if subclass in cls._abc_cache:\n   return True\n   \n  if cls._abc_negative_cache_version < ABCMeta._abc_invalidation_counter:\n  \n   cls._abc_negative_cache = WeakSet()\n   cls._abc_negative_cache_version = ABCMeta._abc_invalidation_counter\n  elif subclass in cls._abc_negative_cache:\n   return False\n   \n  ok = cls.__subclasshook__(subclass)\n  if ok is not NotImplemented:\n   assert isinstance(ok, bool)\n   if ok:\n    cls._abc_cache.add(subclass)\n   else:\n    cls._abc_negative_cache.add(subclass)\n   return ok\n   \n  if cls in getattr(subclass, '__mro__', ()):\n   cls._abc_cache.add(subclass)\n   return True\n   \n  for rcls in cls._abc_registry:\n   if issubclass(subclass, rcls):\n    cls._abc_cache.add(subclass)\n    return True\n    \n  for scls in cls.__subclasses__():\n   if issubclass(subclass, scls):\n    cls._abc_cache.add(subclass)\n    return True\n    \n  cls._abc_negative_cache.add(subclass)\n  return False\n"], "_thread": [".py", "\"\"\n\n\n__all__ = ['error', 'start_new_thread', 'exit', 'get_ident', 'allocate_lock',\n'interrupt_main', 'LockType']\n\n\nTIMEOUT_MAX = 2**31\n\n\n\n\n\n\nerror = RuntimeError\n\ndef start_new_thread(function, args, kwargs={}):\n \"\"\n if type(args) != type(tuple()):\n  raise TypeError(\"2nd arg must be a tuple\")\n if type(kwargs) != type(dict()):\n  raise TypeError(\"3rd arg must be a dict\")\n global _main\n _main = False\n try:\n  function(*args, **kwargs)\n except SystemExit:\n  pass\n except:\n  import traceback\n  traceback.print_exc()\n _main = True\n global _interrupt\n if _interrupt:\n  _interrupt = False\n  raise KeyboardInterrupt\n  \ndef exit():\n \"\"\n raise SystemExit\n \ndef get_ident():\n \"\"\n return -1\n \ndef allocate_lock():\n \"\"\n return LockType()\n \ndef stack_size(size=None):\n \"\"\n if size is not None:\n  raise error(\"setting thread stack size not supported\")\n return 0\n \nclass LockType(object):\n \"\"\n \n def __init__(self):\n  self.locked_status = False\n  \n def acquire(self, waitflag=None, timeout=-1):\n  \"\"\n  if waitflag is None or waitflag:\n   self.locked_status = True\n   return True\n  else:\n   if not self.locked_status:\n    self.locked_status = True\n    return True\n   else:\n    if timeout > 0:\n     import time\n     time.sleep(timeout)\n    return False\n    \n __enter__ = acquire\n \n def __exit__(self, typ, val, tb):\n  self.release()\n  \n def release(self):\n  \"\"\n  \n  \n  if not self.locked_status:\n   raise error\n  self.locked_status = False\n  return True\n  \n def locked(self):\n  return self.locked_status\n  \n  \n_interrupt = False\n\n_main = True\n\ndef interrupt_main():\n \"\"\n if _main:\n  raise KeyboardInterrupt\n else:\n  global _interrupt\n  _interrupt = True\n  \n  \nclass _local:\n pass"], "html.parser": [".py", "\"\"\n\n\n\n\n\n\n\n\n\nimport _markupbase\nimport re\nimport warnings\n\n\n\ninteresting_normal = re.compile('[&<]')\nincomplete = re.compile('&[a-zA-Z#]')\n\nentityref = re.compile('&([a-zA-Z][-.a-zA-Z0-9]*)[^a-zA-Z0-9]')\ncharref = re.compile('&#(?:[0-9]+|[xX][0-9a-fA-F]+)[^0-9a-fA-F]')\n\nstarttagopen = re.compile('<[a-zA-Z]')\npiclose = re.compile('>')\ncommentclose = re.compile(r'--\\s*>')\ntagfind = re.compile('([a-zA-Z][-.a-zA-Z0-9:_]*)(?:\\s|/(?!>))*')\n\n\ntagfind_tolerant = re.compile('[a-zA-Z][^\\t\\n\\r\\f />\\x00]*')\n\n\n\n\n\n\nattrfind = re.compile(\nr'\\s*([a-zA-Z_][-.:a-zA-Z_0-9]*)(\\s*=\\s*'\nr'(\\'[^\\']*\\'|\"[^\"]*\"|[^\\s\"\\'=<>`]*))?')\nattrfind_tolerant = re.compile(\nr'((?<=[\\'\"\\s/])[^\\s/>][^\\s/=>]*)(\\s*=+\\s*'\nr'(\\'[^\\']*\\'|\"[^\"]*\"|(?![\\'\"])[^>\\s]*))?(?:\\s|/(?!>))*')\nlocatestarttagend = re.compile(r\"\"\"\n  <[a-zA-Z][-.a-zA-Z0-9:_]*          # tag name\n  (?:\\s+                             # whitespace before attribute name\n    (?:[a-zA-Z_][-.:a-zA-Z0-9_]*     # attribute name\n      (?:\\s*=\\s*                     # value indicator\n        (?:'[^']*'                   # LITA-enclosed value\n          |\\\"[^\\\"]*\\\"                # LIT-enclosed value\n          |[^'\\\">\\s]+                # bare value\n         )\n       )?\n     )\n   )*\n  \\s*                                # trailing whitespace\n\"\"\", re.VERBOSE)\nlocatestarttagend_tolerant = re.compile(r\"\"\"\n  <[a-zA-Z][-.a-zA-Z0-9:_]*          # tag name\n  (?:[\\s/]*                          # optional whitespace before attribute name\n    (?:(?<=['\"\\s/])[^\\s/>][^\\s/=>]*  # attribute name\n      (?:\\s*=+\\s*                    # value indicator\n        (?:'[^']*'                   # LITA-enclosed value\n          |\"[^\"]*\"                   # LIT-enclosed value\n          |(?!['\"])[^>\\s]*           # bare value\n         )\n         (?:\\s*,)*                   # possibly followed by a comma\n       )?(?:\\s|/(?!>))*\n     )*\n   )?\n  \\s*                                # trailing whitespace\n\"\"\", re.VERBOSE)\nendendtag = re.compile('>')\n\n\nendtagfind = re.compile('</\\s*([a-zA-Z][-.a-zA-Z0-9:_]*)\\s*>')\n\n\nclass HTMLParseError(Exception):\n \"\"\n \n def __init__(self, msg, position=(None, None)):\n  assert msg\n  self.msg = msg\n  self.lineno = position[0]\n  self.offset = position[1]\n  \n def __str__(self):\n  result = self.msg\n  if self.lineno is not None:\n   result = result + \", at line %d\" % self.lineno\n  if self.offset is not None:\n   result = result + \", column %d\" % (self.offset + 1)\n  return result\n  \n  \nclass HTMLParser(_markupbase.ParserBase):\n \"\"\n \n CDATA_CONTENT_ELEMENTS = (\"script\", \"style\")\n \n def __init__(self, strict=False):\n  \"\"\n  if strict:\n   warnings.warn(\"The strict mode is deprecated.\",\n   DeprecationWarning, stacklevel=2)\n  self.strict = strict\n  self.reset()\n  \n def reset(self):\n  \"\"\n  self.rawdata = ''\n  self.lasttag = '???'\n  self.interesting = interesting_normal\n  self.cdata_elem = None\n  _markupbase.ParserBase.reset(self)\n  \n def feed(self, data):\n  \"\"\n  self.rawdata = self.rawdata + data\n  self.goahead(0)\n  \n def close(self):\n  \"\"\n  self.goahead(1)\n  \n def error(self, message):\n  raise HTMLParseError(message, self.getpos())\n  \n __starttag_text = None\n \n def get_starttag_text(self):\n  \"\"\n  return self.__starttag_text\n  \n def set_cdata_mode(self, elem):\n  self.cdata_elem = elem.lower()\n  self.interesting = re.compile(r'</\\s*%s\\s*>' % self.cdata_elem, re.I)\n  \n def clear_cdata_mode(self):\n  self.interesting = interesting_normal\n  self.cdata_elem = None\n  \n  \n  \n  \n def goahead(self, end):\n  rawdata = self.rawdata\n  i = 0\n  n = len(rawdata)\n  while i < n:\n   match = self.interesting.search(rawdata, i) \n   if match:\n    j = match.start()\n   else:\n    if self.cdata_elem:\n     break\n    j = n\n   if i < j: self.handle_data(rawdata[i:j])\n   i = self.updatepos(i, j)\n   if i == n: break\n   startswith = rawdata.startswith\n   if startswith('<', i):\n    if starttagopen.match(rawdata, i): \n     k = self.parse_starttag(i)\n    elif startswith(\"</\", i):\n     k = self.parse_endtag(i)\n    elif startswith(\"<!--\", i):\n     k = self.parse_comment(i)\n    elif startswith(\"<?\", i):\n     k = self.parse_pi(i)\n    elif startswith(\"<!\", i):\n     if self.strict:\n      k = self.parse_declaration(i)\n     else:\n      k = self.parse_html_declaration(i)\n    elif (i + 1) < n:\n     self.handle_data(\"<\")\n     k = i + 1\n    else:\n     break\n    if k < 0:\n     if not end:\n      break\n     if self.strict:\n      self.error(\"EOF in middle of construct\")\n     k = rawdata.find('>', i + 1)\n     if k < 0:\n      k = rawdata.find('<', i + 1)\n      if k < 0:\n       k = i + 1\n     else:\n      k += 1\n     self.handle_data(rawdata[i:k])\n    i = self.updatepos(i, k)\n   elif startswith(\"&#\", i):\n    match = charref.match(rawdata, i)\n    if match:\n     name = match.group()[2:-1]\n     self.handle_charref(name)\n     k = match.end()\n     if not startswith(';', k-1):\n      k = k - 1\n     i = self.updatepos(i, k)\n     continue\n    else:\n     if \";\" in rawdata[i:]: \n      self.handle_data(rawdata[0:2])\n      i = self.updatepos(i, 2)\n     break\n   elif startswith('&', i):\n    match = entityref.match(rawdata, i)\n    if match:\n     name = match.group(1)\n     self.handle_entityref(name)\n     k = match.end()\n     if not startswith(';', k-1):\n      k = k - 1\n     i = self.updatepos(i, k)\n     continue\n    match = incomplete.match(rawdata, i)\n    if match:\n    \n     if end and match.group() == rawdata[i:]:\n      if self.strict:\n       self.error(\"EOF in middle of entity or char ref\")\n      else:\n       k = match.end()\n       if k <= i:\n        k = n\n       i = self.updatepos(i, i + 1)\n       \n     break\n    elif (i + 1) < n:\n    \n    \n     self.handle_data(\"&\")\n     i = self.updatepos(i, i + 1)\n    else:\n     break\n   else:\n    assert 0, \"interesting.search() lied\"\n    \n  if end and i < n and not self.cdata_elem:\n   self.handle_data(rawdata[i:n])\n   i = self.updatepos(i, n)\n  self.rawdata = rawdata[i:]\n  \n  \n  \n  \n def parse_html_declaration(self, i):\n  rawdata = self.rawdata\n  assert rawdata[i:i+2] == '<!', ('unexpected call to '\n  'parse_html_declaration()')\n  if rawdata[i:i+4] == '<!--':\n  \n   return self.parse_comment(i)\n  elif rawdata[i:i+3] == '<![':\n   return self.parse_marked_section(i)\n  elif rawdata[i:i+9].lower() == '<!doctype':\n  \n   gtpos = rawdata.find('>', i+9)\n   if gtpos == -1:\n    return -1\n   self.handle_decl(rawdata[i+2:gtpos])\n   return gtpos+1\n  else:\n   return self.parse_bogus_comment(i)\n   \n   \n   \n def parse_bogus_comment(self, i, report=1):\n  rawdata = self.rawdata\n  assert rawdata[i:i+2] in ('<!', '</'), ('unexpected call to '\n  'parse_comment()')\n  pos = rawdata.find('>', i+2)\n  if pos == -1:\n   return -1\n  if report:\n   self.handle_comment(rawdata[i+2:pos])\n  return pos + 1\n  \n  \n def parse_pi(self, i):\n  rawdata = self.rawdata\n  assert rawdata[i:i+2] == '<?', 'unexpected call to parse_pi()'\n  match = piclose.search(rawdata, i+2) \n  if not match:\n   return -1\n  j = match.start()\n  self.handle_pi(rawdata[i+2: j])\n  j = match.end()\n  return j\n  \n  \n def parse_starttag(self, i):\n  self.__starttag_text = None\n  endpos = self.check_for_whole_start_tag(i)\n  if endpos < 0:\n   return endpos\n  rawdata = self.rawdata\n  self.__starttag_text = rawdata[i:endpos]\n  \n  \n  attrs = []\n  match = tagfind.match(rawdata, i+1)\n  assert match, 'unexpected call to parse_starttag()'\n  k = match.end()\n  self.lasttag = tag = match.group(1).lower()\n  while k < endpos:\n   if self.strict:\n    m = attrfind.match(rawdata, k)\n   else:\n    m = attrfind_tolerant.match(rawdata, k)\n   if not m:\n    break\n   attrname, rest, attrvalue = m.group(1, 2, 3)\n   if not rest:\n    attrvalue = None\n   elif attrvalue[:1] == '\\'' == attrvalue[-1:] or attrvalue[:1] == '\"' == attrvalue[-1:]:\n    attrvalue = attrvalue[1:-1]\n   if attrvalue:\n    attrvalue = self.unescape(attrvalue)\n   attrs.append((attrname.lower(), attrvalue))\n   k = m.end()\n   \n  end = rawdata[k:endpos].strip()\n  if end not in (\">\", \"/>\"):\n   lineno, offset = self.getpos()\n   if \"\\n\" in self.__starttag_text:\n    lineno = lineno + self.__starttag_text.count(\"\\n\")\n    offset = len(self.__starttag_text) - self.__starttag_text.rfind(\"\\n\")\n   else:\n    offset = offset + len(self.__starttag_text)\n   if self.strict:\n    self.error(\"junk characters in start tag: %r\"\n    % (rawdata[k:endpos][:20],))\n   self.handle_data(rawdata[i:endpos])\n   return endpos\n  if end.endswith('/>'):\n  \n   self.handle_startendtag(tag, attrs)\n  else:\n   self.handle_starttag(tag, attrs)\n   if tag in self.CDATA_CONTENT_ELEMENTS:\n    self.set_cdata_mode(tag)\n  return endpos\n  \n  \n  \n def check_for_whole_start_tag(self, i):\n  rawdata = self.rawdata\n  if self.strict:\n   m = locatestarttagend.match(rawdata, i)\n  else:\n   m = locatestarttagend_tolerant.match(rawdata, i)\n  if m:\n   j = m.end()\n   next = rawdata[j:j+1]\n   if next == \">\":\n    return j + 1\n   if next == \"/\":\n    if rawdata.startswith(\"/>\", j):\n     return j + 2\n    if rawdata.startswith(\"/\", j):\n    \n     return -1\n     \n    if self.strict:\n     self.updatepos(i, j + 1)\n     self.error(\"malformed empty start tag\")\n    if j > i:\n     return j\n    else:\n     return i + 1\n   if next == \"\":\n   \n    return -1\n   if next in (\"abcdefghijklmnopqrstuvwxyz=/\"\n   \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"):\n   \n   \n    return -1\n   if self.strict:\n    self.updatepos(i, j)\n    self.error(\"malformed start tag\")\n   if j > i:\n    return j\n   else:\n    return i + 1\n  raise AssertionError(\"we should not get here!\")\n  \n  \n def parse_endtag(self, i):\n  rawdata = self.rawdata\n  assert rawdata[i:i+2] == \"</\", \"unexpected call to parse_endtag\"\n  match = endendtag.search(rawdata, i+1) \n  if not match:\n   return -1\n  gtpos = match.end()\n  match = endtagfind.match(rawdata, i) \n  if not match:\n   if self.cdata_elem is not None:\n    self.handle_data(rawdata[i:gtpos])\n    return gtpos\n   if self.strict:\n    self.error(\"bad end tag: %r\" % (rawdata[i:gtpos],))\n    \n   namematch = tagfind_tolerant.match(rawdata, i+2)\n   if not namematch:\n   \n    if rawdata[i:i+3] == '</>':\n     return i+3\n    else:\n     return self.parse_bogus_comment(i)\n   tagname = namematch.group().lower()\n   \n   \n   \n   \n   gtpos = rawdata.find('>', namematch.end())\n   self.handle_endtag(tagname)\n   return gtpos+1\n   \n  elem = match.group(1).lower() \n  if self.cdata_elem is not None:\n   if elem != self.cdata_elem:\n    self.handle_data(rawdata[i:gtpos])\n    return gtpos\n    \n  self.handle_endtag(elem.lower())\n  self.clear_cdata_mode()\n  return gtpos\n  \n  \n def handle_startendtag(self, tag, attrs):\n  self.handle_starttag(tag, attrs)\n  self.handle_endtag(tag)\n  \n  \n def handle_starttag(self, tag, attrs):\n  pass\n  \n  \n def handle_endtag(self, tag):\n  pass\n  \n  \n def handle_charref(self, name):\n  pass\n  \n  \n def handle_entityref(self, name):\n  pass\n  \n  \n def handle_data(self, data):\n  pass\n  \n  \n def handle_comment(self, data):\n  pass\n  \n  \n def handle_decl(self, decl):\n  pass\n  \n  \n def handle_pi(self, data):\n  pass\n  \n def unknown_decl(self, data):\n  if self.strict:\n   self.error(\"unknown declaration: %r\" % (data,))\n   \n   \n def unescape(self, s):\n  if '&' not in s:\n   return s\n  def replaceEntities(s):\n   s = s.groups()[0]\n   try:\n    if s[0] == \"#\":\n     s = s[1:]\n     if s[0] in ['x','X']:\n      c = int(s[1:].rstrip(';'), 16)\n     else:\n      c = int(s.rstrip(';'))\n     return chr(c)\n   except ValueError:\n    return '&#' + s\n   else:\n    from html.entities import html5\n    if s in html5:\n     return html5[s]\n    elif s.endswith(';'):\n     return '&' + s\n    for x in range(2, len(s)):\n     if s[:x] in html5:\n      return html5[s[:x]] + s[x:]\n    else:\n     return '&' + s\n     \n  return re.sub(r\"&(#?[xX]?(?:[0-9a-fA-F]+;|\\w{1,32};?))\",\n  replaceEntities, s, flags=re.ASCII)\n"], "unittest.test": [".py", "import os\nimport sys\nimport unittest\n\n\nhere = os.path.dirname(__file__)\nloader = unittest.defaultTestLoader\n\ndef suite():\n suite = unittest.TestSuite()\n for fn in os.listdir(here):\n  if fn.startswith(\"test\") and fn.endswith(\".py\"):\n   modname = \"unittest.test.\" + fn[:-3]\n   __import__(modname)\n   module = sys.modules[modname]\n   suite.addTest(loader.loadTestsFromModule(module))\n suite.addTest(loader.loadTestsFromName('unittest.test.testmock'))\n return suite\n \n \nif __name__ == \"__main__\":\n unittest.main(defaultTest=\"suite\")\n", 1], "_multiprocessing": [".js", "// multiprocessing\nvar $module = (function($B){\n\nvar _b_ = $B.builtins\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\n//for(var $py_builtin in _b_){eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")}\n\nvar $ProcessDict = {__class__:$B.$type,__name__:'Process'}\n\nvar $convert_args=function(args) {\n    var _list=[]\n    for(var i=0; i < args.length; i++) {\n      var _a=args[i]\n      if(isinstance(_a, str)){_list.push(\"'\"+_a+\"'\")} else {_list.push(_a)} \n    }\n\n    return _list.join(',')\n}\n\n$ProcessDict.__mro__ = [$ProcessDict, _b_.object.$dict]\n\n$ProcessDict.__str__=$ProcessDict.toString=$ProcessDict.__repr__=function(self){\n   return '<object Process>'\n}\n\n$ProcessDict.is_alive = function(self){return self.$alive}\n\n$ProcessDict.join = function(self, timeout){\n   // need to block until process is complete\n   // could probably use a addEventListener to execute all existing code\n   // after this join statement\n\n   self.$worker.addEventListener('message', function (e) {\n        var data=e.data\n        if (data.stdout != '') { // output stdout from process\n           $B.stdout.write(data.stdout)\n        }\n   }, false);\n}\n\n$ProcessDict.run = function(self){\n   //fix me\n}\n\n$ProcessDict.start = function(self){\n   //var _args=[]\n   //for(var i=0; i < self.$args.length; i++) {\n   //   var _a=self.$args[i]\n   //   if(isinstance(_a, str)){_args.push(\"'\"+_a+\"'\")} else {_args.push(_a)} \n   //}\n\n   self.$worker.postMessage({target: self.$target, \n                             args: $convert_args(self.$args),\n                          //   kwargs: self.$kwargs\n                           })\n   self.$worker.addEventListener('error', function(e) { throw e})\n   self.$alive=true\n}\n\n$ProcessDict.terminate = function(self){\n   self.$worker.terminate()\n   self.$alive=false\n}\n\n// variables\n//name\n//daemon\n//pid\n//exitcode\n\nfunction Process(){\n    //arguments group=None, target=None, name=None, args=(), kwargs=()\n\n    var $ns=$B.$MakeArgs('Process',arguments,[],[],null,'kw')\n    var kw=$ns['kw']\n\n    var target=_b_.dict.$dict.get($ns['kw'],'target',None)\n    var args=_b_.dict.$dict.get($ns['kw'],'args',tuple())\n\n    var worker = new Worker('/src/web_workers/multiprocessing.js')\n\n    var res = {\n        __class__:$ProcessDict,\n        $worker: worker,\n        name: $ns['name'] || None,\n        $target: target+'',\n        $args: args,\n        //$kwargs: $ns['kw'],\n        $alive: false\n    }\n    return res\n}\n\nProcess.__class__ = $B.$factory\nProcess.$dict = $ProcessDict\n\n\nvar $PoolDict = {__class__:$B.$type,__name__:'Pool'}\n\n$PoolDict.__mro__ = [$PoolDict, _b_.object.$dict]\n\n$PoolDict.__enter__ = function(self){}\n$PoolDict.__exit__ = function(self){}\n\n$PoolDict.__str__ = $PoolDict.toString = $PoolDict.__repr__=function(self){\n   return '<object Pool>'\n}\n\n$PoolDict.map = function(self){\n   var args = []\n   for(var i=1;i<arguments.length;i++) args.push(arguments[i])\n\n   var $ns=$B.$MakeArgs('Pool.map',args,['func', 'fargs'],[],'args','kw')\n   var func=$ns['func']\n   var fargs=$ns['fargs']\n\n   var _results=[]\n\n   fargs=iter(fargs)\n\n   var _pos=0\n   console.log(self.$processes)\n   _workers=[]\n   for(var i=0; i < self.$processes; i++) {\n       _workers[i] = new Worker('/src/web_workers/multiprocessing.js')\n       var arg\n\n       try{ \n          arg=getattr(fargs, '__next__')()\n       } catch(err) {\n          if (err.__name__ == 'StopIteration') {\n             __BRYTHON__.$pop_exc()\n          } else {\n             throw err\n          }\n       }\n       console.log(arg)\n       _workers[i].finished=false\n       _workers[i].postMessage({target: func+'', pos: _pos,\n                             args: $convert_args([arg])})\n       _pos++\n\n       _workers[i].addEventListener('message', function(e) {\n           _results[e.data.pos]=e.data.result\n           if (_results.length == args.length) return _results\n\n           try {\n               arg=getattr(fargs, '__next__')()\n               e.currentTarget.postMessage({target: func+'', pos: _pos,\n                                            args: $convert_args([arg])})\n               _pos++\n           } catch(err) {\n               if (err.__name__ != 'StopIteration') throw err\n               this.finished=true\n           }\n       }, false);\n   }\n}\n\n$PoolDict.apply_async = function(self){\n   var args = []\n   for(var i=1;i<arguments.length;i++){args.push(arguments[i])}\n\n   var $ns=$B.$MakeArgs('apply_async',args,['func', 'fargs'],[],'args','kw')\n   var func=$ns['func']\n   var fargs=$ns['fargs']\n\n   fargs=iter(fargs)\n\n   async_result = {}\n   async_result.get=function(timeout){\n                      console.log(results)\n                      console.log(fargs)\n                      return this.results}\n   async_result.results=[]\n\n   var _pos=0\n\n   _workers=[]\n   for(var i=0; i < self.$processes; i++) {\n       _workers[i] = new Worker('/src/web_workers/multiprocessing.js')\n       var arg\n\n       try{ \n          arg=getattr(fargs, '__next__')()\n       } catch(err) {\n          if (err.__name__ == 'StopIteration') {\n             $B.$pop_exc()\n          } else {\n             throw err\n          }\n       }\n       //console.log(arg)\n       //_workers[i].finished=false\n       _workers[i].postMessage({target: func+'', pos: _pos,\n                             args: $convert_args([arg])})\n       _pos++\n\n       _workers[i].addEventListener('message', function(e) {\n           async_result.results[e.data.pos]=e.data.result\n           //if (_results.length == args.length) return _results\n\n           try {\n               arg=getattr(fargs, '__next__')()\n               e.currentTarget.postMessage({target: func+'', pos: _pos,\n                                            args: $convert_args([arg])})\n               _pos++\n           } catch(err) {\n               if (err.__name__ != 'StopIteration') throw err\n               this.finished=true\n           }\n       }, false);\n   }\n\n   console.log(\"return\", async_result)\n   return async_result\n}\n\nfunction Pool(){\n    console.log(\"pool\")\n    console.log(arguments)\n    var $ns=$B.$MakeArgs('Pool',arguments,[],['processes'],'args','kw')\n    //var kw=$ns['kw']\n\n    var processes=$ns['processes']\n\n    if (processes == None) {\n       // look to see if we have stored cpu_count in local storage\n       // maybe we should create a brython config file with settings,etc..??\n\n       // if not there use a tool such as Core Estimator to calculate number of cpu's\n       // http://eligrey.com/blog/post/cpu-core-estimation-with-javascript\n    }\n\n    console.log(processes)\n    var res = {\n        __class__:$PoolDict,\n        $processes:processes\n    }\n    return res\n}\n\nPool.__class__ = $B.$factory\nPool.$dict = $PoolDict\n\nreturn {Process:Process, Pool:Pool}\n\n})(__BRYTHON__)\n"], "tarfile": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\n\nversion = \"0.9.0\"\n__author__ = \"Lars Gust\\u00e4bel (lars@gustaebel.de)\"\n__date__ = \"$Date: 2011-02-25 17:42:01 +0200 (Fri, 25 Feb 2011) $\"\n__cvsid__ = \"$Id: tarfile.py 88586 2011-02-25 15:42:01Z marc-andre.lemburg $\"\n__credits__ = \"Gustavo Niemeyer, Niels Gust\\u00e4bel, Richard Townsend.\"\n\n\n\n\nimport sys\nimport os\nimport io\nimport shutil\nimport stat\nimport time\nimport struct\nimport copy\nimport re\n\ntry:\n import grp, pwd\nexcept ImportError:\n grp = pwd = None\n \n \nsymlink_exception = (AttributeError, NotImplementedError)\ntry:\n\n\n symlink_exception += (WindowsError,)\nexcept NameError:\n pass\n \n \n__all__ = [\"TarFile\", \"TarInfo\", \"is_tarfile\", \"TarError\"]\n\nfrom builtins import open as _open \n\n\n\n\nNUL = b\"\\0\" \nBLOCKSIZE = 512 \nRECORDSIZE = BLOCKSIZE * 20 \nGNU_MAGIC = b\"ustar  \\0\" \nPOSIX_MAGIC = b\"ustar\\x0000\" \n\nLENGTH_NAME = 100 \nLENGTH_LINK = 100 \nLENGTH_PREFIX = 155 \n\nREGTYPE = b\"0\" \nAREGTYPE = b\"\\0\" \nLNKTYPE = b\"1\" \nSYMTYPE = b\"2\" \nCHRTYPE = b\"3\" \nBLKTYPE = b\"4\" \nDIRTYPE = b\"5\" \nFIFOTYPE = b\"6\" \nCONTTYPE = b\"7\" \n\nGNUTYPE_LONGNAME = b\"L\" \nGNUTYPE_LONGLINK = b\"K\" \nGNUTYPE_SPARSE = b\"S\" \n\nXHDTYPE = b\"x\" \nXGLTYPE = b\"g\" \nSOLARIS_XHDTYPE = b\"X\" \n\nUSTAR_FORMAT = 0 \nGNU_FORMAT = 1 \nPAX_FORMAT = 2 \nDEFAULT_FORMAT = GNU_FORMAT\n\n\n\n\n\nSUPPORTED_TYPES = (REGTYPE, AREGTYPE, LNKTYPE,\nSYMTYPE, DIRTYPE, FIFOTYPE,\nCONTTYPE, CHRTYPE, BLKTYPE,\nGNUTYPE_LONGNAME, GNUTYPE_LONGLINK,\nGNUTYPE_SPARSE)\n\n\nREGULAR_TYPES = (REGTYPE, AREGTYPE,\nCONTTYPE, GNUTYPE_SPARSE)\n\n\nGNU_TYPES = (GNUTYPE_LONGNAME, GNUTYPE_LONGLINK,\nGNUTYPE_SPARSE)\n\n\nPAX_FIELDS = (\"path\", \"linkpath\", \"size\", \"mtime\",\n\"uid\", \"gid\", \"uname\", \"gname\")\n\n\nPAX_NAME_FIELDS = {\"path\", \"linkpath\", \"uname\", \"gname\"}\n\n\n\nPAX_NUMBER_FIELDS = {\n\"atime\": float,\n\"ctime\": float,\n\"mtime\": float,\n\"uid\": int,\n\"gid\": int,\n\"size\": int\n}\n\n\n\n\nS_IFLNK = 0o120000 \nS_IFREG = 0o100000 \nS_IFBLK = 0o060000 \nS_IFDIR = 0o040000 \nS_IFCHR = 0o020000 \nS_IFIFO = 0o010000 \n\nTSUID = 0o4000 \nTSGID = 0o2000 \nTSVTX = 0o1000 \n\nTUREAD = 0o400 \nTUWRITE = 0o200 \nTUEXEC = 0o100 \nTGREAD = 0o040 \nTGWRITE = 0o020 \nTGEXEC = 0o010 \nTOREAD = 0o004 \nTOWRITE = 0o002 \nTOEXEC = 0o001 \n\n\n\n\nif os.name in (\"nt\", \"ce\"):\n ENCODING = \"utf-8\"\nelse:\n ENCODING = sys.getfilesystemencoding()\n \n \n \n \n \ndef stn(s, length, encoding, errors):\n \"\"\n s = s.encode(encoding, errors)\n return s[:length] + (length - len(s)) * NUL\n \ndef nts(s, encoding, errors):\n \"\"\n p = s.find(b\"\\0\")\n if p != -1:\n  s = s[:p]\n return s.decode(encoding, errors)\n \ndef nti(s):\n \"\"\n \n \n if s[0] in (0o200, 0o377):\n  n = 0\n  for i in range(len(s) - 1):\n   n <<= 8\n   n += s[i + 1]\n  if s[0] == 0o377:\n   n = -(256 ** (len(s) - 1) - n)\n else:\n  try:\n   n = int(nts(s, \"ascii\", \"strict\") or \"0\", 8)\n  except ValueError:\n   raise InvalidHeaderError(\"invalid header\")\n return n\n \ndef itn(n, digits=8, format=DEFAULT_FORMAT):\n \"\"\n \n \n \n \n \n \n \n \n if 0 <= n < 8 ** (digits - 1):\n  s = bytes(\"%0*o\" % (digits - 1, n), \"ascii\") + NUL\n elif format == GNU_FORMAT and -256 ** (digits - 1) <= n < 256 ** (digits - 1):\n  if n >= 0:\n   s = bytearray([0o200])\n  else:\n   s = bytearray([0o377])\n   n = 256 ** digits + n\n   \n  for i in range(digits - 1):\n   s.insert(1, n & 0o377)\n   n >>= 8\n else:\n  raise ValueError(\"overflow in number field\")\n  \n return s\n \ndef calc_chksums(buf):\n \"\"\n unsigned_chksum = 256 + sum(struct.unpack_from(\"148B8x356B\", buf))\n signed_chksum = 256 + sum(struct.unpack_from(\"148b8x356b\", buf))\n return unsigned_chksum, signed_chksum\n \ndef copyfileobj(src, dst, length=None):\n \"\"\n if length == 0:\n  return\n if length is None:\n  shutil.copyfileobj(src, dst)\n  return\n  \n BUFSIZE = 16 * 1024\n blocks, remainder = divmod(length, BUFSIZE)\n for b in range(blocks):\n  buf = src.read(BUFSIZE)\n  if len(buf) < BUFSIZE:\n   raise IOError(\"end of file reached\")\n  dst.write(buf)\n  \n if remainder != 0:\n  buf = src.read(remainder)\n  if len(buf) < remainder:\n   raise IOError(\"end of file reached\")\n  dst.write(buf)\n return\n \ndef filemode(mode):\n \"\"\n import warnings\n warnings.warn(\"deprecated in favor of stat.filemode\",\n DeprecationWarning, 2)\n return stat.filemode(mode)\n \n \nclass TarError(Exception):\n \"\"\n pass\nclass ExtractError(TarError):\n \"\"\n pass\nclass ReadError(TarError):\n \"\"\n pass\nclass CompressionError(TarError):\n \"\"\n pass\nclass StreamError(TarError):\n \"\"\n pass\nclass HeaderError(TarError):\n \"\"\n pass\nclass EmptyHeaderError(HeaderError):\n \"\"\n pass\nclass TruncatedHeaderError(HeaderError):\n \"\"\n pass\nclass EOFHeaderError(HeaderError):\n \"\"\n pass\nclass InvalidHeaderError(HeaderError):\n \"\"\n pass\nclass SubsequentHeaderError(HeaderError):\n \"\"\n pass\n \n \n \n \nclass _LowLevelFile:\n \"\"\n \n def __init__(self, name, mode):\n  mode = {\n  \"r\": os.O_RDONLY,\n  \"w\": os.O_WRONLY | os.O_CREAT | os.O_TRUNC,\n  }[mode]\n  if hasattr(os, \"O_BINARY\"):\n   mode |= os.O_BINARY\n  self.fd = os.open(name, mode, 0o666)\n  \n def close(self):\n  os.close(self.fd)\n  \n def read(self, size):\n  return os.read(self.fd, size)\n  \n def write(self, s):\n  os.write(self.fd, s)\n  \nclass _Stream:\n \"\"\n \n def __init__(self, name, mode, comptype, fileobj, bufsize):\n  \"\"\n  self._extfileobj = True\n  if fileobj is None:\n   fileobj = _LowLevelFile(name, mode)\n   self._extfileobj = False\n   \n  if comptype == '*':\n  \n  \n   fileobj = _StreamProxy(fileobj)\n   comptype = fileobj.getcomptype()\n   \n  self.name = name or \"\"\n  self.mode = mode\n  self.comptype = comptype\n  self.fileobj = fileobj\n  self.bufsize = bufsize\n  self.buf = b\"\"\n  self.pos = 0\n  self.closed = False\n  \n  try:\n   if comptype == \"gz\":\n    try:\n     import zlib\n    except ImportError:\n     raise CompressionError(\"zlib module is not available\")\n    self.zlib = zlib\n    self.crc = zlib.crc32(b\"\")\n    if mode == \"r\":\n     self._init_read_gz()\n     self.exception = zlib.error\n    else:\n     self._init_write_gz()\n     \n   elif comptype == \"bz2\":\n    try:\n     import bz2\n    except ImportError:\n     raise CompressionError(\"bz2 module is not available\")\n    if mode == \"r\":\n     self.dbuf = b\"\"\n     self.cmp = bz2.BZ2Decompressor()\n     self.exception = IOError\n    else:\n     self.cmp = bz2.BZ2Compressor()\n     \n   elif comptype == \"xz\":\n    try:\n     import lzma\n    except ImportError:\n     raise CompressionError(\"lzma module is not available\")\n    if mode == \"r\":\n     self.dbuf = b\"\"\n     self.cmp = lzma.LZMADecompressor()\n     self.exception = lzma.LZMAError\n    else:\n     self.cmp = lzma.LZMACompressor()\n     \n   elif comptype != \"tar\":\n    raise CompressionError(\"unknown compression type %r\" % comptype)\n    \n  except:\n   if not self._extfileobj:\n    self.fileobj.close()\n   self.closed = True\n   raise\n   \n def __del__(self):\n  if hasattr(self, \"closed\") and not self.closed:\n   self.close()\n   \n def _init_write_gz(self):\n  \"\"\n  self.cmp = self.zlib.compressobj(9, self.zlib.DEFLATED,\n  -self.zlib.MAX_WBITS,\n  self.zlib.DEF_MEM_LEVEL,\n  0)\n  timestamp = struct.pack(\"<L\", int(time.time()))\n  self.__write(b\"\\037\\213\\010\\010\" + timestamp + b\"\\002\\377\")\n  if self.name.endswith(\".gz\"):\n   self.name = self.name[:-3]\n   \n  self.__write(self.name.encode(\"iso-8859-1\", \"replace\") + NUL)\n  \n def write(self, s):\n  \"\"\n  if self.comptype == \"gz\":\n   self.crc = self.zlib.crc32(s, self.crc)\n  self.pos += len(s)\n  if self.comptype != \"tar\":\n   s = self.cmp.compress(s)\n  self.__write(s)\n  \n def __write(self, s):\n  \"\"\n  self.buf += s\n  while len(self.buf) > self.bufsize:\n   self.fileobj.write(self.buf[:self.bufsize])\n   self.buf = self.buf[self.bufsize:]\n   \n def close(self):\n  \"\"\n  if self.closed:\n   return\n   \n  if self.mode == \"w\" and self.comptype != \"tar\":\n   self.buf += self.cmp.flush()\n   \n  if self.mode == \"w\" and self.buf:\n   self.fileobj.write(self.buf)\n   self.buf = b\"\"\n   if self.comptype == \"gz\":\n   \n   \n   \n   \n   \n   \n    self.fileobj.write(struct.pack(\"<L\", self.crc & 0xffffffff))\n    self.fileobj.write(struct.pack(\"<L\", self.pos & 0xffffFFFF))\n    \n  if not self._extfileobj:\n   self.fileobj.close()\n   \n  self.closed = True\n  \n def _init_read_gz(self):\n  \"\"\n  self.cmp = self.zlib.decompressobj(-self.zlib.MAX_WBITS)\n  self.dbuf = b\"\"\n  \n  \n  if self.__read(2) != b\"\\037\\213\":\n   raise ReadError(\"not a gzip file\")\n  if self.__read(1) != b\"\\010\":\n   raise CompressionError(\"unsupported compression method\")\n   \n  flag = ord(self.__read(1))\n  self.__read(6)\n  \n  if flag & 4:\n   xlen = ord(self.__read(1)) + 256 * ord(self.__read(1))\n   self.read(xlen)\n  if flag & 8:\n   while True:\n    s = self.__read(1)\n    if not s or s == NUL:\n     break\n  if flag & 16:\n   while True:\n    s = self.__read(1)\n    if not s or s == NUL:\n     break\n  if flag & 2:\n   self.__read(2)\n   \n def tell(self):\n  \"\"\n  return self.pos\n  \n def seek(self, pos=0):\n  \"\"\n  if pos - self.pos >= 0:\n   blocks, remainder = divmod(pos - self.pos, self.bufsize)\n   for i in range(blocks):\n    self.read(self.bufsize)\n   self.read(remainder)\n  else:\n   raise StreamError(\"seeking backwards is not allowed\")\n  return self.pos\n  \n def read(self, size=None):\n  \"\"\n  if size is None:\n   t = []\n   while True:\n    buf = self._read(self.bufsize)\n    if not buf:\n     break\n    t.append(buf)\n   buf = \"\".join(t)\n  else:\n   buf = self._read(size)\n  self.pos += len(buf)\n  return buf\n  \n def _read(self, size):\n  \"\"\n  if self.comptype == \"tar\":\n   return self.__read(size)\n   \n  c = len(self.dbuf)\n  while c < size:\n   buf = self.__read(self.bufsize)\n   if not buf:\n    break\n   try:\n    buf = self.cmp.decompress(buf)\n   except self.exception:\n    raise ReadError(\"invalid compressed data\")\n   self.dbuf += buf\n   c += len(buf)\n  buf = self.dbuf[:size]\n  self.dbuf = self.dbuf[size:]\n  return buf\n  \n def __read(self, size):\n  \"\"\n  c = len(self.buf)\n  while c < size:\n   buf = self.fileobj.read(self.bufsize)\n   if not buf:\n    break\n   self.buf += buf\n   c += len(buf)\n  buf = self.buf[:size]\n  self.buf = self.buf[size:]\n  return buf\n  \n  \nclass _StreamProxy(object):\n \"\"\n \n def __init__(self, fileobj):\n  self.fileobj = fileobj\n  self.buf = self.fileobj.read(BLOCKSIZE)\n  \n def read(self, size):\n  self.read = self.fileobj.read\n  return self.buf\n  \n def getcomptype(self):\n  if self.buf.startswith(b\"\\x1f\\x8b\\x08\"):\n   return \"gz\"\n  elif self.buf[0:3] == b\"BZh\" and self.buf[4:10] == b\"1AY&SY\":\n   return \"bz2\"\n  elif self.buf.startswith((b\"\\x5d\\x00\\x00\\x80\", b\"\\xfd7zXZ\")):\n   return \"xz\"\n  else:\n   return \"tar\"\n   \n def close(self):\n  self.fileobj.close()\n  \n  \n  \n  \n  \nclass _FileInFile(object):\n \"\"\n \n def __init__(self, fileobj, offset, size, blockinfo=None):\n  self.fileobj = fileobj\n  self.offset = offset\n  self.size = size\n  self.position = 0\n  self.name = getattr(fileobj, \"name\", None)\n  self.closed = False\n  \n  if blockinfo is None:\n   blockinfo = [(0, size)]\n   \n   \n  self.map_index = 0\n  self.map = []\n  lastpos = 0\n  realpos = self.offset\n  for offset, size in blockinfo:\n   if offset > lastpos:\n    self.map.append((False, lastpos, offset, None))\n   self.map.append((True, offset, offset + size, realpos))\n   realpos += size\n   lastpos = offset + size\n  if lastpos < self.size:\n   self.map.append((False, lastpos, self.size, None))\n   \n def flush(self):\n  pass\n  \n def readable(self):\n  return True\n  \n def writable(self):\n  return False\n  \n def seekable(self):\n  return self.fileobj.seekable()\n  \n def tell(self):\n  \"\"\n  return self.position\n  \n def seek(self, position, whence=io.SEEK_SET):\n  \"\"\n  if whence == io.SEEK_SET:\n   self.position = min(max(position, 0), self.size)\n  elif whence == io.SEEK_CUR:\n   if position < 0:\n    self.position = max(self.position + position, 0)\n   else:\n    self.position = min(self.position + position, self.size)\n  elif whence == io.SEEK_END:\n   self.position = max(min(self.size + position, self.size), 0)\n  else:\n   raise ValueError(\"Invalid argument\")\n  return self.position\n  \n def read(self, size=None):\n  \"\"\n  if size is None:\n   size = self.size - self.position\n  else:\n   size = min(size, self.size - self.position)\n   \n  buf = b\"\"\n  while size > 0:\n   while True:\n    data, start, stop, offset = self.map[self.map_index]\n    if start <= self.position < stop:\n     break\n    else:\n     self.map_index += 1\n     if self.map_index == len(self.map):\n      self.map_index = 0\n   length = min(size, stop - self.position)\n   if data:\n    self.fileobj.seek(offset + (self.position - start))\n    buf += self.fileobj.read(length)\n   else:\n    buf += NUL * length\n   size -= length\n   self.position += length\n  return buf\n  \n def readinto(self, b):\n  buf = self.read(len(b))\n  b[:len(buf)] = buf\n  return len(buf)\n  \n def close(self):\n  self.closed = True\n  \n  \nclass ExFileObject(io.BufferedReader):\n\n def __init__(self, tarfile, tarinfo):\n  fileobj = _FileInFile(tarfile.fileobj, tarinfo.offset_data,\n  tarinfo.size, tarinfo.sparse)\n  super().__init__(fileobj)\n  \n  \n  \n  \n  \nclass TarInfo(object):\n \"\"\n \n __slots__ = (\"name\", \"mode\", \"uid\", \"gid\", \"size\", \"mtime\",\n \"chksum\", \"type\", \"linkname\", \"uname\", \"gname\",\n \"devmajor\", \"devminor\",\n \"offset\", \"offset_data\", \"pax_headers\", \"sparse\",\n \"tarfile\", \"_sparse_structs\", \"_link_target\")\n \n def __init__(self, name=\"\"):\n  \"\"\n  self.name = name \n  self.mode = 0o644 \n  self.uid = 0 \n  self.gid = 0 \n  self.size = 0 \n  self.mtime = 0 \n  self.chksum = 0 \n  self.type = REGTYPE \n  self.linkname = \"\" \n  self.uname = \"\" \n  self.gname = \"\" \n  self.devmajor = 0 \n  self.devminor = 0 \n  \n  self.offset = 0 \n  self.offset_data = 0 \n  \n  self.sparse = None \n  self.pax_headers = {} \n  \n  \n  \n def _getpath(self):\n  return self.name\n def _setpath(self, name):\n  self.name = name\n path = property(_getpath, _setpath)\n \n def _getlinkpath(self):\n  return self.linkname\n def _setlinkpath(self, linkname):\n  self.linkname = linkname\n linkpath = property(_getlinkpath, _setlinkpath)\n \n def __repr__(self):\n  return \"<%s %r at %#x>\" % (self.__class__.__name__,self.name,id(self))\n  \n def get_info(self):\n  \"\"\n  info = {\n  \"name\": self.name,\n  \"mode\": self.mode & 0o7777,\n  \"uid\": self.uid,\n  \"gid\": self.gid,\n  \"size\": self.size,\n  \"mtime\": self.mtime,\n  \"chksum\": self.chksum,\n  \"type\": self.type,\n  \"linkname\": self.linkname,\n  \"uname\": self.uname,\n  \"gname\": self.gname,\n  \"devmajor\": self.devmajor,\n  \"devminor\": self.devminor\n  }\n  \n  if info[\"type\"] == DIRTYPE and not info[\"name\"].endswith(\"/\"):\n   info[\"name\"] += \"/\"\n   \n  return info\n  \n def tobuf(self, format=DEFAULT_FORMAT, encoding=ENCODING, errors=\"surrogateescape\"):\n  \"\"\n  info = self.get_info()\n  \n  if format == USTAR_FORMAT:\n   return self.create_ustar_header(info, encoding, errors)\n  elif format == GNU_FORMAT:\n   return self.create_gnu_header(info, encoding, errors)\n  elif format == PAX_FORMAT:\n   return self.create_pax_header(info, encoding)\n  else:\n   raise ValueError(\"invalid format\")\n   \n def create_ustar_header(self, info, encoding, errors):\n  \"\"\n  info[\"magic\"] = POSIX_MAGIC\n  \n  if len(info[\"linkname\"]) > LENGTH_LINK:\n   raise ValueError(\"linkname is too long\")\n   \n  if len(info[\"name\"]) > LENGTH_NAME:\n   info[\"prefix\"], info[\"name\"] = self._posix_split_name(info[\"name\"])\n   \n  return self._create_header(info, USTAR_FORMAT, encoding, errors)\n  \n def create_gnu_header(self, info, encoding, errors):\n  \"\"\n  info[\"magic\"] = GNU_MAGIC\n  \n  buf = b\"\"\n  if len(info[\"linkname\"]) > LENGTH_LINK:\n   buf += self._create_gnu_long_header(info[\"linkname\"], GNUTYPE_LONGLINK, encoding, errors)\n   \n  if len(info[\"name\"]) > LENGTH_NAME:\n   buf += self._create_gnu_long_header(info[\"name\"], GNUTYPE_LONGNAME, encoding, errors)\n   \n  return buf + self._create_header(info, GNU_FORMAT, encoding, errors)\n  \n def create_pax_header(self, info, encoding):\n  \"\"\n  info[\"magic\"] = POSIX_MAGIC\n  pax_headers = self.pax_headers.copy()\n  \n  \n  \n  for name, hname, length in (\n  (\"name\", \"path\", LENGTH_NAME), (\"linkname\", \"linkpath\", LENGTH_LINK),\n  (\"uname\", \"uname\", 32), (\"gname\", \"gname\", 32)):\n  \n   if hname in pax_headers:\n   \n    continue\n    \n    \n   try:\n    info[name].encode(\"ascii\", \"strict\")\n   except UnicodeEncodeError:\n    pax_headers[hname] = info[name]\n    continue\n    \n   if len(info[name]) > length:\n    pax_headers[hname] = info[name]\n    \n    \n    \n  for name, digits in ((\"uid\", 8), (\"gid\", 8), (\"size\", 12), (\"mtime\", 12)):\n   if name in pax_headers:\n   \n    info[name] = 0\n    continue\n    \n   val = info[name]\n   if not 0 <= val < 8 ** (digits - 1) or isinstance(val, float):\n    pax_headers[name] = str(val)\n    info[name] = 0\n    \n    \n  if pax_headers:\n   buf = self._create_pax_generic_header(pax_headers, XHDTYPE, encoding)\n  else:\n   buf = b\"\"\n   \n  return buf + self._create_header(info, USTAR_FORMAT, \"ascii\", \"replace\")\n  \n @classmethod\n def create_pax_global_header(cls, pax_headers):\n  \"\"\n  return cls._create_pax_generic_header(pax_headers, XGLTYPE, \"utf-8\")\n  \n def _posix_split_name(self, name):\n  \"\"\n  prefix = name[:LENGTH_PREFIX + 1]\n  while prefix and prefix[-1] != \"/\":\n   prefix = prefix[:-1]\n   \n  name = name[len(prefix):]\n  prefix = prefix[:-1]\n  \n  if not prefix or len(name) > LENGTH_NAME:\n   raise ValueError(\"name is too long\")\n  return prefix, name\n  \n @staticmethod\n def _create_header(info, format, encoding, errors):\n  \"\"\n  parts = [\n  stn(info.get(\"name\", \"\"), 100, encoding, errors),\n  itn(info.get(\"mode\", 0) & 0o7777, 8, format),\n  itn(info.get(\"uid\", 0), 8, format),\n  itn(info.get(\"gid\", 0), 8, format),\n  itn(info.get(\"size\", 0), 12, format),\n  itn(info.get(\"mtime\", 0), 12, format),\n  b\"        \", \n  info.get(\"type\", REGTYPE),\n  stn(info.get(\"linkname\", \"\"), 100, encoding, errors),\n  info.get(\"magic\", POSIX_MAGIC),\n  stn(info.get(\"uname\", \"\"), 32, encoding, errors),\n  stn(info.get(\"gname\", \"\"), 32, encoding, errors),\n  itn(info.get(\"devmajor\", 0), 8, format),\n  itn(info.get(\"devminor\", 0), 8, format),\n  stn(info.get(\"prefix\", \"\"), 155, encoding, errors)\n  ]\n  \n  buf = struct.pack(\"%ds\" % BLOCKSIZE, b\"\".join(parts))\n  chksum = calc_chksums(buf[-BLOCKSIZE:])[0]\n  buf = buf[:-364] + bytes(\"%06o\\0\" % chksum, \"ascii\") + buf[-357:]\n  return buf\n  \n @staticmethod\n def _create_payload(payload):\n  \"\"\n  blocks, remainder = divmod(len(payload), BLOCKSIZE)\n  if remainder > 0:\n   payload += (BLOCKSIZE - remainder) * NUL\n  return payload\n  \n @classmethod\n def _create_gnu_long_header(cls, name, type, encoding, errors):\n  \"\"\n  name = name.encode(encoding, errors) + NUL\n  \n  info = {}\n  info[\"name\"] = \"././@LongLink\"\n  info[\"type\"] = type\n  info[\"size\"] = len(name)\n  info[\"magic\"] = GNU_MAGIC\n  \n  \n  return cls._create_header(info, USTAR_FORMAT, encoding, errors) + cls._create_payload(name)\n  \n @classmethod\n def _create_pax_generic_header(cls, pax_headers, type, encoding):\n  \"\"\n  \n  \n  binary = False\n  for keyword, value in pax_headers.items():\n   try:\n    value.encode(\"utf-8\", \"strict\")\n   except UnicodeEncodeError:\n    binary = True\n    break\n    \n  records = b\"\"\n  if binary:\n  \n   records += b\"21 hdrcharset=BINARY\\n\"\n   \n  for keyword, value in pax_headers.items():\n   keyword = keyword.encode(\"utf-8\")\n   if binary:\n   \n   \n    value = value.encode(encoding, \"surrogateescape\")\n   else:\n    value = value.encode(\"utf-8\")\n    \n   l = len(keyword) + len(value) + 3 \n   n = p = 0\n   while True:\n    n = l + len(str(p))\n    if n == p:\n     break\n    p = n\n   records += bytes(str(p), \"ascii\") + b\" \" + keyword + b\"=\" + value + b\"\\n\"\n   \n   \n   \n  info = {}\n  info[\"name\"] = \"././@PaxHeader\"\n  info[\"type\"] = type\n  info[\"size\"] = len(records)\n  info[\"magic\"] = POSIX_MAGIC\n  \n  \n  return cls._create_header(info, USTAR_FORMAT, \"ascii\", \"replace\") + cls._create_payload(records)\n  \n @classmethod\n def frombuf(cls, buf, encoding, errors):\n  \"\"\n  if len(buf) == 0:\n   raise EmptyHeaderError(\"empty header\")\n  if len(buf) != BLOCKSIZE:\n   raise TruncatedHeaderError(\"truncated header\")\n  if buf.count(NUL) == BLOCKSIZE:\n   raise EOFHeaderError(\"end of file header\")\n   \n  chksum = nti(buf[148:156])\n  if chksum not in calc_chksums(buf):\n   raise InvalidHeaderError(\"bad checksum\")\n   \n  obj = cls()\n  obj.name = nts(buf[0:100], encoding, errors)\n  obj.mode = nti(buf[100:108])\n  obj.uid = nti(buf[108:116])\n  obj.gid = nti(buf[116:124])\n  obj.size = nti(buf[124:136])\n  obj.mtime = nti(buf[136:148])\n  obj.chksum = chksum\n  obj.type = buf[156:157]\n  obj.linkname = nts(buf[157:257], encoding, errors)\n  obj.uname = nts(buf[265:297], encoding, errors)\n  obj.gname = nts(buf[297:329], encoding, errors)\n  obj.devmajor = nti(buf[329:337])\n  obj.devminor = nti(buf[337:345])\n  prefix = nts(buf[345:500], encoding, errors)\n  \n  \n  \n  if obj.type == AREGTYPE and obj.name.endswith(\"/\"):\n   obj.type = DIRTYPE\n   \n   \n   \n   \n  if obj.type == GNUTYPE_SPARSE:\n   pos = 386\n   structs = []\n   for i in range(4):\n    try:\n     offset = nti(buf[pos:pos + 12])\n     numbytes = nti(buf[pos + 12:pos + 24])\n    except ValueError:\n     break\n    structs.append((offset, numbytes))\n    pos += 24\n   isextended = bool(buf[482])\n   origsize = nti(buf[483:495])\n   obj._sparse_structs = (structs, isextended, origsize)\n   \n   \n  if obj.isdir():\n   obj.name = obj.name.rstrip(\"/\")\n   \n   \n  if prefix and obj.type not in GNU_TYPES:\n   obj.name = prefix + \"/\" + obj.name\n  return obj\n  \n @classmethod\n def fromtarfile(cls, tarfile):\n  \"\"\n  buf = tarfile.fileobj.read(BLOCKSIZE)\n  obj = cls.frombuf(buf, tarfile.encoding, tarfile.errors)\n  obj.offset = tarfile.fileobj.tell() - BLOCKSIZE\n  return obj._proc_member(tarfile)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def _proc_member(self, tarfile):\n  \"\"\n  if self.type in (GNUTYPE_LONGNAME, GNUTYPE_LONGLINK):\n   return self._proc_gnulong(tarfile)\n  elif self.type == GNUTYPE_SPARSE:\n   return self._proc_sparse(tarfile)\n  elif self.type in (XHDTYPE, XGLTYPE, SOLARIS_XHDTYPE):\n   return self._proc_pax(tarfile)\n  else:\n   return self._proc_builtin(tarfile)\n   \n def _proc_builtin(self, tarfile):\n  \"\"\n  self.offset_data = tarfile.fileobj.tell()\n  offset = self.offset_data\n  if self.isreg() or self.type not in SUPPORTED_TYPES:\n  \n   offset += self._block(self.size)\n  tarfile.offset = offset\n  \n  \n  \n  self._apply_pax_info(tarfile.pax_headers, tarfile.encoding, tarfile.errors)\n  \n  return self\n  \n def _proc_gnulong(self, tarfile):\n  \"\"\n  buf = tarfile.fileobj.read(self._block(self.size))\n  \n  \n  try:\n   next = self.fromtarfile(tarfile)\n  except HeaderError:\n   raise SubsequentHeaderError(\"missing or bad subsequent header\")\n   \n   \n   \n  next.offset = self.offset\n  if self.type == GNUTYPE_LONGNAME:\n   next.name = nts(buf, tarfile.encoding, tarfile.errors)\n  elif self.type == GNUTYPE_LONGLINK:\n   next.linkname = nts(buf, tarfile.encoding, tarfile.errors)\n   \n  return next\n  \n def _proc_sparse(self, tarfile):\n  \"\"\n  \n  structs, isextended, origsize = self._sparse_structs\n  del self._sparse_structs\n  \n  \n  while isextended:\n   buf = tarfile.fileobj.read(BLOCKSIZE)\n   pos = 0\n   for i in range(21):\n    try:\n     offset = nti(buf[pos:pos + 12])\n     numbytes = nti(buf[pos + 12:pos + 24])\n    except ValueError:\n     break\n    if offset and numbytes:\n     structs.append((offset, numbytes))\n    pos += 24\n   isextended = bool(buf[504])\n  self.sparse = structs\n  \n  self.offset_data = tarfile.fileobj.tell()\n  tarfile.offset = self.offset_data + self._block(self.size)\n  self.size = origsize\n  return self\n  \n def _proc_pax(self, tarfile):\n  \"\"\n  \n  buf = tarfile.fileobj.read(self._block(self.size))\n  \n  \n  \n  \n  if self.type == XGLTYPE:\n   pax_headers = tarfile.pax_headers\n  else:\n   pax_headers = tarfile.pax_headers.copy()\n   \n   \n   \n   \n   \n   \n  match = re.search(br\"\\d+ hdrcharset=([^\\n]+)\\n\", buf)\n  if match is not None:\n   pax_headers[\"hdrcharset\"] = match.group(1).decode(\"utf-8\")\n   \n   \n   \n   \n  hdrcharset = pax_headers.get(\"hdrcharset\")\n  if hdrcharset == \"BINARY\":\n   encoding = tarfile.encoding\n  else:\n   encoding = \"utf-8\"\n   \n   \n   \n   \n   \n  regex = re.compile(br\"(\\d+) ([^=]+)=\")\n  pos = 0\n  while True:\n   match = regex.match(buf, pos)\n   if not match:\n    break\n    \n   length, keyword = match.groups()\n   length = int(length)\n   value = buf[match.end(2) + 1:match.start(1) + length - 1]\n   \n   \n   \n   \n   \n   \n   \n   \n   keyword = self._decode_pax_field(keyword, \"utf-8\", \"utf-8\",\n   tarfile.errors)\n   if keyword in PAX_NAME_FIELDS:\n    value = self._decode_pax_field(value, encoding, tarfile.encoding,\n    tarfile.errors)\n   else:\n    value = self._decode_pax_field(value, \"utf-8\", \"utf-8\",\n    tarfile.errors)\n    \n   pax_headers[keyword] = value\n   pos += length\n   \n   \n  try:\n   next = self.fromtarfile(tarfile)\n  except HeaderError:\n   raise SubsequentHeaderError(\"missing or bad subsequent header\")\n   \n   \n  if \"GNU.sparse.map\" in pax_headers:\n  \n   self._proc_gnusparse_01(next, pax_headers)\n   \n  elif \"GNU.sparse.size\" in pax_headers:\n  \n   self._proc_gnusparse_00(next, pax_headers, buf)\n   \n  elif pax_headers.get(\"GNU.sparse.major\") == \"1\" and pax_headers.get(\"GNU.sparse.minor\") == \"0\":\n  \n   self._proc_gnusparse_10(next, pax_headers, tarfile)\n   \n  if self.type in (XHDTYPE, SOLARIS_XHDTYPE):\n  \n   next._apply_pax_info(pax_headers, tarfile.encoding, tarfile.errors)\n   next.offset = self.offset\n   \n   if \"size\" in pax_headers:\n   \n   \n   \n    offset = next.offset_data\n    if next.isreg() or next.type not in SUPPORTED_TYPES:\n     offset += next._block(next.size)\n    tarfile.offset = offset\n    \n  return next\n  \n def _proc_gnusparse_00(self, next, pax_headers, buf):\n  \"\"\n  offsets = []\n  for match in re.finditer(br\"\\d+ GNU.sparse.offset=(\\d+)\\n\", buf):\n   offsets.append(int(match.group(1)))\n  numbytes = []\n  for match in re.finditer(br\"\\d+ GNU.sparse.numbytes=(\\d+)\\n\", buf):\n   numbytes.append(int(match.group(1)))\n  next.sparse = list(zip(offsets, numbytes))\n  \n def _proc_gnusparse_01(self, next, pax_headers):\n  \"\"\n  sparse = [int(x) for x in pax_headers[\"GNU.sparse.map\"].split(\",\")]\n  next.sparse = list(zip(sparse[::2], sparse[1::2]))\n  \n def _proc_gnusparse_10(self, next, pax_headers, tarfile):\n  \"\"\n  fields = None\n  sparse = []\n  buf = tarfile.fileobj.read(BLOCKSIZE)\n  fields, buf = buf.split(b\"\\n\", 1)\n  fields = int(fields)\n  while len(sparse) < fields * 2:\n   if b\"\\n\" not in buf:\n    buf += tarfile.fileobj.read(BLOCKSIZE)\n   number, buf = buf.split(b\"\\n\", 1)\n   sparse.append(int(number))\n  next.offset_data = tarfile.fileobj.tell()\n  next.sparse = list(zip(sparse[::2], sparse[1::2]))\n  \n def _apply_pax_info(self, pax_headers, encoding, errors):\n  \"\"\n  for keyword, value in pax_headers.items():\n   if keyword == \"GNU.sparse.name\":\n    setattr(self, \"path\", value)\n   elif keyword == \"GNU.sparse.size\":\n    setattr(self, \"size\", int(value))\n   elif keyword == \"GNU.sparse.realsize\":\n    setattr(self, \"size\", int(value))\n   elif keyword in PAX_FIELDS:\n    if keyword in PAX_NUMBER_FIELDS:\n     try:\n      value = PAX_NUMBER_FIELDS[keyword](value)\n     except ValueError:\n      value = 0\n    if keyword == \"path\":\n     value = value.rstrip(\"/\")\n    setattr(self, keyword, value)\n    \n  self.pax_headers = pax_headers.copy()\n  \n def _decode_pax_field(self, value, encoding, fallback_encoding, fallback_errors):\n  \"\"\n  try:\n   return value.decode(encoding, \"strict\")\n  except UnicodeDecodeError:\n   return value.decode(fallback_encoding, fallback_errors)\n   \n def _block(self, count):\n  \"\"\n  blocks, remainder = divmod(count, BLOCKSIZE)\n  if remainder:\n   blocks += 1\n  return blocks * BLOCKSIZE\n  \n def isreg(self):\n  return self.type in REGULAR_TYPES\n def isfile(self):\n  return self.isreg()\n def isdir(self):\n  return self.type == DIRTYPE\n def issym(self):\n  return self.type == SYMTYPE\n def islnk(self):\n  return self.type == LNKTYPE\n def ischr(self):\n  return self.type == CHRTYPE\n def isblk(self):\n  return self.type == BLKTYPE\n def isfifo(self):\n  return self.type == FIFOTYPE\n def issparse(self):\n  return self.sparse is not None\n def isdev(self):\n  return self.type in (CHRTYPE, BLKTYPE, FIFOTYPE)\n  \n  \nclass TarFile(object):\n \"\"\n \n debug = 0 \n \n dereference = False \n \n \n ignore_zeros = False \n \n \n errorlevel = 1 \n \n \n \n format = DEFAULT_FORMAT \n \n encoding = ENCODING \n \n errors = None \n \n tarinfo = TarInfo \n \n fileobject = ExFileObject \n \n def __init__(self, name=None, mode=\"r\", fileobj=None, format=None,\n tarinfo=None, dereference=None, ignore_zeros=None, encoding=None,\n errors=\"surrogateescape\", pax_headers=None, debug=None, errorlevel=None):\n  \"\"\n  if len(mode) > 1 or mode not in \"raw\":\n   raise ValueError(\"mode must be 'r', 'a' or 'w'\")\n  self.mode = mode\n  self._mode = {\"r\": \"rb\", \"a\": \"r+b\", \"w\": \"wb\"}[mode]\n  \n  if not fileobj:\n   if self.mode == \"a\" and not os.path.exists(name):\n   \n    self.mode = \"w\"\n    self._mode = \"wb\"\n   fileobj = bltn_open(name, self._mode)\n   self._extfileobj = False\n  else:\n   if name is None and hasattr(fileobj, \"name\"):\n    name = fileobj.name\n   if hasattr(fileobj, \"mode\"):\n    self._mode = fileobj.mode\n   self._extfileobj = True\n  self.name = os.path.abspath(name) if name else None\n  self.fileobj = fileobj\n  \n  \n  if format is not None:\n   self.format = format\n  if tarinfo is not None:\n   self.tarinfo = tarinfo\n  if dereference is not None:\n   self.dereference = dereference\n  if ignore_zeros is not None:\n   self.ignore_zeros = ignore_zeros\n  if encoding is not None:\n   self.encoding = encoding\n  self.errors = errors\n  \n  if pax_headers is not None and self.format == PAX_FORMAT:\n   self.pax_headers = pax_headers\n  else:\n   self.pax_headers = {}\n   \n  if debug is not None:\n   self.debug = debug\n  if errorlevel is not None:\n   self.errorlevel = errorlevel\n   \n   \n  self.closed = False\n  self.members = [] \n  self._loaded = False \n  self.offset = self.fileobj.tell()\n  \n  self.inodes = {} \n  \n  \n  try:\n   if self.mode == \"r\":\n    self.firstmember = None\n    self.firstmember = self.next()\n    \n   if self.mode == \"a\":\n   \n   \n    while True:\n     self.fileobj.seek(self.offset)\n     try:\n      tarinfo = self.tarinfo.fromtarfile(self)\n      self.members.append(tarinfo)\n     except EOFHeaderError:\n      self.fileobj.seek(self.offset)\n      break\n     except HeaderError as e:\n      raise ReadError(str(e))\n      \n   if self.mode in \"aw\":\n    self._loaded = True\n    \n    if self.pax_headers:\n     buf = self.tarinfo.create_pax_global_header(self.pax_headers.copy())\n     self.fileobj.write(buf)\n     self.offset += len(buf)\n  except:\n   if not self._extfileobj:\n    self.fileobj.close()\n   self.closed = True\n   raise\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n @classmethod\n def open(cls, name=None, mode=\"r\", fileobj=None, bufsize=RECORDSIZE, **kwargs):\n  \"\"\n  \n  if not name and not fileobj:\n   raise ValueError(\"nothing to open\")\n   \n  if mode in (\"r\", \"r:*\"):\n  \n   for comptype in cls.OPEN_METH:\n    func = getattr(cls, cls.OPEN_METH[comptype])\n    if fileobj is not None:\n     saved_pos = fileobj.tell()\n    try:\n     return func(name, \"r\", fileobj, **kwargs)\n    except (ReadError, CompressionError) as e:\n     if fileobj is not None:\n      fileobj.seek(saved_pos)\n     continue\n   raise ReadError(\"file could not be opened successfully\")\n   \n  elif \":\" in mode:\n   filemode, comptype = mode.split(\":\", 1)\n   filemode = filemode or \"r\"\n   comptype = comptype or \"tar\"\n   \n   \n   \n   if comptype in cls.OPEN_METH:\n    func = getattr(cls, cls.OPEN_METH[comptype])\n   else:\n    raise CompressionError(\"unknown compression type %r\" % comptype)\n   return func(name, filemode, fileobj, **kwargs)\n   \n  elif \"|\" in mode:\n   filemode, comptype = mode.split(\"|\", 1)\n   filemode = filemode or \"r\"\n   comptype = comptype or \"tar\"\n   \n   if filemode not in \"rw\":\n    raise ValueError(\"mode must be 'r' or 'w'\")\n    \n   stream = _Stream(name, filemode, comptype, fileobj, bufsize)\n   try:\n    t = cls(name, filemode, stream, **kwargs)\n   except:\n    stream.close()\n    raise\n   t._extfileobj = False\n   return t\n   \n  elif mode in \"aw\":\n   return cls.taropen(name, mode, fileobj, **kwargs)\n   \n  raise ValueError(\"undiscernible mode\")\n  \n @classmethod\n def taropen(cls, name, mode=\"r\", fileobj=None, **kwargs):\n  \"\"\n  if len(mode) > 1 or mode not in \"raw\":\n   raise ValueError(\"mode must be 'r', 'a' or 'w'\")\n  return cls(name, mode, fileobj, **kwargs)\n  \n @classmethod\n def gzopen(cls, name, mode=\"r\", fileobj=None, compresslevel=9, **kwargs):\n  \"\"\n  if len(mode) > 1 or mode not in \"rw\":\n   raise ValueError(\"mode must be 'r' or 'w'\")\n   \n  try:\n   import gzip\n   gzip.GzipFile\n  except (ImportError, AttributeError):\n   raise CompressionError(\"gzip module is not available\")\n   \n  extfileobj = fileobj is not None\n  try:\n   fileobj = gzip.GzipFile(name, mode + \"b\", compresslevel, fileobj)\n   t = cls.taropen(name, mode, fileobj, **kwargs)\n  except IOError:\n   if not extfileobj and fileobj is not None:\n    fileobj.close()\n   if fileobj is None:\n    raise\n   raise ReadError(\"not a gzip file\")\n  except:\n   if not extfileobj and fileobj is not None:\n    fileobj.close()\n   raise\n  t._extfileobj = extfileobj\n  return t\n  \n @classmethod\n def bz2open(cls, name, mode=\"r\", fileobj=None, compresslevel=9, **kwargs):\n  \"\"\n  if len(mode) > 1 or mode not in \"rw\":\n   raise ValueError(\"mode must be 'r' or 'w'.\")\n   \n  try:\n   import bz2\n  except ImportError:\n   raise CompressionError(\"bz2 module is not available\")\n   \n  fileobj = bz2.BZ2File(fileobj or name, mode,\n  compresslevel=compresslevel)\n  \n  try:\n   t = cls.taropen(name, mode, fileobj, **kwargs)\n  except (IOError, EOFError):\n   fileobj.close()\n   raise ReadError(\"not a bzip2 file\")\n  t._extfileobj = False\n  return t\n  \n @classmethod\n def xzopen(cls, name, mode=\"r\", fileobj=None, preset=None, **kwargs):\n  \"\"\n  if mode not in (\"r\", \"w\"):\n   raise ValueError(\"mode must be 'r' or 'w'\")\n   \n  try:\n   import lzma\n  except ImportError:\n   raise CompressionError(\"lzma module is not available\")\n   \n  fileobj = lzma.LZMAFile(fileobj or name, mode, preset=preset)\n  \n  try:\n   t = cls.taropen(name, mode, fileobj, **kwargs)\n  except (lzma.LZMAError, EOFError):\n   fileobj.close()\n   raise ReadError(\"not an lzma file\")\n  t._extfileobj = False\n  return t\n  \n  \n OPEN_METH = {\n \"tar\": \"taropen\", \n \"gz\": \"gzopen\", \n \"bz2\": \"bz2open\", \n \"xz\": \"xzopen\" \n }\n \n \n \n \n def close(self):\n  \"\"\n  if self.closed:\n   return\n   \n  if self.mode in \"aw\":\n   self.fileobj.write(NUL * (BLOCKSIZE * 2))\n   self.offset += (BLOCKSIZE * 2)\n   \n   \n   blocks, remainder = divmod(self.offset, RECORDSIZE)\n   if remainder > 0:\n    self.fileobj.write(NUL * (RECORDSIZE - remainder))\n    \n  if not self._extfileobj:\n   self.fileobj.close()\n  self.closed = True\n  \n def getmember(self, name):\n  \"\"\n  tarinfo = self._getmember(name)\n  if tarinfo is None:\n   raise KeyError(\"filename %r not found\" % name)\n  return tarinfo\n  \n def getmembers(self):\n  \"\"\n  self._check()\n  if not self._loaded: \n   self._load() \n   \n  return self.members\n  \n def getnames(self):\n  \"\"\n  return [tarinfo.name for tarinfo in self.getmembers()]\n  \n def gettarinfo(self, name=None, arcname=None, fileobj=None):\n  \"\"\n  self._check(\"aw\")\n  \n  \n  \n  if fileobj is not None:\n   name = fileobj.name\n   \n   \n   \n   \n  if arcname is None:\n   arcname = name\n  drv, arcname = os.path.splitdrive(arcname)\n  arcname = arcname.replace(os.sep, \"/\")\n  arcname = arcname.lstrip(\"/\")\n  \n  \n  \n  tarinfo = self.tarinfo()\n  tarinfo.tarfile = self\n  \n  \n  \n  if fileobj is None:\n   if hasattr(os, \"lstat\") and not self.dereference:\n    statres = os.lstat(name)\n   else:\n    statres = os.stat(name)\n  else:\n   statres = os.fstat(fileobj.fileno())\n  linkname = \"\"\n  \n  stmd = statres.st_mode\n  if stat.S_ISREG(stmd):\n   inode = (statres.st_ino, statres.st_dev)\n   if not self.dereference and statres.st_nlink > 1 and inode in self.inodes and arcname != self.inodes[inode]:\n   \n   \n    type = LNKTYPE\n    linkname = self.inodes[inode]\n   else:\n   \n   \n    type = REGTYPE\n    if inode[0]:\n     self.inodes[inode] = arcname\n  elif stat.S_ISDIR(stmd):\n   type = DIRTYPE\n  elif stat.S_ISFIFO(stmd):\n   type = FIFOTYPE\n  elif stat.S_ISLNK(stmd):\n   type = SYMTYPE\n   linkname = os.readlink(name)\n  elif stat.S_ISCHR(stmd):\n   type = CHRTYPE\n  elif stat.S_ISBLK(stmd):\n   type = BLKTYPE\n  else:\n   return None\n   \n   \n   \n  tarinfo.name = arcname\n  tarinfo.mode = stmd\n  tarinfo.uid = statres.st_uid\n  tarinfo.gid = statres.st_gid\n  if type == REGTYPE:\n   tarinfo.size = statres.st_size\n  else:\n   tarinfo.size = 0\n  tarinfo.mtime = statres.st_mtime\n  tarinfo.type = type\n  tarinfo.linkname = linkname\n  if pwd:\n   try:\n    tarinfo.uname = pwd.getpwuid(tarinfo.uid)[0]\n   except KeyError:\n    pass\n  if grp:\n   try:\n    tarinfo.gname = grp.getgrgid(tarinfo.gid)[0]\n   except KeyError:\n    pass\n    \n  if type in (CHRTYPE, BLKTYPE):\n   if hasattr(os, \"major\") and hasattr(os, \"minor\"):\n    tarinfo.devmajor = os.major(statres.st_rdev)\n    tarinfo.devminor = os.minor(statres.st_rdev)\n  return tarinfo\n  \n def list(self, verbose=True):\n  \"\"\n  self._check()\n  \n  for tarinfo in self:\n   if verbose:\n    print(stat.filemode(tarinfo.mode), end=' ')\n    print(\"%s/%s\" % (tarinfo.uname or tarinfo.uid,\n    tarinfo.gname or tarinfo.gid), end=' ')\n    if tarinfo.ischr() or tarinfo.isblk():\n     print(\"%10s\" % (\"%d,%d\" % (tarinfo.devmajor, tarinfo.devminor)), end=' ')\n    else:\n     print(\"%10d\" % tarinfo.size, end=' ')\n    print(\"%d-%02d-%02d %02d:%02d:%02d\" % time.localtime(tarinfo.mtime)[:6], end=' ')\n    \n   print(tarinfo.name + (\"/\" if tarinfo.isdir() else \"\"), end=' ')\n   \n   if verbose:\n    if tarinfo.issym():\n     print(\"->\", tarinfo.linkname, end=' ')\n    if tarinfo.islnk():\n     print(\"link to\", tarinfo.linkname, end=' ')\n   print()\n   \n def add(self, name, arcname=None, recursive=True, exclude=None, *, filter=None):\n  \"\"\n  self._check(\"aw\")\n  \n  if arcname is None:\n   arcname = name\n   \n   \n  if exclude is not None:\n   import warnings\n   warnings.warn(\"use the filter argument instead\",\n   DeprecationWarning, 2)\n   if exclude(name):\n    self._dbg(2, \"tarfile: Excluded %r\" % name)\n    return\n    \n    \n  if self.name is not None and os.path.abspath(name) == self.name:\n   self._dbg(2, \"tarfile: Skipped %r\" % name)\n   return\n   \n  self._dbg(1, name)\n  \n  \n  tarinfo = self.gettarinfo(name, arcname)\n  \n  if tarinfo is None:\n   self._dbg(1, \"tarfile: Unsupported type %r\" % name)\n   return\n   \n   \n  if filter is not None:\n   tarinfo = filter(tarinfo)\n   if tarinfo is None:\n    self._dbg(2, \"tarfile: Excluded %r\" % name)\n    return\n    \n    \n  if tarinfo.isreg():\n   with bltn_open(name, \"rb\") as f:\n    self.addfile(tarinfo, f)\n    \n  elif tarinfo.isdir():\n   self.addfile(tarinfo)\n   if recursive:\n    for f in os.listdir(name):\n     self.add(os.path.join(name, f), os.path.join(arcname, f),\n     recursive, exclude, filter=filter)\n     \n  else:\n   self.addfile(tarinfo)\n   \n def addfile(self, tarinfo, fileobj=None):\n  \"\"\n  self._check(\"aw\")\n  \n  tarinfo = copy.copy(tarinfo)\n  \n  buf = tarinfo.tobuf(self.format, self.encoding, self.errors)\n  self.fileobj.write(buf)\n  self.offset += len(buf)\n  \n  \n  if fileobj is not None:\n   copyfileobj(fileobj, self.fileobj, tarinfo.size)\n   blocks, remainder = divmod(tarinfo.size, BLOCKSIZE)\n   if remainder > 0:\n    self.fileobj.write(NUL * (BLOCKSIZE - remainder))\n    blocks += 1\n   self.offset += blocks * BLOCKSIZE\n   \n  self.members.append(tarinfo)\n  \n def extractall(self, path=\".\", members=None):\n  \"\"\n  directories = []\n  \n  if members is None:\n   members = self\n   \n  for tarinfo in members:\n   if tarinfo.isdir():\n   \n    directories.append(tarinfo)\n    tarinfo = copy.copy(tarinfo)\n    tarinfo.mode = 0o700\n    \n   self.extract(tarinfo, path, set_attrs=not tarinfo.isdir())\n   \n   \n  directories.sort(key=lambda a: a.name)\n  directories.reverse()\n  \n  \n  for tarinfo in directories:\n   dirpath = os.path.join(path, tarinfo.name)\n   try:\n    self.chown(tarinfo, dirpath)\n    self.utime(tarinfo, dirpath)\n    self.chmod(tarinfo, dirpath)\n   except ExtractError as e:\n    if self.errorlevel > 1:\n     raise\n    else:\n     self._dbg(1, \"tarfile: %s\" % e)\n     \n def extract(self, member, path=\"\", set_attrs=True):\n  \"\"\n  self._check(\"r\")\n  \n  if isinstance(member, str):\n   tarinfo = self.getmember(member)\n  else:\n   tarinfo = member\n   \n   \n  if tarinfo.islnk():\n   tarinfo._link_target = os.path.join(path, tarinfo.linkname)\n   \n  try:\n   self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n   set_attrs=set_attrs)\n  except EnvironmentError as e:\n   if self.errorlevel > 0:\n    raise\n   else:\n    if e.filename is None:\n     self._dbg(1, \"tarfile: %s\" % e.strerror)\n    else:\n     self._dbg(1, \"tarfile: %s %r\" % (e.strerror, e.filename))\n  except ExtractError as e:\n   if self.errorlevel > 1:\n    raise\n   else:\n    self._dbg(1, \"tarfile: %s\" % e)\n    \n def extractfile(self, member):\n  \"\"\n  self._check(\"r\")\n  \n  if isinstance(member, str):\n   tarinfo = self.getmember(member)\n  else:\n   tarinfo = member\n   \n  if tarinfo.isreg() or tarinfo.type not in SUPPORTED_TYPES:\n  \n   return self.fileobject(self, tarinfo)\n   \n  elif tarinfo.islnk() or tarinfo.issym():\n   if isinstance(self.fileobj, _Stream):\n   \n   \n   \n    raise StreamError(\"cannot extract (sym)link as file object\")\n   else:\n   \n    return self.extractfile(self._find_link_target(tarinfo))\n  else:\n  \n  \n   return None\n   \n def _extract_member(self, tarinfo, targetpath, set_attrs=True):\n  \"\"\n  \n  \n  \n  targetpath = targetpath.rstrip(\"/\")\n  targetpath = targetpath.replace(\"/\", os.sep)\n  \n  \n  upperdirs = os.path.dirname(targetpath)\n  if upperdirs and not os.path.exists(upperdirs):\n  \n  \n   os.makedirs(upperdirs)\n   \n  if tarinfo.islnk() or tarinfo.issym():\n   self._dbg(1, \"%s -> %s\" % (tarinfo.name, tarinfo.linkname))\n  else:\n   self._dbg(1, tarinfo.name)\n   \n  if tarinfo.isreg():\n   self.makefile(tarinfo, targetpath)\n  elif tarinfo.isdir():\n   self.makedir(tarinfo, targetpath)\n  elif tarinfo.isfifo():\n   self.makefifo(tarinfo, targetpath)\n  elif tarinfo.ischr() or tarinfo.isblk():\n   self.makedev(tarinfo, targetpath)\n  elif tarinfo.islnk() or tarinfo.issym():\n   self.makelink(tarinfo, targetpath)\n  elif tarinfo.type not in SUPPORTED_TYPES:\n   self.makeunknown(tarinfo, targetpath)\n  else:\n   self.makefile(tarinfo, targetpath)\n   \n  if set_attrs:\n   self.chown(tarinfo, targetpath)\n   if not tarinfo.issym():\n    self.chmod(tarinfo, targetpath)\n    self.utime(tarinfo, targetpath)\n    \n    \n    \n    \n    \n    \n def makedir(self, tarinfo, targetpath):\n  \"\"\n  try:\n  \n  \n   os.mkdir(targetpath, 0o700)\n  except FileExistsError:\n   pass\n   \n def makefile(self, tarinfo, targetpath):\n  \"\"\n  source = self.fileobj\n  source.seek(tarinfo.offset_data)\n  with bltn_open(targetpath, \"wb\") as target:\n   if tarinfo.sparse is not None:\n    for offset, size in tarinfo.sparse:\n     target.seek(offset)\n     copyfileobj(source, target, size)\n   else:\n    copyfileobj(source, target, tarinfo.size)\n   target.seek(tarinfo.size)\n   target.truncate()\n   \n def makeunknown(self, tarinfo, targetpath):\n  \"\"\n  self.makefile(tarinfo, targetpath)\n  self._dbg(1, \"tarfile: Unknown file type %r, \" \"extracted as regular file.\" % tarinfo.type)\n  \n def makefifo(self, tarinfo, targetpath):\n  \"\"\n  if hasattr(os, \"mkfifo\"):\n   os.mkfifo(targetpath)\n  else:\n   raise ExtractError(\"fifo not supported by system\")\n   \n def makedev(self, tarinfo, targetpath):\n  \"\"\n  if not hasattr(os, \"mknod\") or not hasattr(os, \"makedev\"):\n   raise ExtractError(\"special devices not supported by system\")\n   \n  mode = tarinfo.mode\n  if tarinfo.isblk():\n   mode |= stat.S_IFBLK\n  else:\n   mode |= stat.S_IFCHR\n   \n  os.mknod(targetpath, mode,\n  os.makedev(tarinfo.devmajor, tarinfo.devminor))\n  \n def makelink(self, tarinfo, targetpath):\n  \"\"\n  try:\n  \n   if tarinfo.issym():\n    os.symlink(tarinfo.linkname, targetpath)\n   else:\n   \n    if os.path.exists(tarinfo._link_target):\n     os.link(tarinfo._link_target, targetpath)\n    else:\n     self._extract_member(self._find_link_target(tarinfo),\n     targetpath)\n  except symlink_exception:\n   try:\n    self._extract_member(self._find_link_target(tarinfo),\n    targetpath)\n   except KeyError:\n    raise ExtractError(\"unable to resolve link inside archive\")\n    \n def chown(self, tarinfo, targetpath):\n  \"\"\n  if pwd and hasattr(os, \"geteuid\") and os.geteuid() == 0:\n  \n   try:\n    g = grp.getgrnam(tarinfo.gname)[2]\n   except KeyError:\n    g = tarinfo.gid\n   try:\n    u = pwd.getpwnam(tarinfo.uname)[2]\n   except KeyError:\n    u = tarinfo.uid\n   try:\n    if tarinfo.issym() and hasattr(os, \"lchown\"):\n     os.lchown(targetpath, u, g)\n    else:\n     if sys.platform != \"os2emx\":\n      os.chown(targetpath, u, g)\n   except EnvironmentError as e:\n    raise ExtractError(\"could not change owner\")\n    \n def chmod(self, tarinfo, targetpath):\n  \"\"\n  if hasattr(os, 'chmod'):\n   try:\n    os.chmod(targetpath, tarinfo.mode)\n   except EnvironmentError as e:\n    raise ExtractError(\"could not change mode\")\n    \n def utime(self, tarinfo, targetpath):\n  \"\"\n  if not hasattr(os, 'utime'):\n   return\n  try:\n   os.utime(targetpath, (tarinfo.mtime, tarinfo.mtime))\n  except EnvironmentError as e:\n   raise ExtractError(\"could not change modification time\")\n   \n   \n def next(self):\n  \"\"\n  self._check(\"ra\")\n  if self.firstmember is not None:\n   m = self.firstmember\n   self.firstmember = None\n   return m\n   \n   \n  self.fileobj.seek(self.offset)\n  tarinfo = None\n  while True:\n   try:\n    tarinfo = self.tarinfo.fromtarfile(self)\n   except EOFHeaderError as e:\n    if self.ignore_zeros:\n     self._dbg(2, \"0x%X: %s\" % (self.offset, e))\n     self.offset += BLOCKSIZE\n     continue\n   except InvalidHeaderError as e:\n    if self.ignore_zeros:\n     self._dbg(2, \"0x%X: %s\" % (self.offset, e))\n     self.offset += BLOCKSIZE\n     continue\n    elif self.offset == 0:\n     raise ReadError(str(e))\n   except EmptyHeaderError:\n    if self.offset == 0:\n     raise ReadError(\"empty file\")\n   except TruncatedHeaderError as e:\n    if self.offset == 0:\n     raise ReadError(str(e))\n   except SubsequentHeaderError as e:\n    raise ReadError(str(e))\n   break\n   \n  if tarinfo is not None:\n   self.members.append(tarinfo)\n  else:\n   self._loaded = True\n   \n  return tarinfo\n  \n  \n  \n  \n def _getmember(self, name, tarinfo=None, normalize=False):\n  \"\"\n  \n  members = self.getmembers()\n  \n  \n  if tarinfo is not None:\n   members = members[:members.index(tarinfo)]\n   \n  if normalize:\n   name = os.path.normpath(name)\n   \n  for member in reversed(members):\n   if normalize:\n    member_name = os.path.normpath(member.name)\n   else:\n    member_name = member.name\n    \n   if name == member_name:\n    return member\n    \n def _load(self):\n  \"\"\n  while True:\n   tarinfo = self.next()\n   if tarinfo is None:\n    break\n  self._loaded = True\n  \n def _check(self, mode=None):\n  \"\"\n  if self.closed:\n   raise IOError(\"%s is closed\" % self.__class__.__name__)\n  if mode is not None and self.mode not in mode:\n   raise IOError(\"bad operation for mode %r\" % self.mode)\n   \n def _find_link_target(self, tarinfo):\n  \"\"\n  if tarinfo.issym():\n  \n   linkname = \"/\".join(filter(None, (os.path.dirname(tarinfo.name), tarinfo.linkname)))\n   limit = None\n  else:\n  \n  \n   linkname = tarinfo.linkname\n   limit = tarinfo\n   \n  member = self._getmember(linkname, tarinfo=limit, normalize=True)\n  if member is None:\n   raise KeyError(\"linkname %r not found\" % linkname)\n  return member\n  \n def __iter__(self):\n  \"\"\n  if self._loaded:\n   return iter(self.members)\n  else:\n   return TarIter(self)\n   \n def _dbg(self, level, msg):\n  \"\"\n  if level <= self.debug:\n   print(msg, file=sys.stderr)\n   \n def __enter__(self):\n  self._check()\n  return self\n  \n def __exit__(self, type, value, traceback):\n  if type is None:\n   self.close()\n  else:\n  \n  \n   if not self._extfileobj:\n    self.fileobj.close()\n   self.closed = True\n   \n   \nclass TarIter:\n \"\"\n \n def __init__(self, tarfile):\n  \"\"\n  self.tarfile = tarfile\n  self.index = 0\n def __iter__(self):\n  \"\"\n  return self\n def __next__(self):\n  \"\"\n  \n  \n  \n  \n  if self.index == 0 and self.tarfile.firstmember is not None:\n   tarinfo = self.tarfile.next()\n  elif self.index < len(self.tarfile.members):\n   tarinfo = self.tarfile.members[self.index]\n  elif not self.tarfile._loaded:\n   tarinfo = self.tarfile.next()\n   if not tarinfo:\n    self.tarfile._loaded = True\n    raise StopIteration\n  else:\n   raise StopIteration\n  self.index += 1\n  return tarinfo\n  \n  \n  \n  \ndef is_tarfile(name):\n \"\"\n try:\n  t = open(name)\n  t.close()\n  return True\n except TarError:\n  return False\n  \nbltn_open = open\nopen = TarFile.open\n"], "urllib": [".py", "", 1], "crypto_js.rollups.sha224": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(g,l){var f={},k=f.lib={},h=function(){},m=k.Base={extend:function(a){h.prototype=this;var c=new h;a&&c.mixIn(a);c.hasOwnProperty(\"init\")||(c.init=function(){c.$super.init.apply(this,arguments)});c.init.prototype=c;c.$super=this;return c},create:function(){var a=this.extend();a.init.apply(a,arguments);return a},init:function(){},mixIn:function(a){for(var c in a)a.hasOwnProperty(c)&&(this[c]=a[c]);a.hasOwnProperty(\"toString\")&&(this.toString=a.toString)},clone:function(){return this.init.prototype.extend(this)}},\nq=k.WordArray=m.extend({init:function(a,c){a=this.words=a||[];this.sigBytes=c!=l?c:4*a.length},toString:function(a){return(a||s).stringify(this)},concat:function(a){var c=this.words,d=a.words,b=this.sigBytes;a=a.sigBytes;this.clamp();if(b%4)for(var e=0;e<a;e++)c[b+e>>>2]|=(d[e>>>2]>>>24-8*(e%4)&255)<<24-8*((b+e)%4);else if(65535<d.length)for(e=0;e<a;e+=4)c[b+e>>>2]=d[e>>>2];else c.push.apply(c,d);this.sigBytes+=a;return this},clamp:function(){var a=this.words,c=this.sigBytes;a[c>>>2]&=4294967295<<\n32-8*(c%4);a.length=g.ceil(c/4)},clone:function(){var a=m.clone.call(this);a.words=this.words.slice(0);return a},random:function(a){for(var c=[],d=0;d<a;d+=4)c.push(4294967296*g.random()|0);return new q.init(c,a)}}),t=f.enc={},s=t.Hex={stringify:function(a){var c=a.words;a=a.sigBytes;for(var d=[],b=0;b<a;b++){var e=c[b>>>2]>>>24-8*(b%4)&255;d.push((e>>>4).toString(16));d.push((e&15).toString(16))}return d.join(\"\")},parse:function(a){for(var c=a.length,d=[],b=0;b<c;b+=2)d[b>>>3]|=parseInt(a.substr(b,\n2),16)<<24-4*(b%8);return new q.init(d,c/2)}},n=t.Latin1={stringify:function(a){var c=a.words;a=a.sigBytes;for(var d=[],b=0;b<a;b++)d.push(String.fromCharCode(c[b>>>2]>>>24-8*(b%4)&255));return d.join(\"\")},parse:function(a){for(var c=a.length,d=[],b=0;b<c;b++)d[b>>>2]|=(a.charCodeAt(b)&255)<<24-8*(b%4);return new q.init(d,c)}},j=t.Utf8={stringify:function(a){try{return decodeURIComponent(escape(n.stringify(a)))}catch(c){throw Error(\"Malformed UTF-8 data\");}},parse:function(a){return n.parse(unescape(encodeURIComponent(a)))}},\nw=k.BufferedBlockAlgorithm=m.extend({reset:function(){this._data=new q.init;this._nDataBytes=0},_append:function(a){\"string\"==typeof a&&(a=j.parse(a));this._data.concat(a);this._nDataBytes+=a.sigBytes},_process:function(a){var c=this._data,d=c.words,b=c.sigBytes,e=this.blockSize,f=b/(4*e),f=a?g.ceil(f):g.max((f|0)-this._minBufferSize,0);a=f*e;b=g.min(4*a,b);if(a){for(var u=0;u<a;u+=e)this._doProcessBlock(d,u);u=d.splice(0,a);c.sigBytes-=b}return new q.init(u,b)},clone:function(){var a=m.clone.call(this);\na._data=this._data.clone();return a},_minBufferSize:0});k.Hasher=w.extend({cfg:m.extend(),init:function(a){this.cfg=this.cfg.extend(a);this.reset()},reset:function(){w.reset.call(this);this._doReset()},update:function(a){this._append(a);this._process();return this},finalize:function(a){a&&this._append(a);return this._doFinalize()},blockSize:16,_createHelper:function(a){return function(c,d){return(new a.init(d)).finalize(c)}},_createHmacHelper:function(a){return function(c,d){return(new v.HMAC.init(a,\nd)).finalize(c)}}});var v=f.algo={};return f}(Math);\n(function(g){for(var l=CryptoJS,f=l.lib,k=f.WordArray,h=f.Hasher,f=l.algo,m=[],q=[],t=function(a){return 4294967296*(a-(a|0))|0},s=2,n=0;64>n;){var j;a:{j=s;for(var w=g.sqrt(j),v=2;v<=w;v++)if(!(j%v)){j=!1;break a}j=!0}j&&(8>n&&(m[n]=t(g.pow(s,0.5))),q[n]=t(g.pow(s,1/3)),n++);s++}var a=[],f=f.SHA256=h.extend({_doReset:function(){this._hash=new k.init(m.slice(0))},_doProcessBlock:function(c,d){for(var b=this._hash.words,e=b[0],f=b[1],g=b[2],k=b[3],h=b[4],l=b[5],m=b[6],n=b[7],p=0;64>p;p++){if(16>p)a[p]=\nc[d+p]|0;else{var j=a[p-15],r=a[p-2];a[p]=((j<<25|j>>>7)^(j<<14|j>>>18)^j>>>3)+a[p-7]+((r<<15|r>>>17)^(r<<13|r>>>19)^r>>>10)+a[p-16]}j=n+((h<<26|h>>>6)^(h<<21|h>>>11)^(h<<7|h>>>25))+(h&l^~h&m)+q[p]+a[p];r=((e<<30|e>>>2)^(e<<19|e>>>13)^(e<<10|e>>>22))+(e&f^e&g^f&g);n=m;m=l;l=h;h=k+j|0;k=g;g=f;f=e;e=j+r|0}b[0]=b[0]+e|0;b[1]=b[1]+f|0;b[2]=b[2]+g|0;b[3]=b[3]+k|0;b[4]=b[4]+h|0;b[5]=b[5]+l|0;b[6]=b[6]+m|0;b[7]=b[7]+n|0},_doFinalize:function(){var a=this._data,d=a.words,b=8*this._nDataBytes,e=8*a.sigBytes;\nd[e>>>5]|=128<<24-e%32;d[(e+64>>>9<<4)+14]=g.floor(b/4294967296);d[(e+64>>>9<<4)+15]=b;a.sigBytes=4*d.length;this._process();return this._hash},clone:function(){var a=h.clone.call(this);a._hash=this._hash.clone();return a}});l.SHA256=h._createHelper(f);l.HmacSHA256=h._createHmacHelper(f)})(Math);\n(function(){var g=CryptoJS,l=g.lib.WordArray,f=g.algo,k=f.SHA256,f=f.SHA224=k.extend({_doReset:function(){this._hash=new l.init([3238371032,914150663,812702999,4144912697,4290775857,1750603025,1694076839,3204075428])},_doFinalize:function(){var f=k._doFinalize.call(this);f.sigBytes-=4;return f}});g.SHA224=k._createHelper(f);g.HmacSHA224=k._createHmacHelper(f)})();\n"], "VFS_import": [".py", "import os\nfrom browser import doc\n\n\n\n\n\n\nVFS=dict(JSObject(__BRYTHON__.py_VFS))\nclass VFSModuleFinder:\n def __init__(self, path_entry):\n  print(\"in VFSModuleFinder\")\n  if path_entry.startswith('/libs') or path_entry.startswith('/Lib'):\n   self.path_entry=path_entry\n  else:\n   raise ImportError()\n   \n def __str__(self):\n  return '<%s for \"%s\">' % (self.__class__.__name__, self.path_entry)\n  \n def find_module(self, fullname, path=None):\n  path = path or self.path_entry\n  \n  for _ext in ['js', 'pyj', 'py']:\n   _filepath=os.path.join(self.path_entry, '%s.%s' % (fullname, _ext))\n   if _filepath in VFS:\n    print(\"module found at %s:%s\" % (_filepath, fullname))\n    return VFSModuleLoader(_filepath, fullname)\n    \n  print('module %s not found' % fullname)\n  raise ImportError()\n  return None\n  \nclass VFSModuleLoader:\n \"\"\n \n def __init__(self, filepath, name):\n  self._filepath=filepath\n  self._name=name\n  \n def get_source(self):\n  if self._filepath in VFS:\n   return JSObject(readFromVFS(self._filepath))\n   \n  raise ImportError('could not find source for %s' % fullname)\n  \n def is_package(self):\n  return '.' in self._name\n  \n def load_module(self):\n  if self._name in sys.modules:\n  \n   mod = sys.modules[self._name]\n   return mod\n   \n  _src=self.get_source()\n  if self._filepath.endswith('.js'):\n   mod=JSObject(import_js_module(_src, self._filepath, self._name))\n  elif self._filepath.endswith('.py'):\n   mod=JSObject(import_py_module(_src, self._filepath, self._name))\n  elif self._filepath.endswith('.pyj'):\n   mod=JSObject(import_pyj_module(_src, self._filepath, self._name))\n  else:\n   raise ImportError('Invalid Module: %s' % self._filepath)\n   \n   \n  mod.__file__ = self._filepath\n  mod.__name__ = self._name\n  mod.__path__ = os.path.abspath(self._filepath)\n  mod.__loader__ = self\n  mod.__package__ = '.'.join(self._name.split('.')[:-1])\n  \n  if self.is_package():\n   print('adding path for package')\n   \n   \n   mod.__path__ = [ self.path_entry ]\n  else:\n   print('imported as regular module')\n   \n  print('creating a new module object for \"%s\"' % self._name)\n  sys.modules.setdefault(self._name, mod)\n  JSObject(__BRYTHON__.imported)[self._name]=mod\n  \n  return mod\n  \nJSObject(__BRYTHON__.path_hooks.insert(0, VFSModuleFinder))\n"], "unittest.test.test_discovery": [".py", "import os\nimport re\nimport sys\n\nimport unittest\n\n\nclass TestableTestProgram(unittest.TestProgram):\n module = '__main__'\n exit = True\n defaultTest = failfast = catchbreak = buffer = None\n verbosity = 1\n progName = ''\n testRunner = testLoader = None\n \n def __init__(self):\n  pass\n  \n  \nclass TestDiscovery(unittest.TestCase):\n\n\n def test_get_name_from_path(self):\n  loader = unittest.TestLoader()\n  loader._top_level_dir = '/foo'\n  name = loader._get_name_from_path('/foo/bar/baz.py')\n  self.assertEqual(name, 'bar.baz')\n  \n  if not __debug__:\n  \n   return\n   \n  with self.assertRaises(AssertionError):\n   loader._get_name_from_path('/bar/baz.py')\n   \n def test_find_tests(self):\n  loader = unittest.TestLoader()\n  \n  original_listdir = os.listdir\n  def restore_listdir():\n   os.listdir = original_listdir\n  original_isfile = os.path.isfile\n  def restore_isfile():\n   os.path.isfile = original_isfile\n  original_isdir = os.path.isdir\n  def restore_isdir():\n   os.path.isdir = original_isdir\n   \n  path_lists = [['test1.py', 'test2.py', 'not_a_test.py', 'test_dir',\n  'test.foo', 'test-not-a-module.py', 'another_dir'],\n  ['test3.py', 'test4.py', ]]\n  os.listdir = lambda path: path_lists.pop(0)\n  self.addCleanup(restore_listdir)\n  \n  def isdir(path):\n   return path.endswith('dir')\n  os.path.isdir = isdir\n  self.addCleanup(restore_isdir)\n  \n  def isfile(path):\n  \n   return not path.endswith('dir') and not 'another_dir' in path\n  os.path.isfile = isfile\n  self.addCleanup(restore_isfile)\n  \n  loader._get_module_from_name = lambda path: path + ' module'\n  loader.loadTestsFromModule = lambda module: module + ' tests'\n  \n  top_level = os.path.abspath('/foo')\n  loader._top_level_dir = top_level\n  suite = list(loader._find_tests(top_level, 'test*.py'))\n  \n  expected = [name + ' module tests' for name in\n  ('test1', 'test2')]\n  expected.extend([('test_dir.%s' % name) + ' module tests' for name in\n  ('test3', 'test4')])\n  self.assertEqual(suite, expected)\n  \n def test_find_tests_with_package(self):\n  loader = unittest.TestLoader()\n  \n  original_listdir = os.listdir\n  def restore_listdir():\n   os.listdir = original_listdir\n  original_isfile = os.path.isfile\n  def restore_isfile():\n   os.path.isfile = original_isfile\n  original_isdir = os.path.isdir\n  def restore_isdir():\n   os.path.isdir = original_isdir\n   \n  directories = ['a_directory', 'test_directory', 'test_directory2']\n  path_lists = [directories, [], [], []]\n  os.listdir = lambda path: path_lists.pop(0)\n  self.addCleanup(restore_listdir)\n  \n  os.path.isdir = lambda path: True\n  self.addCleanup(restore_isdir)\n  \n  os.path.isfile = lambda path: os.path.basename(path) not in directories\n  self.addCleanup(restore_isfile)\n  \n  class Module(object):\n   paths = []\n   load_tests_args = []\n   \n   def __init__(self, path):\n    self.path = path\n    self.paths.append(path)\n    if os.path.basename(path) == 'test_directory':\n     def load_tests(loader, tests, pattern):\n      self.load_tests_args.append((loader, tests, pattern))\n      return 'load_tests'\n     self.load_tests = load_tests\n     \n   def __eq__(self, other):\n    return self.path == other.path\n    \n  loader._get_module_from_name = lambda name: Module(name)\n  def loadTestsFromModule(module, use_load_tests):\n   if use_load_tests:\n    raise self.failureException('use_load_tests should be False for packages')\n   return module.path + ' module tests'\n  loader.loadTestsFromModule = loadTestsFromModule\n  \n  loader._top_level_dir = '/foo'\n  \n  \n  suite = list(loader._find_tests('/foo', 'test*'))\n  \n  \n  \n  self.assertEqual(suite,\n  ['load_tests', 'test_directory2' + ' module tests'])\n  self.assertEqual(Module.paths, ['test_directory', 'test_directory2'])\n  \n  \n  self.assertEqual(Module.load_tests_args,\n  [(loader, 'test_directory' + ' module tests', 'test*')])\n  \n def test_discover(self):\n  loader = unittest.TestLoader()\n  \n  original_isfile = os.path.isfile\n  original_isdir = os.path.isdir\n  def restore_isfile():\n   os.path.isfile = original_isfile\n   \n  os.path.isfile = lambda path: False\n  self.addCleanup(restore_isfile)\n  \n  orig_sys_path = sys.path[:]\n  def restore_path():\n   sys.path[:] = orig_sys_path\n  self.addCleanup(restore_path)\n  \n  full_path = os.path.abspath(os.path.normpath('/foo'))\n  with self.assertRaises(ImportError):\n   loader.discover('/foo/bar', top_level_dir='/foo')\n   \n  self.assertEqual(loader._top_level_dir, full_path)\n  self.assertIn(full_path, sys.path)\n  \n  os.path.isfile = lambda path: True\n  os.path.isdir = lambda path: True\n  \n  def restore_isdir():\n   os.path.isdir = original_isdir\n  self.addCleanup(restore_isdir)\n  \n  _find_tests_args = []\n  def _find_tests(start_dir, pattern):\n   _find_tests_args.append((start_dir, pattern))\n   return ['tests']\n  loader._find_tests = _find_tests\n  loader.suiteClass = str\n  \n  suite = loader.discover('/foo/bar/baz', 'pattern', '/foo/bar')\n  \n  top_level_dir = os.path.abspath('/foo/bar')\n  start_dir = os.path.abspath('/foo/bar/baz')\n  self.assertEqual(suite, \"['tests']\")\n  self.assertEqual(loader._top_level_dir, top_level_dir)\n  self.assertEqual(_find_tests_args, [(start_dir, 'pattern')])\n  self.assertIn(top_level_dir, sys.path)\n  \n def test_discover_with_modules_that_fail_to_import(self):\n  loader = unittest.TestLoader()\n  \n  listdir = os.listdir\n  os.listdir = lambda _: ['test_this_does_not_exist.py']\n  isfile = os.path.isfile\n  os.path.isfile = lambda _: True\n  orig_sys_path = sys.path[:]\n  def restore():\n   os.path.isfile = isfile\n   os.listdir = listdir\n   sys.path[:] = orig_sys_path\n  self.addCleanup(restore)\n  \n  suite = loader.discover('.')\n  self.assertIn(os.getcwd(), sys.path)\n  self.assertEqual(suite.countTestCases(), 1)\n  test = list(list(suite)[0])[0] \n  \n  with self.assertRaises(ImportError):\n   test.test_this_does_not_exist()\n   \n def test_command_line_handling_parseArgs(self):\n  program = TestableTestProgram()\n  \n  args = []\n  def do_discovery(argv):\n   args.extend(argv)\n  program._do_discovery = do_discovery\n  program.parseArgs(['something', 'discover'])\n  self.assertEqual(args, [])\n  \n  program.parseArgs(['something', 'discover', 'foo', 'bar'])\n  self.assertEqual(args, ['foo', 'bar'])\n  \n def test_command_line_handling_discover_by_default(self):\n  program = TestableTestProgram()\n  program.module = None\n  \n  self.called = False\n  def do_discovery(argv):\n   self.called = True\n   self.assertEqual(argv, [])\n  program._do_discovery = do_discovery\n  program.parseArgs(['something'])\n  self.assertTrue(self.called)\n  \n def test_command_line_handling_discover_by_default_with_options(self):\n  program = TestableTestProgram()\n  program.module = None\n  \n  args = ['something', '-v', '-b', '-v', '-c', '-f']\n  self.called = False\n  def do_discovery(argv):\n   self.called = True\n   self.assertEqual(argv, args[1:])\n  program._do_discovery = do_discovery\n  program.parseArgs(args)\n  self.assertTrue(self.called)\n  \n  \n def test_command_line_handling_do_discovery_too_many_arguments(self):\n  class Stop(Exception):\n   pass\n  def usageExit():\n   raise Stop\n   \n  program = TestableTestProgram()\n  program.usageExit = usageExit\n  \n  with self.assertRaises(Stop):\n  \n   program._do_discovery(['one', 'two', 'three', 'four'])\n   \n   \n def test_command_line_handling_do_discovery_calls_loader(self):\n  program = TestableTestProgram()\n  \n  class Loader(object):\n   args = []\n   def discover(self, start_dir, pattern, top_level_dir):\n    self.args.append((start_dir, pattern, top_level_dir))\n    return 'tests'\n    \n  program._do_discovery(['-v'], Loader=Loader)\n  self.assertEqual(program.verbosity, 2)\n  self.assertEqual(program.test, 'tests')\n  self.assertEqual(Loader.args, [('.', 'test*.py', None)])\n  \n  Loader.args = []\n  program = TestableTestProgram()\n  program._do_discovery(['--verbose'], Loader=Loader)\n  self.assertEqual(program.test, 'tests')\n  self.assertEqual(Loader.args, [('.', 'test*.py', None)])\n  \n  Loader.args = []\n  program = TestableTestProgram()\n  program._do_discovery([], Loader=Loader)\n  self.assertEqual(program.test, 'tests')\n  self.assertEqual(Loader.args, [('.', 'test*.py', None)])\n  \n  Loader.args = []\n  program = TestableTestProgram()\n  program._do_discovery(['fish'], Loader=Loader)\n  self.assertEqual(program.test, 'tests')\n  self.assertEqual(Loader.args, [('fish', 'test*.py', None)])\n  \n  Loader.args = []\n  program = TestableTestProgram()\n  program._do_discovery(['fish', 'eggs'], Loader=Loader)\n  self.assertEqual(program.test, 'tests')\n  self.assertEqual(Loader.args, [('fish', 'eggs', None)])\n  \n  Loader.args = []\n  program = TestableTestProgram()\n  program._do_discovery(['fish', 'eggs', 'ham'], Loader=Loader)\n  self.assertEqual(program.test, 'tests')\n  self.assertEqual(Loader.args, [('fish', 'eggs', 'ham')])\n  \n  Loader.args = []\n  program = TestableTestProgram()\n  program._do_discovery(['-s', 'fish'], Loader=Loader)\n  self.assertEqual(program.test, 'tests')\n  self.assertEqual(Loader.args, [('fish', 'test*.py', None)])\n  \n  Loader.args = []\n  program = TestableTestProgram()\n  program._do_discovery(['-t', 'fish'], Loader=Loader)\n  self.assertEqual(program.test, 'tests')\n  self.assertEqual(Loader.args, [('.', 'test*.py', 'fish')])\n  \n  Loader.args = []\n  program = TestableTestProgram()\n  program._do_discovery(['-p', 'fish'], Loader=Loader)\n  self.assertEqual(program.test, 'tests')\n  self.assertEqual(Loader.args, [('.', 'fish', None)])\n  self.assertFalse(program.failfast)\n  self.assertFalse(program.catchbreak)\n  \n  Loader.args = []\n  program = TestableTestProgram()\n  program._do_discovery(['-p', 'eggs', '-s', 'fish', '-v', '-f', '-c'],\n  Loader=Loader)\n  self.assertEqual(program.test, 'tests')\n  self.assertEqual(Loader.args, [('fish', 'eggs', None)])\n  self.assertEqual(program.verbosity, 2)\n  self.assertTrue(program.failfast)\n  self.assertTrue(program.catchbreak)\n  \n def test_detect_module_clash(self):\n  class Module(object):\n   __file__ = 'bar/foo.py'\n  sys.modules['foo'] = Module\n  full_path = os.path.abspath('foo')\n  original_listdir = os.listdir\n  original_isfile = os.path.isfile\n  original_isdir = os.path.isdir\n  \n  def cleanup():\n   os.listdir = original_listdir\n   os.path.isfile = original_isfile\n   os.path.isdir = original_isdir\n   del sys.modules['foo']\n   if full_path in sys.path:\n    sys.path.remove(full_path)\n  self.addCleanup(cleanup)\n  \n  def listdir(_):\n   return ['foo.py']\n  def isfile(_):\n   return True\n  def isdir(_):\n   return True\n  os.listdir = listdir\n  os.path.isfile = isfile\n  os.path.isdir = isdir\n  \n  loader = unittest.TestLoader()\n  \n  mod_dir = os.path.abspath('bar')\n  expected_dir = os.path.abspath('foo')\n  msg = re.escape(r\"'foo' module incorrectly imported from %r. Expected %r. \"\n  \"Is this module globally installed?\" % (mod_dir, expected_dir))\n  self.assertRaisesRegex(\n  ImportError, '^%s$' % msg, loader.discover,\n  start_dir='foo', pattern='foo.py'\n  )\n  self.assertEqual(sys.path[0], full_path)\n  \n  \n def test_discovery_from_dotted_path(self):\n  loader = unittest.TestLoader()\n  \n  tests = [self]\n  expectedPath = os.path.abspath(os.path.dirname(unittest.test.__file__))\n  \n  self.wasRun = False\n  def _find_tests(start_dir, pattern):\n   self.wasRun = True\n   self.assertEqual(start_dir, expectedPath)\n   return tests\n  loader._find_tests = _find_tests\n  suite = loader.discover('unittest.test')\n  self.assertTrue(self.wasRun)\n  self.assertEqual(suite._tests, tests)\n  \n  \nif __name__ == '__main__':\n unittest.main()\n"], "colorsys": [".py", "\"\"\n\n\n\n\n\n\n__all__ = [\"rgb_to_yiq\",\"yiq_to_rgb\",\"rgb_to_hls\",\"hls_to_rgb\",\n\"rgb_to_hsv\",\"hsv_to_rgb\"]\n\n\n\nONE_THIRD = 1.0/3.0\nONE_SIXTH = 1.0/6.0\nTWO_THIRD = 2.0/3.0\n\n\n\n\n\ndef rgb_to_yiq(r, g, b):\n y = 0.30*r + 0.59*g + 0.11*b\n i = 0.60*r - 0.28*g - 0.32*b\n q = 0.21*r - 0.52*g + 0.31*b\n return (y, i, q)\n \ndef yiq_to_rgb(y, i, q):\n r = y + 0.948262*i + 0.624013*q\n g = y - 0.276066*i - 0.639810*q\n b = y - 1.105450*i + 1.729860*q\n if r < 0.0:\n  r = 0.0\n if g < 0.0:\n  g = 0.0\n if b < 0.0:\n  b = 0.0\n if r > 1.0:\n  r = 1.0\n if g > 1.0:\n  g = 1.0\n if b > 1.0:\n  b = 1.0\n return (r, g, b)\n \n \n \n \n \n \n \ndef rgb_to_hls(r, g, b):\n maxc = max(r, g, b)\n minc = min(r, g, b)\n \n l = (minc+maxc)/2.0\n if minc == maxc:\n  return 0.0, l, 0.0\n if l <= 0.5:\n  s = (maxc-minc) / (maxc+minc)\n else:\n  s = (maxc-minc) / (2.0-maxc-minc)\n rc = (maxc-r) / (maxc-minc)\n gc = (maxc-g) / (maxc-minc)\n bc = (maxc-b) / (maxc-minc)\n if r == maxc:\n  h = bc-gc\n elif g == maxc:\n  h = 2.0+rc-bc\n else:\n  h = 4.0+gc-rc\n h = (h/6.0) % 1.0\n return h, l, s\n \ndef hls_to_rgb(h, l, s):\n if s == 0.0:\n  return l, l, l\n if l <= 0.5:\n  m2 = l * (1.0+s)\n else:\n  m2 = l+s-(l*s)\n m1 = 2.0*l - m2\n return (_v(m1, m2, h+ONE_THIRD), _v(m1, m2, h), _v(m1, m2, h-ONE_THIRD))\n \ndef _v(m1, m2, hue):\n hue = hue % 1.0\n if hue < ONE_SIXTH:\n  return m1 + (m2-m1)*hue*6.0\n if hue < 0.5:\n  return m2\n if hue < TWO_THIRD:\n  return m1 + (m2-m1)*(TWO_THIRD-hue)*6.0\n return m1\n \n \n \n \n \n \n \ndef rgb_to_hsv(r, g, b):\n maxc = max(r, g, b)\n minc = min(r, g, b)\n v = maxc\n if minc == maxc:\n  return 0.0, 0.0, v\n s = (maxc-minc) / maxc\n rc = (maxc-r) / (maxc-minc)\n gc = (maxc-g) / (maxc-minc)\n bc = (maxc-b) / (maxc-minc)\n if r == maxc:\n  h = bc-gc\n elif g == maxc:\n  h = 2.0+rc-bc\n else:\n  h = 4.0+gc-rc\n h = (h/6.0) % 1.0\n return h, s, v\n \ndef hsv_to_rgb(h, s, v):\n if s == 0.0:\n  return v, v, v\n i = int(h*6.0) \n f = (h*6.0) - i\n p = v*(1.0 - s)\n q = v*(1.0 - s*f)\n t = v*(1.0 - s*(1.0-f))\n i = i%6\n if i == 0:\n  return v, t, p\n if i == 1:\n  return q, v, p\n if i == 2:\n  return p, v, t\n if i == 3:\n  return p, q, v\n if i == 4:\n  return t, p, v\n if i == 5:\n  return v, p, q\n  \n"], "formatter": [".py", "\"\"\n\nimport sys\n\n\nAS_IS = None\n\n\nclass NullFormatter:\n \"\"\n \n def __init__(self, writer=None):\n  if writer is None:\n   writer = NullWriter()\n  self.writer = writer\n def end_paragraph(self, blankline): pass\n def add_line_break(self): pass\n def add_hor_rule(self, *args, **kw): pass\n def add_label_data(self, format, counter, blankline=None): pass\n def add_flowing_data(self, data): pass\n def add_literal_data(self, data): pass\n def flush_softspace(self): pass\n def push_alignment(self, align): pass\n def pop_alignment(self): pass\n def push_font(self, x): pass\n def pop_font(self): pass\n def push_margin(self, margin): pass\n def pop_margin(self): pass\n def set_spacing(self, spacing): pass\n def push_style(self, *styles): pass\n def pop_style(self, n=1): pass\n def assert_line_data(self, flag=1): pass\n \n \nclass AbstractFormatter:\n \"\"\n \n \n \n \n \n \n def __init__(self, writer):\n  self.writer = writer \n  self.align = None \n  self.align_stack = [] \n  self.font_stack = [] \n  self.margin_stack = [] \n  self.spacing = None \n  self.style_stack = [] \n  self.nospace = 1 \n  self.softspace = 0 \n  self.para_end = 1 \n  self.parskip = 0 \n  self.hard_break = 1 \n  self.have_label = 0\n  \n def end_paragraph(self, blankline):\n  if not self.hard_break:\n   self.writer.send_line_break()\n   self.have_label = 0\n  if self.parskip < blankline and not self.have_label:\n   self.writer.send_paragraph(blankline - self.parskip)\n   self.parskip = blankline\n   self.have_label = 0\n  self.hard_break = self.nospace = self.para_end = 1\n  self.softspace = 0\n  \n def add_line_break(self):\n  if not (self.hard_break or self.para_end):\n   self.writer.send_line_break()\n   self.have_label = self.parskip = 0\n  self.hard_break = self.nospace = 1\n  self.softspace = 0\n  \n def add_hor_rule(self, *args, **kw):\n  if not self.hard_break:\n   self.writer.send_line_break()\n  self.writer.send_hor_rule(*args, **kw)\n  self.hard_break = self.nospace = 1\n  self.have_label = self.para_end = self.softspace = self.parskip = 0\n  \n def add_label_data(self, format, counter, blankline = None):\n  if self.have_label or not self.hard_break:\n   self.writer.send_line_break()\n  if not self.para_end:\n   self.writer.send_paragraph((blankline and 1) or 0)\n  if isinstance(format, str):\n   self.writer.send_label_data(self.format_counter(format, counter))\n  else:\n   self.writer.send_label_data(format)\n  self.nospace = self.have_label = self.hard_break = self.para_end = 1\n  self.softspace = self.parskip = 0\n  \n def format_counter(self, format, counter):\n  label = ''\n  for c in format:\n   if c == '1':\n    label = label + ('%d' % counter)\n   elif c in 'aA':\n    if counter > 0:\n     label = label + self.format_letter(c, counter)\n   elif c in 'iI':\n    if counter > 0:\n     label = label + self.format_roman(c, counter)\n   else:\n    label = label + c\n  return label\n  \n def format_letter(self, case, counter):\n  label = ''\n  while counter > 0:\n   counter, x = divmod(counter-1, 26)\n   \n   \n   \n   s = chr(ord(case) + x)\n   label = s + label\n  return label\n  \n def format_roman(self, case, counter):\n  ones = ['i', 'x', 'c', 'm']\n  fives = ['v', 'l', 'd']\n  label, index = '', 0\n  \n  while counter > 0:\n   counter, x = divmod(counter, 10)\n   if x == 9:\n    label = ones[index] + ones[index+1] + label\n   elif x == 4:\n    label = ones[index] + fives[index] + label\n   else:\n    if x >= 5:\n     s = fives[index]\n     x = x-5\n    else:\n     s = ''\n    s = s + ones[index]*x\n    label = s + label\n   index = index + 1\n  if case == 'I':\n   return label.upper()\n  return label\n  \n def add_flowing_data(self, data):\n  if not data: return\n  prespace = data[:1].isspace()\n  postspace = data[-1:].isspace()\n  data = \" \".join(data.split())\n  if self.nospace and not data:\n   return\n  elif prespace or self.softspace:\n   if not data:\n    if not self.nospace:\n     self.softspace = 1\n     self.parskip = 0\n    return\n   if not self.nospace:\n    data = ' ' + data\n  self.hard_break = self.nospace = self.para_end = self.parskip = self.have_label = 0\n  self.softspace = postspace\n  self.writer.send_flowing_data(data)\n  \n def add_literal_data(self, data):\n  if not data: return\n  if self.softspace:\n   self.writer.send_flowing_data(\" \")\n  self.hard_break = data[-1:] == '\\n'\n  self.nospace = self.para_end = self.softspace = self.parskip = self.have_label = 0\n  self.writer.send_literal_data(data)\n  \n def flush_softspace(self):\n  if self.softspace:\n   self.hard_break = self.para_end = self.parskip = self.have_label = self.softspace = 0\n   self.nospace = 1\n   self.writer.send_flowing_data(' ')\n   \n def push_alignment(self, align):\n  if align and align != self.align:\n   self.writer.new_alignment(align)\n   self.align = align\n   self.align_stack.append(align)\n  else:\n   self.align_stack.append(self.align)\n   \n def pop_alignment(self):\n  if self.align_stack:\n   del self.align_stack[-1]\n  if self.align_stack:\n   self.align = align = self.align_stack[-1]\n   self.writer.new_alignment(align)\n  else:\n   self.align = None\n   self.writer.new_alignment(None)\n   \n def push_font(self, font):\n  size, i, b, tt = font\n  if self.softspace:\n   self.hard_break = self.para_end = self.softspace = 0\n   self.nospace = 1\n   self.writer.send_flowing_data(' ')\n  if self.font_stack:\n   csize, ci, cb, ctt = self.font_stack[-1]\n   if size is AS_IS: size = csize\n   if i is AS_IS: i = ci\n   if b is AS_IS: b = cb\n   if tt is AS_IS: tt = ctt\n  font = (size, i, b, tt)\n  self.font_stack.append(font)\n  self.writer.new_font(font)\n  \n def pop_font(self):\n  if self.font_stack:\n   del self.font_stack[-1]\n  if self.font_stack:\n   font = self.font_stack[-1]\n  else:\n   font = None\n  self.writer.new_font(font)\n  \n def push_margin(self, margin):\n  self.margin_stack.append(margin)\n  fstack = [m for m in self.margin_stack if m]\n  if not margin and fstack:\n   margin = fstack[-1]\n  self.writer.new_margin(margin, len(fstack))\n  \n def pop_margin(self):\n  if self.margin_stack:\n   del self.margin_stack[-1]\n  fstack = [m for m in self.margin_stack if m]\n  if fstack:\n   margin = fstack[-1]\n  else:\n   margin = None\n  self.writer.new_margin(margin, len(fstack))\n  \n def set_spacing(self, spacing):\n  self.spacing = spacing\n  self.writer.new_spacing(spacing)\n  \n def push_style(self, *styles):\n  if self.softspace:\n   self.hard_break = self.para_end = self.softspace = 0\n   self.nospace = 1\n   self.writer.send_flowing_data(' ')\n  for style in styles:\n   self.style_stack.append(style)\n  self.writer.new_styles(tuple(self.style_stack))\n  \n def pop_style(self, n=1):\n  del self.style_stack[-n:]\n  self.writer.new_styles(tuple(self.style_stack))\n  \n def assert_line_data(self, flag=1):\n  self.nospace = self.hard_break = not flag\n  self.para_end = self.parskip = self.have_label = 0\n  \n  \nclass NullWriter:\n \"\"\n def __init__(self): pass\n def flush(self): pass\n def new_alignment(self, align): pass\n def new_font(self, font): pass\n def new_margin(self, margin, level): pass\n def new_spacing(self, spacing): pass\n def new_styles(self, styles): pass\n def send_paragraph(self, blankline): pass\n def send_line_break(self): pass\n def send_hor_rule(self, *args, **kw): pass\n def send_label_data(self, data): pass\n def send_flowing_data(self, data): pass\n def send_literal_data(self, data): pass\n \n \nclass AbstractWriter(NullWriter):\n \"\"\n \n def new_alignment(self, align):\n  print(\"new_alignment(%r)\" % (align,))\n  \n def new_font(self, font):\n  print(\"new_font(%r)\" % (font,))\n  \n def new_margin(self, margin, level):\n  print(\"new_margin(%r, %d)\" % (margin, level))\n  \n def new_spacing(self, spacing):\n  print(\"new_spacing(%r)\" % (spacing,))\n  \n def new_styles(self, styles):\n  print(\"new_styles(%r)\" % (styles,))\n  \n def send_paragraph(self, blankline):\n  print(\"send_paragraph(%r)\" % (blankline,))\n  \n def send_line_break(self):\n  print(\"send_line_break()\")\n  \n def send_hor_rule(self, *args, **kw):\n  print(\"send_hor_rule()\")\n  \n def send_label_data(self, data):\n  print(\"send_label_data(%r)\" % (data,))\n  \n def send_flowing_data(self, data):\n  print(\"send_flowing_data(%r)\" % (data,))\n  \n def send_literal_data(self, data):\n  print(\"send_literal_data(%r)\" % (data,))\n  \n  \nclass DumbWriter(NullWriter):\n \"\"\n \n def __init__(self, file=None, maxcol=72):\n  self.file = file or sys.stdout\n  self.maxcol = maxcol\n  NullWriter.__init__(self)\n  self.reset()\n  \n def reset(self):\n  self.col = 0\n  self.atbreak = 0\n  \n def send_paragraph(self, blankline):\n  self.file.write('\\n'*blankline)\n  self.col = 0\n  self.atbreak = 0\n  \n def send_line_break(self):\n  self.file.write('\\n')\n  self.col = 0\n  self.atbreak = 0\n  \n def send_hor_rule(self, *args, **kw):\n  self.file.write('\\n')\n  self.file.write('-'*self.maxcol)\n  self.file.write('\\n')\n  self.col = 0\n  self.atbreak = 0\n  \n def send_literal_data(self, data):\n  self.file.write(data)\n  i = data.rfind('\\n')\n  if i >= 0:\n   self.col = 0\n   data = data[i+1:]\n  data = data.expandtabs()\n  self.col = self.col + len(data)\n  self.atbreak = 0\n  \n def send_flowing_data(self, data):\n  if not data: return\n  atbreak = self.atbreak or data[0].isspace()\n  col = self.col\n  maxcol = self.maxcol\n  write = self.file.write\n  for word in data.split():\n   if atbreak:\n    if col + len(word) >= maxcol:\n     write('\\n')\n     col = 0\n    else:\n     write(' ')\n     col = col + 1\n   write(word)\n   col = col + len(word)\n   atbreak = 1\n  self.col = col\n  self.atbreak = data[-1].isspace()\n  \n  \ndef test(file = None):\n w = DumbWriter()\n f = AbstractFormatter(w)\n if file is not None:\n  fp = open(file)\n elif sys.argv[1:]:\n  fp = open(sys.argv[1])\n else:\n  fp = sys.stdin\n for line in fp:\n  if line == '\\n':\n   f.end_paragraph(1)\n  else:\n   f.add_flowing_data(line)\n f.end_paragraph(0)\n \n \nif __name__ == '__main__':\n test()\n"], "unittest.test.testmock.testcallable": [".py", "\n\n\n\nimport unittest\nfrom unittest.test.testmock.support import is_instance, X, SomeClass\n\nfrom unittest.mock import (\nMock, MagicMock, NonCallableMagicMock,\nNonCallableMock, patch, create_autospec,\nCallableMixin\n)\n\n\n\nclass TestCallable(unittest.TestCase):\n\n def assertNotCallable(self, mock):\n  self.assertTrue(is_instance(mock, NonCallableMagicMock))\n  self.assertFalse(is_instance(mock, CallableMixin))\n  \n  \n def test_non_callable(self):\n  for mock in NonCallableMagicMock(), NonCallableMock():\n   self.assertRaises(TypeError, mock)\n   self.assertFalse(hasattr(mock, '__call__'))\n   self.assertIn(mock.__class__.__name__, repr(mock))\n   \n   \n def test_heirarchy(self):\n  self.assertTrue(issubclass(MagicMock, Mock))\n  self.assertTrue(issubclass(NonCallableMagicMock, NonCallableMock))\n  \n  \n def test_attributes(self):\n  one = NonCallableMock()\n  self.assertTrue(issubclass(type(one.one), Mock))\n  \n  two = NonCallableMagicMock()\n  self.assertTrue(issubclass(type(two.two), MagicMock))\n  \n  \n def test_subclasses(self):\n  class MockSub(Mock):\n   pass\n   \n  one = MockSub()\n  self.assertTrue(issubclass(type(one.one), MockSub))\n  \n  class MagicSub(MagicMock):\n   pass\n   \n  two = MagicSub()\n  self.assertTrue(issubclass(type(two.two), MagicSub))\n  \n  \n def test_patch_spec(self):\n  patcher = patch('%s.X' % __name__, spec=True)\n  mock = patcher.start()\n  self.addCleanup(patcher.stop)\n  \n  instance = mock()\n  mock.assert_called_once_with()\n  \n  self.assertNotCallable(instance)\n  self.assertRaises(TypeError, instance)\n  \n  \n def test_patch_spec_set(self):\n  patcher = patch('%s.X' % __name__, spec_set=True)\n  mock = patcher.start()\n  self.addCleanup(patcher.stop)\n  \n  instance = mock()\n  mock.assert_called_once_with()\n  \n  self.assertNotCallable(instance)\n  self.assertRaises(TypeError, instance)\n  \n  \n def test_patch_spec_instance(self):\n  patcher = patch('%s.X' % __name__, spec=X())\n  mock = patcher.start()\n  self.addCleanup(patcher.stop)\n  \n  self.assertNotCallable(mock)\n  self.assertRaises(TypeError, mock)\n  \n  \n def test_patch_spec_set_instance(self):\n  patcher = patch('%s.X' % __name__, spec_set=X())\n  mock = patcher.start()\n  self.addCleanup(patcher.stop)\n  \n  self.assertNotCallable(mock)\n  self.assertRaises(TypeError, mock)\n  \n  \n def test_patch_spec_callable_class(self):\n  class CallableX(X):\n   def __call__(self):\n    pass\n    \n  class Sub(CallableX):\n   pass\n   \n  class Multi(SomeClass, Sub):\n   pass\n   \n  for arg in 'spec', 'spec_set':\n   for Klass in CallableX, Sub, Multi:\n    with patch('%s.X' % __name__, **{arg: Klass}) as mock:\n     instance = mock()\n     mock.assert_called_once_with()\n     \n     self.assertTrue(is_instance(instance, MagicMock))\n     \n     self.assertRaises(AttributeError, getattr, instance,\n     'foobarbaz')\n     \n     result = instance()\n     \n     instance.assert_called_once_with()\n     \n     result(3, 2, 1)\n     result.assert_called_once_with(3, 2, 1)\n     result.foo(3, 2, 1)\n     result.foo.assert_called_once_with(3, 2, 1)\n     \n     \n def test_create_autopsec(self):\n  mock = create_autospec(X)\n  instance = mock()\n  self.assertRaises(TypeError, instance)\n  \n  mock = create_autospec(X())\n  self.assertRaises(TypeError, mock)\n  \n  \n def test_create_autospec_instance(self):\n  mock = create_autospec(SomeClass, instance=True)\n  \n  self.assertRaises(TypeError, mock)\n  mock.wibble()\n  mock.wibble.assert_called_once_with()\n  \n  self.assertRaises(TypeError, mock.wibble, 'some', 'args')\n"], "math": [".js", "var $module=(function($B){\n\nvar _b_ = $B.builtins\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\n//for(var $py_builtin in _b_){eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")}\n\nvar float_check=function(x) {\n    if (x.value !== undefined && isinstance(x, float)) return x.value\n    return x\n}\n\nvar isWholeNumber=function(x){return (x*10) % 10 == 0}\n\nvar isOdd=function(x) {return isWholeNumber(x) && 2*Math.floor(x/2) != x}\n\nvar isLargeNumber=function(x) {return x > Math.pow(2,32)}\n\n// Big number Library from jsfromhell.com\n// This library helps with producing \"correct\" results from \n// mathematic operations\n\n//+ Jonas Raoni Soares Silva\n//@ http://jsfromhell.com/classes/bignumber [rev. #4]\n\n\nvar BigNumber = function(n, p, r){\n\tvar o = this, i;\n\tif(n instanceof BigNumber){\n\t\tfor(i in {precision: 0, roundType: 0, _s: 0, _f: 0}) o[i] = n[i];\n\t\to._d = n._d.slice();\n\t\treturn;\n\t}\n\to.precision = isNaN(p = Math.abs(p)) ? BigNumber.defaultPrecision : p;\n\to.roundType = isNaN(r = Math.abs(r)) ? BigNumber.defaultRoundType : r;\n\to._s = (n += \"\").charAt(0) == \"-\";\n\to._f = ((n = n.replace(/[^\\d.]/g, \"\").split(\".\", 2))[0] = n[0].replace(/^0+/, \"\") || \"0\").length;\n\tfor(i = (n = o._d = (n.join(\"\") || \"0\").split(\"\")).length; i; n[--i] = +n[i]);\n\to.round();\n};\nwith({$: BigNumber, o: BigNumber.prototype}){\n\t$.ROUND_HALF_EVEN = ($.ROUND_HALF_DOWN = ($.ROUND_HALF_UP = ($.ROUND_FLOOR = ($.ROUND_CEIL = ($.ROUND_DOWN = ($.ROUND_UP = 0) + 1) + 1) + 1) + 1) + 1) + 1;\n\t$.defaultPrecision = 40;\n\t$.defaultRoundType = $.ROUND_HALF_UP;\n\to.add = function(n){\n\t\tif(this._s != (n = new BigNumber(n))._s)\n\t\t\treturn n._s ^= 1, this.subtract(n);\n\t\tvar o = new BigNumber(this), a = o._d, b = n._d, la = o._f,\n\t\tlb = n._f, n = Math.max(la, lb), i, r;\n\t\tla != lb && ((lb = la - lb) > 0 ? o._zeroes(b, lb, 1) : o._zeroes(a, -lb, 1));\n\t\ti = (la = a.length) == (lb = b.length) ? a.length : ((lb = la - lb) > 0 ? o._zeroes(b, lb) : o._zeroes(a, -lb)).length;\n\t\tfor(r = 0; i; r = (a[--i] = a[i] + b[i] + r) / 10 >>> 0, a[i] %= 10);\n\t\treturn r && ++n && a.unshift(r), o._f = n, o.round();\n\t};\n\to.subtract = function(n){\n\t\tif(this._s != (n = new BigNumber(n))._s)\n\t\t\treturn n._s ^= 1, this.add(n);\n\t\tvar o = new BigNumber(this), c = o.abs().compare(n.abs()) + 1, a = c ? o : n, b = c ? n : o, la = a._f, lb = b._f, d = la, i, j;\n\t\ta = a._d, b = b._d, la != lb && ((lb = la - lb) > 0 ? o._zeroes(b, lb, 1) : o._zeroes(a, -lb, 1));\n\t\tfor(i = (la = a.length) == (lb = b.length) ? a.length : ((lb = la - lb) > 0 ? o._zeroes(b, lb) : o._zeroes(a, -lb)).length; i;){\n\t\t\tif(a[--i] < b[i]){\n\t\t\t\tfor(j = i; j && !a[--j]; a[j] = 9);\n\t\t\t\t--a[j], a[i] += 10;\n\t\t\t}\n\t\t\tb[i] = a[i] - b[i];\n\t\t}\n\t\treturn c || (o._s ^= 1), o._f = d, o._d = b, o.round();\n\t};\n\to.multiply = function(n){\n\t\tvar o = new BigNumber(this), r = o._d.length >= (n = new BigNumber(n))._d.length, a = (r ? o : n)._d,\n\t\tb = (r ? n : o)._d, la = a.length, lb = b.length, x = new BigNumber, i, j, s;\n\t\tfor(i = lb; i; r && s.unshift(r), x.set(x.add(new BigNumber(s.join(\"\")))))\n\t\t\tfor(s = (new Array(lb - --i)).join(\"0\").split(\"\"), r = 0, j = la; j; r += a[--j] * b[i], s.unshift(r % 10), r = (r / 10) >>> 0);\n\t\treturn o._s = o._s != n._s, o._f = ((r = la + lb - o._f - n._f) >= (j = (o._d = x._d).length) ? this._zeroes(o._d, r - j + 1, 1).length : j) - r, o.round();\n\t};\n\to.divide = function(n){\n\t\tif((n = new BigNumber(n)) == \"0\")\n\t\t\tthrow new Error(\"Division by 0\");\n\t\telse if(this == \"0\")\n\t\t\treturn new BigNumber;\n\t\tvar o = new BigNumber(this), a = o._d, b = n._d, la = a.length - o._f,\n\t\tlb = b.length - n._f, r = new BigNumber, i = 0, j, s, l, f = 1, c = 0, e = 0;\n\t\tr._s = o._s != n._s, r.precision = Math.max(o.precision, n.precision),\n\t\tr._f = +r._d.pop(), la != lb && o._zeroes(la > lb ? b : a, Math.abs(la - lb));\n\t\tn._f = b.length, b = n, b._s = false, b = b.round();\n\t\tfor(n = new BigNumber; a[0] == \"0\"; a.shift());\n\t\tout:\n\t\tdo{\n\t\t\tfor(l = c = 0, n == \"0\" && (n._d = [], n._f = 0); i < a.length && n.compare(b) == -1; ++i){\n\t\t\t\t(l = i + 1 == a.length, (!f && ++c > 1 || (e = l && n == \"0\" && a[i] == \"0\")))\n\t\t\t\t&& (r._f == r._d.length && ++r._f, r._d.push(0));\n\t\t\t\t(a[i] == \"0\" && n == \"0\") || (n._d.push(a[i]), ++n._f);\n\t\t\t\tif(e)\n\t\t\t\t\tbreak out;\n\t\t\t\tif((l && n.compare(b) == -1 && (r._f == r._d.length && ++r._f, 1)) || (l = 0))\n\t\t\t\t\twhile(r._d.push(0), n._d.push(0), ++n._f, n.compare(b) == -1);\n\t\t\t}\n\t\t\tif(f = 0, n.compare(b) == -1 && !(l = 0))\n\t\t\t\twhile(l ? r._d.push(0) : l = 1, n._d.push(0), ++n._f, n.compare(b) == -1);\n\t\t\tfor(s = new BigNumber, j = 0; n.compare(y = s.add(b)) + 1 && ++j; s.set(y));\n\t\t\tn.set(n.subtract(s)), !l && r._f == r._d.length && ++r._f, r._d.push(j);\n\t\t}\n\t\twhile((i < a.length || n != \"0\") && (r._d.length - r._f) <= r.precision);\n\t\treturn r.round();\n\t};\n\to.mod = function(n){\n\t\treturn this.subtract(this.divide(n).intPart().multiply(n));\n\t};\n\to.pow = function(n){\n\t\tvar o = new BigNumber(this), i;\n\t\tif((n = (new BigNumber(n)).intPart()) == 0) return o.set(1);\n\t\tfor(i = Math.abs(n); --i; o.set(o.multiply(this)));\n\t\treturn n < 0 ? o.set((new BigNumber(1)).divide(o)) : o;\n\t};\n\to.set = function(n){\n\t\treturn this.constructor(n), this;\n\t};\n\to.compare = function(n){\n\t\tvar a = this, la = this._f, b = new BigNumber(n), lb = b._f, r = [-1, 1], i, l;\n\t\tif(a._s != b._s)\n\t\t\treturn a._s ? -1 : 1;\n\t\tif(la != lb)\n\t\t\treturn r[(la > lb) ^ a._s];\n\t\tfor(la = (a = a._d).length, lb = (b = b._d).length, i = -1, l = Math.min(la, lb); ++i < l;)\n\t\t\tif(a[i] != b[i])\n\t\t\t\treturn r[(a[i] > b[i]) ^ a._s];\n\t\treturn la != lb ? r[(la > lb) ^ a._s] : 0;\n\t};\n\to.negate = function(){\n\t\tvar n = new BigNumber(this); return n._s ^= 1, n;\n\t};\n\to.abs = function(){\n\t\tvar n = new BigNumber(this); return n._s = 0, n;\n\t};\n\to.intPart = function(){\n\t\treturn new BigNumber((this._s ? \"-\" : \"\") + (this._d.slice(0, this._f).join(\"\") || \"0\"));\n\t};\n\to.valueOf = o.toString = function(){\n\t\tvar o = this;\n\t\treturn (o._s ? \"-\" : \"\") + (o._d.slice(0, o._f).join(\"\") || \"0\") + (o._f != o._d.length ? \".\" + o._d.slice(o._f).join(\"\") : \"\");\n\t};\n\to._zeroes = function(n, l, t){\n\t\tvar s = [\"push\", \"unshift\"][t || 0];\n\t\tfor(++l; --l;  n[s](0));\n\t\treturn n;\n\t};\n\to.round = function(){\n\t\tif(\"_rounding\" in this) return this;\n\t\tvar $ = BigNumber, r = this.roundType, b = this._d, d, p, n, x;\n\t\tfor(this._rounding = true; this._f > 1 && !b[0]; --this._f, b.shift());\n\t\tfor(d = this._f, p = this.precision + d, n = b[p]; b.length > d && !b[b.length -1]; b.pop());\n\t\tx = (this._s ? \"-\" : \"\") + (p - d ? \"0.\" + this._zeroes([], p - d - 1).join(\"\") : \"\") + 1;\n\t\tif(b.length > p){\n\t\t\tn && (r == $.DOWN ? false : r == $.UP ? true : r == $.CEIL ? !this._s\n\t\t\t: r == $.FLOOR ? this._s : r == $.HALF_UP ? n >= 5 : r == $.HALF_DOWN ? n > 5\n\t\t\t: r == $.HALF_EVEN ? n >= 5 && b[p - 1] & 1 : false) && this.add(x);\n\t\t\tb.splice(p, b.length - p);\n\t\t}\n\t\treturn delete this._rounding, this;\n\t};\n}\n\nvar isNegZero=function(x) {return x===0 && Math.atan2(x,x) < 0}\n\nvar _mod = {\n    __getattr__ : function(attr){\n        var res = this[attr]\n        if(res===undefined){$raise('AttributeError','module math has no attribute '+attr)}\n        return res\n    },\n    acos: function(x) {return float(Math.acos(float_check(x)))},\n    acosh: function(x) { \n        if (_b_.$isinf(x)) return float('inf');\n        var y = float_check(x);\n        return float(Math.log(y + Math.sqrt(y*y-1)));\n    },\n    asin: function(x) {return float(Math.asin(float_check(x)))},\n    asinh: function(x) {\n        if (_b_.$isninf(x)) return float('-inf');\n        if (_b_.$isinf(x)) return float('inf');\n        var y = float_check(x);\n        return float(Math.log(y + Math.sqrt(y*y+1)))\n    },\n    atan: function(x) {\n        if (_b_.$isninf(x)) return float(-Math.PI/2);\n        if (_b_.$isinf(x)) return float(Math.PI/2);\n        return float(Math.atan(float_check(x)))},\n    atan2: function(y,x) {\n        return float(Math.atan2(float_check(y),float_check(x)))\n    },\n    atanh: function(x) { \n       var y=float_check(x);\n       if (y==0) return 0;\n       return float(0.5 * Math.log((1/y+1)/(1/y-1)));\n    },\n    ceil: function(x) {\n       try{return getattr(x,'__ceil__')()}catch(err){$B.$pop_exc()}\n\n       if (_b_.$isninf(x)) return float('-inf')\n       if (_b_.$isinf(x)) return float('inf')\n       if (isNaN(x)) return float('nan')\n\n       var y=float_check(x);\n       if (!isNaN(parseFloat(y)) && isFinite(y)) return int(Math.ceil(y));\n       \n       $raise('ValueError', 'object is not a number and does not contain __ceil__')\n    },\n    copysign: function(x,y) {\n        var x1=Math.abs(float_check(x))\n        var y1=float_check(y)\n        var sign=y1?y1<0?-1:1:1\n        if (isNegZero(y1)) sign=-1   // probably need to work on adding a check for -0\n        return float(x1 * sign)\n    },\n    cos : function(x){return float(Math.cos(float_check(x)))},\n    cosh: function(x){\n        if (_b_.$isinf(x)) return float('inf')\n        var y = float_check(x)\n        if (Math.cosh !== undefined) return float(Math.cosh(y))\n        return float((Math.pow(Math.E,y) + Math.pow(Math.E,-y))/2)\n    },\n    degrees: function(x){return float(float_check(x) * 180/Math.PI)},\n    e: float(Math.E),\n    erf: function(x) {\n        // inspired from \n        // http://stackoverflow.com/questions/457408/is-there-an-easily-available-implementation-of-erf-for-python\n        var y =float_check(x);\n        var t = 1.0 / (1.0 + 0.5 * Math.abs(y))\n        var ans = 1 - t * Math.exp( -y*y - 1.26551223 +\n                     t * ( 1.00002368 +\n                     t * ( 0.37409196 + \n                     t * ( 0.09678418 + \n                     t * (-0.18628806 + \n                     t * ( 0.27886807 + \n                     t * (-1.13520398 + \n                     t * ( 1.48851587 + \n                     t * (-0.82215223 + \n                     t * 0.17087277)))))))))\n        if (y >= 0.0) return ans\n\n        return -ans\n    },\n\n    erfc: function(x) {\n        // inspired from \n        // http://stackoverflow.com/questions/457408/is-there-an-easily-available-implementation-of-erf-for-python\n        var y = float_check(x);\n        var t = 1.0 / (1.0 + 0.5 * Math.abs(y))\n        var ans = 1 - t * Math.exp( -y*y - 1.26551223 +\n                     t * ( 1.00002368 +\n                     t * ( 0.37409196 + \n                     t * ( 0.09678418 + \n                     t * (-0.18628806 + \n                     t * ( 0.27886807 + \n                     t * (-1.13520398 + \n                     t * ( 1.48851587 + \n                     t * (-0.82215223 + \n                     t * 0.17087277)))))))))\n        if (y >= 0.0) return 1-ans\n        return 1+ans\n    },\n    exp: function(x){\n         if (_b_.$isninf(x)) {return float(0)}\n         if (_b_.$isinf(x)) {return float('inf')}\n         var _r=Math.exp(float_check(x))\n         if (_b_.$isinf(_r)) {throw OverflowError(\"math range error\")}\n         return float(_r)\n    },\n    expm1: function(x){return float(Math.exp(float_check(x))-1)},\n    //fabs: function(x){ return x>0?float(x):float(-x)},\n    fabs: function(x){return _b_.$fabs(x)}, //located in py_float.js\n    factorial: function(x) {\n         //using code from http://stackoverflow.com/questions/3959211/fast-factorial-function-in-javascript\n         var y=float_check(x);\n         var r=1\n         for (var i=2; i<=y; i++){r*=i}\n         return r\n    },\n    floor:function(x){return Math.floor(float_check(x))},\n    fmod:function(x,y){return float(float_check(x)%float_check(y))},\n    frexp: function(x){return _b_.tuple(_b_.$frexp(x))}, // located in py_float.js\n    //fsum:function(x){},\n    gamma: function(x){\n         //using code from http://stackoverflow.com/questions/3959211/fast-factorial-function-in-javascript\n         // Lanczos Approximation of the Gamma Function\n         // As described in Numerical Recipes in C (2nd ed. Cambridge University Press, 1992)\n         var y=float_check(x);\n         var z = y + 1;\n         var d1 = Math.sqrt(2 * Math.PI) / z;\n\n         var d2 = 1.000000000190015;\n         d2 +=  76.18009172947146 / (z+1);\n         d2 += -86.50532032941677 / (z+2);\n         d2 +=  24.01409824083091 / (z+3); \n         d2 += -1.231739572450155 / (z+4); \n         d2 +=  1.208650973866179E-3 / (z+5);\n         d2 += -5.395239384953E-6 / (z+6);\n\n         return d1 * d2 * Math.pow(z+5.5,z+0.5) * Math.exp(-(z+5.5));\n    },\n    hypot: function(x,y){\n       if (_b_.$isinf(x) || _b_.$isinf(y)) return float('inf')\n       var x1=float_check(x);\n       var y1=float_check(y);\n       return float(Math.sqrt(x1*x1 + y1*y1))},\n    isfinite:function(x) {return isFinite(float_check(x))},\n    isinf:function(x) {return _b_.$isinf(float_check(x))},\n    isnan:function(x) {return isNaN(float_check(x))},\n    ldexp:function(x,i) {return _b_.$ldexp(x,i)},   //located in py_float.js\n    lgamma:function(x) {\n         // see gamma function for sources\n         var y=float_check(x);\n         var z = y + 1;\n         var d1 = Math.sqrt(2 * Math.PI) / z;\n\n         var d2 = 1.000000000190015;\n         d2 +=  76.18009172947146 / (z+1);\n         d2 += -86.50532032941677 / (z+2);\n         d2 +=  24.01409824083091 / (z+3); \n         d2 += -1.231739572450155 / (z+4); \n         d2 +=  1.208650973866179E-3 / (z+5);\n         d2 += -5.395239384953E-6 / (z+6);\n\n         return float(Math.log(Math.abs(d1 * d2 * Math.pow(z+5.5,z+0.5) * Math.exp(-(z+5.5)))));\n    },\n    log: function(x, base) {\n         var x1=float_check(x);\n         if (base === undefined) return float(Math.log(x1));\n         return float(Math.log(x1)/Math.log(float_check(base)));\n    },\n    log1p: function(x) {return float(Math.log(1.0 + float_check(x)))},\n    log2: function(x) {\n        if (isNaN(x)) return float('nan')\n        if (_b_.$isninf(x)) throw ValueError('')\n        var x1=float_check(x)\n        if (x1 < 0.0) throw ValueError('')\n        //if (isLargeNumber(x1)) x1=new BigNumber(x1)         \n        return float(Math.log(x1)/Math.LN2)\n    },\n    log10: function(x) {return float(Math.log(float_check(x))/Math.LN10)},\n    modf:function(x) {\n       if (_b_.$isninf(x)) return _b_.tuple([0.0, float('-inf')])\n       if (_b_.$isinf(x)) return _b_.tuple([0.0, float('inf')])\n       if (isNaN(x)) return _b_.tuple([float('nan'), float('nan')])\n\n       var x1=float_check(x);\n       if (x1 > 0) {\n          var i=float(x1-Math.floor(x1))\n          return _b_.tuple([i, float(x1-i)])\n       }\n\n       var x2=Math.ceil(x1)\n       var i=float(x1-x2)\n       return _b_.tuple([i, float(x2)])\n    },\n    pi : float(Math.PI),\n    pow: function(x,y) {\n        var x1=float_check(x)\n        var y1=float_check(y)\n        if (y1 == 0) return float(1)        \n        if (x1 == 0 && y1 < 0) throw _b_.ValueError('')\n\n        if(isNaN(y1)) {if(x1==1) return float(1) \n                       return float('nan')\n        }\n        if (x1 == 0) return float(0)\n\n        if(_b_.$isninf(y)) {if(x1==1||x1==-1) {return float(1)}\n                       if(x1 < 1 && x1 > -1) return float('inf') \n                       return float(0)\n        }\n        if(_b_.$isinf(y)) {if(x1==1||x1==-1) {return float(1)} \n                      if(x1 < 1 && x1 > -1) return float(0) \n                      return float('inf')}\n\n        if(isNaN(x1)) return float('nan')\n        if(_b_.$isninf(x)) {\n            if (y1 > 0 && isOdd(y1)) return float('-inf')\n            if (y1 > 0) return float('inf')  // this is even or a float\n            if (y1 < 0) return float(0)\n            return float(1)\n        }\n\n        if(_b_.$isinf(x)) { \n            if (y1 > 0) return float('inf')\n            if (y1 < 0) return float(0)\n            return float(1)\n        }\n\n        var r\n        if (isLargeNumber(x1) || isLargeNumber(y1)) {\n           var x=new BigNumber(x1)\n           var y=new BigNumber(y1)\n           r=x.pow(y)\n        } else {\n           r=Math.pow(x1,y1)\n        }\n\n        if (isNaN(r)) return float('nan')\n        if (_b_.$isninf(r)) return float('-inf')\n        if (_b_.$isinf(r)) return float('inf')\n\n        return r\n    },\n    radians: function(x){return float(float_check(x) * Math.PI/180)},\n    sin : function(x){return float(Math.sin(float_check(x)))},\n    sinh: function(x) { \n        //if (_b_.$isinf(x)) return float('inf');\n        var y = float_check(x)\n        if (Math.sinh !== undefined) { return float(Math.sinh(y))}\n        return float((Math.pow(Math.E,y) - Math.pow(Math.E,-y))/2)\n    },\n    sqrt : function(x){\n      var y = float_check(x)\n      if (y < 0) { throw ValueError(\"math range error\")}\n      if (_b_.$isinf(y)) return float('inf')\n      var _r=Math.sqrt(y)\n      if (_b_.$isinf(_r)) {throw OverflowError(\"math range error\")}\n      return float(_r)\n    },\n    tan: function(x) {\n        var y = float_check(x)\n        return float(Math.tan(y))\n    },\n    tanh: function(x) {\n        var y = float_check(x)\n        if (Math.tanh !== undefined) return float(Math.tanh(y))\n        return float((Math.pow(Math.E,y) - Math.pow(Math.E,-y))/\n                     (Math.pow(Math.E,y) + Math.pow(Math.E,-y)))       \n    },\n    trunc: function(x) {\n       try{return getattr(x,'__trunc__')()}catch(err){$B.$pop_exc()}\n       var x1=float_check(x);\n       if (!isNaN(parseFloat(x1)) && isFinite(x1)) {\n          if (Math.trunc !== undefined) { return int(Math.trunc(x1))}\n          if (x1 > 0) {return int(Math.floor(x1))}\n          return int(Math.ceil(x1))  // x1 < 0\n       }\n       $raise('ValueError', 'object is not a number and does not contain __trunc__')\n    }\n}\n\nfor(var $attr in _mod){\n    if(typeof _mod[$attr]==='function'){\n        _mod[$attr].__repr__=(function(func){\n            return function(){return '<built-in function '+func+'>'}})($attr)\n        _mod[$attr].__str__=(function(func){\n            return function(){return '<built-in function '+func+'>'}})($attr)\n    }\n}\n\nreturn _mod\n\n})(__BRYTHON__)\n"], "unittest.loader": [".py", "\"\"\n\nimport os\nimport re\nimport sys\nimport traceback\nimport types\nimport functools\n\nfrom fnmatch import fnmatch\n\nfrom . import case, suite, util\n\n__unittest = True\n\n\n\n\nVALID_MODULE_NAME = re.compile(r'[_a-z]\\w*\\.py$', re.IGNORECASE)\n\n\ndef _make_failed_import_test(name, suiteClass):\n message = 'Failed to import test module: %s\\n%s' % (name, traceback.format_exc())\n return _make_failed_test('ModuleImportFailure', name, ImportError(message),\n suiteClass)\n \ndef _make_failed_load_tests(name, exception, suiteClass):\n return _make_failed_test('LoadTestsFailure', name, exception, suiteClass)\n \ndef _make_failed_test(classname, methodname, exception, suiteClass):\n def testFailure(self):\n  raise exception\n attrs = {methodname: testFailure}\n TestClass = type(classname, (case.TestCase,), attrs)\n return suiteClass((TestClass(methodname),))\n \ndef _jython_aware_splitext(path):\n if path.lower().endswith('$py.class'):\n  return path[:-9]\n return os.path.splitext(path)[0]\n \n \nclass TestLoader(object):\n \"\"\n testMethodPrefix = 'test'\n sortTestMethodsUsing = staticmethod(util.three_way_cmp)\n suiteClass = suite.TestSuite\n _top_level_dir = None\n \n def loadTestsFromTestCase(self, testCaseClass):\n  \"\"\n  if issubclass(testCaseClass, suite.TestSuite):\n   raise TypeError(\"Test cases should not be derived from TestSuite.\" \" Maybe you meant to derive from TestCase?\")\n  testCaseNames = self.getTestCaseNames(testCaseClass)\n  if not testCaseNames and hasattr(testCaseClass, 'runTest'):\n   testCaseNames = ['runTest']\n  loaded_suite = self.suiteClass(map(testCaseClass, testCaseNames))\n  return loaded_suite\n  \n def loadTestsFromModule(self, module, use_load_tests=True):\n  \"\"\n  tests = []\n  for name in dir(module):\n   obj = getattr(module, name)\n   if isinstance(obj, type) and issubclass(obj, case.TestCase):\n    tests.append(self.loadTestsFromTestCase(obj))\n    \n  load_tests = getattr(module, 'load_tests', None)\n  tests = self.suiteClass(tests)\n  if use_load_tests and load_tests is not None:\n   try:\n    return load_tests(self, tests, None)\n   except Exception as e:\n    return _make_failed_load_tests(module.__name__, e,\n    self.suiteClass)\n  return tests\n  \n def loadTestsFromName(self, name, module=None):\n  \"\"\n  parts = name.split('.')\n  if module is None:\n   parts_copy = parts[:]\n   while parts_copy:\n    try:\n     module = __import__('.'.join(parts_copy))\n     break\n    except ImportError:\n     del parts_copy[-1]\n     if not parts_copy:\n      raise\n   parts = parts[1:]\n  obj = module\n  for part in parts:\n   parent, obj = obj, getattr(obj, part)\n   \n  if isinstance(obj, types.ModuleType):\n   return self.loadTestsFromModule(obj)\n  elif isinstance(obj, type) and issubclass(obj, case.TestCase):\n   return self.loadTestsFromTestCase(obj)\n  elif (isinstance(obj, types.FunctionType) and\n  isinstance(parent, type) and\n  issubclass(parent, case.TestCase)):\n   name = parts[-1]\n   inst = parent(name)\n   \n   if not isinstance(getattr(inst, name), types.FunctionType):\n    return self.suiteClass([inst])\n  elif isinstance(obj, suite.TestSuite):\n   return obj\n  if callable(obj):\n   test = obj()\n   if isinstance(test, suite.TestSuite):\n    return test\n   elif isinstance(test, case.TestCase):\n    return self.suiteClass([test])\n   else:\n    raise TypeError(\"calling %s returned %s, not a test\" %\n    (obj, test))\n  else:\n   raise TypeError(\"don't know how to make test from: %s\" % obj)\n   \n def loadTestsFromNames(self, names, module=None):\n  \"\"\n  suites = [self.loadTestsFromName(name, module) for name in names]\n  return self.suiteClass(suites)\n  \n def getTestCaseNames(self, testCaseClass):\n  \"\"\n  def isTestMethod(attrname, testCaseClass=testCaseClass,\n  prefix=self.testMethodPrefix):\n   return attrname.startswith(prefix) and callable(getattr(testCaseClass, attrname))\n  testFnNames = list(filter(isTestMethod, dir(testCaseClass)))\n  if self.sortTestMethodsUsing:\n   testFnNames.sort(key=functools.cmp_to_key(self.sortTestMethodsUsing))\n  return testFnNames\n  \n def discover(self, start_dir, pattern='test*.py', top_level_dir=None):\n  \"\"\n  set_implicit_top = False\n  if top_level_dir is None and self._top_level_dir is not None:\n  \n   top_level_dir = self._top_level_dir\n  elif top_level_dir is None:\n   set_implicit_top = True\n   top_level_dir = start_dir\n   \n  top_level_dir = os.path.abspath(top_level_dir)\n  \n  if not top_level_dir in sys.path:\n  \n  \n  \n  \n   sys.path.insert(0, top_level_dir)\n  self._top_level_dir = top_level_dir\n  \n  is_not_importable = False\n  if os.path.isdir(os.path.abspath(start_dir)):\n   start_dir = os.path.abspath(start_dir)\n   if start_dir != top_level_dir:\n    is_not_importable = not os.path.isfile(os.path.join(start_dir, '__init__.py'))\n  else:\n  \n   try:\n    __import__(start_dir)\n   except ImportError:\n    is_not_importable = True\n   else:\n    the_module = sys.modules[start_dir]\n    top_part = start_dir.split('.')[0]\n    start_dir = os.path.abspath(os.path.dirname((the_module.__file__)))\n    if set_implicit_top:\n     self._top_level_dir = self._get_directory_containing_module(top_part)\n     sys.path.remove(top_level_dir)\n     \n  if is_not_importable:\n   raise ImportError('Start directory is not importable: %r' % start_dir)\n   \n  tests = list(self._find_tests(start_dir, pattern))\n  return self.suiteClass(tests)\n  \n def _get_directory_containing_module(self, module_name):\n  module = sys.modules[module_name]\n  full_path = os.path.abspath(module.__file__)\n  \n  if os.path.basename(full_path).lower().startswith('__init__.py'):\n   return os.path.dirname(os.path.dirname(full_path))\n  else:\n  \n  \n  \n   return os.path.dirname(full_path)\n   \n def _get_name_from_path(self, path):\n  path = _jython_aware_splitext(os.path.normpath(path))\n  \n  _relpath = os.path.relpath(path, self._top_level_dir)\n  assert not os.path.isabs(_relpath), \"Path must be within the project\"\n  assert not _relpath.startswith('..'), \"Path must be within the project\"\n  \n  name = _relpath.replace(os.path.sep, '.')\n  return name\n  \n def _get_module_from_name(self, name):\n  __import__(name)\n  return sys.modules[name]\n  \n def _match_path(self, path, full_path, pattern):\n \n  return fnmatch(path, pattern)\n  \n def _find_tests(self, start_dir, pattern):\n  \"\"\n  paths = os.listdir(start_dir)\n  \n  for path in paths:\n   full_path = os.path.join(start_dir, path)\n   if os.path.isfile(full_path):\n    if not VALID_MODULE_NAME.match(path):\n    \n     continue\n    if not self._match_path(path, full_path, pattern):\n     continue\n     \n    name = self._get_name_from_path(full_path)\n    try:\n     module = self._get_module_from_name(name)\n    except:\n     yield _make_failed_import_test(name, self.suiteClass)\n    else:\n     mod_file = os.path.abspath(getattr(module, '__file__', full_path))\n     realpath = _jython_aware_splitext(os.path.realpath(mod_file))\n     fullpath_noext = _jython_aware_splitext(os.path.realpath(full_path))\n     if realpath.lower() != fullpath_noext.lower():\n      module_dir = os.path.dirname(realpath)\n      mod_name = _jython_aware_splitext(os.path.basename(full_path))\n      expected_dir = os.path.dirname(full_path)\n      msg = (\"%r module incorrectly imported from %r. Expected %r. \"\n      \"Is this module globally installed?\")\n      raise ImportError(msg % (mod_name, module_dir, expected_dir))\n     yield self.loadTestsFromModule(module)\n   elif os.path.isdir(full_path):\n    if not os.path.isfile(os.path.join(full_path, '__init__.py')):\n     continue\n     \n    load_tests = None\n    tests = None\n    if fnmatch(path, pattern):\n    \n     name = self._get_name_from_path(full_path)\n     package = self._get_module_from_name(name)\n     load_tests = getattr(package, 'load_tests', None)\n     tests = self.loadTestsFromModule(package, use_load_tests=False)\n     \n    if load_tests is None:\n     if tests is not None:\n     \n      yield tests\n      \n     for test in self._find_tests(full_path, pattern):\n      yield test\n    else:\n     try:\n      yield load_tests(self, tests, pattern)\n     except Exception as e:\n      yield _make_failed_load_tests(package.__name__, e,\n      self.suiteClass)\n      \ndefaultTestLoader = TestLoader()\n\n\ndef _makeLoader(prefix, sortUsing, suiteClass=None):\n loader = TestLoader()\n loader.sortTestMethodsUsing = sortUsing\n loader.testMethodPrefix = prefix\n if suiteClass:\n  loader.suiteClass = suiteClass\n return loader\n \ndef getTestCaseNames(testCaseClass, prefix, sortUsing=util.three_way_cmp):\n return _makeLoader(prefix, sortUsing).getTestCaseNames(testCaseClass)\n \ndef makeSuite(testCaseClass, prefix='test', sortUsing=util.three_way_cmp,\nsuiteClass=suite.TestSuite):\n return _makeLoader(prefix, sortUsing, suiteClass).loadTestsFromTestCase(\n testCaseClass)\n \ndef findTestCases(module, prefix='test', sortUsing=util.three_way_cmp,\nsuiteClass=suite.TestSuite):\n return _makeLoader(prefix, sortUsing, suiteClass).loadTestsFromModule( module)\n"], "unittest.case": [".py", "\"\"\n\nimport sys\nimport functools\nimport difflib\nimport pprint\nimport re\nimport warnings\nimport collections\n\nfrom . import result\nfrom .util import (strclass, safe_repr, _count_diff_all_purpose,\n_count_diff_hashable)\n\n__unittest = True\n\n\nDIFF_OMITTED = ('\\nDiff is %s characters long. '\n'Set self.maxDiff to None to see it.')\n\nclass SkipTest(Exception):\n \"\"\n \nclass _ExpectedFailure(Exception):\n \"\"\n \n def __init__(self, exc_info):\n  super(_ExpectedFailure, self).__init__()\n  self.exc_info = exc_info\n  \nclass _UnexpectedSuccess(Exception):\n \"\"\n \n \nclass _Outcome(object):\n def __init__(self):\n  self.success = True\n  self.skipped = None\n  self.unexpectedSuccess = None\n  self.expectedFailure = None\n  self.errors = []\n  self.failures = []\n  \n  \ndef _id(obj):\n return obj\n \ndef skip(reason):\n \"\"\n def decorator(test_item):\n  if not isinstance(test_item, type):\n   @functools.wraps(test_item)\n   def skip_wrapper(*args, **kwargs):\n    raise SkipTest(reason)\n   test_item = skip_wrapper\n   \n  test_item.__unittest_skip__ = True\n  test_item.__unittest_skip_why__ = reason\n  return test_item\n return decorator\n \ndef skipIf(condition, reason):\n \"\"\n if condition:\n  return skip(reason)\n return _id\n \ndef skipUnless(condition, reason):\n \"\"\n if not condition:\n  return skip(reason)\n return _id\n \n \ndef expectedFailure(func):\n @functools.wraps(func)\n def wrapper(*args, **kwargs):\n  try:\n   func(*args, **kwargs)\n  except Exception:\n   raise _ExpectedFailure(sys.exc_info())\n  raise _UnexpectedSuccess\n return wrapper\n \n \nclass _AssertRaisesBaseContext(object):\n\n def __init__(self, expected, test_case, callable_obj=None,\n expected_regex=None):\n  self.expected = expected\n  self.test_case = test_case\n  if callable_obj is not None:\n   try:\n    self.obj_name = callable_obj.__name__\n   except AttributeError:\n    self.obj_name = str(callable_obj)\n  else:\n   self.obj_name = None\n  if isinstance(expected_regex, (bytes, str)):\n   expected_regex = re.compile(expected_regex)\n  self.expected_regex = expected_regex\n  self.msg = None\n  \n def _raiseFailure(self, standardMsg):\n  msg = self.test_case._formatMessage(self.msg, standardMsg)\n  raise self.test_case.failureException(msg)\n  \n def handle(self, name, callable_obj, args, kwargs):\n  \"\"\n  if callable_obj is None:\n   self.msg = kwargs.pop('msg', None)\n   return self\n  with self:\n   callable_obj(*args, **kwargs)\n   \n   \n   \nclass _AssertRaisesContext(_AssertRaisesBaseContext):\n \"\"\n \n def __enter__(self):\n  return self\n  \n def __exit__(self, exc_type, exc_value, tb):\n  if exc_type is None:\n   try:\n    exc_name = self.expected.__name__\n   except AttributeError:\n    exc_name = str(self.expected)\n   if self.obj_name:\n    self._raiseFailure(\"{} not raised by {}\".format(exc_name,\n    self.obj_name))\n   else:\n    self._raiseFailure(\"{} not raised\".format(exc_name))\n  if not issubclass(exc_type, self.expected):\n  \n   return False\n   \n  self.exception = exc_value.with_traceback(None)\n  if self.expected_regex is None:\n   return True\n   \n  expected_regex = self.expected_regex\n  if not expected_regex.search(str(exc_value)):\n   self._raiseFailure('\"{}\" does not match \"{}\"'.format(\n   expected_regex.pattern, str(exc_value)))\n  return True\n  \n  \nclass _AssertWarnsContext(_AssertRaisesBaseContext):\n \"\"\n \n def __enter__(self):\n \n \n  for v in sys.modules.values():\n   if getattr(v, '__warningregistry__', None):\n    v.__warningregistry__ = {}\n  self.warnings_manager = warnings.catch_warnings(record=True)\n  self.warnings = self.warnings_manager.__enter__()\n  warnings.simplefilter(\"always\", self.expected)\n  return self\n  \n def __exit__(self, exc_type, exc_value, tb):\n  self.warnings_manager.__exit__(exc_type, exc_value, tb)\n  if exc_type is not None:\n  \n   return\n  try:\n   exc_name = self.expected.__name__\n  except AttributeError:\n   exc_name = str(self.expected)\n  first_matching = None\n  for m in self.warnings:\n   w = m.message\n   if not isinstance(w, self.expected):\n    continue\n   if first_matching is None:\n    first_matching = w\n   if (self.expected_regex is not None and\n   not self.expected_regex.search(str(w))):\n    continue\n    \n   self.warning = w\n   self.filename = m.filename\n   self.lineno = m.lineno\n   return\n   \n  if first_matching is not None:\n   self._raiseFailure('\"{}\" does not match \"{}\"'.format(\n   self.expected_regex.pattern, str(first_matching)))\n  if self.obj_name:\n   self._raiseFailure(\"{} not triggered by {}\".format(exc_name,\n   self.obj_name))\n  else:\n   self._raiseFailure(\"{} not triggered\".format(exc_name))\n   \n   \nclass TestCase(object):\n \"\"\n \n failureException = AssertionError\n \n longMessage = True\n \n maxDiff = 80*8\n \n \n \n _diffThreshold = 2**16\n \n \n \n _classSetupFailed = False\n \n def __init__(self, methodName='runTest'):\n  \"\"\n  self._testMethodName = methodName\n  self._outcomeForDoCleanups = None\n  self._testMethodDoc = 'No test'\n  try:\n   testMethod = getattr(self, methodName)\n  except AttributeError:\n   if methodName != 'runTest':\n   \n   \n    raise ValueError(\"no such test method in %s: %s\" %\n    (self.__class__, methodName))\n  else:\n   self._testMethodDoc = testMethod.__doc__\n  self._cleanups = []\n  \n  \n  \n  \n  self._type_equality_funcs = {}\n  self.addTypeEqualityFunc(dict, 'assertDictEqual')\n  self.addTypeEqualityFunc(list, 'assertListEqual')\n  self.addTypeEqualityFunc(tuple, 'assertTupleEqual')\n  self.addTypeEqualityFunc(set, 'assertSetEqual')\n  self.addTypeEqualityFunc(frozenset, 'assertSetEqual')\n  self.addTypeEqualityFunc(str, 'assertMultiLineEqual')\n  \n def addTypeEqualityFunc(self, typeobj, function):\n  \"\"\n  self._type_equality_funcs[typeobj] = function\n  \n def addCleanup(self, function, *args, **kwargs):\n  \"\"\n  self._cleanups.append((function, args, kwargs))\n  \n def setUp(self):\n  \"\"\n  pass\n  \n def tearDown(self):\n  \"\"\n  pass\n  \n @classmethod\n def setUpClass(cls):\n  \"\"\n  \n @classmethod\n def tearDownClass(cls):\n  \"\"\n  \n def countTestCases(self):\n  return 1\n  \n def defaultTestResult(self):\n  return result.TestResult()\n  \n def shortDescription(self):\n  \"\"\n  doc = self._testMethodDoc\n  return doc and doc.split(\"\\n\")[0].strip() or None\n  \n  \n def id(self):\n  return \"%s.%s\" % (strclass(self.__class__), self._testMethodName)\n  \n def __eq__(self, other):\n  if type(self) is not type(other):\n   return NotImplemented\n   \n  return self._testMethodName == other._testMethodName\n  \n def __hash__(self):\n  return hash((type(self), self._testMethodName))\n  \n def __str__(self):\n  return \"%s (%s)\" % (self._testMethodName, strclass(self.__class__))\n  \n def __repr__(self):\n  return \"<%s testMethod=%s>\" % (strclass(self.__class__), self._testMethodName)\n  \n def _addSkip(self, result, reason):\n  addSkip = getattr(result, 'addSkip', None)\n  if addSkip is not None:\n   addSkip(self, reason)\n  else:\n   warnings.warn(\"TestResult has no addSkip method, skips not reported\",\n   RuntimeWarning, 2)\n   result.addSuccess(self)\n   \n def _executeTestPart(self, function, outcome, isTest=False):\n  try:\n   function()\n  except KeyboardInterrupt:\n   raise\n  except SkipTest as e:\n   outcome.success = False\n   outcome.skipped = str(e)\n  except _UnexpectedSuccess:\n   exc_info = sys.exc_info()\n   outcome.success = False\n   if isTest:\n    outcome.unexpectedSuccess = exc_info\n   else:\n    outcome.errors.append(exc_info)\n  except _ExpectedFailure:\n   outcome.success = False\n   exc_info = sys.exc_info()\n   if isTest:\n    outcome.expectedFailure = exc_info\n   else:\n    outcome.errors.append(exc_info)\n  except self.failureException:\n   outcome.success = False\n   outcome.failures.append(sys.exc_info())\n   exc_info = sys.exc_info()\n  except:\n   outcome.success = False\n   outcome.errors.append(sys.exc_info())\n   \n def run(self, result=None):\n  orig_result = result\n  if result is None:\n   result = self.defaultTestResult()\n   startTestRun = getattr(result, 'startTestRun', None)\n   if startTestRun is not None:\n    startTestRun()\n    \n  result.startTest(self)\n  \n  testMethod = getattr(self, self._testMethodName)\n  if (getattr(self.__class__, \"__unittest_skip__\", False) or\n  getattr(testMethod, \"__unittest_skip__\", False)):\n  \n   try:\n    skip_why = (getattr(self.__class__, '__unittest_skip_why__', '')\n    or getattr(testMethod, '__unittest_skip_why__', ''))\n    self._addSkip(result, skip_why)\n   finally:\n    result.stopTest(self)\n   return\n  try:\n   outcome = _Outcome()\n   self._outcomeForDoCleanups = outcome\n   \n   self._executeTestPart(self.setUp, outcome)\n   if outcome.success:\n    self._executeTestPart(testMethod, outcome, isTest=True)\n    self._executeTestPart(self.tearDown, outcome)\n    \n   self.doCleanups()\n   if outcome.success:\n    result.addSuccess(self)\n   else:\n    if outcome.skipped is not None:\n     self._addSkip(result, outcome.skipped)\n    for exc_info in outcome.errors:\n     result.addError(self, exc_info)\n    for exc_info in outcome.failures:\n     result.addFailure(self, exc_info)\n    if outcome.unexpectedSuccess is not None:\n     addUnexpectedSuccess = getattr(result, 'addUnexpectedSuccess', None)\n     if addUnexpectedSuccess is not None:\n      addUnexpectedSuccess(self)\n     else:\n      warnings.warn(\"TestResult has no addUnexpectedSuccess method, reporting as failures\",\n      RuntimeWarning)\n      result.addFailure(self, outcome.unexpectedSuccess)\n      \n    if outcome.expectedFailure is not None:\n     addExpectedFailure = getattr(result, 'addExpectedFailure', None)\n     if addExpectedFailure is not None:\n      addExpectedFailure(self, outcome.expectedFailure)\n     else:\n      warnings.warn(\"TestResult has no addExpectedFailure method, reporting as passes\",\n      RuntimeWarning)\n      result.addSuccess(self)\n   return result\n  finally:\n   result.stopTest(self)\n   if orig_result is None:\n    stopTestRun = getattr(result, 'stopTestRun', None)\n    if stopTestRun is not None:\n     stopTestRun()\n     \n def doCleanups(self):\n  \"\"\n  outcome = self._outcomeForDoCleanups or _Outcome()\n  while self._cleanups:\n   function, args, kwargs = self._cleanups.pop()\n   part = lambda: function(*args, **kwargs)\n   self._executeTestPart(part, outcome)\n   \n   \n   \n  return outcome.success\n  \n def __call__(self, *args, **kwds):\n  return self.run(*args, **kwds)\n  \n def debug(self):\n  \"\"\n  self.setUp()\n  getattr(self, self._testMethodName)()\n  self.tearDown()\n  while self._cleanups:\n   function, args, kwargs = self._cleanups.pop(-1)\n   function(*args, **kwargs)\n   \n def skipTest(self, reason):\n  \"\"\n  raise SkipTest(reason)\n  \n def fail(self, msg=None):\n  \"\"\n  raise self.failureException(msg)\n  \n def assertFalse(self, expr, msg=None):\n  \"\"\n  if expr:\n   msg = self._formatMessage(msg, \"%s is not false\" % safe_repr(expr))\n   raise self.failureException(msg)\n   \n def assertTrue(self, expr, msg=None):\n  \"\"\n  if not expr:\n   msg = self._formatMessage(msg, \"%s is not true\" % safe_repr(expr))\n   raise self.failureException(msg)\n   \n def _formatMessage(self, msg, standardMsg):\n  \"\"\n  if not self.longMessage:\n   return msg or standardMsg\n  if msg is None:\n   return standardMsg\n  try:\n  \n  \n   return '%s : %s' % (standardMsg, msg)\n  except UnicodeDecodeError:\n   return '%s : %s' % (safe_repr(standardMsg), safe_repr(msg))\n   \n def assertRaises(self, excClass, callableObj=None, *args, **kwargs):\n  \"\"\n  context = _AssertRaisesContext(excClass, self, callableObj)\n  return context.handle('assertRaises', callableObj, args, kwargs)\n  \n def assertWarns(self, expected_warning, callable_obj=None, *args, **kwargs):\n  \"\"\n  context = _AssertWarnsContext(expected_warning, self, callable_obj)\n  return context.handle('assertWarns', callable_obj, args, kwargs)\n  \n def _getAssertEqualityFunc(self, first, second):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  if type(first) is type(second):\n   asserter = self._type_equality_funcs.get(type(first))\n   if asserter is not None:\n    if isinstance(asserter, str):\n     asserter = getattr(self, asserter)\n    return asserter\n    \n  return self._baseAssertEqual\n  \n def _baseAssertEqual(self, first, second, msg=None):\n  \"\"\n  if not first == second:\n   standardMsg = '%s != %s' % (safe_repr(first), safe_repr(second))\n   msg = self._formatMessage(msg, standardMsg)\n   raise self.failureException(msg)\n   \n def assertEqual(self, first, second, msg=None):\n  \"\"\n  assertion_func = self._getAssertEqualityFunc(first, second)\n  assertion_func(first, second, msg=msg)\n  \n def assertNotEqual(self, first, second, msg=None):\n  \"\"\n  if not first != second:\n   msg = self._formatMessage(msg, '%s == %s' % (safe_repr(first),\n   safe_repr(second)))\n   raise self.failureException(msg)\n   \n def assertAlmostEqual(self, first, second, places=None, msg=None,\n delta=None):\n  \"\"\n  if first == second:\n  \n   return\n  if delta is not None and places is not None:\n   raise TypeError(\"specify delta or places not both\")\n   \n  if delta is not None:\n   if abs(first - second) <= delta:\n    return\n    \n   standardMsg = '%s != %s within %s delta' % (safe_repr(first),\n   safe_repr(second),\n   safe_repr(delta))\n  else:\n   if places is None:\n    places = 7\n    \n   if round(abs(second-first), places) == 0:\n    return\n    \n   standardMsg = '%s != %s within %r places' % (safe_repr(first),\n   safe_repr(second),\n   places)\n  msg = self._formatMessage(msg, standardMsg)\n  raise self.failureException(msg)\n  \n def assertNotAlmostEqual(self, first, second, places=None, msg=None,\n delta=None):\n  \"\"\n  if delta is not None and places is not None:\n   raise TypeError(\"specify delta or places not both\")\n  if delta is not None:\n   if not (first == second) and abs(first - second) > delta:\n    return\n   standardMsg = '%s == %s within %s delta' % (safe_repr(first),\n   safe_repr(second),\n   safe_repr(delta))\n  else:\n   if places is None:\n    places = 7\n   if not (first == second) and round(abs(second-first), places) != 0:\n    return\n   standardMsg = '%s == %s within %r places' % (safe_repr(first),\n   safe_repr(second),\n   places)\n   \n  msg = self._formatMessage(msg, standardMsg)\n  raise self.failureException(msg)\n  \n  \n def assertSequenceEqual(self, seq1, seq2, msg=None, seq_type=None):\n  \"\"\n  if seq_type is not None:\n   seq_type_name = seq_type.__name__\n   if not isinstance(seq1, seq_type):\n    raise self.failureException('First sequence is not a %s: %s'\n    % (seq_type_name, safe_repr(seq1)))\n   if not isinstance(seq2, seq_type):\n    raise self.failureException('Second sequence is not a %s: %s'\n    % (seq_type_name, safe_repr(seq2)))\n  else:\n   seq_type_name = \"sequence\"\n   \n  differing = None\n  try:\n   len1 = len(seq1)\n  except (TypeError, NotImplementedError):\n   differing = 'First %s has no length.    Non-sequence?' % (\n   seq_type_name)\n   \n  if differing is None:\n   try:\n    len2 = len(seq2)\n   except (TypeError, NotImplementedError):\n    differing = 'Second %s has no length.    Non-sequence?' % (\n    seq_type_name)\n    \n  if differing is None:\n   if seq1 == seq2:\n    return\n    \n   seq1_repr = safe_repr(seq1)\n   seq2_repr = safe_repr(seq2)\n   if len(seq1_repr) > 30:\n    seq1_repr = seq1_repr[:30] + '...'\n   if len(seq2_repr) > 30:\n    seq2_repr = seq2_repr[:30] + '...'\n   elements = (seq_type_name.capitalize(), seq1_repr, seq2_repr)\n   differing = '%ss differ: %s != %s\\n' % elements\n   \n   for i in range(min(len1, len2)):\n    try:\n     item1 = seq1[i]\n    except (TypeError, IndexError, NotImplementedError):\n     differing += ('\\nUnable to index element %d of first %s\\n' %\n     (i, seq_type_name))\n     break\n     \n    try:\n     item2 = seq2[i]\n    except (TypeError, IndexError, NotImplementedError):\n     differing += ('\\nUnable to index element %d of second %s\\n' %\n     (i, seq_type_name))\n     break\n     \n    if item1 != item2:\n     differing += ('\\nFirst differing element %d:\\n%s\\n%s\\n' %\n     (i, item1, item2))\n     break\n   else:\n    if (len1 == len2 and seq_type is None and\n    type(seq1) != type(seq2)):\n    \n     return\n     \n   if len1 > len2:\n    differing += ('\\nFirst %s contains %d additional '\n    'elements.\\n' % (seq_type_name, len1 - len2))\n    try:\n     differing += ('First extra element %d:\\n%s\\n' %\n     (len2, seq1[len2]))\n    except (TypeError, IndexError, NotImplementedError):\n     differing += ('Unable to index element %d '\n     'of first %s\\n' % (len2, seq_type_name))\n   elif len1 < len2:\n    differing += ('\\nSecond %s contains %d additional '\n    'elements.\\n' % (seq_type_name, len2 - len1))\n    try:\n     differing += ('First extra element %d:\\n%s\\n' %\n     (len1, seq2[len1]))\n    except (TypeError, IndexError, NotImplementedError):\n     differing += ('Unable to index element %d '\n     'of second %s\\n' % (len1, seq_type_name))\n  standardMsg = differing\n  diffMsg = '\\n' + '\\n'.join(\n  difflib.ndiff(pprint.pformat(seq1).splitlines(),\n  pprint.pformat(seq2).splitlines()))\n  \n  standardMsg = self._truncateMessage(standardMsg, diffMsg)\n  msg = self._formatMessage(msg, standardMsg)\n  self.fail(msg)\n  \n def _truncateMessage(self, message, diff):\n  max_diff = self.maxDiff\n  if max_diff is None or len(diff) <= max_diff:\n   return message + diff\n  return message + (DIFF_OMITTED % len(diff))\n  \n def assertListEqual(self, list1, list2, msg=None):\n  \"\"\n  self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  \n def assertTupleEqual(self, tuple1, tuple2, msg=None):\n  \"\"\n  self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n  \n def assertSetEqual(self, set1, set2, msg=None):\n  \"\"\n  try:\n   difference1 = set1.difference(set2)\n  except TypeError as e:\n   self.fail('invalid type when attempting set difference: %s' % e)\n  except AttributeError as e:\n   self.fail('first argument does not support set difference: %s' % e)\n   \n  try:\n   difference2 = set2.difference(set1)\n  except TypeError as e:\n   self.fail('invalid type when attempting set difference: %s' % e)\n  except AttributeError as e:\n   self.fail('second argument does not support set difference: %s' % e)\n   \n  if not (difference1 or difference2):\n   return\n   \n  lines = []\n  if difference1:\n   lines.append('Items in the first set but not the second:')\n   for item in difference1:\n    lines.append(repr(item))\n  if difference2:\n   lines.append('Items in the second set but not the first:')\n   for item in difference2:\n    lines.append(repr(item))\n    \n  standardMsg = '\\n'.join(lines)\n  self.fail(self._formatMessage(msg, standardMsg))\n  \n def assertIn(self, member, container, msg=None):\n  \"\"\n  if member not in container:\n   standardMsg = '%s not found in %s' % (safe_repr(member),\n   safe_repr(container))\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertNotIn(self, member, container, msg=None):\n  \"\"\n  if member in container:\n   standardMsg = '%s unexpectedly found in %s' % (safe_repr(member),\n   safe_repr(container))\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertIs(self, expr1, expr2, msg=None):\n  \"\"\n  if expr1 is not expr2:\n   standardMsg = '%s is not %s' % (safe_repr(expr1),\n   safe_repr(expr2))\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertIsNot(self, expr1, expr2, msg=None):\n  \"\"\n  if expr1 is expr2:\n   standardMsg = 'unexpectedly identical: %s' % (safe_repr(expr1),)\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertDictEqual(self, d1, d2, msg=None):\n  self.assertIsInstance(d1, dict, 'First argument is not a dictionary')\n  self.assertIsInstance(d2, dict, 'Second argument is not a dictionary')\n  \n  if d1 != d2:\n   standardMsg = '%s != %s' % (safe_repr(d1, True), safe_repr(d2, True))\n   diff = ('\\n' + '\\n'.join(difflib.ndiff(\n   pprint.pformat(d1).splitlines(),\n   pprint.pformat(d2).splitlines())))\n   standardMsg = self._truncateMessage(standardMsg, diff)\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertDictContainsSubset(self, subset, dictionary, msg=None):\n  \"\"\n  warnings.warn('assertDictContainsSubset is deprecated',\n  DeprecationWarning)\n  missing = []\n  mismatched = []\n  for key, value in subset.items():\n   if key not in dictionary:\n    missing.append(key)\n   elif value != dictionary[key]:\n    mismatched.append('%s, expected: %s, actual: %s' %\n    (safe_repr(key), safe_repr(value),\n    safe_repr(dictionary[key])))\n    \n  if not (missing or mismatched):\n   return\n   \n  standardMsg = ''\n  if missing:\n   standardMsg = 'Missing: %s' % ','.join(safe_repr(m) for m in\n   missing)\n  if mismatched:\n   if standardMsg:\n    standardMsg += '; '\n   standardMsg += 'Mismatched values: %s' % ','.join(mismatched)\n   \n  self.fail(self._formatMessage(msg, standardMsg))\n  \n  \n def assertCountEqual(self, first, second, msg=None):\n  \"\"\n  first_seq, second_seq = list(first), list(second)\n  try:\n   first = collections.Counter(first_seq)\n   second = collections.Counter(second_seq)\n  except TypeError:\n  \n   differences = _count_diff_all_purpose(first_seq, second_seq)\n  else:\n   if first == second:\n    return\n   differences = _count_diff_hashable(first_seq, second_seq)\n   \n  if differences:\n   standardMsg = 'Element counts were not equal:\\n'\n   lines = ['First has %d, Second has %d:  %r' % diff for diff in differences]\n   diffMsg = '\\n'.join(lines)\n   standardMsg = self._truncateMessage(standardMsg, diffMsg)\n   msg = self._formatMessage(msg, standardMsg)\n   self.fail(msg)\n   \n def assertMultiLineEqual(self, first, second, msg=None):\n  \"\"\n  self.assertIsInstance(first, str, 'First argument is not a string')\n  self.assertIsInstance(second, str, 'Second argument is not a string')\n  \n  if first != second:\n  \n   if (len(first) > self._diffThreshold or\n   len(second) > self._diffThreshold):\n    self._baseAssertEqual(first, second, msg)\n   firstlines = first.splitlines(keepends=True)\n   secondlines = second.splitlines(keepends=True)\n   if len(firstlines) == 1 and first.strip('\\r\\n') == first:\n    firstlines = [first + '\\n']\n    secondlines = [second + '\\n']\n   standardMsg = '%s != %s' % (safe_repr(first, True),\n   safe_repr(second, True))\n   diff = '\\n' + ''.join(difflib.ndiff(firstlines, secondlines))\n   standardMsg = self._truncateMessage(standardMsg, diff)\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertLess(self, a, b, msg=None):\n  \"\"\n  if not a < b:\n   standardMsg = '%s not less than %s' % (safe_repr(a), safe_repr(b))\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertLessEqual(self, a, b, msg=None):\n  \"\"\n  if not a <= b:\n   standardMsg = '%s not less than or equal to %s' % (safe_repr(a), safe_repr(b))\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertGreater(self, a, b, msg=None):\n  \"\"\n  if not a > b:\n   standardMsg = '%s not greater than %s' % (safe_repr(a), safe_repr(b))\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertGreaterEqual(self, a, b, msg=None):\n  \"\"\n  if not a >= b:\n   standardMsg = '%s not greater than or equal to %s' % (safe_repr(a), safe_repr(b))\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertIsNone(self, obj, msg=None):\n  \"\"\n  if obj is not None:\n   standardMsg = '%s is not None' % (safe_repr(obj),)\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertIsNotNone(self, obj, msg=None):\n  \"\"\n  if obj is None:\n   standardMsg = 'unexpectedly None'\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertIsInstance(self, obj, cls, msg=None):\n  \"\"\n  if not isinstance(obj, cls):\n   standardMsg = '%s is not an instance of %r' % (safe_repr(obj), cls)\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertNotIsInstance(self, obj, cls, msg=None):\n  \"\"\n  if isinstance(obj, cls):\n   standardMsg = '%s is an instance of %r' % (safe_repr(obj), cls)\n   self.fail(self._formatMessage(msg, standardMsg))\n   \n def assertRaisesRegex(self, expected_exception, expected_regex,\n callable_obj=None, *args, **kwargs):\n  \"\"\n  context = _AssertRaisesContext(expected_exception, self, callable_obj,\n  expected_regex)\n  \n  return context.handle('assertRaisesRegex', callable_obj, args, kwargs)\n  \n def assertWarnsRegex(self, expected_warning, expected_regex,\n callable_obj=None, *args, **kwargs):\n  \"\"\n  context = _AssertWarnsContext(expected_warning, self, callable_obj,\n  expected_regex)\n  return context.handle('assertWarnsRegex', callable_obj, args, kwargs)\n  \n def assertRegex(self, text, expected_regex, msg=None):\n  \"\"\n  if isinstance(expected_regex, (str, bytes)):\n   assert expected_regex, \"expected_regex must not be empty.\"\n   expected_regex = re.compile(expected_regex)\n  if not expected_regex.search(text):\n   msg = msg or \"Regex didn't match\"\n   msg = '%s: %r not found in %r' % (msg, expected_regex.pattern, text)\n   raise self.failureException(msg)\n   \n def assertNotRegex(self, text, unexpected_regex, msg=None):\n  \"\"\n  if isinstance(unexpected_regex, (str, bytes)):\n   unexpected_regex = re.compile(unexpected_regex)\n  match = unexpected_regex.search(text)\n  if match:\n   msg = msg or \"Regex matched\"\n   msg = '%s: %r matches %r in %r' % (msg,\n   text[match.start():match.end()],\n   unexpected_regex.pattern,\n   text)\n   raise self.failureException(msg)\n   \n   \n def _deprecate(original_func):\n  def deprecated_func(*args, **kwargs):\n   warnings.warn(\n   'Please use {0} instead.'.format(original_func.__name__),\n   DeprecationWarning, 2)\n   return original_func(*args, **kwargs)\n  return deprecated_func\n  \n  \n failUnlessEqual = assertEquals = _deprecate(assertEqual)\n failIfEqual = assertNotEquals = _deprecate(assertNotEqual)\n failUnlessAlmostEqual = assertAlmostEquals = _deprecate(assertAlmostEqual)\n failIfAlmostEqual = assertNotAlmostEquals = _deprecate(assertNotAlmostEqual)\n failUnless = assert_ = _deprecate(assertTrue)\n failUnlessRaises = _deprecate(assertRaises)\n failIf = _deprecate(assertFalse)\n assertRaisesRegexp = _deprecate(assertRaisesRegex)\n assertRegexpMatches = _deprecate(assertRegex)\n \n \n \nclass FunctionTestCase(TestCase):\n \"\"\n \n def __init__(self, testFunc, setUp=None, tearDown=None, description=None):\n  super(FunctionTestCase, self).__init__()\n  self._setUpFunc = setUp\n  self._tearDownFunc = tearDown\n  self._testFunc = testFunc\n  self._description = description\n  \n def setUp(self):\n  if self._setUpFunc is not None:\n   self._setUpFunc()\n   \n def tearDown(self):\n  if self._tearDownFunc is not None:\n   self._tearDownFunc()\n   \n def runTest(self):\n  self._testFunc()\n  \n def id(self):\n  return self._testFunc.__name__\n  \n def __eq__(self, other):\n  if not isinstance(other, self.__class__):\n   return NotImplemented\n   \n  return self._setUpFunc == other._setUpFunc and self._tearDownFunc == other._tearDownFunc and self._testFunc == other._testFunc and self._description == other._description\n  \n def __ne__(self, other):\n  return not self == other\n  \n def __hash__(self):\n  return hash((type(self), self._setUpFunc, self._tearDownFunc,\n  self._testFunc, self._description))\n  \n def __str__(self):\n  return \"%s (%s)\" % (strclass(self.__class__),\n  self._testFunc.__name__)\n  \n def __repr__(self):\n  return \"<%s tec=%s>\" % (strclass(self.__class__),\n  self._testFunc)\n  \n def shortDescription(self):\n  if self._description is not None:\n   return self._description\n  doc = self._testFunc.__doc__\n  return doc and doc.split(\"\\n\")[0].strip() or None\n"], "javascript": [".js", "var $module=(function($B) {\n  return {\n    JSObject: $B.JSObject,\n    JSConstructor: $B.JSConstructor,\n    console: $B.JSObject(window.console),\n    py2js: function(src){return $B.py2js(src).to_js()},\n    pyobj2jsobj:function(obj){ return $B.pyobj2jsobj(obj)},\n    jsobj2pyobj:function(obj){ return $B.jsobj2pyobj(obj)}\n  }\n})(__BRYTHON__)\n"], "unittest.test.test_suite": [".py", "import unittest\n\nimport sys\nfrom .support import LoggingResult, TestEquality\n\n\n\n\n\nclass Test(object):\n class Foo(unittest.TestCase):\n  def test_1(self): pass\n  def test_2(self): pass\n  def test_3(self): pass\n  def runTest(self): pass\n  \ndef _mk_TestSuite(*names):\n return unittest.TestSuite(Test.Foo(n) for n in names)\n \n \n \n \nclass Test_TestSuite(unittest.TestCase, TestEquality):\n\n\n\n\n\n eq_pairs = [(unittest.TestSuite(), unittest.TestSuite())\n ,(unittest.TestSuite(), unittest.TestSuite([]))\n ,(_mk_TestSuite('test_1'), _mk_TestSuite('test_1'))]\n \n \n ne_pairs = [(unittest.TestSuite(), _mk_TestSuite('test_1'))\n ,(unittest.TestSuite([]), _mk_TestSuite('test_1'))\n ,(_mk_TestSuite('test_1', 'test_2'), _mk_TestSuite('test_1', 'test_3'))\n ,(_mk_TestSuite('test_1'), _mk_TestSuite('test_2'))]\n \n \n \n \n \n \n \n \n \n \n def test_init__tests_optional(self):\n  suite = unittest.TestSuite()\n  \n  self.assertEqual(suite.countTestCases(), 0)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_init__empty_tests(self):\n  suite = unittest.TestSuite([])\n  \n  self.assertEqual(suite.countTestCases(), 0)\n  \n  \n  \n  \n  \n  \n  \n def test_init__tests_from_any_iterable(self):\n  def tests():\n   yield unittest.FunctionTestCase(lambda: None)\n   yield unittest.FunctionTestCase(lambda: None)\n   \n  suite_1 = unittest.TestSuite(tests())\n  self.assertEqual(suite_1.countTestCases(), 2)\n  \n  suite_2 = unittest.TestSuite(suite_1)\n  self.assertEqual(suite_2.countTestCases(), 2)\n  \n  suite_3 = unittest.TestSuite(set(suite_1))\n  self.assertEqual(suite_3.countTestCases(), 2)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_init__TestSuite_instances_in_tests(self):\n  def tests():\n   ftc = unittest.FunctionTestCase(lambda: None)\n   yield unittest.TestSuite([ftc])\n   yield unittest.FunctionTestCase(lambda: None)\n   \n  suite = unittest.TestSuite(tests())\n  self.assertEqual(suite.countTestCases(), 2)\n  \n  \n  \n  \n  \n def test_iter(self):\n  test1 = unittest.FunctionTestCase(lambda: None)\n  test2 = unittest.FunctionTestCase(lambda: None)\n  suite = unittest.TestSuite((test1, test2))\n  \n  self.assertEqual(list(suite), [test1, test2])\n  \n  \n  \n  \n  \n  \n def test_countTestCases_zero_simple(self):\n  suite = unittest.TestSuite()\n  \n  self.assertEqual(suite.countTestCases(), 0)\n  \n  \n  \n  \n  \n  \n  \n def test_countTestCases_zero_nested(self):\n  class Test1(unittest.TestCase):\n   def test(self):\n    pass\n    \n  suite = unittest.TestSuite([unittest.TestSuite()])\n  \n  self.assertEqual(suite.countTestCases(), 0)\n  \n  \n  \n  \n def test_countTestCases_simple(self):\n  test1 = unittest.FunctionTestCase(lambda: None)\n  test2 = unittest.FunctionTestCase(lambda: None)\n  suite = unittest.TestSuite((test1, test2))\n  \n  self.assertEqual(suite.countTestCases(), 2)\n  \n  \n  \n  \n  \n  \n def test_countTestCases_nested(self):\n  class Test1(unittest.TestCase):\n   def test1(self): pass\n   def test2(self): pass\n   \n  test2 = unittest.FunctionTestCase(lambda: None)\n  test3 = unittest.FunctionTestCase(lambda: None)\n  child = unittest.TestSuite((Test1('test2'), test2))\n  parent = unittest.TestSuite((test3, child, Test1('test1')))\n  \n  self.assertEqual(parent.countTestCases(), 4)\n  \n  \n  \n  \n  \n def test_run__empty_suite(self):\n  events = []\n  result = LoggingResult(events)\n  \n  suite = unittest.TestSuite()\n  \n  suite.run(result)\n  \n  self.assertEqual(events, [])\n  \n  \n  \n def test_run__requires_result(self):\n  suite = unittest.TestSuite()\n  \n  try:\n   suite.run()\n  except TypeError:\n   pass\n  else:\n   self.fail(\"Failed to raise TypeError\")\n   \n   \n   \n def test_run(self):\n  events = []\n  result = LoggingResult(events)\n  \n  class LoggingCase(unittest.TestCase):\n   def run(self, result):\n    events.append('run %s' % self._testMethodName)\n    \n   def test1(self): pass\n   def test2(self): pass\n   \n  tests = [LoggingCase('test1'), LoggingCase('test2')]\n  \n  unittest.TestSuite(tests).run(result)\n  \n  self.assertEqual(events, ['run test1', 'run test2'])\n  \n  \n def test_addTest__TestCase(self):\n  class Foo(unittest.TestCase):\n   def test(self): pass\n   \n  test = Foo('test')\n  suite = unittest.TestSuite()\n  \n  suite.addTest(test)\n  \n  self.assertEqual(suite.countTestCases(), 1)\n  self.assertEqual(list(suite), [test])\n  \n  \n def test_addTest__TestSuite(self):\n  class Foo(unittest.TestCase):\n   def test(self): pass\n   \n  suite_2 = unittest.TestSuite([Foo('test')])\n  \n  suite = unittest.TestSuite()\n  suite.addTest(suite_2)\n  \n  self.assertEqual(suite.countTestCases(), 1)\n  self.assertEqual(list(suite), [suite_2])\n  \n  \n  \n  \n  \n  \n def test_addTests(self):\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   \n  test_1 = Foo('test_1')\n  test_2 = Foo('test_2')\n  inner_suite = unittest.TestSuite([test_2])\n  \n  def gen():\n   yield test_1\n   yield test_2\n   yield inner_suite\n   \n  suite_1 = unittest.TestSuite()\n  suite_1.addTests(gen())\n  \n  self.assertEqual(list(suite_1), list(gen()))\n  \n  \n  \n  suite_2 = unittest.TestSuite()\n  for t in gen():\n   suite_2.addTest(t)\n   \n  self.assertEqual(suite_1, suite_2)\n  \n  \n  \n  \n  \n def test_addTest__noniterable(self):\n  suite = unittest.TestSuite()\n  \n  try:\n   suite.addTests(5)\n  except TypeError:\n   pass\n  else:\n   self.fail(\"Failed to raise TypeError\")\n   \n def test_addTest__noncallable(self):\n  suite = unittest.TestSuite()\n  self.assertRaises(TypeError, suite.addTest, 5)\n  \n def test_addTest__casesuiteclass(self):\n  suite = unittest.TestSuite()\n  self.assertRaises(TypeError, suite.addTest, Test_TestSuite)\n  self.assertRaises(TypeError, suite.addTest, unittest.TestSuite)\n  \n def test_addTests__string(self):\n  suite = unittest.TestSuite()\n  self.assertRaises(TypeError, suite.addTests, \"foo\")\n  \n def test_function_in_suite(self):\n  def f(_):\n   pass\n  suite = unittest.TestSuite()\n  suite.addTest(f)\n  \n  \n  suite.run(unittest.TestResult())\n  \n  \n  \n def test_basetestsuite(self):\n  class Test(unittest.TestCase):\n   wasSetUp = False\n   wasTornDown = False\n   @classmethod\n   def setUpClass(cls):\n    cls.wasSetUp = True\n   @classmethod\n   def tearDownClass(cls):\n    cls.wasTornDown = True\n   def testPass(self):\n    pass\n   def testFail(self):\n    fail\n  class Module(object):\n   wasSetUp = False\n   wasTornDown = False\n   @staticmethod\n   def setUpModule():\n    Module.wasSetUp = True\n   @staticmethod\n   def tearDownModule():\n    Module.wasTornDown = True\n    \n  Test.__module__ = 'Module'\n  sys.modules['Module'] = Module\n  self.addCleanup(sys.modules.pop, 'Module')\n  \n  suite = unittest.BaseTestSuite()\n  suite.addTests([Test('testPass'), Test('testFail')])\n  self.assertEqual(suite.countTestCases(), 2)\n  \n  result = unittest.TestResult()\n  suite.run(result)\n  self.assertFalse(Module.wasSetUp)\n  self.assertFalse(Module.wasTornDown)\n  self.assertFalse(Test.wasSetUp)\n  self.assertFalse(Test.wasTornDown)\n  self.assertEqual(len(result.errors), 1)\n  self.assertEqual(len(result.failures), 0)\n  self.assertEqual(result.testsRun, 2)\n  \n  \n def test_overriding_call(self):\n  class MySuite(unittest.TestSuite):\n   called = False\n   def __call__(self, *args, **kw):\n    self.called = True\n    unittest.TestSuite.__call__(self, *args, **kw)\n    \n  suite = MySuite()\n  result = unittest.TestResult()\n  wrapper = unittest.TestSuite()\n  wrapper.addTest(suite)\n  wrapper(result)\n  self.assertTrue(suite.called)\n  \n  \n  self.assertFalse(result._testRunEntered)\n  \n  \n  \nif __name__ == '__main__':\n unittest.main()\n"], "ui.widget": [".py", "import __random as random\nfrom browser import doc\n\ndef getMousePosition(e):\n if e is None:\n  e=win.event\n  \n if e.pageX or e.pageY:\n  return {'x': e.pageX, 'y': e.pageY}\n  \n if e.clientX or e.clientY:\n  _posx=e.clientX + doc.body.scrollLeft + doc.documentElement.scrollLeft;\n  _posy=e.clientY + doc.body.scrollTop + doc.documentElement.scrollTop;\n  return {'x': _posx, 'y': _posy}\n  \n return {'x': 0, 'y': 0}\n \nclass Widget:\n def __init__(self, element, type, id=None):\n  self._element=element\n  \n  if id is None:\n   self._element.id='%s_%s' % (type, int(100000*random.random()))\n  else:\n   self._element.id=id\n   \n def get_id(self):\n  return self._element.id\n  \n def attach(self, element_id):\n  \"\"\n  \n  \n  doc[element_id] <= self._element\n  \n def show(self):\n  self._element.display='block'\n  \n def hide(self):\n  self._element.display='none'\n  \nclass DraggableWidget(Widget):\n def __init__(self, element, type, id=None):\n  Widget.__init__(self, element, type, id)\n  \n  def drag(e):\n   self._element.style.top='%spx' % (e.clientY - self._deltaY)\n   self._element.style.left='%spx' % (e.clientX - self._deltaX)\n   \n  def mouseDown(e):\n   self._element.style.position='absolute'\n   self._deltaX=e.clientX - self._element.offsetLeft\n   self._deltaY=e.clientY - self._element.offsetTop\n   doc.bind('mousemove', drag)\n   \n  def mouseUp(e):\n   doc.unbind('mousemove')\n   \n  self._element.bind('mousedown', mouseDown)\n  self._element.bind('mouseup', mouseUp)\n"], "crypto_js.rollups.sha512": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(a,m){var r={},f=r.lib={},g=function(){},l=f.Base={extend:function(a){g.prototype=this;var b=new g;a&&b.mixIn(a);b.hasOwnProperty(\"init\")||(b.init=function(){b.$super.init.apply(this,arguments)});b.init.prototype=b;b.$super=this;return b},create:function(){var a=this.extend();a.init.apply(a,arguments);return a},init:function(){},mixIn:function(a){for(var b in a)a.hasOwnProperty(b)&&(this[b]=a[b]);a.hasOwnProperty(\"toString\")&&(this.toString=a.toString)},clone:function(){return this.init.prototype.extend(this)}},\np=f.WordArray=l.extend({init:function(a,b){a=this.words=a||[];this.sigBytes=b!=m?b:4*a.length},toString:function(a){return(a||q).stringify(this)},concat:function(a){var b=this.words,d=a.words,c=this.sigBytes;a=a.sigBytes;this.clamp();if(c%4)for(var j=0;j<a;j++)b[c+j>>>2]|=(d[j>>>2]>>>24-8*(j%4)&255)<<24-8*((c+j)%4);else if(65535<d.length)for(j=0;j<a;j+=4)b[c+j>>>2]=d[j>>>2];else b.push.apply(b,d);this.sigBytes+=a;return this},clamp:function(){var n=this.words,b=this.sigBytes;n[b>>>2]&=4294967295<<\n32-8*(b%4);n.length=a.ceil(b/4)},clone:function(){var a=l.clone.call(this);a.words=this.words.slice(0);return a},random:function(n){for(var b=[],d=0;d<n;d+=4)b.push(4294967296*a.random()|0);return new p.init(b,n)}}),y=r.enc={},q=y.Hex={stringify:function(a){var b=a.words;a=a.sigBytes;for(var d=[],c=0;c<a;c++){var j=b[c>>>2]>>>24-8*(c%4)&255;d.push((j>>>4).toString(16));d.push((j&15).toString(16))}return d.join(\"\")},parse:function(a){for(var b=a.length,d=[],c=0;c<b;c+=2)d[c>>>3]|=parseInt(a.substr(c,\n2),16)<<24-4*(c%8);return new p.init(d,b/2)}},G=y.Latin1={stringify:function(a){var b=a.words;a=a.sigBytes;for(var d=[],c=0;c<a;c++)d.push(String.fromCharCode(b[c>>>2]>>>24-8*(c%4)&255));return d.join(\"\")},parse:function(a){for(var b=a.length,d=[],c=0;c<b;c++)d[c>>>2]|=(a.charCodeAt(c)&255)<<24-8*(c%4);return new p.init(d,b)}},fa=y.Utf8={stringify:function(a){try{return decodeURIComponent(escape(G.stringify(a)))}catch(b){throw Error(\"Malformed UTF-8 data\");}},parse:function(a){return G.parse(unescape(encodeURIComponent(a)))}},\nh=f.BufferedBlockAlgorithm=l.extend({reset:function(){this._data=new p.init;this._nDataBytes=0},_append:function(a){\"string\"==typeof a&&(a=fa.parse(a));this._data.concat(a);this._nDataBytes+=a.sigBytes},_process:function(n){var b=this._data,d=b.words,c=b.sigBytes,j=this.blockSize,l=c/(4*j),l=n?a.ceil(l):a.max((l|0)-this._minBufferSize,0);n=l*j;c=a.min(4*n,c);if(n){for(var h=0;h<n;h+=j)this._doProcessBlock(d,h);h=d.splice(0,n);b.sigBytes-=c}return new p.init(h,c)},clone:function(){var a=l.clone.call(this);\na._data=this._data.clone();return a},_minBufferSize:0});f.Hasher=h.extend({cfg:l.extend(),init:function(a){this.cfg=this.cfg.extend(a);this.reset()},reset:function(){h.reset.call(this);this._doReset()},update:function(a){this._append(a);this._process();return this},finalize:function(a){a&&this._append(a);return this._doFinalize()},blockSize:16,_createHelper:function(a){return function(b,d){return(new a.init(d)).finalize(b)}},_createHmacHelper:function(a){return function(b,d){return(new ga.HMAC.init(a,\nd)).finalize(b)}}});var ga=r.algo={};return r}(Math);\n(function(a){var m=CryptoJS,r=m.lib,f=r.Base,g=r.WordArray,m=m.x64={};m.Word=f.extend({init:function(a,p){this.high=a;this.low=p}});m.WordArray=f.extend({init:function(l,p){l=this.words=l||[];this.sigBytes=p!=a?p:8*l.length},toX32:function(){for(var a=this.words,p=a.length,f=[],q=0;q<p;q++){var G=a[q];f.push(G.high);f.push(G.low)}return g.create(f,this.sigBytes)},clone:function(){for(var a=f.clone.call(this),p=a.words=this.words.slice(0),g=p.length,q=0;q<g;q++)p[q]=p[q].clone();return a}})})();\n(function(){function a(){return g.create.apply(g,arguments)}for(var m=CryptoJS,r=m.lib.Hasher,f=m.x64,g=f.Word,l=f.WordArray,f=m.algo,p=[a(1116352408,3609767458),a(1899447441,602891725),a(3049323471,3964484399),a(3921009573,2173295548),a(961987163,4081628472),a(1508970993,3053834265),a(2453635748,2937671579),a(2870763221,3664609560),a(3624381080,2734883394),a(310598401,1164996542),a(607225278,1323610764),a(1426881987,3590304994),a(1925078388,4068182383),a(2162078206,991336113),a(2614888103,633803317),\na(3248222580,3479774868),a(3835390401,2666613458),a(4022224774,944711139),a(264347078,2341262773),a(604807628,2007800933),a(770255983,1495990901),a(1249150122,1856431235),a(1555081692,3175218132),a(1996064986,2198950837),a(2554220882,3999719339),a(2821834349,766784016),a(2952996808,2566594879),a(3210313671,3203337956),a(3336571891,1034457026),a(3584528711,2466948901),a(113926993,3758326383),a(338241895,168717936),a(666307205,1188179964),a(773529912,1546045734),a(1294757372,1522805485),a(1396182291,\n2643833823),a(1695183700,2343527390),a(1986661051,1014477480),a(2177026350,1206759142),a(2456956037,344077627),a(2730485921,1290863460),a(2820302411,3158454273),a(3259730800,3505952657),a(3345764771,106217008),a(3516065817,3606008344),a(3600352804,1432725776),a(4094571909,1467031594),a(275423344,851169720),a(430227734,3100823752),a(506948616,1363258195),a(659060556,3750685593),a(883997877,3785050280),a(958139571,3318307427),a(1322822218,3812723403),a(1537002063,2003034995),a(1747873779,3602036899),\na(1955562222,1575990012),a(2024104815,1125592928),a(2227730452,2716904306),a(2361852424,442776044),a(2428436474,593698344),a(2756734187,3733110249),a(3204031479,2999351573),a(3329325298,3815920427),a(3391569614,3928383900),a(3515267271,566280711),a(3940187606,3454069534),a(4118630271,4000239992),a(116418474,1914138554),a(174292421,2731055270),a(289380356,3203993006),a(460393269,320620315),a(685471733,587496836),a(852142971,1086792851),a(1017036298,365543100),a(1126000580,2618297676),a(1288033470,\n3409855158),a(1501505948,4234509866),a(1607167915,987167468),a(1816402316,1246189591)],y=[],q=0;80>q;q++)y[q]=a();f=f.SHA512=r.extend({_doReset:function(){this._hash=new l.init([new g.init(1779033703,4089235720),new g.init(3144134277,2227873595),new g.init(1013904242,4271175723),new g.init(2773480762,1595750129),new g.init(1359893119,2917565137),new g.init(2600822924,725511199),new g.init(528734635,4215389547),new g.init(1541459225,327033209)])},_doProcessBlock:function(a,f){for(var h=this._hash.words,\ng=h[0],n=h[1],b=h[2],d=h[3],c=h[4],j=h[5],l=h[6],h=h[7],q=g.high,m=g.low,r=n.high,N=n.low,Z=b.high,O=b.low,$=d.high,P=d.low,aa=c.high,Q=c.low,ba=j.high,R=j.low,ca=l.high,S=l.low,da=h.high,T=h.low,v=q,s=m,H=r,E=N,I=Z,F=O,W=$,J=P,w=aa,t=Q,U=ba,K=R,V=ca,L=S,X=da,M=T,x=0;80>x;x++){var B=y[x];if(16>x)var u=B.high=a[f+2*x]|0,e=B.low=a[f+2*x+1]|0;else{var u=y[x-15],e=u.high,z=u.low,u=(e>>>1|z<<31)^(e>>>8|z<<24)^e>>>7,z=(z>>>1|e<<31)^(z>>>8|e<<24)^(z>>>7|e<<25),D=y[x-2],e=D.high,k=D.low,D=(e>>>19|k<<13)^\n(e<<3|k>>>29)^e>>>6,k=(k>>>19|e<<13)^(k<<3|e>>>29)^(k>>>6|e<<26),e=y[x-7],Y=e.high,C=y[x-16],A=C.high,C=C.low,e=z+e.low,u=u+Y+(e>>>0<z>>>0?1:0),e=e+k,u=u+D+(e>>>0<k>>>0?1:0),e=e+C,u=u+A+(e>>>0<C>>>0?1:0);B.high=u;B.low=e}var Y=w&U^~w&V,C=t&K^~t&L,B=v&H^v&I^H&I,ha=s&E^s&F^E&F,z=(v>>>28|s<<4)^(v<<30|s>>>2)^(v<<25|s>>>7),D=(s>>>28|v<<4)^(s<<30|v>>>2)^(s<<25|v>>>7),k=p[x],ia=k.high,ea=k.low,k=M+((t>>>14|w<<18)^(t>>>18|w<<14)^(t<<23|w>>>9)),A=X+((w>>>14|t<<18)^(w>>>18|t<<14)^(w<<23|t>>>9))+(k>>>0<M>>>\n0?1:0),k=k+C,A=A+Y+(k>>>0<C>>>0?1:0),k=k+ea,A=A+ia+(k>>>0<ea>>>0?1:0),k=k+e,A=A+u+(k>>>0<e>>>0?1:0),e=D+ha,B=z+B+(e>>>0<D>>>0?1:0),X=V,M=L,V=U,L=K,U=w,K=t,t=J+k|0,w=W+A+(t>>>0<J>>>0?1:0)|0,W=I,J=F,I=H,F=E,H=v,E=s,s=k+e|0,v=A+B+(s>>>0<k>>>0?1:0)|0}m=g.low=m+s;g.high=q+v+(m>>>0<s>>>0?1:0);N=n.low=N+E;n.high=r+H+(N>>>0<E>>>0?1:0);O=b.low=O+F;b.high=Z+I+(O>>>0<F>>>0?1:0);P=d.low=P+J;d.high=$+W+(P>>>0<J>>>0?1:0);Q=c.low=Q+t;c.high=aa+w+(Q>>>0<t>>>0?1:0);R=j.low=R+K;j.high=ba+U+(R>>>0<K>>>0?1:0);S=l.low=\nS+L;l.high=ca+V+(S>>>0<L>>>0?1:0);T=h.low=T+M;h.high=da+X+(T>>>0<M>>>0?1:0)},_doFinalize:function(){var a=this._data,f=a.words,h=8*this._nDataBytes,g=8*a.sigBytes;f[g>>>5]|=128<<24-g%32;f[(g+128>>>10<<5)+30]=Math.floor(h/4294967296);f[(g+128>>>10<<5)+31]=h;a.sigBytes=4*f.length;this._process();return this._hash.toX32()},clone:function(){var a=r.clone.call(this);a._hash=this._hash.clone();return a},blockSize:32});m.SHA512=r._createHelper(f);m.HmacSHA512=r._createHmacHelper(f)})();\n"], "unittest.suite": [".py", "\"\"\n\nimport sys\n\nfrom . import case\nfrom . import util\n\n__unittest = True\n\n\ndef _call_if_exists(parent, attr):\n func = getattr(parent, attr, lambda: None)\n func()\n \n \nclass BaseTestSuite(object):\n \"\"\n def __init__(self, tests=()):\n  self._tests = []\n  self.addTests(tests)\n  \n def __repr__(self):\n  return \"<%s tests=%s>\" % (util.strclass(self.__class__), list(self))\n  \n def __eq__(self, other):\n  if not isinstance(other, self.__class__):\n   return NotImplemented\n  return list(self) == list(other)\n  \n def __ne__(self, other):\n  return not self == other\n  \n def __iter__(self):\n  return iter(self._tests)\n  \n def countTestCases(self):\n  cases = 0\n  for test in self:\n   cases += test.countTestCases()\n  return cases\n  \n def addTest(self, test):\n \n  if not callable(test):\n   raise TypeError(\"{} is not callable\".format(repr(test)))\n  if isinstance(test, type) and issubclass(test,\n  (case.TestCase, TestSuite)):\n   raise TypeError(\"TestCases and TestSuites must be instantiated \"\n   \"before passing them to addTest()\")\n  self._tests.append(test)\n  \n def addTests(self, tests):\n  if isinstance(tests, str):\n   raise TypeError(\"tests must be an iterable of tests, not a string\")\n  for test in tests:\n   self.addTest(test)\n   \n def run(self, result):\n  for test in self:\n   if result.shouldStop:\n    break\n   test(result)\n  return result\n  \n def __call__(self, *args, **kwds):\n  return self.run(*args, **kwds)\n  \n def debug(self):\n  \"\"\n  for test in self:\n   test.debug()\n   \n   \nclass TestSuite(BaseTestSuite):\n \"\"\n \n def run(self, result, debug=False):\n  topLevel = False\n  if getattr(result, '_testRunEntered', False) is False:\n   result._testRunEntered = topLevel = True\n   \n  for test in self:\n   if result.shouldStop:\n    break\n    \n   if _isnotsuite(test):\n    self._tearDownPreviousClass(test, result)\n    self._handleModuleFixture(test, result)\n    self._handleClassSetUp(test, result)\n    result._previousTestClass = test.__class__\n    \n    if (getattr(test.__class__, '_classSetupFailed', False) or\n    getattr(result, '_moduleSetUpFailed', False)):\n     continue\n     \n   if not debug:\n    test(result)\n   else:\n    test.debug()\n    \n  if topLevel:\n   self._tearDownPreviousClass(None, result)\n   self._handleModuleTearDown(result)\n   result._testRunEntered = False\n  return result\n  \n def debug(self):\n  \"\"\n  debug = _DebugResult()\n  self.run(debug, True)\n  \n  \n  \n def _handleClassSetUp(self, test, result):\n  previousClass = getattr(result, '_previousTestClass', None)\n  currentClass = test.__class__\n  if currentClass == previousClass:\n   return\n  if result._moduleSetUpFailed:\n   return\n  if getattr(currentClass, \"__unittest_skip__\", False):\n   return\n   \n  try:\n   currentClass._classSetupFailed = False\n  except TypeError:\n  \n  \n   pass\n   \n  setUpClass = getattr(currentClass, 'setUpClass', None)\n  if setUpClass is not None:\n   _call_if_exists(result, '_setupStdout')\n   try:\n    setUpClass()\n   except Exception as e:\n    if isinstance(result, _DebugResult):\n     raise\n    currentClass._classSetupFailed = True\n    className = util.strclass(currentClass)\n    errorName = 'setUpClass (%s)' % className\n    self._addClassOrModuleLevelException(result, e, errorName)\n   finally:\n    _call_if_exists(result, '_restoreStdout')\n    \n def _get_previous_module(self, result):\n  previousModule = None\n  previousClass = getattr(result, '_previousTestClass', None)\n  if previousClass is not None:\n   previousModule = previousClass.__module__\n  return previousModule\n  \n  \n def _handleModuleFixture(self, test, result):\n  previousModule = self._get_previous_module(result)\n  currentModule = test.__class__.__module__\n  if currentModule == previousModule:\n   return\n   \n  self._handleModuleTearDown(result)\n  \n  \n  result._moduleSetUpFailed = False\n  try:\n   module = sys.modules[currentModule]\n  except KeyError:\n   return\n  setUpModule = getattr(module, 'setUpModule', None)\n  if setUpModule is not None:\n   _call_if_exists(result, '_setupStdout')\n   try:\n    setUpModule()\n   except Exception as e:\n    if isinstance(result, _DebugResult):\n     raise\n    result._moduleSetUpFailed = True\n    errorName = 'setUpModule (%s)' % currentModule\n    self._addClassOrModuleLevelException(result, e, errorName)\n   finally:\n    _call_if_exists(result, '_restoreStdout')\n    \n def _addClassOrModuleLevelException(self, result, exception, errorName):\n  error = _ErrorHolder(errorName)\n  addSkip = getattr(result, 'addSkip', None)\n  if addSkip is not None and isinstance(exception, case.SkipTest):\n   addSkip(error, str(exception))\n  else:\n   result.addError(error, sys.exc_info())\n   \n def _handleModuleTearDown(self, result):\n  previousModule = self._get_previous_module(result)\n  if previousModule is None:\n   return\n  if result._moduleSetUpFailed:\n   return\n   \n  try:\n   module = sys.modules[previousModule]\n  except KeyError:\n   return\n   \n  tearDownModule = getattr(module, 'tearDownModule', None)\n  if tearDownModule is not None:\n   _call_if_exists(result, '_setupStdout')\n   try:\n    tearDownModule()\n   except Exception as e:\n    if isinstance(result, _DebugResult):\n     raise\n    errorName = 'tearDownModule (%s)' % previousModule\n    self._addClassOrModuleLevelException(result, e, errorName)\n   finally:\n    _call_if_exists(result, '_restoreStdout')\n    \n def _tearDownPreviousClass(self, test, result):\n  previousClass = getattr(result, '_previousTestClass', None)\n  currentClass = test.__class__\n  if currentClass == previousClass:\n   return\n  if getattr(previousClass, '_classSetupFailed', False):\n   return\n  if getattr(result, '_moduleSetUpFailed', False):\n   return\n  if getattr(previousClass, \"__unittest_skip__\", False):\n   return\n   \n  tearDownClass = getattr(previousClass, 'tearDownClass', None)\n  if tearDownClass is not None:\n   _call_if_exists(result, '_setupStdout')\n   try:\n    tearDownClass()\n   except Exception as e:\n    if isinstance(result, _DebugResult):\n     raise\n    className = util.strclass(previousClass)\n    errorName = 'tearDownClass (%s)' % className\n    self._addClassOrModuleLevelException(result, e, errorName)\n   finally:\n    _call_if_exists(result, '_restoreStdout')\n    \n    \nclass _ErrorHolder(object):\n \"\"\n \n \n \n \n failureException = None\n \n def __init__(self, description):\n  self.description = description\n  \n def id(self):\n  return self.description\n  \n def shortDescription(self):\n  return None\n  \n def __repr__(self):\n  return \"<ErrorHolder description=%r>\" % (self.description,)\n  \n def __str__(self):\n  return self.id()\n  \n def run(self, result):\n \n \n  pass\n  \n def __call__(self, result):\n  return self.run(result)\n  \n def countTestCases(self):\n  return 0\n  \ndef _isnotsuite(test):\n \"\"\n try:\n  iter(test)\n except TypeError:\n  return True\n return False\n \n \nclass _DebugResult(object):\n \"\"\n _previousTestClass = None\n _moduleSetUpFailed = False\n shouldStop = False\n"], "inspect": [".py", "\"\"\n\n\n\n__author__ = ('Ka-Ping Yee <ping@lfw.org>',\n'Yury Selivanov <yselivanov@sprymix.com>')\n\nimport imp\nimport importlib.machinery\nimport itertools\nimport linecache\nimport os\nimport re\nimport sys\nimport tokenize\nimport types\nimport warnings\nimport functools\nimport builtins\nfrom operator import attrgetter\nfrom collections import namedtuple, OrderedDict\n\n\n\n\ntry:\n from dis import COMPILER_FLAG_NAMES as _flag_names\nexcept ImportError:\n CO_OPTIMIZED, CO_NEWLOCALS = 0x1, 0x2\n CO_VARARGS, CO_VARKEYWORDS = 0x4, 0x8\n CO_NESTED, CO_GENERATOR, CO_NOFREE = 0x10, 0x20, 0x40\nelse:\n mod_dict = globals()\n for k, v in _flag_names.items():\n  mod_dict[\"CO_\" + v] = k\n  \n  \nTPFLAGS_IS_ABSTRACT = 1 << 20\n\n\ndef ismodule(object):\n \"\"\n return isinstance(object, types.ModuleType)\n \ndef isclass(object):\n \"\"\n return isinstance(object, type)\n \ndef ismethod(object):\n \"\"\n return isinstance(object, types.MethodType)\n \ndef ismethoddescriptor(object):\n \"\"\n if isclass(object) or ismethod(object) or isfunction(object):\n \n  return False\n tp = type(object)\n return hasattr(tp, \"__get__\") and not hasattr(tp, \"__set__\")\n \ndef isdatadescriptor(object):\n \"\"\n if isclass(object) or ismethod(object) or isfunction(object):\n \n  return False\n tp = type(object)\n return hasattr(tp, \"__set__\") and hasattr(tp, \"__get__\")\n \nif hasattr(types, 'MemberDescriptorType'):\n\n def ismemberdescriptor(object):\n  \"\"\n  return isinstance(object, types.MemberDescriptorType)\nelse:\n\n def ismemberdescriptor(object):\n  \"\"\n  return False\n  \nif hasattr(types, 'GetSetDescriptorType'):\n\n def isgetsetdescriptor(object):\n  \"\"\n  return isinstance(object, types.GetSetDescriptorType)\nelse:\n\n def isgetsetdescriptor(object):\n  \"\"\n  return False\n  \ndef isfunction(object):\n \"\"\n return isinstance(object, types.FunctionType)\n \ndef isgeneratorfunction(object):\n \"\"\n return bool((isfunction(object) or ismethod(object)) and\n object.__code__.co_flags & CO_GENERATOR)\n \ndef isgenerator(object):\n \"\"\n return isinstance(object, types.GeneratorType)\n \ndef istraceback(object):\n \"\"\n return isinstance(object, types.TracebackType)\n \ndef isframe(object):\n \"\"\n return isinstance(object, types.FrameType)\n \ndef iscode(object):\n \"\"\n return isinstance(object, types.CodeType)\n \ndef isbuiltin(object):\n \"\"\n return isinstance(object, types.BuiltinFunctionType)\n \ndef isroutine(object):\n \"\"\n return (isbuiltin(object)\n or isfunction(object)\n or ismethod(object)\n or ismethoddescriptor(object))\n \ndef isabstract(object):\n \"\"\n return bool(isinstance(object, type) and object.__flags__ & TPFLAGS_IS_ABSTRACT)\n \ndef getmembers(object, predicate=None):\n \"\"\n if isclass(object):\n  mro = (object,) + getmro(object)\n else:\n  mro = ()\n results = []\n for key in dir(object):\n \n \n  for base in mro:\n   if key in base.__dict__:\n    value = base.__dict__[key]\n    break\n  else:\n   try:\n    value = getattr(object, key)\n   except AttributeError:\n    continue\n  if not predicate or predicate(value):\n   results.append((key, value))\n results.sort()\n return results\n \nAttribute = namedtuple('Attribute', 'name kind defining_class object')\n\ndef classify_class_attrs(cls):\n \"\"\n \n mro = getmro(cls)\n names = dir(cls)\n result = []\n for name in names:\n \n \n \n \n \n \n  homecls = None\n  for base in (cls,) + mro:\n   if name in base.__dict__:\n    obj = base.__dict__[name]\n    homecls = base\n    break\n  else:\n   obj = getattr(cls, name)\n   homecls = getattr(obj, \"__objclass__\", homecls)\n   \n   \n  if isinstance(obj, staticmethod):\n   kind = \"static method\"\n  elif isinstance(obj, classmethod):\n   kind = \"class method\"\n  elif isinstance(obj, property):\n   kind = \"property\"\n  elif ismethoddescriptor(obj):\n   kind = \"method\"\n  elif isdatadescriptor(obj):\n   kind = \"data\"\n  else:\n   obj_via_getattr = getattr(cls, name)\n   if (isfunction(obj_via_getattr) or\n   ismethoddescriptor(obj_via_getattr)):\n    kind = \"method\"\n   else:\n    kind = \"data\"\n   obj = obj_via_getattr\n   \n  result.append(Attribute(name, kind, homecls, obj))\n  \n return result\n \n \n \ndef getmro(cls):\n \"\"\n return cls.__mro__\n \n \ndef indentsize(line):\n \"\"\n expline = line.expandtabs()\n return len(expline) - len(expline.lstrip())\n \ndef getdoc(object):\n \"\"\n try:\n  doc = object.__doc__\n except AttributeError:\n  return None\n if not isinstance(doc, str):\n  return None\n return cleandoc(doc)\n \ndef cleandoc(doc):\n \"\"\n try:\n  lines = doc.expandtabs().split('\\n')\n except UnicodeError:\n  return None\n else:\n \n  margin = sys.maxsize\n  for line in lines[1:]:\n   content = len(line.lstrip())\n   if content:\n    indent = len(line) - content\n    margin = min(margin, indent)\n    \n  if lines:\n   lines[0] = lines[0].lstrip()\n  if margin < sys.maxsize:\n   for i in range(1, len(lines)): lines[i] = lines[i][margin:]\n   \n  while lines and not lines[-1]:\n   lines.pop()\n  while lines and not lines[0]:\n   lines.pop(0)\n  return '\\n'.join(lines)\n  \ndef getfile(object):\n \"\"\n if ismodule(object):\n  if hasattr(object, '__file__'):\n   return object.__file__\n  raise TypeError('{!r} is a built-in module'.format(object))\n if isclass(object):\n  object = sys.modules.get(object.__module__)\n  if hasattr(object, '__file__'):\n   return object.__file__\n  raise TypeError('{!r} is a built-in class'.format(object))\n if ismethod(object):\n  object = object.__func__\n if isfunction(object):\n  object = object.__code__\n if istraceback(object):\n  object = object.tb_frame\n if isframe(object):\n  object = object.f_code\n if iscode(object):\n  return object.co_filename\n raise TypeError('{!r} is not a module, class, method, '\n 'function, traceback, frame, or code object'.format(object))\n \nModuleInfo = namedtuple('ModuleInfo', 'name suffix mode module_type')\n\ndef getmoduleinfo(path):\n \"\"\n warnings.warn('inspect.getmoduleinfo() is deprecated', DeprecationWarning,\n 2)\n filename = os.path.basename(path)\n suffixes = [(-len(suffix), suffix, mode, mtype)\n for suffix, mode, mtype in imp.get_suffixes()]\n suffixes.sort() \n for neglen, suffix, mode, mtype in suffixes:\n  if filename[neglen:] == suffix:\n   return ModuleInfo(filename[:neglen], suffix, mode, mtype)\n   \ndef getmodulename(path):\n \"\"\n fname = os.path.basename(path)\n \n suffixes = [(-len(suffix), suffix)\n for suffix in importlib.machinery.all_suffixes()]\n suffixes.sort() \n for neglen, suffix in suffixes:\n  if fname.endswith(suffix):\n   return fname[:neglen]\n return None\n \ndef getsourcefile(object):\n \"\"\n filename = getfile(object)\n all_bytecode_suffixes = importlib.machinery.DEBUG_BYTECODE_SUFFIXES[:]\n all_bytecode_suffixes += importlib.machinery.OPTIMIZED_BYTECODE_SUFFIXES[:]\n if any(filename.endswith(s) for s in all_bytecode_suffixes):\n  filename = (os.path.splitext(filename)[0] +\n  importlib.machinery.SOURCE_SUFFIXES[0])\n elif any(filename.endswith(s) for s in\n importlib.machinery.EXTENSION_SUFFIXES):\n  return None\n if os.path.exists(filename):\n  return filename\n  \n if hasattr(getmodule(object, filename), '__loader__'):\n  return filename\n  \n if filename in linecache.cache:\n  return filename\n  \ndef getabsfile(object, _filename=None):\n \"\"\n if _filename is None:\n  _filename = getsourcefile(object) or getfile(object)\n return os.path.normcase(os.path.abspath(_filename))\n \nmodulesbyfile = {}\n_filesbymodname = {}\n\ndef getmodule(object, _filename=None):\n \"\"\n if ismodule(object):\n  return object\n if hasattr(object, '__module__'):\n  return sys.modules.get(object.__module__)\n  \n if _filename is not None and _filename in modulesbyfile:\n  return sys.modules.get(modulesbyfile[_filename])\n  \n try:\n  file = getabsfile(object, _filename)\n except TypeError:\n  return None\n if file in modulesbyfile:\n  return sys.modules.get(modulesbyfile[file])\n  \n  \n for modname, module in list(sys.modules.items()):\n  if ismodule(module) and hasattr(module, '__file__'):\n   f = module.__file__\n   if f == _filesbymodname.get(modname, None):\n   \n    continue\n   _filesbymodname[modname] = f\n   f = getabsfile(module)\n   \n   modulesbyfile[f] = modulesbyfile[\n   os.path.realpath(f)] = module.__name__\n if file in modulesbyfile:\n  return sys.modules.get(modulesbyfile[file])\n  \n main = sys.modules['__main__']\n if not hasattr(object, '__name__'):\n  return None\n if hasattr(main, object.__name__):\n  mainobject = getattr(main, object.__name__)\n  if mainobject is object:\n   return main\n   \n builtin = sys.modules['builtins']\n if hasattr(builtin, object.__name__):\n  builtinobject = getattr(builtin, object.__name__)\n  if builtinobject is object:\n   return builtin\n   \ndef findsource(object):\n \"\"\n \n file = getfile(object)\n sourcefile = getsourcefile(object)\n if not sourcefile and file[:1] + file[-1:] != '<>':\n  raise IOError('source code not available')\n file = sourcefile if sourcefile else file\n \n module = getmodule(object, file)\n if module:\n  lines = linecache.getlines(file, module.__dict__)\n else:\n  lines = linecache.getlines(file)\n if not lines:\n  raise IOError('could not get source code')\n  \n if ismodule(object):\n  return lines, 0\n  \n if isclass(object):\n  name = object.__name__\n  pat = re.compile(r'^(\\s*)class\\s*' + name + r'\\b')\n  \n  \n  \n  candidates = []\n  for i in range(len(lines)):\n   match = pat.match(lines[i])\n   if match:\n   \n    if lines[i][0] == 'c':\n     return lines, i\n     \n    candidates.append((match.group(1), i))\n  if candidates:\n  \n  \n   candidates.sort()\n   return lines, candidates[0][1]\n  else:\n   raise IOError('could not find class definition')\n   \n if ismethod(object):\n  object = object.__func__\n if isfunction(object):\n  object = object.__code__\n if istraceback(object):\n  object = object.tb_frame\n if isframe(object):\n  object = object.f_code\n if iscode(object):\n  if not hasattr(object, 'co_firstlineno'):\n   raise IOError('could not find function definition')\n  lnum = object.co_firstlineno - 1\n  pat = re.compile(r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)')\n  while lnum > 0:\n   if pat.match(lines[lnum]): break\n   lnum = lnum - 1\n  return lines, lnum\n raise IOError('could not find code object')\n \ndef getcomments(object):\n \"\"\n try:\n  lines, lnum = findsource(object)\n except (IOError, TypeError):\n  return None\n  \n if ismodule(object):\n \n  start = 0\n  if lines and lines[0][:2] == '#!': start = 1\n  while start < len(lines) and lines[start].strip() in ('', '#'):\n   start = start + 1\n  if start < len(lines) and lines[start][:1] == '#':\n   comments = []\n   end = start\n   while end < len(lines) and lines[end][:1] == '#':\n    comments.append(lines[end].expandtabs())\n    end = end + 1\n   return ''.join(comments)\n   \n   \n elif lnum > 0:\n  indent = indentsize(lines[lnum])\n  end = lnum - 1\n  if end >= 0 and lines[end].lstrip()[:1] == '#' and indentsize(lines[end]) == indent:\n   comments = [lines[end].expandtabs().lstrip()]\n   if end > 0:\n    end = end - 1\n    comment = lines[end].expandtabs().lstrip()\n    while comment[:1] == '#' and indentsize(lines[end]) == indent:\n     comments[:0] = [comment]\n     end = end - 1\n     if end < 0: break\n     comment = lines[end].expandtabs().lstrip()\n   while comments and comments[0].strip() == '#':\n    comments[:1] = []\n   while comments and comments[-1].strip() == '#':\n    comments[-1:] = []\n   return ''.join(comments)\n   \nclass EndOfBlock(Exception): pass\n\nclass BlockFinder:\n \"\"\n def __init__(self):\n  self.indent = 0\n  self.islambda = False\n  self.started = False\n  self.passline = False\n  self.last = 1\n  \n def tokeneater(self, type, token, srowcol, erowcol, line):\n  if not self.started:\n  \n   if token in (\"def\", \"class\", \"lambda\"):\n    if token == \"lambda\":\n     self.islambda = True\n    self.started = True\n   self.passline = True \n  elif type == tokenize.NEWLINE:\n   self.passline = False \n   self.last = srowcol[0]\n   if self.islambda: \n    raise EndOfBlock\n  elif self.passline:\n   pass\n  elif type == tokenize.INDENT:\n   self.indent = self.indent + 1\n   self.passline = True\n  elif type == tokenize.DEDENT:\n   self.indent = self.indent - 1\n   \n   \n   \n   if self.indent <= 0:\n    raise EndOfBlock\n  elif self.indent == 0 and type not in (tokenize.COMMENT, tokenize.NL):\n  \n  \n   raise EndOfBlock\n   \ndef getblock(lines):\n \"\"\n blockfinder = BlockFinder()\n try:\n  tokens = tokenize.generate_tokens(iter(lines).__next__)\n  for _token in tokens:\n   blockfinder.tokeneater(*_token)\n except (EndOfBlock, IndentationError):\n  pass\n return lines[:blockfinder.last]\n \ndef getsourcelines(object):\n \"\"\n lines, lnum = findsource(object)\n \n if ismodule(object): return lines, 0\n else: return getblock(lines[lnum:]), lnum + 1\n \ndef getsource(object):\n \"\"\n lines, lnum = getsourcelines(object)\n return ''.join(lines)\n \n \ndef walktree(classes, children, parent):\n \"\"\n results = []\n classes.sort(key=attrgetter('__module__', '__name__'))\n for c in classes:\n  results.append((c, c.__bases__))\n  if c in children:\n   results.append(walktree(children[c], children, c))\n return results\n \ndef getclasstree(classes, unique=False):\n \"\"\n children = {}\n roots = []\n for c in classes:\n  if c.__bases__:\n   for parent in c.__bases__:\n    if not parent in children:\n     children[parent] = []\n    if c not in children[parent]:\n     children[parent].append(c)\n    if unique and parent in classes: break\n  elif c not in roots:\n   roots.append(c)\n for parent in children:\n  if parent not in classes:\n   roots.append(parent)\n return walktree(roots, children, None)\n \n \nArguments = namedtuple('Arguments', 'args, varargs, varkw')\n\ndef getargs(co):\n \"\"\n args, varargs, kwonlyargs, varkw = _getfullargs(co)\n return Arguments(args + kwonlyargs, varargs, varkw)\n \ndef _getfullargs(co):\n \"\"\n \n if not iscode(co):\n  raise TypeError('{!r} is not a code object'.format(co))\n  \n nargs = co.co_argcount\n names = co.co_varnames\n nkwargs = co.co_kwonlyargcount\n args = list(names[:nargs])\n kwonlyargs = list(names[nargs:nargs+nkwargs])\n step = 0\n \n nargs += nkwargs\n varargs = None\n if co.co_flags & CO_VARARGS:\n  varargs = co.co_varnames[nargs]\n  nargs = nargs + 1\n varkw = None\n if co.co_flags & CO_VARKEYWORDS:\n  varkw = co.co_varnames[nargs]\n return args, varargs, kwonlyargs, varkw\n \n \nArgSpec = namedtuple('ArgSpec', 'args varargs keywords defaults')\n\ndef getargspec(func):\n \"\"\n \n args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, ann = getfullargspec(func)\n if kwonlyargs or ann:\n  raise ValueError(\"Function has keyword-only arguments or annotations\"\n  \", use getfullargspec() API which can support them\")\n return ArgSpec(args, varargs, varkw, defaults)\n \nFullArgSpec = namedtuple('FullArgSpec',\n'args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations')\n\ndef getfullargspec(func):\n \"\"\n \n if ismethod(func):\n  func = func.__func__\n if not isfunction(func):\n  raise TypeError('{!r} is not a Python function'.format(func))\n args, varargs, kwonlyargs, varkw = _getfullargs(func.__code__)\n return FullArgSpec(args, varargs, varkw, func.__defaults__,\n kwonlyargs, func.__kwdefaults__, func.__annotations__)\n \nArgInfo = namedtuple('ArgInfo', 'args varargs keywords locals')\n\ndef getargvalues(frame):\n \"\"\n args, varargs, varkw = getargs(frame.f_code)\n return ArgInfo(args, varargs, varkw, frame.f_locals)\n \ndef formatannotation(annotation, base_module=None):\n if isinstance(annotation, type):\n  if annotation.__module__ in ('builtins', base_module):\n   return annotation.__name__\n  return annotation.__module__+'.'+annotation.__name__\n return repr(annotation)\n \ndef formatannotationrelativeto(object):\n module = getattr(object, '__module__', None)\n def _formatannotation(annotation):\n  return formatannotation(annotation, module)\n return _formatannotation\n \n \ndef formatargspec(args, varargs=None, varkw=None, defaults=None,\nkwonlyargs=(), kwonlydefaults={}, annotations={},\nformatarg=str,\nformatvarargs=lambda name: '*' + name,\nformatvarkw=lambda name: '**' + name,\nformatvalue=lambda value: '=' + repr(value),\nformatreturns=lambda text: ' -> ' + text,\nformatannotation=formatannotation):\n \"\"\n def formatargandannotation(arg):\n  result = formatarg(arg)\n  if arg in annotations:\n   result += ': ' + formatannotation(annotations[arg])\n  return result\n specs = []\n if defaults:\n  firstdefault = len(args) - len(defaults)\n for i, arg in enumerate(args):\n  spec = formatargandannotation(arg)\n  if defaults and i >= firstdefault:\n   spec = spec + formatvalue(defaults[i - firstdefault])\n  specs.append(spec)\n if varargs is not None:\n  specs.append(formatvarargs(formatargandannotation(varargs)))\n else:\n  if kwonlyargs:\n   specs.append('*')\n if kwonlyargs:\n  for kwonlyarg in kwonlyargs:\n   spec = formatargandannotation(kwonlyarg)\n   if kwonlydefaults and kwonlyarg in kwonlydefaults:\n    spec += formatvalue(kwonlydefaults[kwonlyarg])\n   specs.append(spec)\n if varkw is not None:\n  specs.append(formatvarkw(formatargandannotation(varkw)))\n result = '(' + ', '.join(specs) + ')'\n if 'return' in annotations:\n  result += formatreturns(formatannotation(annotations['return']))\n return result\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \ndef _missing_arguments(f_name, argnames, pos, values):\n names = [repr(name) for name in argnames if name not in values]\n missing = len(names)\n if missing == 1:\n  s = names[0]\n elif missing == 2:\n  s = \"{} and {}\".format(*names)\n else:\n  tail = \", {} and {}\".format(names[-2:])\n  del names[-2:]\n  s = \", \".join(names) + tail\n raise TypeError(\"%s() missing %i required %s argument%s: %s\" %\n (f_name, missing,\n \"positional\" if pos else \"keyword-only\",\n \"\" if missing == 1 else \"s\", s))\n \ndef _too_many(f_name, args, kwonly, varargs, defcount, given, values):\n atleast = len(args) - defcount\n kwonly_given = len([arg for arg in kwonly if arg in values])\n if varargs:\n  plural = atleast != 1\n  sig = \"at least %d\" % (atleast,)\n elif defcount:\n  plural = True\n  sig = \"from %d to %d\" % (atleast, len(args))\n else:\n  plural = len(args) != 1\n  sig = str(len(args))\n kwonly_sig = \"\"\n if kwonly_given:\n  msg = \" positional argument%s (and %d keyword-only argument%s)\"\n  kwonly_sig = (msg % (\"s\" if given != 1 else \"\", kwonly_given,\n  \"s\" if kwonly_given != 1 else \"\"))\n raise TypeError(\"%s() takes %s positional argument%s but %d%s %s given\" %\n (f_name, sig, \"s\" if plural else \"\", given, kwonly_sig,\n \"was\" if given == 1 and not kwonly_given else \"were\"))\n \ndef getcallargs(func, *positional, **named):\n \"\"\n spec = getfullargspec(func)\n args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, ann = spec\n f_name = func.__name__\n arg2value = {}\n \n \n if ismethod(func) and func.__self__ is not None:\n \n  positional = (func.__self__,) + positional\n num_pos = len(positional)\n num_args = len(args)\n num_defaults = len(defaults) if defaults else 0\n \n n = min(num_pos, num_args)\n for i in range(n):\n  arg2value[args[i]] = positional[i]\n if varargs:\n  arg2value[varargs] = tuple(positional[n:])\n possible_kwargs = set(args + kwonlyargs)\n if varkw:\n  arg2value[varkw] = {}\n for kw, value in named.items():\n  if kw not in possible_kwargs:\n   if not varkw:\n    raise TypeError(\"%s() got an unexpected keyword argument %r\" %\n    (f_name, kw))\n   arg2value[varkw][kw] = value\n   continue\n  if kw in arg2value:\n   raise TypeError(\"%s() got multiple values for argument %r\" %\n   (f_name, kw))\n  arg2value[kw] = value\n if num_pos > num_args and not varargs:\n  _too_many(f_name, args, kwonlyargs, varargs, num_defaults,\n  num_pos, arg2value)\n if num_pos < num_args:\n  req = args[:num_args - num_defaults]\n  for arg in req:\n   if arg not in arg2value:\n    _missing_arguments(f_name, req, True, arg2value)\n  for i, arg in enumerate(args[num_args - num_defaults:]):\n   if arg not in arg2value:\n    arg2value[arg] = defaults[i]\n missing = 0\n for kwarg in kwonlyargs:\n  if kwarg not in arg2value:\n   if kwarg in kwonlydefaults:\n    arg2value[kwarg] = kwonlydefaults[kwarg]\n   else:\n    missing += 1\n if missing:\n  _missing_arguments(f_name, kwonlyargs, False, arg2value)\n return arg2value\n \nClosureVars = namedtuple('ClosureVars', 'nonlocals globals builtins unbound')\n\ndef getclosurevars(func):\n \"\"\n \n if ismethod(func):\n  func = func.__func__\n  \n if not isfunction(func):\n  raise TypeError(\"'{!r}' is not a Python function\".format(func))\n  \n code = func.__code__\n \n \n if func.__closure__ is None:\n  nonlocal_vars = {}\n else:\n  nonlocal_vars = {\n  var : cell.cell_contents\n  for var, cell in zip(code.co_freevars, func.__closure__)\n  }\n  \n  \n  \n global_ns = func.__globals__\n builtin_ns = global_ns.get(\"__builtins__\", builtins.__dict__)\n if ismodule(builtin_ns):\n  builtin_ns = builtin_ns.__dict__\n global_vars = {}\n builtin_vars = {}\n unbound_names = set()\n for name in code.co_names:\n  if name in (\"None\", \"True\", \"False\"):\n  \n  \n   continue\n  try:\n   global_vars[name] = global_ns[name]\n  except KeyError:\n   try:\n    builtin_vars[name] = builtin_ns[name]\n   except KeyError:\n    unbound_names.add(name)\n    \n return ClosureVars(nonlocal_vars, global_vars,\n builtin_vars, unbound_names)\n \n \n \nTraceback = namedtuple('Traceback', 'filename lineno function code_context index')\n\ndef getframeinfo(frame, context=1):\n \"\"\n if istraceback(frame):\n  lineno = frame.tb_lineno\n  frame = frame.tb_frame\n else:\n  lineno = frame.f_lineno\n if not isframe(frame):\n  raise TypeError('{!r} is not a frame or traceback object'.format(frame))\n  \n filename = getsourcefile(frame) or getfile(frame)\n if context > 0:\n  start = lineno - 1 - context//2\n  try:\n   lines, lnum = findsource(frame)\n  except IOError:\n   lines = index = None\n  else:\n   start = max(start, 1)\n   start = max(0, min(start, len(lines) - context))\n   lines = lines[start:start+context]\n   index = lineno - 1 - start\n else:\n  lines = index = None\n  \n return Traceback(filename, lineno, frame.f_code.co_name, lines, index)\n \ndef getlineno(frame):\n \"\"\n \n return frame.f_lineno\n \ndef getouterframes(frame, context=1):\n \"\"\n framelist = []\n while frame:\n  framelist.append((frame,) + getframeinfo(frame, context))\n  frame = frame.f_back\n return framelist\n \ndef getinnerframes(tb, context=1):\n \"\"\n framelist = []\n while tb:\n  framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n  tb = tb.tb_next\n return framelist\n \ndef currentframe():\n \"\"\n return sys._getframe(1) if hasattr(sys, \"_getframe\") else None\n \ndef stack(context=1):\n \"\"\n return getouterframes(sys._getframe(1), context)\n \ndef trace(context=1):\n \"\"\n return getinnerframes(sys.exc_info()[2], context)\n \n \n \n \n_sentinel = object()\n\ndef _static_getmro(klass):\n return type.__dict__['__mro__'].__get__(klass)\n \ndef _check_instance(obj, attr):\n instance_dict = {}\n try:\n  instance_dict = object.__getattribute__(obj, \"__dict__\")\n except AttributeError:\n  pass\n return dict.get(instance_dict, attr, _sentinel)\n \n \ndef _check_class(klass, attr):\n for entry in _static_getmro(klass):\n  if _shadowed_dict(type(entry)) is _sentinel:\n   try:\n    return entry.__dict__[attr]\n   except KeyError:\n    pass\n return _sentinel\n \ndef _is_type(obj):\n try:\n  _static_getmro(obj)\n except TypeError:\n  return False\n return True\n \ndef _shadowed_dict(klass):\n dict_attr = type.__dict__[\"__dict__\"]\n for entry in _static_getmro(klass):\n  try:\n   class_dict = dict_attr.__get__(entry)[\"__dict__\"]\n  except KeyError:\n   pass\n  else:\n   if not (type(class_dict) is types.GetSetDescriptorType and\n   class_dict.__name__ == \"__dict__\" and\n   class_dict.__objclass__ is entry):\n    return class_dict\n return _sentinel\n \ndef getattr_static(obj, attr, default=_sentinel):\n \"\"\n instance_result = _sentinel\n if not _is_type(obj):\n  klass = type(obj)\n  dict_attr = _shadowed_dict(klass)\n  if (dict_attr is _sentinel or\n  type(dict_attr) is types.MemberDescriptorType):\n   instance_result = _check_instance(obj, attr)\n else:\n  klass = obj\n  \n klass_result = _check_class(klass, attr)\n \n if instance_result is not _sentinel and klass_result is not _sentinel:\n  if (_check_class(type(klass_result), '__get__') is not _sentinel and\n  _check_class(type(klass_result), '__set__') is not _sentinel):\n   return klass_result\n   \n if instance_result is not _sentinel:\n  return instance_result\n if klass_result is not _sentinel:\n  return klass_result\n  \n if obj is klass:\n \n  for entry in _static_getmro(type(klass)):\n   if _shadowed_dict(type(entry)) is _sentinel:\n    try:\n     return entry.__dict__[attr]\n    except KeyError:\n     pass\n if default is not _sentinel:\n  return default\n raise AttributeError(attr)\n \n \n \n \nGEN_CREATED = 'GEN_CREATED'\nGEN_RUNNING = 'GEN_RUNNING'\nGEN_SUSPENDED = 'GEN_SUSPENDED'\nGEN_CLOSED = 'GEN_CLOSED'\n\ndef getgeneratorstate(generator):\n \"\"\n if generator.gi_running:\n  return GEN_RUNNING\n if generator.gi_frame is None:\n  return GEN_CLOSED\n if generator.gi_frame.f_lasti == -1:\n  return GEN_CREATED\n return GEN_SUSPENDED\n \n \ndef getgeneratorlocals(generator):\n \"\"\n \n if not isgenerator(generator):\n  raise TypeError(\"'{!r}' is not a Python generator\".format(generator))\n  \n frame = getattr(generator, \"gi_frame\", None)\n if frame is not None:\n  return generator.gi_frame.f_locals\n else:\n  return {}\n  \n  \n  \n  \n  \n  \n_WrapperDescriptor = type(type.__call__)\n_MethodWrapper = type(all.__call__)\n\n_NonUserDefinedCallables = (_WrapperDescriptor,\n_MethodWrapper,\ntypes.BuiltinFunctionType)\n\n\ndef _get_user_defined_method(cls, method_name):\n try:\n  meth = getattr(cls, method_name)\n except AttributeError:\n  return\n else:\n  if not isinstance(meth, _NonUserDefinedCallables):\n  \n  \n   return meth\n   \n   \ndef signature(obj):\n \"\"\n \n if not callable(obj):\n  raise TypeError('{!r} is not a callable object'.format(obj))\n  \n if isinstance(obj, types.MethodType):\n \n \n  sig = signature(obj.__func__)\n  return sig.replace(parameters=tuple(sig.parameters.values())[1:])\n  \n try:\n  sig = obj.__signature__\n except AttributeError:\n  pass\n else:\n  if sig is not None:\n   return sig\n   \n try:\n \n  wrapped = obj.__wrapped__\n except AttributeError:\n  pass\n else:\n  return signature(wrapped)\n  \n if isinstance(obj, types.FunctionType):\n  return Signature.from_function(obj)\n  \n if isinstance(obj, functools.partial):\n  sig = signature(obj.func)\n  \n  new_params = OrderedDict(sig.parameters.items())\n  \n  partial_args = obj.args or ()\n  partial_keywords = obj.keywords or {}\n  try:\n   ba = sig.bind_partial(*partial_args, **partial_keywords)\n  except TypeError as ex:\n   msg = 'partial object {!r} has incorrect arguments'.format(obj)\n   raise ValueError(msg) from ex\n   \n  for arg_name, arg_value in ba.arguments.items():\n   param = new_params[arg_name]\n   if arg_name in partial_keywords:\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n    new_params[arg_name] = param.replace(default=arg_value,\n    _partial_kwarg=True)\n    \n   elif (param.kind not in (_VAR_KEYWORD, _VAR_POSITIONAL) and\n   not param._partial_kwarg):\n    new_params.pop(arg_name)\n    \n  return sig.replace(parameters=new_params.values())\n  \n sig = None\n if isinstance(obj, type):\n \n \n \n \n  call = _get_user_defined_method(type(obj), '__call__')\n  if call is not None:\n   sig = signature(call)\n  else:\n  \n   new = _get_user_defined_method(obj, '__new__')\n   if new is not None:\n    sig = signature(new)\n   else:\n   \n    init = _get_user_defined_method(obj, '__init__')\n    if init is not None:\n     sig = signature(init)\n elif not isinstance(obj, _NonUserDefinedCallables):\n \n \n \n \n  call = _get_user_defined_method(type(obj), '__call__')\n  if call is not None:\n   sig = signature(call)\n   \n if sig is not None:\n \n \n  return sig.replace(parameters=tuple(sig.parameters.values())[1:])\n  \n if isinstance(obj, types.BuiltinFunctionType):\n \n  msg = 'no signature found for builtin function {!r}'.format(obj)\n  raise ValueError(msg)\n  \n raise ValueError('callable {!r} is not supported by signature'.format(obj))\n \n \nclass _void:\n \"\"\n \n \nclass _empty:\n pass\n \n \nclass _ParameterKind(int):\n def __new__(self, *args, name):\n  obj = int.__new__(self, *args)\n  obj._name = name\n  return obj\n  \n def __str__(self):\n  return self._name\n  \n def __repr__(self):\n  return '<_ParameterKind: {!r}>'.format(self._name)\n  \n  \n_POSITIONAL_ONLY = _ParameterKind(0, name='POSITIONAL_ONLY')\n_POSITIONAL_OR_KEYWORD = _ParameterKind(1, name='POSITIONAL_OR_KEYWORD')\n_VAR_POSITIONAL = _ParameterKind(2, name='VAR_POSITIONAL')\n_KEYWORD_ONLY = _ParameterKind(3, name='KEYWORD_ONLY')\n_VAR_KEYWORD = _ParameterKind(4, name='VAR_KEYWORD')\n\n\nclass Parameter:\n \"\"\n \n __slots__ = ('_name', '_kind', '_default', '_annotation', '_partial_kwarg')\n \n POSITIONAL_ONLY = _POSITIONAL_ONLY\n POSITIONAL_OR_KEYWORD = _POSITIONAL_OR_KEYWORD\n VAR_POSITIONAL = _VAR_POSITIONAL\n KEYWORD_ONLY = _KEYWORD_ONLY\n VAR_KEYWORD = _VAR_KEYWORD\n \n empty = _empty\n \n def __init__(self, name, kind, *, default=_empty, annotation=_empty,\n _partial_kwarg=False):\n \n  if kind not in (_POSITIONAL_ONLY, _POSITIONAL_OR_KEYWORD,\n  _VAR_POSITIONAL, _KEYWORD_ONLY, _VAR_KEYWORD):\n   raise ValueError(\"invalid value for 'Parameter.kind' attribute\")\n  self._kind = kind\n  \n  if default is not _empty:\n   if kind in (_VAR_POSITIONAL, _VAR_KEYWORD):\n    msg = '{} parameters cannot have default values'.format(kind)\n    raise ValueError(msg)\n  self._default = default\n  self._annotation = annotation\n  \n  if name is None:\n   if kind != _POSITIONAL_ONLY:\n    raise ValueError(\"None is not a valid name for a \"\n    \"non-positional-only parameter\")\n   self._name = name\n  else:\n   name = str(name)\n   if kind != _POSITIONAL_ONLY and not name.isidentifier():\n    msg = '{!r} is not a valid parameter name'.format(name)\n    raise ValueError(msg)\n   self._name = name\n   \n  self._partial_kwarg = _partial_kwarg\n  \n @property\n def name(self):\n  return self._name\n  \n @property\n def default(self):\n  return self._default\n  \n @property\n def annotation(self):\n  return self._annotation\n  \n @property\n def kind(self):\n  return self._kind\n  \n def replace(self, *, name=_void, kind=_void, annotation=_void,\n default=_void, _partial_kwarg=_void):\n  \"\"\n  \n  if name is _void:\n   name = self._name\n   \n  if kind is _void:\n   kind = self._kind\n   \n  if annotation is _void:\n   annotation = self._annotation\n   \n  if default is _void:\n   default = self._default\n   \n  if _partial_kwarg is _void:\n   _partial_kwarg = self._partial_kwarg\n   \n  return type(self)(name, kind, default=default, annotation=annotation,\n  _partial_kwarg=_partial_kwarg)\n  \n def __str__(self):\n  kind = self.kind\n  \n  formatted = self._name\n  if kind == _POSITIONAL_ONLY:\n   if formatted is None:\n    formatted = ''\n   formatted = '<{}>'.format(formatted)\n   \n   \n  if self._annotation is not _empty:\n   formatted = '{}:{}'.format(formatted,\n   formatannotation(self._annotation))\n   \n  if self._default is not _empty:\n   formatted = '{}={}'.format(formatted, repr(self._default))\n   \n  if kind == _VAR_POSITIONAL:\n   formatted = '*' + formatted\n  elif kind == _VAR_KEYWORD:\n   formatted = '**' + formatted\n   \n  return formatted\n  \n def __repr__(self):\n  return '<{} at {:#x} {!r}>'.format(self.__class__.__name__,\n  id(self), self.name)\n  \n def __eq__(self, other):\n  return (issubclass(other.__class__, Parameter) and\n  self._name == other._name and\n  self._kind == other._kind and\n  self._default == other._default and\n  self._annotation == other._annotation)\n  \n def __ne__(self, other):\n  return not self.__eq__(other)\n  \n  \nclass BoundArguments:\n \"\"\n \n def __init__(self, signature, arguments):\n  self.arguments = arguments\n  self._signature = signature\n  \n @property\n def signature(self):\n  return self._signature\n  \n @property\n def args(self):\n  args = []\n  for param_name, param in self._signature.parameters.items():\n   if (param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY) or\n   param._partial_kwarg):\n   \n   \n   \n   \n    break\n    \n   try:\n    arg = self.arguments[param_name]\n   except KeyError:\n   \n   \n    break\n   else:\n    if param.kind == _VAR_POSITIONAL:\n    \n     args.extend(arg)\n    else:\n    \n     args.append(arg)\n     \n  return tuple(args)\n  \n @property\n def kwargs(self):\n  kwargs = {}\n  kwargs_started = False\n  for param_name, param in self._signature.parameters.items():\n   if not kwargs_started:\n    if (param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY) or\n    param._partial_kwarg):\n     kwargs_started = True\n    else:\n     if param_name not in self.arguments:\n      kwargs_started = True\n      continue\n      \n   if not kwargs_started:\n    continue\n    \n   try:\n    arg = self.arguments[param_name]\n   except KeyError:\n    pass\n   else:\n    if param.kind == _VAR_KEYWORD:\n    \n     kwargs.update(arg)\n    else:\n    \n     kwargs[param_name] = arg\n     \n  return kwargs\n  \n def __eq__(self, other):\n  return (issubclass(other.__class__, BoundArguments) and\n  self.signature == other.signature and\n  self.arguments == other.arguments)\n  \n def __ne__(self, other):\n  return not self.__eq__(other)\n  \n  \nclass Signature:\n \"\"\n \n __slots__ = ('_return_annotation', '_parameters')\n \n _parameter_cls = Parameter\n _bound_arguments_cls = BoundArguments\n \n empty = _empty\n \n def __init__(self, parameters=None, *, return_annotation=_empty,\n __validate_parameters__=True):\n  \"\"\n  \n  if parameters is None:\n   params = OrderedDict()\n  else:\n   if __validate_parameters__:\n    params = OrderedDict()\n    top_kind = _POSITIONAL_ONLY\n    \n    for idx, param in enumerate(parameters):\n     kind = param.kind\n     if kind < top_kind:\n      msg = 'wrong parameter order: {} before {}'\n      msg = msg.format(top_kind, param.kind)\n      raise ValueError(msg)\n     else:\n      top_kind = kind\n      \n     name = param.name\n     if name is None:\n      name = str(idx)\n      param = param.replace(name=name)\n      \n     if name in params:\n      msg = 'duplicate parameter name: {!r}'.format(name)\n      raise ValueError(msg)\n     params[name] = param\n   else:\n    params = OrderedDict(((param.name, param)\n    for param in parameters))\n    \n  self._parameters = types.MappingProxyType(params)\n  self._return_annotation = return_annotation\n  \n @classmethod\n def from_function(cls, func):\n  \"\"\n  \n  if not isinstance(func, types.FunctionType):\n   raise TypeError('{!r} is not a Python function'.format(func))\n   \n  Parameter = cls._parameter_cls\n  \n  \n  func_code = func.__code__\n  pos_count = func_code.co_argcount\n  arg_names = func_code.co_varnames\n  positional = tuple(arg_names[:pos_count])\n  keyword_only_count = func_code.co_kwonlyargcount\n  keyword_only = arg_names[pos_count:(pos_count + keyword_only_count)]\n  annotations = func.__annotations__\n  defaults = func.__defaults__\n  kwdefaults = func.__kwdefaults__\n  \n  if defaults:\n   pos_default_count = len(defaults)\n  else:\n   pos_default_count = 0\n   \n  parameters = []\n  \n  \n  non_default_count = pos_count - pos_default_count\n  for name in positional[:non_default_count]:\n   annotation = annotations.get(name, _empty)\n   parameters.append(Parameter(name, annotation=annotation,\n   kind=_POSITIONAL_OR_KEYWORD))\n   \n   \n  for offset, name in enumerate(positional[non_default_count:]):\n   annotation = annotations.get(name, _empty)\n   parameters.append(Parameter(name, annotation=annotation,\n   kind=_POSITIONAL_OR_KEYWORD,\n   default=defaults[offset]))\n   \n   \n  if func_code.co_flags & 0x04:\n   name = arg_names[pos_count + keyword_only_count]\n   annotation = annotations.get(name, _empty)\n   parameters.append(Parameter(name, annotation=annotation,\n   kind=_VAR_POSITIONAL))\n   \n   \n  for name in keyword_only:\n   default = _empty\n   if kwdefaults is not None:\n    default = kwdefaults.get(name, _empty)\n    \n   annotation = annotations.get(name, _empty)\n   parameters.append(Parameter(name, annotation=annotation,\n   kind=_KEYWORD_ONLY,\n   default=default))\n   \n  if func_code.co_flags & 0x08:\n   index = pos_count + keyword_only_count\n   if func_code.co_flags & 0x04:\n    index += 1\n    \n   name = arg_names[index]\n   annotation = annotations.get(name, _empty)\n   parameters.append(Parameter(name, annotation=annotation,\n   kind=_VAR_KEYWORD))\n   \n  return cls(parameters,\n  return_annotation=annotations.get('return', _empty),\n  __validate_parameters__=False)\n  \n @property\n def parameters(self):\n  return self._parameters\n  \n @property\n def return_annotation(self):\n  return self._return_annotation\n  \n def replace(self, *, parameters=_void, return_annotation=_void):\n  \"\"\n  \n  if parameters is _void:\n   parameters = self.parameters.values()\n   \n  if return_annotation is _void:\n   return_annotation = self._return_annotation\n   \n  return type(self)(parameters,\n  return_annotation=return_annotation)\n  \n def __eq__(self, other):\n  if (not issubclass(type(other), Signature) or\n  self.return_annotation != other.return_annotation or\n  len(self.parameters) != len(other.parameters)):\n   return False\n   \n  other_positions = {param: idx\n  for idx, param in enumerate(other.parameters.keys())}\n  \n  for idx, (param_name, param) in enumerate(self.parameters.items()):\n   if param.kind == _KEYWORD_ONLY:\n    try:\n     other_param = other.parameters[param_name]\n    except KeyError:\n     return False\n    else:\n     if param != other_param:\n      return False\n   else:\n    try:\n     other_idx = other_positions[param_name]\n    except KeyError:\n     return False\n    else:\n     if (idx != other_idx or\n     param != other.parameters[param_name]):\n      return False\n      \n  return True\n  \n def __ne__(self, other):\n  return not self.__eq__(other)\n  \n def _bind(self, args, kwargs, *, partial=False):\n  \"\"\n  \n  arguments = OrderedDict()\n  \n  parameters = iter(self.parameters.values())\n  parameters_ex = ()\n  arg_vals = iter(args)\n  \n  if partial:\n  \n  \n  \n   for param_name, param in self.parameters.items():\n    if (param._partial_kwarg and param_name not in kwargs):\n    \n     kwargs[param_name] = param.default\n     \n  while True:\n  \n  \n   try:\n    arg_val = next(arg_vals)\n   except StopIteration:\n   \n    try:\n     param = next(parameters)\n    except StopIteration:\n    \n    \n     break\n    else:\n     if param.kind == _VAR_POSITIONAL:\n     \n     \n      break\n     elif param.name in kwargs:\n      if param.kind == _POSITIONAL_ONLY:\n       msg = '{arg!r} parameter is positional only, ' 'but was passed as a keyword'\n       msg = msg.format(arg=param.name)\n       raise TypeError(msg) from None\n      parameters_ex = (param,)\n      break\n     elif (param.kind == _VAR_KEYWORD or\n     param.default is not _empty):\n     \n     \n     \n      parameters_ex = (param,)\n      break\n     else:\n      if partial:\n       parameters_ex = (param,)\n       break\n      else:\n       msg = '{arg!r} parameter lacking default value'\n       msg = msg.format(arg=param.name)\n       raise TypeError(msg) from None\n   else:\n   \n    try:\n     param = next(parameters)\n    except StopIteration:\n     raise TypeError('too many positional arguments') from None\n    else:\n     if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):\n     \n     \n      raise TypeError('too many positional arguments')\n      \n     if param.kind == _VAR_POSITIONAL:\n     \n     \n     \n      values = [arg_val]\n      values.extend(arg_vals)\n      arguments[param.name] = tuple(values)\n      break\n      \n     if param.name in kwargs:\n      raise TypeError('multiple values for argument '\n      '{arg!r}'.format(arg=param.name))\n      \n     arguments[param.name] = arg_val\n     \n     \n     \n  kwargs_param = None\n  for param in itertools.chain(parameters_ex, parameters):\n   if param.kind == _POSITIONAL_ONLY:\n   \n   \n   \n    raise TypeError('{arg!r} parameter is positional only, '\n    'but was passed as a keyword'. format(arg=param.name))\n    \n   if param.kind == _VAR_KEYWORD:\n   \n    kwargs_param = param\n    continue\n    \n   param_name = param.name\n   try:\n    arg_val = kwargs.pop(param_name)\n   except KeyError:\n   \n   \n   \n   \n    if (not partial and param.kind != _VAR_POSITIONAL and\n    param.default is _empty):\n     raise TypeError('{arg!r} parameter lacking default value'. format(arg=param_name)) from None\n     \n   else:\n    arguments[param_name] = arg_val\n    \n  if kwargs:\n   if kwargs_param is not None:\n   \n    arguments[kwargs_param.name] = kwargs\n   else:\n    raise TypeError('too many keyword arguments')\n    \n  return self._bound_arguments_cls(self, arguments)\n  \n def bind(__bind_self, *args, **kwargs):\n  \"\"\n  return __bind_self._bind(args, kwargs)\n  \n def bind_partial(__bind_self, *args, **kwargs):\n  \"\"\n  return __bind_self._bind(args, kwargs, partial=True)\n  \n def __str__(self):\n  result = []\n  render_kw_only_separator = True\n  for idx, param in enumerate(self.parameters.values()):\n   formatted = str(param)\n   \n   kind = param.kind\n   if kind == _VAR_POSITIONAL:\n   \n   \n    render_kw_only_separator = False\n   elif kind == _KEYWORD_ONLY and render_kw_only_separator:\n   \n   \n   \n    result.append('*')\n    \n    \n    render_kw_only_separator = False\n    \n   result.append(formatted)\n   \n  rendered = '({})'.format(', '.join(result))\n  \n  if self.return_annotation is not _empty:\n   anno = formatannotation(self.return_annotation)\n   rendered += ' -> {}'.format(anno)\n   \n  return rendered\n"], "browser.markdown": [".py", "import browser.html\nimport _jsre as re\nimport __random as random\n\nletters = 'abcdefghijklmnopqrstuvwxyz'\nletters += letters.upper()+'0123456789'\n\nclass URL:\n def __init__(self,src):\n  elts = src.split(maxsplit=1)\n  self.href = elts[0]\n  self.alt = ''\n  if len(elts)==2:\n   alt = elts[1]\n   if alt[0]=='\"' and alt[-1]=='\"':self.alt=alt[1:-1]\n   elif alt[0]==\"'\" and alt[-1]==\"'\":self.alt=alt[1:-1]\n   elif alt[0]==\"(\" and alt[-1]==\")\":self.alt=alt[1:-1]\n   \nclass CodeBlock:\n def __init__(self,line):\n  self.lines = [line]\n  \n def to_html(self):\n  if self.lines[0].startswith(\"`\"):\n   self.lines.pop(0)\n  res = escape('\\n'.join(self.lines))\n  res = unmark(res)\n  res = '<pre class=\"marked\">%s</pre>\\n' %res\n  return res,[]\n  \nclass HtmlBlock:\n\n def __init__(self, src):\n  self.src = src\n  \n def to_html(self):\n  return self.src\n  \nclass Marked:\n def __init__(self, line=''):\n  self.line = line\n  self.children = []\n  \n def to_html(self):\n  return apply_markdown(self.line)\n  \n  \nrefs = {}\nref_pattern = r\"^\\[(.*)\\]:\\s+(.*)\"\n\ndef mark(src):\n\n global refs\n refs = {}\n \n \n \n \n \n \n \n \n src = src.replace('\\r\\n','\\n')\n \n \n src = re.sub(r'(.*?)\\n=+\\n', '\\n# \\\\1\\n', src)\n src = re.sub(r'(.*?)\\n-+\\n', '\\n## \\\\1\\n', src) \n \n lines = src.split('\\n')+['']\n \n i = bq = 0\n ul = ol = 0\n \n while i<len(lines):\n \n \n  if lines[i].startswith('>'):\n   nb = 1\n   while nb<len(lines[i]) and lines[i][nb]=='>':\n    nb += 1\n   lines[i] = lines[i][nb:]\n   if nb>bq:\n    lines.insert(i,'<blockquote>'*(nb-bq))\n    i += 1\n    bq = nb\n   elif nb<bq:\n    lines.insert(i,'</blockquote>'*(bq-nb))\n    i += 1\n    bq = nb\n  elif bq>0:\n   lines.insert(i,'</blockquote>'*bq)\n   i += 1\n   bq = 0\n   \n   \n  if lines[i].strip() and lines[i].lstrip()[0] in '-+*' and len(lines[i].lstrip())>1 and lines[i].lstrip()[1]==' ' and (i==0 or ul or not lines[i-1].strip()):\n  \n   nb = 1+len(lines[i])-len(lines[i].lstrip())\n   lines[i] = '<li>'+lines[i][nb:]\n   if nb>ul:\n    lines.insert(i,'<ul>'*(nb-ul))\n    i += 1\n   elif nb<ul:\n    lines.insert(i,'</ul>'*(ul-nb))\n    i += 1\n   ul = nb\n  elif ul and not lines[i].strip():\n   if i<len(lines)-1 and lines[i+1].strip() and not lines[i+1].startswith(' '):\n    nline = lines[i+1].lstrip()\n    if nline[0] in '-+*' and len(nline)>1 and nline[1]==' ':\n     pass\n    else:\n     lines.insert(i,'</ul>'*ul)\n     i += 1\n     ul = 0\n     \n     \n  mo = re.search(r'^(\\d+\\.)',lines[i])\n  if mo:\n   if not ol:\n    lines.insert(i,'<ol>')\n    i += 1\n   lines[i] = '<li>'+lines[i][len(mo.groups()[0]):]\n   ol = 1\n  elif ol and not lines[i].strip() and i<len(lines)-1 and not lines[i+1].startswith(' ') and not re.search(r'^(\\d+\\.)',lines[i+1]):\n   lines.insert(i,'</ol>')\n   i += 1\n   ol = 0\n   \n  i += 1\n  \n if ul:\n  lines.append('</ul>'*ul)\n if ol:\n  lines.append('</ol>'*ol)\n if bq:\n  lines.append('</blockquote>'*bq)\n  \n sections = []\n scripts = []\n section = Marked()\n \n i = 0\n while i<len(lines):\n  line = lines[i]\n  if line.strip() and line.startswith('    '):\n   if isinstance(section,Marked) and section.line:\n    sections.append(section)\n   section = CodeBlock(line[4:])\n   j = i+1\n   while j<len(lines) and lines[j].startswith('    '):\n    section.lines.append(lines[j][4:])\n    j += 1\n   sections.append(section)\n   section = Marked()\n   i = j \n   continue\n   \n  elif line.lower().startswith('<script'):\n   if isinstance(section,Marked) and section.line:\n    sections.append(section)\n    section = Marked()\n   j = i+1\n   while j<len(lines):\n    if lines[j].lower().startswith('</script>'):\n     scripts.append('\\n'.join(lines[i+1:j]))\n     for k in range(i,j+1):\n      lines[k] = ''\n     break\n    j += 1\n   i = j\n   continue\n   \n   \n  elif line.startswith('#'):\n   level = 1\n   line = lines[i]\n   while level<len(line) and line[level]=='#' and level<=6:\n    level += 1\n   if not line[level+1:].strip():\n    if level==1:\n     i += 1\n     continue\n    else:\n     lines[i] = '<H%s>%s</H%s>\\n' %(level-1,'#',level-1)\n   else:\n    lines[i] = '<H%s>%s</H%s>\\n' %(level,line[level+1:],level)\n    \n  else:\n   mo = re.search(ref_pattern,line)\n   if mo is not None:\n    if isinstance(section,Marked) and section.line:\n     sections.append(section)\n     section = Marked()\n    key = mo.groups()[0]\n    value = URL(mo.groups()[1])\n    refs[key.lower()] = value\n   else:\n    if not line.strip():\n     line = '<p></p>'\n    if section.line:\n     section.line += ' '\n    section.line += line\n    \n   i += 1\n   \n if isinstance(section,Marked) and section.line:\n  sections.append(section)\n  \n res = ''\n for section in sections:\n  mk,_scripts = section.to_html()\n  res += mk\n  scripts += _scripts\n return res,scripts\n \ndef escape(czone):\n czone = czone.replace('&','&amp;')\n czone = czone.replace('<','&lt;')\n czone = czone.replace('>','&gt;')\n czone = czone.replace('_','&#95;')\n czone = czone.replace('*','&#42;')\n return czone\n \ndef s_escape(mo):\n\n czone = mo.string[mo.start():mo.end()]\n return escape(czone)\n \ndef unmark(code_zone):\n\n code_zone = code_zone.replace('_','&#95;')\n return code_zone\n \ndef s_unmark(mo):\n\n code_zone = mo.string[mo.start():mo.end()]\n code_zone = code_zone.replace('_','&#95;')\n return code_zone\n \ndef apply_markdown(src):\n\n scripts = []\n key = None\n \n i = 0\n while i<len(src):\n  if src[i]=='[':\n   start_a = i+1\n   while True:\n    end_a = src.find(']',i)\n    if end_a == -1:\n     break\n    if src[end_a-1]=='\\\\':\n     i = end_a+1\n    else:\n     break\n   if end_a>-1 and src[start_a:end_a].find('\\n')==-1:\n    link = src[start_a:end_a]\n    rest = src[end_a+1:].lstrip()\n    if rest and rest[0]=='(':\n     j = 0\n     while True:\n      end_href = rest.find(')',j)\n      if end_href == -1:\n       break\n      if rest[end_href-1]=='\\\\':\n       j = end_href+1\n      else:\n       break\n     if end_href>-1 and rest[:end_href].find('\\n')==-1:\n      tag = '<a href=\"'+rest[1:end_href]+'\">'+link+'</a>'\n      src = src[:start_a-1]+tag+rest[end_href+1:]\n      i = start_a+len(tag)\n    elif rest and rest[0]=='[':\n     j = 0\n     while True:\n      end_key = rest.find(']',j)\n      if end_key == -1:\n       break\n      if rest[end_key-1]=='\\\\':\n       j = end_key+1\n      else:\n       break\n     if end_key>-1 and rest[:end_key].find('\\n')==-1:\n      if not key:\n       key = link\n      if key.lower() not in refs:\n       raise KeyError('unknown reference %s' %key)\n      url = refs[key.lower()]\n      tag = '<a href=\"'+url+'\">'+link+'</a>'\n      src = src[:start_a-1]+tag+rest[end_key+1:]\n      i = start_a+len(tag)\n      \n  i += 1\n  \n  \n  \n  \n  \n rstr = ''.join(random.choice(letters) for i in range(16))\n \n i = 0\n state = None\n start = -1\n data = ''\n tags = []\n while i<len(src):\n  if src[i]=='<':\n   j = i+1\n   while j<len(src):\n    if src[j]=='\"' or src[j]==\"'\":\n     if state==src[j] and src[j-1]!='\\\\':\n      state = None\n      \n      j = start+len(data)+1\n      data = ''\n     elif state==None:\n      state = src[j]\n      start = j\n     else:\n      data += src[j]\n    elif src[j]=='>' and state is None:\n     tags.append(src[i:j+1])\n     src = src[:i]+rstr+src[j+1:]\n     i += len(rstr)\n     break\n    elif state=='\"' or state==\"'\":\n     data += src[j]\n    elif src[j]=='\\n':\n    \n    \n     src = src[:i]+'&lt;'+src[i+1:]\n     j=i+4\n     break\n    j += 1\n    \n  elif src[i]=='`' and i>0 and src[i-1]!='\\\\':\n  \n   j = i+1\n   while j<len(src):\n    if src[j]=='`' and src[j-1]!='\\\\':\n     break\n    j += 1\n   i = j\n  i += 1 \n  \n  \n code_pattern = r'\\`(.*?)\\`'\n src = re.sub(code_pattern,s_escape,src)\n \n \n src = src.replace(r'\\\\\\`','&#96;')\n src = src.replace(r'\\\\_','&#95;')\n src = src.replace(r'\\\\*','&#42;')\n \n \n strong_patterns = [('STRONG',r'\\*\\*(.*?)\\*\\*'),('B',r'__(.*?)__')]\n for tag,strong_pattern in strong_patterns:\n  src = re.sub(strong_pattern,r'<%s>\\1</%s>' %(tag,tag),src)\n  \n em_patterns = [('EM',r'\\*(.*?)\\*'),('I',r'\\_(.*?)\\_')]\n for tag,em_pattern in em_patterns:\n  src = re.sub(em_pattern,r'<%s>\\1</%s>' %(tag,tag),src)\n  \n  \n code_pattern = r'\\`(.*?)\\`'\n src = re.sub(code_pattern,r'<code>\\1</code>',src)\n \n \n while True:\n  pos = src.rfind(rstr)\n  if pos==-1:\n   break\n  repl = tags.pop()\n  src = src[:pos]+repl+src[pos+len(rstr):]\n  \n src = '<p>'+src+'</p>'\n \n return src,scripts\n"], "test.pystone": [".py", "\n\n\"\"\n\nLOOPS = 50000\n\nfrom time import clock\n\n__version__ = \"1.1\"\n\n[Ident1, Ident2, Ident3, Ident4, Ident5] = range(1, 6)\n\nclass Record:\n\n def __init__(self, PtrComp = None, Discr = 0, EnumComp = 0,\n IntComp = 0, StringComp = 0):\n  self.PtrComp = PtrComp\n  self.Discr = Discr\n  self.EnumComp = EnumComp\n  self.IntComp = IntComp\n  self.StringComp = StringComp\n  \n def copy(self):\n  return Record(self.PtrComp, self.Discr, self.EnumComp,\n  self.IntComp, self.StringComp)\n  \nTRUE = 1\nFALSE = 0\n\ndef main(loops=LOOPS):\n benchtime, stones = pystones(loops)\n print(\"Pystone(%s) time for %d passes = %g\" % (__version__, loops, benchtime))\n print(\"This machine benchmarks at %g pystones/second\" % stones)\n \n \ndef pystones(loops=LOOPS):\n return Proc0(loops)\n \nIntGlob = 0\nBoolGlob = FALSE\nChar1Glob = '\\0'\nChar2Glob = '\\0'\nArray1Glob = [0]*51\nArray2Glob = [x[:] for x in [Array1Glob]*51]\nPtrGlb = None\nPtrGlbNext = None\n\ndef Proc0(loops=LOOPS):\n global IntGlob\n global BoolGlob\n global Char1Glob\n global Char2Glob\n global Array1Glob\n global Array2Glob\n global PtrGlb\n global PtrGlbNext\n \n starttime = clock()\n for i in range(loops):\n  pass\n nulltime = clock() - starttime\n \n PtrGlbNext = Record()\n PtrGlb = Record()\n PtrGlb.PtrComp = PtrGlbNext\n PtrGlb.Discr = Ident1\n PtrGlb.EnumComp = Ident3\n PtrGlb.IntComp = 40\n PtrGlb.StringComp = \"DHRYSTONE PROGRAM, SOME STRING\"\n String1Loc = \"DHRYSTONE PROGRAM, 1'ST STRING\"\n Array2Glob[8][7] = 10\n \n starttime = clock()\n \n for i in range(loops):\n  Proc5()\n  Proc4()\n  IntLoc1 = 2\n  IntLoc2 = 3\n  String2Loc = \"DHRYSTONE PROGRAM, 2'ND STRING\"\n  EnumLoc = Ident2\n  BoolGlob = not Func2(String1Loc, String2Loc)\n  while IntLoc1 < IntLoc2:\n   IntLoc3 = 5 * IntLoc1 - IntLoc2\n   IntLoc3 = Proc7(IntLoc1, IntLoc2)\n   IntLoc1 = IntLoc1 + 1\n  Proc8(Array1Glob, Array2Glob, IntLoc1, IntLoc3)\n  PtrGlb = Proc1(PtrGlb)\n  CharIndex = 'A'\n  while CharIndex <= Char2Glob:\n   if EnumLoc == Func1(CharIndex, 'C'):\n    EnumLoc = Proc6(Ident1)\n   CharIndex = chr(ord(CharIndex)+1)\n  IntLoc3 = IntLoc2 * IntLoc1\n  IntLoc2 = IntLoc3 / IntLoc1\n  IntLoc2 = 7 * (IntLoc3 - IntLoc2) - IntLoc1\n  IntLoc1 = Proc2(IntLoc1)\n  \n benchtime = clock() - starttime - nulltime\n if benchtime == 0.0:\n  loopsPerBenchtime = 0.0\n else:\n  loopsPerBenchtime = (loops / benchtime)\n return benchtime, loopsPerBenchtime\n \ndef Proc1(PtrParIn):\n PtrParIn.PtrComp = NextRecord = PtrGlb.copy()\n PtrParIn.IntComp = 5\n NextRecord.IntComp = PtrParIn.IntComp\n NextRecord.PtrComp = PtrParIn.PtrComp\n NextRecord.PtrComp = Proc3(NextRecord.PtrComp)\n if NextRecord.Discr == Ident1:\n  NextRecord.IntComp = 6\n  NextRecord.EnumComp = Proc6(PtrParIn.EnumComp)\n  NextRecord.PtrComp = PtrGlb.PtrComp\n  NextRecord.IntComp = Proc7(NextRecord.IntComp, 10)\n else:\n  PtrParIn = NextRecord.copy()\n NextRecord.PtrComp = None\n return PtrParIn\n \ndef Proc2(IntParIO):\n IntLoc = IntParIO + 10\n while 1:\n  if Char1Glob == 'A':\n   IntLoc = IntLoc - 1\n   IntParIO = IntLoc - IntGlob\n   EnumLoc = Ident1\n  if EnumLoc == Ident1:\n   break\n return IntParIO\n \ndef Proc3(PtrParOut):\n global IntGlob\n \n if PtrGlb is not None:\n  PtrParOut = PtrGlb.PtrComp\n else:\n  IntGlob = 100\n PtrGlb.IntComp = Proc7(10, IntGlob)\n return PtrParOut\n \ndef Proc4():\n global Char2Glob\n \n BoolLoc = Char1Glob == 'A'\n BoolLoc = BoolLoc or BoolGlob\n Char2Glob = 'B'\n \ndef Proc5():\n global Char1Glob\n global BoolGlob\n \n Char1Glob = 'A'\n BoolGlob = FALSE\n \ndef Proc6(EnumParIn):\n EnumParOut = EnumParIn\n if not Func3(EnumParIn):\n  EnumParOut = Ident4\n if EnumParIn == Ident1:\n  EnumParOut = Ident1\n elif EnumParIn == Ident2:\n  if IntGlob > 100:\n   EnumParOut = Ident1\n  else:\n   EnumParOut = Ident4\n elif EnumParIn == Ident3:\n  EnumParOut = Ident2\n elif EnumParIn == Ident4:\n  pass\n elif EnumParIn == Ident5:\n  EnumParOut = Ident3\n return EnumParOut\n \ndef Proc7(IntParI1, IntParI2):\n IntLoc = IntParI1 + 2\n IntParOut = IntParI2 + IntLoc\n return IntParOut\n \ndef Proc8(Array1Par, Array2Par, IntParI1, IntParI2):\n global IntGlob\n \n IntLoc = IntParI1 + 5\n Array1Par[IntLoc] = IntParI2\n Array1Par[IntLoc+1] = Array1Par[IntLoc]\n Array1Par[IntLoc+30] = IntLoc\n for IntIndex in range(IntLoc, IntLoc+2):\n  Array2Par[IntLoc][IntIndex] = IntLoc\n Array2Par[IntLoc][IntLoc-1] = Array2Par[IntLoc][IntLoc-1] + 1\n Array2Par[IntLoc+20][IntLoc] = Array1Par[IntLoc]\n IntGlob = 5\n \ndef Func1(CharPar1, CharPar2):\n CharLoc1 = CharPar1\n CharLoc2 = CharLoc1\n if CharLoc2 != CharPar2:\n  return Ident1\n else:\n  return Ident2\n  \ndef Func2(StrParI1, StrParI2):\n IntLoc = 1\n while IntLoc <= 1:\n  if Func1(StrParI1[IntLoc], StrParI2[IntLoc+1]) == Ident1:\n   CharLoc = 'A'\n   IntLoc = IntLoc + 1\n if CharLoc >= 'W' and CharLoc <= 'Z':\n  IntLoc = 7\n if CharLoc == 'X':\n  return TRUE\n else:\n  if StrParI1 > StrParI2:\n   IntLoc = IntLoc + 7\n   return TRUE\n  else:\n   return FALSE\n   \ndef Func3(EnumParIn):\n EnumLoc = EnumParIn\n if EnumLoc == Ident3: return TRUE\n return FALSE\n \nif __name__ == '__main__':\n import sys\n def error(msg):\n  print(msg, end=' ', file=sys.stderr)\n  print(\"usage: %s [number_of_loops]\" % sys.argv[0], file=sys.stderr)\n  sys.exit(100)\n nargs = len(sys.argv) - 1\n if nargs > 1:\n  error(\"%d arguments are too many;\" % nargs)\n elif nargs == 1:\n  try: loops = int(sys.argv[1])\n  except ValueError:\n   error(\"Invalid argument %r;\" % sys.argv[1])\n else:\n  loops = LOOPS\n main(loops)\n"], "xml": [".py", "\"\"\n\n\n__all__ = [\"dom\", \"parsers\", \"sax\", \"etree\"]\n", 1], "_testcapi": [".py", "\nCHAR_MAX = 127\n\nCHAR_MIN = -128\n\nDBL_MAX = 1.7976931348623157e+308\n\nDBL_MIN = 2.2250738585072014e-308\n\nFLT_MAX = 3.4028234663852886e+38\n\nFLT_MIN = 1.1754943508222875e-38\n\nINT_MAX = 2147483647\n\nINT_MIN = -2147483648\n\nLLONG_MAX = 9223372036854775807\n\nLLONG_MIN = -9223372036854775808\n\nLONG_MAX = 2147483647\n\nLONG_MIN = -2147483648\n\nPY_SSIZE_T_MAX = 2147483647\n\nPY_SSIZE_T_MIN = -2147483648\n\nSHRT_MAX = 32767\n\nSHRT_MIN = -32768\n\nSIZEOF_PYGC_HEAD = 16\n\nUCHAR_MAX = 255\n\nUINT_MAX = 4294967295\n\nULLONG_MAX = 18446744073709551615\n\nULONG_MAX = 4294967295\n\nUSHRT_MAX = 65535\n\n__loader__ = \"<_frozen_importlib.ExtensionFileLoader object at 0x00C98DD0>\"\n\ndef _pending_threadfunc(*args,**kw):\n pass\n \nclass _test_structmembersType(object):\n pass\n \ndef _test_thread_state(*args,**kw):\n pass\n \ndef argparsing(*args,**kw):\n pass\n \ndef code_newempty(*args,**kw):\n pass\n \ndef codec_incrementaldecoder(*args,**kw):\n pass\n \ndef codec_incrementalencoder(*args,**kw):\n pass\n \ndef crash_no_current_thread(*args,**kw):\n pass\n \nclass error(Exception):\n pass\n \ndef exception_print(*args,**kw):\n pass\n \ndef getargs_B(*args,**kw):\n pass\n \ndef getargs_H(*args,**kw):\n pass\n \ndef getargs_I(*args,**kw):\n pass\n \ndef getargs_K(*args,**kw):\n pass\n \ndef getargs_L(*args,**kw):\n pass\n \ndef getargs_Z(*args,**kw):\n pass\n \ndef getargs_Z_hash(*args,**kw):\n pass\n \ndef getargs_b(*args,**kw):\n pass\n \ndef getargs_c(*args,**kw):\n pass\n \ndef getargs_h(*args,**kw):\n pass\n \ndef getargs_i(*args,**kw):\n pass\n \ndef getargs_k(*args,**kw):\n pass\n \ndef getargs_keyword_only(*args,**kw):\n pass\n \ndef getargs_keywords(*args,**kw):\n pass\n \ndef getargs_l(*args,**kw):\n pass\n \ndef getargs_n(*args,**kw):\n pass\n \ndef getargs_p(*args,**kw):\n pass\n \ndef getargs_s(*args,**kw):\n pass\n \ndef getargs_s_hash(*args,**kw):\n pass\n \ndef getargs_s_star(*args,**kw):\n pass\n \ndef getargs_tuple(*args,**kw):\n pass\n \ndef getargs_u(*args,**kw):\n pass\n \ndef getargs_u_hash(*args,**kw):\n pass\n \ndef getargs_w_star(*args,**kw):\n pass\n \ndef getargs_y(*args,**kw):\n pass\n \ndef getargs_y_hash(*args,**kw):\n pass\n \ndef getargs_y_star(*args,**kw):\n pass\n \ndef getargs_z(*args,**kw):\n pass\n \ndef getargs_z_hash(*args,**kw):\n pass\n \ndef getargs_z_star(*args,**kw):\n pass\n \nclass instancemethod(object):\n pass\n \ndef make_exception_with_doc(*args,**kw):\n pass\n \ndef make_memoryview_from_NULL_pointer(*args,**kw):\n pass\n \ndef parse_tuple_and_keywords(*args,**kw):\n pass\n \ndef pytime_object_to_time_t(*args,**kw):\n pass\n \ndef pytime_object_to_timespec(*args,**kw):\n pass\n \ndef pytime_object_to_timeval(*args,**kw):\n pass\n \ndef raise_exception(*args,**kw):\n pass\n \ndef raise_memoryerror(*args,**kw):\n pass\n \ndef run_in_subinterp(*args,**kw):\n pass\n \ndef set_exc_info(*args,**kw):\n pass\n \ndef test_L_code(*args,**kw):\n pass\n \ndef test_Z_code(*args,**kw):\n pass\n \ndef test_capsule(*args,**kw):\n pass\n \ndef test_config(*args,**kw):\n pass\n \ndef test_datetime_capi(*args,**kw):\n pass\n \ndef test_dict_iteration(*args,**kw):\n pass\n \ndef test_empty_argparse(*args,**kw):\n pass\n \ndef test_k_code(*args,**kw):\n pass\n \ndef test_lazy_hash_inheritance(*args,**kw):\n pass\n \ndef test_list_api(*args,**kw):\n pass\n \ndef test_long_and_overflow(*args,**kw):\n pass\n \ndef test_long_api(*args,**kw):\n pass\n \ndef test_long_as_double(*args,**kw):\n pass\n \ndef test_long_as_size_t(*args,**kw):\n pass\n \ndef test_long_long_and_overflow(*args,**kw):\n pass\n \ndef test_long_numbits(*args,**kw):\n pass\n \ndef test_longlong_api(*args,**kw):\n pass\n \ndef test_null_strings(*args,**kw):\n pass\n \ndef test_s_code(*args,**kw):\n pass\n \ndef test_string_from_format(*args,**kw):\n pass\n \ndef test_string_to_double(*args,**kw):\n pass\n \ndef test_u_code(*args,**kw):\n pass\n \ndef test_unicode_compare_with_ascii(*args,**kw):\n pass\n \ndef test_widechar(*args,**kw):\n pass\n \ndef test_with_docstring(*args,**kw):\n \"\"\n pass\n \ndef traceback_print(*args,**kw):\n pass\n \ndef unicode_aswidechar(*args,**kw):\n pass\n \ndef unicode_aswidecharstring(*args,**kw):\n pass\n \ndef unicode_encodedecimal(*args,**kw):\n pass\n \ndef unicode_transformdecimaltoascii(*args,**kw):\n pass\n"], "codecs": [".py", "\"\"\n\nimport builtins, sys\n\n\n\ntry:\n from _codecs import *\nexcept ImportError as why:\n raise SystemError('Failed to load the builtin codecs: %s' % why)\n \n__all__ = [\"register\", \"lookup\", \"open\", \"EncodedFile\", \"BOM\", \"BOM_BE\",\n\"BOM_LE\", \"BOM32_BE\", \"BOM32_LE\", \"BOM64_BE\", \"BOM64_LE\",\n\"BOM_UTF8\", \"BOM_UTF16\", \"BOM_UTF16_LE\", \"BOM_UTF16_BE\",\n\"BOM_UTF32\", \"BOM_UTF32_LE\", \"BOM_UTF32_BE\",\n\"strict_errors\", \"ignore_errors\", \"replace_errors\",\n\"xmlcharrefreplace_errors\",\n\"register_error\", \"lookup_error\"]\n\n\n\n\n\n\n\n\n\n\nBOM_UTF8 = b'\\xef\\xbb\\xbf'\n\n\nBOM_LE = BOM_UTF16_LE = b'\\xff\\xfe'\n\n\nBOM_BE = BOM_UTF16_BE = b'\\xfe\\xff'\n\n\nBOM_UTF32_LE = b'\\xff\\xfe\\x00\\x00'\n\n\nBOM_UTF32_BE = b'\\x00\\x00\\xfe\\xff'\n\nif sys.byteorder == 'little':\n\n\n BOM = BOM_UTF16 = BOM_UTF16_LE\n \n \n BOM_UTF32 = BOM_UTF32_LE\n \nelse:\n\n\n BOM = BOM_UTF16 = BOM_UTF16_BE\n \n \n BOM_UTF32 = BOM_UTF32_BE\n \n \nBOM32_LE = BOM_UTF16_LE\nBOM32_BE = BOM_UTF16_BE\nBOM64_LE = BOM_UTF32_LE\nBOM64_BE = BOM_UTF32_BE\n\n\n\n\nclass CodecInfo(tuple):\n\n def __new__(cls, encode, decode, streamreader=None, streamwriter=None,\n incrementalencoder=None, incrementaldecoder=None, name=None):\n  self = tuple.__new__(cls, (encode, decode, streamreader, streamwriter))\n  self.name = name\n  self.encode = encode\n  self.decode = decode\n  self.incrementalencoder = incrementalencoder\n  self.incrementaldecoder = incrementaldecoder\n  self.streamwriter = streamwriter\n  self.streamreader = streamreader\n  return self\n  \n def __repr__(self):\n  return \"<%s.%s object for encoding %s at 0x%x>\" % (self.__class__.__module__, self.__class__.__name__,\n  self.name, id(self))\n  \nclass Codec:\n\n \"\"\n def encode(self, input, errors='strict'):\n \n  \"\"\n  raise NotImplementedError\n  \n def decode(self, input, errors='strict'):\n \n  \"\"\n  raise NotImplementedError\n  \nclass IncrementalEncoder(object):\n \"\"\n def __init__(self, errors='strict'):\n  \"\"\n  self.errors = errors\n  self.buffer = \"\"\n  \n def encode(self, input, final=False):\n  \"\"\n  raise NotImplementedError\n  \n def reset(self):\n  \"\"\n  \n def getstate(self):\n  \"\"\n  return 0\n  \n def setstate(self, state):\n  \"\"\n  \nclass BufferedIncrementalEncoder(IncrementalEncoder):\n \"\"\n def __init__(self, errors='strict'):\n  IncrementalEncoder.__init__(self, errors)\n  \n  self.buffer = \"\"\n  \n def _buffer_encode(self, input, errors, final):\n \n \n  raise NotImplementedError\n  \n def encode(self, input, final=False):\n \n  data = self.buffer + input\n  (result, consumed) = self._buffer_encode(data, self.errors, final)\n  \n  self.buffer = data[consumed:]\n  return result\n  \n def reset(self):\n  IncrementalEncoder.reset(self)\n  self.buffer = \"\"\n  \n def getstate(self):\n  return self.buffer or 0\n  \n def setstate(self, state):\n  self.buffer = state or \"\"\n  \nclass IncrementalDecoder(object):\n \"\"\n def __init__(self, errors='strict'):\n  \"\"\n  self.errors = errors\n  \n def decode(self, input, final=False):\n  \"\"\n  raise NotImplementedError\n  \n def reset(self):\n  \"\"\n  \n def getstate(self):\n  \"\"\n  return (b\"\", 0)\n  \n def setstate(self, state):\n  \"\"\n  \nclass BufferedIncrementalDecoder(IncrementalDecoder):\n \"\"\n def __init__(self, errors='strict'):\n  IncrementalDecoder.__init__(self, errors)\n  \n  self.buffer = b\"\"\n  \n def _buffer_decode(self, input, errors, final):\n \n \n  raise NotImplementedError\n  \n def decode(self, input, final=False):\n \n  data = self.buffer + input\n  (result, consumed) = self._buffer_decode(data, self.errors, final)\n  \n  self.buffer = data[consumed:]\n  return result\n  \n def reset(self):\n  IncrementalDecoder.reset(self)\n  self.buffer = b\"\"\n  \n def getstate(self):\n \n  return (self.buffer, 0)\n  \n def setstate(self, state):\n \n  self.buffer = state[0]\n  \n  \n  \n  \n  \n  \n  \n  \nclass StreamWriter(Codec):\n\n def __init__(self, stream, errors='strict'):\n \n  \"\"\n  self.stream = stream\n  self.errors = errors\n  \n def write(self, object):\n \n  \"\"\n  data, consumed = self.encode(object, self.errors)\n  self.stream.write(data)\n  \n def writelines(self, list):\n \n  \"\"\n  self.write(''.join(list))\n  \n def reset(self):\n \n  \"\"\n  pass\n  \n def seek(self, offset, whence=0):\n  self.stream.seek(offset, whence)\n  if whence == 0 and offset == 0:\n   self.reset()\n   \n def __getattr__(self, name,\n getattr=getattr):\n \n  \"\"\n  return getattr(self.stream, name)\n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, type, value, tb):\n  self.stream.close()\n  \n  \n  \nclass StreamReader(Codec):\n\n charbuffertype = str\n \n def __init__(self, stream, errors='strict'):\n \n  \"\"\n  self.stream = stream\n  self.errors = errors\n  self.bytebuffer = b\"\"\n  self._empty_charbuffer = self.charbuffertype()\n  self.charbuffer = self._empty_charbuffer\n  self.linebuffer = None\n  \n def decode(self, input, errors='strict'):\n  raise NotImplementedError\n  \n def read(self, size=-1, chars=-1, firstline=False):\n \n  \"\"\n  \n  if self.linebuffer:\n   self.charbuffer = self._empty_charbuffer.join(self.linebuffer)\n   self.linebuffer = None\n   \n   \n  while True:\n  \n   if chars < 0:\n    if size < 0:\n     if self.charbuffer:\n      break\n    elif len(self.charbuffer) >= size:\n     break\n   else:\n    if len(self.charbuffer) >= chars:\n     break\n     \n   if size < 0:\n    newdata = self.stream.read()\n   else:\n    newdata = self.stream.read(size)\n    \n   data = self.bytebuffer + newdata\n   try:\n    newchars, decodedbytes = self.decode(data, self.errors)\n   except UnicodeDecodeError as exc:\n    if firstline:\n     newchars, decodedbytes = self.decode(data[:exc.start], self.errors)\n     lines = newchars.splitlines(keepends=True)\n     if len(lines)<=1:\n      raise\n    else:\n     raise\n     \n   self.bytebuffer = data[decodedbytes:]\n   \n   self.charbuffer += newchars\n   \n   if not newdata:\n    break\n  if chars < 0:\n  \n   result = self.charbuffer\n   self.charbuffer = self._empty_charbuffer\n  else:\n  \n   result = self.charbuffer[:chars]\n   self.charbuffer = self.charbuffer[chars:]\n  return result\n  \n def readline(self, size=None, keepends=True):\n \n  \"\"\n  \n  \n  if self.linebuffer:\n   line = self.linebuffer[0]\n   del self.linebuffer[0]\n   if len(self.linebuffer) == 1:\n   \n   \n    self.charbuffer = self.linebuffer[0]\n    self.linebuffer = None\n   if not keepends:\n    line = line.splitlines(keepends=False)[0]\n   return line\n   \n  readsize = size or 72\n  line = self._empty_charbuffer\n  \n  while True:\n   data = self.read(readsize, firstline=True)\n   if data:\n   \n   \n   \n    if (isinstance(data, str) and data.endswith(\"\\r\")) or (isinstance(data, bytes) and data.endswith(b\"\\r\")):\n     data += self.read(size=1, chars=1)\n     \n   line += data\n   lines = line.splitlines(keepends=True)\n   if lines:\n    if len(lines) > 1:\n    \n    \n     line = lines[0]\n     del lines[0]\n     if len(lines) > 1:\n     \n      lines[-1] += self.charbuffer\n      self.linebuffer = lines\n      self.charbuffer = None\n     else:\n     \n      self.charbuffer = lines[0] + self.charbuffer\n     if not keepends:\n      line = line.splitlines(keepends=False)[0]\n     break\n    line0withend = lines[0]\n    line0withoutend = lines[0].splitlines(keepends=False)[0]\n    if line0withend != line0withoutend: \n    \n     self.charbuffer = self._empty_charbuffer.join(lines[1:]) + self.charbuffer\n     if keepends:\n      line = line0withend\n     else:\n      line = line0withoutend\n     break\n     \n   if not data or size is not None:\n    if line and not keepends:\n     line = line.splitlines(keepends=False)[0]\n    break\n   if readsize < 8000:\n    readsize *= 2\n  return line\n  \n def readlines(self, sizehint=None, keepends=True):\n \n  \"\"\n  data = self.read()\n  return data.splitlines(keepends)\n  \n def reset(self):\n \n  \"\"\n  self.bytebuffer = b\"\"\n  self.charbuffer = self._empty_charbuffer\n  self.linebuffer = None\n  \n def seek(self, offset, whence=0):\n  \"\"\n  self.stream.seek(offset, whence)\n  self.reset()\n  \n def __next__(self):\n \n  \"\"\n  line = self.readline()\n  if line:\n   return line\n  raise StopIteration\n  \n def __iter__(self):\n  return self\n  \n def __getattr__(self, name,\n getattr=getattr):\n \n  \"\"\n  return getattr(self.stream, name)\n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, type, value, tb):\n  self.stream.close()\n  \n  \n  \nclass StreamReaderWriter:\n\n \"\"\n \n encoding = 'unknown'\n \n def __init__(self, stream, Reader, Writer, errors='strict'):\n \n  \"\"\n  self.stream = stream\n  self.reader = Reader(stream, errors)\n  self.writer = Writer(stream, errors)\n  self.errors = errors\n  \n def read(self, size=-1):\n \n  return self.reader.read(size)\n  \n def readline(self, size=None):\n \n  return self.reader.readline(size)\n  \n def readlines(self, sizehint=None):\n \n  return self.reader.readlines(sizehint)\n  \n def __next__(self):\n \n  \"\"\n  return next(self.reader)\n  \n def __iter__(self):\n  return self\n  \n def write(self, data):\n \n  return self.writer.write(data)\n  \n def writelines(self, list):\n \n  return self.writer.writelines(list)\n  \n def reset(self):\n \n  self.reader.reset()\n  self.writer.reset()\n  \n def seek(self, offset, whence=0):\n  self.stream.seek(offset, whence)\n  self.reader.reset()\n  if whence == 0 and offset == 0:\n   self.writer.reset()\n   \n def __getattr__(self, name,\n getattr=getattr):\n \n  \"\"\n  return getattr(self.stream, name)\n  \n  \n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, type, value, tb):\n  self.stream.close()\n  \n  \n  \nclass StreamRecoder:\n\n \"\"\n \n data_encoding = 'unknown'\n file_encoding = 'unknown'\n \n def __init__(self, stream, encode, decode, Reader, Writer,\n errors='strict'):\n \n  \"\"\n  self.stream = stream\n  self.encode = encode\n  self.decode = decode\n  self.reader = Reader(stream, errors)\n  self.writer = Writer(stream, errors)\n  self.errors = errors\n  \n def read(self, size=-1):\n \n  data = self.reader.read(size)\n  data, bytesencoded = self.encode(data, self.errors)\n  return data\n  \n def readline(self, size=None):\n \n  if size is None:\n   data = self.reader.readline()\n  else:\n   data = self.reader.readline(size)\n  data, bytesencoded = self.encode(data, self.errors)\n  return data\n  \n def readlines(self, sizehint=None):\n \n  data = self.reader.read()\n  data, bytesencoded = self.encode(data, self.errors)\n  return data.splitlines(keepends=True)\n  \n def __next__(self):\n \n  \"\"\n  data = next(self.reader)\n  data, bytesencoded = self.encode(data, self.errors)\n  return data\n  \n def __iter__(self):\n  return self\n  \n def write(self, data):\n \n  data, bytesdecoded = self.decode(data, self.errors)\n  return self.writer.write(data)\n  \n def writelines(self, list):\n \n  data = ''.join(list)\n  data, bytesdecoded = self.decode(data, self.errors)\n  return self.writer.write(data)\n  \n def reset(self):\n \n  self.reader.reset()\n  self.writer.reset()\n  \n def __getattr__(self, name,\n getattr=getattr):\n \n  \"\"\n  return getattr(self.stream, name)\n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, type, value, tb):\n  self.stream.close()\n  \n  \n  \ndef open(filename, mode='rb', encoding=None, errors='strict', buffering=1):\n\n \"\"\n if encoding is not None and 'b' not in mode:\n \n  mode = mode + 'b'\n file = builtins.open(filename, mode, buffering)\n if encoding is None:\n  return file\n info = lookup(encoding)\n srw = StreamReaderWriter(file, info.streamreader, info.streamwriter, errors)\n \n srw.encoding = encoding\n return srw\n \ndef EncodedFile(file, data_encoding, file_encoding=None, errors='strict'):\n\n \"\"\n if file_encoding is None:\n  file_encoding = data_encoding\n data_info = lookup(data_encoding)\n file_info = lookup(file_encoding)\n sr = StreamRecoder(file, data_info.encode, data_info.decode,\n file_info.streamreader, file_info.streamwriter, errors)\n \n sr.data_encoding = data_encoding\n sr.file_encoding = file_encoding\n return sr\n \n \n \ndef getencoder(encoding):\n\n \"\"\n return lookup(encoding).encode\n \ndef getdecoder(encoding):\n\n \"\"\n return lookup(encoding).decode\n \ndef getincrementalencoder(encoding):\n\n \"\"\n encoder = lookup(encoding).incrementalencoder\n if encoder is None:\n  raise LookupError(encoding)\n return encoder\n \ndef getincrementaldecoder(encoding):\n\n \"\"\n decoder = lookup(encoding).incrementaldecoder\n if decoder is None:\n  raise LookupError(encoding)\n return decoder\n \ndef getreader(encoding):\n\n \"\"\n return lookup(encoding).streamreader\n \ndef getwriter(encoding):\n\n \"\"\n return lookup(encoding).streamwriter\n \ndef iterencode(iterator, encoding, errors='strict', **kwargs):\n \"\"\n encoder = getincrementalencoder(encoding)(errors, **kwargs)\n for input in iterator:\n  output = encoder.encode(input)\n  if output:\n   yield output\n output = encoder.encode(\"\", True)\n if output:\n  yield output\n  \ndef iterdecode(iterator, encoding, errors='strict', **kwargs):\n \"\"\n decoder = getincrementaldecoder(encoding)(errors, **kwargs)\n for input in iterator:\n  output = decoder.decode(input)\n  if output:\n   yield output\n output = decoder.decode(b\"\", True)\n if output:\n  yield output\n  \n  \n  \ndef make_identity_dict(rng):\n\n \"\"\n return {i:i for i in rng}\n \ndef make_encoding_map(decoding_map):\n\n \"\"\n m = {}\n for k,v in decoding_map.items():\n  if not v in m:\n   m[v] = k\n  else:\n   m[v] = None\n return m\n \n \n \ntry:\n strict_errors = lookup_error(\"strict\")\n ignore_errors = lookup_error(\"ignore\")\n replace_errors = lookup_error(\"replace\")\n xmlcharrefreplace_errors = lookup_error(\"xmlcharrefreplace\")\n backslashreplace_errors = lookup_error(\"backslashreplace\")\nexcept LookupError:\n\n strict_errors = None\n ignore_errors = None\n replace_errors = None\n xmlcharrefreplace_errors = None\n backslashreplace_errors = None\n \n \n \n_false = 0\nif _false:\n import encodings\n \n \n \nif __name__ == '__main__':\n\n\n sys.stdout = EncodedFile(sys.stdout, 'latin-1', 'utf-8')\n \n \n sys.stdin = EncodedFile(sys.stdin, 'utf-8', 'latin-1')\n"], "unittest.runner": [".py", "\"\"\n\nimport sys\nimport time\nimport warnings\n\nfrom . import result\nfrom .signals import registerResult\n\n__unittest = True\n\n\nclass _WritelnDecorator(object):\n \"\"\n def __init__(self,stream):\n  self.stream = stream\n  \n def __getattr__(self, attr):\n  if attr in ('stream', '__getstate__'):\n   raise AttributeError(attr)\n  return getattr(self.stream,attr)\n  \n def writeln(self, arg=None):\n  if arg:\n   self.write(arg)\n  self.write('\\n') \n  \n  \nclass TextTestResult(result.TestResult):\n \"\"\n separator1 = '=' * 70\n separator2 = '-' * 70\n \n def __init__(self, stream, descriptions, verbosity):\n  super(TextTestResult, self).__init__(stream, descriptions, verbosity)\n  self.stream = stream\n  self.showAll = verbosity > 1\n  self.dots = verbosity == 1\n  self.descriptions = descriptions\n  \n def getDescription(self, test):\n  doc_first_line = test.shortDescription()\n  if self.descriptions and doc_first_line:\n   return '\\n'.join((str(test), doc_first_line))\n  else:\n   return str(test)\n   \n def startTest(self, test):\n  super(TextTestResult, self).startTest(test)\n  if self.showAll:\n   self.stream.write(self.getDescription(test))\n   self.stream.write(\" ... \")\n   self.stream.flush()\n   \n def addSuccess(self, test):\n  super(TextTestResult, self).addSuccess(test)\n  if self.showAll:\n   self.stream.writeln(\"ok\")\n  elif self.dots:\n   self.stream.write('.')\n   self.stream.flush()\n   \n def addError(self, test, err):\n  super(TextTestResult, self).addError(test, err)\n  if self.showAll:\n   self.stream.writeln(\"ERROR\")\n  elif self.dots:\n   self.stream.write('E')\n   self.stream.flush()\n   \n def addFailure(self, test, err):\n  super(TextTestResult, self).addFailure(test, err)\n  if self.showAll:\n   self.stream.writeln(\"FAIL\")\n  elif self.dots:\n   self.stream.write('F')\n   self.stream.flush()\n   \n def addSkip(self, test, reason):\n  super(TextTestResult, self).addSkip(test, reason)\n  if self.showAll:\n   self.stream.writeln(\"skipped {0!r}\".format(reason))\n  elif self.dots:\n   self.stream.write(\"s\")\n   self.stream.flush()\n   \n def addExpectedFailure(self, test, err):\n  super(TextTestResult, self).addExpectedFailure(test, err)\n  if self.showAll:\n   self.stream.writeln(\"expected failure\")\n  elif self.dots:\n   self.stream.write(\"x\")\n   self.stream.flush()\n   \n def addUnexpectedSuccess(self, test):\n  super(TextTestResult, self).addUnexpectedSuccess(test)\n  if self.showAll:\n   self.stream.writeln(\"unexpected success\")\n  elif self.dots:\n   self.stream.write(\"u\")\n   self.stream.flush()\n   \n def printErrors(self):\n  if self.dots or self.showAll:\n   self.stream.writeln()\n  self.printErrorList('ERROR', self.errors)\n  self.printErrorList('FAIL', self.failures)\n  \n def printErrorList(self, flavour, errors):\n  for test, err in errors:\n   self.stream.writeln(self.separator1)\n   self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\n   self.stream.writeln(self.separator2)\n   self.stream.writeln(\"%s\" % err)\n   \n   \nclass TextTestRunner(object):\n \"\"\n resultclass = TextTestResult\n \n def __init__(self, stream=None, descriptions=True, verbosity=1,\n failfast=False, buffer=False, resultclass=None, warnings=None):\n  if stream is None:\n   stream = sys.stderr\n  self.stream = _WritelnDecorator(stream)\n  self.descriptions = descriptions\n  self.verbosity = verbosity\n  self.failfast = failfast\n  self.buffer = buffer\n  self.warnings = warnings\n  if resultclass is not None:\n   self.resultclass = resultclass\n   \n def _makeResult(self):\n  return self.resultclass(self.stream, self.descriptions, self.verbosity)\n  \n def run(self, test):\n  \"\"\n  result = self._makeResult()\n  registerResult(result)\n  result.failfast = self.failfast\n  result.buffer = self.buffer\n  with warnings.catch_warnings():\n  \n   if self.warnings:\n   \n    warnings.simplefilter(self.warnings)\n    \n    \n    \n    \n    \n    if self.warnings in ['default', 'always']:\n     warnings.filterwarnings('module',\n     category=DeprecationWarning,\n     message='Please use assert\\w+ instead.')\n   startTime = time.time()\n   startTestRun = getattr(result, 'startTestRun', None)\n   if startTestRun is not None:\n    startTestRun()\n   try:\n    test(result)\n   finally:\n    stopTestRun = getattr(result, 'stopTestRun', None)\n    if stopTestRun is not None:\n     stopTestRun()\n   stopTime = time.time()\n  timeTaken = stopTime - startTime\n  result.printErrors()\n  if hasattr(result, 'separator2'):\n   self.stream.writeln(result.separator2)\n  run = result.testsRun\n  self.stream.writeln(\"Ran %d test%s in %.3fs\" %\n  (run, run != 1 and \"s\" or \"\", timeTaken))\n  self.stream.writeln()\n  \n  expectedFails = unexpectedSuccesses = skipped = 0\n  try:\n   results = map(len, (result.expectedFailures,\n   result.unexpectedSuccesses,\n   result.skipped))\n  except AttributeError:\n   pass\n  else:\n   expectedFails, unexpectedSuccesses, skipped = results\n   \n  infos = []\n  if not result.wasSuccessful():\n   self.stream.write(\"FAILED\")\n   failed, errored = len(result.failures), len(result.errors)\n   if failed:\n    infos.append(\"failures=%d\" % failed)\n   if errored:\n    infos.append(\"errors=%d\" % errored)\n  else:\n   self.stream.write(\"OK\")\n  if skipped:\n   infos.append(\"skipped=%d\" % skipped)\n  if expectedFails:\n   infos.append(\"expected failures=%d\" % expectedFails)\n  if unexpectedSuccesses:\n   infos.append(\"unexpected successes=%d\" % unexpectedSuccesses)\n  if infos:\n   self.stream.writeln(\" (%s)\" % (\", \".join(infos),))\n  else:\n   self.stream.write(\"\\n\")\n  return result\n"], "unittest.signals": [".py", "import signal\nimport weakref\n\nfrom functools import wraps\n\n__unittest = True\n\n\nclass _InterruptHandler(object):\n def __init__(self, default_handler):\n  self.called = False\n  self.original_handler = default_handler\n  if isinstance(default_handler, int):\n   if default_handler == signal.SIG_DFL:\n   \n    default_handler = signal.default_int_handler\n   elif default_handler == signal.SIG_IGN:\n   \n   \n    def default_handler(unused_signum, unused_frame):\n     pass\n   else:\n    raise TypeError(\"expected SIGINT signal handler to be \"\n    \"signal.SIG_IGN, signal.SIG_DFL, or a \"\n    \"callable object\")\n  self.default_handler = default_handler\n  \n def __call__(self, signum, frame):\n  installed_handler = signal.getsignal(signal.SIGINT)\n  if installed_handler is not self:\n  \n  \n   self.default_handler(signum, frame)\n   \n  if self.called:\n   self.default_handler(signum, frame)\n  self.called = True\n  for result in _results.keys():\n   result.stop()\n   \n_results = weakref.WeakKeyDictionary()\ndef registerResult(result):\n _results[result] = 1\n \ndef removeResult(result):\n return bool(_results.pop(result, None))\n \n_interrupt_handler = None\ndef installHandler():\n global _interrupt_handler\n if _interrupt_handler is None:\n  default_handler = signal.getsignal(signal.SIGINT)\n  _interrupt_handler = _InterruptHandler(default_handler)\n  signal.signal(signal.SIGINT, _interrupt_handler)\n  \n  \ndef removeHandler(method=None):\n if method is not None:\n  @wraps(method)\n  def inner(*args, **kwargs):\n   initial = signal.getsignal(signal.SIGINT)\n   removeHandler()\n   try:\n    return method(*args, **kwargs)\n   finally:\n    signal.signal(signal.SIGINT, initial)\n  return inner\n  \n global _interrupt_handler\n if _interrupt_handler is not None:\n  signal.signal(signal.SIGINT, _interrupt_handler.original_handler)\n"], "browser.ajax": [".py", "from _ajax import *"], "http.cookies": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\n\n\n\n\nimport re\nimport string\n\n__all__ = [\"CookieError\", \"BaseCookie\", \"SimpleCookie\"]\n\n_nulljoin = ''.join\n_semispacejoin = '; '.join\n_spacejoin = ' '.join\n\n\n\n\nclass CookieError(Exception):\n pass\n \n \n \n \n \n \n \n \n \n \n \n \n \n_LegalChars = string.ascii_letters + string.digits + \"!#$%&'*+-.^_`|~:\"\n_Translator = {\n'\\000' : '\\\\000', '\\001' : '\\\\001', '\\002' : '\\\\002',\n'\\003' : '\\\\003', '\\004' : '\\\\004', '\\005' : '\\\\005',\n'\\006' : '\\\\006', '\\007' : '\\\\007', '\\010' : '\\\\010',\n'\\011' : '\\\\011', '\\012' : '\\\\012', '\\013' : '\\\\013',\n'\\014' : '\\\\014', '\\015' : '\\\\015', '\\016' : '\\\\016',\n'\\017' : '\\\\017', '\\020' : '\\\\020', '\\021' : '\\\\021',\n'\\022' : '\\\\022', '\\023' : '\\\\023', '\\024' : '\\\\024',\n'\\025' : '\\\\025', '\\026' : '\\\\026', '\\027' : '\\\\027',\n'\\030' : '\\\\030', '\\031' : '\\\\031', '\\032' : '\\\\032',\n'\\033' : '\\\\033', '\\034' : '\\\\034', '\\035' : '\\\\035',\n'\\036' : '\\\\036', '\\037' : '\\\\037',\n\n\n\n\n',' : '\\\\054', ';' : '\\\\073',\n\n'\"' : '\\\\\"', '\\\\' : '\\\\\\\\',\n\n'\\177' : '\\\\177', '\\200' : '\\\\200', '\\201' : '\\\\201',\n'\\202' : '\\\\202', '\\203' : '\\\\203', '\\204' : '\\\\204',\n'\\205' : '\\\\205', '\\206' : '\\\\206', '\\207' : '\\\\207',\n'\\210' : '\\\\210', '\\211' : '\\\\211', '\\212' : '\\\\212',\n'\\213' : '\\\\213', '\\214' : '\\\\214', '\\215' : '\\\\215',\n'\\216' : '\\\\216', '\\217' : '\\\\217', '\\220' : '\\\\220',\n'\\221' : '\\\\221', '\\222' : '\\\\222', '\\223' : '\\\\223',\n'\\224' : '\\\\224', '\\225' : '\\\\225', '\\226' : '\\\\226',\n'\\227' : '\\\\227', '\\230' : '\\\\230', '\\231' : '\\\\231',\n'\\232' : '\\\\232', '\\233' : '\\\\233', '\\234' : '\\\\234',\n'\\235' : '\\\\235', '\\236' : '\\\\236', '\\237' : '\\\\237',\n'\\240' : '\\\\240', '\\241' : '\\\\241', '\\242' : '\\\\242',\n'\\243' : '\\\\243', '\\244' : '\\\\244', '\\245' : '\\\\245',\n'\\246' : '\\\\246', '\\247' : '\\\\247', '\\250' : '\\\\250',\n'\\251' : '\\\\251', '\\252' : '\\\\252', '\\253' : '\\\\253',\n'\\254' : '\\\\254', '\\255' : '\\\\255', '\\256' : '\\\\256',\n'\\257' : '\\\\257', '\\260' : '\\\\260', '\\261' : '\\\\261',\n'\\262' : '\\\\262', '\\263' : '\\\\263', '\\264' : '\\\\264',\n'\\265' : '\\\\265', '\\266' : '\\\\266', '\\267' : '\\\\267',\n'\\270' : '\\\\270', '\\271' : '\\\\271', '\\272' : '\\\\272',\n'\\273' : '\\\\273', '\\274' : '\\\\274', '\\275' : '\\\\275',\n'\\276' : '\\\\276', '\\277' : '\\\\277', '\\300' : '\\\\300',\n'\\301' : '\\\\301', '\\302' : '\\\\302', '\\303' : '\\\\303',\n'\\304' : '\\\\304', '\\305' : '\\\\305', '\\306' : '\\\\306',\n'\\307' : '\\\\307', '\\310' : '\\\\310', '\\311' : '\\\\311',\n'\\312' : '\\\\312', '\\313' : '\\\\313', '\\314' : '\\\\314',\n'\\315' : '\\\\315', '\\316' : '\\\\316', '\\317' : '\\\\317',\n'\\320' : '\\\\320', '\\321' : '\\\\321', '\\322' : '\\\\322',\n'\\323' : '\\\\323', '\\324' : '\\\\324', '\\325' : '\\\\325',\n'\\326' : '\\\\326', '\\327' : '\\\\327', '\\330' : '\\\\330',\n'\\331' : '\\\\331', '\\332' : '\\\\332', '\\333' : '\\\\333',\n'\\334' : '\\\\334', '\\335' : '\\\\335', '\\336' : '\\\\336',\n'\\337' : '\\\\337', '\\340' : '\\\\340', '\\341' : '\\\\341',\n'\\342' : '\\\\342', '\\343' : '\\\\343', '\\344' : '\\\\344',\n'\\345' : '\\\\345', '\\346' : '\\\\346', '\\347' : '\\\\347',\n'\\350' : '\\\\350', '\\351' : '\\\\351', '\\352' : '\\\\352',\n'\\353' : '\\\\353', '\\354' : '\\\\354', '\\355' : '\\\\355',\n'\\356' : '\\\\356', '\\357' : '\\\\357', '\\360' : '\\\\360',\n'\\361' : '\\\\361', '\\362' : '\\\\362', '\\363' : '\\\\363',\n'\\364' : '\\\\364', '\\365' : '\\\\365', '\\366' : '\\\\366',\n'\\367' : '\\\\367', '\\370' : '\\\\370', '\\371' : '\\\\371',\n'\\372' : '\\\\372', '\\373' : '\\\\373', '\\374' : '\\\\374',\n'\\375' : '\\\\375', '\\376' : '\\\\376', '\\377' : '\\\\377'\n}\n\ndef _quote(str, LegalChars=_LegalChars):\n \"\"\n if all(c in LegalChars for c in str):\n  return str\n else:\n  return '\"' + _nulljoin(_Translator.get(s, s) for s in str) + '\"'\n  \n  \n_OctalPatt = re.compile(r\"\\\\[0-3][0-7][0-7]\")\n_QuotePatt = re.compile(r\"[\\\\].\")\n\ndef _unquote(str):\n\n\n if len(str) < 2:\n  return str\n if str[0] != '\"' or str[-1] != '\"':\n  return str\n  \n  \n  \n  \n  \n str = str[1:-1]\n \n \n \n \n \n i = 0\n n = len(str)\n res = []\n while 0 <= i < n:\n  o_match = _OctalPatt.search(str, i)\n  q_match = _QuotePatt.search(str, i)\n  if not o_match and not q_match: \n   res.append(str[i:])\n   break\n   \n  j = k = -1\n  if o_match:\n   j = o_match.start(0)\n  if q_match:\n   k = q_match.start(0)\n  if q_match and (not o_match or k < j): \n   res.append(str[i:k])\n   res.append(str[k+1])\n   i = k + 2\n  else: \n   res.append(str[i:j])\n   res.append(chr(int(str[j+1:j+4], 8)))\n   i = j + 4\n return _nulljoin(res)\n \n \n \n \n \n \n \n \n_weekdayname = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n\n_monthname = [None,\n'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n\ndef _getdate(future=0, weekdayname=_weekdayname, monthname=_monthname):\n from time import gmtime, time\n now = time()\n year, month, day, hh, mm, ss, wd, y, z = gmtime(now + future)\n return \"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % (weekdayname[wd], day, monthname[month], year, hh, mm, ss)\n \n \nclass Morsel(dict):\n \"\"\n \n \n \n \n \n \n \n \n \n \n \n \n \n _reserved = {\n \"expires\" : \"expires\",\n \"path\" : \"Path\",\n \"comment\" : \"Comment\",\n \"domain\" : \"Domain\",\n \"max-age\" : \"Max-Age\",\n \"secure\" : \"secure\",\n \"httponly\" : \"httponly\",\n \"version\" : \"Version\",\n }\n \n _flags = {'secure', 'httponly'}\n \n def __init__(self):\n \n  self.key = self.value = self.coded_value = None\n  \n  \n  for key in self._reserved:\n   dict.__setitem__(self, key, \"\")\n   \n def __setitem__(self, K, V):\n  K = K.lower()\n  if not K in self._reserved:\n   raise CookieError(\"Invalid Attribute %s\" % K)\n  dict.__setitem__(self, K, V)\n  \n def isReservedKey(self, K):\n  return K.lower() in self._reserved\n  \n def set(self, key, val, coded_val, LegalChars=_LegalChars):\n \n \n  if key.lower() in self._reserved:\n   raise CookieError(\"Attempt to set a reserved key: %s\" % key)\n  if any(c not in LegalChars for c in key):\n   raise CookieError(\"Illegal key value: %s\" % key)\n   \n   \n  self.key = key\n  self.value = val\n  self.coded_value = coded_val\n  \n def output(self, attrs=None, header=\"Set-Cookie:\"):\n  return \"%s %s\" % (header, self.OutputString(attrs))\n  \n __str__ = output\n \n def __repr__(self):\n  return '<%s: %s=%s>' % (self.__class__.__name__,\n  self.key, repr(self.value))\n  \n def js_output(self, attrs=None):\n \n  return \"\"\"\n        <script type=\"text/javascript\">\n        <!-- begin hiding\n        document.cookie = \\\"%s\\\";\n        // end hiding -->\n        </script>\n        \"\"\"  % (self.OutputString(attrs).replace('\"', r'\\\"'))\n  \n def OutputString(self, attrs=None):\n \n \n  result = []\n  append = result.append\n  \n  \n  append(\"%s=%s\" % (self.key, self.coded_value))\n  \n  \n  if attrs is None:\n   attrs = self._reserved\n  items = sorted(self.items())\n  for key, value in items:\n   if value == \"\":\n    continue\n   if key not in attrs:\n    continue\n   if key == \"expires\" and isinstance(value, int):\n    append(\"%s=%s\" % (self._reserved[key], _getdate(value)))\n   elif key == \"max-age\" and isinstance(value, int):\n    append(\"%s=%d\" % (self._reserved[key], value))\n   elif key == \"secure\":\n    append(str(self._reserved[key]))\n   elif key == \"httponly\":\n    append(str(self._reserved[key]))\n   else:\n    append(\"%s=%s\" % (self._reserved[key], value))\n    \n    \n  return _semispacejoin(result)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n_LegalCharsPatt = r\"[\\w\\d!#%&'~_`><@,:/\\$\\*\\+\\-\\.\\^\\|\\)\\(\\?\\}\\{\\=]\"\n_CookiePattern = re.compile(r\"\"\"\n    (?x)                           # This is a verbose pattern\n    (?P<key>                       # Start of group 'key'\n    \"\"\"+ _LegalCharsPatt + r\"\"\"+?   # Any word of at least one letter\n    )                              # End of group 'key'\n    (                              # Optional group: there may not be a value.\n    \\s*=\\s*                          # Equal Sign\n    (?P<val>                         # Start of group 'val'\n    \"(?:[^\\\\\"]|\\\\.)*\"                  # Any doublequoted string\n    |                                  # or\n    \\w{3},\\s[\\w\\d\\s-]{9,11}\\s[\\d:]{8}\\sGMT  # Special case for \"expires\" attr\n    |                                  # or\n    \"\"\"+ _LegalCharsPatt + r\"\"\"*      # Any word or empty string\n    )                                # End of group 'val'\n    )?                             # End of optional value group\n    \\s*                            # Any number of spaces.\n    (\\s+|;|$)                      # Ending either at space, semicolon, or EOS.\n    \"\"\", re.ASCII) \n\n\n\n\n\nclass BaseCookie(dict):\n \"\"\n \n def value_decode(self, val):\n  \"\"\n  return val, val\n  \n def value_encode(self, val):\n  \"\"\n  strval = str(val)\n  return strval, strval\n  \n def __init__(self, input=None):\n  if input:\n   self.load(input)\n   \n def __set(self, key, real_value, coded_value):\n  \"\"\n  M = self.get(key, Morsel())\n  M.set(key, real_value, coded_value)\n  dict.__setitem__(self, key, M)\n  \n def __setitem__(self, key, value):\n  \"\"\n  rval, cval = self.value_encode(value)\n  self.__set(key, rval, cval)\n  \n def output(self, attrs=None, header=\"Set-Cookie:\", sep=\"\\015\\012\"):\n  \"\"\n  result = []\n  items = sorted(self.items())\n  for key, value in items:\n   result.append(value.output(attrs, header))\n  return sep.join(result)\n  \n __str__ = output\n \n def __repr__(self):\n  l = []\n  items = sorted(self.items())\n  for key, value in items:\n   l.append('%s=%s' % (key, repr(value.value)))\n  return '<%s: %s>' % (self.__class__.__name__, _spacejoin(l))\n  \n def js_output(self, attrs=None):\n  \"\"\n  result = []\n  items = sorted(self.items())\n  for key, value in items:\n   result.append(value.js_output(attrs))\n  return _nulljoin(result)\n  \n def load(self, rawdata):\n  \"\"\n  if isinstance(rawdata, str):\n   self.__parse_string(rawdata)\n  else:\n  \n   for key, value in rawdata.items():\n    self[key] = value\n  return\n  \n def __parse_string(self, str, patt=_CookiePattern):\n  i = 0 \n  n = len(str) \n  M = None \n  \n  while 0 <= i < n:\n  \n   match = patt.search(str, i)\n   if not match:\n   \n    break\n    \n   key, value = match.group(\"key\"), match.group(\"val\")\n   i = match.end(0)\n   \n   \n   if key[0] == \"$\":\n   \n   \n   \n    if M:\n     M[key[1:]] = value\n   elif key.lower() in Morsel._reserved:\n    if M:\n     if value is None:\n      if key.lower() in Morsel._flags:\n       M[key] = True\n     else:\n      M[key] = _unquote(value)\n   elif value is not None:\n    rval, cval = self.value_decode(value)\n    self.__set(key, rval, cval)\n    M = self[key]\n    \n    \nclass SimpleCookie(BaseCookie):\n \"\"\n def value_decode(self, val):\n  return _unquote(val), val\n  \n def value_encode(self, val):\n  strval = str(val)\n  return strval, _quote(strval)\n"], "importlib": [".py", "\"\"\n__all__ = ['__import__', 'import_module', 'invalidate_caches']\n\n\n\n\n\n\n\n\n\nimport _imp \nimport sys\n\nfrom . import machinery \n\ntry:\n import _frozen_importlib as _bootstrap\nexcept ImportError:\n from . import _bootstrap\n _bootstrap._setup(sys, _imp)\nelse:\n\n\n _bootstrap.__name__ = 'importlib._bootstrap'\n _bootstrap.__package__ = 'importlib'\n _bootstrap.__file__ = __file__.replace('__init__.py', '_bootstrap.py')\n sys.modules['importlib._bootstrap'] = _bootstrap\n \n \n_w_long = _bootstrap._w_long\n_r_long = _bootstrap._r_long\n\n\n\n\n\n\nfrom ._bootstrap import __import__\n\n\ndef invalidate_caches():\n \"\"\n for finder in sys.meta_path:\n  if hasattr(finder, 'invalidate_caches'):\n   finder.invalidate_caches()\n   \n   \ndef find_loader(name, path=None):\n \"\"\n try:\n  loader = sys.modules[name].__loader__\n  if loader is None:\n   raise ValueError('{}.__loader__ is None'.format(name))\n  else:\n   return loader\n except KeyError:\n  pass\n return _bootstrap._find_module(name, path)\n \n \ndef import_module(name, package=None):\n \"\"\n level = 0\n if name.startswith('.'):\n  if not package:\n   raise TypeError(\"relative imports require the 'package' argument\")\n  for character in name:\n   if character != '.':\n    break\n   level += 1\n return _bootstrap._gcd_import(name[level:], package, level)\n", 1], "_functools": [".py", "def partial(func, *args, **keywords):\n def newfunc(*fargs, **fkeywords):\n  newkeywords = keywords.copy()\n  newkeywords.update(fkeywords)\n  return func(*(args + fargs), **newkeywords)\n newfunc.func = func\n newfunc.args = args\n newfunc.keywords = keywords\n return newfunc\n \ndef reduce(func,iterable,initializer=None):\n args = iter(iterable)\n if initializer is not None:\n  res = initializer\n else:\n  res = next(args)\n while True:\n  try:\n   res = func(res,next(args))\n  except StopIteration:\n   return res\n"], "logging": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\n\nimport sys, os, time, io, traceback, warnings, weakref\nfrom string import Template\n\n__all__ = ['BASIC_FORMAT', 'BufferingFormatter', 'CRITICAL', 'DEBUG', 'ERROR',\n'FATAL', 'FileHandler', 'Filter', 'Formatter', 'Handler', 'INFO',\n'LogRecord', 'Logger', 'LoggerAdapter', 'NOTSET', 'NullHandler',\n'StreamHandler', 'WARN', 'WARNING', 'addLevelName', 'basicConfig',\n'captureWarnings', 'critical', 'debug', 'disable', 'error',\n'exception', 'fatal', 'getLevelName', 'getLogger', 'getLoggerClass',\n'info', 'log', 'makeLogRecord', 'setLoggerClass', 'warn', 'warning',\n'getLogRecordFactory', 'setLogRecordFactory', 'lastResort']\n\ntry:\n import threading\nexcept ImportError: \n threading = None\n \n__author__ = \"Vinay Sajip <vinay_sajip@red-dove.com>\"\n__status__ = \"production\"\n__version__ = \"0.5.1.2\"\n__date__ = \"07 February 2010\"\n\n\n\n\n\n\n\n\n\nif hasattr(sys, 'frozen'): \n _srcfile = \"logging%s__init__%s\" % (os.sep, __file__[-4:])\nelse:\n _srcfile = __file__\n_srcfile = os.path.normcase(_srcfile)\n\n\nif hasattr(sys, '_getframe'):\n currentframe = lambda: sys._getframe(3)\nelse: \n def currentframe():\n  \"\"\n  try:\n   raise Exception\n  except:\n   return sys.exc_info()[2].tb_frame.f_back\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n_startTime = time.time()\n\n\n\n\n\nraiseExceptions = True\n\n\n\n\nlogThreads = True\n\n\n\n\nlogMultiprocessing = True\n\n\n\n\nlogProcesses = True\n\n\n\n\n\n\n\n\n\n\n\n\nCRITICAL = 50\nFATAL = CRITICAL\nERROR = 40\nWARNING = 30\nWARN = WARNING\nINFO = 20\nDEBUG = 10\nNOTSET = 0\n\n_levelNames = {\nCRITICAL : 'CRITICAL',\nERROR : 'ERROR',\nWARNING : 'WARNING',\nINFO : 'INFO',\nDEBUG : 'DEBUG',\nNOTSET : 'NOTSET',\n'CRITICAL' : CRITICAL,\n'ERROR' : ERROR,\n'WARN' : WARNING,\n'WARNING' : WARNING,\n'INFO' : INFO,\n'DEBUG' : DEBUG,\n'NOTSET' : NOTSET,\n}\n\ndef getLevelName(level):\n \"\"\n return _levelNames.get(level, (\"Level %s\" % level))\n \ndef addLevelName(level, levelName):\n \"\"\n _acquireLock()\n try: \n  _levelNames[level] = levelName\n  _levelNames[levelName] = level\n finally:\n  _releaseLock()\n  \ndef _checkLevel(level):\n if isinstance(level, int):\n  rv = level\n elif str(level) == level:\n  if level not in _levelNames:\n   raise ValueError(\"Unknown level: %r\" % level)\n  rv = _levelNames[level]\n else:\n  raise TypeError(\"Level not an integer or a valid string: %r\" % level)\n return rv\n \n \n \n \n \n \n \n \n \n \n \n \n \nif threading:\n _lock = threading.RLock()\nelse: \n _lock = None\n \n \ndef _acquireLock():\n \"\"\n if _lock:\n  _lock.acquire()\n  \ndef _releaseLock():\n \"\"\n if _lock:\n  _lock.release()\n  \n  \n  \n  \n  \nclass LogRecord(object):\n \"\"\n def __init__(self, name, level, pathname, lineno,\n msg, args, exc_info, func=None, sinfo=None, **kwargs):\n  \"\"\n  ct = time.time()\n  self.name = name\n  self.msg = msg\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  if args and len(args) == 1 and isinstance(args[0], dict) and args[0]:\n   args = args[0]\n  self.args = args\n  self.levelname = getLevelName(level)\n  self.levelno = level\n  self.pathname = pathname\n  try:\n   self.filename = os.path.basename(pathname)\n   self.module = os.path.splitext(self.filename)[0]\n  except (TypeError, ValueError, AttributeError):\n   self.filename = pathname\n   self.module = \"Unknown module\"\n  self.exc_info = exc_info\n  self.exc_text = None \n  self.stack_info = sinfo\n  self.lineno = lineno\n  self.funcName = func\n  self.created = ct\n  self.msecs = (ct - int(ct)) * 1000\n  self.relativeCreated = (self.created - _startTime) * 1000\n  if logThreads and threading:\n   self.thread = threading.get_ident()\n   self.threadName = threading.current_thread().name\n  else: \n   self.thread = None\n   self.threadName = None\n  if not logMultiprocessing: \n   self.processName = None\n  else:\n   self.processName = 'MainProcess'\n   mp = sys.modules.get('multiprocessing')\n   if mp is not None:\n   \n   \n   \n   \n    try:\n     self.processName = mp.current_process().name\n    except Exception: \n     pass\n  if logProcesses and hasattr(os, 'getpid'):\n   self.process = os.getpid()\n  else:\n   self.process = None\n   \n def __str__(self):\n  return '<LogRecord: %s, %s, %s, %s, \"%s\">'%(self.name, self.levelno,\n  self.pathname, self.lineno, self.msg)\n  \n def getMessage(self):\n  \"\"\n  msg = str(self.msg)\n  if self.args:\n   msg = msg % self.args\n  return msg\n  \n  \n  \n  \n_logRecordFactory = LogRecord\n\ndef setLogRecordFactory(factory):\n \"\"\n global _logRecordFactory\n _logRecordFactory = factory\n \ndef getLogRecordFactory():\n \"\"\n \n return _logRecordFactory\n \ndef makeLogRecord(dict):\n \"\"\n rv = _logRecordFactory(None, None, \"\", 0, \"\", (), None, None)\n rv.__dict__.update(dict)\n return rv\n \n \n \n \n \nclass PercentStyle(object):\n\n default_format = '%(message)s'\n asctime_format = '%(asctime)s'\n asctime_search = '%(asctime)'\n \n def __init__(self, fmt):\n  self._fmt = fmt or self.default_format\n  \n def usesTime(self):\n  return self._fmt.find(self.asctime_search) >= 0\n  \n def format(self, record):\n  return self._fmt % record.__dict__\n  \nclass StrFormatStyle(PercentStyle):\n default_format = '{message}'\n asctime_format = '{asctime}'\n asctime_search = '{asctime'\n \n def format(self, record):\n  return self._fmt.format(**record.__dict__)\n  \n  \nclass StringTemplateStyle(PercentStyle):\n default_format = '${message}'\n asctime_format = '${asctime}'\n asctime_search = '${asctime}'\n \n def __init__(self, fmt):\n  self._fmt = fmt or self.default_format\n  self._tpl = Template(self._fmt)\n  \n def usesTime(self):\n  fmt = self._fmt\n  return fmt.find('$asctime') >= 0 or fmt.find(self.asctime_format) >= 0\n  \n def format(self, record):\n  return self._tpl.substitute(**record.__dict__)\n  \n_STYLES = {\n'%': PercentStyle,\n'{': StrFormatStyle,\n'$': StringTemplateStyle\n}\n\nclass Formatter(object):\n \"\"\n \n converter = time.localtime\n \n def __init__(self, fmt=None, datefmt=None, style='%'):\n  \"\"\n  if style not in _STYLES:\n   raise ValueError('Style must be one of: %s' % ','.join(\n   _STYLES.keys()))\n  self._style = _STYLES[style](fmt)\n  self._fmt = self._style._fmt\n  self.datefmt = datefmt\n  \n default_time_format = '%Y-%m-%d %H:%M:%S'\n default_msec_format = '%s,%03d'\n \n def formatTime(self, record, datefmt=None):\n  \"\"\n  ct = self.converter(record.created)\n  if datefmt:\n   s = time.strftime(datefmt, ct)\n  else:\n   t = time.strftime(self.default_time_format, ct)\n   s = self.default_msec_format % (t, record.msecs)\n  return s\n  \n def formatException(self, ei):\n  \"\"\n  sio = io.StringIO()\n  tb = ei[2]\n  \n  \n  \n  traceback.print_exception(ei[0], ei[1], tb, None, sio)\n  s = sio.getvalue()\n  sio.close()\n  if s[-1:] == \"\\n\":\n   s = s[:-1]\n  return s\n  \n def usesTime(self):\n  \"\"\n  return self._style.usesTime()\n  \n def formatMessage(self, record):\n  return self._style.format(record)\n  \n def formatStack(self, stack_info):\n  \"\"\n  return stack_info\n  \n def format(self, record):\n  \"\"\n  record.message = record.getMessage()\n  if self.usesTime():\n   record.asctime = self.formatTime(record, self.datefmt)\n  s = self.formatMessage(record)\n  if record.exc_info:\n  \n  \n   if not record.exc_text:\n    record.exc_text = self.formatException(record.exc_info)\n  if record.exc_text:\n   if s[-1:] != \"\\n\":\n    s = s + \"\\n\"\n   s = s + record.exc_text\n  if record.stack_info:\n   if s[-1:] != \"\\n\":\n    s = s + \"\\n\"\n   s = s + self.formatStack(record.stack_info)\n  return s\n  \n  \n  \n  \n_defaultFormatter = Formatter()\n\nclass BufferingFormatter(object):\n \"\"\n def __init__(self, linefmt=None):\n  \"\"\n  if linefmt:\n   self.linefmt = linefmt\n  else:\n   self.linefmt = _defaultFormatter\n   \n def formatHeader(self, records):\n  \"\"\n  return \"\"\n  \n def formatFooter(self, records):\n  \"\"\n  return \"\"\n  \n def format(self, records):\n  \"\"\n  rv = \"\"\n  if len(records) > 0:\n   rv = rv + self.formatHeader(records)\n   for record in records:\n    rv = rv + self.linefmt.format(record)\n   rv = rv + self.formatFooter(records)\n  return rv\n  \n  \n  \n  \n  \nclass Filter(object):\n \"\"\n def __init__(self, name=''):\n  \"\"\n  self.name = name\n  self.nlen = len(name)\n  \n def filter(self, record):\n  \"\"\n  if self.nlen == 0:\n   return True\n  elif self.name == record.name:\n   return True\n  elif record.name.find(self.name, 0, self.nlen) != 0:\n   return False\n  return (record.name[self.nlen] == \".\")\n  \nclass Filterer(object):\n \"\"\n def __init__(self):\n  \"\"\n  self.filters = []\n  \n def addFilter(self, filter):\n  \"\"\n  if not (filter in self.filters):\n   self.filters.append(filter)\n   \n def removeFilter(self, filter):\n  \"\"\n  if filter in self.filters:\n   self.filters.remove(filter)\n   \n def filter(self, record):\n  \"\"\n  rv = True\n  for f in self.filters:\n   if hasattr(f, 'filter'):\n    result = f.filter(record)\n   else:\n    result = f(record) \n   if not result:\n    rv = False\n    break\n  return rv\n  \n  \n  \n  \n  \n_handlers = weakref.WeakValueDictionary() \n_handlerList = [] \n\ndef _removeHandlerRef(wr):\n \"\"\n \n \n \n if (_acquireLock is not None and _handlerList is not None and\n _releaseLock is not None):\n  _acquireLock()\n  try:\n   if wr in _handlerList:\n    _handlerList.remove(wr)\n  finally:\n   _releaseLock()\n   \ndef _addHandlerRef(handler):\n \"\"\n _acquireLock()\n try:\n  _handlerList.append(weakref.ref(handler, _removeHandlerRef))\n finally:\n  _releaseLock()\n  \nclass Handler(Filterer):\n \"\"\n def __init__(self, level=NOTSET):\n  \"\"\n  Filterer.__init__(self)\n  self._name = None\n  self.level = _checkLevel(level)\n  self.formatter = None\n  \n  _addHandlerRef(self)\n  self.createLock()\n  \n def get_name(self):\n  return self._name\n  \n def set_name(self, name):\n  _acquireLock()\n  try:\n   if self._name in _handlers:\n    del _handlers[self._name]\n   self._name = name\n   if name:\n    _handlers[name] = self\n  finally:\n   _releaseLock()\n   \n name = property(get_name, set_name)\n \n def createLock(self):\n  \"\"\n  if threading:\n   self.lock = threading.RLock()\n  else: \n   self.lock = None\n   \n def acquire(self):\n  \"\"\n  if self.lock:\n   self.lock.acquire()\n   \n def release(self):\n  \"\"\n  if self.lock:\n   self.lock.release()\n   \n def setLevel(self, level):\n  \"\"\n  self.level = _checkLevel(level)\n  \n def format(self, record):\n  \"\"\n  if self.formatter:\n   fmt = self.formatter\n  else:\n   fmt = _defaultFormatter\n  return fmt.format(record)\n  \n def emit(self, record):\n  \"\"\n  raise NotImplementedError('emit must be implemented '\n  'by Handler subclasses')\n  \n def handle(self, record):\n  \"\"\n  rv = self.filter(record)\n  if rv:\n   self.acquire()\n   try:\n    self.emit(record)\n   finally:\n    self.release()\n  return rv\n  \n def setFormatter(self, fmt):\n  \"\"\n  self.formatter = fmt\n  \n def flush(self):\n  \"\"\n  pass\n  \n def close(self):\n  \"\"\n  \n  _acquireLock()\n  try: \n   if self._name and self._name in _handlers:\n    del _handlers[self._name]\n  finally:\n   _releaseLock()\n   \n def handleError(self, record):\n  \"\"\n  if raiseExceptions and sys.stderr: \n   ei = sys.exc_info()\n   try:\n    traceback.print_exception(ei[0], ei[1], ei[2],\n    None, sys.stderr)\n    sys.stderr.write('Logged from file %s, line %s\\n' % (\n    record.filename, record.lineno))\n   except IOError: \n    pass \n   finally:\n    del ei\n    \nclass StreamHandler(Handler):\n \"\"\n \n terminator = '\\n'\n \n def __init__(self, stream=None):\n  \"\"\n  Handler.__init__(self)\n  if stream is None:\n   stream = sys.stderr\n  self.stream = stream\n  \n def flush(self):\n  \"\"\n  self.acquire()\n  try:\n   if self.stream and hasattr(self.stream, \"flush\"):\n    self.stream.flush()\n  finally:\n   self.release()\n   \n def emit(self, record):\n  \"\"\n  try:\n   msg = self.format(record)\n   stream = self.stream\n   stream.write(msg)\n   stream.write(self.terminator)\n   self.flush()\n  except (KeyboardInterrupt, SystemExit): \n   raise\n  except:\n   self.handleError(record)\n   \nclass FileHandler(StreamHandler):\n \"\"\n def __init__(self, filename, mode='a', encoding=None, delay=False):\n  \"\"\n  \n  \n  self.baseFilename = os.path.abspath(filename)\n  self.mode = mode\n  self.encoding = encoding\n  self.delay = delay\n  if delay:\n  \n  \n   Handler.__init__(self)\n   self.stream = None\n  else:\n   StreamHandler.__init__(self, self._open())\n   \n def close(self):\n  \"\"\n  self.acquire()\n  try:\n   if self.stream:\n    self.flush()\n    if hasattr(self.stream, \"close\"):\n     self.stream.close()\n    StreamHandler.close(self)\n    self.stream = None\n  finally:\n   self.release()\n   \n def _open(self):\n  \"\"\n  return open(self.baseFilename, self.mode, encoding=self.encoding)\n  \n def emit(self, record):\n  \"\"\n  if self.stream is None:\n   self.stream = self._open()\n  StreamHandler.emit(self, record)\n  \nclass _StderrHandler(StreamHandler):\n \"\"\n def __init__(self, level=NOTSET):\n  \"\"\n  Handler.__init__(self, level)\n  \n @property\n def stream(self):\n  return sys.stderr\n  \n  \n_defaultLastResort = _StderrHandler(WARNING)\nlastResort = _defaultLastResort\n\n\n\n\n\nclass PlaceHolder(object):\n \"\"\n def __init__(self, alogger):\n  \"\"\n  self.loggerMap = { alogger : None }\n  \n def append(self, alogger):\n  \"\"\n  if alogger not in self.loggerMap:\n   self.loggerMap[alogger] = None\n   \n   \n   \n   \n_loggerClass = None\n\ndef setLoggerClass(klass):\n \"\"\n if klass != Logger:\n  if not issubclass(klass, Logger):\n   raise TypeError(\"logger not derived from logging.Logger: \"\n   + klass.__name__)\n global _loggerClass\n _loggerClass = klass\n \ndef getLoggerClass():\n \"\"\n \n return _loggerClass\n \nclass Manager(object):\n \"\"\n def __init__(self, rootnode):\n  \"\"\n  self.root = rootnode\n  self.disable = 0\n  self.emittedNoHandlerWarning = False\n  self.loggerDict = {}\n  self.loggerClass = None\n  self.logRecordFactory = None\n  \n def getLogger(self, name):\n  \"\"\n  rv = None\n  if not isinstance(name, str):\n   raise TypeError('A logger name must be a string')\n  _acquireLock()\n  try:\n   if name in self.loggerDict:\n    rv = self.loggerDict[name]\n    if isinstance(rv, PlaceHolder):\n     ph = rv\n     rv = (self.loggerClass or _loggerClass)(name)\n     rv.manager = self\n     self.loggerDict[name] = rv\n     self._fixupChildren(ph, rv)\n     self._fixupParents(rv)\n   else:\n    rv = (self.loggerClass or _loggerClass)(name)\n    rv.manager = self\n    self.loggerDict[name] = rv\n    self._fixupParents(rv)\n  finally:\n   _releaseLock()\n  return rv\n  \n def setLoggerClass(self, klass):\n  \"\"\n  if klass != Logger:\n   if not issubclass(klass, Logger):\n    raise TypeError(\"logger not derived from logging.Logger: \"\n    + klass.__name__)\n  self.loggerClass = klass\n  \n def setLogRecordFactory(self, factory):\n  \"\"\n  self.logRecordFactory = factory\n  \n def _fixupParents(self, alogger):\n  \"\"\n  name = alogger.name\n  i = name.rfind(\".\")\n  rv = None\n  while (i > 0) and not rv:\n   substr = name[:i]\n   if substr not in self.loggerDict:\n    self.loggerDict[substr] = PlaceHolder(alogger)\n   else:\n    obj = self.loggerDict[substr]\n    if isinstance(obj, Logger):\n     rv = obj\n    else:\n     assert isinstance(obj, PlaceHolder)\n     obj.append(alogger)\n   i = name.rfind(\".\", 0, i - 1)\n  if not rv:\n   rv = self.root\n  alogger.parent = rv\n  \n def _fixupChildren(self, ph, alogger):\n  \"\"\n  name = alogger.name\n  namelen = len(name)\n  for c in ph.loggerMap.keys():\n  \n   if c.parent.name[:namelen] != name:\n    alogger.parent = c.parent\n    c.parent = alogger\n    \n    \n    \n    \n    \nclass Logger(Filterer):\n \"\"\n def __init__(self, name, level=NOTSET):\n  \"\"\n  Filterer.__init__(self)\n  self.name = name\n  self.level = _checkLevel(level)\n  self.parent = None\n  self.propagate = True\n  self.handlers = []\n  self.disabled = False\n  \n def setLevel(self, level):\n  \"\"\n  self.level = _checkLevel(level)\n  \n def debug(self, msg, *args, **kwargs):\n  \"\"\n  if self.isEnabledFor(DEBUG):\n   self._log(DEBUG, msg, args, **kwargs)\n   \n def info(self, msg, *args, **kwargs):\n  \"\"\n  if self.isEnabledFor(INFO):\n   self._log(INFO, msg, args, **kwargs)\n   \n def warning(self, msg, *args, **kwargs):\n  \"\"\n  if self.isEnabledFor(WARNING):\n   self._log(WARNING, msg, args, **kwargs)\n   \n def warn(self, msg, *args, **kwargs):\n  warnings.warn(\"The 'warn' method is deprecated, \"\n  \"use 'warning' instead\", DeprecationWarning, 2)\n  self.warning(msg, *args, **kwargs)\n  \n def error(self, msg, *args, **kwargs):\n  \"\"\n  if self.isEnabledFor(ERROR):\n   self._log(ERROR, msg, args, **kwargs)\n   \n def exception(self, msg, *args, **kwargs):\n  \"\"\n  kwargs['exc_info'] = True\n  self.error(msg, *args, **kwargs)\n  \n def critical(self, msg, *args, **kwargs):\n  \"\"\n  if self.isEnabledFor(CRITICAL):\n   self._log(CRITICAL, msg, args, **kwargs)\n   \n fatal = critical\n \n def log(self, level, msg, *args, **kwargs):\n  \"\"\n  if not isinstance(level, int):\n   if raiseExceptions:\n    raise TypeError(\"level must be an integer\")\n   else:\n    return\n  if self.isEnabledFor(level):\n   self._log(level, msg, args, **kwargs)\n   \n def findCaller(self, stack_info=False):\n  \"\"\n  f = currentframe()\n  \n  \n  if f is not None:\n   f = f.f_back\n  rv = \"(unknown file)\", 0, \"(unknown function)\", None\n  while hasattr(f, \"f_code\"):\n   co = f.f_code\n   filename = os.path.normcase(co.co_filename)\n   if filename == _srcfile:\n    f = f.f_back\n    continue\n   sinfo = None\n   if stack_info:\n    sio = io.StringIO()\n    sio.write('Stack (most recent call last):\\n')\n    traceback.print_stack(f, file=sio)\n    sinfo = sio.getvalue()\n    if sinfo[-1] == '\\n':\n     sinfo = sinfo[:-1]\n    sio.close()\n   rv = (co.co_filename, f.f_lineno, co.co_name, sinfo)\n   break\n  return rv\n  \n def makeRecord(self, name, level, fn, lno, msg, args, exc_info,\n func=None, extra=None, sinfo=None):\n  \"\"\n  rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n  sinfo)\n  if extra is not None:\n   for key in extra:\n    if (key in [\"message\", \"asctime\"]) or (key in rv.__dict__):\n     raise KeyError(\"Attempt to overwrite %r in LogRecord\" % key)\n    rv.__dict__[key] = extra[key]\n  return rv\n  \n def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False):\n  \"\"\n  sinfo = None\n  if _srcfile:\n  \n  \n  \n   try:\n    fn, lno, func, sinfo = self.findCaller(stack_info)\n   except ValueError: \n    fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n  else: \n   fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n  if exc_info:\n   if not isinstance(exc_info, tuple):\n    exc_info = sys.exc_info()\n  record = self.makeRecord(self.name, level, fn, lno, msg, args,\n  exc_info, func, extra, sinfo)\n  self.handle(record)\n  \n def handle(self, record):\n  \"\"\n  if (not self.disabled) and self.filter(record):\n   self.callHandlers(record)\n   \n def addHandler(self, hdlr):\n  \"\"\n  _acquireLock()\n  try:\n   if not (hdlr in self.handlers):\n    self.handlers.append(hdlr)\n  finally:\n   _releaseLock()\n   \n def removeHandler(self, hdlr):\n  \"\"\n  _acquireLock()\n  try:\n   if hdlr in self.handlers:\n    self.handlers.remove(hdlr)\n  finally:\n   _releaseLock()\n   \n def hasHandlers(self):\n  \"\"\n  c = self\n  rv = False\n  while c:\n   if c.handlers:\n    rv = True\n    break\n   if not c.propagate:\n    break\n   else:\n    c = c.parent\n  return rv\n  \n def callHandlers(self, record):\n  \"\"\n  c = self\n  found = 0\n  while c:\n   for hdlr in c.handlers:\n    found = found + 1\n    if record.levelno >= hdlr.level:\n     hdlr.handle(record)\n   if not c.propagate:\n    c = None \n   else:\n    c = c.parent\n  if (found == 0):\n   if lastResort:\n    if record.levelno >= lastResort.level:\n     lastResort.handle(record)\n   elif raiseExceptions and not self.manager.emittedNoHandlerWarning:\n    sys.stderr.write(\"No handlers could be found for logger\"\n    \" \\\"%s\\\"\\n\" % self.name)\n    self.manager.emittedNoHandlerWarning = True\n    \n def getEffectiveLevel(self):\n  \"\"\n  logger = self\n  while logger:\n   if logger.level:\n    return logger.level\n   logger = logger.parent\n  return NOTSET\n  \n def isEnabledFor(self, level):\n  \"\"\n  if self.manager.disable >= level:\n   return False\n  return level >= self.getEffectiveLevel()\n  \n def getChild(self, suffix):\n  \"\"\n  if self.root is not self:\n   suffix = '.'.join((self.name, suffix))\n  return self.manager.getLogger(suffix)\n  \nclass RootLogger(Logger):\n \"\"\n def __init__(self, level):\n  \"\"\n  Logger.__init__(self, \"root\", level)\n  \n_loggerClass = Logger\n\nclass LoggerAdapter(object):\n \"\"\n \n def __init__(self, logger, extra):\n  \"\"\n  self.logger = logger\n  self.extra = extra\n  \n def process(self, msg, kwargs):\n  \"\"\n  kwargs[\"extra\"] = self.extra\n  return msg, kwargs\n  \n  \n  \n  \n def debug(self, msg, *args, **kwargs):\n  \"\"\n  self.log(DEBUG, msg, *args, **kwargs)\n  \n def info(self, msg, *args, **kwargs):\n  \"\"\n  self.log(INFO, msg, *args, **kwargs)\n  \n def warning(self, msg, *args, **kwargs):\n  \"\"\n  self.log(WARNING, msg, *args, **kwargs)\n  \n def warn(self, msg, *args, **kwargs):\n  warnings.warn(\"The 'warn' method is deprecated, \"\n  \"use 'warning' instead\", DeprecationWarning, 2)\n  self.warning(msg, *args, **kwargs)\n  \n def error(self, msg, *args, **kwargs):\n  \"\"\n  self.log(ERROR, msg, *args, **kwargs)\n  \n def exception(self, msg, *args, **kwargs):\n  \"\"\n  kwargs[\"exc_info\"] = True\n  self.log(ERROR, msg, *args, **kwargs)\n  \n def critical(self, msg, *args, **kwargs):\n  \"\"\n  self.log(CRITICAL, msg, *args, **kwargs)\n  \n def log(self, level, msg, *args, **kwargs):\n  \"\"\n  if self.isEnabledFor(level):\n   msg, kwargs = self.process(msg, kwargs)\n   self.logger._log(level, msg, args, **kwargs)\n   \n def isEnabledFor(self, level):\n  \"\"\n  if self.logger.manager.disable >= level:\n   return False\n  return level >= self.getEffectiveLevel()\n  \n def setLevel(self, level):\n  \"\"\n  self.logger.setLevel(level)\n  \n def getEffectiveLevel(self):\n  \"\"\n  return self.logger.getEffectiveLevel()\n  \n def hasHandlers(self):\n  \"\"\n  return self.logger.hasHandlers()\n  \nroot = RootLogger(WARNING)\nLogger.root = root\nLogger.manager = Manager(Logger.root)\n\n\n\n\n\nBASIC_FORMAT = \"%(levelname)s:%(name)s:%(message)s\"\n\ndef basicConfig(**kwargs):\n \"\"\n \n \n _acquireLock()\n try:\n  if len(root.handlers) == 0:\n   handlers = kwargs.get(\"handlers\")\n   if handlers is None:\n    if \"stream\" in kwargs and \"filename\" in kwargs:\n     raise ValueError(\"'stream' and 'filename' should not be \"\n     \"specified together\")\n   else:\n    if \"stream\" in kwargs or \"filename\" in kwargs:\n     raise ValueError(\"'stream' or 'filename' should not be \"\n     \"specified together with 'handlers'\")\n   if handlers is None:\n    filename = kwargs.get(\"filename\")\n    if filename:\n     mode = kwargs.get(\"filemode\", 'a')\n     h = FileHandler(filename, mode)\n    else:\n     stream = kwargs.get(\"stream\")\n     h = StreamHandler(stream)\n    handlers = [h]\n   fs = kwargs.get(\"format\", BASIC_FORMAT)\n   dfs = kwargs.get(\"datefmt\", None)\n   style = kwargs.get(\"style\", '%')\n   fmt = Formatter(fs, dfs, style)\n   for h in handlers:\n    if h.formatter is None:\n     h.setFormatter(fmt)\n    root.addHandler(h)\n   level = kwargs.get(\"level\")\n   if level is not None:\n    root.setLevel(level)\n finally:\n  _releaseLock()\n  \n  \n  \n  \n  \n  \ndef getLogger(name=None):\n \"\"\n if name:\n  return Logger.manager.getLogger(name)\n else:\n  return root\n  \ndef critical(msg, *args, **kwargs):\n \"\"\n if len(root.handlers) == 0:\n  basicConfig()\n root.critical(msg, *args, **kwargs)\n \nfatal = critical\n\ndef error(msg, *args, **kwargs):\n \"\"\n if len(root.handlers) == 0:\n  basicConfig()\n root.error(msg, *args, **kwargs)\n \ndef exception(msg, *args, **kwargs):\n \"\"\n kwargs['exc_info'] = True\n error(msg, *args, **kwargs)\n \ndef warning(msg, *args, **kwargs):\n \"\"\n if len(root.handlers) == 0:\n  basicConfig()\n root.warning(msg, *args, **kwargs)\n \ndef warn(msg, *args, **kwargs):\n warnings.warn(\"The 'warn' function is deprecated, \"\n \"use 'warning' instead\", DeprecationWarning, 2)\n warning(msg, *args, **kwargs)\n \ndef info(msg, *args, **kwargs):\n \"\"\n if len(root.handlers) == 0:\n  basicConfig()\n root.info(msg, *args, **kwargs)\n \ndef debug(msg, *args, **kwargs):\n \"\"\n if len(root.handlers) == 0:\n  basicConfig()\n root.debug(msg, *args, **kwargs)\n \ndef log(level, msg, *args, **kwargs):\n \"\"\n if len(root.handlers) == 0:\n  basicConfig()\n root.log(level, msg, *args, **kwargs)\n \ndef disable(level):\n \"\"\n root.manager.disable = level\n \ndef shutdown(handlerList=_handlerList):\n \"\"\n for wr in reversed(handlerList[:]):\n \n \n  try:\n   h = wr()\n   if h:\n    try:\n     h.acquire()\n     h.flush()\n     h.close()\n    except (IOError, ValueError):\n    \n    \n    \n    \n     pass\n    finally:\n     h.release()\n  except:\n   if raiseExceptions:\n    raise\n    \n    \n    \nimport atexit\natexit.register(shutdown)\n\n\n\nclass NullHandler(Handler):\n \"\"\n def handle(self, record):\n  \"\"\n  \n def emit(self, record):\n  \"\"\n  \n def createLock(self):\n  self.lock = None\n  \n  \n  \n_warnings_showwarning = None\n\ndef _showwarning(message, category, filename, lineno, file=None, line=None):\n \"\"\n if file is not None:\n  if _warnings_showwarning is not None:\n   _warnings_showwarning(message, category, filename, lineno, file, line)\n else:\n  s = warnings.formatwarning(message, category, filename, lineno, line)\n  logger = getLogger(\"py.warnings\")\n  if not logger.handlers:\n   logger.addHandler(NullHandler())\n  logger.warning(\"%s\", s)\n  \ndef captureWarnings(capture):\n \"\"\n global _warnings_showwarning\n if capture:\n  if _warnings_showwarning is None:\n   _warnings_showwarning = warnings.showwarning\n   warnings.showwarning = _showwarning\n else:\n  if _warnings_showwarning is not None:\n   warnings.showwarning = _warnings_showwarning\n   _warnings_showwarning = None\n", 1], "socket": [".py", "\n\n\n\"\"\n\nimport _socket\nfrom _socket import *\n\nimport os, sys, io\n\ntry:\n import errno\nexcept ImportError:\n errno = None\nEBADF = getattr(errno, 'EBADF', 9)\nEAGAIN = getattr(errno, 'EAGAIN', 11)\nEWOULDBLOCK = getattr(errno, 'EWOULDBLOCK', 11)\n\n__all__ = [\"getfqdn\", \"create_connection\"]\n__all__.extend(os._get_exports_list(_socket))\n\n\n_realsocket = socket\n\n\nif sys.platform.lower().startswith(\"win\"):\n errorTab = {}\n errorTab[10004] = \"The operation was interrupted.\"\n errorTab[10009] = \"A bad file handle was passed.\"\n errorTab[10013] = \"Permission denied.\"\n errorTab[10014] = \"A fault occurred on the network??\" \n errorTab[10022] = \"An invalid operation was attempted.\"\n errorTab[10035] = \"The socket operation would block\"\n errorTab[10036] = \"A blocking operation is already in progress.\"\n errorTab[10048] = \"The network address is in use.\"\n errorTab[10054] = \"The connection has been reset.\"\n errorTab[10058] = \"The network has been shut down.\"\n errorTab[10060] = \"The operation timed out.\"\n errorTab[10061] = \"Connection refused.\"\n errorTab[10063] = \"The name is too long.\"\n errorTab[10064] = \"The host is down.\"\n errorTab[10065] = \"The host is unreachable.\"\n __all__.append(\"errorTab\")\n \n \nclass socket(_socket.socket):\n\n \"\"\n \n __slots__ = [\"__weakref__\", \"_io_refs\", \"_closed\"]\n \n def __init__(self, family=AF_INET, type=SOCK_STREAM, proto=0, fileno=None):\n  _socket.socket.__init__(self, family, type, proto, fileno)\n  self._io_refs = 0\n  self._closed = False\n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, *args):\n  if not self._closed:\n   self.close()\n   \n def __repr__(self):\n  \"\"\n  s = _socket.socket.__repr__(self)\n  if s.startswith(\"<socket object\"):\n   s = \"<%s.%s%s%s\" % (self.__class__.__module__,\n   self.__class__.__name__,\n   getattr(self, '_closed', False) and \" [closed] \" or \"\",\n   s[7:])\n  return s\n  \n def __getstate__(self):\n  raise TypeError(\"Cannot serialize socket object\")\n  \n def dup(self):\n  \"\"\n  fd = dup(self.fileno())\n  sock = self.__class__(self.family, self.type, self.proto, fileno=fd)\n  sock.settimeout(self.gettimeout())\n  return sock\n  \n def accept(self):\n  \"\"\n  fd, addr = self._accept()\n  sock = socket(self.family, self.type, self.proto, fileno=fd)\n  \n  \n  \n  if getdefaulttimeout() is None and self.gettimeout():\n   sock.setblocking(True)\n  return sock, addr\n  \n def makefile(self, mode=\"r\", buffering=None, *,\n encoding=None, errors=None, newline=None):\n  \"\"\n  for c in mode:\n   if c not in {\"r\", \"w\", \"b\"}:\n    raise ValueError(\"invalid mode %r (only r, w, b allowed)\")\n  writing = \"w\" in mode\n  reading = \"r\" in mode or not writing\n  assert reading or writing\n  binary = \"b\" in mode\n  rawmode = \"\"\n  if reading:\n   rawmode += \"r\"\n  if writing:\n   rawmode += \"w\"\n  raw = SocketIO(self, rawmode)\n  self._io_refs += 1\n  if buffering is None:\n   buffering = -1\n  if buffering < 0:\n   buffering = io.DEFAULT_BUFFER_SIZE\n  if buffering == 0:\n   if not binary:\n    raise ValueError(\"unbuffered streams must be binary\")\n   return raw\n  if reading and writing:\n   buffer = io.BufferedRWPair(raw, raw, buffering)\n  elif reading:\n   buffer = io.BufferedReader(raw, buffering)\n  else:\n   assert writing\n   buffer = io.BufferedWriter(raw, buffering)\n  if binary:\n   return buffer\n  text = io.TextIOWrapper(buffer, encoding, errors, newline)\n  text.mode = mode\n  return text\n  \n def _decref_socketios(self):\n  if self._io_refs > 0:\n   self._io_refs -= 1\n  if self._closed:\n   self.close()\n   \n def _real_close(self, _ss=_socket.socket):\n \n  _ss.close(self)\n  \n def close(self):\n \n  self._closed = True\n  if self._io_refs <= 0:\n   self._real_close()\n   \n def detach(self):\n  \"\"\n  self._closed = True\n  return super().detach()\n  \ndef fromfd(fd, family, type, proto=0):\n \"\"\n nfd = dup(fd)\n return socket(family, type, proto, nfd)\n \nif hasattr(_socket.socket, \"share\"):\n def fromshare(info):\n  \"\"\n  return socket(0, 0, 0, info)\n  \nif hasattr(_socket, \"socketpair\"):\n\n def socketpair(family=None, type=SOCK_STREAM, proto=0):\n  \"\"\n  if family is None:\n   try:\n    family = AF_UNIX\n   except NameError:\n    family = AF_INET\n  a, b = _socket.socketpair(family, type, proto)\n  a = socket(family, type, proto, a.detach())\n  b = socket(family, type, proto, b.detach())\n  return a, b\n  \n  \n_blocking_errnos = { EAGAIN, EWOULDBLOCK }\n\nclass SocketIO(io.RawIOBase):\n\n \"\"\n \n \n \n \n \n \n \n \n \n \n def __init__(self, sock, mode):\n  if mode not in (\"r\", \"w\", \"rw\", \"rb\", \"wb\", \"rwb\"):\n   raise ValueError(\"invalid mode: %r\" % mode)\n  io.RawIOBase.__init__(self)\n  self._sock = sock\n  if \"b\" not in mode:\n   mode += \"b\"\n  self._mode = mode\n  self._reading = \"r\" in mode\n  self._writing = \"w\" in mode\n  self._timeout_occurred = False\n  \n def readinto(self, b):\n  \"\"\n  self._checkClosed()\n  self._checkReadable()\n  if self._timeout_occurred:\n   raise IOError(\"cannot read from timed out object\")\n  while True:\n   try:\n    return self._sock.recv_into(b)\n   except timeout:\n    self._timeout_occurred = True\n    raise\n   except InterruptedError:\n    continue\n   except error as e:\n    if e.args[0] in _blocking_errnos:\n     return None\n    raise\n    \n def write(self, b):\n  \"\"\n  self._checkClosed()\n  self._checkWritable()\n  try:\n   return self._sock.send(b)\n  except error as e:\n  \n   if e.args[0] in _blocking_errnos:\n    return None\n   raise\n   \n def readable(self):\n  \"\"\n  if self.closed:\n   raise ValueError(\"I/O operation on closed socket.\")\n  return self._reading\n  \n def writable(self):\n  \"\"\n  if self.closed:\n   raise ValueError(\"I/O operation on closed socket.\")\n  return self._writing\n  \n def seekable(self):\n  \"\"\n  if self.closed:\n   raise ValueError(\"I/O operation on closed socket.\")\n  return super().seekable()\n  \n def fileno(self):\n  \"\"\n  self._checkClosed()\n  return self._sock.fileno()\n  \n @property\n def name(self):\n  if not self.closed:\n   return self.fileno()\n  else:\n   return -1\n   \n @property\n def mode(self):\n  return self._mode\n  \n def close(self):\n  \"\"\n  if self.closed:\n   return\n  io.RawIOBase.close(self)\n  self._sock._decref_socketios()\n  self._sock = None\n  \n  \ndef getfqdn(name=''):\n \"\"\n name = name.strip()\n if not name or name == '0.0.0.0':\n  name = gethostname()\n try:\n  hostname, aliases, ipaddrs = gethostbyaddr(name)\n except error:\n  pass\n else:\n  aliases.insert(0, hostname)\n  for name in aliases:\n   if '.' in name:\n    break\n  else:\n   name = hostname\n return name\n \n \n_GLOBAL_DEFAULT_TIMEOUT = object()\n\ndef create_connection(address, timeout=_GLOBAL_DEFAULT_TIMEOUT,\nsource_address=None):\n \"\"\n \n host, port = address\n err = None\n for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n  af, socktype, proto, canonname, sa = res\n  sock = None\n  try:\n   sock = socket(af, socktype, proto)\n   if timeout is not _GLOBAL_DEFAULT_TIMEOUT:\n    sock.settimeout(timeout)\n   if source_address:\n    sock.bind(source_address)\n   sock.connect(sa)\n   return sock\n   \n  except error as _:\n   err = _\n   if sock is not None:\n    sock.close()\n    \n if err is not None:\n  raise err\n else:\n  raise error(\"getaddrinfo returns an empty list\")\n"], "xml.etree": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", 1], "traceback": [".py", "import sys\ndef print_exc(file=sys.stderr):\n exc = __BRYTHON__.exception_stack[-1]\n file.write(exc.info)\n file.write('\\n'+exc.__name__)\n if exc.message:\n  file.write(': '+exc.message)\n file.write('\\n')\n \ndef format_exc(limit=None,chain=True):\n exc = __BRYTHON__.exception_stack[-1]\n res = exc.info+'\\n'+exc.__name__\n if exc.message:\n  res += ': '+exc.message\n return res+'\\n'\n \ndef format_exception(_type, value, tb, limit=None, chain=True):\n return ['%s\\n' %_type,'%s\\n' %value] \n"], "test.re_tests": [".py", "\n\n\n\n\n\n[SUCCEED, FAIL, SYNTAX_ERROR] = range(3)\n\n\n\n\n\n\n\n\n\nbenchmarks = [\n\n\n('Python|Perl', 'Perl'), \n('(Python|Perl)', 'Perl'), \n\n('Python|Perl|Tcl', 'Perl'), \n('(Python|Perl|Tcl)', 'Perl'), \n\n('(Python)\\\\1', 'PythonPython'), \n('([0a-z][a-z0-9]*,)+', 'a5,b7,c9,'), \n('([a-z][a-z0-9]*,)+', 'a5,b7,c9,'), \n\n('Python', 'Python'), \n('.*Python', 'Python'), \n('.*Python.*', 'Python'), \n('.*(Python)', 'Python'), \n\n]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntests = [\n\n('(?P<foo_123', '', SYNTAX_ERROR), \n('(?P<1>a)', '', SYNTAX_ERROR), \n('(?P<!>a)', '', SYNTAX_ERROR), \n('(?P<foo!>a)', '', SYNTAX_ERROR), \n\n\n('(?P<foo_123>a)(?P=foo_123', 'aa', SYNTAX_ERROR),\n('(?P<foo_123>a)(?P=1)', 'aa', SYNTAX_ERROR),\n('(?P<foo_123>a)(?P=!)', 'aa', SYNTAX_ERROR),\n('(?P<foo_123>a)(?P=foo_124', 'aa', SYNTAX_ERROR), \n\n('(?P<foo_123>a)', 'a', SUCCEED, 'g1', 'a'),\n('(?P<foo_123>a)(?P=foo_123)', 'aa', SUCCEED, 'g1', 'a'),\n\n\n('\\\\1', 'a', SYNTAX_ERROR), \n('[\\\\1]', '\\1', SUCCEED, 'found', '\\1'), \n('\\\\09', chr(0) + '9', SUCCEED, 'found', chr(0) + '9'),\n('\\\\141', 'a', SUCCEED, 'found', 'a'),\n('(a)(b)(c)(d)(e)(f)(g)(h)(i)(j)(k)(l)\\\\119', 'abcdefghijklk9', SUCCEED, 'found+\"-\"+g11', 'abcdefghijklk9-k'),\n\n\n(r'\\0', '\\0', SUCCEED, 'found', '\\0'),\n(r'[\\0a]', '\\0', SUCCEED, 'found', '\\0'),\n(r'[a\\0]', '\\0', SUCCEED, 'found', '\\0'),\n(r'[^a\\0]', '\\0', FAIL),\n\n\n(r'\\a[\\b]\\f\\n\\r\\t\\v', '\\a\\b\\f\\n\\r\\t\\v', SUCCEED, 'found', '\\a\\b\\f\\n\\r\\t\\v'),\n(r'[\\a][\\b][\\f][\\n][\\r][\\t][\\v]', '\\a\\b\\f\\n\\r\\t\\v', SUCCEED, 'found', '\\a\\b\\f\\n\\r\\t\\v'),\n\n\n(r'\\c\\e\\g\\h\\i\\j\\k\\m\\o\\p\\q\\y\\z', 'ceghijkmopqyz', SUCCEED, 'found', 'ceghijkmopqyz'),\n(r'\\xff', '\\377', SUCCEED, 'found', chr(255)),\n\n(r'\\x00ffffffffffffff', '\\377', FAIL, 'found', chr(255)),\n(r'\\x00f', '\\017', FAIL, 'found', chr(15)),\n(r'\\x00fe', '\\376', FAIL, 'found', chr(254)),\n\n\n\n\n(r\"^\\w+=(\\\\[\\000-\\277]|[^\\n\\\\])*\", \"SRC=eval.c g.c blah blah blah \\\\\\\\\\n\\tapes.c\",\nSUCCEED, 'found', \"SRC=eval.c g.c blah blah blah \\\\\\\\\"),\n\n\n('a.b', 'acb', SUCCEED, 'found', 'acb'),\n('a.b', 'a\\nb', FAIL),\n('a.*b', 'acc\\nccb', FAIL),\n('a.{4,5}b', 'acc\\nccb', FAIL),\n('a.b', 'a\\rb', SUCCEED, 'found', 'a\\rb'),\n('a.b(?s)', 'a\\nb', SUCCEED, 'found', 'a\\nb'),\n('a.*(?s)b', 'acc\\nccb', SUCCEED, 'found', 'acc\\nccb'),\n('(?s)a.{4,5}b', 'acc\\nccb', SUCCEED, 'found', 'acc\\nccb'),\n('(?s)a.b', 'a\\nb', SUCCEED, 'found', 'a\\nb'),\n\n(')', '', SYNTAX_ERROR), \n('', '', SUCCEED, 'found', ''), \n('abc', 'abc', SUCCEED, 'found', 'abc'),\n('abc', 'xbc', FAIL),\n('abc', 'axc', FAIL),\n('abc', 'abx', FAIL),\n('abc', 'xabcy', SUCCEED, 'found', 'abc'),\n('abc', 'ababc', SUCCEED, 'found', 'abc'),\n('ab*c', 'abc', SUCCEED, 'found', 'abc'),\n('ab*bc', 'abc', SUCCEED, 'found', 'abc'),\n('ab*bc', 'abbc', SUCCEED, 'found', 'abbc'),\n('ab*bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n('ab+bc', 'abbc', SUCCEED, 'found', 'abbc'),\n('ab+bc', 'abc', FAIL),\n('ab+bc', 'abq', FAIL),\n('ab+bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n('ab?bc', 'abbc', SUCCEED, 'found', 'abbc'),\n('ab?bc', 'abc', SUCCEED, 'found', 'abc'),\n('ab?bc', 'abbbbc', FAIL),\n('ab?c', 'abc', SUCCEED, 'found', 'abc'),\n('^abc$', 'abc', SUCCEED, 'found', 'abc'),\n('^abc$', 'abcc', FAIL),\n('^abc', 'abcc', SUCCEED, 'found', 'abc'),\n('^abc$', 'aabc', FAIL),\n('abc$', 'aabc', SUCCEED, 'found', 'abc'),\n('^', 'abc', SUCCEED, 'found+\"-\"', '-'),\n('$', 'abc', SUCCEED, 'found+\"-\"', '-'),\n('a.c', 'abc', SUCCEED, 'found', 'abc'),\n('a.c', 'axc', SUCCEED, 'found', 'axc'),\n('a.*c', 'axyzc', SUCCEED, 'found', 'axyzc'),\n('a.*c', 'axyzd', FAIL),\n('a[bc]d', 'abc', FAIL),\n('a[bc]d', 'abd', SUCCEED, 'found', 'abd'),\n('a[b-d]e', 'abd', FAIL),\n('a[b-d]e', 'ace', SUCCEED, 'found', 'ace'),\n('a[b-d]', 'aac', SUCCEED, 'found', 'ac'),\n('a[-b]', 'a-', SUCCEED, 'found', 'a-'),\n('a[\\\\-b]', 'a-', SUCCEED, 'found', 'a-'),\n\n\n('a[]b', '-', SYNTAX_ERROR),\n('a[', '-', SYNTAX_ERROR),\n('a\\\\', '-', SYNTAX_ERROR),\n('abc)', '-', SYNTAX_ERROR),\n('(abc', '-', SYNTAX_ERROR),\n('a]', 'a]', SUCCEED, 'found', 'a]'),\n('a[]]b', 'a]b', SUCCEED, 'found', 'a]b'),\n('a[\\]]b', 'a]b', SUCCEED, 'found', 'a]b'),\n('a[^bc]d', 'aed', SUCCEED, 'found', 'aed'),\n('a[^bc]d', 'abd', FAIL),\n('a[^-b]c', 'adc', SUCCEED, 'found', 'adc'),\n('a[^-b]c', 'a-c', FAIL),\n('a[^]b]c', 'a]c', FAIL),\n('a[^]b]c', 'adc', SUCCEED, 'found', 'adc'),\n('\\\\ba\\\\b', 'a-', SUCCEED, '\"-\"', '-'),\n('\\\\ba\\\\b', '-a', SUCCEED, '\"-\"', '-'),\n('\\\\ba\\\\b', '-a-', SUCCEED, '\"-\"', '-'),\n('\\\\by\\\\b', 'xy', FAIL),\n('\\\\by\\\\b', 'yz', FAIL),\n('\\\\by\\\\b', 'xyz', FAIL),\n('x\\\\b', 'xyz', FAIL),\n('x\\\\B', 'xyz', SUCCEED, '\"-\"', '-'),\n('\\\\Bz', 'xyz', SUCCEED, '\"-\"', '-'),\n('z\\\\B', 'xyz', FAIL),\n('\\\\Bx', 'xyz', FAIL),\n('\\\\Ba\\\\B', 'a-', FAIL, '\"-\"', '-'),\n('\\\\Ba\\\\B', '-a', FAIL, '\"-\"', '-'),\n('\\\\Ba\\\\B', '-a-', FAIL, '\"-\"', '-'),\n('\\\\By\\\\B', 'xy', FAIL),\n('\\\\By\\\\B', 'yz', FAIL),\n('\\\\By\\\\b', 'xy', SUCCEED, '\"-\"', '-'),\n('\\\\by\\\\B', 'yz', SUCCEED, '\"-\"', '-'),\n('\\\\By\\\\B', 'xyz', SUCCEED, '\"-\"', '-'),\n('ab|cd', 'abc', SUCCEED, 'found', 'ab'),\n('ab|cd', 'abcd', SUCCEED, 'found', 'ab'),\n('()ef', 'def', SUCCEED, 'found+\"-\"+g1', 'ef-'),\n('$b', 'b', FAIL),\n('a\\\\(b', 'a(b', SUCCEED, 'found+\"-\"+g1', 'a(b-Error'),\n('a\\\\(*b', 'ab', SUCCEED, 'found', 'ab'),\n('a\\\\(*b', 'a((b', SUCCEED, 'found', 'a((b'),\n('a\\\\\\\\b', 'a\\\\b', SUCCEED, 'found', 'a\\\\b'),\n('((a))', 'abc', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'a-a-a'),\n('(a)b(c)', 'abc', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abc-a-c'),\n('a+b+c', 'aabbabc', SUCCEED, 'found', 'abc'),\n('(a+|b)*', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n('(a+|b)+', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n('(a+|b)?', 'ab', SUCCEED, 'found+\"-\"+g1', 'a-a'),\n(')(', '-', SYNTAX_ERROR),\n('[^ab]*', 'cde', SUCCEED, 'found', 'cde'),\n('abc', '', FAIL),\n('a*', '', SUCCEED, 'found', ''),\n('a|b|c|d|e', 'e', SUCCEED, 'found', 'e'),\n('(a|b|c|d|e)f', 'ef', SUCCEED, 'found+\"-\"+g1', 'ef-e'),\n('abcd*efg', 'abcdefg', SUCCEED, 'found', 'abcdefg'),\n('ab*', 'xabyabbbz', SUCCEED, 'found', 'ab'),\n('ab*', 'xayabbbz', SUCCEED, 'found', 'a'),\n('(ab|cd)e', 'abcde', SUCCEED, 'found+\"-\"+g1', 'cde-cd'),\n('[abhgefdc]ij', 'hij', SUCCEED, 'found', 'hij'),\n('^(ab|cd)e', 'abcde', FAIL, 'xg1y', 'xy'),\n('(abc|)ef', 'abcdef', SUCCEED, 'found+\"-\"+g1', 'ef-'),\n('(a|b)c*d', 'abcd', SUCCEED, 'found+\"-\"+g1', 'bcd-b'),\n('(ab|ab*)bc', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-a'),\n('a([bc]*)c*', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-bc'),\n('a([bc]*)(c*d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-bc-d'),\n('a([bc]+)(c*d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-bc-d'),\n('a([bc]*)(c+d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-b-cd'),\n('a[bcd]*dcdcde', 'adcdcde', SUCCEED, 'found', 'adcdcde'),\n('a[bcd]+dcdcde', 'adcdcde', FAIL),\n('(ab|a)b*c', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-ab'),\n('((a)(b)c)(d)', 'abcd', SUCCEED, 'g1+\"-\"+g2+\"-\"+g3+\"-\"+g4', 'abc-a-b-d'),\n('[a-zA-Z_][a-zA-Z0-9_]*', 'alpha', SUCCEED, 'found', 'alpha'),\n('^a(bc+|b[eh])g|.h$', 'abh', SUCCEED, 'found+\"-\"+g1', 'bh-None'),\n('(bc+d$|ef*g.|h?i(j|k))', 'effgz', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'effgz-effgz-None'),\n('(bc+d$|ef*g.|h?i(j|k))', 'ij', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ij-ij-j'),\n('(bc+d$|ef*g.|h?i(j|k))', 'effg', FAIL),\n('(bc+d$|ef*g.|h?i(j|k))', 'bcdd', FAIL),\n('(bc+d$|ef*g.|h?i(j|k))', 'reffgz', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'effgz-effgz-None'),\n('(((((((((a)))))))))', 'a', SUCCEED, 'found', 'a'),\n('multiple words of text', 'uh-uh', FAIL),\n('multiple words', 'multiple words, yeah', SUCCEED, 'found', 'multiple words'),\n('(.*)c(.*)', 'abcde', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcde-ab-de'),\n('\\\\((.*), (.*)\\\\)', '(a, b)', SUCCEED, 'g2+\"-\"+g1', 'b-a'),\n('[k]', 'ab', FAIL),\n('a[-]?c', 'ac', SUCCEED, 'found', 'ac'),\n('(abc)\\\\1', 'abcabc', SUCCEED, 'g1', 'abc'),\n('([a-c]*)\\\\1', 'abcabc', SUCCEED, 'g1', 'abc'),\n('^(.+)?B', 'AB', SUCCEED, 'g1', 'A'),\n('(a+).\\\\1$', 'aaaaa', SUCCEED, 'found+\"-\"+g1', 'aaaaa-aa'),\n('^(a+).\\\\1$', 'aaaa', FAIL),\n('(abc)\\\\1', 'abcabc', SUCCEED, 'found+\"-\"+g1', 'abcabc-abc'),\n('([a-c]+)\\\\1', 'abcabc', SUCCEED, 'found+\"-\"+g1', 'abcabc-abc'),\n('(a)\\\\1', 'aa', SUCCEED, 'found+\"-\"+g1', 'aa-a'),\n('(a+)\\\\1', 'aa', SUCCEED, 'found+\"-\"+g1', 'aa-a'),\n('(a+)+\\\\1', 'aa', SUCCEED, 'found+\"-\"+g1', 'aa-a'),\n('(a).+\\\\1', 'aba', SUCCEED, 'found+\"-\"+g1', 'aba-a'),\n('(a)ba*\\\\1', 'aba', SUCCEED, 'found+\"-\"+g1', 'aba-a'),\n('(aa|a)a\\\\1$', 'aaa', SUCCEED, 'found+\"-\"+g1', 'aaa-a'),\n('(a|aa)a\\\\1$', 'aaa', SUCCEED, 'found+\"-\"+g1', 'aaa-a'),\n('(a+)a\\\\1$', 'aaa', SUCCEED, 'found+\"-\"+g1', 'aaa-a'),\n('([abc]*)\\\\1', 'abcabc', SUCCEED, 'found+\"-\"+g1', 'abcabc-abc'),\n('(a)(b)c|ab', 'ab', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ab-None-None'),\n('(a)+x', 'aaax', SUCCEED, 'found+\"-\"+g1', 'aaax-a'),\n('([ac])+x', 'aacx', SUCCEED, 'found+\"-\"+g1', 'aacx-c'),\n('([^/]*/)*sub1/', 'd:msgs/tdir/sub1/trial/away.cpp', SUCCEED, 'found+\"-\"+g1', 'd:msgs/tdir/sub1/-tdir/'),\n('([^.]*)\\\\.([^:]*):[T ]+(.*)', 'track1.title:TBlah blah blah', SUCCEED, 'found+\"-\"+g1+\"-\"+g2+\"-\"+g3', 'track1.title:TBlah blah blah-track1-title-Blah blah blah'),\n('([^N]*N)+', 'abNNxyzN', SUCCEED, 'found+\"-\"+g1', 'abNNxyzN-xyzN'),\n('([^N]*N)+', 'abNNxyz', SUCCEED, 'found+\"-\"+g1', 'abNN-N'),\n('([abc]*)x', 'abcx', SUCCEED, 'found+\"-\"+g1', 'abcx-abc'),\n('([abc]*)x', 'abc', FAIL),\n('([xyz]*)x', 'abcx', SUCCEED, 'found+\"-\"+g1', 'x-'),\n('(a)+b|aac', 'aac', SUCCEED, 'found+\"-\"+g1', 'aac-None'),\n\n\n\n('(?P<i d>aaa)a', 'aaaa', SYNTAX_ERROR),\n('(?P<id>aaa)a', 'aaaa', SUCCEED, 'found+\"-\"+id', 'aaaa-aaa'),\n('(?P<id>aa)(?P=id)', 'aaaa', SUCCEED, 'found+\"-\"+id', 'aaaa-aa'),\n('(?P<id>aa)(?P=xd)', 'aaaa', SYNTAX_ERROR),\n\n\n\n('\\\\1', 'a', SYNTAX_ERROR),\n('\\\\09', chr(0) + '9', SUCCEED, 'found', chr(0) + '9'),\n('\\\\141', 'a', SUCCEED, 'found', 'a'),\n('(a)(b)(c)(d)(e)(f)(g)(h)(i)(j)(k)(l)\\\\119', 'abcdefghijklk9', SUCCEED, 'found+\"-\"+g11', 'abcdefghijklk9-k'),\n\n\n\n('abc', 'abc', SUCCEED, 'found', 'abc'),\n('abc', 'xbc', FAIL),\n('abc', 'axc', FAIL),\n('abc', 'abx', FAIL),\n('abc', 'xabcy', SUCCEED, 'found', 'abc'),\n('abc', 'ababc', SUCCEED, 'found', 'abc'),\n('ab*c', 'abc', SUCCEED, 'found', 'abc'),\n('ab*bc', 'abc', SUCCEED, 'found', 'abc'),\n('ab*bc', 'abbc', SUCCEED, 'found', 'abbc'),\n('ab*bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n('ab{0,}bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n('ab+bc', 'abbc', SUCCEED, 'found', 'abbc'),\n('ab+bc', 'abc', FAIL),\n('ab+bc', 'abq', FAIL),\n('ab{1,}bc', 'abq', FAIL),\n('ab+bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n('ab{1,}bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n('ab{1,3}bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n('ab{3,4}bc', 'abbbbc', SUCCEED, 'found', 'abbbbc'),\n('ab{4,5}bc', 'abbbbc', FAIL),\n('ab?bc', 'abbc', SUCCEED, 'found', 'abbc'),\n('ab?bc', 'abc', SUCCEED, 'found', 'abc'),\n('ab{0,1}bc', 'abc', SUCCEED, 'found', 'abc'),\n('ab?bc', 'abbbbc', FAIL),\n('ab?c', 'abc', SUCCEED, 'found', 'abc'),\n('ab{0,1}c', 'abc', SUCCEED, 'found', 'abc'),\n('^abc$', 'abc', SUCCEED, 'found', 'abc'),\n('^abc$', 'abcc', FAIL),\n('^abc', 'abcc', SUCCEED, 'found', 'abc'),\n('^abc$', 'aabc', FAIL),\n('abc$', 'aabc', SUCCEED, 'found', 'abc'),\n('^', 'abc', SUCCEED, 'found', ''),\n('$', 'abc', SUCCEED, 'found', ''),\n('a.c', 'abc', SUCCEED, 'found', 'abc'),\n('a.c', 'axc', SUCCEED, 'found', 'axc'),\n('a.*c', 'axyzc', SUCCEED, 'found', 'axyzc'),\n('a.*c', 'axyzd', FAIL),\n('a[bc]d', 'abc', FAIL),\n('a[bc]d', 'abd', SUCCEED, 'found', 'abd'),\n('a[b-d]e', 'abd', FAIL),\n('a[b-d]e', 'ace', SUCCEED, 'found', 'ace'),\n('a[b-d]', 'aac', SUCCEED, 'found', 'ac'),\n('a[-b]', 'a-', SUCCEED, 'found', 'a-'),\n('a[b-]', 'a-', SUCCEED, 'found', 'a-'),\n('a[b-a]', '-', SYNTAX_ERROR),\n('a[]b', '-', SYNTAX_ERROR),\n('a[', '-', SYNTAX_ERROR),\n('a]', 'a]', SUCCEED, 'found', 'a]'),\n('a[]]b', 'a]b', SUCCEED, 'found', 'a]b'),\n('a[^bc]d', 'aed', SUCCEED, 'found', 'aed'),\n('a[^bc]d', 'abd', FAIL),\n('a[^-b]c', 'adc', SUCCEED, 'found', 'adc'),\n('a[^-b]c', 'a-c', FAIL),\n('a[^]b]c', 'a]c', FAIL),\n('a[^]b]c', 'adc', SUCCEED, 'found', 'adc'),\n('ab|cd', 'abc', SUCCEED, 'found', 'ab'),\n('ab|cd', 'abcd', SUCCEED, 'found', 'ab'),\n('()ef', 'def', SUCCEED, 'found+\"-\"+g1', 'ef-'),\n('*a', '-', SYNTAX_ERROR),\n('(*)b', '-', SYNTAX_ERROR),\n('$b', 'b', FAIL),\n('a\\\\', '-', SYNTAX_ERROR),\n('a\\\\(b', 'a(b', SUCCEED, 'found+\"-\"+g1', 'a(b-Error'),\n('a\\\\(*b', 'ab', SUCCEED, 'found', 'ab'),\n('a\\\\(*b', 'a((b', SUCCEED, 'found', 'a((b'),\n('a\\\\\\\\b', 'a\\\\b', SUCCEED, 'found', 'a\\\\b'),\n('abc)', '-', SYNTAX_ERROR),\n('(abc', '-', SYNTAX_ERROR),\n('((a))', 'abc', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'a-a-a'),\n('(a)b(c)', 'abc', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abc-a-c'),\n('a+b+c', 'aabbabc', SUCCEED, 'found', 'abc'),\n('a{1,}b{1,}c', 'aabbabc', SUCCEED, 'found', 'abc'),\n('a**', '-', SYNTAX_ERROR),\n('a.+?c', 'abcabc', SUCCEED, 'found', 'abc'),\n('(a+|b)*', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n('(a+|b){0,}', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n('(a+|b)+', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n('(a+|b){1,}', 'ab', SUCCEED, 'found+\"-\"+g1', 'ab-b'),\n('(a+|b)?', 'ab', SUCCEED, 'found+\"-\"+g1', 'a-a'),\n('(a+|b){0,1}', 'ab', SUCCEED, 'found+\"-\"+g1', 'a-a'),\n(')(', '-', SYNTAX_ERROR),\n('[^ab]*', 'cde', SUCCEED, 'found', 'cde'),\n('abc', '', FAIL),\n('a*', '', SUCCEED, 'found', ''),\n('([abc])*d', 'abbbcd', SUCCEED, 'found+\"-\"+g1', 'abbbcd-c'),\n('([abc])*bcd', 'abcd', SUCCEED, 'found+\"-\"+g1', 'abcd-a'),\n('a|b|c|d|e', 'e', SUCCEED, 'found', 'e'),\n('(a|b|c|d|e)f', 'ef', SUCCEED, 'found+\"-\"+g1', 'ef-e'),\n('abcd*efg', 'abcdefg', SUCCEED, 'found', 'abcdefg'),\n('ab*', 'xabyabbbz', SUCCEED, 'found', 'ab'),\n('ab*', 'xayabbbz', SUCCEED, 'found', 'a'),\n('(ab|cd)e', 'abcde', SUCCEED, 'found+\"-\"+g1', 'cde-cd'),\n('[abhgefdc]ij', 'hij', SUCCEED, 'found', 'hij'),\n('^(ab|cd)e', 'abcde', FAIL),\n('(abc|)ef', 'abcdef', SUCCEED, 'found+\"-\"+g1', 'ef-'),\n('(a|b)c*d', 'abcd', SUCCEED, 'found+\"-\"+g1', 'bcd-b'),\n('(ab|ab*)bc', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-a'),\n('a([bc]*)c*', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-bc'),\n('a([bc]*)(c*d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-bc-d'),\n('a([bc]+)(c*d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-bc-d'),\n('a([bc]*)(c+d)', 'abcd', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcd-b-cd'),\n('a[bcd]*dcdcde', 'adcdcde', SUCCEED, 'found', 'adcdcde'),\n('a[bcd]+dcdcde', 'adcdcde', FAIL),\n('(ab|a)b*c', 'abc', SUCCEED, 'found+\"-\"+g1', 'abc-ab'),\n('((a)(b)c)(d)', 'abcd', SUCCEED, 'g1+\"-\"+g2+\"-\"+g3+\"-\"+g4', 'abc-a-b-d'),\n('[a-zA-Z_][a-zA-Z0-9_]*', 'alpha', SUCCEED, 'found', 'alpha'),\n('^a(bc+|b[eh])g|.h$', 'abh', SUCCEED, 'found+\"-\"+g1', 'bh-None'),\n('(bc+d$|ef*g.|h?i(j|k))', 'effgz', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'effgz-effgz-None'),\n('(bc+d$|ef*g.|h?i(j|k))', 'ij', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ij-ij-j'),\n('(bc+d$|ef*g.|h?i(j|k))', 'effg', FAIL),\n('(bc+d$|ef*g.|h?i(j|k))', 'bcdd', FAIL),\n('(bc+d$|ef*g.|h?i(j|k))', 'reffgz', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'effgz-effgz-None'),\n('((((((((((a))))))))))', 'a', SUCCEED, 'g10', 'a'),\n('((((((((((a))))))))))\\\\10', 'aa', SUCCEED, 'found', 'aa'),\n\n\n\n('((((((((((a))))))))))\\\\41', '', SYNTAX_ERROR),\n('(?i)((((((((((a))))))))))\\\\41', '', SYNTAX_ERROR),\n('(((((((((a)))))))))', 'a', SUCCEED, 'found', 'a'),\n('multiple words of text', 'uh-uh', FAIL),\n('multiple words', 'multiple words, yeah', SUCCEED, 'found', 'multiple words'),\n('(.*)c(.*)', 'abcde', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'abcde-ab-de'),\n('\\\\((.*), (.*)\\\\)', '(a, b)', SUCCEED, 'g2+\"-\"+g1', 'b-a'),\n('[k]', 'ab', FAIL),\n('a[-]?c', 'ac', SUCCEED, 'found', 'ac'),\n('(abc)\\\\1', 'abcabc', SUCCEED, 'g1', 'abc'),\n('([a-c]*)\\\\1', 'abcabc', SUCCEED, 'g1', 'abc'),\n('(?i)abc', 'ABC', SUCCEED, 'found', 'ABC'),\n('(?i)abc', 'XBC', FAIL),\n('(?i)abc', 'AXC', FAIL),\n('(?i)abc', 'ABX', FAIL),\n('(?i)abc', 'XABCY', SUCCEED, 'found', 'ABC'),\n('(?i)abc', 'ABABC', SUCCEED, 'found', 'ABC'),\n('(?i)ab*c', 'ABC', SUCCEED, 'found', 'ABC'),\n('(?i)ab*bc', 'ABC', SUCCEED, 'found', 'ABC'),\n('(?i)ab*bc', 'ABBC', SUCCEED, 'found', 'ABBC'),\n('(?i)ab*?bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n('(?i)ab{0,}?bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n('(?i)ab+?bc', 'ABBC', SUCCEED, 'found', 'ABBC'),\n('(?i)ab+bc', 'ABC', FAIL),\n('(?i)ab+bc', 'ABQ', FAIL),\n('(?i)ab{1,}bc', 'ABQ', FAIL),\n('(?i)ab+bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n('(?i)ab{1,}?bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n('(?i)ab{1,3}?bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n('(?i)ab{3,4}?bc', 'ABBBBC', SUCCEED, 'found', 'ABBBBC'),\n('(?i)ab{4,5}?bc', 'ABBBBC', FAIL),\n('(?i)ab??bc', 'ABBC', SUCCEED, 'found', 'ABBC'),\n('(?i)ab??bc', 'ABC', SUCCEED, 'found', 'ABC'),\n('(?i)ab{0,1}?bc', 'ABC', SUCCEED, 'found', 'ABC'),\n('(?i)ab??bc', 'ABBBBC', FAIL),\n('(?i)ab??c', 'ABC', SUCCEED, 'found', 'ABC'),\n('(?i)ab{0,1}?c', 'ABC', SUCCEED, 'found', 'ABC'),\n('(?i)^abc$', 'ABC', SUCCEED, 'found', 'ABC'),\n('(?i)^abc$', 'ABCC', FAIL),\n('(?i)^abc', 'ABCC', SUCCEED, 'found', 'ABC'),\n('(?i)^abc$', 'AABC', FAIL),\n('(?i)abc$', 'AABC', SUCCEED, 'found', 'ABC'),\n('(?i)^', 'ABC', SUCCEED, 'found', ''),\n('(?i)$', 'ABC', SUCCEED, 'found', ''),\n('(?i)a.c', 'ABC', SUCCEED, 'found', 'ABC'),\n('(?i)a.c', 'AXC', SUCCEED, 'found', 'AXC'),\n('(?i)a.*?c', 'AXYZC', SUCCEED, 'found', 'AXYZC'),\n('(?i)a.*c', 'AXYZD', FAIL),\n('(?i)a[bc]d', 'ABC', FAIL),\n('(?i)a[bc]d', 'ABD', SUCCEED, 'found', 'ABD'),\n('(?i)a[b-d]e', 'ABD', FAIL),\n('(?i)a[b-d]e', 'ACE', SUCCEED, 'found', 'ACE'),\n('(?i)a[b-d]', 'AAC', SUCCEED, 'found', 'AC'),\n('(?i)a[-b]', 'A-', SUCCEED, 'found', 'A-'),\n('(?i)a[b-]', 'A-', SUCCEED, 'found', 'A-'),\n('(?i)a[b-a]', '-', SYNTAX_ERROR),\n('(?i)a[]b', '-', SYNTAX_ERROR),\n('(?i)a[', '-', SYNTAX_ERROR),\n('(?i)a]', 'A]', SUCCEED, 'found', 'A]'),\n('(?i)a[]]b', 'A]B', SUCCEED, 'found', 'A]B'),\n('(?i)a[^bc]d', 'AED', SUCCEED, 'found', 'AED'),\n('(?i)a[^bc]d', 'ABD', FAIL),\n('(?i)a[^-b]c', 'ADC', SUCCEED, 'found', 'ADC'),\n('(?i)a[^-b]c', 'A-C', FAIL),\n('(?i)a[^]b]c', 'A]C', FAIL),\n('(?i)a[^]b]c', 'ADC', SUCCEED, 'found', 'ADC'),\n('(?i)ab|cd', 'ABC', SUCCEED, 'found', 'AB'),\n('(?i)ab|cd', 'ABCD', SUCCEED, 'found', 'AB'),\n('(?i)()ef', 'DEF', SUCCEED, 'found+\"-\"+g1', 'EF-'),\n('(?i)*a', '-', SYNTAX_ERROR),\n('(?i)(*)b', '-', SYNTAX_ERROR),\n('(?i)$b', 'B', FAIL),\n('(?i)a\\\\', '-', SYNTAX_ERROR),\n('(?i)a\\\\(b', 'A(B', SUCCEED, 'found+\"-\"+g1', 'A(B-Error'),\n('(?i)a\\\\(*b', 'AB', SUCCEED, 'found', 'AB'),\n('(?i)a\\\\(*b', 'A((B', SUCCEED, 'found', 'A((B'),\n('(?i)a\\\\\\\\b', 'A\\\\B', SUCCEED, 'found', 'A\\\\B'),\n('(?i)abc)', '-', SYNTAX_ERROR),\n('(?i)(abc', '-', SYNTAX_ERROR),\n('(?i)((a))', 'ABC', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'A-A-A'),\n('(?i)(a)b(c)', 'ABC', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ABC-A-C'),\n('(?i)a+b+c', 'AABBABC', SUCCEED, 'found', 'ABC'),\n('(?i)a{1,}b{1,}c', 'AABBABC', SUCCEED, 'found', 'ABC'),\n('(?i)a**', '-', SYNTAX_ERROR),\n('(?i)a.+?c', 'ABCABC', SUCCEED, 'found', 'ABC'),\n('(?i)a.*?c', 'ABCABC', SUCCEED, 'found', 'ABC'),\n('(?i)a.{0,5}?c', 'ABCABC', SUCCEED, 'found', 'ABC'),\n('(?i)(a+|b)*', 'AB', SUCCEED, 'found+\"-\"+g1', 'AB-B'),\n('(?i)(a+|b){0,}', 'AB', SUCCEED, 'found+\"-\"+g1', 'AB-B'),\n('(?i)(a+|b)+', 'AB', SUCCEED, 'found+\"-\"+g1', 'AB-B'),\n('(?i)(a+|b){1,}', 'AB', SUCCEED, 'found+\"-\"+g1', 'AB-B'),\n('(?i)(a+|b)?', 'AB', SUCCEED, 'found+\"-\"+g1', 'A-A'),\n('(?i)(a+|b){0,1}', 'AB', SUCCEED, 'found+\"-\"+g1', 'A-A'),\n('(?i)(a+|b){0,1}?', 'AB', SUCCEED, 'found+\"-\"+g1', '-None'),\n('(?i))(', '-', SYNTAX_ERROR),\n('(?i)[^ab]*', 'CDE', SUCCEED, 'found', 'CDE'),\n('(?i)abc', '', FAIL),\n('(?i)a*', '', SUCCEED, 'found', ''),\n('(?i)([abc])*d', 'ABBBCD', SUCCEED, 'found+\"-\"+g1', 'ABBBCD-C'),\n('(?i)([abc])*bcd', 'ABCD', SUCCEED, 'found+\"-\"+g1', 'ABCD-A'),\n('(?i)a|b|c|d|e', 'E', SUCCEED, 'found', 'E'),\n('(?i)(a|b|c|d|e)f', 'EF', SUCCEED, 'found+\"-\"+g1', 'EF-E'),\n('(?i)abcd*efg', 'ABCDEFG', SUCCEED, 'found', 'ABCDEFG'),\n('(?i)ab*', 'XABYABBBZ', SUCCEED, 'found', 'AB'),\n('(?i)ab*', 'XAYABBBZ', SUCCEED, 'found', 'A'),\n('(?i)(ab|cd)e', 'ABCDE', SUCCEED, 'found+\"-\"+g1', 'CDE-CD'),\n('(?i)[abhgefdc]ij', 'HIJ', SUCCEED, 'found', 'HIJ'),\n('(?i)^(ab|cd)e', 'ABCDE', FAIL),\n('(?i)(abc|)ef', 'ABCDEF', SUCCEED, 'found+\"-\"+g1', 'EF-'),\n('(?i)(a|b)c*d', 'ABCD', SUCCEED, 'found+\"-\"+g1', 'BCD-B'),\n('(?i)(ab|ab*)bc', 'ABC', SUCCEED, 'found+\"-\"+g1', 'ABC-A'),\n('(?i)a([bc]*)c*', 'ABC', SUCCEED, 'found+\"-\"+g1', 'ABC-BC'),\n('(?i)a([bc]*)(c*d)', 'ABCD', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ABCD-BC-D'),\n('(?i)a([bc]+)(c*d)', 'ABCD', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ABCD-BC-D'),\n('(?i)a([bc]*)(c+d)', 'ABCD', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ABCD-B-CD'),\n('(?i)a[bcd]*dcdcde', 'ADCDCDE', SUCCEED, 'found', 'ADCDCDE'),\n('(?i)a[bcd]+dcdcde', 'ADCDCDE', FAIL),\n('(?i)(ab|a)b*c', 'ABC', SUCCEED, 'found+\"-\"+g1', 'ABC-AB'),\n('(?i)((a)(b)c)(d)', 'ABCD', SUCCEED, 'g1+\"-\"+g2+\"-\"+g3+\"-\"+g4', 'ABC-A-B-D'),\n('(?i)[a-zA-Z_][a-zA-Z0-9_]*', 'ALPHA', SUCCEED, 'found', 'ALPHA'),\n('(?i)^a(bc+|b[eh])g|.h$', 'ABH', SUCCEED, 'found+\"-\"+g1', 'BH-None'),\n('(?i)(bc+d$|ef*g.|h?i(j|k))', 'EFFGZ', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'EFFGZ-EFFGZ-None'),\n('(?i)(bc+d$|ef*g.|h?i(j|k))', 'IJ', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'IJ-IJ-J'),\n('(?i)(bc+d$|ef*g.|h?i(j|k))', 'EFFG', FAIL),\n('(?i)(bc+d$|ef*g.|h?i(j|k))', 'BCDD', FAIL),\n('(?i)(bc+d$|ef*g.|h?i(j|k))', 'REFFGZ', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'EFFGZ-EFFGZ-None'),\n('(?i)((((((((((a))))))))))', 'A', SUCCEED, 'g10', 'A'),\n('(?i)((((((((((a))))))))))\\\\10', 'AA', SUCCEED, 'found', 'AA'),\n\n\n('(?i)(((((((((a)))))))))', 'A', SUCCEED, 'found', 'A'),\n('(?i)(?:(?:(?:(?:(?:(?:(?:(?:(?:(a))))))))))', 'A', SUCCEED, 'g1', 'A'),\n('(?i)(?:(?:(?:(?:(?:(?:(?:(?:(?:(a|b|c))))))))))', 'C', SUCCEED, 'g1', 'C'),\n('(?i)multiple words of text', 'UH-UH', FAIL),\n('(?i)multiple words', 'MULTIPLE WORDS, YEAH', SUCCEED, 'found', 'MULTIPLE WORDS'),\n('(?i)(.*)c(.*)', 'ABCDE', SUCCEED, 'found+\"-\"+g1+\"-\"+g2', 'ABCDE-AB-DE'),\n('(?i)\\\\((.*), (.*)\\\\)', '(A, B)', SUCCEED, 'g2+\"-\"+g1', 'B-A'),\n('(?i)[k]', 'AB', FAIL),\n\n\n('(?i)a[-]?c', 'AC', SUCCEED, 'found', 'AC'),\n('(?i)(abc)\\\\1', 'ABCABC', SUCCEED, 'g1', 'ABC'),\n('(?i)([a-c]*)\\\\1', 'ABCABC', SUCCEED, 'g1', 'ABC'),\n('a(?!b).', 'abad', SUCCEED, 'found', 'ad'),\n('a(?=d).', 'abad', SUCCEED, 'found', 'ad'),\n('a(?=c|d).', 'abad', SUCCEED, 'found', 'ad'),\n('a(?:b|c|d)(.)', 'ace', SUCCEED, 'g1', 'e'),\n('a(?:b|c|d)*(.)', 'ace', SUCCEED, 'g1', 'e'),\n('a(?:b|c|d)+?(.)', 'ace', SUCCEED, 'g1', 'e'),\n('a(?:b|(c|e){1,2}?|d)+?(.)', 'ace', SUCCEED, 'g1 + g2', 'ce'),\n('^(.+)?B', 'AB', SUCCEED, 'g1', 'A'),\n\n\n('(?<!-):(.*?)(?<!-):', 'a:bc-:de:f', SUCCEED, 'g1', 'bc-:de' ),\n\n('(?<!\\\\\\):(.*?)(?<!\\\\\\):', 'a:bc\\\\:de:f', SUCCEED, 'g1', 'bc\\\\:de' ),\n\n(\"(?<!\\\\?)'(.*?)(?<!\\\\?)'\", \"a'bc?'de'f\", SUCCEED, 'g1', \"bc?'de\" ),\n\n\n\n('w(?# comment', 'w', SYNTAX_ERROR),\n('w(?# comment 1)xy(?# comment 2)z', 'wxyz', SUCCEED, 'found', 'wxyz'),\n\n\n\n\n('w(?i)', 'W', SUCCEED, 'found', 'W'),\n\n\n\n\n(\"\"\"(?x)w# comment 1\n        x y\n        # comment 2\n        z\"\"\", 'wxyz', SUCCEED, 'found', 'wxyz'),\n\n\n\n('^abc', \"\"\"jkl\nabc\nxyz\"\"\", FAIL),\n('(?m)^abc', \"\"\"jkl\nabc\nxyz\"\"\", SUCCEED, 'found', 'abc'),\n\n('(?m)abc$', \"\"\"jkl\nxyzabc\n123\"\"\", SUCCEED, 'found', 'abc'),\n\n\n\n('a.b', 'a\\nb', FAIL),\n('(?s)a.b', 'a\\nb', SUCCEED, 'found', 'a\\nb'),\n\n\n\n('\\\\w+', '--ab_cd0123--', SUCCEED, 'found', 'ab_cd0123'),\n('[\\\\w]+', '--ab_cd0123--', SUCCEED, 'found', 'ab_cd0123'),\n('\\\\D+', '1234abc5678', SUCCEED, 'found', 'abc'),\n('[\\\\D]+', '1234abc5678', SUCCEED, 'found', 'abc'),\n('[\\\\da-fA-F]+', '123abc', SUCCEED, 'found', '123abc'),\n\n\n(r'([\\s]*)([\\S]*)([\\s]*)', ' testing!1972', SUCCEED, 'g3+g2+g1', 'testing!1972 '),\n(r'(\\s*)(\\S*)(\\s*)', ' testing!1972', SUCCEED, 'g3+g2+g1', 'testing!1972 '),\n\n(r'\\xff', '\\377', SUCCEED, 'found', chr(255)),\n\n(r'\\x00ff', '\\377', FAIL),\n\n(r'\\t\\n\\v\\r\\f\\a\\g', '\\t\\n\\v\\r\\f\\ag', SUCCEED, 'found', '\\t\\n\\v\\r\\f\\ag'),\n('\\t\\n\\v\\r\\f\\a\\g', '\\t\\n\\v\\r\\f\\ag', SUCCEED, 'found', '\\t\\n\\v\\r\\f\\ag'),\n(r'\\t\\n\\v\\r\\f\\a', '\\t\\n\\v\\r\\f\\a', SUCCEED, 'found', chr(9)+chr(10)+chr(11)+chr(13)+chr(12)+chr(7)),\n(r'[\\t][\\n][\\v][\\r][\\f][\\b]', '\\t\\n\\v\\r\\f\\b', SUCCEED, 'found', '\\t\\n\\v\\r\\f\\b'),\n\n\n\n\n\n(r'(([a-z]+):)?([a-z]+)$', 'smil', SUCCEED, 'g1+\"-\"+g2+\"-\"+g3', 'None-None-smil'),\n\n(r'((.)\\1+)', '', SYNTAX_ERROR),\n\n(r'.*d', 'abc\\nabd', SUCCEED, 'found', 'abd'),\n\n(r'(', '', SYNTAX_ERROR),\n(r'[\\41]', '!', SUCCEED, 'found', '!'),\n\n(r'(x?)?', 'x', SUCCEED, 'found', 'x'),\n\n(r' (?x)foo ', 'foo', SUCCEED, 'found', 'foo'),\n\n(r'(?<!abc)(d.f)', 'abcdefdof', SUCCEED, 'found', 'dof'),\n\n(r'[\\w-]+', 'laser_beam', SUCCEED, 'found', 'laser_beam'),\n\n(r'.*?\\S *:', 'xx:', SUCCEED, 'found', 'xx:'),\n(r'a[ ]*?\\ (\\d+).*', 'a   10', SUCCEED, 'found', 'a   10'),\n(r'a[ ]*?\\ (\\d+).*', 'a    10', SUCCEED, 'found', 'a    10'),\n\n(r'(?ms).*?x\\s*\\Z(.*)','xx\\nx\\n', SUCCEED, 'g1', ''),\n\n(r'(?i)M+', 'MMM', SUCCEED, 'found', 'MMM'),\n(r'(?i)m+', 'MMM', SUCCEED, 'found', 'MMM'),\n(r'(?i)[M]+', 'MMM', SUCCEED, 'found', 'MMM'),\n(r'(?i)[m]+', 'MMM', SUCCEED, 'found', 'MMM'),\n\n(r'^*', '', SYNTAX_ERROR),\n\n(r'\"(?:\\\\\"|[^\"])*?\"', r'\"\\\"\"', SUCCEED, 'found', r'\"\\\"\"'),\n\n(r'^.*?$', 'one\\ntwo\\nthree\\n', FAIL),\n\n(r'a[^>]*?b', 'a>b', FAIL),\n\n(r'^a*?$', 'foo', FAIL),\n\n(r'^((a)c)?(ab)$', 'ab', SUCCEED, 'g1+\"-\"+g2+\"-\"+g3', 'None-None-ab'),\n\n('^([ab]*?)(?=(b)?)c', 'abc', SUCCEED, 'g1+\"-\"+g2', 'ab-None'),\n('^([ab]*?)(?!(b))c', 'abc', SUCCEED, 'g1+\"-\"+g2', 'ab-None'),\n('^([ab]*?)(?<!(a))c', 'abc', SUCCEED, 'g1+\"-\"+g2', 'ab-None'),\n]\n\nu = '\\N{LATIN CAPITAL LETTER A WITH DIAERESIS}'\ntests.extend([\n\n(r'\\b.\\b', 'a', SUCCEED, 'found', 'a'),\n(r'(?u)\\b.\\b', u, SUCCEED, 'found', u),\n(r'(?u)\\w', u, SUCCEED, 'found', u),\n])\n"], "multiprocessing": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n__version__ = '0.70a1'\n\n__all__ = [\n'Process', 'current_process', 'active_children', 'freeze_support',\n'Manager', 'Pipe', 'cpu_count', 'log_to_stderr', 'get_logger',\n'allow_connection_pickling', 'BufferTooShort', 'TimeoutError',\n'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Condition',\n'Event', 'Barrier', 'Queue', 'SimpleQueue', 'JoinableQueue', 'Pool',\n'Value', 'Array', 'RawValue', 'RawArray', 'SUBDEBUG', 'SUBWARNING',\n]\n\n__author__ = 'R. Oudkerk (r.m.oudkerk@gmail.com)'\n\n\n\n\n\nimport os\nimport sys\n\nfrom multiprocessing.process import Process, current_process, active_children\nfrom multiprocessing.util import SUBDEBUG, SUBWARNING\n\n\n\n\n\nclass ProcessError(Exception):\n pass\n \nclass BufferTooShort(ProcessError):\n pass\n \nclass TimeoutError(ProcessError):\n pass\n \nclass AuthenticationError(ProcessError):\n pass\n \nimport _multiprocessing\n\n\n\n\n\ndef Manager():\n \"\"\n from multiprocessing.managers import SyncManager\n m = SyncManager()\n m.start()\n return m\n \n \n \n \n \n \n \n \n \ndef cpu_count():\n \"\"\n if sys.platform == 'win32':\n  try:\n   num = int(os.environ['NUMBER_OF_PROCESSORS'])\n  except (ValueError, KeyError):\n   num = 0\n elif 'bsd' in sys.platform or sys.platform == 'darwin':\n  comm = '/sbin/sysctl -n hw.ncpu'\n  if sys.platform == 'darwin':\n   comm = '/usr' + comm\n  try:\n   with os.popen(comm) as p:\n    num = int(p.read())\n  except ValueError:\n   num = 0\n else:\n  try:\n   num = os.sysconf('SC_NPROCESSORS_ONLN')\n  except (ValueError, OSError, AttributeError):\n   num = 0\n   \n if num >= 1:\n  return num\n else:\n  raise NotImplementedError('cannot determine number of cpus')\n  \ndef freeze_support():\n \"\"\n if sys.platform == 'win32' and getattr(sys, 'frozen', False):\n  from multiprocessing.forking import freeze_support\n  freeze_support()\n  \ndef get_logger():\n \"\"\n from multiprocessing.util import get_logger\n return get_logger()\n \ndef log_to_stderr(level=None):\n \"\"\n from multiprocessing.util import log_to_stderr\n return log_to_stderr(level)\n \n \n \n \n \n \n \n \n \n \n \n \n \n \ndef Lock():\n \"\"\n from multiprocessing.synchronize import Lock\n return Lock()\n \ndef RLock():\n \"\"\n from multiprocessing.synchronize import RLock\n return RLock()\n \ndef Condition(lock=None):\n \"\"\n from multiprocessing.synchronize import Condition\n return Condition(lock)\n \ndef Semaphore(value=1):\n \"\"\n from multiprocessing.synchronize import Semaphore\n return Semaphore(value)\n \ndef BoundedSemaphore(value=1):\n \"\"\n from multiprocessing.synchronize import BoundedSemaphore\n return BoundedSemaphore(value)\n \ndef Event():\n \"\"\n from multiprocessing.synchronize import Event\n return Event()\n \ndef Barrier(parties, action=None, timeout=None):\n \"\"\n from multiprocessing.synchronize import Barrier\n return Barrier(parties, action, timeout)\n \ndef Queue(maxsize=0):\n \"\"\n from multiprocessing.queues import Queue\n return Queue(maxsize)\n \ndef JoinableQueue(maxsize=0):\n \"\"\n from multiprocessing.queues import JoinableQueue\n return JoinableQueue(maxsize)\n \ndef SimpleQueue():\n \"\"\n from multiprocessing.queues import SimpleQueue\n return SimpleQueue()\n \ndef Pool(processes=None, initializer=None, initargs=(), maxtasksperchild=None):\n \"\"\n from multiprocessing.pool import Pool\n return Pool(processes, initializer, initargs, maxtasksperchild)\n \ndef RawValue(typecode_or_type, *args):\n \"\"\n from multiprocessing.sharedctypes import RawValue\n return RawValue(typecode_or_type, *args)\n \ndef RawArray(typecode_or_type, size_or_initializer):\n \"\"\n from multiprocessing.sharedctypes import RawArray\n return RawArray(typecode_or_type, size_or_initializer)\n \ndef Value(typecode_or_type, *args, lock=True):\n \"\"\n from multiprocessing.sharedctypes import Value\n return Value(typecode_or_type, *args, lock=lock)\n \ndef Array(typecode_or_type, size_or_initializer, *, lock=True):\n \"\"\n from multiprocessing.sharedctypes import Array\n return Array(typecode_or_type, size_or_initializer, lock=lock)\n \n \n \n \n \nif sys.platform == 'win32':\n\n def set_executable(executable):\n  \"\"\n  from multiprocessing.forking import set_executable\n  set_executable(executable)\n  \n __all__ += ['set_executable']\n", 1], "queue": [".py", "\"\"\n\ntry:\n import threading\nexcept ImportError:\n import dummy_threading as threading\nfrom collections import deque\nfrom heapq import heappush, heappop\ntry:\n from time import monotonic as time\nexcept ImportError:\n from time import time\n \n__all__ = ['Empty', 'Full', 'Queue', 'PriorityQueue', 'LifoQueue']\n\nclass Empty(Exception):\n \"\"\n pass\n \nclass Full(Exception):\n \"\"\n pass\n \nclass Queue:\n \"\"\n \n def __init__(self, maxsize=0):\n  self.maxsize = maxsize\n  self._init(maxsize)\n  \n  \n  \n  \n  \n  self.mutex = threading.Lock()\n  \n  \n  \n  self.not_empty = threading.Condition(self.mutex)\n  \n  \n  \n  self.not_full = threading.Condition(self.mutex)\n  \n  \n  \n  self.all_tasks_done = threading.Condition(self.mutex)\n  self.unfinished_tasks = 0\n  \n def task_done(self):\n  \"\"\n  with self.all_tasks_done:\n   unfinished = self.unfinished_tasks - 1\n   if unfinished <= 0:\n    if unfinished < 0:\n     raise ValueError('task_done() called too many times')\n    self.all_tasks_done.notify_all()\n   self.unfinished_tasks = unfinished\n   \n def join(self):\n  \"\"\n  with self.all_tasks_done:\n   while self.unfinished_tasks:\n    self.all_tasks_done.wait()\n    \n def qsize(self):\n  \"\"\n  with self.mutex:\n   return self._qsize()\n   \n def empty(self):\n  \"\"\n  with self.mutex:\n   return not self._qsize()\n   \n def full(self):\n  \"\"\n  with self.mutex:\n   return 0 < self.maxsize <= self._qsize()\n   \n def put(self, item, block=True, timeout=None):\n  \"\"\n  with self.not_full:\n   if self.maxsize > 0:\n    if not block:\n     if self._qsize() >= self.maxsize:\n      raise Full\n    elif timeout is None:\n     while self._qsize() >= self.maxsize:\n      self.not_full.wait()\n    elif timeout < 0:\n     raise ValueError(\"'timeout' must be a non-negative number\")\n    else:\n     endtime = time() + timeout\n     while self._qsize() >= self.maxsize:\n      remaining = endtime - time()\n      if remaining <= 0.0:\n       raise Full\n      self.not_full.wait(remaining)\n   self._put(item)\n   self.unfinished_tasks += 1\n   self.not_empty.notify()\n   \n def get(self, block=True, timeout=None):\n  \"\"\n  with self.not_empty:\n   if not block:\n    if not self._qsize():\n     raise Empty\n   elif timeout is None:\n    while not self._qsize():\n     self.not_empty.wait()\n   elif timeout < 0:\n    raise ValueError(\"'timeout' must be a non-negative number\")\n   else:\n    endtime = time() + timeout\n    while not self._qsize():\n     remaining = endtime - time()\n     if remaining <= 0.0:\n      raise Empty\n     self.not_empty.wait(remaining)\n   item = self._get()\n   self.not_full.notify()\n   return item\n   \n def put_nowait(self, item):\n  \"\"\n  return self.put(item, block=False)\n  \n def get_nowait(self):\n  \"\"\n  return self.get(block=False)\n  \n  \n  \n  \n  \n  \n def _init(self, maxsize):\n  self.queue = deque()\n  \n def _qsize(self):\n  return len(self.queue)\n  \n  \n def _put(self, item):\n  self.queue.append(item)\n  \n  \n def _get(self):\n  return self.queue.popleft()\n  \n  \nclass PriorityQueue(Queue):\n \"\"\n \n def _init(self, maxsize):\n  self.queue = []\n  \n def _qsize(self):\n  return len(self.queue)\n  \n def _put(self, item):\n  heappush(self.queue, item)\n  \n def _get(self):\n  return heappop(self.queue)\n  \n  \nclass LifoQueue(Queue):\n \"\"\n \n def _init(self, maxsize):\n  self.queue = []\n  \n def _qsize(self):\n  return len(self.queue)\n  \n def _put(self, item):\n  self.queue.append(item)\n  \n def _get(self):\n  return self.queue.pop()\n"], "itertools": [".py", "import operator\n\nclass accumulate:\n def __init__(self, iterable, func = operator.add):\n  self.it = iter(iterable)\n  self._total = None\n  self.func = func\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  if not self._total:\n   self._total = next(self.it)\n   return self._total\n  else:\n   element = next(self.it)\n   try:\n    self._total = self.func(self._total, element)\n   except:\n    raise TypeError(\"unsupported operand type\")\n   return self._total\n   \n   \n   \nclass chain:\n def __init__(self, *iterables):\n  self._iterables_iter = iter(map(iter, iterables))\n  \n  self._cur_iterable_iter = iter([])\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  while True:\n   try:\n    return next(self._cur_iterable_iter)\n   except StopIteration:\n    self._cur_iterable_iter = next(self._iterables_iter)\n    \n @classmethod\n def from_iterable(cls, iterable):\n  for it in iterable:\n   for element in it:\n    yield element\n    \nclass combinations:\n def __init__(self, iterable, r):\n  self.pool = tuple(iterable)\n  self.n = len(self.pool)\n  self.r = r\n  self.indices = list(range(self.r))\n  self.zero = False\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  if self.r > self.n:\n   raise StopIteration\n  if not self.zero:\n   self.zero = True\n   return tuple(self.pool[i] for i in self.indices)\n  else:\n   try:\n    for i in reversed(range(self.r)):\n     if self.indices[i] != i + self.n - self.r:\n      break\n    self.indices[i] += 1\n    for j in range(i+1, self.r):\n     self.indices[j] = self.indices[j-1] + 1\n    return tuple(self.pool[i] for i in self.indices)\n   except:\n    raise StopIteration\n    \nclass combinations_with_replacement:\n def __init__(self, iterable, r):\n  self.pool = tuple(iterable)\n  self.n = len(self.pool)\n  self.r = r\n  self.indices = [0] * self.r\n  self.zero = False\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  if not self.n and self.r:\n   raise StopIteration\n  if not self.zero:\n   self.zero = True\n   return tuple(self.pool[i] for i in self.indices)\n  else:\n   try:\n    for i in reversed(range(self.r)):\n     if self.indices[i] != self.n - 1:\n      break\n    self.indices[i:] = [self.indices[i] + 1] * (self.r - i)\n    return tuple(self.pool[i] for i in self.indices)\n   except:\n    raise StopIteration\n    \n    \n    \nclass compress:\n def __init__(self, data, selectors):\n  self.data = iter(data)\n  self.selectors = iter(selectors)\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  while True:\n   next_item = next(self.data)\n   next_selector = next(self.selectors)\n   if bool(next_selector):\n    return next_item\n    \n    \n    \n    \nclass count:\n \"\"\n def __init__(self, start = 0, step = 1):\n  if not isinstance(start, (int, float)):\n   raise TypeError('a number is required')\n  self.times = start - step\n  self.step = step\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  self.times += self.step\n  return self.times\n  \n def __repr__(self):\n  return 'count(%d)' % (self.times + self.step)\n  \n  \n  \nclass cycle:\n def __init__(self, iterable):\n  self._cur_iter = iter(iterable)\n  self._saved = []\n  self._must_save = True\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  try:\n   next_elt = next(self._cur_iter)\n   if self._must_save:\n    self._saved.append(next_elt)\n  except StopIteration:\n   self._cur_iter = iter(self._saved)\n   next_elt = next(self._cur_iter)\n   self._must_save = False\n  return next_elt\n  \n  \n  \nclass dropwhile:\n def __init__(self, predicate, iterable):\n  self._predicate = predicate\n  self._iter = iter(iterable)\n  self._dropped = False\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  value = next(self._iter)\n  if self._dropped:\n   return value\n  while self._predicate(value):\n   value = next(self._iter)\n  self._dropped = True\n  return value\n  \n  \n  \nclass filterfalse:\n def __init__(self, predicate, iterable):\n \n  self._iter = iter(iterable)\n  if predicate is None:\n   self._predicate = bool\n  else:\n   self._predicate = predicate\n   \n def __iter__(self):\n  return self\n def __next__(self):\n  next_elt = next(self._iter)\n  while True:\n   if not self._predicate(next_elt):\n    return next_elt\n   next_elt = next(self._iter)\n   \nclass groupby:\n\n\n def __init__(self, iterable, key=None):\n  if key is None:\n   key = lambda x: x\n  self.keyfunc = key\n  self.it = iter(iterable)\n  self.tgtkey = self.currkey = self.currvalue = object()\n def __iter__(self):\n  return self\n def __next__(self):\n  while self.currkey == self.tgtkey:\n   self.currvalue = next(self.it) \n   self.currkey = self.keyfunc(self.currvalue)\n  self.tgtkey = self.currkey\n  return (self.currkey, self._grouper(self.tgtkey))\n def _grouper(self, tgtkey):\n  while self.currkey == tgtkey:\n   yield self.currvalue\n   self.currvalue = next(self.it) \n   self.currkey = self.keyfunc(self.currvalue)\n   \n   \n   \nclass islice:\n def __init__(self, iterable, *args):\n  s = slice(*args)\n  self.start, self.stop, self.step = s.start or 0, s.stop, s.step\n  if not isinstance(self.start, int):\n   raise ValueError(\"Start argument must be an integer\")\n  if self.stop != None and not isinstance(self.stop, int):\n   raise ValueError(\"Stop argument must be an integer or None\")\n  if self.step is None:\n   self.step = 1\n  if self.start<0 or (self.stop != None and self.stop<0\n  ) or self.step<=0:\n   raise ValueError(\"indices for islice() must be positive\")\n  self.it = iter(iterable)\n  self.donext = None\n  self.cnt = 0\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  nextindex = self.start\n  if self.stop != None and nextindex >= self.stop:\n   raise StopIteration\n  while self.cnt <= nextindex:\n   nextitem = next(self.it)\n   self.cnt += 1\n  self.start += self.step \n  return nextitem\n  \nclass permutations:\n def __init__(self, iterable, r = None):\n  self.pool = tuple(iterable)\n  self.n = len(self.pool)\n  self.r = self.n if r is None else r\n  self.indices = list(range(self.n))\n  self.cycles = list(range(self.n, self.n - self.r, -1))\n  self.zero = False\n  self.stop = False\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  indices = self.indices\n  if self.r > self.n:\n   raise StopIteration\n  if not self.zero:\n   self.zero = True\n   return tuple(self.pool[i] for i in indices[:self.r])\n   \n  i = self.r - 1\n  while i >= 0:\n   j = self.cycles[i] - 1\n   if j > 0:\n    self.cycles[i] = j\n    indices[i], indices[-j] = indices[-j], indices[i]\n    return tuple(self.pool[i] for i in indices[:self.r])\n   self.cycles[i] = len(indices) - i\n   n1 = len(indices) - 1\n   assert n1 >= 0\n   num = indices[i]\n   for k in range(i, n1):\n    indices[k] = indices[k+1]\n   indices[n1] = num\n   i -= 1\n  raise StopIteration\n  \n  \ndef product(*args, repeat=1):\n\n\n pools = [tuple(pool) for pool in args] * repeat\n result = [[]]\n for pool in pools:\n  result = [x+[y] for x in result for y in pool]\n for prod in result:\n  yield tuple(prod)\n  \n  \n  \n  \n  \n  \n  \n  \nclass _product:\n def __init__(self, *args, **kw):\n  if len(kw) > 1:\n   raise TypeError(\"product() takes at most 1 argument (%d given)\" %\n   len(kw))\n  self.repeat = kw.get('repeat', 1)\n  if not isinstance(self.repeat, int):\n   raise TypeError(\"integer argument expected, got %s\" %\n   type(self.repeat))\n  self.gears = [x for x in args] * self.repeat\n  self.num_gears = len(self.gears)\n  \n  self.indicies = [(0, len(self.gears[x]))\n  for x in range(0, self.num_gears)]\n  self.cont = True\n  self.zero = False\n  \n def roll_gears(self):\n \n \n \n  should_carry = True\n  for n in range(0, self.num_gears):\n   nth_gear = self.num_gears - n - 1\n   if should_carry:\n    count, lim = self.indicies[nth_gear]\n    count += 1\n    if count == lim and nth_gear == 0:\n     self.cont = False\n    if count == lim:\n     should_carry = True\n     count = 0\n    else:\n     should_carry = False\n    self.indicies[nth_gear] = (count, lim) \n   else:\n    break\n    \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  if self.zero:\n   raise StopIteration\n  if self.repeat > 0:\n   if not self.cont:\n    raise StopIteration\n   l = []\n   for x in range(0, self.num_gears):\n    index, limit = self.indicies[x]\n    print('itertools 353',self.gears,x,index)\n    l.append(self.gears[x][index])\n   self.roll_gears()\n   return tuple(l)\n  elif self.repeat == 0:\n   self.zero = True\n   return ()\n  else:\n   raise ValueError(\"repeat argument cannot be negative\")\n   \n   \n   \nclass repeat:\n def __init__(self, obj, times=None):\n  self._obj = obj\n  if times is not None:\n   range(times) \n   if times < 0:\n    times = 0\n  self._times = times\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n \n  if self._times is not None:\n   if self._times <= 0: \n    raise StopIteration()\n   self._times -= 1\n  return self._obj\n  \n def __repr__(self):\n  if self._times is not None:\n   return 'repeat(%r, %r)' % (self._obj, self._times)\n  else:\n   return 'repeat(%r)' % (self._obj,)\n   \n def __len__(self):\n  if self._times == -1 or self._times is None:\n   raise TypeError(\"len() of uniszed object\")\n  return self._times\n  \n  \n  \nclass starmap(object):\n def __init__(self, function, iterable):\n  self._func = function\n  self._iter = iter(iterable)\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  t = next(self._iter)\n  return self._func(*t)\n  \n  \n  \nclass takewhile(object):\n def __init__(self, predicate, iterable):\n  self._predicate = predicate\n  self._iter = iter(iterable)\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  value = next(self._iter)\n  if not self._predicate(value):\n   raise StopIteration()\n  return value\n  \n  \n  \nclass TeeData(object):\n def __init__(self, iterator):\n  self.data = []\n  self._iter = iterator\n  \n def __getitem__(self, i):\n \n  while i>= len(self.data):\n   self.data.append(next(self._iter))\n  return self.data[i]\n  \n  \nclass TeeObject(object):\n def __init__(self, iterable=None, tee_data=None):\n  if tee_data:\n   self.tee_data = tee_data\n   self.pos = 0\n   \n  elif isinstance(iterable, TeeObject):\n   self.tee_data = iterable.tee_data\n   self.pos = iterable.pos\n  else:\n   self.tee_data = TeeData(iter(iterable))\n   self.pos = 0\n   \n def __next__(self):\n  data = self.tee_data[self.pos]\n  self.pos += 1\n  return data\n  \n def __iter__(self):\n  return self\n  \n  \ndef tee(iterable, n=2):\n if isinstance(iterable, TeeObject):\n  return tuple([iterable] +\n  [TeeObject(tee_data=iterable.tee_data) for i in range(n - 1)])\n tee_data = TeeData(iter(iterable))\n return tuple([TeeObject(tee_data=tee_data) for i in range(n)])\n \nclass zip_longest:\n def __init__(self, *args, fillvalue = None):\n  self.args = args\n  self.fillvalue = fillvalue\n  self.max_length = max([len(arg) for arg in self.args])\n  self.units = len(args)\n  self.counter = 0\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  if self.counter == self.max_length:\n   raise StopIteration\n  else:\n   temp = []\n   for i in range(self.units):\n    try:\n     temp.append(self.args[i][self.counter])\n    except:\n     temp.append(self.fillvalue)\n   self.counter = self.counter + 1\n   return tuple(temp)\n"], "crypto_js.rollups.md5": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(s,p){var m={},l=m.lib={},n=function(){},r=l.Base={extend:function(b){n.prototype=this;var h=new n;b&&h.mixIn(b);h.hasOwnProperty(\"init\")||(h.init=function(){h.$super.init.apply(this,arguments)});h.init.prototype=h;h.$super=this;return h},create:function(){var b=this.extend();b.init.apply(b,arguments);return b},init:function(){},mixIn:function(b){for(var h in b)b.hasOwnProperty(h)&&(this[h]=b[h]);b.hasOwnProperty(\"toString\")&&(this.toString=b.toString)},clone:function(){return this.init.prototype.extend(this)}},\nq=l.WordArray=r.extend({init:function(b,h){b=this.words=b||[];this.sigBytes=h!=p?h:4*b.length},toString:function(b){return(b||t).stringify(this)},concat:function(b){var h=this.words,a=b.words,j=this.sigBytes;b=b.sigBytes;this.clamp();if(j%4)for(var g=0;g<b;g++)h[j+g>>>2]|=(a[g>>>2]>>>24-8*(g%4)&255)<<24-8*((j+g)%4);else if(65535<a.length)for(g=0;g<b;g+=4)h[j+g>>>2]=a[g>>>2];else h.push.apply(h,a);this.sigBytes+=b;return this},clamp:function(){var b=this.words,h=this.sigBytes;b[h>>>2]&=4294967295<<\n32-8*(h%4);b.length=s.ceil(h/4)},clone:function(){var b=r.clone.call(this);b.words=this.words.slice(0);return b},random:function(b){for(var h=[],a=0;a<b;a+=4)h.push(4294967296*s.random()|0);return new q.init(h,b)}}),v=m.enc={},t=v.Hex={stringify:function(b){var a=b.words;b=b.sigBytes;for(var g=[],j=0;j<b;j++){var k=a[j>>>2]>>>24-8*(j%4)&255;g.push((k>>>4).toString(16));g.push((k&15).toString(16))}return g.join(\"\")},parse:function(b){for(var a=b.length,g=[],j=0;j<a;j+=2)g[j>>>3]|=parseInt(b.substr(j,\n2),16)<<24-4*(j%8);return new q.init(g,a/2)}},a=v.Latin1={stringify:function(b){var a=b.words;b=b.sigBytes;for(var g=[],j=0;j<b;j++)g.push(String.fromCharCode(a[j>>>2]>>>24-8*(j%4)&255));return g.join(\"\")},parse:function(b){for(var a=b.length,g=[],j=0;j<a;j++)g[j>>>2]|=(b.charCodeAt(j)&255)<<24-8*(j%4);return new q.init(g,a)}},u=v.Utf8={stringify:function(b){try{return decodeURIComponent(escape(a.stringify(b)))}catch(g){throw Error(\"Malformed UTF-8 data\");}},parse:function(b){return a.parse(unescape(encodeURIComponent(b)))}},\ng=l.BufferedBlockAlgorithm=r.extend({reset:function(){this._data=new q.init;this._nDataBytes=0},_append:function(b){\"string\"==typeof b&&(b=u.parse(b));this._data.concat(b);this._nDataBytes+=b.sigBytes},_process:function(b){var a=this._data,g=a.words,j=a.sigBytes,k=this.blockSize,m=j/(4*k),m=b?s.ceil(m):s.max((m|0)-this._minBufferSize,0);b=m*k;j=s.min(4*b,j);if(b){for(var l=0;l<b;l+=k)this._doProcessBlock(g,l);l=g.splice(0,b);a.sigBytes-=j}return new q.init(l,j)},clone:function(){var b=r.clone.call(this);\nb._data=this._data.clone();return b},_minBufferSize:0});l.Hasher=g.extend({cfg:r.extend(),init:function(b){this.cfg=this.cfg.extend(b);this.reset()},reset:function(){g.reset.call(this);this._doReset()},update:function(b){this._append(b);this._process();return this},finalize:function(b){b&&this._append(b);return this._doFinalize()},blockSize:16,_createHelper:function(b){return function(a,g){return(new b.init(g)).finalize(a)}},_createHmacHelper:function(b){return function(a,g){return(new k.HMAC.init(b,\ng)).finalize(a)}}});var k=m.algo={};return m}(Math);\n(function(s){function p(a,k,b,h,l,j,m){a=a+(k&b|~k&h)+l+m;return(a<<j|a>>>32-j)+k}function m(a,k,b,h,l,j,m){a=a+(k&h|b&~h)+l+m;return(a<<j|a>>>32-j)+k}function l(a,k,b,h,l,j,m){a=a+(k^b^h)+l+m;return(a<<j|a>>>32-j)+k}function n(a,k,b,h,l,j,m){a=a+(b^(k|~h))+l+m;return(a<<j|a>>>32-j)+k}for(var r=CryptoJS,q=r.lib,v=q.WordArray,t=q.Hasher,q=r.algo,a=[],u=0;64>u;u++)a[u]=4294967296*s.abs(s.sin(u+1))|0;q=q.MD5=t.extend({_doReset:function(){this._hash=new v.init([1732584193,4023233417,2562383102,271733878])},\n_doProcessBlock:function(g,k){for(var b=0;16>b;b++){var h=k+b,w=g[h];g[h]=(w<<8|w>>>24)&16711935|(w<<24|w>>>8)&4278255360}var b=this._hash.words,h=g[k+0],w=g[k+1],j=g[k+2],q=g[k+3],r=g[k+4],s=g[k+5],t=g[k+6],u=g[k+7],v=g[k+8],x=g[k+9],y=g[k+10],z=g[k+11],A=g[k+12],B=g[k+13],C=g[k+14],D=g[k+15],c=b[0],d=b[1],e=b[2],f=b[3],c=p(c,d,e,f,h,7,a[0]),f=p(f,c,d,e,w,12,a[1]),e=p(e,f,c,d,j,17,a[2]),d=p(d,e,f,c,q,22,a[3]),c=p(c,d,e,f,r,7,a[4]),f=p(f,c,d,e,s,12,a[5]),e=p(e,f,c,d,t,17,a[6]),d=p(d,e,f,c,u,22,a[7]),\nc=p(c,d,e,f,v,7,a[8]),f=p(f,c,d,e,x,12,a[9]),e=p(e,f,c,d,y,17,a[10]),d=p(d,e,f,c,z,22,a[11]),c=p(c,d,e,f,A,7,a[12]),f=p(f,c,d,e,B,12,a[13]),e=p(e,f,c,d,C,17,a[14]),d=p(d,e,f,c,D,22,a[15]),c=m(c,d,e,f,w,5,a[16]),f=m(f,c,d,e,t,9,a[17]),e=m(e,f,c,d,z,14,a[18]),d=m(d,e,f,c,h,20,a[19]),c=m(c,d,e,f,s,5,a[20]),f=m(f,c,d,e,y,9,a[21]),e=m(e,f,c,d,D,14,a[22]),d=m(d,e,f,c,r,20,a[23]),c=m(c,d,e,f,x,5,a[24]),f=m(f,c,d,e,C,9,a[25]),e=m(e,f,c,d,q,14,a[26]),d=m(d,e,f,c,v,20,a[27]),c=m(c,d,e,f,B,5,a[28]),f=m(f,c,\nd,e,j,9,a[29]),e=m(e,f,c,d,u,14,a[30]),d=m(d,e,f,c,A,20,a[31]),c=l(c,d,e,f,s,4,a[32]),f=l(f,c,d,e,v,11,a[33]),e=l(e,f,c,d,z,16,a[34]),d=l(d,e,f,c,C,23,a[35]),c=l(c,d,e,f,w,4,a[36]),f=l(f,c,d,e,r,11,a[37]),e=l(e,f,c,d,u,16,a[38]),d=l(d,e,f,c,y,23,a[39]),c=l(c,d,e,f,B,4,a[40]),f=l(f,c,d,e,h,11,a[41]),e=l(e,f,c,d,q,16,a[42]),d=l(d,e,f,c,t,23,a[43]),c=l(c,d,e,f,x,4,a[44]),f=l(f,c,d,e,A,11,a[45]),e=l(e,f,c,d,D,16,a[46]),d=l(d,e,f,c,j,23,a[47]),c=n(c,d,e,f,h,6,a[48]),f=n(f,c,d,e,u,10,a[49]),e=n(e,f,c,d,\nC,15,a[50]),d=n(d,e,f,c,s,21,a[51]),c=n(c,d,e,f,A,6,a[52]),f=n(f,c,d,e,q,10,a[53]),e=n(e,f,c,d,y,15,a[54]),d=n(d,e,f,c,w,21,a[55]),c=n(c,d,e,f,v,6,a[56]),f=n(f,c,d,e,D,10,a[57]),e=n(e,f,c,d,t,15,a[58]),d=n(d,e,f,c,B,21,a[59]),c=n(c,d,e,f,r,6,a[60]),f=n(f,c,d,e,z,10,a[61]),e=n(e,f,c,d,j,15,a[62]),d=n(d,e,f,c,x,21,a[63]);b[0]=b[0]+c|0;b[1]=b[1]+d|0;b[2]=b[2]+e|0;b[3]=b[3]+f|0},_doFinalize:function(){var a=this._data,k=a.words,b=8*this._nDataBytes,h=8*a.sigBytes;k[h>>>5]|=128<<24-h%32;var l=s.floor(b/\n4294967296);k[(h+64>>>9<<4)+15]=(l<<8|l>>>24)&16711935|(l<<24|l>>>8)&4278255360;k[(h+64>>>9<<4)+14]=(b<<8|b>>>24)&16711935|(b<<24|b>>>8)&4278255360;a.sigBytes=4*(k.length+1);this._process();a=this._hash;k=a.words;for(b=0;4>b;b++)h=k[b],k[b]=(h<<8|h>>>24)&16711935|(h<<24|h>>>8)&4278255360;return a},clone:function(){var a=t.clone.call(this);a._hash=this._hash.clone();return a}});r.MD5=t._createHelper(q);r.HmacMD5=t._createHmacHelper(q)})(Math);\n"], "_posixsubprocess": [".js", "var $module=(function($B){\n\n    return {\n       cloexec_pipe: function() {}   // fixme\n    }\n})(__BRYTHON__)\n"], "multiprocessing.util": [".py", "\n\n\n\n\n\n\n\n\nimport sys\nimport functools\nimport os\nimport itertools\nimport weakref\nimport atexit\nimport threading \n\nfrom subprocess import _args_from_interpreter_flags\n\nfrom multiprocessing.process import current_process, active_children\n\n__all__ = [\n'sub_debug', 'debug', 'info', 'sub_warning', 'get_logger',\n'log_to_stderr', 'get_temp_dir', 'register_after_fork',\n'is_exiting', 'Finalize', 'ForkAwareThreadLock', 'ForkAwareLocal',\n'SUBDEBUG', 'SUBWARNING',\n]\n\n\n\n\n\nNOTSET = 0\nSUBDEBUG = 5\nDEBUG = 10\nINFO = 20\nSUBWARNING = 25\n\nLOGGER_NAME = 'multiprocessing'\nDEFAULT_LOGGING_FORMAT = '[%(levelname)s/%(processName)s] %(message)s'\n\n_logger = None\n_log_to_stderr = False\n\ndef sub_debug(msg, *args):\n if _logger:\n  _logger.log(SUBDEBUG, msg, *args)\n  \ndef debug(msg, *args):\n if _logger:\n  _logger.log(DEBUG, msg, *args)\n  \ndef info(msg, *args):\n if _logger:\n  _logger.log(INFO, msg, *args)\n  \ndef sub_warning(msg, *args):\n if _logger:\n  _logger.log(SUBWARNING, msg, *args)\n  \ndef get_logger():\n \"\"\n global _logger\n import logging\n \n logging._acquireLock()\n try:\n  if not _logger:\n  \n   _logger = logging.getLogger(LOGGER_NAME)\n   _logger.propagate = 0\n   logging.addLevelName(SUBDEBUG, 'SUBDEBUG')\n   logging.addLevelName(SUBWARNING, 'SUBWARNING')\n   \n   \n   if hasattr(atexit, 'unregister'):\n    atexit.unregister(_exit_function)\n    atexit.register(_exit_function)\n   else:\n    atexit._exithandlers.remove((_exit_function, (), {}))\n    atexit._exithandlers.append((_exit_function, (), {}))\n    \n finally:\n  logging._releaseLock()\n  \n return _logger\n \ndef log_to_stderr(level=None):\n \"\"\n global _log_to_stderr\n import logging\n \n logger = get_logger()\n formatter = logging.Formatter(DEFAULT_LOGGING_FORMAT)\n handler = logging.StreamHandler()\n handler.setFormatter(formatter)\n logger.addHandler(handler)\n \n if level:\n  logger.setLevel(level)\n _log_to_stderr = True\n return _logger\n \n \n \n \n \ndef get_temp_dir():\n\n if current_process()._tempdir is None:\n  import shutil, tempfile\n  tempdir = tempfile.mkdtemp(prefix='pymp-')\n  info('created temp directory %s', tempdir)\n  Finalize(None, shutil.rmtree, args=[tempdir], exitpriority=-100)\n  current_process()._tempdir = tempdir\n return current_process()._tempdir\n \n \n \n \n \n_afterfork_registry = weakref.WeakValueDictionary()\n_afterfork_counter = itertools.count()\n\ndef _run_after_forkers():\n items = list(_afterfork_registry.items())\n items.sort()\n for (index, ident, func), obj in items:\n  try:\n   func(obj)\n  except Exception as e:\n   info('after forker raised exception %s', e)\n   \ndef register_after_fork(obj, func):\n _afterfork_registry[(next(_afterfork_counter), id(obj), func)] = obj\n \n \n \n \n \n_finalizer_registry = {}\n_finalizer_counter = itertools.count()\n\n\nclass Finalize(object):\n \"\"\n def __init__(self, obj, callback, args=(), kwargs=None, exitpriority=None):\n  assert exitpriority is None or type(exitpriority) is int\n  \n  if obj is not None:\n   self._weakref = weakref.ref(obj, self)\n  else:\n   assert exitpriority is not None\n   \n  self._callback = callback\n  self._args = args\n  self._kwargs = kwargs or {}\n  self._key = (exitpriority, next(_finalizer_counter))\n  self._pid = os.getpid()\n  \n  _finalizer_registry[self._key] = self\n  \n def __call__(self, wr=None,\n \n \n _finalizer_registry=_finalizer_registry,\n sub_debug=sub_debug, getpid=os.getpid):\n  \"\"\n  try:\n   del _finalizer_registry[self._key]\n  except KeyError:\n   sub_debug('finalizer no longer registered')\n  else:\n   if self._pid != getpid():\n    sub_debug('finalizer ignored because different process')\n    res = None\n   else:\n    sub_debug('finalizer calling %s with args %s and kwargs %s',\n    self._callback, self._args, self._kwargs)\n    res = self._callback(*self._args, **self._kwargs)\n   self._weakref = self._callback = self._args = self._kwargs = self._key = None\n   return res\n   \n def cancel(self):\n  \"\"\n  try:\n   del _finalizer_registry[self._key]\n  except KeyError:\n   pass\n  else:\n   self._weakref = self._callback = self._args = self._kwargs = self._key = None\n   \n def still_active(self):\n  \"\"\n  return self._key in _finalizer_registry\n  \n def __repr__(self):\n  try:\n   obj = self._weakref()\n  except (AttributeError, TypeError):\n   obj = None\n   \n  if obj is None:\n   return '<Finalize object, dead>'\n   \n  x = '<Finalize object, callback=%s' % getattr(self._callback, '__name__', self._callback)\n  if self._args:\n   x += ', args=' + str(self._args)\n  if self._kwargs:\n   x += ', kwargs=' + str(self._kwargs)\n  if self._key[0] is not None:\n   x += ', exitprority=' + str(self._key[0])\n  return x + '>'\n  \n  \ndef _run_finalizers(minpriority=None):\n \"\"\n if _finalizer_registry is None:\n \n \n \n  return\n  \n if minpriority is None:\n  f = lambda p : p[0][0] is not None\n else:\n  f = lambda p : p[0][0] is not None and p[0][0] >= minpriority\n  \n items = [x for x in list(_finalizer_registry.items()) if f(x)]\n items.sort(reverse=True)\n \n for key, finalizer in items:\n  sub_debug('calling %s', finalizer)\n  try:\n   finalizer()\n  except Exception:\n   import traceback\n   traceback.print_exc()\n   \n if minpriority is None:\n  _finalizer_registry.clear()\n  \n  \n  \n  \n  \ndef is_exiting():\n \"\"\n return _exiting or _exiting is None\n \n_exiting = False\n\ndef _exit_function(info=info, debug=debug, _run_finalizers=_run_finalizers,\nactive_children=active_children,\ncurrent_process=current_process):\n\n\n\n\n global _exiting\n \n if not _exiting:\n  _exiting = True\n  \n  info('process shutting down')\n  debug('running all \"atexit\" finalizers with priority >= 0')\n  _run_finalizers(0)\n  \n  if current_process() is not None:\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n   for p in active_children():\n    if p._daemonic:\n     info('calling terminate() for daemon %s', p.name)\n     p._popen.terminate()\n     \n   for p in active_children():\n    info('calling join() for process %s', p.name)\n    p.join()\n    \n  debug('running the remaining \"atexit\" finalizers')\n  _run_finalizers()\n  \natexit.register(_exit_function)\n\n\n\n\n\nclass ForkAwareThreadLock(object):\n def __init__(self):\n  self._reset()\n  register_after_fork(self, ForkAwareThreadLock._reset)\n  \n def _reset(self):\n  self._lock = threading.Lock()\n  self.acquire = self._lock.acquire\n  self.release = self._lock.release\n  \nclass ForkAwareLocal(threading.local):\n def __init__(self):\n  register_after_fork(self, lambda obj : obj.__dict__.clear())\n def __reduce__(self):\n  return type(self), ()\n"], "xml.dom.xmlbuilder": [".py", "\"\"\n\nimport copy\nimport xml.dom\n\nfrom xml.dom.NodeFilter import NodeFilter\n\n\n__all__ = [\"DOMBuilder\", \"DOMEntityResolver\", \"DOMInputSource\"]\n\n\nclass Options:\n \"\"\n \n \n \n \n namespaces = 1\n namespace_declarations = True\n validation = False\n external_parameter_entities = True\n external_general_entities = True\n external_dtd_subset = True\n validate_if_schema = False\n validate = False\n datatype_normalization = False\n create_entity_ref_nodes = True\n entities = True\n whitespace_in_element_content = True\n cdata_sections = True\n comments = True\n charset_overrides_xml_encoding = True\n infoset = False\n supported_mediatypes_only = False\n \n errorHandler = None\n filter = None\n \n \nclass DOMBuilder:\n entityResolver = None\n errorHandler = None\n filter = None\n \n ACTION_REPLACE = 1\n ACTION_APPEND_AS_CHILDREN = 2\n ACTION_INSERT_AFTER = 3\n ACTION_INSERT_BEFORE = 4\n \n _legal_actions = (ACTION_REPLACE, ACTION_APPEND_AS_CHILDREN,\n ACTION_INSERT_AFTER, ACTION_INSERT_BEFORE)\n \n def __init__(self):\n  self._options = Options()\n  \n def _get_entityResolver(self):\n  return self.entityResolver\n def _set_entityResolver(self, entityResolver):\n  self.entityResolver = entityResolver\n  \n def _get_errorHandler(self):\n  return self.errorHandler\n def _set_errorHandler(self, errorHandler):\n  self.errorHandler = errorHandler\n  \n def _get_filter(self):\n  return self.filter\n def _set_filter(self, filter):\n  self.filter = filter\n  \n def setFeature(self, name, state):\n  if self.supportsFeature(name):\n   state = state and 1 or 0\n   try:\n    settings = self._settings[(_name_xform(name), state)]\n   except KeyError:\n    raise xml.dom.NotSupportedErr(\n    \"unsupported feature: %r\" % (name,))\n   else:\n    for name, value in settings:\n     setattr(self._options, name, value)\n  else:\n   raise xml.dom.NotFoundErr(\"unknown feature: \" + repr(name))\n   \n def supportsFeature(self, name):\n  return hasattr(self._options, _name_xform(name))\n  \n def canSetFeature(self, name, state):\n  key = (_name_xform(name), state and 1 or 0)\n  return key in self._settings\n  \n  \n  \n  \n  \n  \n _settings = {\n (\"namespace_declarations\", 0): [\n (\"namespace_declarations\", 0)],\n (\"namespace_declarations\", 1): [\n (\"namespace_declarations\", 1)],\n (\"validation\", 0): [\n (\"validation\", 0)],\n (\"external_general_entities\", 0): [\n (\"external_general_entities\", 0)],\n (\"external_general_entities\", 1): [\n (\"external_general_entities\", 1)],\n (\"external_parameter_entities\", 0): [\n (\"external_parameter_entities\", 0)],\n (\"external_parameter_entities\", 1): [\n (\"external_parameter_entities\", 1)],\n (\"validate_if_schema\", 0): [\n (\"validate_if_schema\", 0)],\n (\"create_entity_ref_nodes\", 0): [\n (\"create_entity_ref_nodes\", 0)],\n (\"create_entity_ref_nodes\", 1): [\n (\"create_entity_ref_nodes\", 1)],\n (\"entities\", 0): [\n (\"create_entity_ref_nodes\", 0),\n (\"entities\", 0)],\n (\"entities\", 1): [\n (\"entities\", 1)],\n (\"whitespace_in_element_content\", 0): [\n (\"whitespace_in_element_content\", 0)],\n (\"whitespace_in_element_content\", 1): [\n (\"whitespace_in_element_content\", 1)],\n (\"cdata_sections\", 0): [\n (\"cdata_sections\", 0)],\n (\"cdata_sections\", 1): [\n (\"cdata_sections\", 1)],\n (\"comments\", 0): [\n (\"comments\", 0)],\n (\"comments\", 1): [\n (\"comments\", 1)],\n (\"charset_overrides_xml_encoding\", 0): [\n (\"charset_overrides_xml_encoding\", 0)],\n (\"charset_overrides_xml_encoding\", 1): [\n (\"charset_overrides_xml_encoding\", 1)],\n (\"infoset\", 0): [],\n (\"infoset\", 1): [\n (\"namespace_declarations\", 0),\n (\"validate_if_schema\", 0),\n (\"create_entity_ref_nodes\", 0),\n (\"entities\", 0),\n (\"cdata_sections\", 0),\n (\"datatype_normalization\", 1),\n (\"whitespace_in_element_content\", 1),\n (\"comments\", 1),\n (\"charset_overrides_xml_encoding\", 1)],\n (\"supported_mediatypes_only\", 0): [\n (\"supported_mediatypes_only\", 0)],\n (\"namespaces\", 0): [\n (\"namespaces\", 0)],\n (\"namespaces\", 1): [\n (\"namespaces\", 1)],\n }\n \n def getFeature(self, name):\n  xname = _name_xform(name)\n  try:\n   return getattr(self._options, xname)\n  except AttributeError:\n   if name == \"infoset\":\n    options = self._options\n    return (options.datatype_normalization\n    and options.whitespace_in_element_content\n    and options.comments\n    and options.charset_overrides_xml_encoding\n    and not (options.namespace_declarations\n    or options.validate_if_schema\n    or options.create_entity_ref_nodes\n    or options.entities\n    or options.cdata_sections))\n   raise xml.dom.NotFoundErr(\"feature %s not known\" % repr(name))\n   \n def parseURI(self, uri):\n  if self.entityResolver:\n   input = self.entityResolver.resolveEntity(None, uri)\n  else:\n   input = DOMEntityResolver().resolveEntity(None, uri)\n  return self.parse(input)\n  \n def parse(self, input):\n  options = copy.copy(self._options)\n  options.filter = self.filter\n  options.errorHandler = self.errorHandler\n  fp = input.byteStream\n  if fp is None and options.systemId:\n   import urllib.request\n   fp = urllib.request.urlopen(input.systemId)\n  return self._parse_bytestream(fp, options)\n  \n def parseWithContext(self, input, cnode, action):\n  if action not in self._legal_actions:\n   raise ValueError(\"not a legal action\")\n  raise NotImplementedError(\"Haven't written this yet...\")\n  \n def _parse_bytestream(self, stream, options):\n  import xml.dom.expatbuilder\n  builder = xml.dom.expatbuilder.makeBuilder(options)\n  return builder.parseFile(stream)\n  \n  \ndef _name_xform(name):\n return name.lower().replace('-', '_')\n \n \nclass DOMEntityResolver(object):\n __slots__ = '_opener',\n \n def resolveEntity(self, publicId, systemId):\n  assert systemId is not None\n  source = DOMInputSource()\n  source.publicId = publicId\n  source.systemId = systemId\n  source.byteStream = self._get_opener().open(systemId)\n  \n  \n  source.encoding = self._guess_media_encoding(source)\n  \n  \n  import posixpath, urllib.parse\n  parts = urllib.parse.urlparse(systemId)\n  scheme, netloc, path, params, query, fragment = parts\n  \n  if path and not path.endswith(\"/\"):\n   path = posixpath.dirname(path) + \"/\"\n   parts = scheme, netloc, path, params, query, fragment\n   source.baseURI = urllib.parse.urlunparse(parts)\n   \n  return source\n  \n def _get_opener(self):\n  try:\n   return self._opener\n  except AttributeError:\n   self._opener = self._create_opener()\n   return self._opener\n   \n def _create_opener(self):\n  import urllib.request\n  return urllib.request.build_opener()\n  \n def _guess_media_encoding(self, source):\n  info = source.byteStream.info()\n  if \"Content-Type\" in info:\n   for param in info.getplist():\n    if param.startswith(\"charset=\"):\n     return param.split(\"=\", 1)[1].lower()\n     \n     \nclass DOMInputSource(object):\n __slots__ = ('byteStream', 'characterStream', 'stringData',\n 'encoding', 'publicId', 'systemId', 'baseURI')\n \n def __init__(self):\n  self.byteStream = None\n  self.characterStream = None\n  self.stringData = None\n  self.encoding = None\n  self.publicId = None\n  self.systemId = None\n  self.baseURI = None\n  \n def _get_byteStream(self):\n  return self.byteStream\n def _set_byteStream(self, byteStream):\n  self.byteStream = byteStream\n  \n def _get_characterStream(self):\n  return self.characterStream\n def _set_characterStream(self, characterStream):\n  self.characterStream = characterStream\n  \n def _get_stringData(self):\n  return self.stringData\n def _set_stringData(self, data):\n  self.stringData = data\n  \n def _get_encoding(self):\n  return self.encoding\n def _set_encoding(self, encoding):\n  self.encoding = encoding\n  \n def _get_publicId(self):\n  return self.publicId\n def _set_publicId(self, publicId):\n  self.publicId = publicId\n  \n def _get_systemId(self):\n  return self.systemId\n def _set_systemId(self, systemId):\n  self.systemId = systemId\n  \n def _get_baseURI(self):\n  return self.baseURI\n def _set_baseURI(self, uri):\n  self.baseURI = uri\n  \n  \nclass DOMBuilderFilter:\n \"\"\n \n \n \n \n \n \n FILTER_ACCEPT = 1\n FILTER_REJECT = 2\n FILTER_SKIP = 3\n FILTER_INTERRUPT = 4\n \n whatToShow = NodeFilter.SHOW_ALL\n \n def _get_whatToShow(self):\n  return self.whatToShow\n  \n def acceptNode(self, element):\n  return self.FILTER_ACCEPT\n  \n def startContainer(self, element):\n  return self.FILTER_ACCEPT\n  \ndel NodeFilter\n\n\nclass DocumentLS:\n \"\"\n \n async = False\n \n def _get_async(self):\n  return False\n def _set_async(self, async):\n  if async:\n   raise xml.dom.NotSupportedErr(\n   \"asynchronous document loading is not supported\")\n   \n def abort(self):\n \n \n  raise NotImplementedError(\n  \"haven't figured out what this means yet\")\n  \n def load(self, uri):\n  raise NotImplementedError(\"haven't written this yet\")\n  \n def loadXML(self, source):\n  raise NotImplementedError(\"haven't written this yet\")\n  \n def saveXML(self, snode):\n  if snode is None:\n   snode = self\n  elif snode.ownerDocument is not self:\n   raise xml.dom.WrongDocumentErr()\n  return snode.toxml()\n  \n  \nclass DOMImplementationLS:\n MODE_SYNCHRONOUS = 1\n MODE_ASYNCHRONOUS = 2\n \n def createDOMBuilder(self, mode, schemaType):\n  if schemaType is not None:\n   raise xml.dom.NotSupportedErr(\n   \"schemaType not yet supported\")\n  if mode == self.MODE_SYNCHRONOUS:\n   return DOMBuilder()\n  if mode == self.MODE_ASYNCHRONOUS:\n   raise xml.dom.NotSupportedErr(\n   \"asynchronous builders are not supported\")\n  raise ValueError(\"unknown value for mode\")\n  \n def createDOMWriter(self):\n  raise NotImplementedError(\n  \"the writer interface hasn't been written yet!\")\n  \n def createDOMInputSource(self):\n  return DOMInputSource()\n"], "os": [".py", "\"\"\n\nimport sys, errno\nimport stat as st\n\n_names = sys.builtin_module_names\n\n\n__all__ = [\"altsep\", \"curdir\", \"pardir\", \"sep\", \"pathsep\", \"linesep\",\n\"defpath\", \"name\", \"path\", \"devnull\", \"SEEK_SET\", \"SEEK_CUR\",\n\"SEEK_END\", \"fsencode\", \"fsdecode\", \"get_exec_path\", \"fdopen\",\n\"popen\", \"extsep\"]\n\ndef _exists(name):\n return name in globals()\n \ndef _get_exports_list(module):\n try:\n  return list(module.__all__)\n except AttributeError:\n  return [n for n in dir(module) if n[0] != '_']\n  \n  \n  \nif 'posix' in _names:\n name = 'posix'\n linesep = '\\n'\n from posix import *\n try:\n  from posix import _exit\n  __all__.append('_exit')\n except ImportError:\n  pass\n import posixpath as path\n \n try:\n  from posix import _have_functions\n except ImportError:\n  pass\n  \nelif 'nt' in _names:\n name = 'nt'\n linesep = '\\r\\n'\n from nt import *\n try:\n  from nt import _exit\n  __all__.append('_exit')\n except ImportError:\n  pass\n import ntpath as path\n \n import nt\n __all__.extend(_get_exports_list(nt))\n del nt\n \n try:\n  from nt import _have_functions\n except ImportError:\n  pass\n  \nelif 'os2' in _names:\n name = 'os2'\n linesep = '\\r\\n'\n from os2 import *\n try:\n  from os2 import _exit\n  __all__.append('_exit')\n except ImportError:\n  pass\n if sys.version.find('EMX GCC') == -1:\n  import ntpath as path\n else:\n  import os2emxpath as path\n  from _emx_link import link\n  \n import os2\n __all__.extend(_get_exports_list(os2))\n del os2\n \n try:\n  from os2 import _have_functions\n except ImportError:\n  pass\n  \nelif 'ce' in _names:\n name = 'ce'\n linesep = '\\r\\n'\n from ce import *\n try:\n  from ce import _exit\n  __all__.append('_exit')\n except ImportError:\n  pass\n  \n import ntpath as path\n \n import ce\n __all__.extend(_get_exports_list(ce))\n del ce\n \n try:\n  from ce import _have_functions\n except ImportError:\n  pass\n  \nelse:\n raise ImportError('no os specific module found')\n \nsys.modules['os.path'] = path\nfrom os.path import (curdir, pardir, sep, pathsep, defpath, extsep, altsep,\ndevnull)\n\ndel _names\n\n\nif _exists(\"_have_functions\"):\n _globals = globals()\n def _add(str, fn):\n  if (fn in _globals) and (str in _have_functions):\n   _set.add(_globals[fn])\n   \n _set = set()\n _add(\"HAVE_FACCESSAT\", \"access\")\n _add(\"HAVE_FCHMODAT\", \"chmod\")\n _add(\"HAVE_FCHOWNAT\", \"chown\")\n _add(\"HAVE_FSTATAT\", \"stat\")\n _add(\"HAVE_FUTIMESAT\", \"utime\")\n _add(\"HAVE_LINKAT\", \"link\")\n _add(\"HAVE_MKDIRAT\", \"mkdir\")\n _add(\"HAVE_MKFIFOAT\", \"mkfifo\")\n _add(\"HAVE_MKNODAT\", \"mknod\")\n _add(\"HAVE_OPENAT\", \"open\")\n _add(\"HAVE_READLINKAT\", \"readlink\")\n _add(\"HAVE_RENAMEAT\", \"rename\")\n _add(\"HAVE_SYMLINKAT\", \"symlink\")\n _add(\"HAVE_UNLINKAT\", \"unlink\")\n _add(\"HAVE_UNLINKAT\", \"rmdir\")\n _add(\"HAVE_UTIMENSAT\", \"utime\")\n supports_dir_fd = _set\n \n _set = set()\n _add(\"HAVE_FACCESSAT\", \"access\")\n supports_effective_ids = _set\n \n _set = set()\n _add(\"HAVE_FCHDIR\", \"chdir\")\n _add(\"HAVE_FCHMOD\", \"chmod\")\n _add(\"HAVE_FCHOWN\", \"chown\")\n _add(\"HAVE_FDOPENDIR\", \"listdir\")\n _add(\"HAVE_FEXECVE\", \"execve\")\n _set.add(stat) \n _add(\"HAVE_FTRUNCATE\", \"truncate\")\n _add(\"HAVE_FUTIMENS\", \"utime\")\n _add(\"HAVE_FUTIMES\", \"utime\")\n _add(\"HAVE_FPATHCONF\", \"pathconf\")\n if _exists(\"statvfs\") and _exists(\"fstatvfs\"): \n  _add(\"HAVE_FSTATVFS\", \"statvfs\")\n supports_fd = _set\n \n _set = set()\n _add(\"HAVE_FACCESSAT\", \"access\")\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n _add(\"HAVE_FCHOWNAT\", \"chown\")\n _add(\"HAVE_FSTATAT\", \"stat\")\n _add(\"HAVE_LCHFLAGS\", \"chflags\")\n _add(\"HAVE_LCHMOD\", \"chmod\")\n if _exists(\"lchown\"): \n  _add(\"HAVE_LCHOWN\", \"chown\")\n _add(\"HAVE_LINKAT\", \"link\")\n _add(\"HAVE_LUTIMES\", \"utime\")\n _add(\"HAVE_LSTAT\", \"stat\")\n _add(\"HAVE_FSTATAT\", \"stat\")\n _add(\"HAVE_UTIMENSAT\", \"utime\")\n _add(\"MS_WINDOWS\", \"stat\")\n supports_follow_symlinks = _set\n \n del _set\n del _have_functions\n del _globals\n del _add\n \n \n \n \n \nSEEK_SET = 0\nSEEK_CUR = 1\nSEEK_END = 2\n\n\ndef _get_masked_mode(mode):\n mask = umask(0)\n umask(mask)\n return mode & ~mask\n \n \n \n \ndef makedirs(name, mode=0o777, exist_ok=False):\n \"\"\n head, tail = path.split(name)\n if not tail:\n  head, tail = path.split(head)\n if head and tail and not path.exists(head):\n  try:\n   makedirs(head, mode, exist_ok)\n  except OSError as e:\n  \n   if e.errno != errno.EEXIST:\n    raise\n  cdir = curdir\n  if isinstance(tail, bytes):\n   cdir = bytes(curdir, 'ASCII')\n  if tail == cdir: \n   return\n try:\n  mkdir(name, mode)\n except OSError as e:\n  dir_exists = path.isdir(name)\n  expected_mode = _get_masked_mode(mode)\n  if dir_exists:\n  \n  \n  \n   actual_mode = st.S_IMODE(lstat(name).st_mode) & ~st.S_ISGID\n  else:\n   actual_mode = -1\n  if not (e.errno == errno.EEXIST and exist_ok and dir_exists and\n  actual_mode == expected_mode):\n   if dir_exists and actual_mode != expected_mode:\n    e.strerror += ' (mode %o != expected mode %o)' % (\n    actual_mode, expected_mode)\n   raise\n   \ndef removedirs(name):\n \"\"\n rmdir(name)\n head, tail = path.split(name)\n if not tail:\n  head, tail = path.split(head)\n while head and tail:\n  try:\n   rmdir(head)\n  except error:\n   break\n  head, tail = path.split(head)\n  \ndef renames(old, new):\n \"\"\n head, tail = path.split(new)\n if head and tail and not path.exists(head):\n  makedirs(head)\n rename(old, new)\n head, tail = path.split(old)\n if head and tail:\n  try:\n   removedirs(head)\n  except error:\n   pass\n   \n__all__.extend([\"makedirs\", \"removedirs\", \"renames\"])\n\ndef walk(top, topdown=True, onerror=None, followlinks=False):\n \"\"\n \n islink, join, isdir = path.islink, path.join, path.isdir\n \n \n \n \n \n \n try:\n \n \n  names = listdir(top)\n except error as err:\n  if onerror is not None:\n   onerror(err)\n  return\n  \n dirs, nondirs = [], []\n for name in names:\n  if isdir(join(top, name)):\n   dirs.append(name)\n  else:\n   nondirs.append(name)\n   \n if topdown:\n  yield top, dirs, nondirs\n for name in dirs:\n  new_path = join(top, name)\n  if followlinks or not islink(new_path):\n   yield from walk(new_path, topdown, onerror, followlinks)\n if not topdown:\n  yield top, dirs, nondirs\n  \n__all__.append(\"walk\")\n\nif {open, stat} <= supports_dir_fd and {listdir, stat} <= supports_fd:\n\n def fwalk(top=\".\", topdown=True, onerror=None, *, follow_symlinks=False, dir_fd=None):\n  \"\"\n  \n  \n  orig_st = stat(top, follow_symlinks=False, dir_fd=dir_fd)\n  topfd = open(top, O_RDONLY, dir_fd=dir_fd)\n  try:\n   if (follow_symlinks or (st.S_ISDIR(orig_st.st_mode) and\n   path.samestat(orig_st, stat(topfd)))):\n    yield from _fwalk(topfd, top, topdown, onerror, follow_symlinks)\n  finally:\n   close(topfd)\n   \n def _fwalk(topfd, toppath, topdown, onerror, follow_symlinks):\n \n \n \n \n  names = listdir(topfd)\n  dirs, nondirs = [], []\n  for name in names:\n   try:\n   \n   \n   \n   \n    if st.S_ISDIR(stat(name, dir_fd=topfd).st_mode):\n     dirs.append(name)\n    else:\n     nondirs.append(name)\n   except FileNotFoundError:\n    try:\n    \n     if st.S_ISLNK(stat(name, dir_fd=topfd, follow_symlinks=False)\n     .st_mode):\n      nondirs.append(name)\n    except FileNotFoundError:\n     continue\n     \n  if topdown:\n   yield toppath, dirs, nondirs, topfd\n   \n  for name in dirs:\n   try:\n    orig_st = stat(name, dir_fd=topfd, follow_symlinks=follow_symlinks)\n    dirfd = open(name, O_RDONLY, dir_fd=topfd)\n   except error as err:\n    if onerror is not None:\n     onerror(err)\n    return\n   try:\n    if follow_symlinks or path.samestat(orig_st, stat(dirfd)):\n     dirpath = path.join(toppath, name)\n     yield from _fwalk(dirfd, dirpath, topdown, onerror, follow_symlinks)\n   finally:\n    close(dirfd)\n    \n  if not topdown:\n   yield toppath, dirs, nondirs, topfd\n   \n __all__.append(\"fwalk\")\n \n \ntry:\n environ\nexcept NameError:\n environ = {}\n \ndef execl(file, *args):\n \"\"\n execv(file, args)\n \ndef execle(file, *args):\n \"\"\n env = args[-1]\n execve(file, args[:-1], env)\n \ndef execlp(file, *args):\n \"\"\n execvp(file, args)\n \ndef execlpe(file, *args):\n \"\"\n env = args[-1]\n execvpe(file, args[:-1], env)\n \ndef execvp(file, args):\n \"\"\n _execvpe(file, args)\n \ndef execvpe(file, args, env):\n \"\"\n _execvpe(file, args, env)\n \n__all__.extend([\"execl\",\"execle\",\"execlp\",\"execlpe\",\"execvp\",\"execvpe\"])\n\ndef _execvpe(file, args, env=None):\n if env is not None:\n  exec_func = execve\n  argrest = (args, env)\n else:\n  exec_func = execv\n  argrest = (args,)\n  env = environ\n  \n head, tail = path.split(file)\n if head:\n  exec_func(file, *argrest)\n  return\n last_exc = saved_exc = None\n saved_tb = None\n path_list = get_exec_path(env)\n if name != 'nt':\n  file = fsencode(file)\n  path_list = map(fsencode, path_list)\n for dir in path_list:\n  fullname = path.join(dir, file)\n  try:\n   exec_func(fullname, *argrest)\n  except error as e:\n   last_exc = e\n   tb = sys.exc_info()[2]\n   if (e.errno != errno.ENOENT and e.errno != errno.ENOTDIR\n   and saved_exc is None):\n    saved_exc = e\n    saved_tb = tb\n if saved_exc:\n  raise saved_exc.with_traceback(saved_tb)\n raise last_exc.with_traceback(tb)\n \n \ndef get_exec_path(env=None):\n \"\"\n \n \n \n import warnings\n \n if env is None:\n  env = environ\n  \n  \n  \n with warnings.catch_warnings():\n  warnings.simplefilter(\"ignore\", BytesWarning)\n  \n  try:\n   path_list = env.get('PATH')\n  except TypeError:\n   path_list = None\n   \n  if supports_bytes_environ:\n   try:\n    path_listb = env[b'PATH']\n   except (KeyError, TypeError):\n    pass\n   else:\n    if path_list is not None:\n     raise ValueError(\n     \"env cannot contain 'PATH' and b'PATH' keys\")\n    path_list = path_listb\n    \n   if path_list is not None and isinstance(path_list, bytes):\n    path_list = fsdecode(path_list)\n    \n if path_list is None:\n  path_list = defpath\n return path_list.split(pathsep)\n \n \n \nfrom collections.abc import MutableMapping\n\nclass _Environ(MutableMapping):\n def __init__(self, data, encodekey, decodekey, encodevalue, decodevalue, putenv, unsetenv):\n  self.encodekey = encodekey\n  self.decodekey = decodekey\n  self.encodevalue = encodevalue\n  self.decodevalue = decodevalue\n  self.putenv = putenv\n  self.unsetenv = unsetenv\n  self._data = data\n  \n def __getitem__(self, key):\n  try:\n   value = self._data[self.encodekey(key)]\n  except KeyError:\n  \n   raise KeyError(key) from None\n  return self.decodevalue(value)\n  \n def __setitem__(self, key, value):\n  key = self.encodekey(key)\n  value = self.encodevalue(value)\n  self.putenv(key, value)\n  self._data[key] = value\n  \n def __delitem__(self, key):\n  encodedkey = self.encodekey(key)\n  self.unsetenv(encodedkey)\n  try:\n   del self._data[encodedkey]\n  except KeyError:\n  \n   raise KeyError(key) from None\n   \n def __iter__(self):\n  for key in self._data:\n   yield self.decodekey(key)\n   \n def __len__(self):\n  return len(self._data)\n  \n def __repr__(self):\n  return 'environ({{{}}})'.format(', '.join(\n  ('{!r}: {!r}'.format(self.decodekey(key), self.decodevalue(value))\n  for key, value in self._data.items())))\n  \n def copy(self):\n  return dict(self)\n  \n def setdefault(self, key, value):\n  if key not in self:\n   self[key] = value\n  return self[key]\n  \ntry:\n _putenv = putenv\nexcept NameError:\n _putenv = lambda key, value: None\nelse:\n __all__.append(\"putenv\")\n \ntry:\n _unsetenv = unsetenv\nexcept NameError:\n _unsetenv = lambda key: _putenv(key, \"\")\nelse:\n __all__.append(\"unsetenv\")\n \ndef _createenviron():\n if name in ('os2', 'nt'):\n \n  def check_str(value):\n   if not isinstance(value, str):\n    raise TypeError(\"str expected, not %s\" % type(value).__name__)\n   return value\n  encode = check_str\n  decode = str\n  def encodekey(key):\n   return encode(key).upper()\n  data = {}\n  for key, value in environ.items():\n   data[encodekey(key)] = value\n else:\n \n  encoding = sys.getfilesystemencoding()\n  def encode(value):\n   if not isinstance(value, str):\n    raise TypeError(\"str expected, not %s\" % type(value).__name__)\n   return value.encode(encoding, 'surrogateescape')\n  def decode(value):\n   return value.decode(encoding, 'surrogateescape')\n  encodekey = encode\n  data = environ\n return _Environ(data,\n encodekey, decode,\n encode, decode,\n _putenv, _unsetenv)\n \n \nenviron = _createenviron()\ndel _createenviron\n\n\ndef getenv(key, default=None):\n \"\"\n return environ.get(key, default)\n \nsupports_bytes_environ = name not in ('os2', 'nt')\n__all__.extend((\"getenv\", \"supports_bytes_environ\"))\n\nif supports_bytes_environ:\n def _check_bytes(value):\n  if not isinstance(value, bytes):\n   raise TypeError(\"bytes expected, not %s\" % type(value).__name__)\n  return value\n  \n  \n environb = _Environ(environ._data,\n _check_bytes, bytes,\n _check_bytes, bytes,\n _putenv, _unsetenv)\n del _check_bytes\n \n def getenvb(key, default=None):\n  \"\"\n  return environb.get(key, default)\n  \n __all__.extend((\"environb\", \"getenvb\"))\n \ndef _fscodec():\n encoding = sys.getfilesystemencoding()\n if encoding == 'mbcs':\n  errors = 'strict'\n else:\n  errors = 'surrogateescape'\n  \n def fsencode(filename):\n  \"\"\n  if isinstance(filename, bytes):\n   return filename\n  elif isinstance(filename, str):\n   return filename.encode(encoding, errors)\n  else:\n   raise TypeError(\"expect bytes or str, not %s\" % type(filename).__name__)\n   \n def fsdecode(filename):\n  \"\"\n  if isinstance(filename, str):\n   return filename\n  elif isinstance(filename, bytes):\n   return filename.decode(encoding, errors)\n  else:\n   raise TypeError(\"expect bytes or str, not %s\" % type(filename).__name__)\n   \n return fsencode, fsdecode\n \nfsencode, fsdecode = _fscodec()\ndel _fscodec\n\n\nif _exists(\"fork\") and not _exists(\"spawnv\") and _exists(\"execv\"):\n\n P_WAIT = 0\n P_NOWAIT = P_NOWAITO = 1\n \n __all__.extend([\"P_WAIT\", \"P_NOWAIT\", \"P_NOWAITO\"])\n \n \n \n \n \n def _spawnvef(mode, file, args, env, func):\n \n  pid = fork()\n  if not pid:\n  \n   try:\n    if env is None:\n     func(file, args)\n    else:\n     func(file, args, env)\n   except:\n    _exit(127)\n  else:\n  \n   if mode == P_NOWAIT:\n    return pid \n   while 1:\n    wpid, sts = waitpid(pid, 0)\n    if WIFSTOPPED(sts):\n     continue\n    elif WIFSIGNALED(sts):\n     return -WTERMSIG(sts)\n    elif WIFEXITED(sts):\n     return WEXITSTATUS(sts)\n    else:\n     raise error(\"Not stopped, signaled or exited???\")\n     \n def spawnv(mode, file, args):\n  \"\"\n  return _spawnvef(mode, file, args, None, execv)\n  \n def spawnve(mode, file, args, env):\n  \"\"\n  return _spawnvef(mode, file, args, env, execve)\n  \n  \n  \n def spawnvp(mode, file, args):\n  \"\"\n  return _spawnvef(mode, file, args, None, execvp)\n  \n def spawnvpe(mode, file, args, env):\n  \"\"\n  return _spawnvef(mode, file, args, env, execvpe)\n  \nif _exists(\"spawnv\"):\n\n\n\n def spawnl(mode, file, *args):\n  \"\"\n  return spawnv(mode, file, args)\n  \n def spawnle(mode, file, *args):\n  \"\"\n  env = args[-1]\n  return spawnve(mode, file, args[:-1], env)\n  \n  \n __all__.extend([\"spawnv\", \"spawnve\", \"spawnl\", \"spawnle\",])\n \n \nif _exists(\"spawnvp\"):\n\n\n def spawnlp(mode, file, *args):\n  \"\"\n  return spawnvp(mode, file, args)\n  \n def spawnlpe(mode, file, *args):\n  \"\"\n  env = args[-1]\n  return spawnvpe(mode, file, args[:-1], env)\n  \n  \n __all__.extend([\"spawnvp\", \"spawnvpe\", \"spawnlp\", \"spawnlpe\",])\n \nimport copyreg as _copyreg\n\ndef _make_stat_result(tup, dict):\n return stat_result(tup, dict)\n \ndef _pickle_stat_result(sr):\n (type, args) = sr.__reduce__()\n return (_make_stat_result, args)\n \ntry:\n _copyreg.pickle(stat_result, _pickle_stat_result, _make_stat_result)\nexcept NameError: \n pass\n \ndef _make_statvfs_result(tup, dict):\n return statvfs_result(tup, dict)\n \ndef _pickle_statvfs_result(sr):\n (type, args) = sr.__reduce__()\n return (_make_statvfs_result, args)\n \ntry:\n _copyreg.pickle(statvfs_result, _pickle_statvfs_result,\n _make_statvfs_result)\nexcept NameError: \n pass\n \n \ndef popen(cmd, mode=\"r\", buffering=-1):\n if not isinstance(cmd, str):\n  raise TypeError(\"invalid cmd type (%s, expected string)\" % type(cmd))\n if mode not in (\"r\", \"w\"):\n  raise ValueError(\"invalid mode %r\" % mode)\n if buffering == 0 or buffering is None:\n  raise ValueError(\"popen() does not support unbuffered streams\")\n import subprocess, io\n if mode == \"r\":\n  proc = subprocess.Popen(cmd,\n  shell=True,\n  stdout=subprocess.PIPE,\n  bufsize=buffering)\n  return _wrap_close(io.TextIOWrapper(proc.stdout), proc)\n else:\n  proc = subprocess.Popen(cmd,\n  shell=True,\n  stdin=subprocess.PIPE,\n  bufsize=buffering)\n  return _wrap_close(io.TextIOWrapper(proc.stdin), proc)\n  \n  \nclass _wrap_close:\n def __init__(self, stream, proc):\n  self._stream = stream\n  self._proc = proc\n def close(self):\n  self._stream.close()\n  returncode = self._proc.wait()\n  if returncode == 0:\n   return None\n  if name == 'nt':\n   return returncode\n  else:\n   return returncode << 8 \n def __enter__(self):\n  return self\n def __exit__(self, *args):\n  self.close()\n def __getattr__(self, name):\n  return getattr(self._stream, name)\n def __iter__(self):\n  return iter(self._stream)\n  \n  \ndef fdopen(fd, *args, **kwargs):\n if not isinstance(fd, int):\n  raise TypeError(\"invalid fd type (%s, expected integer)\" % type(fd))\n import io\n return io.open(fd, *args, **kwargs)\n"], "marshal": [".js", "var $module = (function($B){\n\nvar _b_ = $B.builtins\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\n//for(var $py_builtin in _b_) eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")\n\nfunction _py(obj){\n    if(obj===null){return None}\n    if(isinstance(obj,list)){\n        var res = []\n        for(var i=0;i<obj.length;i++){\n            res.push(_py(obj[i]))\n        }\n        return res\n    }\n    if(obj.__class__!==undefined){\n        if(obj.__class__===list){\n            for(var i=0;i<obj.length;i++){\n                obj[i] = _py(obj[i])\n            }\n        }\n        return obj\n    }\n    if(typeof obj==='object' && obj.__class__===undefined){\n        // transform JS object into a Python dict\n        var res = dict()\n        for(var attr in obj){\n            getattr(res,'__setitem__')(attr,_py(obj[attr]))\n        }\n        return res\n    }\n    return $B.JSObject(obj)\n}\nfunction _js(obj){\n    // obj is a Python object\n    if (isinstance(obj,[int,str])) return obj\n    if(obj===None) return null\n    if(obj===True) return true\n    if(obj===False) return false\n    if(isinstance(obj,float)) return obj.value\n    if(isinstance(obj,[list,tuple])){\n        var res = []\n        for(var i=0;i<obj.length;i++){res.push(_js(obj[i]))}\n        return res\n    }\n    if(isinstance(obj,dict)){\n        var res = new Object()\n        try {\n            itr = $B.$dict_iterator(obj)\n            while (true) {\n                itm = itr.next()  // k,v pair\n                res[_js(itm[0])]=_js(itm[1])\n            }\n        } catch (err) {\n            if (err.__name__ !== \"StopIteration\") { throw err } else { $B.$pop_exc() }\n        }\n        return res\n    }\n    throw _b_.TypeError(str(obj)+' is not JSON serializable')\n}\n\nreturn  {\n    loads : function(json_obj){return _py(JSON.parse(json_obj))},\n    dumps : function(obj){return JSON.stringify(_js(obj))},\n}\n\n})(__BRYTHON__)\n"], "ui.slider": [".py", "from . import widget\nfrom browser import doc,html\n\nclass Slider(widget.Widget):\n\n def __init__(self, id=None, label=False):\n \n  self._div_shell=html.DIV(Class=\"ui-slider ui-slider-horizontal ui-widget ui-widget-content ui-corner-all\")\n  \n  widget.Widget.__init__(self, self._div_shell, 'slider', id)\n  \n  self._handle=html.A(Class=\"ui-slider-handle ui-state-default ui-corner-all\",\n  Href='#', style={'left': '0px'})\n  self._value=0\n  self._isMouseDown=False\n  \n  def startSlide(e):\n   self._isMouseDown=True\n   self._upperBound = self._div_shell.offsetWidth - self._handle.offsetWidth\n   \n   pos = widget.getMousePosition(e)\n   self._startMouseX=pos['x']\n   \n   self._lastElementLeft = parseInt(self._handle.style.left)\n   updatePosition(e)\n   \n  def updatePosition(e):\n   pos = widget.getMousePosition(e)\n   \n   _newPos = self._lastElementLeft + pos['x'] - self._startMouseX\n   \n   _newPos = max(0, _newPos)\n   _newPos = min(_newPos, self._upperBound)\n   \n   self._handle.style.left = '%spx' % _newPos\n   \n   self._lastElementLeft = _newPos\n   \n  def moving(e):\n   if self._isMouseDown:\n    updatePosition(e)\n    \n  def dropCallback(e):\n   self._isMouseDown=False\n   self._handle.unbind('mousemove', moving)\n   \n   \n  self._handle.bind('mousemove', moving)\n  self._handle.bind('mouseup', dropCallback)\n  \n  self._handle.bind('mousedown', startSlide)\n  \n  def mouseover(e):\n   _class=self._handle.getAttribute('class')\n   self._handle.setAttribute('class', '%s %s' % (_class, 'ui-state-hover'))\n   \n  def mouseout(e):\n   self._isMouseDown=False\n   _class=self._handle.getAttribute('class')\n   self._handle.setAttribute('class', _class.replace('ui-state-hover', ''))\n   \n  self._handle.bind('mouseover', mouseover)\n  self._handle.bind('mouseout', mouseout)\n  \n  self._div_shell <= self._handle\n  \n def get_value(self):\n  return self._value\n  \n  \n  \n  \n"], "pprint": [".py", "\n\n\n\n\n\n\n\n\n\n\"\"\n\nimport sys as _sys\nfrom collections import OrderedDict as _OrderedDict\nfrom io import StringIO as _StringIO\n\n__all__ = [\"pprint\",\"pformat\",\"isreadable\",\"isrecursive\",\"saferepr\",\n\"PrettyPrinter\"]\n\n\n_commajoin = \", \".join\n_id = id\n_len = len\n_type = type\n\n\ndef pprint(object, stream=None, indent=1, width=80, depth=None):\n \"\"\n printer = PrettyPrinter(\n stream=stream, indent=indent, width=width, depth=depth)\n printer.pprint(object)\n \ndef pformat(object, indent=1, width=80, depth=None):\n \"\"\n return PrettyPrinter(indent=indent, width=width, depth=depth).pformat(object)\n \ndef saferepr(object):\n \"\"\n return _safe_repr(object, {}, None, 0)[0]\n \ndef isreadable(object):\n \"\"\n return _safe_repr(object, {}, None, 0)[1]\n \ndef isrecursive(object):\n \"\"\n return _safe_repr(object, {}, None, 0)[2]\n \nclass _safe_key:\n \"\"\n \n __slots__ = ['obj']\n \n def __init__(self, obj):\n  self.obj = obj\n  \n def __lt__(self, other):\n  try:\n   rv = self.obj.__lt__(other.obj)\n  except TypeError:\n   rv = NotImplemented\n   \n  if rv is NotImplemented:\n   rv = (str(type(self.obj)), id(self.obj)) < (str(type(other.obj)), id(other.obj))\n  return rv\n  \ndef _safe_tuple(t):\n \"\"\n return _safe_key(t[0]), _safe_key(t[1])\n \nclass PrettyPrinter:\n def __init__(self, indent=1, width=80, depth=None, stream=None):\n  \"\"\n  indent = int(indent)\n  width = int(width)\n  assert indent >= 0, \"indent must be >= 0\"\n  assert depth is None or depth > 0, \"depth must be > 0\"\n  assert width, \"width must be != 0\"\n  self._depth = depth\n  self._indent_per_level = indent\n  self._width = width\n  if stream is not None:\n   self._stream = stream\n  else:\n   self._stream = _sys.stdout\n   \n def pprint(self, object):\n  self._format(object, self._stream, 0, 0, {}, 0)\n  self._stream.write(\"\\n\")\n  \n def pformat(self, object):\n  sio = _StringIO()\n  self._format(object, sio, 0, 0, {}, 0)\n  return sio.getvalue()\n  \n def isrecursive(self, object):\n  return self.format(object, {}, 0, 0)[2]\n  \n def isreadable(self, object):\n  s, readable, recursive = self.format(object, {}, 0, 0)\n  return readable and not recursive\n  \n def _format(self, object, stream, indent, allowance, context, level):\n  level = level + 1\n  import sys\n  sys.stderr.write(str(object))\n  objid = _id(object)\n  if objid in context:\n   stream.write(_recursion(object))\n   self._recursive = True\n   self._readable = False\n   return\n  rep = self._repr(object, context, level - 1)\n  typ = _type(object)\n  sepLines = _len(rep) > (self._width - 1 - indent - allowance)\n  write = stream.write\n  \n  if self._depth and level > self._depth:\n   write(rep)\n   return\n   \n  if sepLines:\n   r = getattr(typ, \"__repr__\", None)\n   if issubclass(typ, dict):\n    write('{')\n    if self._indent_per_level > 1:\n     write((self._indent_per_level - 1) * ' ')\n    length = _len(object)\n    if length:\n     context[objid] = 1\n     indent = indent + self._indent_per_level\n     if issubclass(typ, _OrderedDict):\n      items = list(object.items())\n     else:\n      items = sorted(object.items(), key=_safe_tuple)\n     key, ent = items[0]\n     rep = self._repr(key, context, level)\n     write(rep)\n     write(': ')\n     self._format(ent, stream, indent + _len(rep) + 2,\n     allowance + 1, context, level)\n     if length > 1:\n      for key, ent in items[1:]:\n       rep = self._repr(key, context, level)\n       write(',\\n%s%s: ' % (' '*indent, rep))\n       self._format(ent, stream, indent + _len(rep) + 2,\n       allowance + 1, context, level)\n     indent = indent - self._indent_per_level\n     del context[objid]\n    write('}')\n    return\n    \n   if ((issubclass(typ, list) and r is list.__repr__) or\n   (issubclass(typ, tuple) and r is tuple.__repr__) or\n   (issubclass(typ, set) and r is set.__repr__) or\n   (issubclass(typ, frozenset) and r is frozenset.__repr__)\n   ):\n    length = _len(object)\n    if issubclass(typ, list):\n     write('[')\n     endchar = ']'\n    elif issubclass(typ, tuple):\n     write('(')\n     endchar = ')'\n    else:\n     if not length:\n      write(rep)\n      return\n     if typ is set:\n      write('{')\n      endchar = '}'\n     else:\n      write(typ.__name__)\n      write('({')\n      endchar = '})'\n      indent += len(typ.__name__) + 1\n     object = sorted(object, key=_safe_key)\n    if self._indent_per_level > 1:\n     write((self._indent_per_level - 1) * ' ')\n    if length:\n     context[objid] = 1\n     indent = indent + self._indent_per_level\n     self._format(object[0], stream, indent, allowance + 1,\n     context, level)\n     if length > 1:\n      for ent in object[1:]:\n       write(',\\n' + ' '*indent)\n       self._format(ent, stream, indent,\n       allowance + 1, context, level)\n     indent = indent - self._indent_per_level\n     del context[objid]\n    if issubclass(typ, tuple) and length == 1:\n     write(',')\n    write(endchar)\n    return\n    \n  write(rep)\n  \n def _repr(self, object, context, level):\n  repr, readable, recursive = self.format(object, context.copy(),\n  self._depth, level)\n  if not readable:\n   self._readable = False\n  if recursive:\n   self._recursive = True\n  return repr\n  \n def format(self, object, context, maxlevels, level):\n  \"\"\n  return _safe_repr(object, context, maxlevels, level)\n  \n  \n  \n  \ndef _safe_repr(object, context, maxlevels, level):\n typ = _type(object)\n if typ is str:\n  if 'locale' not in _sys.modules:\n   return repr(object), True, False\n  if \"'\" in object and '\"' not in object:\n   closure = '\"'\n   quotes = {'\"': '\\\\\"'}\n  else:\n   closure = \"'\"\n   quotes = {\"'\": \"\\\\'\"}\n  qget = quotes.get\n  sio = _StringIO()\n  write = sio.write\n  for char in object:\n   if char.isalpha():\n    write(char)\n   else:\n    write(qget(char, repr(char)[1:-1]))\n  return (\"%s%s%s\" % (closure, sio.getvalue(), closure)), True, False\n  \n r = getattr(typ, \"__repr__\", None)\n if issubclass(typ, dict) and r is dict.__repr__:\n  if not object:\n   return \"{}\", True, False\n  objid = _id(object)\n  if maxlevels and level >= maxlevels:\n   return \"{...}\", False, objid in context\n  if objid in context:\n   return _recursion(object), False, True\n  context[objid] = 1\n  readable = True\n  recursive = False\n  components = []\n  append = components.append\n  level += 1\n  saferepr = _safe_repr\n  items = sorted(object.items(), key=_safe_tuple)\n  for k, v in items:\n   krepr, kreadable, krecur = saferepr(k, context, maxlevels, level)\n   vrepr, vreadable, vrecur = saferepr(v, context, maxlevels, level)\n   append(\"%s: %s\" % (krepr, vrepr))\n   readable = readable and kreadable and vreadable\n   if krecur or vrecur:\n    recursive = True\n  del context[objid]\n  return \"{%s}\" % _commajoin(components), readable, recursive\n  \n if (issubclass(typ, list) and r is list.__repr__) or (issubclass(typ, tuple) and r is tuple.__repr__):\n  if issubclass(typ, list):\n   if not object:\n    return \"[]\", True, False\n   format = \"[%s]\"\n  elif _len(object) == 1:\n   format = \"(%s,)\"\n  else:\n   if not object:\n    return \"()\", True, False\n   format = \"(%s)\"\n  objid = _id(object)\n  if maxlevels and level >= maxlevels:\n   return format % \"...\", False, objid in context\n  if objid in context:\n   return _recursion(object), False, True\n  context[objid] = 1\n  readable = True\n  recursive = False\n  components = []\n  append = components.append\n  level += 1\n  for o in object:\n   orepr, oreadable, orecur = _safe_repr(o, context, maxlevels, level)\n   append(orepr)\n   if not oreadable:\n    readable = False\n   if orecur:\n    recursive = True\n  del context[objid]\n  return format % _commajoin(components), readable, recursive\n  \n rep = repr(object)\n return rep, (rep and not rep.startswith('<')), False\n \n \ndef _recursion(object):\n return (\"<Recursion on %s with id=%s>\"\n % (_type(object).__name__, _id(object)))\n \n \ndef _perfcheck(object=None):\n import time\n if object is None:\n  object = [(\"string\", (1, 2), [3, 4], {5: 6, 7: 8})] * 100000\n p = PrettyPrinter()\n t1 = time.time()\n _safe_repr(object, {}, None, 0)\n t2 = time.time()\n p.pformat(object)\n t3 = time.time()\n print(\"_safe_repr:\", t2 - t1)\n print(\"pformat:\", t3 - t2)\n \nif __name__ == \"__main__\":\n _perfcheck()\n"], "unittest.__main__": [".py", "\"\"\n\nimport sys\nif sys.argv[0].endswith(\"__main__.py\"):\n import os.path\n \n \n \n \n executable = os.path.basename(sys.executable)\n sys.argv[0] = executable + \" -m unittest\"\n del os\n \n__unittest = True\n\nfrom .main import main, TestProgram, USAGE_AS_MAIN\nTestProgram.USAGE = USAGE_AS_MAIN\n\nmain(module=None)\n"], "_collections": [".py", "\n\n\n\n\n\n\n\n\n\nimport operator\n\n\n\ndef _thread_ident():\n return -1\n \n \nn = 30\nLFTLNK = n\nRGTLNK = n+1\nBLOCKSIZ = n+2\n\n\n\n\n\n\n\n\nclass deque:\n\n def __new__(cls, iterable=(), *args, **kw):\n \n \n  self=object.__new__(cls, *args, **kw)\n  self.clear()\n  return self\n  \n def __init__(self, iterable=(), maxlen=None):\n  object.__init__(self)\n  self.clear()\n  if maxlen is not None:\n   if maxlen < 0:\n    raise ValueError(\"maxlen must be non-negative\")\n  self._maxlen = maxlen\n  add = self.append\n  for elem in iterable:\n   add(elem)\n   \n @property\n def maxlen(self):\n  return self._maxlen\n  \n def clear(self):\n  self.right = self.left = [None] * BLOCKSIZ\n  self.rightndx = n//2 \n  self.leftndx = n//2+1\n  self.length = 0\n  self.state = 0\n  \n def append(self, x):\n  self.state += 1\n  self.rightndx += 1\n  if self.rightndx == n:\n   newblock = [None] * BLOCKSIZ\n   self.right[RGTLNK] = newblock\n   newblock[LFTLNK] = self.right\n   self.right = newblock\n   self.rightndx = 0\n  self.length += 1\n  self.right[self.rightndx] = x\n  if self.maxlen is not None and self.length > self.maxlen:\n   self.popleft()\n   \n def appendleft(self, x):\n  self.state += 1\n  self.leftndx -= 1\n  if self.leftndx == -1:\n   newblock = [None] * BLOCKSIZ\n   self.left[LFTLNK] = newblock\n   newblock[RGTLNK] = self.left\n   self.left = newblock\n   self.leftndx = n-1\n  self.length += 1\n  self.left[self.leftndx] = x\n  if self.maxlen is not None and self.length > self.maxlen:\n   self.pop()\n   \n def extend(self, iterable):\n  if iterable is self:\n   iterable = list(iterable)\n  for elem in iterable:\n   self.append(elem)\n   \n def extendleft(self, iterable):\n  if iterable is self:\n   iterable = list(iterable)\n  for elem in iterable:\n   self.appendleft(elem)\n   \n def pop(self):\n  if self.left is self.right and self.leftndx > self.rightndx:\n  \n   raise IndexError(\"pop from an empty deque\")\n  x = self.right[self.rightndx]\n  self.right[self.rightndx] = None\n  self.length -= 1\n  self.rightndx -= 1\n  self.state += 1\n  if self.rightndx == -1:\n   prevblock = self.right[LFTLNK]\n   if prevblock is None:\n   \n    self.rightndx = n//2\n    self.leftndx = n//2+1\n   else:\n    prevblock[RGTLNK] = None\n    self.right[LFTLNK] = None\n    self.right = prevblock\n    self.rightndx = n-1\n  return x\n  \n def popleft(self):\n  if self.left is self.right and self.leftndx > self.rightndx:\n  \n   raise IndexError(\"pop from an empty deque\")\n  x = self.left[self.leftndx]\n  self.left[self.leftndx] = None\n  self.length -= 1\n  self.leftndx += 1\n  self.state += 1\n  if self.leftndx == n:\n   prevblock = self.left[RGTLNK]\n   if prevblock is None:\n   \n    self.rightndx = n//2\n    self.leftndx = n//2+1\n   else:\n    prevblock[LFTLNK] = None\n    self.left[RGTLNK] = None\n    self.left = prevblock\n    self.leftndx = 0\n  return x\n  \n def count(self, value):\n  c = 0\n  for item in self:\n   if item == value:\n    c += 1\n  return c\n  \n def remove(self, value):\n \n  for i in range(len(self)):\n   if self[i] == value:\n    del self[i]\n    return\n  raise ValueError(\"deque.remove(x): x not in deque\")\n  \n def rotate(self, n=1):\n  length = len(self)\n  if length == 0:\n   return\n  halflen = (length+1) >> 1\n  if n > halflen or n < -halflen:\n   n %= length\n   if n > halflen:\n    n -= length\n   elif n < -halflen:\n    n += length\n  while n > 0:\n   self.appendleft(self.pop())\n   n -= 1\n  while n < 0:\n   self.append(self.popleft())\n   n += 1\n   \n def reverse(self):\n  \"\"\n  leftblock = self.left\n  rightblock = self.right\n  leftindex = self.leftndx\n  rightindex = self.rightndx\n  for i in range(self.length // 2):\n  \n   assert leftblock != rightblock or leftindex < rightindex\n   \n   \n   (rightblock[rightindex], leftblock[leftindex]) = (\n   leftblock[leftindex], rightblock[rightindex])\n   \n   \n   leftindex += 1\n   if leftindex == n:\n    leftblock = leftblock[RGTLNK]\n    assert leftblock is not None\n    leftindex = 0\n    \n    \n   rightindex -= 1\n   if rightindex == -1:\n    rightblock = rightblock[LFTLNK]\n    assert rightblock is not None\n    rightindex = n - 1\n    \n def __repr__(self):\n  threadlocalattr = '__repr' + str(_thread_ident())\n  if threadlocalattr in self.__dict__:\n   return 'deque([...])'\n  else:\n   self.__dict__[threadlocalattr] = True\n   try:\n    if self.maxlen is not None:\n     return 'deque(%r, maxlen=%s)' % (list(self), self.maxlen)\n    else:\n     return 'deque(%r)' % (list(self),)\n   finally:\n    del self.__dict__[threadlocalattr]\n    \n def __iter__(self):\n  return deque_iterator(self, self._iter_impl)\n  \n def _iter_impl(self, original_state, giveup):\n  if self.state != original_state:\n   giveup()\n  block = self.left\n  while block:\n   l, r = 0, n\n   if block is self.left:\n    l = self.leftndx\n   if block is self.right:\n    r = self.rightndx + 1\n   for elem in block[l:r]:\n    yield elem\n    if self.state != original_state:\n     giveup()\n   block = block[RGTLNK]\n   \n def __reversed__(self):\n  return deque_iterator(self, self._reversed_impl)\n  \n def _reversed_impl(self, original_state, giveup):\n  if self.state != original_state:\n   giveup()\n  block = self.right\n  while block:\n   l, r = 0, n\n   if block is self.left:\n    l = self.leftndx\n   if block is self.right:\n    r = self.rightndx + 1\n   for elem in reversed(block[l:r]):\n    yield elem\n    if self.state != original_state:\n     giveup()\n   block = block[LFTLNK]\n   \n def __len__(self):\n \n \n \n \n \n \n  return self.length\n  \n def __getref(self, index):\n  if index >= 0:\n   block = self.left\n   while block:\n    l, r = 0, n\n    if block is self.left:\n     l = self.leftndx\n    if block is self.right:\n     r = self.rightndx + 1\n    span = r-l\n    if index < span:\n     return block, l+index\n    index -= span\n    block = block[RGTLNK]\n  else:\n   block = self.right\n   while block:\n    l, r = 0, n\n    if block is self.left:\n     l = self.leftndx\n    if block is self.right:\n     r = self.rightndx + 1\n    negative_span = l-r\n    if index >= negative_span:\n     return block, r+index\n    index -= negative_span\n    block = block[LFTLNK]\n  raise IndexError(\"deque index out of range\")\n  \n def __getitem__(self, index):\n  block, index = self.__getref(index)\n  return block[index]\n  \n def __setitem__(self, index, value):\n  block, index = self.__getref(index)\n  block[index] = value\n  \n def __delitem__(self, index):\n  length = len(self)\n  if index >= 0:\n   if index >= length:\n    raise IndexError(\"deque index out of range\")\n   self.rotate(-index)\n   self.popleft()\n   self.rotate(index)\n  else:\n  \n   index= index^(2**31)\n   if index >= length:\n    raise IndexError(\"deque index out of range\")\n   self.rotate(index)\n   self.pop()\n   self.rotate(-index)\n   \n def __reduce_ex__(self, proto):\n  return type(self), (list(self), self.maxlen)\n  \n def __hash__(self):\n \n  raise TypeError(\"deque objects are unhashable\")\n  \n def __copy__(self):\n  return self.__class__(self, self.maxlen)\n  \n  \n def __eq__(self, other):\n  if isinstance(other, deque):\n   return list(self) == list(other)\n  else:\n   return NotImplemented\n   \n def __ne__(self, other):\n  if isinstance(other, deque):\n   return list(self) != list(other)\n  else:\n   return NotImplemented\n   \n def __lt__(self, other):\n  if isinstance(other, deque):\n   return list(self) < list(other)\n  else:\n   return NotImplemented\n   \n def __le__(self, other):\n  if isinstance(other, deque):\n   return list(self) <= list(other)\n  else:\n   return NotImplemented\n   \n def __gt__(self, other):\n  if isinstance(other, deque):\n   return list(self) > list(other)\n  else:\n   return NotImplemented\n   \n def __ge__(self, other):\n  if isinstance(other, deque):\n   return list(self) >= list(other)\n  else:\n   return NotImplemented\n   \n def __iadd__(self, other):\n  self.extend(other)\n  return self\n  \n  \nclass deque_iterator(object):\n\n def __init__(self, deq, itergen):\n  self.counter = len(deq)\n  def giveup():\n   self.counter = 0\n   \n   raise RuntimeError(\"deque mutated during iteration\")\n  self._gen = itergen(deq.state, giveup)\n  \n def next(self):\n  res = self._gen.next()\n  self.counter -= 1\n  return res\n  \n def __iter__(self):\n  return self\n  \nclass defaultdict(dict):\n\n def __init__(self, *args, **kwds):\n  if len(args) > 0:\n   default_factory = args[0]\n   args = args[1:]\n   if not callable(default_factory) and default_factory is not None:\n    raise TypeError(\"first argument must be callable\")\n  else:\n   default_factory = None\n  dict.__init__(self, args, kwds)\n  self.default_factory = default_factory\n  self.update(args, kwds)\n  \n  \n  \n def __getitem__(self, key):\n  if self.__contains__(key): \n   return dict.__getitem__(self,key)\n   \n  return self.__missing__(key)\n  \n def __missing__(self, key):\n \n  if self.default_factory is None: \n   raise KeyError(key)\n  self[key] = value = self.default_factory()\n  return value\n  \n def __repr__(self, recurse=set()):\n  if id(self) in recurse:\n   return \"defaultdict(...)\"\n  try:\n   recurse.add(id(self))\n   return \"defaultdict(%s, %s)\" % (repr(self.default_factory), super(defaultdict, self).__repr__())\n  finally:\n   recurse.remove(id(self))\n   \n def copy(self):\n  return type(self)(self.default_factory, self)\n  \n def __copy__(self):\n  return self.copy()\n  \n def __reduce__(self):\n \n \n \n \n \n \n \n \n \n \n \n  return (type(self), (self.default_factory,), None, None, self.iteritems())\n  \nfrom operator import itemgetter as _itemgetter\nfrom keyword import iskeyword as _iskeyword\nimport sys as _sys\n\ndef namedtuple(typename, field_names, verbose=False, rename=False):\n \"\"\n \n \n \n if isinstance(field_names, str):\n  field_names = field_names.replace(',', ' ').split() \n field_names = tuple(map(str, field_names))\n if rename:\n  names = list(field_names)\n  seen = set()\n  for i, name in enumerate(names):\n   if (not min(c.isalnum() or c=='_' for c in name) or _iskeyword(name)\n   or not name or name[0].isdigit() or name.startswith('_')\n   or name in seen):\n    names[i] = '_%d' % i\n   seen.add(name)\n  field_names = tuple(names)\n for name in (typename,) + field_names:\n  if not min(c.isalnum() or c=='_' for c in name):\n   raise ValueError('Type names and field names can only contain alphanumeric characters and underscores: %r' % name)\n  if _iskeyword(name):\n   raise ValueError('Type names and field names cannot be a keyword: %r' % name)\n  if name[0].isdigit():\n   raise ValueError('Type names and field names cannot start with a number: %r' % name)\n seen_names = set()\n for name in field_names:\n  if name.startswith('_') and not rename:\n   raise ValueError('Field names cannot start with an underscore: %r' % name)\n  if name in seen_names:\n   raise ValueError('Encountered duplicate field name: %r' % name)\n  seen_names.add(name)\n  \n  \n numfields = len(field_names)\n argtxt = repr(field_names).replace(\"'\", \"\")[1:-1] \n reprtxt = ', '.join('%s=%%r' % name for name in field_names)\n template = '''class %(typename)s(tuple):\n        '%(typename)s(%(argtxt)s)' \\n\n        __slots__ = () \\n\n        _fields = %(field_names)r \\n\n        def __new__(_cls, %(argtxt)s):\n            return _tuple.__new__(_cls, (%(argtxt)s)) \\n\n        @classmethod\n        def _make(cls, iterable, new=tuple.__new__, len=len):\n            'Make a new %(typename)s object from a sequence or iterable'\n            result = new(cls, iterable)\n            if len(result) != %(numfields)d:\n                raise TypeError('Expected %(numfields)d arguments, got %%d' %% len(result))\n            return result \\n\n        def __repr__(self):\n            return '%(typename)s(%(reprtxt)s)' %% self \\n\n        def _asdict(self):\n            'Return a new dict which maps field names to their values'\n            return dict(zip(self._fields, self)) \\n\n        def _replace(_self, **kwds):\n            'Return a new %(typename)s object replacing specified fields with new values'\n            result = _self._make(map(kwds.pop, %(field_names)r, _self))\n            if kwds:\n                raise ValueError('Got unexpected field names: %%r' %% kwds.keys())\n            return result \\n\n        def __getnewargs__(self):\n            return tuple(self) \\n\\n''' % locals()\n for i, name in enumerate(field_names):\n  template += '        %s = _property(_itemgetter(%d))\\n' % (name, i)\n  \n if verbose:\n  print(template)\n  \n  \n namespace = dict(_itemgetter=_itemgetter, __name__='namedtuple_%s' % typename,\n _property=property, _tuple=tuple)\n try:\n  exec(template,namespace)\n except SyntaxError as e:\n  raise SyntaxError(e.message + ':\\n' + template)\n result = namespace[typename]\n \n \n \n \n \n try:\n  result.__module__ = _sys._getframe(1).f_globals.get('__name__', '__main__')\n except (AttributeError, ValueError):\n  pass\n  \n return result\n \nif __name__ == '__main__':\n Point = namedtuple('Point', ['x', 'y'])\n p = Point(11, y=22)\n print(p[0]+p[1])\n x,y=p\n print(x,y)\n print(p.x+p.y)\n print(p)\n"], "xml.dom": [".py", "\"\"\n\n\nclass Node:\n \"\"\n __slots__ = ()\n \n \n \n \n \n \n \n \n ELEMENT_NODE = 1\n ATTRIBUTE_NODE = 2\n TEXT_NODE = 3\n CDATA_SECTION_NODE = 4\n ENTITY_REFERENCE_NODE = 5\n ENTITY_NODE = 6\n PROCESSING_INSTRUCTION_NODE = 7\n COMMENT_NODE = 8\n DOCUMENT_NODE = 9\n DOCUMENT_TYPE_NODE = 10\n DOCUMENT_FRAGMENT_NODE = 11\n NOTATION_NODE = 12\n \n \n \nINDEX_SIZE_ERR = 1\nDOMSTRING_SIZE_ERR = 2\nHIERARCHY_REQUEST_ERR = 3\nWRONG_DOCUMENT_ERR = 4\nINVALID_CHARACTER_ERR = 5\nNO_DATA_ALLOWED_ERR = 6\nNO_MODIFICATION_ALLOWED_ERR = 7\nNOT_FOUND_ERR = 8\nNOT_SUPPORTED_ERR = 9\nINUSE_ATTRIBUTE_ERR = 10\nINVALID_STATE_ERR = 11\nSYNTAX_ERR = 12\nINVALID_MODIFICATION_ERR = 13\nNAMESPACE_ERR = 14\nINVALID_ACCESS_ERR = 15\nVALIDATION_ERR = 16\n\n\nclass DOMException(Exception):\n \"\"\n \n def __init__(self, *args, **kw):\n  if self.__class__ is DOMException:\n   raise RuntimeError(\n   \"DOMException should not be instantiated directly\")\n  Exception.__init__(self, *args, **kw)\n  \n def _get_code(self):\n  return self.code\n  \n  \nclass IndexSizeErr(DOMException):\n code = INDEX_SIZE_ERR\n \nclass DomstringSizeErr(DOMException):\n code = DOMSTRING_SIZE_ERR\n \nclass HierarchyRequestErr(DOMException):\n code = HIERARCHY_REQUEST_ERR\n \nclass WrongDocumentErr(DOMException):\n code = WRONG_DOCUMENT_ERR\n \nclass InvalidCharacterErr(DOMException):\n code = INVALID_CHARACTER_ERR\n \nclass NoDataAllowedErr(DOMException):\n code = NO_DATA_ALLOWED_ERR\n \nclass NoModificationAllowedErr(DOMException):\n code = NO_MODIFICATION_ALLOWED_ERR\n \nclass NotFoundErr(DOMException):\n code = NOT_FOUND_ERR\n \nclass NotSupportedErr(DOMException):\n code = NOT_SUPPORTED_ERR\n \nclass InuseAttributeErr(DOMException):\n code = INUSE_ATTRIBUTE_ERR\n \nclass InvalidStateErr(DOMException):\n code = INVALID_STATE_ERR\n \nclass SyntaxErr(DOMException):\n code = SYNTAX_ERR\n \nclass InvalidModificationErr(DOMException):\n code = INVALID_MODIFICATION_ERR\n \nclass NamespaceErr(DOMException):\n code = NAMESPACE_ERR\n \nclass InvalidAccessErr(DOMException):\n code = INVALID_ACCESS_ERR\n \nclass ValidationErr(DOMException):\n code = VALIDATION_ERR\n \nclass UserDataHandler:\n \"\"\n \n \n \n NODE_CLONED = 1\n NODE_IMPORTED = 2\n NODE_DELETED = 3\n NODE_RENAMED = 4\n \nXML_NAMESPACE = \"http://www.w3.org/XML/1998/namespace\"\nXMLNS_NAMESPACE = \"http://www.w3.org/2000/xmlns/\"\nXHTML_NAMESPACE = \"http://www.w3.org/1999/xhtml\"\nEMPTY_NAMESPACE = None\nEMPTY_PREFIX = None\n\nfrom .domreg import getDOMImplementation, registerDOMImplementation\n", 1], "_sre": [".py", "\n\"\"\n\nMAXREPEAT = 2147483648\n\n\nimport operator, sys\nfrom sre_constants import ATCODES, OPCODES, CHCODES\nfrom sre_constants import SRE_INFO_PREFIX, SRE_INFO_LITERAL\nfrom sre_constants import SRE_FLAG_UNICODE, SRE_FLAG_LOCALE\n\n\nimport sys\n\n\n\nMAGIC = 20031017\n\n\n\n\n\n\n\n\n\n\n\n\n\nCODESIZE = 4\n\ncopyright = \"_sre.py 2.4c Copyright 2005 by Nik Haldimann\"\n\n\ndef getcodesize():\n return CODESIZE\n \ndef compile(pattern, flags, code, groups=0, groupindex={}, indexgroup=[None]):\n \"\"\n return SRE_Pattern(pattern, flags, code, groups, groupindex, indexgroup)\n \ndef getlower(char_ord, flags):\n if (char_ord < 128) or (flags & SRE_FLAG_UNICODE) or (flags & SRE_FLAG_LOCALE and char_ord < 256):\n \n  return ord(chr(char_ord).lower())\n else:\n  return char_ord\n  \n  \nclass SRE_Pattern:\n\n def __init__(self, pattern, flags, code, groups=0, groupindex={}, indexgroup=[None]):\n  self.pattern = pattern\n  self.flags = flags\n  self.groups = groups\n  self.groupindex = groupindex \n  self._indexgroup = indexgroup \n  self._code = code\n  \n def match(self, string, pos=0, endpos=sys.maxsize):\n  \"\"\n  state = _State(string, pos, endpos, self.flags)\n  if state.match(self._code):\n   return SRE_Match(self, state)\n  return None\n  \n def search(self, string, pos=0, endpos=sys.maxsize):\n  \"\"\n  state = _State(string, pos, endpos, self.flags)\n  if state.search(self._code):\n   return SRE_Match(self, state)\n  else:\n   return None\n   \n def findall(self, string, pos=0, endpos=sys.maxsize):\n  \"\"\n  matchlist = []\n  state = _State(string, pos, endpos, self.flags)\n  while state.start <= state.end:\n   state.reset()\n   state.string_position = state.start\n   if not state.search(self._code):\n    break\n   match = SRE_Match(self, state)\n   if self.groups == 0 or self.groups == 1:\n    item = match.group(self.groups)\n   else:\n    item = match.groups(\"\")\n   matchlist.append(item)\n   if state.string_position == state.start:\n    state.start += 1\n   else:\n    state.start = state.string_position\n  return matchlist \n  \n def _subx(self, template, string, count=0, subn=False):\n  filter = template\n  if not callable(template) and \"\\\\\" in template:\n  \n  \n  \n  \n   import pyre as sre\n   filter = sre._subx(self, template)\n  state = _State(string, 0, sys.maxsize, self.flags)\n  sublist = []\n  \n  n = last_pos = 0\n  while not count or n < count:\n   state.reset()\n   state.string_position = state.start\n   if not state.search(self._code):\n    break\n   if last_pos < state.start:\n    sublist.append(string[last_pos:state.start])\n   if not (last_pos == state.start and\n   last_pos == state.string_position and n > 0):\n   \n    if callable(filter):\n     sublist.append(filter(SRE_Match(self, state)))\n    else:\n     sublist.append(filter)\n    last_pos = state.string_position\n    n += 1\n   if state.string_position == state.start:\n    state.start += 1\n   else:\n    state.start = state.string_position\n    \n  if last_pos < state.end:\n   sublist.append(string[last_pos:state.end])\n  item = \"\".join(sublist)\n  if subn:\n   return item, n\n  else:\n   return item\n   \n def sub(self, repl, string, count=0):\n  \"\"\n  return self._subx(repl, string, count, False)\n  \n def subn(self, repl, string, count=0):\n  \"\"\n  return self._subx(repl, string, count, True)\n  \n def split(self, string, maxsplit=0):\n  \"\"\n  splitlist = []\n  state = _State(string, 0, sys.maxsize, self.flags)\n  n = 0\n  last = state.start\n  while not maxsplit or n < maxsplit:\n   state.reset()\n   state.string_position = state.start\n   if not state.search(self._code):\n    break\n   if state.start == state.string_position: \n    if last == state.end: \n     break\n    state.start += 1\n    continue\n   splitlist.append(string[last:state.start])\n   \n   if self.groups:\n    match = SRE_Match(self, state)\n    splitlist.extend(list(match.groups(None)))\n   n += 1\n   last = state.start = state.string_position\n  splitlist.append(string[last:state.end])\n  return splitlist\n  \n def finditer(self, string, pos=0, endpos=sys.maxsize):\n  \"\"\n  \n  _list=[]\n  _m=self.scanner(string, pos, endpos)\n  _re=SRE_Scanner(self, string, pos, endpos)\n  _m=_re.search()\n  while _m:\n   _list.append(_m)\n   _m=_re.search()\n  return _list\n  \n  \n def scanner(self, string, start=0, end=sys.maxsize):\n  return SRE_Scanner(self, string, start, end)\n  \n def __copy__(self):\n  raise TypeError(\"cannot copy this pattern object\")\n  \n def __deepcopy__(self):\n  raise TypeError(\"cannot copy this pattern object\")\n  \nclass SRE_Scanner:\n \"\"\n \n def __init__(self, pattern, string, start, end):\n  self.pattern = pattern\n  self._state = _State(string, start, end, self.pattern.flags)\n  \n def _match_search(self, matcher):\n  state = self._state\n  state.reset()\n  state.string_position = state.start\n  match = None\n  if matcher(self.pattern._code):\n   match = SRE_Match(self.pattern, state)\n  if match is None or state.string_position == state.start:\n   state.start += 1\n  else:\n   state.start = state.string_position\n  return match\n  \n def match(self):\n  return self._match_search(self._state.match)\n  \n def search(self):\n  return self._match_search(self._state.search)\n  \nclass SRE_Match:\n\n def __init__(self, pattern, state):\n  self.re = pattern\n  self.string = state.string\n  self.pos = state.pos\n  self.endpos = state.end\n  self.lastindex = state.lastindex\n  if self.lastindex < 0:\n   self.lastindex = None\n  self.regs = self._create_regs(state)\n  \n  \n  \n  if self.lastindex is not None and pattern._indexgroup and 0 <= self.lastindex < len(pattern._indexgroup):\n  \n  \n  \n  \n  \n   self.lastgroup = pattern._indexgroup[self.lastindex]\n  else:\n   self.lastgroup = None\n   \n def _create_regs(self, state):\n  \"\"\n  regs = [(state.start, state.string_position)]\n  for group in range(self.re.groups):\n   mark_index = 2 * group\n   if mark_index + 1 < len(state.marks) and state.marks[mark_index] is not None and state.marks[mark_index + 1] is not None:\n    regs.append((state.marks[mark_index], state.marks[mark_index + 1]))\n   else:\n    regs.append((-1, -1))\n  return tuple(regs)\n  \n def _get_index(self, group):\n  if isinstance(group, int):\n   if group >= 0 and group <= self.re.groups:\n    return group\n  else:\n   if group in self.re.groupindex:\n    return self.re.groupindex[group]\n  raise IndexError(\"no such group\")\n  \n def _get_slice(self, group, default):\n  group_indices = self.regs[group]\n  if group_indices[0] >= 0:\n   return self.string[group_indices[0]:group_indices[1]]\n  else:\n   return default\n   \n def start(self, group=0):\n  \"\"\n  return self.regs[self._get_index(group)][0]\n  \n def end(self, group=0):\n  \"\"\n  return self.regs[self._get_index(group)][1]\n  \n def span(self, group=0):\n  \"\"\n  return self.start(group), self.end(group)\n  \n def expand(self, template):\n  \"\"\n  import sre\n  return sre._expand(self.re, self, template)\n  \n def groups(self, default=None):\n  \"\"\n  groups = []\n  for indices in self.regs[1:]:\n   if indices[0] >= 0:\n    groups.append(self.string[indices[0]:indices[1]])\n   else:\n    groups.append(default)\n  return tuple(groups)\n  \n def groupdict(self, default=None):\n  \"\"\n  groupdict = {}\n  for key, value in self.re.groupindex.items():\n   groupdict[key] = self._get_slice(value, default)\n  return groupdict\n  \n def group(self, *args):\n  \"\"\n  if len(args) == 0:\n   args = (0,)\n  grouplist = []\n  for group in args:\n   grouplist.append(self._get_slice(self._get_index(group), None))\n  if len(grouplist) == 1:\n   return grouplist[0]\n  else:\n   return tuple(grouplist)\n   \n def __copy__():\n  raise TypeError(\"cannot copy this pattern object\")\n  \n def __deepcopy__():\n  raise TypeError(\"cannot copy this pattern object\")\n  \n  \nclass _State:\n\n def __init__(self, string, start, end, flags):\n  self.string = string\n  if start < 0:\n   start = 0\n  if end > len(string):\n   end = len(string)\n  self.start = start\n  self.string_position = self.start\n  self.end = end\n  self.pos = start\n  self.flags = flags\n  self.reset()\n  \n def reset(self):\n  self.marks = []\n  self.lastindex = -1\n  self.marks_stack = []\n  self.context_stack = []\n  self.repeat = None\n  \n def match(self, pattern_codes):\n \n \n \n \n \n \n \n \n \n  dispatcher = _OpcodeDispatcher()\n  self.context_stack.append(_MatchContext(self, pattern_codes))\n  has_matched = None\n  while len(self.context_stack) > 0:\n   context = self.context_stack[-1]\n   has_matched = dispatcher.match(context)\n   if has_matched is not None: \n    self.context_stack.pop()\n  return has_matched\n  \n def search(self, pattern_codes):\n  flags = 0\n  if pattern_codes[0] == OPCODES[\"info\"]:\n  \n  \n   if pattern_codes[2] & SRE_INFO_PREFIX and pattern_codes[5] > 1:\n    return self.fast_search(pattern_codes)\n   flags = pattern_codes[2]\n   pattern_codes = pattern_codes[pattern_codes[1] + 1:]\n   \n  string_position = self.start\n  if pattern_codes[0] == OPCODES[\"literal\"]:\n  \n  \n   character = pattern_codes[1]\n   while True:\n    while string_position < self.end and ord(self.string[string_position]) != character:\n     string_position += 1\n    if string_position >= self.end:\n     return False\n    self.start = string_position\n    string_position += 1\n    self.string_position = string_position\n    if flags & SRE_INFO_LITERAL:\n     return True\n    if self.match(pattern_codes[2:]):\n     return True\n   return False\n   \n   \n  while string_position <= self.end:\n   self.reset()\n   self.start = self.string_position = string_position\n   if self.match(pattern_codes):\n    return True\n   string_position += 1\n  return False\n  \n def fast_search(self, pattern_codes):\n  \"\"\n  \n  \n  flags = pattern_codes[2]\n  prefix_len = pattern_codes[5]\n  prefix_skip = pattern_codes[6] \n  prefix = pattern_codes[7:7 + prefix_len]\n  overlap = pattern_codes[7 + prefix_len - 1:pattern_codes[1] + 1]\n  pattern_codes = pattern_codes[pattern_codes[1] + 1:]\n  i = 0\n  string_position = self.string_position\n  while string_position < self.end:\n   while True:\n    if ord(self.string[string_position]) != prefix[i]:\n     if i == 0:\n      break\n     else:\n      i = overlap[i]\n    else:\n     i += 1\n     if i == prefix_len:\n     \n      self.start = string_position + 1 - prefix_len\n      self.string_position = string_position + 1 - prefix_len + prefix_skip\n      if flags & SRE_INFO_LITERAL:\n       return True \n      if self.match(pattern_codes[2 * prefix_skip:]):\n       return True\n      i = overlap[i]\n     break\n   string_position += 1\n  return False\n  \n def set_mark(self, mark_nr, position):\n  if mark_nr & 1:\n  \n  \n  \n   self.lastindex = mark_nr // 2 + 1\n  if mark_nr >= len(self.marks):\n   self.marks.extend([None] * (mark_nr - len(self.marks) + 1))\n  self.marks[mark_nr] = position\n  \n def get_marks(self, group_index):\n  marks_index = 2 * group_index\n  if len(self.marks) > marks_index + 1:\n   return self.marks[marks_index], self.marks[marks_index + 1]\n  else:\n   return None, None\n   \n def marks_push(self):\n  self.marks_stack.append((self.marks[:], self.lastindex))\n  \n def marks_pop(self):\n  self.marks, self.lastindex = self.marks_stack.pop()\n  \n def marks_pop_keep(self):\n  self.marks, self.lastindex = self.marks_stack[-1]\n  \n def marks_pop_discard(self):\n  self.marks_stack.pop()\n  \n def lower(self, char_ord):\n  return getlower(char_ord, self.flags)\n  \n  \nclass _MatchContext:\n\n def __init__(self, state, pattern_codes):\n  self.state = state\n  self.pattern_codes = pattern_codes\n  self.string_position = state.string_position\n  self.code_position = 0\n  self.has_matched = None\n  \n def push_new_context(self, pattern_offset):\n  \"\"\n  child_context = _MatchContext(self.state,\n  self.pattern_codes[self.code_position + pattern_offset:])\n  \n  \n  \n  \n  self.state.context_stack.append(child_context)\n  return child_context\n  \n def peek_char(self, peek=0):\n  return self.state.string[self.string_position + peek]\n  \n def skip_char(self, skip_count):\n  self.string_position += skip_count\n  \n def remaining_chars(self):\n  return self.state.end - self.string_position\n  \n def peek_code(self, peek=0):\n  return self.pattern_codes[self.code_position + peek]\n  \n def skip_code(self, skip_count):\n  self.code_position += skip_count\n  \n def remaining_codes(self):\n  return len(self.pattern_codes) - self.code_position\n  \n def at_beginning(self):\n  return self.string_position == 0\n  \n def at_end(self):\n  return self.string_position == self.state.end\n  \n def at_linebreak(self):\n  return not self.at_end() and _is_linebreak(self.peek_char())\n  \n def at_boundary(self, word_checker):\n  if self.at_beginning() and self.at_end():\n   return False\n  that = not self.at_beginning() and word_checker(self.peek_char(-1))\n  this = not self.at_end() and word_checker(self.peek_char())\n  return this != that\n  \n  \nclass _RepeatContext(_MatchContext):\n\n def __init__(self, context):\n  _MatchContext.__init__(self, context.state,\n  context.pattern_codes[context.code_position:])\n  self.count = -1\n  \n  self.previous = context.state.repeat\n  self.last_position = None\n  \n  \nclass _Dispatcher:\n\n DISPATCH_TABLE = None\n \n def dispatch(self, code, context):\n  method = self.DISPATCH_TABLE.get(code, self.__class__.unknown)\n  return method(self, context)\n  \n def unknown(self, code, ctx):\n  raise NotImplementedError()\n  \n def build_dispatch_table(cls, code_dict, method_prefix):\n  if cls.DISPATCH_TABLE is not None:\n   return\n  table = {}\n  for key, value in code_dict.items():\n   if hasattr(cls, \"%s%s\" % (method_prefix, key)):\n    table[value] = getattr(cls, \"%s%s\" % (method_prefix, key))\n  cls.DISPATCH_TABLE = table\n  \n build_dispatch_table = classmethod(build_dispatch_table)\n \n \nclass _OpcodeDispatcher(_Dispatcher):\n\n def __init__(self):\n  self.executing_contexts = {}\n  self.at_dispatcher = _AtcodeDispatcher()\n  self.ch_dispatcher = _ChcodeDispatcher()\n  self.set_dispatcher = _CharsetDispatcher()\n  \n def match(self, context):\n  \"\"\n  while context.remaining_codes() > 0 and context.has_matched is None:\n   opcode = context.peek_code()\n   if not self.dispatch(opcode, context):\n    return None\n  if context.has_matched is None:\n   context.has_matched = False\n  return context.has_matched\n  \n def dispatch(self, opcode, context):\n  \"\"\n  \n  if id(context) in self.executing_contexts:\n   generator = self.executing_contexts[id(context)]\n   del self.executing_contexts[id(context)]\n   has_finished = next(generator)\n  else:\n   method = self.DISPATCH_TABLE.get(opcode, _OpcodeDispatcher.unknown)\n   has_finished = method(self, context)\n   if hasattr(has_finished, \"__next__\"): \n    generator = has_finished\n    has_finished = next(generator)\n  if not has_finished:\n   self.executing_contexts[id(context)] = generator\n  return has_finished\n  \n def op_success(self, ctx):\n \n \n  ctx.state.string_position = ctx.string_position\n  ctx.has_matched = True\n  return True\n  \n def op_failure(self, ctx):\n \n \n  ctx.has_matched = False\n  return True\n  \n def general_op_literal(self, ctx, compare, decorate=lambda x: x):\n \n  if ctx.at_end() or not compare(decorate(ord(ctx.peek_char())),\n  decorate(ctx.peek_code(1))):\n   ctx.has_matched = False\n  ctx.skip_code(2)\n  ctx.skip_char(1)\n  \n def op_literal(self, ctx):\n \n \n \n  self.general_op_literal(ctx, operator.eq)\n  return True\n  \n def op_not_literal(self, ctx):\n \n \n \n  self.general_op_literal(ctx, operator.ne)\n  return True\n  \n def op_literal_ignore(self, ctx):\n \n \n \n  self.general_op_literal(ctx, operator.eq, ctx.state.lower)\n  return True\n  \n def op_not_literal_ignore(self, ctx):\n \n \n \n  self.general_op_literal(ctx, operator.ne, ctx.state.lower)\n  return True\n  \n def op_at(self, ctx):\n \n \n \n  if not self.at_dispatcher.dispatch(ctx.peek_code(1), ctx):\n   ctx.has_matched = False\n   \n   return True\n  ctx.skip_code(2)\n  return True\n  \n def op_category(self, ctx):\n \n \n \n  if ctx.at_end() or not self.ch_dispatcher.dispatch(ctx.peek_code(1), ctx):\n   ctx.has_matched = False\n   \n   return True\n  ctx.skip_code(2)\n  ctx.skip_char(1)\n  return True\n  \n def op_any(self, ctx):\n \n \n \n  if ctx.at_end() or ctx.at_linebreak():\n   ctx.has_matched = False\n   \n   return True\n  ctx.skip_code(1)\n  ctx.skip_char(1)\n  return True\n  \n def op_any_all(self, ctx):\n \n \n \n  if ctx.at_end():\n   ctx.has_matched = False\n   \n   return True\n  ctx.skip_code(1)\n  ctx.skip_char(1)\n  return True\n  \n def general_op_in(self, ctx, decorate=lambda x: x):\n \n \n  if ctx.at_end():\n   ctx.has_matched = False\n   \n   return\n  skip = ctx.peek_code(1)\n  ctx.skip_code(2) \n  \n  \n  if not self.check_charset(ctx, decorate(ord(ctx.peek_char()))):\n  \n   ctx.has_matched = False\n   return\n  ctx.skip_code(skip - 1)\n  ctx.skip_char(1)\n  \n  \n def op_in(self, ctx):\n \n \n \n  self.general_op_in(ctx)\n  return True\n  \n def op_in_ignore(self, ctx):\n \n \n \n  self.general_op_in(ctx, ctx.state.lower)\n  return True\n  \n def op_jump(self, ctx):\n \n \n \n  ctx.skip_code(ctx.peek_code(1) + 1)\n  return True\n  \n  \n  \n op_info = op_jump\n \n def op_mark(self, ctx):\n \n \n \n  ctx.state.set_mark(ctx.peek_code(1), ctx.string_position)\n  ctx.skip_code(2)\n  return True\n  \n def op_branch(self, ctx):\n \n \n \n  ctx.state.marks_push()\n  ctx.skip_code(1)\n  current_branch_length = ctx.peek_code(0)\n  while current_branch_length:\n  \n  \n   if not (ctx.peek_code(1) == OPCODES[\"literal\"] and (ctx.at_end() or ctx.peek_code(2) != ord(ctx.peek_char()))):\n    ctx.state.string_position = ctx.string_position\n    child_context = ctx.push_new_context(1)\n    \n    yield False\n    if child_context.has_matched:\n     ctx.has_matched = True\n     yield True\n    ctx.state.marks_pop_keep()\n   ctx.skip_code(current_branch_length)\n   current_branch_length = ctx.peek_code(0)\n  ctx.state.marks_pop_discard()\n  ctx.has_matched = False\n  \n  yield True\n  \n def op_repeat_one(self, ctx):\n \n \n \n \n  mincount = ctx.peek_code(2)\n  maxcount = ctx.peek_code(3)\n  \n  \n  \n  if ctx.remaining_chars() < mincount:\n   ctx.has_matched = False\n   yield True\n  ctx.state.string_position = ctx.string_position\n  count = self.count_repetitions(ctx, maxcount)\n  ctx.skip_char(count)\n  if count < mincount:\n   ctx.has_matched = False\n   yield True\n  if ctx.peek_code(ctx.peek_code(1) + 1) == OPCODES[\"success\"]:\n  \n   ctx.state.string_position = ctx.string_position\n   ctx.has_matched = True\n   yield True\n   \n  ctx.state.marks_push()\n  if ctx.peek_code(ctx.peek_code(1) + 1) == OPCODES[\"literal\"]:\n  \n  \n   char = ctx.peek_code(ctx.peek_code(1) + 2)\n   while True:\n    while count >= mincount and (ctx.at_end() or ord(ctx.peek_char()) != char):\n     ctx.skip_char(-1)\n     count -= 1\n    if count < mincount:\n     break\n    ctx.state.string_position = ctx.string_position\n    child_context = ctx.push_new_context(ctx.peek_code(1) + 1)\n    \n    yield False\n    if child_context.has_matched:\n     ctx.has_matched = True\n     yield True\n    ctx.skip_char(-1)\n    count -= 1\n    ctx.state.marks_pop_keep()\n    \n  else:\n  \n   while count >= mincount:\n    ctx.state.string_position = ctx.string_position\n    child_context = ctx.push_new_context(ctx.peek_code(1) + 1)\n    yield False\n    if child_context.has_matched:\n     ctx.has_matched = True\n     yield True\n    ctx.skip_char(-1)\n    count -= 1\n    ctx.state.marks_pop_keep()\n    \n  ctx.state.marks_pop_discard()\n  ctx.has_matched = False\n  \n  yield True\n  \n def op_min_repeat_one(self, ctx):\n \n \n  mincount = ctx.peek_code(2)\n  maxcount = ctx.peek_code(3)\n  \n  \n  if ctx.remaining_chars() < mincount:\n   ctx.has_matched = False\n   yield True\n  ctx.state.string_position = ctx.string_position\n  if mincount == 0:\n   count = 0\n  else:\n   count = self.count_repetitions(ctx, mincount)\n   if count < mincount:\n    ctx.has_matched = False\n    \n    yield True\n   ctx.skip_char(count)\n  if ctx.peek_code(ctx.peek_code(1) + 1) == OPCODES[\"success\"]:\n  \n   ctx.state.string_position = ctx.string_position\n   ctx.has_matched = True\n   yield True\n   \n  ctx.state.marks_push()\n  while maxcount == MAXREPEAT or count <= maxcount:\n   ctx.state.string_position = ctx.string_position\n   child_context = ctx.push_new_context(ctx.peek_code(1) + 1)\n   \n   yield False\n   if child_context.has_matched:\n    ctx.has_matched = True\n    yield True\n   ctx.state.string_position = ctx.string_position\n   if self.count_repetitions(ctx, 1) == 0:\n    break\n   ctx.skip_char(1)\n   count += 1\n   ctx.state.marks_pop_keep()\n   \n  ctx.state.marks_pop_discard()\n  ctx.has_matched = False\n  yield True\n  \n def op_repeat(self, ctx):\n \n \n \n \n \n \n \n \n \n  repeat = _RepeatContext(ctx)\n  ctx.state.repeat = repeat\n  ctx.state.string_position = ctx.string_position\n  child_context = ctx.push_new_context(ctx.peek_code(1) + 1)\n  \n  \n  \n  \n  yield False\n  ctx.state.repeat = repeat.previous\n  ctx.has_matched = child_context.has_matched\n  yield True\n  \n def op_max_until(self, ctx):\n \n \n  repeat = ctx.state.repeat\n  \n  if repeat is None:\n  \n   raise RuntimeError(\"Internal re error: MAX_UNTIL without REPEAT.\")\n  mincount = repeat.peek_code(2)\n  maxcount = repeat.peek_code(3)\n  ctx.state.string_position = ctx.string_position\n  count = repeat.count + 1\n  \n  \n  if count < mincount:\n  \n   repeat.count = count\n   child_context = repeat.push_new_context(4)\n   yield False\n   ctx.has_matched = child_context.has_matched\n   if not ctx.has_matched:\n    repeat.count = count - 1\n    ctx.state.string_position = ctx.string_position\n   yield True\n   \n  if (count < maxcount or maxcount == MAXREPEAT) and ctx.state.string_position != repeat.last_position:\n  \n   repeat.count = count\n   ctx.state.marks_push()\n   save_last_position = repeat.last_position \n   repeat.last_position = ctx.state.string_position\n   child_context = repeat.push_new_context(4)\n   yield False\n   repeat.last_position = save_last_position\n   if child_context.has_matched:\n    ctx.state.marks_pop_discard()\n    ctx.has_matched = True\n    yield True\n   ctx.state.marks_pop()\n   repeat.count = count - 1\n   ctx.state.string_position = ctx.string_position\n   \n   \n  ctx.state.repeat = repeat.previous\n  child_context = ctx.push_new_context(1)\n  \n  yield False\n  ctx.has_matched = child_context.has_matched\n  if not ctx.has_matched:\n   ctx.state.repeat = repeat\n   ctx.state.string_position = ctx.string_position\n  yield True\n  \n def op_min_until(self, ctx):\n \n \n  repeat = ctx.state.repeat\n  if repeat is None:\n   raise RuntimeError(\"Internal re error: MIN_UNTIL without REPEAT.\")\n  mincount = repeat.peek_code(2)\n  maxcount = repeat.peek_code(3)\n  ctx.state.string_position = ctx.string_position\n  count = repeat.count + 1\n  \n  \n  if count < mincount:\n  \n   repeat.count = count\n   child_context = repeat.push_new_context(4)\n   yield False\n   ctx.has_matched = child_context.has_matched\n   if not ctx.has_matched:\n    repeat.count = count - 1\n    ctx.state.string_position = ctx.string_position\n   yield True\n   \n   \n  ctx.state.marks_push()\n  ctx.state.repeat = repeat.previous\n  child_context = ctx.push_new_context(1)\n  \n  yield False\n  if child_context.has_matched:\n   ctx.has_matched = True\n   yield True\n  ctx.state.repeat = repeat\n  ctx.state.string_position = ctx.string_position\n  ctx.state.marks_pop()\n  \n  \n  if count >= maxcount and maxcount != MAXREPEAT:\n   ctx.has_matched = False\n   \n   yield True\n  repeat.count = count\n  child_context = repeat.push_new_context(4)\n  yield False\n  ctx.has_matched = child_context.has_matched\n  if not ctx.has_matched:\n   repeat.count = count - 1\n   ctx.state.string_position = ctx.string_position\n  yield True\n  \n def general_op_groupref(self, ctx, decorate=lambda x: x):\n  group_start, group_end = ctx.state.get_marks(ctx.peek_code(1))\n  if group_start is None or group_end is None or group_end < group_start:\n   ctx.has_matched = False\n   return True\n  while group_start < group_end:\n   if ctx.at_end() or decorate(ord(ctx.peek_char())) != decorate(ord(ctx.state.string[group_start])):\n    ctx.has_matched = False\n    \n    return True\n   group_start += 1\n   ctx.skip_char(1)\n  ctx.skip_code(2)\n  return True\n  \n def op_groupref(self, ctx):\n \n \n \n  return self.general_op_groupref(ctx)\n  \n def op_groupref_ignore(self, ctx):\n \n \n \n  return self.general_op_groupref(ctx, ctx.state.lower)\n  \n def op_groupref_exists(self, ctx):\n \n \n  group_start, group_end = ctx.state.get_marks(ctx.peek_code(1))\n  if group_start is None or group_end is None or group_end < group_start:\n   ctx.skip_code(ctx.peek_code(2) + 1)\n  else:\n   ctx.skip_code(3)\n  return True\n  \n def op_assert(self, ctx):\n \n \n \n  ctx.state.string_position = ctx.string_position - ctx.peek_code(2)\n  if ctx.state.string_position < 0:\n   ctx.has_matched = False\n   yield True\n  child_context = ctx.push_new_context(3)\n  yield False\n  if child_context.has_matched:\n   ctx.skip_code(ctx.peek_code(1) + 1)\n  else:\n   ctx.has_matched = False\n  yield True\n  \n def op_assert_not(self, ctx):\n \n \n \n  ctx.state.string_position = ctx.string_position - ctx.peek_code(2)\n  if ctx.state.string_position >= 0:\n   child_context = ctx.push_new_context(3)\n   yield False\n   if child_context.has_matched:\n    ctx.has_matched = False\n    yield True\n  ctx.skip_code(ctx.peek_code(1) + 1)\n  yield True\n  \n def unknown(self, ctx):\n \n  raise RuntimeError(\"Internal re error. Unknown opcode: %s\" % ctx.peek_code())\n  \n def check_charset(self, ctx, char):\n  \"\"\n  self.set_dispatcher.reset(char)\n  save_position = ctx.code_position\n  result = None\n  while result is None:\n   result = self.set_dispatcher.dispatch(ctx.peek_code(), ctx)\n  ctx.code_position = save_position\n  \n  return result\n  \n def count_repetitions(self, ctx, maxcount):\n  \"\"\n  count = 0\n  real_maxcount = ctx.state.end - ctx.string_position\n  if maxcount < real_maxcount and maxcount != MAXREPEAT:\n   real_maxcount = maxcount\n   \n   \n   \n  code_position = ctx.code_position\n  string_position = ctx.string_position\n  ctx.skip_code(4)\n  reset_position = ctx.code_position\n  while count < real_maxcount:\n  \n  \n   ctx.code_position = reset_position\n   self.dispatch(ctx.peek_code(), ctx)\n   \n   if ctx.has_matched is False: \n    break\n   count += 1\n  ctx.has_matched = None\n  ctx.code_position = code_position\n  ctx.string_position = string_position\n  return count\n  \n def _log(self, context, opname, *args):\n  arg_string = (\"%s \" * len(args)) % args\n  _log(\"|%s|%s|%s %s\" % (context.pattern_codes,\n  context.string_position, opname, arg_string))\n  \n_OpcodeDispatcher.build_dispatch_table(OPCODES, \"op_\")\n\n\nclass _CharsetDispatcher(_Dispatcher):\n\n def __init__(self):\n  self.ch_dispatcher = _ChcodeDispatcher()\n  \n def reset(self, char):\n  self.char = char\n  self.ok = True\n  \n def set_failure(self, ctx):\n  return not self.ok\n def set_literal(self, ctx):\n \n  if ctx.peek_code(1) == self.char:\n   return self.ok\n  else:\n   ctx.skip_code(2)\n def set_category(self, ctx):\n \n  if self.ch_dispatcher.dispatch(ctx.peek_code(1), ctx):\n   return self.ok\n  else:\n   ctx.skip_code(2)\n def set_charset(self, ctx):\n \n  char_code = self.char\n  ctx.skip_code(1) \n  if CODESIZE == 2:\n   if char_code < 256 and ctx.peek_code(char_code >> 4) & (1 << (char_code & 15)):\n    return self.ok\n   ctx.skip_code(16) \n  else:\n   if char_code < 256 and ctx.peek_code(char_code >> 5) & (1 << (char_code & 31)):\n    return self.ok\n   ctx.skip_code(8) \n def set_range(self, ctx):\n \n  if ctx.peek_code(1) <= self.char <= ctx.peek_code(2):\n   return self.ok\n  ctx.skip_code(3)\n def set_negate(self, ctx):\n  self.ok = not self.ok\n  ctx.skip_code(1)\n  \n  \n def set_bigcharset(self, ctx):\n  raise NotImplementationError(\"_sre.py: set_bigcharset, array not implemented\")\n  \n  char_code = self.char\n  count = ctx.peek_code(1)\n  ctx.skip_code(2)\n  if char_code < 65536:\n   block_index = char_code >> 8\n   \n   a = array.array(\"B\")\n   a.fromstring(array.array(CODESIZE == 2 and \"H\" or \"I\",\n   [ctx.peek_code(block_index // CODESIZE)]).tostring())\n   block = a[block_index % CODESIZE]\n   ctx.skip_code(256 // CODESIZE) \n   block_value = ctx.peek_code(block * (32 // CODESIZE)\n   + ((char_code & 255) >> (CODESIZE == 2 and 4 or 5)))\n   if block_value & (1 << (char_code & ((8 * CODESIZE) - 1))):\n    return self.ok\n  else:\n   ctx.skip_code(256 // CODESIZE) \n  ctx.skip_code(count * (32 // CODESIZE)) \n  \n def unknown(self, ctx):\n  return False\n  \n_CharsetDispatcher.build_dispatch_table(OPCODES, \"set_\")\n\n\nclass _AtcodeDispatcher(_Dispatcher):\n\n def at_beginning(self, ctx):\n  return ctx.at_beginning()\n at_beginning_string = at_beginning\n def at_beginning_line(self, ctx):\n  return ctx.at_beginning() or _is_linebreak(ctx.peek_char(-1))\n def at_end(self, ctx):\n  return (ctx.remaining_chars() == 1 and ctx.at_linebreak()) or ctx.at_end()\n def at_end_line(self, ctx):\n  return ctx.at_linebreak() or ctx.at_end()\n def at_end_string(self, ctx):\n  return ctx.at_end()\n def at_boundary(self, ctx):\n  return ctx.at_boundary(_is_word)\n def at_non_boundary(self, ctx):\n  return not ctx.at_boundary(_is_word)\n def at_loc_boundary(self, ctx):\n  return ctx.at_boundary(_is_loc_word)\n def at_loc_non_boundary(self, ctx):\n  return not ctx.at_boundary(_is_loc_word)\n def at_uni_boundary(self, ctx):\n  return ctx.at_boundary(_is_uni_word)\n def at_uni_non_boundary(self, ctx):\n  return not ctx.at_boundary(_is_uni_word)\n def unknown(self, ctx):\n  return False\n  \n_AtcodeDispatcher.build_dispatch_table(ATCODES, \"\")\n\n\nclass _ChcodeDispatcher(_Dispatcher):\n\n def category_digit(self, ctx):\n  return _is_digit(ctx.peek_char())\n def category_not_digit(self, ctx):\n  return not _is_digit(ctx.peek_char())\n def category_space(self, ctx):\n  return _is_space(ctx.peek_char())\n def category_not_space(self, ctx):\n  return not _is_space(ctx.peek_char())\n def category_word(self, ctx):\n  return _is_word(ctx.peek_char())\n def category_not_word(self, ctx):\n  return not _is_word(ctx.peek_char())\n def category_linebreak(self, ctx):\n  return _is_linebreak(ctx.peek_char())\n def category_not_linebreak(self, ctx):\n  return not _is_linebreak(ctx.peek_char())\n def category_loc_word(self, ctx):\n  return _is_loc_word(ctx.peek_char())\n def category_loc_not_word(self, ctx):\n  return not _is_loc_word(ctx.peek_char())\n def category_uni_digit(self, ctx):\n  return ctx.peek_char().isdigit()\n def category_uni_not_digit(self, ctx):\n  return not ctx.peek_char().isdigit()\n def category_uni_space(self, ctx):\n  return ctx.peek_char().isspace()\n def category_uni_not_space(self, ctx):\n  return not ctx.peek_char().isspace()\n def category_uni_word(self, ctx):\n  return _is_uni_word(ctx.peek_char())\n def category_uni_not_word(self, ctx):\n  return not _is_uni_word(ctx.peek_char())\n def category_uni_linebreak(self, ctx):\n  return ord(ctx.peek_char()) in _uni_linebreaks\n def category_uni_not_linebreak(self, ctx):\n  return ord(ctx.peek_char()) not in _uni_linebreaks\n def unknown(self, ctx):\n  return False\n  \n_ChcodeDispatcher.build_dispatch_table(CHCODES, \"\")\n\n\n_ascii_char_info = [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 2,\n2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 25, 25, 25, 25, 25, 25, 25,\n25, 25, 0, 0, 0, 0, 0, 0, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 0, 0,\n0, 0, 16, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 0, 0, 0, 0, 0 ]\n\ndef _is_digit(char):\n code = ord(char)\n return code < 128 and _ascii_char_info[code] & 1\n \ndef _is_space(char):\n code = ord(char)\n return code < 128 and _ascii_char_info[code] & 2\n \ndef _is_word(char):\n\n code = ord(char)\n return code < 128 and _ascii_char_info[code] & 16\n \ndef _is_loc_word(char):\n return (not (ord(char) & ~255) and char.isalnum()) or char == '_'\n \ndef _is_uni_word(char):\n\n\n return chr(ord(char)).isalnum() or char == '_'\n \ndef _is_linebreak(char):\n return char == \"\\n\"\n \n \n_uni_linebreaks = [10, 13, 28, 29, 30, 133, 8232, 8233]\n\ndef _log(message):\n if 0:\n  print(message)\n"], "unittest": [".py", "\"\"\n\n__all__ = ['TestResult', 'TestCase', 'TestSuite',\n'TextTestRunner', 'TestLoader', 'FunctionTestCase', 'main',\n'defaultTestLoader', 'SkipTest', 'skip', 'skipIf', 'skipUnless',\n'expectedFailure', 'TextTestResult', 'installHandler',\n'registerResult', 'removeResult', 'removeHandler']\n\n\n__all__.extend(['getTestCaseNames', 'makeSuite', 'findTestCases'])\n\n__unittest = True\n\nfrom .result import TestResult\nfrom .case import (TestCase, FunctionTestCase, SkipTest, skip, skipIf,\nskipUnless, expectedFailure)\nfrom .suite import BaseTestSuite, TestSuite\nfrom .loader import (TestLoader, defaultTestLoader, makeSuite, getTestCaseNames,\nfindTestCases)\nfrom .main import TestProgram, main\nfrom .runner import TextTestRunner, TextTestResult\nfrom .signals import installHandler, registerResult, removeResult, removeHandler\n\n\n_TextTestResult = TextTestResult\n", 1], "_string": [".py", "\"\"\n\nimport pyre as re\n\nclass __loader__(object):\n pass\n \ndef formatter_field_name_split(*args,**kw):\n \"\"\n pass\n \ndef formatter_parser(*args,**kw):\n \"\"\n \n assert len(args)==1\n assert isinstance(args[0], str)\n \n _result=[]\n for _match in re.finditer(\"([^{]*)?(\\{[^}]*\\})?\", args[0]):\n  _pre, _fmt = _match.groups()\n  if _fmt is None:\n   _result.append((_pre, None, None, None))\n  elif _fmt == '{}':\n   _result.append((_pre, '', '', None))\n  else:\n   _m=re.match(\"\\{([^!]*)!?(.*)?\\}\", _fmt)\n   _name=_m.groups(0)\n   _flags=_m.groups(1)\n   \n   _result.append((_pre, _name, _flags, None))\n   \n return _result\n"], "xml.parsers": [".py", "\"\"\n", 1], "test.support": [".py", "\"\"\n\nif __name__ != 'test.support':\n raise ImportError('support must be imported from the test package')\n \nimport contextlib\nimport errno\nimport functools\nimport gc\nimport socket\nimport sys\nimport os\nimport platform\nimport shutil\nimport warnings\nimport unittest\nimport importlib\nimport collections.abc\nimport re\nimport subprocess\nimport imp\nimport time\nimport sysconfig\nimport fnmatch\nimport logging.handlers\nimport struct\nimport tempfile\nimport _testcapi\n\ntry:\n import _thread, threading\nexcept ImportError:\n _thread = None\n threading = None\n \n \n \n \n \n \n \nmultiprocessing = None\n\ntry:\n import zlib\nexcept ImportError:\n zlib = None\n \ntry:\n import bz2\nexcept ImportError:\n bz2 = None\n \ntry:\n import lzma\nexcept ImportError:\n lzma = None\n \n__all__ = [\n\"Error\", \"TestFailed\", \"ResourceDenied\", \"import_module\", \"verbose\",\n\"use_resources\", \"max_memuse\", \"record_original_stdout\",\n\"get_original_stdout\", \"unload\", \"unlink\", \"rmtree\", \"forget\",\n\"is_resource_enabled\", \"requires\", \"requires_freebsd_version\",\n\"requires_linux_version\", \"requires_mac_ver\", \"find_unused_port\",\n\"bind_port\", \"IPV6_ENABLED\", \"is_jython\", \"TESTFN\", \"HOST\", \"SAVEDCWD\",\n\"temp_cwd\", \"findfile\", \"create_empty_file\", \"sortdict\",\n\"check_syntax_error\", \"open_urlresource\", \"check_warnings\", \"CleanImport\",\n\"EnvironmentVarGuard\", \"TransientResource\", \"captured_stdout\",\n\"captured_stdin\", \"captured_stderr\", \"time_out\", \"socket_peer_reset\",\n\"ioerror_peer_reset\", \"run_with_locale\", 'temp_umask',\n\"transient_internet\", \"set_memlimit\", \"bigmemtest\", \"bigaddrspacetest\",\n\"BasicTestRunner\", \"run_unittest\", \"run_doctest\", \"threading_setup\",\n\"threading_cleanup\", \"reap_children\", \"cpython_only\", \"check_impl_detail\",\n\"get_attribute\", \"swap_item\", \"swap_attr\", \"requires_IEEE_754\",\n\"TestHandler\", \"Matcher\", \"can_symlink\", \"skip_unless_symlink\",\n\"skip_unless_xattr\", \"import_fresh_module\", \"requires_zlib\",\n\"PIPE_MAX_SIZE\", \"failfast\", \"anticipate_failure\", \"run_with_tz\",\n\"requires_bz2\", \"requires_lzma\", \"suppress_crash_popup\",\n]\n\nclass Error(Exception):\n \"\"\n \nclass TestFailed(Error):\n \"\"\n \nclass ResourceDenied(unittest.SkipTest):\n \"\"\n \n@contextlib.contextmanager\ndef _ignore_deprecated_imports(ignore=True):\n \"\"\n if ignore:\n  with warnings.catch_warnings():\n   warnings.filterwarnings(\"ignore\", \".+ (module|package)\",\n   DeprecationWarning)\n   yield\n else:\n  yield\n  \n  \ndef import_module(name, deprecated=False):\n \"\"\n with _ignore_deprecated_imports(deprecated):\n  try:\n   return importlib.import_module(name)\n  except ImportError as msg:\n   raise unittest.SkipTest(str(msg))\n   \n   \ndef _save_and_remove_module(name, orig_modules):\n \"\"\n \n if name not in sys.modules:\n  __import__(name)\n  del sys.modules[name]\n for modname in list(sys.modules):\n  if modname == name or modname.startswith(name + '.'):\n   orig_modules[modname] = sys.modules[modname]\n   del sys.modules[modname]\n   \ndef _save_and_block_module(name, orig_modules):\n \"\"\n saved = True\n try:\n  orig_modules[name] = sys.modules[name]\n except KeyError:\n  saved = False\n sys.modules[name] = None\n return saved\n \n \ndef anticipate_failure(condition):\n \"\"\n if condition:\n  return unittest.expectedFailure\n return lambda f: f\n \n \ndef import_fresh_module(name, fresh=(), blocked=(), deprecated=False):\n \"\"\n \n \n with _ignore_deprecated_imports(deprecated):\n \n \n  orig_modules = {}\n  names_to_remove = []\n  _save_and_remove_module(name, orig_modules)\n  try:\n   for fresh_name in fresh:\n    _save_and_remove_module(fresh_name, orig_modules)\n   for blocked_name in blocked:\n    if not _save_and_block_module(blocked_name, orig_modules):\n     names_to_remove.append(blocked_name)\n   fresh_module = importlib.import_module(name)\n  except ImportError:\n   fresh_module = None\n  finally:\n   for orig_name, module in orig_modules.items():\n    sys.modules[orig_name] = module\n   for name_to_remove in names_to_remove:\n    del sys.modules[name_to_remove]\n  return fresh_module\n  \n  \ndef get_attribute(obj, name):\n \"\"\n try:\n  attribute = getattr(obj, name)\n except AttributeError:\n  raise unittest.SkipTest(\"object %r has no attribute %r\" % (obj, name))\n else:\n  return attribute\n  \nverbose = 1 \nuse_resources = None \nmax_memuse = 0 \n\nreal_max_memuse = 0\nfailfast = False\nmatch_tests = None\n\n\n\n\n_original_stdout = None\ndef record_original_stdout(stdout):\n global _original_stdout\n _original_stdout = stdout\n \ndef get_original_stdout():\n return _original_stdout or sys.stdout\n \ndef unload(name):\n try:\n  del sys.modules[name]\n except KeyError:\n  pass\n  \nif sys.platform.startswith(\"win\"):\n def _waitfor(func, pathname, waitall=False):\n \n  func(pathname)\n  \n  if waitall:\n   dirname = pathname\n  else:\n   dirname, name = os.path.split(pathname)\n   dirname = dirname or '.'\n   \n   \n   \n   \n   \n   \n  timeout = 0.001\n  while timeout < 1.0:\n  \n  \n  \n  \n  \n  \n  \n   L = os.listdir(dirname)\n   if not (L if waitall else name in L):\n    return\n    \n   time.sleep(timeout)\n   timeout *= 2\n  warnings.warn('tests may fail, delete still pending for ' + pathname,\n  RuntimeWarning, stacklevel=4)\n  \n def _unlink(filename):\n  _waitfor(os.unlink, filename)\n  \n def _rmdir(dirname):\n  _waitfor(os.rmdir, dirname)\n  \n def _rmtree(path):\n  def _rmtree_inner(path):\n   for name in os.listdir(path):\n    fullname = os.path.join(path, name)\n    if os.path.isdir(fullname):\n     _waitfor(_rmtree_inner, fullname, waitall=True)\n     os.rmdir(fullname)\n    else:\n     os.unlink(fullname)\n  _waitfor(_rmtree_inner, path, waitall=True)\n  _waitfor(os.rmdir, path)\nelse:\n _unlink = os.unlink\n _rmdir = os.rmdir\n _rmtree = shutil.rmtree\n \ndef unlink(filename):\n try:\n  _unlink(filename)\n except OSError as error:\n \n  if error.errno not in (errno.ENOENT, errno.ENOTDIR):\n   raise\n   \ndef rmdir(dirname):\n try:\n  _rmdir(dirname)\n except OSError as error:\n \n  if error.errno != errno.ENOENT:\n   raise\n   \ndef rmtree(path):\n try:\n  _rmtree(path)\n except OSError as error:\n  if error.errno != errno.ENOENT:\n   raise\n   \ndef make_legacy_pyc(source):\n \"\"\n pyc_file = imp.cache_from_source(source)\n up_one = os.path.dirname(os.path.abspath(source))\n legacy_pyc = os.path.join(up_one, source + ('c' if __debug__ else 'o'))\n os.rename(pyc_file, legacy_pyc)\n return legacy_pyc\n \ndef forget(modname):\n \"\"\n unload(modname)\n for dirname in sys.path:\n  source = os.path.join(dirname, modname + '.py')\n  \n  \n  unlink(source + 'c')\n  unlink(source + 'o')\n  unlink(imp.cache_from_source(source, debug_override=True))\n  unlink(imp.cache_from_source(source, debug_override=False))\n  \n  \n  \nif sys.platform.startswith('win'):\n import ctypes\n import ctypes.wintypes\n def _is_gui_available():\n  UOI_FLAGS = 1\n  WSF_VISIBLE = 0x0001\n  class USEROBJECTFLAGS(ctypes.Structure):\n   _fields_ = [(\"fInherit\", ctypes.wintypes.BOOL),\n   (\"fReserved\", ctypes.wintypes.BOOL),\n   (\"dwFlags\", ctypes.wintypes.DWORD)]\n  dll = ctypes.windll.user32\n  h = dll.GetProcessWindowStation()\n  if not h:\n   raise ctypes.WinError()\n  uof = USEROBJECTFLAGS()\n  needed = ctypes.wintypes.DWORD()\n  res = dll.GetUserObjectInformationW(h,\n  UOI_FLAGS,\n  ctypes.byref(uof),\n  ctypes.sizeof(uof),\n  ctypes.byref(needed))\n  if not res:\n   raise ctypes.WinError()\n  return bool(uof.dwFlags & WSF_VISIBLE)\nelse:\n def _is_gui_available():\n  return True\n  \ndef is_resource_enabled(resource):\n \"\"\n return use_resources is not None and resource in use_resources\n \ndef requires(resource, msg=None):\n \"\"\n if resource == 'gui' and not _is_gui_available():\n  raise unittest.SkipTest(\"Cannot use the 'gui' resource\")\n  \n  \n if sys._getframe(1).f_globals.get(\"__name__\") == \"__main__\":\n  return\n if not is_resource_enabled(resource):\n  if msg is None:\n   msg = \"Use of the %r resource not enabled\" % resource\n  raise ResourceDenied(msg)\n  \ndef _requires_unix_version(sysname, min_version):\n \"\"\n def decorator(func):\n  @functools.wraps(func)\n  def wrapper(*args, **kw):\n   if platform.system() == sysname:\n    version_txt = platform.release().split('-', 1)[0]\n    try:\n     version = tuple(map(int, version_txt.split('.')))\n    except ValueError:\n     pass\n    else:\n     if version < min_version:\n      min_version_txt = '.'.join(map(str, min_version))\n      raise unittest.SkipTest(\n      \"%s version %s or higher required, not %s\"\n      % (sysname, min_version_txt, version_txt))\n  return wrapper\n return decorator\n \ndef requires_freebsd_version(*min_version):\n \"\"\n return _requires_unix_version('FreeBSD', min_version)\n \ndef requires_linux_version(*min_version):\n \"\"\n return _requires_unix_version('Linux', min_version)\n \ndef requires_mac_ver(*min_version):\n \"\"\n def decorator(func):\n  @functools.wraps(func)\n  def wrapper(*args, **kw):\n   if sys.platform == 'darwin':\n    version_txt = platform.mac_ver()[0]\n    try:\n     version = tuple(map(int, version_txt.split('.')))\n    except ValueError:\n     pass\n    else:\n     if version < min_version:\n      min_version_txt = '.'.join(map(str, min_version))\n      raise unittest.SkipTest(\n      \"Mac OS X %s or higher required, not %s\"\n      % (min_version_txt, version_txt))\n   return func(*args, **kw)\n  wrapper.min_version = min_version\n  return wrapper\n return decorator\n \n \nHOST = 'localhost'\n\ndef find_unused_port(family=socket.AF_INET, socktype=socket.SOCK_STREAM):\n \"\"\n \n tempsock = socket.socket(family, socktype)\n port = bind_port(tempsock)\n tempsock.close()\n del tempsock\n return port\n \ndef bind_port(sock, host=HOST):\n \"\"\n \n if sock.family == socket.AF_INET and sock.type == socket.SOCK_STREAM:\n  if hasattr(socket, 'SO_REUSEADDR'):\n   if sock.getsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR) == 1:\n    raise TestFailed(\"tests should never set the SO_REUSEADDR \" \"socket option on TCP/IP sockets!\")\n  if hasattr(socket, 'SO_REUSEPORT'):\n   if sock.getsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT) == 1:\n    raise TestFailed(\"tests should never set the SO_REUSEPORT \" \"socket option on TCP/IP sockets!\")\n  if hasattr(socket, 'SO_EXCLUSIVEADDRUSE'):\n   sock.setsockopt(socket.SOL_SOCKET, socket.SO_EXCLUSIVEADDRUSE, 1)\n   \n sock.bind((host, 0))\n port = sock.getsockname()[1]\n return port\n \ndef _is_ipv6_enabled():\n \"\"\n if socket.has_ipv6:\n  sock = None\n  try:\n   sock = socket.socket(socket.AF_INET6, socket.SOCK_STREAM)\n   sock.bind(('::1', 0))\n   return True\n  except (socket.error, socket.gaierror):\n   pass\n  finally:\n   if sock:\n    sock.close()\n return False\n \nIPV6_ENABLED = _is_ipv6_enabled()\n\n\n\n\n\nPIPE_MAX_SIZE = 3 * 1000 * 1000\n\n\n\nrequires_IEEE_754 = unittest.skipUnless(\nfloat.__getformat__(\"double\").startswith(\"IEEE\"),\n\"test requires IEEE 754 doubles\")\n\nrequires_zlib = unittest.skipUnless(zlib, 'requires zlib')\n\nrequires_bz2 = unittest.skipUnless(bz2, 'requires bz2')\n\nrequires_lzma = unittest.skipUnless(lzma, 'requires lzma')\n\nis_jython = sys.platform.startswith('java')\n\n\nif os.name == 'java':\n\n TESTFN = '$test'\nelse:\n TESTFN = '@test'\n \n \n \nTESTFN = \"{}_{}_tmp\".format(TESTFN, os.getpid())\n\n\n\nFS_NONASCII = None\nfor character in (\n\n\n\n\n\n'\\u00E6',\n\n'\\u0130',\n\n'\\u0141',\n\n'\\u03C6',\n\n'\\u041A',\n\n'\\u05D0',\n\n'\\u060C',\n\n'\\u062A',\n\n'\\u0E01',\n\n\n\n\n\n\n'\\u00A0',\n\n'\\u20AC',\n):\n try:\n  os.fsdecode(os.fsencode(character))\n except UnicodeError:\n  pass\n else:\n  FS_NONASCII = character\n  break\n  \n  \nTESTFN_UNICODE = TESTFN + \"-\\xe0\\xf2\\u0258\\u0141\\u011f\"\nif sys.platform == 'darwin':\n\n\n\n import unicodedata\n TESTFN_UNICODE = unicodedata.normalize('NFD', TESTFN_UNICODE)\nTESTFN_ENCODING = sys.getfilesystemencoding()\n\n\n\n\nTESTFN_UNENCODABLE = None\nif os.name in ('nt', 'ce'):\n\n if sys.getwindowsversion().platform >= 2:\n \n \n  TESTFN_UNENCODABLE = TESTFN + \"-\\u5171\\u0141\\u2661\\u0363\\uDC80\"\n  try:\n   TESTFN_UNENCODABLE.encode(TESTFN_ENCODING)\n  except UnicodeEncodeError:\n   pass\n  else:\n   print('WARNING: The filename %r CAN be encoded by the filesystem encoding (%s). '\n   'Unicode filename tests may not be effective'\n   % (TESTFN_UNENCODABLE, TESTFN_ENCODING))\n   TESTFN_UNENCODABLE = None\n   \nelif sys.platform != 'darwin':\n try:\n \n  \"\".decode(TESTFN_ENCODING)\n except UnicodeDecodeError:\n \n  TESTFN_UNENCODABLE = TESTFN + b'-\\xff'.decode(TESTFN_ENCODING, 'surrogateescape')\n else:\n \n \n  pass\n  \n  \n  \n  \n  \n  \n  \nTESTFN_UNDECODABLE = None\n\"\"\nif FS_NONASCII:\n TESTFN_NONASCII = TESTFN + '-' + FS_NONASCII\nelse:\n TESTFN_NONASCII = None\n \n \nSAVEDCWD = os.getcwd()\n\n@contextlib.contextmanager\ndef temp_cwd(name='tempcwd', quiet=False, path=None):\n \"\"\n saved_dir = os.getcwd()\n is_temporary = False\n if path is None:\n  path = name\n  try:\n   os.mkdir(name)\n   is_temporary = True\n  except OSError:\n   if not quiet:\n    raise\n   warnings.warn('tests may fail, unable to create temp CWD ' + name,\n   RuntimeWarning, stacklevel=3)\n try:\n  os.chdir(path)\n except OSError:\n  if not quiet:\n   raise\n  warnings.warn('tests may fail, unable to change the CWD to ' + path,\n  RuntimeWarning, stacklevel=3)\n try:\n  yield os.getcwd()\n finally:\n  os.chdir(saved_dir)\n  if is_temporary:\n   rmtree(name)\n   \n   \nif hasattr(os, \"umask\"):\n @contextlib.contextmanager\n def temp_umask(umask):\n  \"\"\n  oldmask = os.umask(umask)\n  try:\n   yield\n  finally:\n   os.umask(oldmask)\n   \n   \ndef findfile(file, here=__file__, subdir=None):\n \"\"\n if os.path.isabs(file):\n  return file\n if subdir is not None:\n  file = os.path.join(subdir, file)\n path = sys.path\n path = [os.path.dirname(here)] + path\n for dn in path:\n  fn = os.path.join(dn, file)\n  if os.path.exists(fn): return fn\n return file\n \ndef create_empty_file(filename):\n \"\"\n fd = os.open(filename, os.O_WRONLY | os.O_CREAT | os.O_TRUNC)\n os.close(fd)\n \ndef sortdict(dict):\n \"\"\n items = sorted(dict.items())\n reprpairs = [\"%r: %r\" % pair for pair in items]\n withcommas = \", \".join(reprpairs)\n return \"{%s}\" % withcommas\n \ndef make_bad_fd():\n \"\"\n file = open(TESTFN, \"wb\")\n try:\n  return file.fileno()\n finally:\n  file.close()\n  unlink(TESTFN)\n  \ndef check_syntax_error(testcase, statement):\n testcase.assertRaises(SyntaxError, compile, statement,\n '<test string>', 'exec')\n \ndef open_urlresource(url, *args, **kw):\n import urllib.request, urllib.parse\n \n check = kw.pop('check', None)\n \n filename = urllib.parse.urlparse(url)[2].split('/')[-1] \n \n fn = os.path.join(os.path.dirname(__file__), \"data\", filename)\n \n def check_valid_file(fn):\n  f = open(fn, *args, **kw)\n  if check is None:\n   return f\n  elif check(f):\n   f.seek(0)\n   return f\n  f.close()\n  \n if os.path.exists(fn):\n  f = check_valid_file(fn)\n  if f is not None:\n   return f\n  unlink(fn)\n  \n  \n requires('urlfetch')\n \n print('\\tfetching %s ...' % url, file=get_original_stdout())\n f = urllib.request.urlopen(url, timeout=15)\n try:\n  with open(fn, \"wb\") as out:\n   s = f.read()\n   while s:\n    out.write(s)\n    s = f.read()\n finally:\n  f.close()\n  \n f = check_valid_file(fn)\n if f is not None:\n  return f\n raise TestFailed('invalid resource %r' % fn)\n \n \nclass WarningsRecorder(object):\n \"\"\n def __init__(self, warnings_list):\n  self._warnings = warnings_list\n  self._last = 0\n  \n def __getattr__(self, attr):\n  if len(self._warnings) > self._last:\n   return getattr(self._warnings[-1], attr)\n  elif attr in warnings.WarningMessage._WARNING_DETAILS:\n   return None\n  raise AttributeError(\"%r has no attribute %r\" % (self, attr))\n  \n @property\n def warnings(self):\n  return self._warnings[self._last:]\n  \n def reset(self):\n  self._last = len(self._warnings)\n  \n  \ndef _filterwarnings(filters, quiet=False):\n \"\"\n \n \n frame = sys._getframe(2)\n registry = frame.f_globals.get('__warningregistry__')\n if registry:\n  registry.clear()\n with warnings.catch_warnings(record=True) as w:\n \n \n \n  sys.modules['warnings'].simplefilter(\"always\")\n  yield WarningsRecorder(w)\n  \n reraise = list(w)\n missing = []\n for msg, cat in filters:\n  seen = False\n  for w in reraise[:]:\n   warning = w.message\n   \n   if (re.match(msg, str(warning), re.I) and\n   issubclass(warning.__class__, cat)):\n    seen = True\n    reraise.remove(w)\n  if not seen and not quiet:\n  \n   missing.append((msg, cat.__name__))\n if reraise:\n  raise AssertionError(\"unhandled warning %s\" % reraise[0])\n if missing:\n  raise AssertionError(\"filter (%r, %s) did not catch any warning\" %\n  missing[0])\n  \n  \n@contextlib.contextmanager\ndef check_warnings(*filters, **kwargs):\n \"\"\n quiet = kwargs.get('quiet')\n if not filters:\n  filters = ((\"\", Warning),)\n  \n  if quiet is None:\n   quiet = True\n return _filterwarnings(filters, quiet)\n \n \nclass CleanImport(object):\n \"\"\n \n def __init__(self, *module_names):\n  self.original_modules = sys.modules.copy()\n  for module_name in module_names:\n   if module_name in sys.modules:\n    module = sys.modules[module_name]\n    \n    \n    \n    \n    if module.__name__ != module_name:\n     del sys.modules[module.__name__]\n    del sys.modules[module_name]\n    \n def __enter__(self):\n  return self\n  \n def __exit__(self, *ignore_exc):\n  sys.modules.update(self.original_modules)\n  \n  \nclass EnvironmentVarGuard(collections.abc.MutableMapping):\n\n \"\"\n \n def __init__(self):\n  self._environ = os.environ\n  self._changed = {}\n  \n def __getitem__(self, envvar):\n  return self._environ[envvar]\n  \n def __setitem__(self, envvar, value):\n \n  if envvar not in self._changed:\n   self._changed[envvar] = self._environ.get(envvar)\n  self._environ[envvar] = value\n  \n def __delitem__(self, envvar):\n \n  if envvar not in self._changed:\n   self._changed[envvar] = self._environ.get(envvar)\n  if envvar in self._environ:\n   del self._environ[envvar]\n   \n def keys(self):\n  return self._environ.keys()\n  \n def __iter__(self):\n  return iter(self._environ)\n  \n def __len__(self):\n  return len(self._environ)\n  \n def set(self, envvar, value):\n  self[envvar] = value\n  \n def unset(self, envvar):\n  del self[envvar]\n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, *ignore_exc):\n  for (k, v) in self._changed.items():\n   if v is None:\n    if k in self._environ:\n     del self._environ[k]\n   else:\n    self._environ[k] = v\n  os.environ = self._environ\n  \n  \nclass DirsOnSysPath(object):\n \"\"\n \n def __init__(self, *paths):\n  self.original_value = sys.path[:]\n  self.original_object = sys.path\n  sys.path.extend(paths)\n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, *ignore_exc):\n  sys.path = self.original_object\n  sys.path[:] = self.original_value\n  \n  \nclass TransientResource(object):\n\n \"\"\n \n def __init__(self, exc, **kwargs):\n  self.exc = exc\n  self.attrs = kwargs\n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, type_=None, value=None, traceback=None):\n  \"\"\n  if type_ is not None and issubclass(self.exc, type_):\n   for attr, attr_value in self.attrs.items():\n    if not hasattr(value, attr):\n     break\n    if getattr(value, attr) != attr_value:\n     break\n   else:\n    raise ResourceDenied(\"an optional resource is not available\")\n    \n    \n    \n    \ntime_out = TransientResource(IOError, errno=errno.ETIMEDOUT)\nsocket_peer_reset = TransientResource(socket.error, errno=errno.ECONNRESET)\nioerror_peer_reset = TransientResource(IOError, errno=errno.ECONNRESET)\n\n\n@contextlib.contextmanager\ndef transient_internet(resource_name, *, timeout=30.0, errnos=()):\n \"\"\n default_errnos = [\n ('ECONNREFUSED', 111),\n ('ECONNRESET', 104),\n ('EHOSTUNREACH', 113),\n ('ENETUNREACH', 101),\n ('ETIMEDOUT', 110),\n ]\n default_gai_errnos = [\n ('EAI_AGAIN', -3),\n ('EAI_FAIL', -4),\n ('EAI_NONAME', -2),\n ('EAI_NODATA', -5),\n \n ('WSANO_DATA', 11004),\n ]\n \n denied = ResourceDenied(\"Resource %r is not available\" % resource_name)\n captured_errnos = errnos\n gai_errnos = []\n if not captured_errnos:\n  captured_errnos = [getattr(errno, name, num)\n  for (name, num) in default_errnos]\n  gai_errnos = [getattr(socket, name, num)\n  for (name, num) in default_gai_errnos]\n  \n def filter_error(err):\n  n = getattr(err, 'errno', None)\n  if (isinstance(err, socket.timeout) or\n  (isinstance(err, socket.gaierror) and n in gai_errnos) or\n  n in captured_errnos):\n   if not verbose:\n    sys.stderr.write(denied.args[0] + \"\\n\")\n   raise denied from err\n   \n old_timeout = socket.getdefaulttimeout()\n try:\n  if timeout is not None:\n   socket.setdefaulttimeout(timeout)\n  yield\n except IOError as err:\n \n \n  while True:\n   a = err.args\n   if len(a) >= 1 and isinstance(a[0], IOError):\n    err = a[0]\n    \n    \n    \n   elif len(a) >= 2 and isinstance(a[1], IOError):\n    err = a[1]\n   else:\n    break\n  filter_error(err)\n  raise\n  \n  \n finally:\n  socket.setdefaulttimeout(old_timeout)\n  \n  \n@contextlib.contextmanager\ndef captured_output(stream_name):\n \"\"\n import io\n orig_stdout = getattr(sys, stream_name)\n setattr(sys, stream_name, io.StringIO())\n try:\n  yield getattr(sys, stream_name)\n finally:\n  setattr(sys, stream_name, orig_stdout)\n  \ndef captured_stdout():\n \"\"\n return captured_output(\"stdout\")\n \ndef captured_stderr():\n return captured_output(\"stderr\")\n \ndef captured_stdin():\n return captured_output(\"stdin\")\n \n \ndef gc_collect():\n \"\"\n gc.collect()\n if is_jython:\n  time.sleep(0.1)\n gc.collect()\n gc.collect()\n \n@contextlib.contextmanager\ndef disable_gc():\n have_gc = gc.isenabled()\n gc.disable()\n try:\n  yield\n finally:\n  if have_gc:\n   gc.enable()\n   \n   \ndef python_is_optimized():\n \"\"\n cflags = sysconfig.get_config_var('PY_CFLAGS') or ''\n final_opt = \"\"\n for opt in cflags.split():\n  if opt.startswith('-O'):\n   final_opt = opt\n return final_opt != '' and final_opt != '-O0'\n \n \n_header = 'nP'\n_align = '0n'\nif hasattr(sys, \"gettotalrefcount\"):\n _header = '2P' + _header\n _align = '0P'\n_vheader = _header + 'n'\n\ndef calcobjsize(fmt):\n return struct.calcsize(_header + fmt + _align)\n \ndef calcvobjsize(fmt):\n return struct.calcsize(_vheader + fmt + _align)\n \n \n_TPFLAGS_HAVE_GC = 1<<14\n_TPFLAGS_HEAPTYPE = 1<<9\n\ndef check_sizeof(test, o, size):\n result = sys.getsizeof(o)\n \n if ((type(o) == type) and (o.__flags__ & _TPFLAGS_HEAPTYPE) or ((type(o) != type) and (type(o).__flags__ & _TPFLAGS_HAVE_GC))):\n  size += _testcapi.SIZEOF_PYGC_HEAD\n msg = 'wrong size for %s: got %d, expected %d' % (type(o), result, size)\n test.assertEqual(result, size, msg)\n \n \n \n \n \ndef run_with_locale(catstr, *locales):\n def decorator(func):\n  def inner(*args, **kwds):\n   try:\n    import locale\n    category = getattr(locale, catstr)\n    orig_locale = locale.setlocale(category)\n   except AttributeError:\n   \n    raise\n   except:\n   \n    locale = orig_locale = None\n   else:\n    for loc in locales:\n     try:\n      locale.setlocale(category, loc)\n      break\n     except:\n      pass\n      \n      \n   try:\n    return func(*args, **kwds)\n   finally:\n    if locale and orig_locale:\n     locale.setlocale(category, orig_locale)\n  inner.__name__ = func.__name__\n  inner.__doc__ = func.__doc__\n  return inner\n return decorator\n \n \n \n \n \ndef run_with_tz(tz):\n def decorator(func):\n  def inner(*args, **kwds):\n   try:\n    tzset = time.tzset\n   except AttributeError:\n    raise unittest.SkipTest(\"tzset required\")\n   if 'TZ' in os.environ:\n    orig_tz = os.environ['TZ']\n   else:\n    orig_tz = None\n   os.environ['TZ'] = tz\n   tzset()\n   \n   \n   try:\n    return func(*args, **kwds)\n   finally:\n    if orig_tz is None:\n     del os.environ['TZ']\n    else:\n     os.environ['TZ'] = orig_tz\n    time.tzset()\n    \n  inner.__name__ = func.__name__\n  inner.__doc__ = func.__doc__\n  return inner\n return decorator\n \n \n \n \n \n \n \n_1M = 1024*1024\n_1G = 1024 * _1M\n_2G = 2 * _1G\n_4G = 4 * _1G\n\nMAX_Py_ssize_t = sys.maxsize\n\ndef set_memlimit(limit):\n global max_memuse\n global real_max_memuse\n sizes = {\n 'k': 1024,\n 'm': _1M,\n 'g': _1G,\n 't': 1024*_1G,\n }\n m = re.match(r'(\\d+(\\.\\d+)?) (K|M|G|T)b?$', limit,\n re.IGNORECASE | re.VERBOSE)\n if m is None:\n  raise ValueError('Invalid memory limit %r' % (limit,))\n memlimit = int(float(m.group(1)) * sizes[m.group(3).lower()])\n real_max_memuse = memlimit\n if memlimit > MAX_Py_ssize_t:\n  memlimit = MAX_Py_ssize_t\n if memlimit < _2G - 1:\n  raise ValueError('Memory limit %r too low to be useful' % (limit,))\n max_memuse = memlimit\n \nclass _MemoryWatchdog:\n \"\"\n \n def __init__(self):\n  self.procfile = '/proc/{pid}/statm'.format(pid=os.getpid())\n  self.started = False\n  \n def start(self):\n  try:\n   f = open(self.procfile, 'r')\n  except OSError as e:\n   warnings.warn('/proc not available for stats: {}'.format(e),\n   RuntimeWarning)\n   sys.stderr.flush()\n   return\n   \n  watchdog_script = findfile(\"memory_watchdog.py\")\n  self.mem_watchdog = subprocess.Popen([sys.executable, watchdog_script],\n  stdin=f, stderr=subprocess.DEVNULL)\n  f.close()\n  self.started = True\n  \n def stop(self):\n  if self.started:\n   self.mem_watchdog.terminate()\n   self.mem_watchdog.wait()\n   \n   \ndef bigmemtest(size, memuse, dry_run=True):\n \"\"\n def decorator(f):\n  def wrapper(self):\n   size = wrapper.size\n   memuse = wrapper.memuse\n   if not real_max_memuse:\n    maxsize = 5147\n   else:\n    maxsize = size\n    \n   if ((real_max_memuse or not dry_run)\n   and real_max_memuse < maxsize * memuse):\n    raise unittest.SkipTest(\n    \"not enough memory: %.1fG minimum needed\"\n    % (size * memuse / (1024 ** 3)))\n    \n   if real_max_memuse and verbose:\n    print()\n    print(\" ... expected peak memory use: {peak:.1f}G\"\n    .format(peak=size * memuse / (1024 ** 3)))\n    watchdog = _MemoryWatchdog()\n    watchdog.start()\n   else:\n    watchdog = None\n    \n   try:\n    return f(self, maxsize)\n   finally:\n    if watchdog:\n     watchdog.stop()\n     \n  wrapper.size = size\n  wrapper.memuse = memuse\n  return wrapper\n return decorator\n \ndef bigaddrspacetest(f):\n \"\"\n def wrapper(self):\n  if max_memuse < MAX_Py_ssize_t:\n   if MAX_Py_ssize_t >= 2**63 - 1 and max_memuse >= 2**31:\n    raise unittest.SkipTest(\n    \"not enough memory: try a 32-bit build instead\")\n   else:\n    raise unittest.SkipTest(\n    \"not enough memory: %.1fG minimum needed\"\n    % (MAX_Py_ssize_t / (1024 ** 3)))\n  else:\n   return f(self)\n return wrapper\n \n \n \n \nclass BasicTestRunner:\n def run(self, test):\n  result = unittest.TestResult()\n  test(result)\n  return result\n  \ndef _id(obj):\n return obj\n \ndef requires_resource(resource):\n if resource == 'gui' and not _is_gui_available():\n  return unittest.skip(\"resource 'gui' is not available\")\n if is_resource_enabled(resource):\n  return _id\n else:\n  return unittest.skip(\"resource {0!r} is not enabled\".format(resource))\n  \ndef cpython_only(test):\n \"\"\n return impl_detail(cpython=True)(test)\n \ndef impl_detail(msg=None, **guards):\n if check_impl_detail(**guards):\n  return _id\n if msg is None:\n  guardnames, default = _parse_guards(guards)\n  if default:\n   msg = \"implementation detail not available on {0}\"\n  else:\n   msg = \"implementation detail specific to {0}\"\n  guardnames = sorted(guardnames.keys())\n  msg = msg.format(' or '.join(guardnames))\n return unittest.skip(msg)\n \ndef _parse_guards(guards):\n\n if not guards:\n  return ({'cpython': True}, False)\n is_true = list(guards.values())[0]\n assert list(guards.values()) == [is_true] * len(guards) \n return (guards, not is_true)\n \n \n \ndef check_impl_detail(**guards):\n \"\"\n guards, default = _parse_guards(guards)\n return guards.get(platform.python_implementation().lower(), default)\n \n \ndef no_tracing(func):\n \"\"\n if not hasattr(sys, 'gettrace'):\n  return func\n else:\n  @functools.wraps(func)\n  def wrapper(*args, **kwargs):\n   original_trace = sys.gettrace()\n   try:\n    sys.settrace(None)\n    return func(*args, **kwargs)\n   finally:\n    sys.settrace(original_trace)\n  return wrapper\n  \n  \ndef refcount_test(test):\n \"\"\n return no_tracing(cpython_only(test))\n \n \ndef _filter_suite(suite, pred):\n \"\"\n newtests = []\n for test in suite._tests:\n  if isinstance(test, unittest.TestSuite):\n   _filter_suite(test, pred)\n   newtests.append(test)\n  else:\n   if pred(test):\n    newtests.append(test)\n suite._tests = newtests\n \ndef _run_suite(suite):\n \"\"\n if verbose:\n  runner = unittest.TextTestRunner(sys.stdout, verbosity=2,\n  failfast=failfast)\n else:\n  runner = BasicTestRunner()\n  \n result = runner.run(suite)\n if not result.wasSuccessful():\n  if len(result.errors) == 1 and not result.failures:\n   err = result.errors[0][1]\n  elif len(result.failures) == 1 and not result.errors:\n   err = result.failures[0][1]\n  else:\n   err = \"multiple errors occurred\"\n   if not verbose: err += \"; run in verbose mode for details\"\n  raise TestFailed(err)\n  \n  \ndef run_unittest(*classes):\n \"\"\n valid_types = (unittest.TestSuite, unittest.TestCase)\n suite = unittest.TestSuite()\n for cls in classes:\n  if isinstance(cls, str):\n   if cls in sys.modules:\n    suite.addTest(unittest.findTestCases(sys.modules[cls]))\n   else:\n    raise ValueError(\"str arguments must be keys in sys.modules\")\n  elif isinstance(cls, valid_types):\n   suite.addTest(cls)\n  else:\n   suite.addTest(unittest.makeSuite(cls))\n def case_pred(test):\n  if match_tests is None:\n   return True\n  for name in test.id().split(\".\"):\n   if fnmatch.fnmatchcase(name, match_tests):\n    return True\n  return False\n _filter_suite(suite, case_pred)\n _run_suite(suite)\n \n \n \n \nHAVE_DOCSTRINGS = (check_impl_detail(cpython=False) or\nsys.platform == 'win32' or\nsysconfig.get_config_var('WITH_DOC_STRINGS'))\n\nrequires_docstrings = unittest.skipUnless(HAVE_DOCSTRINGS,\n\"test requires docstrings\")\n\n\n\n\n\ndef run_doctest(module, verbosity=None, optionflags=0):\n \"\"\n \n import doctest\n \n if verbosity is None:\n  verbosity = verbose\n else:\n  verbosity = None\n  \n f, t = doctest.testmod(module, verbose=verbosity, optionflags=optionflags)\n if f:\n  raise TestFailed(\"%d of %d doctests failed\" % (f, t))\n if verbose:\n  print('doctest (%s) ... %d tests with zero failures' %\n  (module.__name__, t))\n return f, t\n \n \n \n \n \ndef modules_setup():\n return sys.modules.copy(),\n \ndef modules_cleanup(oldmodules):\n\n\n\n encodings = [(k, v) for k, v in sys.modules.items()\n if k.startswith('encodings.')]\n sys.modules.clear()\n sys.modules.update(encodings)\n \n \n \n \n \n \n sys.modules.update(oldmodules)\n \n \n \n \n \n \n \n \n \n \n \n \ndef threading_setup():\n if _thread:\n  return _thread._count(), threading._dangling.copy()\n else:\n  return 1, ()\n  \ndef threading_cleanup(*original_values):\n if not _thread:\n  return\n _MAX_COUNT = 10\n for count in range(_MAX_COUNT):\n  values = _thread._count(), threading._dangling\n  if values == original_values:\n   break\n  time.sleep(0.1)\n  gc_collect()\n  \n  \ndef reap_threads(func):\n \"\"\n if not _thread:\n  return func\n  \n @functools.wraps(func)\n def decorator(*args):\n  key = threading_setup()\n  try:\n   return func(*args)\n  finally:\n   threading_cleanup(*key)\n return decorator\n \ndef reap_children():\n \"\"\n \n \n \n if hasattr(os, 'waitpid'):\n  any_process = -1\n  while True:\n   try:\n   \n    pid, status = os.waitpid(any_process, os.WNOHANG)\n    if pid == 0:\n     break\n   except:\n    break\n    \n@contextlib.contextmanager\ndef swap_attr(obj, attr, new_val):\n \"\"\n if hasattr(obj, attr):\n  real_val = getattr(obj, attr)\n  setattr(obj, attr, new_val)\n  try:\n   yield\n  finally:\n   setattr(obj, attr, real_val)\n else:\n  setattr(obj, attr, new_val)\n  try:\n   yield\n  finally:\n   delattr(obj, attr)\n   \n@contextlib.contextmanager\ndef swap_item(obj, item, new_val):\n \"\"\n if item in obj:\n  real_val = obj[item]\n  obj[item] = new_val\n  try:\n   yield\n  finally:\n   obj[item] = real_val\n else:\n  obj[item] = new_val\n  try:\n   yield\n  finally:\n   del obj[item]\n   \ndef strip_python_stderr(stderr):\n \"\"\n stderr = re.sub(br\"\\[\\d+ refs\\]\\r?\\n?\", b\"\", stderr).strip()\n return stderr\n \ndef args_from_interpreter_flags():\n \"\"\n return subprocess._args_from_interpreter_flags()\n \n \n \n \n \nclass TestHandler(logging.handlers.BufferingHandler):\n def __init__(self, matcher):\n \n \n \n \n \n  logging.handlers.BufferingHandler.__init__(self, 0)\n  self.matcher = matcher\n  \n def shouldFlush(self):\n  return False\n  \n def emit(self, record):\n  self.format(record)\n  self.buffer.append(record.__dict__)\n  \n def matches(self, **kwargs):\n  \"\"\n  result = False\n  for d in self.buffer:\n   if self.matcher.matches(d, **kwargs):\n    result = True\n    break\n  return result\n  \nclass Matcher(object):\n\n _partial_matches = ('msg', 'message')\n \n def matches(self, d, **kwargs):\n  \"\"\n  result = True\n  for k in kwargs:\n   v = kwargs[k]\n   dv = d.get(k)\n   if not self.match_value(k, dv, v):\n    result = False\n    break\n  return result\n  \n def match_value(self, k, dv, v):\n  \"\"\n  if type(v) != type(dv):\n   result = False\n  elif type(dv) is not str or k not in self._partial_matches:\n   result = (v == dv)\n  else:\n   result = dv.find(v) >= 0\n  return result\n  \n  \n_can_symlink = None\ndef can_symlink():\n global _can_symlink\n if _can_symlink is not None:\n  return _can_symlink\n symlink_path = TESTFN + \"can_symlink\"\n try:\n  os.symlink(TESTFN, symlink_path)\n  can = True\n except (OSError, NotImplementedError, AttributeError):\n  can = False\n else:\n  os.remove(symlink_path)\n _can_symlink = can\n return can\n \ndef skip_unless_symlink(test):\n \"\"\n ok = can_symlink()\n msg = \"Requires functional symlink implementation\"\n return test if ok else unittest.skip(msg)(test)\n \n_can_xattr = None\ndef can_xattr():\n global _can_xattr\n if _can_xattr is not None:\n  return _can_xattr\n if not hasattr(os, \"setxattr\"):\n  can = False\n else:\n  tmp_fp, tmp_name = tempfile.mkstemp()\n  try:\n   with open(TESTFN, \"wb\") as fp:\n    try:\n    \n    \n     os.setxattr(tmp_fp, b\"user.test\", b\"\")\n     os.setxattr(fp.fileno(), b\"user.test\", b\"\")\n     \n     kernel_version = platform.release()\n     m = re.match(\"2.6.(\\d{1,2})\", kernel_version)\n     can = m is None or int(m.group(1)) >= 39\n    except OSError:\n     can = False\n  finally:\n   unlink(TESTFN)\n   unlink(tmp_name)\n _can_xattr = can\n return can\n \ndef skip_unless_xattr(test):\n \"\"\n ok = can_xattr()\n msg = \"no non-broken extended attribute support\"\n return test if ok else unittest.skip(msg)(test)\n \n \nif sys.platform.startswith('win'):\n @contextlib.contextmanager\n def suppress_crash_popup():\n  \"\"\n  \n  \n  \n  import ctypes\n  k32 = ctypes.windll.kernel32\n  SEM_NOGPFAULTERRORBOX = 0x02\n  old_error_mode = k32.SetErrorMode(SEM_NOGPFAULTERRORBOX)\n  k32.SetErrorMode(old_error_mode | SEM_NOGPFAULTERRORBOX)\n  try:\n   yield\n  finally:\n   k32.SetErrorMode(old_error_mode)\nelse:\n\n @contextlib.contextmanager\n def suppress_crash_popup():\n  yield\n  \n  \ndef patch(test_instance, object_to_patch, attr_name, new_value):\n \"\"\n \n \n getattr(object_to_patch, attr_name)\n \n \n attr_is_local = False\n try:\n  old_value = object_to_patch.__dict__[attr_name]\n except (AttributeError, KeyError):\n  old_value = getattr(object_to_patch, attr_name, None)\n else:\n  attr_is_local = True\n  \n  \n def cleanup():\n  if attr_is_local:\n   setattr(object_to_patch, attr_name, old_value)\n  else:\n   delattr(object_to_patch, attr_name)\n   \n test_instance.addCleanup(cleanup)\n \n \n setattr(object_to_patch, attr_name, new_value)\n \n"], "xml.sax.xmlreader": [".py", "\"\"\n\nfrom . import handler\n\nfrom ._exceptions import SAXNotSupportedException, SAXNotRecognizedException\n\n\n\n\nclass XMLReader:\n \"\"\n \n def __init__(self):\n  self._cont_handler = handler.ContentHandler()\n  self._dtd_handler = handler.DTDHandler()\n  self._ent_handler = handler.EntityResolver()\n  self._err_handler = handler.ErrorHandler()\n  \n def parse(self, source):\n  \"\"\n  raise NotImplementedError(\"This method must be implemented!\")\n  \n def getContentHandler(self):\n  \"\"\n  return self._cont_handler\n  \n def setContentHandler(self, handler):\n  \"\"\n  self._cont_handler = handler\n  \n def getDTDHandler(self):\n  \"\"\n  return self._dtd_handler\n  \n def setDTDHandler(self, handler):\n  \"\"\n  self._dtd_handler = handler\n  \n def getEntityResolver(self):\n  \"\"\n  return self._ent_handler\n  \n def setEntityResolver(self, resolver):\n  \"\"\n  self._ent_handler = resolver\n  \n def getErrorHandler(self):\n  \"\"\n  return self._err_handler\n  \n def setErrorHandler(self, handler):\n  \"\"\n  self._err_handler = handler\n  \n def setLocale(self, locale):\n  \"\"\n  raise SAXNotSupportedException(\"Locale support not implemented\")\n  \n def getFeature(self, name):\n  \"\"\n  raise SAXNotRecognizedException(\"Feature '%s' not recognized\" % name)\n  \n def setFeature(self, name, state):\n  \"\"\n  raise SAXNotRecognizedException(\"Feature '%s' not recognized\" % name)\n  \n def getProperty(self, name):\n  \"\"\n  raise SAXNotRecognizedException(\"Property '%s' not recognized\" % name)\n  \n def setProperty(self, name, value):\n  \"\"\n  raise SAXNotRecognizedException(\"Property '%s' not recognized\" % name)\n  \nclass IncrementalParser(XMLReader):\n \"\"\n \n def __init__(self, bufsize=2**16):\n  self._bufsize = bufsize\n  XMLReader.__init__(self)\n  \n def parse(self, source):\n  from . import saxutils\n  source = saxutils.prepare_input_source(source)\n  \n  self.prepareParser(source)\n  file = source.getByteStream()\n  buffer = file.read(self._bufsize)\n  while buffer:\n   self.feed(buffer)\n   buffer = file.read(self._bufsize)\n  self.close()\n  \n def feed(self, data):\n  \"\"\n  raise NotImplementedError(\"This method must be implemented!\")\n  \n def prepareParser(self, source):\n  \"\"\n  raise NotImplementedError(\"prepareParser must be overridden!\")\n  \n def close(self):\n  \"\"\n  raise NotImplementedError(\"This method must be implemented!\")\n  \n def reset(self):\n  \"\"\n  raise NotImplementedError(\"This method must be implemented!\")\n  \n  \n  \nclass Locator:\n \"\"\n \n def getColumnNumber(self):\n  \"\"\n  return -1\n  \n def getLineNumber(self):\n  \"\"\n  return -1\n  \n def getPublicId(self):\n  \"\"\n  return None\n  \n def getSystemId(self):\n  \"\"\n  return None\n  \n  \n  \nclass InputSource:\n \"\"\n \n def __init__(self, system_id = None):\n  self.__system_id = system_id\n  self.__public_id = None\n  self.__encoding = None\n  self.__bytefile = None\n  self.__charfile = None\n  \n def setPublicId(self, public_id):\n  \"\"\n  self.__public_id = public_id\n  \n def getPublicId(self):\n  \"\"\n  return self.__public_id\n  \n def setSystemId(self, system_id):\n  \"\"\n  self.__system_id = system_id\n  \n def getSystemId(self):\n  \"\"\n  return self.__system_id\n  \n def setEncoding(self, encoding):\n  \"\"\n  self.__encoding = encoding\n  \n def getEncoding(self):\n  \"\"\n  return self.__encoding\n  \n def setByteStream(self, bytefile):\n  \"\"\n  self.__bytefile = bytefile\n  \n def getByteStream(self):\n  \"\"\n  return self.__bytefile\n  \n def setCharacterStream(self, charfile):\n  \"\"\n  self.__charfile = charfile\n  \n def getCharacterStream(self):\n  \"\"\n  return self.__charfile\n  \n  \n  \nclass AttributesImpl:\n\n def __init__(self, attrs):\n  \"\"\n  self._attrs = attrs\n  \n def getLength(self):\n  return len(self._attrs)\n  \n def getType(self, name):\n  return \"CDATA\"\n  \n def getValue(self, name):\n  return self._attrs[name]\n  \n def getValueByQName(self, name):\n  return self._attrs[name]\n  \n def getNameByQName(self, name):\n  if name not in self._attrs:\n   raise KeyError(name)\n  return name\n  \n def getQNameByName(self, name):\n  if name not in self._attrs:\n   raise KeyError(name)\n  return name\n  \n def getNames(self):\n  return list(self._attrs.keys())\n  \n def getQNames(self):\n  return list(self._attrs.keys())\n  \n def __len__(self):\n  return len(self._attrs)\n  \n def __getitem__(self, name):\n  return self._attrs[name]\n  \n def keys(self):\n  return list(self._attrs.keys())\n  \n def __contains__(self, name):\n  return name in self._attrs\n  \n def get(self, name, alternative=None):\n  return self._attrs.get(name, alternative)\n  \n def copy(self):\n  return self.__class__(self._attrs)\n  \n def items(self):\n  return list(self._attrs.items())\n  \n def values(self):\n  return list(self._attrs.values())\n  \n  \n  \nclass AttributesNSImpl(AttributesImpl):\n\n def __init__(self, attrs, qnames):\n  \"\"\n  self._attrs = attrs\n  self._qnames = qnames\n  \n def getValueByQName(self, name):\n  for (nsname, qname) in self._qnames.items():\n   if qname == name:\n    return self._attrs[nsname]\n    \n  raise KeyError(name)\n  \n def getNameByQName(self, name):\n  for (nsname, qname) in self._qnames.items():\n   if qname == name:\n    return nsname\n    \n  raise KeyError(name)\n  \n def getQNameByName(self, name):\n  return self._qnames[name]\n  \n def getQNames(self):\n  return list(self._qnames.values())\n  \n def copy(self):\n  return self.__class__(self._attrs, self._qnames)\n  \n  \ndef _test():\n XMLReader()\n IncrementalParser()\n Locator()\n \nif __name__ == \"__main__\":\n _test()\n"], "unittest.test.dummy": [".py", "\n"], "operator": [".py", "\n\"\"\n\n\n\n\n\ndef lt(a, b):\n \"\"\n return a < b\n__lt__ = lt\n\ndef le(a, b):\n \"\"\n return a <= b\n__le__ = le\n\ndef eq(a, b):\n \"\"\n return a == b\n__eq__ = eq\n\ndef ne(a, b):\n \"\"\n return a != b\n__ne__ = ne\n\ndef ge(a, b):\n \"\"\n return a >= b\n__ge__ = ge\n\ndef gt(a, b):\n \"\"\n return a > b\n__gt__ = gt\n\ndef not_(a):\n \"\"\n return not a\n__not__ = not_\n\ndef truth(a):\n \"\"\n \n return bool(a)\n \ndef is_(a, b):\n \"\"\n return a is b\n \n \n \n \n \n \n \n \n \n \n \n__abs__ = abs\nabs=abs\n\n\ndef add(a, b):\n \"\"\n return a + b\n__add__ = add\n\ndef and_(a, b):\n \"\"\n return a & b\n__and__ = and_\n\ndef floordiv(a, b):\n \"\"\n return a // b\n__floordiv__ = floordiv\n\ndef index(a):\n \"\"\n return a.__index__()\n__index__ = index\n\ndef inv(a):\n \"\"\n return ~a \n \ninvert = __inv__ = __invert__ = inv\n\ndef lshift(a, b):\n \"\"\n return a << b\n__lshift__ = lshift\n\ndef mod(a, b):\n \"\"\n return a % b\n__mod__ = mod\n\ndef mul(a, b):\n \"\"\n return a * b\n__mul__ = mul\n\ndef neg(a):\n \"\"\n return -a\n__neg__ = neg\n\ndef or_(a, b):\n \"\"\n return a | b\n__or__ = or_\n\ndef pos(a):\n \"\"\n return +a \n if a >= 0: return a\n return -a\n__pos__ = pos\n\ndef pow(a, b):\n \"\"\n return a ** b\n__pow__ = pow\n\ndef rshift(a, b):\n \"\"\n return a >> b\n__rshift__ = rshift\n\ndef sub(a, b):\n \"\"\n return a - b\n__sub__ = sub\n\ndef truediv(a, b):\n \"\"\n return a / b\n__truediv__ = truediv\n\ndef xor(a, b):\n \"\"\n return a ^ b\n__xor__ = xor\n\ndef concat(a, b):\n \"\"\n if not (hasattr(a, '__getitem__') and hasattr(b, '__getitem__')):\n  raise TypeError('a and b must be sequences')\n return a + b\n__concat__ = concat\n\ndef contains(a, b):\n \"\"\n return b in a\n__contains__ = contains\n\ndef countOf(a, b):\n \"\"\n count = 0\n for i in a:\n  if i == b:\n   count += 1\n return count\n \ndef delitem(a, b):\n \"\"\n del a[b]\n__delitem__ = delitem\n\ndef getitem(a, b):\n \"\"\n return a[b]\n__getitem__ = getitem\n\n\ndef indexOf(a, b):\n \"\"\n \n for i, j in enumerate(a):\n  if j == b:\n   return i\n else:\n  raise ValueError('b not found in a')\n  \ndef setitem(a, b, c):\n \"\"\n a[b] = c\n__setitem__ = setitem\n\n\n\nclass attrgetter:\n \"\"\n def __init__(self, attr, *attrs):\n  self._attrs = (attr,)\n  self._attrs += attrs\n  if any(not isinstance(attr, str) for attr in self._attrs):\n   raise TypeError('attribute name must be a string')\n   \n @staticmethod\n def _resolve_attr(obj, attr):\n  for name in attr.split('.'):\n  \n   obj = getattr(obj, name)\n  return obj\n  \n def __call__(self, obj):\n  if len(self._attrs) == 1:\n   return self._resolve_attr(obj, self._attrs[0])\n  return tuple(self._resolve_attr(obj, attr) for attr in self._attrs)\n  \nclass itemgetter:\n \"\"\n def __init__(self, item, *items):\n  self._items = (item,)\n  self._items += items\n  \n def __call__(self, obj):\n  if len(self._items) == 1:\n   return obj[self._items[0]]\n  return tuple(obj[item] for item in self._items)\n  \nclass methodcaller:\n \"\"\n \n def __init__(self, name, *args, **kwargs):\n  self._name = name\n  self._args = args\n  self._kwargs = kwargs\n  \n def __call__(self, obj):\n  return getattr(obj, self._name)(*self._args, **self._kwargs)\n  \n  \ndef iadd(a, b):\n \"\"\n a += b\n return a\n__iadd__ = iadd\n\ndef iand(a, b):\n \"\"\n a &= b\n return a\n__iand__ = iand\n\ndef iconcat(a, b):\n \"\"\n if not (hasattr(a, '__getitem__') and hasattr(b, '__getitem__')):\n  raise TypeError('a and b must be sequences')\n a += b\n return a\n__iconcat__ = iconcat\n\ndef ifloordiv(a, b):\n \"\"\n a //= b\n return a\n__ifloordiv__ = ifloordiv\n\ndef ilshift(a, b):\n \"\"\n a <<= b\n return a\n__ilshift__ = ilshift\n\ndef imod(a, b):\n \"\"\n a %= b\n return a\n__imod__ = imod\n\ndef imul(a, b):\n \"\"\n a *= b\n return a\n__imul__ = imul\n\ndef ior(a, b):\n \"\"\n a |= b\n return a\n__ior__ = ior\n\ndef ipow(a, b):\n \"\"\n a **=b\n return a\n__ipow__ = ipow\n\ndef irshift(a, b):\n \"\"\n a >>= b\n return a\n__irshift__ = irshift\n\ndef isub(a, b):\n \"\"\n a -= b\n return a\n__isub__ = isub\n\ndef itruediv(a, b):\n \"\"\n a /= b\n return a\n__itruediv__ = itruediv\n\ndef ixor(a, b):\n \"\"\n a ^= b\n return a\n__ixor__ = ixor\n\ndef length_hint(obj, default=0):\n \"\"\n try:\n  return len(obj)\n except TypeError:\n  try:\n   val = obj.__length_hint__()\n   if val is NotImplemented:\n    raise TypeError\n  except (AttributeError, TypeError):\n   return default\n  else:\n   if not val > 0:\n    raise ValueError('default must be > 0')\n   return val\n   \n   \n   \n   \n   \n   \n"], "xml.dom.pulldom": [".py", "import xml.sax\nimport xml.sax.handler\n\nSTART_ELEMENT = \"START_ELEMENT\"\nEND_ELEMENT = \"END_ELEMENT\"\nCOMMENT = \"COMMENT\"\nSTART_DOCUMENT = \"START_DOCUMENT\"\nEND_DOCUMENT = \"END_DOCUMENT\"\nPROCESSING_INSTRUCTION = \"PROCESSING_INSTRUCTION\"\nIGNORABLE_WHITESPACE = \"IGNORABLE_WHITESPACE\"\nCHARACTERS = \"CHARACTERS\"\n\nclass PullDOM(xml.sax.ContentHandler):\n _locator = None\n document = None\n \n def __init__(self, documentFactory=None):\n  from xml.dom import XML_NAMESPACE\n  self.documentFactory = documentFactory\n  self.firstEvent = [None, None]\n  self.lastEvent = self.firstEvent\n  self.elementStack = []\n  self.push = self.elementStack.append\n  try:\n   self.pop = self.elementStack.pop\n  except AttributeError:\n  \n   pass\n  self._ns_contexts = [{XML_NAMESPACE:'xml'}] \n  self._current_context = self._ns_contexts[-1]\n  self.pending_events = []\n  \n def pop(self):\n  result = self.elementStack[-1]\n  del self.elementStack[-1]\n  return result\n  \n def setDocumentLocator(self, locator):\n  self._locator = locator\n  \n def startPrefixMapping(self, prefix, uri):\n  if not hasattr(self, '_xmlns_attrs'):\n   self._xmlns_attrs = []\n  self._xmlns_attrs.append((prefix or 'xmlns', uri))\n  self._ns_contexts.append(self._current_context.copy())\n  self._current_context[uri] = prefix or None\n  \n def endPrefixMapping(self, prefix):\n  self._current_context = self._ns_contexts.pop()\n  \n def startElementNS(self, name, tagName , attrs):\n \n  xmlns_uri = 'http://www.w3.org/2000/xmlns/'\n  xmlns_attrs = getattr(self, '_xmlns_attrs', None)\n  if xmlns_attrs is not None:\n   for aname, value in xmlns_attrs:\n    attrs._attrs[(xmlns_uri, aname)] = value\n   self._xmlns_attrs = []\n  uri, localname = name\n  if uri:\n  \n  \n  \n   if tagName is None:\n    prefix = self._current_context[uri]\n    if prefix:\n     tagName = prefix + \":\" + localname\n    else:\n     tagName = localname\n   if self.document:\n    node = self.document.createElementNS(uri, tagName)\n   else:\n    node = self.buildDocument(uri, tagName)\n  else:\n  \n  \n   if self.document:\n    node = self.document.createElement(localname)\n   else:\n    node = self.buildDocument(None, localname)\n    \n  for aname,value in attrs.items():\n   a_uri, a_localname = aname\n   if a_uri == xmlns_uri:\n    if a_localname == 'xmlns':\n     qname = a_localname\n    else:\n     qname = 'xmlns:' + a_localname\n    attr = self.document.createAttributeNS(a_uri, qname)\n    node.setAttributeNodeNS(attr)\n   elif a_uri:\n    prefix = self._current_context[a_uri]\n    if prefix:\n     qname = prefix + \":\" + a_localname\n    else:\n     qname = a_localname\n    attr = self.document.createAttributeNS(a_uri, qname)\n    node.setAttributeNodeNS(attr)\n   else:\n    attr = self.document.createAttribute(a_localname)\n    node.setAttributeNode(attr)\n   attr.value = value\n   \n  self.lastEvent[1] = [(START_ELEMENT, node), None]\n  self.lastEvent = self.lastEvent[1]\n  self.push(node)\n  \n def endElementNS(self, name, tagName):\n  self.lastEvent[1] = [(END_ELEMENT, self.pop()), None]\n  self.lastEvent = self.lastEvent[1]\n  \n def startElement(self, name, attrs):\n  if self.document:\n   node = self.document.createElement(name)\n  else:\n   node = self.buildDocument(None, name)\n   \n  for aname,value in attrs.items():\n   attr = self.document.createAttribute(aname)\n   attr.value = value\n   node.setAttributeNode(attr)\n   \n  self.lastEvent[1] = [(START_ELEMENT, node), None]\n  self.lastEvent = self.lastEvent[1]\n  self.push(node)\n  \n def endElement(self, name):\n  self.lastEvent[1] = [(END_ELEMENT, self.pop()), None]\n  self.lastEvent = self.lastEvent[1]\n  \n def comment(self, s):\n  if self.document:\n   node = self.document.createComment(s)\n   self.lastEvent[1] = [(COMMENT, node), None]\n   self.lastEvent = self.lastEvent[1]\n  else:\n   event = [(COMMENT, s), None]\n   self.pending_events.append(event)\n   \n def processingInstruction(self, target, data):\n  if self.document:\n   node = self.document.createProcessingInstruction(target, data)\n   self.lastEvent[1] = [(PROCESSING_INSTRUCTION, node), None]\n   self.lastEvent = self.lastEvent[1]\n  else:\n   event = [(PROCESSING_INSTRUCTION, target, data), None]\n   self.pending_events.append(event)\n   \n def ignorableWhitespace(self, chars):\n  node = self.document.createTextNode(chars)\n  self.lastEvent[1] = [(IGNORABLE_WHITESPACE, node), None]\n  self.lastEvent = self.lastEvent[1]\n  \n def characters(self, chars):\n  node = self.document.createTextNode(chars)\n  self.lastEvent[1] = [(CHARACTERS, node), None]\n  self.lastEvent = self.lastEvent[1]\n  \n def startDocument(self):\n  if self.documentFactory is None:\n   import xml.dom.minidom\n   self.documentFactory = xml.dom.minidom.Document.implementation\n   \n def buildDocument(self, uri, tagname):\n \n \n  node = self.documentFactory.createDocument(uri, tagname, None)\n  self.document = node\n  self.lastEvent[1] = [(START_DOCUMENT, node), None]\n  self.lastEvent = self.lastEvent[1]\n  self.push(node)\n  \n  for e in self.pending_events:\n   if e[0][0] == PROCESSING_INSTRUCTION:\n    _,target,data = e[0]\n    n = self.document.createProcessingInstruction(target, data)\n    e[0] = (PROCESSING_INSTRUCTION, n)\n   elif e[0][0] == COMMENT:\n    n = self.document.createComment(e[0][1])\n    e[0] = (COMMENT, n)\n   else:\n    raise AssertionError(\"Unknown pending event \",e[0][0])\n   self.lastEvent[1] = e\n   self.lastEvent = e\n  self.pending_events = None\n  return node.firstChild\n  \n def endDocument(self):\n  self.lastEvent[1] = [(END_DOCUMENT, self.document), None]\n  self.pop()\n  \n def clear(self):\n  \"\"\n  self.document = None\n  \nclass ErrorHandler:\n def warning(self, exception):\n  print(exception)\n def error(self, exception):\n  raise exception\n def fatalError(self, exception):\n  raise exception\n  \nclass DOMEventStream:\n def __init__(self, stream, parser, bufsize):\n  self.stream = stream\n  self.parser = parser\n  self.bufsize = bufsize\n  if not hasattr(self.parser, 'feed'):\n   self.getEvent = self._slurp\n  self.reset()\n  \n def reset(self):\n  self.pulldom = PullDOM()\n  \n  self.parser.setFeature(xml.sax.handler.feature_namespaces, 1)\n  self.parser.setContentHandler(self.pulldom)\n  \n def __getitem__(self, pos):\n  rc = self.getEvent()\n  if rc:\n   return rc\n  raise IndexError\n  \n def __next__(self):\n  rc = self.getEvent()\n  if rc:\n   return rc\n  raise StopIteration\n  \n def __iter__(self):\n  return self\n  \n def expandNode(self, node):\n  event = self.getEvent()\n  parents = [node]\n  while event:\n   token, cur_node = event\n   if cur_node is node:\n    return\n   if token != END_ELEMENT:\n    parents[-1].appendChild(cur_node)\n   if token == START_ELEMENT:\n    parents.append(cur_node)\n   elif token == END_ELEMENT:\n    del parents[-1]\n   event = self.getEvent()\n   \n def getEvent(self):\n \n \n  if not self.pulldom.firstEvent[1]:\n   self.pulldom.lastEvent = self.pulldom.firstEvent\n  while not self.pulldom.firstEvent[1]:\n   buf = self.stream.read(self.bufsize)\n   if not buf:\n    self.parser.close()\n    return None\n   self.parser.feed(buf)\n  rc = self.pulldom.firstEvent[1][0]\n  self.pulldom.firstEvent[1] = self.pulldom.firstEvent[1][1]\n  return rc\n  \n def _slurp(self):\n  \"\"\n  self.parser.parse(self.stream)\n  self.getEvent = self._emit\n  return self._emit()\n  \n def _emit(self):\n  \"\"\n  rc = self.pulldom.firstEvent[1][0]\n  self.pulldom.firstEvent[1] = self.pulldom.firstEvent[1][1]\n  return rc\n  \n def clear(self):\n  \"\"\n  self.pulldom.clear()\n  del self.pulldom\n  self.parser = None\n  self.stream = None\n  \nclass SAX2DOM(PullDOM):\n\n def startElementNS(self, name, tagName , attrs):\n  PullDOM.startElementNS(self, name, tagName, attrs)\n  curNode = self.elementStack[-1]\n  parentNode = self.elementStack[-2]\n  parentNode.appendChild(curNode)\n  \n def startElement(self, name, attrs):\n  PullDOM.startElement(self, name, attrs)\n  curNode = self.elementStack[-1]\n  parentNode = self.elementStack[-2]\n  parentNode.appendChild(curNode)\n  \n def processingInstruction(self, target, data):\n  PullDOM.processingInstruction(self, target, data)\n  node = self.lastEvent[0][1]\n  parentNode = self.elementStack[-1]\n  parentNode.appendChild(node)\n  \n def ignorableWhitespace(self, chars):\n  PullDOM.ignorableWhitespace(self, chars)\n  node = self.lastEvent[0][1]\n  parentNode = self.elementStack[-1]\n  parentNode.appendChild(node)\n  \n def characters(self, chars):\n  PullDOM.characters(self, chars)\n  node = self.lastEvent[0][1]\n  parentNode = self.elementStack[-1]\n  parentNode.appendChild(node)\n  \n  \ndefault_bufsize = (2 ** 14) - 20\n\ndef parse(stream_or_string, parser=None, bufsize=None):\n if bufsize is None:\n  bufsize = default_bufsize\n if isinstance(stream_or_string, str):\n  stream = open(stream_or_string, 'rb')\n else:\n  stream = stream_or_string\n if not parser:\n  parser = xml.sax.make_parser()\n return DOMEventStream(stream, parser, bufsize)\n \ndef parseString(string, parser=None):\n from io import StringIO\n \n bufsize = len(string)\n buf = StringIO(string)\n if not parser:\n  parser = xml.sax.make_parser()\n return DOMEventStream(buf, parser, bufsize)\n"], "select": [".py", "\"\"\n\n\n\n\n\n\nimport errno\nimport os\nimport queue\nimport socket\n\nclass error(Exception): pass\n\nALL = None\n\n_exception_map = {\n\n\n\n\n\n\n}\n\ndef _map_exception(exc, circumstance=ALL):\n try:\n  mapped_exception = _exception_map[(exc.__class__, circumstance)]\n  mapped_exception.java_exception = exc\n  return mapped_exception\n except KeyError:\n  return error(-1, 'Unmapped java exception: <%s:%s>' % (exc.toString(), circumstance))\n  \nPOLLIN = 1\nPOLLOUT = 2\n\n\n\n\n\nPOLLPRI = 4\nPOLLERR = 8\nPOLLHUP = 16\nPOLLNVAL = 32\n\ndef _getselectable(selectable_object):\n try:\n  channel = selectable_object.getchannel()\n except:\n  try:\n   channel = selectable_object.fileno().getChannel()\n  except:\n   raise TypeError(\"Object '%s' is not watchable\" % selectable_object,\n   errno.ENOTSOCK)\n   \n if channel and not isinstance(channel, java.nio.channels.SelectableChannel):\n  raise TypeError(\"Object '%s' is not watchable\" % selectable_object,\n  errno.ENOTSOCK)\n return channel\n \nclass poll:\n\n def __init__(self):\n  self.selector = java.nio.channels.Selector.open()\n  self.chanmap = {}\n  self.unconnected_sockets = []\n  \n def _register_channel(self, socket_object, channel, mask):\n  jmask = 0\n  if mask & POLLIN:\n  \n   if channel.validOps() & OP_ACCEPT:\n    jmask = OP_ACCEPT\n   else:\n    jmask = OP_READ\n  if mask & POLLOUT:\n   if channel.validOps() & OP_WRITE:\n    jmask |= OP_WRITE\n   if channel.validOps() & OP_CONNECT:\n    jmask |= OP_CONNECT\n  selectionkey = channel.register(self.selector, jmask)\n  self.chanmap[channel] = (socket_object, selectionkey)\n  \n def _check_unconnected_sockets(self):\n  temp_list = []\n  for socket_object, mask in self.unconnected_sockets:\n   channel = _getselectable(socket_object)\n   if channel is not None:\n    self._register_channel(socket_object, channel, mask)\n   else:\n    temp_list.append( (socket_object, mask) )\n  self.unconnected_sockets = temp_list\n  \n def register(self, socket_object, mask = POLLIN|POLLOUT|POLLPRI):\n  try:\n   channel = _getselectable(socket_object)\n   if channel is None:\n   \n   \n    self.unconnected_sockets.append( (socket_object, mask) )\n    return\n   self._register_channel(socket_object, channel, mask)\n  except BaseException:\n  \n   raise _map_exception(jlx)\n   \n def unregister(self, socket_object):\n  try:\n   channel = _getselectable(socket_object)\n   self.chanmap[channel][1].cancel()\n   del self.chanmap[channel]\n  except BaseException:\n  \n   raise _map_exception(jlx)\n   \n def _dopoll(self, timeout):\n  if timeout is None or timeout < 0:\n   self.selector.select()\n  else:\n   try:\n    timeout = int(timeout)\n    if not timeout:\n     self.selector.selectNow()\n    else:\n    \n     self.selector.select(timeout)\n   except ValueError as vx:\n    raise error(\"poll timeout must be a number of milliseconds or None\", errno.EINVAL)\n    \n  return self.selector.selectedKeys()\n  \n def poll(self, timeout=None):\n  try:\n   self._check_unconnected_sockets()\n   selectedkeys = self._dopoll(timeout)\n   results = []\n   for k in selectedkeys.iterator():\n    jmask = k.readyOps()\n    pymask = 0\n    if jmask & OP_READ: pymask |= POLLIN\n    if jmask & OP_WRITE: pymask |= POLLOUT\n    if jmask & OP_ACCEPT: pymask |= POLLIN\n    if jmask & OP_CONNECT: pymask |= POLLOUT\n    \n    results.append( (self.chanmap[k.channel()][0], pymask) )\n   return results\n  except BaseException:\n  \n   raise _map_exception(jlx)\n   \n def _deregister_all(self):\n  try:\n   for k in self.selector.keys():\n    k.cancel()\n    \n   self.selector.selectNow()\n  except BaseException:\n  \n   raise _map_exception(jlx)\n   \n def close(self):\n  try:\n   self._deregister_all()\n   self.selector.close()\n  except BaseException:\n  \n   raise _map_exception(jlx)\n   \ndef _calcselecttimeoutvalue(value):\n if value is None:\n  return None\n try:\n  floatvalue = float(value)\n except Exception as x:\n  raise TypeError(\"Select timeout value must be a number or None\")\n if value < 0:\n  raise error(\"Select timeout value cannot be negative\", errno.EINVAL)\n if floatvalue < 0.000001:\n  return 0\n return int(floatvalue * 1000) \n \n \n \n \nclass poll_object_cache:\n\n def __init__(self):\n  self.is_windows = os.name == 'nt'\n  if self.is_windows:\n   self.poll_object_queue = Queue.Queue()\n  import atexit\n  atexit.register(self.finalize)\n  \n def get_poll_object(self):\n  if not self.is_windows:\n   return poll()\n  try:\n   return self.poll_object_queue.get(False)\n  except Queue.Empty:\n   return poll()\n   \n def release_poll_object(self, pobj):\n  if self.is_windows:\n   pobj._deregister_all()\n   self.poll_object_queue.put(pobj)\n  else:\n   pobj.close()\n   \n def finalize(self):\n  if self.is_windows:\n   while True:\n    try:\n     p = self.poll_object_queue.get(False)\n     p.close()\n    except Queue.Empty:\n     return\n     \n_poll_object_cache = poll_object_cache()\n\ndef native_select(read_fd_list, write_fd_list, outofband_fd_list, timeout=None):\n timeout = _calcselecttimeoutvalue(timeout)\n \n pobj = _poll_object_cache.get_poll_object()\n try:\n  registered_for_read = {}\n  \n  for fd in read_fd_list:\n   pobj.register(fd, POLLIN)\n   registered_for_read[fd] = 1\n   \n  for fd in write_fd_list:\n   if fd in registered_for_read:\n   \n    pobj.register(fd, POLLIN|POLLOUT)\n   else:\n    pobj.register(fd, POLLOUT)\n  results = pobj.poll(timeout)\n  \n  read_ready_list, write_ready_list, oob_ready_list = [], [], []\n  for fd, mask in results:\n   if mask & POLLIN:\n    read_ready_list.append(fd)\n   if mask & POLLOUT:\n    write_ready_list.append(fd)\n  return read_ready_list, write_ready_list, oob_ready_list\n finally:\n  _poll_object_cache.release_poll_object(pobj)\n  \nselect = native_select\n\ndef cpython_compatible_select(read_fd_list, write_fd_list, outofband_fd_list, timeout=None):\n\n\n modified_channels = []\n try:\n  for socket_list in [read_fd_list, write_fd_list, outofband_fd_list]:\n   for s in socket_list:\n    channel = _getselectable(s)\n    if channel.isBlocking():\n     modified_channels.append(channel)\n     channel.configureBlocking(0)\n  return native_select(read_fd_list, write_fd_list, outofband_fd_list, timeout)\n finally:\n  for channel in modified_channels:\n   channel.configureBlocking(1)\n"], "unittest.test.testmock.testwith": [".py", "import unittest\nfrom warnings import catch_warnings\n\nfrom unittest.test.testmock.support import is_instance\nfrom unittest.mock import MagicMock, Mock, patch, sentinel, mock_open, call\n\n\n\nsomething = sentinel.Something\nsomething_else = sentinel.SomethingElse\n\n\n\nclass WithTest(unittest.TestCase):\n\n def test_with_statement(self):\n  with patch('%s.something' % __name__, sentinel.Something2):\n   self.assertEqual(something, sentinel.Something2, \"unpatched\")\n  self.assertEqual(something, sentinel.Something)\n  \n  \n def test_with_statement_exception(self):\n  try:\n   with patch('%s.something' % __name__, sentinel.Something2):\n    self.assertEqual(something, sentinel.Something2, \"unpatched\")\n    raise Exception('pow')\n  except Exception:\n   pass\n  else:\n   self.fail(\"patch swallowed exception\")\n  self.assertEqual(something, sentinel.Something)\n  \n  \n def test_with_statement_as(self):\n  with patch('%s.something' % __name__) as mock_something:\n   self.assertEqual(something, mock_something, \"unpatched\")\n   self.assertTrue(is_instance(mock_something, MagicMock),\n   \"patching wrong type\")\n  self.assertEqual(something, sentinel.Something)\n  \n  \n def test_patch_object_with_statement(self):\n  class Foo(object):\n   something = 'foo'\n  original = Foo.something\n  with patch.object(Foo, 'something'):\n   self.assertNotEqual(Foo.something, original, \"unpatched\")\n  self.assertEqual(Foo.something, original)\n  \n  \n def test_with_statement_nested(self):\n  with catch_warnings(record=True):\n   with patch('%s.something' % __name__) as mock_something, patch('%s.something_else' % __name__) as mock_something_else:\n    self.assertEqual(something, mock_something, \"unpatched\")\n    self.assertEqual(something_else, mock_something_else,\n    \"unpatched\")\n    \n  self.assertEqual(something, sentinel.Something)\n  self.assertEqual(something_else, sentinel.SomethingElse)\n  \n  \n def test_with_statement_specified(self):\n  with patch('%s.something' % __name__, sentinel.Patched) as mock_something:\n   self.assertEqual(something, mock_something, \"unpatched\")\n   self.assertEqual(mock_something, sentinel.Patched, \"wrong patch\")\n  self.assertEqual(something, sentinel.Something)\n  \n  \n def testContextManagerMocking(self):\n  mock = Mock()\n  mock.__enter__ = Mock()\n  mock.__exit__ = Mock()\n  mock.__exit__.return_value = False\n  \n  with mock as m:\n   self.assertEqual(m, mock.__enter__.return_value)\n  mock.__enter__.assert_called_with()\n  mock.__exit__.assert_called_with(None, None, None)\n  \n  \n def test_context_manager_with_magic_mock(self):\n  mock = MagicMock()\n  \n  with self.assertRaises(TypeError):\n   with mock:\n    \"\" + 3\n  mock.__enter__.assert_called_with()\n  self.assertTrue(mock.__exit__.called)\n  \n  \n def test_with_statement_same_attribute(self):\n  with patch('%s.something' % __name__, sentinel.Patched) as mock_something:\n   self.assertEqual(something, mock_something, \"unpatched\")\n   \n   with patch('%s.something' % __name__) as mock_again:\n    self.assertEqual(something, mock_again, \"unpatched\")\n    \n   self.assertEqual(something, mock_something,\n   \"restored with wrong instance\")\n   \n  self.assertEqual(something, sentinel.Something, \"not restored\")\n  \n  \n def test_with_statement_imbricated(self):\n  with patch('%s.something' % __name__) as mock_something:\n   self.assertEqual(something, mock_something, \"unpatched\")\n   \n   with patch('%s.something_else' % __name__) as mock_something_else:\n    self.assertEqual(something_else, mock_something_else,\n    \"unpatched\")\n    \n  self.assertEqual(something, sentinel.Something)\n  self.assertEqual(something_else, sentinel.SomethingElse)\n  \n  \n def test_dict_context_manager(self):\n  foo = {}\n  with patch.dict(foo, {'a': 'b'}):\n   self.assertEqual(foo, {'a': 'b'})\n  self.assertEqual(foo, {})\n  \n  with self.assertRaises(NameError):\n   with patch.dict(foo, {'a': 'b'}):\n    self.assertEqual(foo, {'a': 'b'})\n    raise NameError('Konrad')\n    \n  self.assertEqual(foo, {})\n  \n  \n  \nclass TestMockOpen(unittest.TestCase):\n\n def test_mock_open(self):\n  mock = mock_open()\n  with patch('%s.open' % __name__, mock, create=True) as patched:\n   self.assertIs(patched, mock)\n   open('foo')\n   \n  mock.assert_called_once_with('foo')\n  \n  \n def test_mock_open_context_manager(self):\n  mock = mock_open()\n  handle = mock.return_value\n  with patch('%s.open' % __name__, mock, create=True):\n   with open('foo') as f:\n    f.read()\n    \n  expected_calls = [call('foo'), call().__enter__(), call().read(),\n  call().__exit__(None, None, None)]\n  self.assertEqual(mock.mock_calls, expected_calls)\n  self.assertIs(f, handle)\n  \n  \n def test_explicit_mock(self):\n  mock = MagicMock()\n  mock_open(mock)\n  \n  with patch('%s.open' % __name__, mock, create=True) as patched:\n   self.assertIs(patched, mock)\n   open('foo')\n   \n  mock.assert_called_once_with('foo')\n  \n  \n def test_read_data(self):\n  mock = mock_open(read_data='foo')\n  with patch('%s.open' % __name__, mock, create=True):\n   h = open('bar')\n   result = h.read()\n   \n  self.assertEqual(result, 'foo')\n  \n  \nif __name__ == '__main__':\n unittest.main()\n"], "_threading_local": [".py", "\"\"\n\nfrom weakref import ref\nfrom contextlib import contextmanager\n\n__all__ = [\"local\"]\n\n\n\n\n\n\n\n\n\n\n\nclass _localimpl:\n \"\"\n __slots__ = 'key', 'dicts', 'localargs', 'locallock', '__weakref__'\n \n def __init__(self):\n \n \n \n  self.key = '_threading_local._localimpl.' + str(id(self))\n  \n  self.dicts = {}\n  \n def get_dict(self):\n  \"\"\n  thread = current_thread()\n  return self.dicts[id(thread)][1]\n  \n def create_dict(self):\n  \"\"\n  localdict = {}\n  key = self.key\n  thread = current_thread()\n  idt = id(thread)\n  def local_deleted(_, key=key):\n  \n   thread = wrthread()\n   if thread is not None:\n    del thread.__dict__[key]\n  def thread_deleted(_, idt=idt):\n  \n  \n  \n  \n   local = wrlocal()\n   if local is not None:\n    dct = local.dicts.pop(idt)\n  wrlocal = ref(self, local_deleted)\n  wrthread = ref(thread, thread_deleted)\n  thread.__dict__[key] = wrlocal\n  self.dicts[idt] = wrthread, localdict\n  return localdict\n  \n  \n@contextmanager\ndef _patch(self):\n impl = object.__getattribute__(self, '_local__impl')\n try:\n  dct = impl.get_dict()\n except KeyError:\n  dct = impl.create_dict()\n  args, kw = impl.localargs\n  self.__init__(*args, **kw)\n with impl.locallock:\n  object.__setattr__(self, '__dict__', dct)\n  yield\n  \n  \nclass local:\n __slots__ = '_local__impl', '__dict__'\n \n def __new__(cls, *args, **kw):\n  if (args or kw) and (cls.__init__ is object.__init__):\n   raise TypeError(\"Initialization arguments are not supported\")\n  self = object.__new__(cls)\n  impl = _localimpl()\n  impl.localargs = (args, kw)\n  impl.locallock = RLock()\n  object.__setattr__(self, '_local__impl', impl)\n  \n  \n  \n  impl.create_dict()\n  return self\n  \n def __getattribute__(self, name):\n  with _patch(self):\n   return object.__getattribute__(self, name)\n   \n def __setattr__(self, name, value):\n  if name == '__dict__':\n   raise AttributeError(\n   \"%r object attribute '__dict__' is read-only\"\n   % self.__class__.__name__)\n  with _patch(self):\n   return object.__setattr__(self, name, value)\n   \n def __delattr__(self, name):\n  if name == '__dict__':\n   raise AttributeError(\n   \"%r object attribute '__dict__' is read-only\"\n   % self.__class__.__name__)\n  with _patch(self):\n   return object.__delattr__(self, name)\n   \n   \nfrom threading import current_thread, RLock\n"], "unittest.test._test_warnings": [".py", "\n\n\"\"\n\nimport sys\nimport unittest\nimport warnings\n\ndef warnfun():\n warnings.warn('rw', RuntimeWarning)\n \nclass TestWarnings(unittest.TestCase):\n\n\n def test_assert(self):\n  self.assertEquals(2+2, 4)\n  self.assertEquals(2*2, 4)\n  self.assertEquals(2**2, 4)\n  \n def test_fail(self):\n  self.failUnless(1)\n  self.failUnless(True)\n  \n def test_other_unittest(self):\n  self.assertAlmostEqual(2+2, 4)\n  self.assertNotAlmostEqual(4+4, 2)\n  \n  \n def test_deprecation(self):\n  warnings.warn('dw', DeprecationWarning)\n  warnings.warn('dw', DeprecationWarning)\n  warnings.warn('dw', DeprecationWarning)\n  \n def test_import(self):\n  warnings.warn('iw', ImportWarning)\n  warnings.warn('iw', ImportWarning)\n  warnings.warn('iw', ImportWarning)\n  \n  \n def test_warning(self):\n  warnings.warn('uw')\n  warnings.warn('uw')\n  warnings.warn('uw')\n  \n  \n  \n def test_function(self):\n \n  warnfun()\n  warnfun()\n  warnfun()\n  \n  \n  \nif __name__ == '__main__':\n with warnings.catch_warnings(record=True) as ws:\n \n  if len(sys.argv) == 2:\n   unittest.main(exit=False, warnings=sys.argv.pop())\n  else:\n   unittest.main(exit=False)\n   \n   \n for w in ws:\n  print(w.message)\n"], "posixpath": [".py", "\"\"\n\nimport os\nimport sys\nimport stat\nimport genericpath\nfrom genericpath import *\n\n__all__ = [\"normcase\",\"isabs\",\"join\",\"splitdrive\",\"split\",\"splitext\",\n\"basename\",\"dirname\",\"commonprefix\",\"getsize\",\"getmtime\",\n\"getatime\",\"getctime\",\"islink\",\"exists\",\"lexists\",\"isdir\",\"isfile\",\n\"ismount\", \"expanduser\",\"expandvars\",\"normpath\",\"abspath\",\n\"samefile\",\"sameopenfile\",\"samestat\",\n\"curdir\",\"pardir\",\"sep\",\"pathsep\",\"defpath\",\"altsep\",\"extsep\",\n\"devnull\",\"realpath\",\"supports_unicode_filenames\",\"relpath\"]\n\n\n\ncurdir = '.'\npardir = '..'\nextsep = '.'\nsep = '/'\npathsep = ':'\ndefpath = ':/bin:/usr/bin'\naltsep = None\ndevnull = '/dev/null'\n\ndef _get_sep(path):\n if isinstance(path, bytes):\n  return b'/'\n else:\n  return '/'\n  \n  \n  \n  \n  \n  \ndef normcase(s):\n \"\"\n \n if not isinstance(s, (bytes, str)):\n  raise TypeError(\"normcase() argument must be str or bytes, \"\n  \"not '{}'\".format(s.__class__.__name__))\n return s\n \n \n \n \n \ndef isabs(s):\n \"\"\n sep = _get_sep(s)\n return s.startswith(sep)\n \n \n \n \n \n \ndef join(a, *p):\n \"\"\n sep = _get_sep(a)\n path = a\n try:\n  for b in p:\n   if b.startswith(sep):\n    path = b\n   elif not path or path.endswith(sep):\n    path += b\n   else:\n    path += sep + b\n except TypeError:\n  valid_types = all(isinstance(s, (str, bytes, bytearray))\n  for s in (a, ) + p)\n  if valid_types:\n  \n   raise TypeError(\"Can't mix strings and bytes in path \"\n   \"components.\") from None\n  raise\n return path\n \n \n \n \n \n \n \ndef split(p):\n \"\"\n sep = _get_sep(p)\n i = p.rfind(sep) + 1\n head, tail = p[:i], p[i:]\n if head and head != sep*len(head):\n  head = head.rstrip(sep)\n return head, tail\n \n \n \n \n \n \n \ndef splitext(p):\n if isinstance(p, bytes):\n  sep = b'/'\n  extsep = b'.'\n else:\n  sep = '/'\n  extsep = '.'\n return genericpath._splitext(p, sep, None, extsep)\nsplitext.__doc__ = genericpath._splitext.__doc__\n\n\n\n\ndef splitdrive(p):\n \"\"\n return p[:0], p\n \n \n \n \ndef basename(p):\n \"\"\n sep = _get_sep(p)\n i = p.rfind(sep) + 1\n return p[i:]\n \n \n \n \ndef dirname(p):\n \"\"\n sep = _get_sep(p)\n i = p.rfind(sep) + 1\n head = p[:i]\n if head and head != sep*len(head):\n  head = head.rstrip(sep)\n return head\n \n \n \n \n \ndef islink(path):\n \"\"\n try:\n  st = os.lstat(path)\n except (os.error, AttributeError):\n  return False\n return stat.S_ISLNK(st.st_mode)\n \n \n \ndef lexists(path):\n \"\"\n try:\n  os.lstat(path)\n except os.error:\n  return False\n return True\n \n \n \n \ndef samefile(f1, f2):\n \"\"\n s1 = os.stat(f1)\n s2 = os.stat(f2)\n return samestat(s1, s2)\n \n \n \n \n \ndef sameopenfile(fp1, fp2):\n \"\"\n s1 = os.fstat(fp1)\n s2 = os.fstat(fp2)\n return samestat(s1, s2)\n \n \n \n \n \ndef samestat(s1, s2):\n \"\"\n return s1.st_ino == s2.st_ino and s1.st_dev == s2.st_dev\n \n \n \n \n \ndef ismount(path):\n \"\"\n if islink(path):\n \n  return False\n try:\n  s1 = os.lstat(path)\n  if isinstance(path, bytes):\n   parent = join(path, b'..')\n  else:\n   parent = join(path, '..')\n  s2 = os.lstat(parent)\n except os.error:\n  return False \n dev1 = s1.st_dev\n dev2 = s2.st_dev\n if dev1 != dev2:\n  return True \n ino1 = s1.st_ino\n ino2 = s2.st_ino\n if ino1 == ino2:\n  return True \n return False\n \n \n \n \n \n \n \n \n \n \n \ndef expanduser(path):\n \"\"\n if isinstance(path, bytes):\n  tilde = b'~'\n else:\n  tilde = '~'\n if not path.startswith(tilde):\n  return path\n sep = _get_sep(path)\n i = path.find(sep, 1)\n if i < 0:\n  i = len(path)\n if i == 1:\n  if 'HOME' not in os.environ:\n   import pwd\n   userhome = pwd.getpwuid(os.getuid()).pw_dir\n  else:\n   userhome = os.environ['HOME']\n else:\n  import pwd\n  name = path[1:i]\n  if isinstance(name, bytes):\n   name = str(name, 'ASCII')\n  try:\n   pwent = pwd.getpwnam(name)\n  except KeyError:\n   return path\n  userhome = pwent.pw_dir\n if isinstance(path, bytes):\n  userhome = os.fsencode(userhome)\n  root = b'/'\n else:\n  root = '/'\n userhome = userhome.rstrip(root)\n return (userhome + path[i:]) or root\n \n \n \n \n \n \n_varprog = None\n_varprogb = None\n\ndef expandvars(path):\n \"\"\n global _varprog, _varprogb\n if isinstance(path, bytes):\n  if b'$' not in path:\n   return path\n  if not _varprogb:\n   import re\n   _varprogb = re.compile(br'\\$(\\w+|\\{[^}]*\\})', re.ASCII)\n  search = _varprogb.search\n  start = b'{'\n  end = b'}'\n else:\n  if '$' not in path:\n   return path\n  if not _varprog:\n   import re\n   _varprog = re.compile(r'\\$(\\w+|\\{[^}]*\\})', re.ASCII)\n  search = _varprog.search\n  start = '{'\n  end = '}'\n i = 0\n while True:\n  m = search(path, i)\n  if not m:\n   break\n  i, j = m.span(0)\n  name = m.group(1)\n  if name.startswith(start) and name.endswith(end):\n   name = name[1:-1]\n  if isinstance(name, bytes):\n   name = str(name, 'ASCII')\n  if name in os.environ:\n   tail = path[j:]\n   value = os.environ[name]\n   if isinstance(path, bytes):\n    value = value.encode('ASCII')\n   path = path[:i] + value\n   i = len(path)\n   path += tail\n  else:\n   i = j\n return path\n \n \n \n \n \n \ndef normpath(path):\n \"\"\n if isinstance(path, bytes):\n  sep = b'/'\n  empty = b''\n  dot = b'.'\n  dotdot = b'..'\n else:\n  sep = '/'\n  empty = ''\n  dot = '.'\n  dotdot = '..'\n if path == empty:\n  return dot\n initial_slashes = path.startswith(sep)\n \n \n if (initial_slashes and\n path.startswith(sep*2) and not path.startswith(sep*3)):\n  initial_slashes = 2\n comps = path.split(sep)\n new_comps = []\n for comp in comps:\n  if comp in (empty, dot):\n   continue\n  if (comp != dotdot or (not initial_slashes and not new_comps) or\n  (new_comps and new_comps[-1] == dotdot)):\n   new_comps.append(comp)\n  elif new_comps:\n   new_comps.pop()\n comps = new_comps\n path = sep.join(comps)\n if initial_slashes:\n  path = sep*initial_slashes + path\n return path or dot\n \n \ndef abspath(path):\n \"\"\n if not isabs(path):\n  if isinstance(path, bytes):\n   cwd = os.getcwdb()\n  else:\n   cwd = os.getcwd()\n  path = join(cwd, path)\n return normpath(path)\n \n \n \n \n \ndef realpath(filename):\n \"\"\n path, ok = _joinrealpath(filename[:0], filename, {})\n return abspath(path)\n \n \n \ndef _joinrealpath(path, rest, seen):\n if isinstance(path, bytes):\n  sep = b'/'\n  curdir = b'.'\n  pardir = b'..'\n else:\n  sep = '/'\n  curdir = '.'\n  pardir = '..'\n  \n if isabs(rest):\n  rest = rest[1:]\n  path = sep\n  \n while rest:\n  name, _, rest = rest.partition(sep)\n  if not name or name == curdir:\n  \n   continue\n  if name == pardir:\n  \n   if path:\n    path, name = split(path)\n    if name == pardir:\n     path = join(path, pardir, pardir)\n   else:\n    path = pardir\n   continue\n  newpath = join(path, name)\n  if not islink(newpath):\n   path = newpath\n   continue\n   \n  if newpath in seen:\n  \n   path = seen[newpath]\n   if path is not None:\n   \n    continue\n    \n    \n   return join(newpath, rest), False\n  seen[newpath] = None \n  path, ok = _joinrealpath(path, os.readlink(newpath), seen)\n  if not ok:\n   return join(path, rest), False\n  seen[newpath] = path \n  \n return path, True\n \n \nsupports_unicode_filenames = (sys.platform == 'darwin')\n\ndef relpath(path, start=None):\n \"\"\n \n if not path:\n  raise ValueError(\"no path specified\")\n  \n if isinstance(path, bytes):\n  curdir = b'.'\n  sep = b'/'\n  pardir = b'..'\n else:\n  curdir = '.'\n  sep = '/'\n  pardir = '..'\n  \n if start is None:\n  start = curdir\n  \n start_list = [x for x in abspath(start).split(sep) if x]\n path_list = [x for x in abspath(path).split(sep) if x]\n \n \n i = len(commonprefix([start_list, path_list]))\n \n rel_list = [pardir] * (len(start_list)-i) + path_list[i:]\n if not rel_list:\n  return curdir\n return join(*rel_list)\n"], "imp": [".py", "\"\"\n\nfrom _imp import (lock_held, acquire_lock, release_lock,\nget_frozen_object, is_frozen_package,\ninit_builtin, init_frozen, is_builtin, is_frozen,\n_fix_co_filename)\ntry:\n from _imp import load_dynamic\nexcept ImportError:\n\n load_dynamic = None\n \n \nfrom importlib._bootstrap import new_module\nfrom importlib._bootstrap import cache_from_source, source_from_cache\n\n\nfrom importlib import _bootstrap\n\n\nimport importlib.machinery as machinery\nimport os\nimport sys\nimport tokenize\nimport warnings\n\n\n\nSEARCH_ERROR = 0\nPY_SOURCE = 1\nPY_COMPILED = 2\nC_EXTENSION = 3\nPY_RESOURCE = 4\nPKG_DIRECTORY = 5\nC_BUILTIN = 6\nPY_FROZEN = 7\nPY_CODERESOURCE = 8\nIMP_HOOK = 9\n\n\ndef get_magic():\n \"\"\n return _bootstrap._MAGIC_BYTES\n \n \ndef get_tag():\n \"\"\n return sys.implementation.cache_tag\n \n \ndef get_suffixes():\n warnings.warn('imp.get_suffixes() is deprecated; use the constants '\n 'defined on importlib.machinery instead',\n DeprecationWarning, 2)\n extensions = [(s, 'rb', C_EXTENSION) for s in machinery.EXTENSION_SUFFIXES]\n source = [(s, 'U', PY_SOURCE) for s in machinery.SOURCE_SUFFIXES]\n bytecode = [(s, 'rb', PY_COMPILED) for s in machinery.BYTECODE_SUFFIXES]\n \n return extensions + source + bytecode\n \n \nclass NullImporter:\n\n \"\"\n \n def __init__(self, path):\n  if path == '':\n   raise ImportError('empty pathname', path='')\n  elif os.path.isdir(path):\n   raise ImportError('existing directory', path=path)\n   \n def find_module(self, fullname):\n  \"\"\n  return None\n  \n  \nclass _HackedGetData:\n\n \"\"\n \n def __init__(self, fullname, path, file=None):\n  super().__init__(fullname, path)\n  self.file = file\n  \n def get_data(self, path):\n  \"\"\n  if self.file and path == self.path:\n   if not self.file.closed:\n    file = self.file\n   else:\n    self.file = file = open(self.path, 'r')\n    \n   with file:\n   \n   \n   \n   \n   \n    return file.read()\n  else:\n   return super().get_data(path)\n   \n   \nclass _LoadSourceCompatibility(_HackedGetData, _bootstrap.SourceFileLoader):\n\n \"\"\n \n pass\n \ndef load_source(name, pathname, file=None):\n msg = ('imp.load_source() is deprecated; use '\n 'importlib.machinery.SourceFileLoader(name, pathname).load_module()'\n ' instead')\n warnings.warn(msg, DeprecationWarning, 2)\n _LoadSourceCompatibility(name, pathname, file).load_module(name)\n module = sys.modules[name]\n \n \n module.__loader__ = _bootstrap.SourceFileLoader(name, pathname)\n return module\n \n \nclass _LoadCompiledCompatibility(_HackedGetData,\n_bootstrap.SourcelessFileLoader):\n\n \"\"\n \n pass\n \ndef load_compiled(name, pathname, file=None):\n msg = ('imp.load_compiled() is deprecated; use '\n 'importlib.machinery.SourcelessFileLoader(name, pathname).'\n 'load_module() instead ')\n warnings.warn(msg, DeprecationWarning, 2)\n _LoadCompiledCompatibility(name, pathname, file).load_module(name)\n module = sys.modules[name]\n \n \n module.__loader__ = _bootstrap.SourcelessFileLoader(name, pathname)\n return module\n \n \ndef load_package(name, path):\n msg = ('imp.load_package() is deprecated; use either '\n 'importlib.machinery.SourceFileLoader() or '\n 'importlib.machinery.SourcelessFileLoader() instead')\n warnings.warn(msg, DeprecationWarning, 2)\n if os.path.isdir(path):\n  extensions = (machinery.SOURCE_SUFFIXES[:] +\n  machinery.BYTECODE_SUFFIXES[:])\n  for extension in extensions:\n   path = os.path.join(path, '__init__'+extension)\n   if os.path.exists(path):\n    break\n  else:\n   raise ValueError('{!r} is not a package'.format(path))\n return _bootstrap.SourceFileLoader(name, path).load_module(name)\n \n \ndef load_module(name, file, filename, details):\n \"\"\n suffix, mode, type_ = details\n with warnings.catch_warnings():\n  warnings.simplefilter('ignore')\n  if mode and (not mode.startswith(('r', 'U')) or '+' in mode):\n   raise ValueError('invalid file open mode {!r}'.format(mode))\n  elif file is None and type_ in {PY_SOURCE, PY_COMPILED}:\n   msg = 'file object required for import (type code {})'.format(type_)\n   raise ValueError(msg)\n  elif type_ == PY_SOURCE:\n   return load_source(name, filename, file)\n  elif type_ == PY_COMPILED:\n   return load_compiled(name, filename, file)\n  elif type_ == C_EXTENSION and load_dynamic is not None:\n   if file is None:\n    with open(filename, 'rb') as opened_file:\n     return load_dynamic(name, filename, opened_file)\n   else:\n    return load_dynamic(name, filename, file)\n  elif type_ == PKG_DIRECTORY:\n   return load_package(name, filename)\n  elif type_ == C_BUILTIN:\n   return init_builtin(name)\n  elif type_ == PY_FROZEN:\n   return init_frozen(name)\n  else:\n   msg = \"Don't know how to import {} (type code {})\".format(name, type_)\n   raise ImportError(msg, name=name)\n   \n   \ndef find_module(name, path=None):\n \"\"\n if not isinstance(name, str):\n  raise TypeError(\"'name' must be a str, not {}\".format(type(name)))\n elif not isinstance(path, (type(None), list)):\n \n  raise RuntimeError(\"'list' must be None or a list, \"\n  \"not {}\".format(type(name)))\n  \n if path is None:\n  if is_builtin(name):\n   return None, None, ('', '', C_BUILTIN)\n  elif is_frozen(name):\n   return None, None, ('', '', PY_FROZEN)\n  else:\n   path = sys.path\n   \n for entry in path:\n  package_directory = os.path.join(entry, name)\n  for suffix in ['.py', machinery.BYTECODE_SUFFIXES[0]]:\n   package_file_name = '__init__' + suffix\n   file_path = os.path.join(package_directory, package_file_name)\n   if os.path.isfile(file_path):\n    return None, package_directory, ('', '', PKG_DIRECTORY)\n  with warnings.catch_warnings():\n   warnings.simplefilter('ignore')\n   for suffix, mode, type_ in get_suffixes():\n    file_name = name + suffix\n    file_path = os.path.join(entry, file_name)\n    if os.path.isfile(file_path):\n     break\n   else:\n    continue\n   break \n else:\n  raise ImportError(_bootstrap._ERR_MSG.format(name), name=name)\n  \n encoding = None\n if mode == 'U':\n  with open(file_path, 'rb') as file:\n   encoding = tokenize.detect_encoding(file.readline)[0]\n file = open(file_path, mode, encoding=encoding)\n return file, file_path, (suffix, mode, type_)\n \n \n_RELOADING = {}\n\ndef reload(module):\n \"\"\n if not module or type(module) != type(sys):\n  raise TypeError(\"reload() argument must be module\")\n name = module.__name__\n if name not in sys.modules:\n  msg = \"module {} not in sys.modules\"\n  raise ImportError(msg.format(name), name=name)\n if name in _RELOADING:\n  return _RELOADING[name]\n _RELOADING[name] = module\n try:\n  parent_name = name.rpartition('.')[0]\n  if parent_name and parent_name not in sys.modules:\n   msg = \"parent {!r} not in sys.modules\"\n   raise ImportError(msg.format(parent_name), name=parent_name)\n  module.__loader__.load_module(name)\n  \n  return sys.modules[module.__name__]\n finally:\n  try:\n   del _RELOADING[name]\n  except KeyError:\n   pass\n"], "errno": [".py", "\"\"\n\nerrorcode= {1: 'EPERM', 2: 'ENOENT', 3: 'ESRCH', 4: 'EINTR', 5: 'EIO', \n6: 'ENXIO', 7: 'E2BIG', 8: 'ENOEXEC', 9: 'EBADF', 10: 'ECHILD', 11: 'EAGAIN', \n12: 'ENOMEM', 13: 'EACCES', 14: 'EFAULT', 15: 'ENOTBLK', 16: 'EBUSY', \n17: 'EEXIST', 18: 'EXDEV', 19: 'ENODEV', 20: 'ENOTDIR', 21: 'EISDIR', \n22: 'EINVAL', 23: 'ENFILE', 24: 'EMFILE', 25: 'ENOTTY', 26: 'ETXTBSY', \n27: 'EFBIG', 28: 'ENOSPC', 29: 'ESPIPE', 30: 'EROFS', 31: 'EMLINK', \n32: 'EPIPE', 33: 'EDOM', 34: 'ERANGE', 35: 'EDEADLOCK', 36: 'ENAMETOOLONG', \n37: 'ENOLCK', 38: 'ENOSYS', 39: 'ENOTEMPTY', 40: 'ELOOP', 42: 'ENOMSG', \n43: 'EIDRM', 44: 'ECHRNG', 45: 'EL2NSYNC', 46: 'EL3HLT', 47: 'EL3RST', \n48: 'ELNRNG', 49: 'EUNATCH', 50: 'ENOCSI', 51: 'EL2HLT', 52: 'EBADE', \n53: 'EBADR', 54: 'EXFULL', 55: 'ENOANO', 56: 'EBADRQC', 57: 'EBADSLT', \n59: 'EBFONT', 60: 'ENOSTR', 61: 'ENODATA', 62: 'ETIME', 63: 'ENOSR', \n64: 'ENONET', 65: 'ENOPKG', 66: 'EREMOTE', 67: 'ENOLINK', 68: 'EADV', \n69: 'ESRMNT', 70: 'ECOMM', 71: 'EPROTO', 72: 'EMULTIHOP', 73: 'EDOTDOT', \n74: 'EBADMSG', 75: 'EOVERFLOW', 76: 'ENOTUNIQ', 77: 'EBADFD', 78: 'EREMCHG', \n79: 'ELIBACC', 80: 'ELIBBAD', 81: 'ELIBSCN', 82: 'ELIBMAX', 83: 'ELIBEXEC', \n84: 'EILSEQ', 85: 'ERESTART', 86: 'ESTRPIPE', 87: 'EUSERS', 88: 'ENOTSOCK', \n89: 'EDESTADDRREQ', 90: 'EMSGSIZE', 91: 'EPROTOTYPE', 92: 'ENOPROTOOPT', \n93: 'EPROTONOSUPPORT', 94: 'ESOCKTNOSUPPORT', 95: 'ENOTSUP', \n96: 'EPFNOSUPPORT', 97: 'EAFNOSUPPORT', 98: 'EADDRINUSE', \n99: 'EADDRNOTAVAIL', 100: 'ENETDOWN', 101: 'ENETUNREACH', 102: 'ENETRESET', \n103: 'ECONNABORTED', 104: 'ECONNRESET', 105: 'ENOBUFS', 106: 'EISCONN', \n107: 'ENOTCONN', 108: 'ESHUTDOWN', 109: 'ETOOMANYREFS', 110: 'ETIMEDOUT', \n111: 'ECONNREFUSED', 112: 'EHOSTDOWN', 113: 'EHOSTUNREACH', 114: 'EALREADY', \n115: 'EINPROGRESS', 116: 'ESTALE', 117: 'EUCLEAN', 118: 'ENOTNAM', \n119: 'ENAVAIL', 120: 'EISNAM', 121: 'EREMOTEIO', 122: 'EDQUOT', \n123: 'ENOMEDIUM', 124: 'EMEDIUMTYPE', 125: 'ECANCELED', 126: 'ENOKEY', \n127: 'EKEYEXPIRED', 128: 'EKEYREVOKED', 129: 'EKEYREJECTED', \n130: 'EOWNERDEAD', 131: 'ENOTRECOVERABLE', 132: 'ERFKILL'}\n\n\n_codes=[]\nfor _num, _code in errorcode.items():\n _codes.append('%s=%s' % (_code, _num))\n \neval(';'.join(_codes))\n"], "_socket": [".py", "\"\"\n\n\nAF_APPLETALK = 16\n\nAF_DECnet = 12\n\nAF_INET = 2\n\nAF_INET6 = 23\n\nAF_IPX = 6\n\nAF_IRDA = 26\n\nAF_SNA = 11\n\nAF_UNSPEC = 0\n\nAI_ADDRCONFIG = 1024\n\nAI_ALL = 256\n\nAI_CANONNAME = 2\n\nAI_NUMERICHOST = 4\n\nAI_NUMERICSERV = 8\n\nAI_PASSIVE = 1\n\nAI_V4MAPPED = 2048\n\nCAPI = '<capsule object \"_socket.CAPI\" at 0x00BC4F38>'\n\nEAI_AGAIN = 11002\n\nEAI_BADFLAGS = 10022\n\nEAI_FAIL = 11003\n\nEAI_FAMILY = 10047\n\nEAI_MEMORY = 8\n\nEAI_NODATA = 11001\n\nEAI_NONAME = 11001\n\nEAI_SERVICE = 10109\n\nEAI_SOCKTYPE = 10044\n\nINADDR_ALLHOSTS_GROUP = -536870911\n\nINADDR_ANY = 0\n\nINADDR_BROADCAST = -1\n\nINADDR_LOOPBACK = 2130706433\n\nINADDR_MAX_LOCAL_GROUP = -536870657\n\nINADDR_NONE = -1\n\nINADDR_UNSPEC_GROUP = -536870912\n\nIPPORT_RESERVED = 1024\n\nIPPORT_USERRESERVED = 5000\n\nIPPROTO_ICMP = 1\n\nIPPROTO_IP = 0\n\nIPPROTO_RAW = 255\n\nIPPROTO_TCP = 6\n\nIPPROTO_UDP = 17\n\nIPV6_CHECKSUM = 26\n\nIPV6_DONTFRAG = 14\n\nIPV6_HOPLIMIT = 21\n\nIPV6_HOPOPTS = 1\n\nIPV6_JOIN_GROUP = 12\n\nIPV6_LEAVE_GROUP = 13\n\nIPV6_MULTICAST_HOPS = 10\n\nIPV6_MULTICAST_IF = 9\n\nIPV6_MULTICAST_LOOP = 11\n\nIPV6_PKTINFO = 19\n\nIPV6_RECVRTHDR = 38\n\nIPV6_RECVTCLASS = 40\n\nIPV6_RTHDR = 32\n\nIPV6_TCLASS = 39\n\nIPV6_UNICAST_HOPS = 4\n\nIPV6_V6ONLY = 27\n\nIP_ADD_MEMBERSHIP = 12\n\nIP_DROP_MEMBERSHIP = 13\n\nIP_HDRINCL = 2\n\nIP_MULTICAST_IF = 9\n\nIP_MULTICAST_LOOP = 11\n\nIP_MULTICAST_TTL = 10\n\nIP_OPTIONS = 1\n\nIP_RECVDSTADDR = 25\n\nIP_TOS = 3\n\nIP_TTL = 4\n\nMSG_BCAST = 1024\n\nMSG_CTRUNC = 512\n\nMSG_DONTROUTE = 4\n\nMSG_MCAST = 2048\n\nMSG_OOB = 1\n\nMSG_PEEK = 2\n\nMSG_TRUNC = 256\n\nNI_DGRAM = 16\n\nNI_MAXHOST = 1025\n\nNI_MAXSERV = 32\n\nNI_NAMEREQD = 4\n\nNI_NOFQDN = 1\n\nNI_NUMERICHOST = 2\n\nNI_NUMERICSERV = 8\n\nRCVALL_MAX = 3\n\nRCVALL_OFF = 0\n\nRCVALL_ON = 1\n\nRCVALL_SOCKETLEVELONLY = 2\n\nSHUT_RD = 0\n\nSHUT_RDWR = 2\n\nSHUT_WR = 1\n\nSIO_KEEPALIVE_VALS = 2550136836\n\nSIO_RCVALL = 2550136833\n\nSOCK_DGRAM = 2\n\nSOCK_RAW = 3\n\nSOCK_RDM = 4\n\nSOCK_SEQPACKET = 5\n\nSOCK_STREAM = 1\n\nSOL_IP = 0\n\nSOL_SOCKET = 65535\n\nSOL_TCP = 6\n\nSOL_UDP = 17\n\nSOMAXCONN = 2147483647\n\nSO_ACCEPTCONN = 2\n\nSO_BROADCAST = 32\n\nSO_DEBUG = 1\n\nSO_DONTROUTE = 16\n\nSO_ERROR = 4103\n\nSO_EXCLUSIVEADDRUSE = -5\n\nSO_KEEPALIVE = 8\n\nSO_LINGER = 128\n\nSO_OOBINLINE = 256\n\nSO_RCVBUF = 4098\n\nSO_RCVLOWAT = 4100\n\nSO_RCVTIMEO = 4102\n\nSO_REUSEADDR = 4\n\nSO_SNDBUF = 4097\n\nSO_SNDLOWAT = 4099\n\nSO_SNDTIMEO = 4101\n\nSO_TYPE = 4104\n\nSO_USELOOPBACK = 64\n\nclass SocketType:\n pass\n \nTCP_MAXSEG = 4\n\nTCP_NODELAY = 1\n\n__loader__ = '<_frozen_importlib.ExtensionFileLoader object at 0x00CA2D90>'\n\ndef dup(*args,**kw):\n \"\"\n pass\n \nclass error:\n pass\n \nclass gaierror:\n pass\n \ndef getaddrinfo(*args,**kw):\n \"\"\n pass\n \ndef getdefaulttimeout(*args,**kw):\n \"\"\n pass\n \ndef gethostbyaddr(*args,**kw):\n \"\"\n pass\n \ndef gethostbyname(*args,**kw):\n \"\"\n pass\n \ndef gethostbyname_ex(*args,**kw):\n \"\"\n pass\n \ndef gethostname(*args,**kw):\n \"\"\n pass\n \ndef getnameinfo(*args,**kw):\n \"\"\n pass\n \ndef getprotobyname(*args,**kw):\n \"\"\n pass\n \ndef getservbyname(*args,**kw):\n \"\"\n pass\n \ndef getservbyport(*args,**kw):\n \"\"\n pass\n \nhas_ipv6 = True\n\nclass herror:\n pass\n \ndef htonl(*args,**kw):\n \"\"\n pass\n \ndef htons(*args,**kw):\n \"\"\n pass\n \ndef inet_aton(*args,**kw):\n \"\"\n pass\n \ndef inet_ntoa(*args,**kw):\n \"\"\n pass\n \ndef ntohl(*args,**kw):\n \"\"\n pass\n \ndef ntohs(*args,**kw):\n \"\"\n pass\n \ndef setdefaulttimeout(*args,**kw):\n \"\"\n pass\n \nclass socket:\n def __init__(self,*args,**kw):\n  pass\n def bind(self,*args,**kw):\n  pass\n def close(self):\n  pass\n  \nclass timeout:\n pass\n"], "binascii": [".py", "\"\"\n\n\n\nclass Error(Exception):\n pass\n \nclass Done(Exception):\n pass\n \nclass Incomplete(Exception):\n pass\n \ndef a2b_uu(s):\n if not s:\n  return ''\n  \n length = (ord(s[0]) - 0x20) % 64\n \n def quadruplets_gen(s):\n  while s:\n   try:\n    yield ord(s[0]), ord(s[1]), ord(s[2]), ord(s[3])\n   except IndexError:\n    s += '   '\n    yield ord(s[0]), ord(s[1]), ord(s[2]), ord(s[3])\n    return\n   s = s[4:]\n   \n try:\n  result = [''.join(\n  [chr((A - 0x20) << 2 | (((B - 0x20) >> 4) & 0x3)),\n  chr(((B - 0x20) & 0xf) << 4 | (((C - 0x20) >> 2) & 0xf)),\n  chr(((C - 0x20) & 0x3) << 6 | ((D - 0x20) & 0x3f))\n  ]) for A, B, C, D in quadruplets_gen(s[1:].rstrip())]\n except ValueError:\n  raise Error('Illegal char')\n result = ''.join(result)\n trailingdata = result[length:]\n if trailingdata.strip('\\x00'):\n  raise Error('Trailing garbage')\n result = result[:length]\n if len(result) < length:\n  result += ((length - len(result)) * '\\x00')\n return bytes(result, __BRYTHON__.charset)\n \n \ndef b2a_uu(s):\n length = len(s)\n if length > 45:\n  raise Error('At most 45 bytes at once')\n  \n def triples_gen(s):\n  while s:\n   try:\n    yield ord(s[0]), ord(s[1]), ord(s[2])\n   except IndexError:\n    s += '\\0\\0'\n    yield ord(s[0]), ord(s[1]), ord(s[2])\n    return\n   s = s[3:]\n   \n result = [''.join(\n [chr(0x20 + (( A >> 2 ) & 0x3F)),\n chr(0x20 + (((A << 4) | ((B >> 4) & 0xF)) & 0x3F)),\n chr(0x20 + (((B << 2) | ((C >> 6) & 0x3)) & 0x3F)),\n chr(0x20 + (( C ) & 0x3F))])\n for A, B, C in triples_gen(s)]\n return chr(ord(' ') + (length & 0o77)) + ''.join(result) + '\\n'\n \n \ntable_a2b_base64 = {\n'A': 0,\n'B': 1,\n'C': 2,\n'D': 3,\n'E': 4,\n'F': 5,\n'G': 6,\n'H': 7,\n'I': 8,\n'J': 9,\n'K': 10,\n'L': 11,\n'M': 12,\n'N': 13,\n'O': 14,\n'P': 15,\n'Q': 16,\n'R': 17,\n'S': 18,\n'T': 19,\n'U': 20,\n'V': 21,\n'W': 22,\n'X': 23,\n'Y': 24,\n'Z': 25,\n'a': 26,\n'b': 27,\n'c': 28,\n'd': 29,\n'e': 30,\n'f': 31,\n'g': 32,\n'h': 33,\n'i': 34,\n'j': 35,\n'k': 36,\n'l': 37,\n'm': 38,\n'n': 39,\n'o': 40,\n'p': 41,\n'q': 42,\n'r': 43,\n's': 44,\n't': 45,\n'u': 46,\n'v': 47,\n'w': 48,\n'x': 49,\n'y': 50,\n'z': 51,\n'0': 52,\n'1': 53,\n'2': 54,\n'3': 55,\n'4': 56,\n'5': 57,\n'6': 58,\n'7': 59,\n'8': 60,\n'9': 61,\n'+': 62,\n'/': 63,\n'=': 0,\n}\n\n\ndef a2b_base64(s):\n if not isinstance(s, (str, bytes)):\n  raise TypeError(\"expected string, got %r\" % (s,))\n s = s.rstrip()\n \n \n \n def next_valid_char(s, pos):\n  for i in range(pos + 1, len(s)):\n   c = s[i]\n   if c < '\\x7f':\n    try:\n     table_a2b_base64[c]\n     return c\n    except KeyError:\n     pass\n  return None\n  \n quad_pos = 0\n leftbits = 0\n leftchar = 0\n res = []\n for i, c in enumerate(s):\n  if isinstance(c, int):\n   c = chr(c)\n  if c > '\\x7f' or c == '\\n' or c == '\\r' or c == ' ':\n   continue\n  if c == '=':\n   if quad_pos < 2 or (quad_pos == 2 and next_valid_char(s, i) != '='):\n    continue\n   else:\n    leftbits = 0\n    break\n  try:\n   next_c = table_a2b_base64[c]\n  except KeyError:\n   continue\n  quad_pos = (quad_pos + 1) & 0x03\n  leftchar = (leftchar << 6) | next_c\n  leftbits += 6\n  if leftbits >= 8:\n   leftbits -= 8\n   res.append((leftchar >> leftbits & 0xff))\n   leftchar &= ((1 << leftbits) - 1)\n if leftbits != 0:\n  raise Error('Incorrect padding')\n  \n return bytes(''.join([chr(i) for i in res]),__BRYTHON__.charset)\n \ntable_b2a_base64 = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" \"0123456789+/\"\n\ndef b2a_base64(s):\n length = len(s)\n final_length = length % 3\n \n def triples_gen(s):\n  while s:\n   try:\n    yield s[0], s[1], s[2]\n   except IndexError:\n    s += b'\\0\\0'\n    yield s[0], s[1], s[2]\n    return\n   s = s[3:]\n   \n a = triples_gen(s[ :length - final_length])\n \n result = [''.join(\n [table_b2a_base64[( A >> 2 ) & 0x3F],\n table_b2a_base64[((A << 4) | ((B >> 4) & 0xF)) & 0x3F],\n table_b2a_base64[((B << 2) | ((C >> 6) & 0x3)) & 0x3F],\n table_b2a_base64[( C ) & 0x3F]])\n for A, B, C in a]\n \n final = s[length - final_length:]\n if final_length == 0:\n  snippet = ''\n elif final_length == 1:\n  a = ord(final[0])\n  snippet = table_b2a_base64[(a >> 2 ) & 0x3F] + table_b2a_base64[(a << 4 ) & 0x3F] + '=='\n else:\n  a = ord(final[0])\n  b = ord(final[1])\n  snippet = table_b2a_base64[(a >> 2) & 0x3F] + table_b2a_base64[((a << 4) | (b >> 4) & 0xF) & 0x3F] + table_b2a_base64[(b << 2) & 0x3F] + '='\n  \n return bytes(''.join(result) + snippet + '\\n',__BRYTHON__.charset)\n \ndef a2b_qp(s, header=False):\n inp = 0\n odata = []\n while inp < len(s):\n  if s[inp] == '=':\n   inp += 1\n   if inp >= len(s):\n    break\n    \n   if (s[inp] == '\\n') or (s[inp] == '\\r'):\n    if s[inp] != '\\n':\n     while inp < len(s) and s[inp] != '\\n':\n      inp += 1\n    if inp < len(s):\n     inp += 1\n   elif s[inp] == '=':\n   \n    odata.append('=')\n    inp += 1\n   elif s[inp] in hex_numbers and s[inp + 1] in hex_numbers:\n    ch = chr(int(s[inp:inp+2], 16))\n    inp += 2\n    odata.append(ch)\n   else:\n    odata.append('=')\n  elif header and s[inp] == '_':\n   odata.append(' ')\n   inp += 1\n  else:\n   odata.append(s[inp])\n   inp += 1\n return bytes(''.join(odata), __BRYTHON__.charset)\n \ndef b2a_qp(data, quotetabs=False, istext=True, header=False):\n \"\"\n MAXLINESIZE = 76\n \n \n lf = data.find('\\n')\n crlf = lf > 0 and data[lf-1] == '\\r'\n \n inp = 0\n linelen = 0\n odata = []\n while inp < len(data):\n  c = data[inp]\n  if (c > '~' or\n  c == '=' or\n  (header and c == '_') or\n  (c == '.' and linelen == 0 and (inp+1 == len(data) or\n  data[inp+1] == '\\n' or\n  data[inp+1] == '\\r')) or\n  (not istext and (c == '\\r' or c == '\\n')) or\n  ((c == '\\t' or c == ' ') and (inp + 1 == len(data))) or\n  (c <= ' ' and c != '\\r' and c != '\\n' and\n  (quotetabs or (not quotetabs and (c != '\\t' and c != ' '))))):\n   linelen += 3\n   if linelen >= MAXLINESIZE:\n    odata.append('=')\n    if crlf: odata.append('\\r')\n    odata.append('\\n')\n    linelen = 3\n   odata.append('=' + two_hex_digits(ord(c)))\n   inp += 1\n  else:\n   if (istext and\n   (c == '\\n' or (inp+1 < len(data) and c == '\\r' and\n   data[inp+1] == '\\n'))):\n    linelen = 0\n    \n    if (len(odata) > 0 and\n    (odata[-1] == ' ' or odata[-1] == '\\t')):\n     ch = ord(odata[-1])\n     odata[-1] = '='\n     odata.append(two_hex_digits(ch))\n     \n    if crlf: odata.append('\\r')\n    odata.append('\\n')\n    if c == '\\r':\n     inp += 2\n    else:\n     inp += 1\n   else:\n    if (inp + 1 < len(data) and\n    data[inp+1] != '\\n' and\n    (linelen + 1) >= MAXLINESIZE):\n     odata.append('=')\n     if crlf: odata.append('\\r')\n     odata.append('\\n')\n     linelen = 0\n     \n    linelen += 1\n    if header and c == ' ':\n     c = '_'\n    odata.append(c)\n    inp += 1\n return ''.join(odata)\n \nhex_numbers = '0123456789ABCDEF'\ndef hex(n):\n if n == 0:\n  return '0'\n  \n if n < 0:\n  n = -n\n  sign = '-'\n else:\n  sign = ''\n arr = []\n \n def hex_gen(n):\n  \"\"\n  while n:\n   yield n % 0x10\n   n = n / 0x10\n   \n for nibble in hex_gen(n):\n  arr = [hex_numbers[nibble]] + arr\n return sign + ''.join(arr)\n \ndef two_hex_digits(n):\n return hex_numbers[n / 0x10] + hex_numbers[n % 0x10]\n \n \ndef strhex_to_int(s):\n i = 0\n for c in s:\n  i = i * 0x10 + hex_numbers.index(c)\n return i\n \nhqx_encoding = '!\"#$%&\\'()*+,-012345689@ABCDEFGHIJKLMNPQRSTUVXYZ[`abcdefhijklmpqr'\n\nDONE = 0x7f\nSKIP = 0x7e\nFAIL = 0x7d\n\ntable_a2b_hqx = [\n\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n\nFAIL, FAIL, SKIP, FAIL, FAIL, SKIP, FAIL, FAIL,\n\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n\nFAIL, 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06,\n\n0x07, 0x08, 0x09, 0x0A, 0x0B, 0x0C, FAIL, FAIL,\n\n0x0D, 0x0E, 0x0F, 0x10, 0x11, 0x12, 0x13, FAIL,\n\n0x14, 0x15, DONE, FAIL, FAIL, FAIL, FAIL, FAIL,\n\n0x16, 0x17, 0x18, 0x19, 0x1A, 0x1B, 0x1C, 0x1D,\n\n0x1E, 0x1F, 0x20, 0x21, 0x22, 0x23, 0x24, FAIL,\n\n0x25, 0x26, 0x27, 0x28, 0x29, 0x2A, 0x2B, FAIL,\n\n0x2C, 0x2D, 0x2E, 0x2F, FAIL, FAIL, FAIL, FAIL,\n\n0x30, 0x31, 0x32, 0x33, 0x34, 0x35, 0x36, FAIL,\n\n0x37, 0x38, 0x39, 0x3A, 0x3B, 0x3C, FAIL, FAIL,\n\n0x3D, 0x3E, 0x3F, FAIL, FAIL, FAIL, FAIL, FAIL,\n\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\nFAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL, FAIL,\n]\n\ndef a2b_hqx(s):\n result = []\n \n def quadruples_gen(s):\n  t = []\n  for c in s:\n   res = table_a2b_hqx[ord(c)]\n   if res == SKIP:\n    continue\n   elif res == FAIL:\n    raise Error('Illegal character')\n   elif res == DONE:\n    yield t\n    raise Done\n   else:\n    t.append(res)\n   if len(t) == 4:\n    yield t\n    t = []\n  yield t\n  \n done = 0\n try:\n  for snippet in quadruples_gen(s):\n   length = len(snippet)\n   if length == 4:\n    result.append(chr(((snippet[0] & 0x3f) << 2) | (snippet[1] >> 4))) \n    result.append(chr(((snippet[1] & 0x0f) << 4) | (snippet[2] >> 2))) \n    result.append(chr(((snippet[2] & 0x03) << 6) | (snippet[3]))) \n   elif length == 3:\n    result.append(chr(((snippet[0] & 0x3f) << 2) | (snippet[1] >> 4))) \n    result.append(chr(((snippet[1] & 0x0f) << 4) | (snippet[2] >> 2))) \n   elif length == 2:\n    result.append(chr(((snippet[0] & 0x3f) << 2) | (snippet[1] >> 4))) \n except Done:\n  done = 1\n except Error:\n  raise\n return (''.join(result), done)\n \n \n \ndef b2a_hqx(s):\n result =[]\n \n def triples_gen(s):\n  while s:\n   try:\n    yield ord(s[0]), ord(s[1]), ord(s[2])\n   except IndexError:\n    yield tuple([ord(c) for c in s])\n   s = s[3:]\n   \n for snippet in triples_gen(s):\n  length = len(snippet)\n  if length == 3:\n   result.append(\n   hqx_encoding[(snippet[0] & 0xfc) >> 2])\n   result.append(hqx_encoding[\n   ((snippet[0] & 0x03) << 4) | ((snippet[1] & 0xf0) >> 4)])\n   result.append(hqx_encoding[\n   (snippet[1] & 0x0f) << 2 | ((snippet[2] & 0xc0) >> 6)])\n   result.append(hqx_encoding[snippet[2] & 0x3f])\n  elif length == 2:\n   result.append(\n   hqx_encoding[(snippet[0] & 0xfc) >> 2])\n   result.append(hqx_encoding[\n   ((snippet[0] & 0x03) << 4) | ((snippet[1] & 0xf0) >> 4)])\n   result.append(hqx_encoding[\n   (snippet[1] & 0x0f) << 2])\n  elif length == 1:\n   result.append(\n   hqx_encoding[(snippet[0] & 0xfc) >> 2])\n   result.append(hqx_encoding[\n   ((snippet[0] & 0x03) << 4)])\n return ''.join(result)\n \ncrctab_hqx = [\n0x0000, 0x1021, 0x2042, 0x3063, 0x4084, 0x50a5, 0x60c6, 0x70e7,\n0x8108, 0x9129, 0xa14a, 0xb16b, 0xc18c, 0xd1ad, 0xe1ce, 0xf1ef,\n0x1231, 0x0210, 0x3273, 0x2252, 0x52b5, 0x4294, 0x72f7, 0x62d6,\n0x9339, 0x8318, 0xb37b, 0xa35a, 0xd3bd, 0xc39c, 0xf3ff, 0xe3de,\n0x2462, 0x3443, 0x0420, 0x1401, 0x64e6, 0x74c7, 0x44a4, 0x5485,\n0xa56a, 0xb54b, 0x8528, 0x9509, 0xe5ee, 0xf5cf, 0xc5ac, 0xd58d,\n0x3653, 0x2672, 0x1611, 0x0630, 0x76d7, 0x66f6, 0x5695, 0x46b4,\n0xb75b, 0xa77a, 0x9719, 0x8738, 0xf7df, 0xe7fe, 0xd79d, 0xc7bc,\n0x48c4, 0x58e5, 0x6886, 0x78a7, 0x0840, 0x1861, 0x2802, 0x3823,\n0xc9cc, 0xd9ed, 0xe98e, 0xf9af, 0x8948, 0x9969, 0xa90a, 0xb92b,\n0x5af5, 0x4ad4, 0x7ab7, 0x6a96, 0x1a71, 0x0a50, 0x3a33, 0x2a12,\n0xdbfd, 0xcbdc, 0xfbbf, 0xeb9e, 0x9b79, 0x8b58, 0xbb3b, 0xab1a,\n0x6ca6, 0x7c87, 0x4ce4, 0x5cc5, 0x2c22, 0x3c03, 0x0c60, 0x1c41,\n0xedae, 0xfd8f, 0xcdec, 0xddcd, 0xad2a, 0xbd0b, 0x8d68, 0x9d49,\n0x7e97, 0x6eb6, 0x5ed5, 0x4ef4, 0x3e13, 0x2e32, 0x1e51, 0x0e70,\n0xff9f, 0xefbe, 0xdfdd, 0xcffc, 0xbf1b, 0xaf3a, 0x9f59, 0x8f78,\n0x9188, 0x81a9, 0xb1ca, 0xa1eb, 0xd10c, 0xc12d, 0xf14e, 0xe16f,\n0x1080, 0x00a1, 0x30c2, 0x20e3, 0x5004, 0x4025, 0x7046, 0x6067,\n0x83b9, 0x9398, 0xa3fb, 0xb3da, 0xc33d, 0xd31c, 0xe37f, 0xf35e,\n0x02b1, 0x1290, 0x22f3, 0x32d2, 0x4235, 0x5214, 0x6277, 0x7256,\n0xb5ea, 0xa5cb, 0x95a8, 0x8589, 0xf56e, 0xe54f, 0xd52c, 0xc50d,\n0x34e2, 0x24c3, 0x14a0, 0x0481, 0x7466, 0x6447, 0x5424, 0x4405,\n0xa7db, 0xb7fa, 0x8799, 0x97b8, 0xe75f, 0xf77e, 0xc71d, 0xd73c,\n0x26d3, 0x36f2, 0x0691, 0x16b0, 0x6657, 0x7676, 0x4615, 0x5634,\n0xd94c, 0xc96d, 0xf90e, 0xe92f, 0x99c8, 0x89e9, 0xb98a, 0xa9ab,\n0x5844, 0x4865, 0x7806, 0x6827, 0x18c0, 0x08e1, 0x3882, 0x28a3,\n0xcb7d, 0xdb5c, 0xeb3f, 0xfb1e, 0x8bf9, 0x9bd8, 0xabbb, 0xbb9a,\n0x4a75, 0x5a54, 0x6a37, 0x7a16, 0x0af1, 0x1ad0, 0x2ab3, 0x3a92,\n0xfd2e, 0xed0f, 0xdd6c, 0xcd4d, 0xbdaa, 0xad8b, 0x9de8, 0x8dc9,\n0x7c26, 0x6c07, 0x5c64, 0x4c45, 0x3ca2, 0x2c83, 0x1ce0, 0x0cc1,\n0xef1f, 0xff3e, 0xcf5d, 0xdf7c, 0xaf9b, 0xbfba, 0x8fd9, 0x9ff8,\n0x6e17, 0x7e36, 0x4e55, 0x5e74, 0x2e93, 0x3eb2, 0x0ed1, 0x1ef0,\n]\n\ndef crc_hqx(s, crc):\n for c in s:\n  crc = ((crc << 8) & 0xff00) ^ crctab_hqx[((crc >> 8) & 0xff) ^ ord(c)]\n  \n return crc\n \ndef rlecode_hqx(s):\n \"\"\n if not s:\n  return ''\n result = []\n prev = s[0]\n count = 1\n \n \n \n \n if s[-1] == '!':\n  s = s[1:] + '?'\n else:\n  s = s[1:] + '!'\n  \n for c in s:\n  if c == prev and count < 255:\n   count += 1\n  else:\n   if count == 1:\n    if prev != '\\x90':\n     result.append(prev)\n    else:\n     result.extend(['\\x90', '\\x00'])\n   elif count < 4:\n    if prev != '\\x90':\n     result.extend([prev] * count)\n    else:\n     result.extend(['\\x90', '\\x00'] * count)\n   else:\n    if prev != '\\x90':\n     result.extend([prev, '\\x90', chr(count)])\n    else:\n     result.extend(['\\x90', '\\x00', '\\x90', chr(count)]) \n   count = 1\n   prev = c\n   \n return ''.join(result)\n \ndef rledecode_hqx(s):\n s = s.split('\\x90')\n result = [s[0]]\n prev = s[0]\n for snippet in s[1:]:\n  count = ord(snippet[0])\n  if count > 0:\n   result.append(prev[-1] * (count-1))\n   prev = snippet\n  else:\n   result.append('\\x90')\n   prev = '\\x90'\n  result.append(snippet[1:])\n  \n return ''.join(result)\n \ncrc_32_tab = [\n0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419,\n0x706af48f, 0xe963a535, 0x9e6495a3, 0x0edb8832, 0x79dcb8a4,\n0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07,\n0x90bf1d91, 0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de,\n0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7, 0x136c9856,\n0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9,\n0xfa0f3d63, 0x8d080df5, 0x3b6e20c8, 0x4c69105e, 0xd56041e4,\n0xa2677172, 0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b,\n0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3,\n0x45df5c75, 0xdcd60dcf, 0xabd13d59, 0x26d930ac, 0x51de003a,\n0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423, 0xcfba9599,\n0xb8bda50f, 0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924,\n0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d, 0x76dc4190,\n0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f,\n0x9fbfe4a5, 0xe8b8d433, 0x7807c9a2, 0x0f00f934, 0x9609a88e,\n0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01,\n0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed,\n0x1b01a57b, 0x8208f4c1, 0xf50fc457, 0x65b0d9c6, 0x12b7e950,\n0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3,\n0xfbd44c65, 0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2,\n0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb, 0x4369e96a,\n0x346ed9fc, 0xad678846, 0xda60b8d0, 0x44042d73, 0x33031de5,\n0xaa0a4c5f, 0xdd0d7cc9, 0x5005713c, 0x270241aa, 0xbe0b1010,\n0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,\n0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17,\n0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad, 0xedb88320, 0x9abfb3b6,\n0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615,\n0x73dc1683, 0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8,\n0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1, 0xf00f9344,\n0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb,\n0x196c3671, 0x6e6b06e7, 0xfed41b76, 0x89d32be0, 0x10da7a5a,\n0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5,\n0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252, 0xd1bb67f1,\n0xa6bc5767, 0x3fb506dd, 0x48b2364b, 0xd80d2bda, 0xaf0a1b4c,\n0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef,\n0x4669be79, 0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236,\n0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f, 0xc5ba3bbe,\n0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31,\n0x2cd99e8b, 0x5bdeae1d, 0x9b64c2b0, 0xec63f226, 0x756aa39c,\n0x026d930a, 0x9c0906a9, 0xeb0e363f, 0x72076785, 0x05005713,\n0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b,\n0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21, 0x86d3d2d4, 0xf1d4e242,\n0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1,\n0x18b74777, 0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c,\n0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45, 0xa00ae278,\n0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7,\n0x4969474d, 0x3e6e77db, 0xaed16a4a, 0xd9d65adc, 0x40df0b66,\n0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,\n0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605,\n0xcdd70693, 0x54de5729, 0x23d967bf, 0xb3667a2e, 0xc4614ab8,\n0x5d681b02, 0x2a6f2b94, 0xb40bbe37, 0xc30c8ea1, 0x5a05df1b,\n0x2d02ef8d\n]\n\ndef crc32(s, crc=0):\n result = 0\n crc = ~int(crc) & 0xffffffff\n \n for c in s:\n  crc = crc_32_tab[(crc ^ int(ord(c))) & 0xff] ^ (crc >> 8)\n  \n  \n  \n result = crc ^ 0xffffffff\n \n if result > 2**31:\n  result = ((result + 2**31) % 2**32) - 2**31\n  \n return result\n \ndef b2a_hex(s):\n result = []\n for char in s:\n  c = (ord(char) >> 4) & 0xf\n  if c > 9:\n   c = c + ord('a') - 10\n  else:\n   c = c + ord('0')\n  result.append(chr(c))\n  c = ord(char) & 0xf\n  if c > 9:\n   c = c + ord('a') - 10\n  else:\n   c = c + ord('0')\n  result.append(chr(c))\n return ''.join(result)\n \nhexlify = b2a_hex\n\ntable_hex = [\n-1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n-1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n-1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9,-1,-1, -1,-1,-1,-1,\n-1,10,11,12, 13,14,15,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n-1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n-1,10,11,12, 13,14,15,-1, -1,-1,-1,-1, -1,-1,-1,-1,\n-1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1, -1,-1,-1,-1\n]\n\n\ndef a2b_hex(t):\n result = []\n \n def pairs_gen(s):\n  while s:\n   try:\n    yield table_hex[ord(s[0])], table_hex[ord(s[1])]\n   except IndexError:\n    if len(s):\n     raise TypeError('Odd-length string')\n    return\n   s = s[2:]\n   \n for a, b in pairs_gen(t):\n  if a < 0 or b < 0:\n   raise TypeError('Non-hexadecimal digit found')\n  result.append(chr((a << 4) + b))\n return bytes(''.join(result), __BRYTHON__.charset)\n \n \nunhexlify = a2b_hex\n"], "sre_constants": [".py", "\n\n\n\n\n\n\n\n\n\n\n\"\"\n\n\n\nMAGIC = 20031017\n\n\n\n\n\n\n\nclass error(Exception):\n pass\n \n \n \nFAILURE = \"failure\"\nSUCCESS = \"success\"\n\nANY = \"any\"\nANY_ALL = \"any_all\"\nASSERT = \"assert\"\nASSERT_NOT = \"assert_not\"\nAT = \"at\"\nBIGCHARSET = \"bigcharset\"\nBRANCH = \"branch\"\nCALL = \"call\"\nCATEGORY = \"category\"\nCHARSET = \"charset\"\nGROUPREF = \"groupref\"\nGROUPREF_IGNORE = \"groupref_ignore\"\nGROUPREF_EXISTS = \"groupref_exists\"\nIN = \"in\"\nIN_IGNORE = \"in_ignore\"\nINFO = \"info\"\nJUMP = \"jump\"\nLITERAL = \"literal\"\nLITERAL_IGNORE = \"literal_ignore\"\nMARK = \"mark\"\nMAX_REPEAT = \"max_repeat\"\nMAX_UNTIL = \"max_until\"\nMIN_REPEAT = \"min_repeat\"\nMIN_UNTIL = \"min_until\"\nNEGATE = \"negate\"\nNOT_LITERAL = \"not_literal\"\nNOT_LITERAL_IGNORE = \"not_literal_ignore\"\nRANGE = \"range\"\nREPEAT = \"repeat\"\nREPEAT_ONE = \"repeat_one\"\nSUBPATTERN = \"subpattern\"\nMIN_REPEAT_ONE = \"min_repeat_one\"\n\n\nAT_BEGINNING = \"at_beginning\"\nAT_BEGINNING_LINE = \"at_beginning_line\"\nAT_BEGINNING_STRING = \"at_beginning_string\"\nAT_BOUNDARY = \"at_boundary\"\nAT_NON_BOUNDARY = \"at_non_boundary\"\nAT_END = \"at_end\"\nAT_END_LINE = \"at_end_line\"\nAT_END_STRING = \"at_end_string\"\nAT_LOC_BOUNDARY = \"at_loc_boundary\"\nAT_LOC_NON_BOUNDARY = \"at_loc_non_boundary\"\nAT_UNI_BOUNDARY = \"at_uni_boundary\"\nAT_UNI_NON_BOUNDARY = \"at_uni_non_boundary\"\n\n\nCATEGORY_DIGIT = \"category_digit\"\nCATEGORY_NOT_DIGIT = \"category_not_digit\"\nCATEGORY_SPACE = \"category_space\"\nCATEGORY_NOT_SPACE = \"category_not_space\"\nCATEGORY_WORD = \"category_word\"\nCATEGORY_NOT_WORD = \"category_not_word\"\nCATEGORY_LINEBREAK = \"category_linebreak\"\nCATEGORY_NOT_LINEBREAK = \"category_not_linebreak\"\nCATEGORY_LOC_WORD = \"category_loc_word\"\nCATEGORY_LOC_NOT_WORD = \"category_loc_not_word\"\nCATEGORY_UNI_DIGIT = \"category_uni_digit\"\nCATEGORY_UNI_NOT_DIGIT = \"category_uni_not_digit\"\nCATEGORY_UNI_SPACE = \"category_uni_space\"\nCATEGORY_UNI_NOT_SPACE = \"category_uni_not_space\"\nCATEGORY_UNI_WORD = \"category_uni_word\"\nCATEGORY_UNI_NOT_WORD = \"category_uni_not_word\"\nCATEGORY_UNI_LINEBREAK = \"category_uni_linebreak\"\nCATEGORY_UNI_NOT_LINEBREAK = \"category_uni_not_linebreak\"\n\nOPCODES = [\n\n\nFAILURE, SUCCESS,\n\nANY, ANY_ALL,\nASSERT, ASSERT_NOT,\nAT,\nBRANCH,\nCALL,\nCATEGORY,\nCHARSET, BIGCHARSET,\nGROUPREF, GROUPREF_EXISTS, GROUPREF_IGNORE,\nIN, IN_IGNORE,\nINFO,\nJUMP,\nLITERAL, LITERAL_IGNORE,\nMARK,\nMAX_UNTIL,\nMIN_UNTIL,\nNOT_LITERAL, NOT_LITERAL_IGNORE,\nNEGATE,\nRANGE,\nREPEAT,\nREPEAT_ONE,\nSUBPATTERN,\nMIN_REPEAT_ONE\n\n]\n\nATCODES = [\nAT_BEGINNING, AT_BEGINNING_LINE, AT_BEGINNING_STRING, AT_BOUNDARY,\nAT_NON_BOUNDARY, AT_END, AT_END_LINE, AT_END_STRING,\nAT_LOC_BOUNDARY, AT_LOC_NON_BOUNDARY, AT_UNI_BOUNDARY,\nAT_UNI_NON_BOUNDARY\n]\n\nCHCODES = [\nCATEGORY_DIGIT, CATEGORY_NOT_DIGIT, CATEGORY_SPACE,\nCATEGORY_NOT_SPACE, CATEGORY_WORD, CATEGORY_NOT_WORD,\nCATEGORY_LINEBREAK, CATEGORY_NOT_LINEBREAK, CATEGORY_LOC_WORD,\nCATEGORY_LOC_NOT_WORD, CATEGORY_UNI_DIGIT, CATEGORY_UNI_NOT_DIGIT,\nCATEGORY_UNI_SPACE, CATEGORY_UNI_NOT_SPACE, CATEGORY_UNI_WORD,\nCATEGORY_UNI_NOT_WORD, CATEGORY_UNI_LINEBREAK,\nCATEGORY_UNI_NOT_LINEBREAK\n]\n\ndef makedict(list):\n d = {}\n i = 0\n for item in list:\n  d[item] = i\n  i = i + 1\n return d\n \nOPCODES = makedict(OPCODES)\nATCODES = makedict(ATCODES)\nCHCODES = makedict(CHCODES)\n\n\nOP_IGNORE = {\nGROUPREF: GROUPREF_IGNORE,\nIN: IN_IGNORE,\nLITERAL: LITERAL_IGNORE,\nNOT_LITERAL: NOT_LITERAL_IGNORE\n}\n\nAT_MULTILINE = {\nAT_BEGINNING: AT_BEGINNING_LINE,\nAT_END: AT_END_LINE\n}\n\nAT_LOCALE = {\nAT_BOUNDARY: AT_LOC_BOUNDARY,\nAT_NON_BOUNDARY: AT_LOC_NON_BOUNDARY\n}\n\nAT_UNICODE = {\nAT_BOUNDARY: AT_UNI_BOUNDARY,\nAT_NON_BOUNDARY: AT_UNI_NON_BOUNDARY\n}\n\nCH_LOCALE = {\nCATEGORY_DIGIT: CATEGORY_DIGIT,\nCATEGORY_NOT_DIGIT: CATEGORY_NOT_DIGIT,\nCATEGORY_SPACE: CATEGORY_SPACE,\nCATEGORY_NOT_SPACE: CATEGORY_NOT_SPACE,\nCATEGORY_WORD: CATEGORY_LOC_WORD,\nCATEGORY_NOT_WORD: CATEGORY_LOC_NOT_WORD,\nCATEGORY_LINEBREAK: CATEGORY_LINEBREAK,\nCATEGORY_NOT_LINEBREAK: CATEGORY_NOT_LINEBREAK\n}\n\nCH_UNICODE = {\nCATEGORY_DIGIT: CATEGORY_UNI_DIGIT,\nCATEGORY_NOT_DIGIT: CATEGORY_UNI_NOT_DIGIT,\nCATEGORY_SPACE: CATEGORY_UNI_SPACE,\nCATEGORY_NOT_SPACE: CATEGORY_UNI_NOT_SPACE,\nCATEGORY_WORD: CATEGORY_UNI_WORD,\nCATEGORY_NOT_WORD: CATEGORY_UNI_NOT_WORD,\nCATEGORY_LINEBREAK: CATEGORY_UNI_LINEBREAK,\nCATEGORY_NOT_LINEBREAK: CATEGORY_UNI_NOT_LINEBREAK\n}\n\n\nSRE_FLAG_TEMPLATE = 1 \nSRE_FLAG_IGNORECASE = 2 \nSRE_FLAG_LOCALE = 4 \nSRE_FLAG_MULTILINE = 8 \nSRE_FLAG_DOTALL = 16 \nSRE_FLAG_UNICODE = 32 \nSRE_FLAG_VERBOSE = 64 \nSRE_FLAG_DEBUG = 128 \nSRE_FLAG_ASCII = 256 \n\n\nSRE_INFO_PREFIX = 1 \nSRE_INFO_LITERAL = 2 \nSRE_INFO_CHARSET = 4 \n\nif __name__ == \"__main__\":\n def dump(f, d, prefix):\n  items = sorted(d.items(), key=lambda a: a[1])\n  for k, v in items:\n   f.write(\"#define %s_%s %s\\n\" % (prefix, k.upper(), v))\n f = open(\"sre_constants.h\", \"w\")\n f.write(\"\"\"\\\n/*\n * Secret Labs' Regular Expression Engine\n *\n * regular expression matching engine\n *\n * NOTE: This file is generated by sre_constants.py.  If you need\n * to change anything in here, edit sre_constants.py and run it.\n *\n * Copyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.\n *\n * See the _sre.c file for information on usage and redistribution.\n */\n\n\"\"\" )\n \n f.write(\"#define SRE_MAGIC %d\\n\" % MAGIC)\n \n dump(f, OPCODES, \"SRE_OP\")\n dump(f, ATCODES, \"SRE\")\n dump(f, CHCODES, \"SRE\")\n \n f.write(\"#define SRE_FLAG_TEMPLATE %d\\n\" % SRE_FLAG_TEMPLATE)\n f.write(\"#define SRE_FLAG_IGNORECASE %d\\n\" % SRE_FLAG_IGNORECASE)\n f.write(\"#define SRE_FLAG_LOCALE %d\\n\" % SRE_FLAG_LOCALE)\n f.write(\"#define SRE_FLAG_MULTILINE %d\\n\" % SRE_FLAG_MULTILINE)\n f.write(\"#define SRE_FLAG_DOTALL %d\\n\" % SRE_FLAG_DOTALL)\n f.write(\"#define SRE_FLAG_UNICODE %d\\n\" % SRE_FLAG_UNICODE)\n f.write(\"#define SRE_FLAG_VERBOSE %d\\n\" % SRE_FLAG_VERBOSE)\n \n f.write(\"#define SRE_INFO_PREFIX %d\\n\" % SRE_INFO_PREFIX)\n f.write(\"#define SRE_INFO_LITERAL %d\\n\" % SRE_INFO_LITERAL)\n f.write(\"#define SRE_INFO_CHARSET %d\\n\" % SRE_INFO_CHARSET)\n \n f.close()\n print(\"done\")\n"], "unittest.test.testmock.testpatch": [".py", "\n\n\n\nimport os\nimport sys\n\nimport unittest\nfrom unittest.test.testmock import support\nfrom unittest.test.testmock.support import SomeClass, is_instance\n\nfrom unittest.mock import (\nNonCallableMock, CallableMixin, patch, sentinel,\nMagicMock, Mock, NonCallableMagicMock, patch, _patch,\nDEFAULT, call, _get_target\n)\n\n\nbuiltin_string = 'builtins'\n\nPTModule = sys.modules[__name__]\nMODNAME = '%s.PTModule' % __name__\n\n\ndef _get_proxy(obj, get_only=True):\n class Proxy(object):\n  def __getattr__(self, name):\n   return getattr(obj, name)\n if not get_only:\n  def __setattr__(self, name, value):\n   setattr(obj, name, value)\n  def __delattr__(self, name):\n   delattr(obj, name)\n  Proxy.__setattr__ = __setattr__\n  Proxy.__delattr__ = __delattr__\n return Proxy()\n \n \n \nsomething = sentinel.Something\nsomething_else = sentinel.SomethingElse\n\n\nclass Foo(object):\n def __init__(self, a):\n  pass\n def f(self, a):\n  pass\n def g(self):\n  pass\n foo = 'bar'\n \n class Bar(object):\n  def a(self):\n   pass\n   \nfoo_name = '%s.Foo' % __name__\n\n\ndef function(a, b=Foo):\n pass\n \n \nclass Container(object):\n def __init__(self):\n  self.values = {}\n  \n def __getitem__(self, name):\n  return self.values[name]\n  \n def __setitem__(self, name, value):\n  self.values[name] = value\n  \n def __delitem__(self, name):\n  del self.values[name]\n  \n def __iter__(self):\n  return iter(self.values)\n  \n  \n  \nclass PatchTest(unittest.TestCase):\n\n def assertNotCallable(self, obj, magic=True):\n  MockClass = NonCallableMagicMock\n  if not magic:\n   MockClass = NonCallableMock\n   \n  self.assertRaises(TypeError, obj)\n  self.assertTrue(is_instance(obj, MockClass))\n  self.assertFalse(is_instance(obj, CallableMixin))\n  \n  \n def test_single_patchobject(self):\n  class Something(object):\n   attribute = sentinel.Original\n   \n  @patch.object(Something, 'attribute', sentinel.Patched)\n  def test():\n   self.assertEqual(Something.attribute, sentinel.Patched, \"unpatched\")\n   \n  test()\n  self.assertEqual(Something.attribute, sentinel.Original,\n  \"patch not restored\")\n  \n  \n def test_patchobject_with_none(self):\n  class Something(object):\n   attribute = sentinel.Original\n   \n  @patch.object(Something, 'attribute', None)\n  def test():\n   self.assertIsNone(Something.attribute, \"unpatched\")\n   \n  test()\n  self.assertEqual(Something.attribute, sentinel.Original,\n  \"patch not restored\")\n  \n  \n def test_multiple_patchobject(self):\n  class Something(object):\n   attribute = sentinel.Original\n   next_attribute = sentinel.Original2\n   \n  @patch.object(Something, 'attribute', sentinel.Patched)\n  @patch.object(Something, 'next_attribute', sentinel.Patched2)\n  def test():\n   self.assertEqual(Something.attribute, sentinel.Patched,\n   \"unpatched\")\n   self.assertEqual(Something.next_attribute, sentinel.Patched2,\n   \"unpatched\")\n   \n  test()\n  self.assertEqual(Something.attribute, sentinel.Original,\n  \"patch not restored\")\n  self.assertEqual(Something.next_attribute, sentinel.Original2,\n  \"patch not restored\")\n  \n  \n def test_object_lookup_is_quite_lazy(self):\n  global something\n  original = something\n  @patch('%s.something' % __name__, sentinel.Something2)\n  def test():\n   pass\n   \n  try:\n   something = sentinel.replacement_value\n   test()\n   self.assertEqual(something, sentinel.replacement_value)\n  finally:\n   something = original\n   \n   \n def test_patch(self):\n  @patch('%s.something' % __name__, sentinel.Something2)\n  def test():\n   self.assertEqual(PTModule.something, sentinel.Something2,\n   \"unpatched\")\n   \n  test()\n  self.assertEqual(PTModule.something, sentinel.Something,\n  \"patch not restored\")\n  \n  @patch('%s.something' % __name__, sentinel.Something2)\n  @patch('%s.something_else' % __name__, sentinel.SomethingElse)\n  def test():\n   self.assertEqual(PTModule.something, sentinel.Something2,\n   \"unpatched\")\n   self.assertEqual(PTModule.something_else, sentinel.SomethingElse,\n   \"unpatched\")\n   \n  self.assertEqual(PTModule.something, sentinel.Something,\n  \"patch not restored\")\n  self.assertEqual(PTModule.something_else, sentinel.SomethingElse,\n  \"patch not restored\")\n  \n  \n  test()\n  \n  self.assertEqual(PTModule.something, sentinel.Something,\n  \"patch not restored\")\n  self.assertEqual(PTModule.something_else, sentinel.SomethingElse,\n  \"patch not restored\")\n  \n  mock = Mock()\n  mock.return_value = sentinel.Handle\n  @patch('%s.open' % builtin_string, mock)\n  def test():\n   self.assertEqual(open('filename', 'r'), sentinel.Handle,\n   \"open not patched\")\n  test()\n  test()\n  \n  self.assertNotEqual(open, mock, \"patch not restored\")\n  \n  \n def test_patch_class_attribute(self):\n  @patch('%s.SomeClass.class_attribute' % __name__,\n  sentinel.ClassAttribute)\n  def test():\n   self.assertEqual(PTModule.SomeClass.class_attribute,\n   sentinel.ClassAttribute, \"unpatched\")\n  test()\n  \n  self.assertIsNone(PTModule.SomeClass.class_attribute,\n  \"patch not restored\")\n  \n  \n def test_patchobject_with_default_mock(self):\n  class Test(object):\n   something = sentinel.Original\n   something2 = sentinel.Original2\n   \n  @patch.object(Test, 'something')\n  def test(mock):\n   self.assertEqual(mock, Test.something,\n   \"Mock not passed into test function\")\n   self.assertIsInstance(mock, MagicMock,\n   \"patch with two arguments did not create a mock\")\n   \n  test()\n  \n  @patch.object(Test, 'something')\n  @patch.object(Test, 'something2')\n  def test(this1, this2, mock1, mock2):\n   self.assertEqual(this1, sentinel.this1,\n   \"Patched function didn't receive initial argument\")\n   self.assertEqual(this2, sentinel.this2,\n   \"Patched function didn't receive second argument\")\n   self.assertEqual(mock1, Test.something2,\n   \"Mock not passed into test function\")\n   self.assertEqual(mock2, Test.something,\n   \"Second Mock not passed into test function\")\n   self.assertIsInstance(mock2, MagicMock,\n   \"patch with two arguments did not create a mock\")\n   self.assertIsInstance(mock2, MagicMock,\n   \"patch with two arguments did not create a mock\")\n   \n   \n   self.assertNotEqual(outerMock1, mock1, \"unexpected value for mock1\")\n   self.assertNotEqual(outerMock2, mock2, \"unexpected value for mock1\")\n   return mock1, mock2\n   \n  outerMock1 = outerMock2 = None\n  outerMock1, outerMock2 = test(sentinel.this1, sentinel.this2)\n  \n  \n  test(sentinel.this1, sentinel.this2)\n  \n  \n def test_patch_with_spec(self):\n  @patch('%s.SomeClass' % __name__, spec=SomeClass)\n  def test(MockSomeClass):\n   self.assertEqual(SomeClass, MockSomeClass)\n   self.assertTrue(is_instance(SomeClass.wibble, MagicMock))\n   self.assertRaises(AttributeError, lambda: SomeClass.not_wibble)\n   \n  test()\n  \n  \n def test_patchobject_with_spec(self):\n  @patch.object(SomeClass, 'class_attribute', spec=SomeClass)\n  def test(MockAttribute):\n   self.assertEqual(SomeClass.class_attribute, MockAttribute)\n   self.assertTrue(is_instance(SomeClass.class_attribute.wibble,\n   MagicMock))\n   self.assertRaises(AttributeError,\n   lambda: SomeClass.class_attribute.not_wibble)\n   \n  test()\n  \n  \n def test_patch_with_spec_as_list(self):\n  @patch('%s.SomeClass' % __name__, spec=['wibble'])\n  def test(MockSomeClass):\n   self.assertEqual(SomeClass, MockSomeClass)\n   self.assertTrue(is_instance(SomeClass.wibble, MagicMock))\n   self.assertRaises(AttributeError, lambda: SomeClass.not_wibble)\n   \n  test()\n  \n  \n def test_patchobject_with_spec_as_list(self):\n  @patch.object(SomeClass, 'class_attribute', spec=['wibble'])\n  def test(MockAttribute):\n   self.assertEqual(SomeClass.class_attribute, MockAttribute)\n   self.assertTrue(is_instance(SomeClass.class_attribute.wibble,\n   MagicMock))\n   self.assertRaises(AttributeError,\n   lambda: SomeClass.class_attribute.not_wibble)\n   \n  test()\n  \n  \n def test_nested_patch_with_spec_as_list(self):\n \n  @patch('%s.open' % builtin_string)\n  @patch('%s.SomeClass' % __name__, spec=['wibble'])\n  def test(MockSomeClass, MockOpen):\n   self.assertEqual(SomeClass, MockSomeClass)\n   self.assertTrue(is_instance(SomeClass.wibble, MagicMock))\n   self.assertRaises(AttributeError, lambda: SomeClass.not_wibble)\n  test()\n  \n  \n def test_patch_with_spec_as_boolean(self):\n  @patch('%s.SomeClass' % __name__, spec=True)\n  def test(MockSomeClass):\n   self.assertEqual(SomeClass, MockSomeClass)\n   \n   MockSomeClass.wibble\n   \n   self.assertRaises(AttributeError, lambda: MockSomeClass.not_wibble)\n   \n  test()\n  \n  \n def test_patch_object_with_spec_as_boolean(self):\n  @patch.object(PTModule, 'SomeClass', spec=True)\n  def test(MockSomeClass):\n   self.assertEqual(SomeClass, MockSomeClass)\n   \n   MockSomeClass.wibble\n   \n   self.assertRaises(AttributeError, lambda: MockSomeClass.not_wibble)\n   \n  test()\n  \n  \n def test_patch_class_acts_with_spec_is_inherited(self):\n  @patch('%s.SomeClass' % __name__, spec=True)\n  def test(MockSomeClass):\n   self.assertTrue(is_instance(MockSomeClass, MagicMock))\n   instance = MockSomeClass()\n   self.assertNotCallable(instance)\n   \n   instance.wibble\n   \n   self.assertRaises(AttributeError, lambda: instance.not_wibble)\n   \n  test()\n  \n  \n def test_patch_with_create_mocks_non_existent_attributes(self):\n  @patch('%s.frooble' % builtin_string, sentinel.Frooble, create=True)\n  def test():\n   self.assertEqual(frooble, sentinel.Frooble)\n   \n  test()\n  self.assertRaises(NameError, lambda: frooble)\n  \n  \n def test_patchobject_with_create_mocks_non_existent_attributes(self):\n  @patch.object(SomeClass, 'frooble', sentinel.Frooble, create=True)\n  def test():\n   self.assertEqual(SomeClass.frooble, sentinel.Frooble)\n   \n  test()\n  self.assertFalse(hasattr(SomeClass, 'frooble'))\n  \n  \n def test_patch_wont_create_by_default(self):\n  try:\n   @patch('%s.frooble' % builtin_string, sentinel.Frooble)\n   def test():\n    self.assertEqual(frooble, sentinel.Frooble)\n    \n   test()\n  except AttributeError:\n   pass\n  else:\n   self.fail('Patching non existent attributes should fail')\n   \n  self.assertRaises(NameError, lambda: frooble)\n  \n  \n def test_patchobject_wont_create_by_default(self):\n  try:\n   @patch.object(SomeClass, 'frooble', sentinel.Frooble)\n   def test():\n    self.fail('Patching non existent attributes should fail')\n    \n   test()\n  except AttributeError:\n   pass\n  else:\n   self.fail('Patching non existent attributes should fail')\n  self.assertFalse(hasattr(SomeClass, 'frooble'))\n  \n  \n def test_patch_with_static_methods(self):\n  class Foo(object):\n   @staticmethod\n   def woot():\n    return sentinel.Static\n    \n  @patch.object(Foo, 'woot', staticmethod(lambda: sentinel.Patched))\n  def anonymous():\n   self.assertEqual(Foo.woot(), sentinel.Patched)\n  anonymous()\n  \n  self.assertEqual(Foo.woot(), sentinel.Static)\n  \n  \n def test_patch_local(self):\n  foo = sentinel.Foo\n  @patch.object(sentinel, 'Foo', 'Foo')\n  def anonymous():\n   self.assertEqual(sentinel.Foo, 'Foo')\n  anonymous()\n  \n  self.assertEqual(sentinel.Foo, foo)\n  \n  \n def test_patch_slots(self):\n  class Foo(object):\n   __slots__ = ('Foo',)\n   \n  foo = Foo()\n  foo.Foo = sentinel.Foo\n  \n  @patch.object(foo, 'Foo', 'Foo')\n  def anonymous():\n   self.assertEqual(foo.Foo, 'Foo')\n  anonymous()\n  \n  self.assertEqual(foo.Foo, sentinel.Foo)\n  \n  \n def test_patchobject_class_decorator(self):\n  class Something(object):\n   attribute = sentinel.Original\n   \n  class Foo(object):\n   def test_method(other_self):\n    self.assertEqual(Something.attribute, sentinel.Patched,\n    \"unpatched\")\n   def not_test_method(other_self):\n    self.assertEqual(Something.attribute, sentinel.Original,\n    \"non-test method patched\")\n    \n  Foo = patch.object(Something, 'attribute', sentinel.Patched)(Foo)\n  \n  f = Foo()\n  f.test_method()\n  f.not_test_method()\n  \n  self.assertEqual(Something.attribute, sentinel.Original,\n  \"patch not restored\")\n  \n  \n def test_patch_class_decorator(self):\n  class Something(object):\n   attribute = sentinel.Original\n   \n  class Foo(object):\n   def test_method(other_self, mock_something):\n    self.assertEqual(PTModule.something, mock_something,\n    \"unpatched\")\n   def not_test_method(other_self):\n    self.assertEqual(PTModule.something, sentinel.Something,\n    \"non-test method patched\")\n  Foo = patch('%s.something' % __name__)(Foo)\n  \n  f = Foo()\n  f.test_method()\n  f.not_test_method()\n  \n  self.assertEqual(Something.attribute, sentinel.Original,\n  \"patch not restored\")\n  self.assertEqual(PTModule.something, sentinel.Something,\n  \"patch not restored\")\n  \n  \n def test_patchobject_twice(self):\n  class Something(object):\n   attribute = sentinel.Original\n   next_attribute = sentinel.Original2\n   \n  @patch.object(Something, 'attribute', sentinel.Patched)\n  @patch.object(Something, 'attribute', sentinel.Patched)\n  def test():\n   self.assertEqual(Something.attribute, sentinel.Patched, \"unpatched\")\n   \n  test()\n  \n  self.assertEqual(Something.attribute, sentinel.Original,\n  \"patch not restored\")\n  \n  \n def test_patch_dict(self):\n  foo = {'initial': object(), 'other': 'something'}\n  original = foo.copy()\n  \n  @patch.dict(foo)\n  def test():\n   foo['a'] = 3\n   del foo['initial']\n   foo['other'] = 'something else'\n   \n  test()\n  \n  self.assertEqual(foo, original)\n  \n  @patch.dict(foo, {'a': 'b'})\n  def test():\n   self.assertEqual(len(foo), 3)\n   self.assertEqual(foo['a'], 'b')\n   \n  test()\n  \n  self.assertEqual(foo, original)\n  \n  @patch.dict(foo, [('a', 'b')])\n  def test():\n   self.assertEqual(len(foo), 3)\n   self.assertEqual(foo['a'], 'b')\n   \n  test()\n  \n  self.assertEqual(foo, original)\n  \n  \n def test_patch_dict_with_container_object(self):\n  foo = Container()\n  foo['initial'] = object()\n  foo['other'] = 'something'\n  \n  original = foo.values.copy()\n  \n  @patch.dict(foo)\n  def test():\n   foo['a'] = 3\n   del foo['initial']\n   foo['other'] = 'something else'\n   \n  test()\n  \n  self.assertEqual(foo.values, original)\n  \n  @patch.dict(foo, {'a': 'b'})\n  def test():\n   self.assertEqual(len(foo.values), 3)\n   self.assertEqual(foo['a'], 'b')\n   \n  test()\n  \n  self.assertEqual(foo.values, original)\n  \n  \n def test_patch_dict_with_clear(self):\n  foo = {'initial': object(), 'other': 'something'}\n  original = foo.copy()\n  \n  @patch.dict(foo, clear=True)\n  def test():\n   self.assertEqual(foo, {})\n   foo['a'] = 3\n   foo['other'] = 'something else'\n   \n  test()\n  \n  self.assertEqual(foo, original)\n  \n  @patch.dict(foo, {'a': 'b'}, clear=True)\n  def test():\n   self.assertEqual(foo, {'a': 'b'})\n   \n  test()\n  \n  self.assertEqual(foo, original)\n  \n  @patch.dict(foo, [('a', 'b')], clear=True)\n  def test():\n   self.assertEqual(foo, {'a': 'b'})\n   \n  test()\n  \n  self.assertEqual(foo, original)\n  \n  \n def test_patch_dict_with_container_object_and_clear(self):\n  foo = Container()\n  foo['initial'] = object()\n  foo['other'] = 'something'\n  \n  original = foo.values.copy()\n  \n  @patch.dict(foo, clear=True)\n  def test():\n   self.assertEqual(foo.values, {})\n   foo['a'] = 3\n   foo['other'] = 'something else'\n   \n  test()\n  \n  self.assertEqual(foo.values, original)\n  \n  @patch.dict(foo, {'a': 'b'}, clear=True)\n  def test():\n   self.assertEqual(foo.values, {'a': 'b'})\n   \n  test()\n  \n  self.assertEqual(foo.values, original)\n  \n  \n def test_name_preserved(self):\n  foo = {}\n  \n  @patch('%s.SomeClass' % __name__, object())\n  @patch('%s.SomeClass' % __name__, object(), autospec=True)\n  @patch.object(SomeClass, object())\n  @patch.dict(foo)\n  def some_name():\n   pass\n   \n  self.assertEqual(some_name.__name__, 'some_name')\n  \n  \n def test_patch_with_exception(self):\n  foo = {}\n  \n  @patch.dict(foo, {'a': 'b'})\n  def test():\n   raise NameError('Konrad')\n  try:\n   test()\n  except NameError:\n   pass\n  else:\n   self.fail('NameError not raised by test')\n   \n  self.assertEqual(foo, {})\n  \n  \n def test_patch_dict_with_string(self):\n  @patch.dict('os.environ', {'konrad_delong': 'some value'})\n  def test():\n   self.assertIn('konrad_delong', os.environ)\n   \n  test()\n  \n  \n def test_patch_descriptor(self):\n \n \n  return\n  class Nothing(object):\n   foo = None\n   \n  class Something(object):\n   foo = {}\n   \n   @patch.object(Nothing, 'foo', 2)\n   @classmethod\n   def klass(cls):\n    self.assertIs(cls, Something)\n    \n   @patch.object(Nothing, 'foo', 2)\n   @staticmethod\n   def static(arg):\n    return arg\n    \n   @patch.dict(foo)\n   @classmethod\n   def klass_dict(cls):\n    self.assertIs(cls, Something)\n    \n   @patch.dict(foo)\n   @staticmethod\n   def static_dict(arg):\n    return arg\n    \n    \n  self.assertEqual(Something.static('f00'), 'f00')\n  Something.klass()\n  self.assertEqual(Something.static_dict('f00'), 'f00')\n  Something.klass_dict()\n  \n  something = Something()\n  self.assertEqual(something.static('f00'), 'f00')\n  something.klass()\n  self.assertEqual(something.static_dict('f00'), 'f00')\n  something.klass_dict()\n  \n  \n def test_patch_spec_set(self):\n  @patch('%s.SomeClass' % __name__, spec=SomeClass, spec_set=True)\n  def test(MockClass):\n   MockClass.z = 'foo'\n   \n  self.assertRaises(AttributeError, test)\n  \n  @patch.object(support, 'SomeClass', spec=SomeClass, spec_set=True)\n  def test(MockClass):\n   MockClass.z = 'foo'\n   \n  self.assertRaises(AttributeError, test)\n  @patch('%s.SomeClass' % __name__, spec_set=True)\n  def test(MockClass):\n   MockClass.z = 'foo'\n   \n  self.assertRaises(AttributeError, test)\n  \n  @patch.object(support, 'SomeClass', spec_set=True)\n  def test(MockClass):\n   MockClass.z = 'foo'\n   \n  self.assertRaises(AttributeError, test)\n  \n  \n def test_spec_set_inherit(self):\n  @patch('%s.SomeClass' % __name__, spec_set=True)\n  def test(MockClass):\n   instance = MockClass()\n   instance.z = 'foo'\n   \n  self.assertRaises(AttributeError, test)\n  \n  \n def test_patch_start_stop(self):\n  original = something\n  patcher = patch('%s.something' % __name__)\n  self.assertIs(something, original)\n  mock = patcher.start()\n  try:\n   self.assertIsNot(mock, original)\n   self.assertIs(something, mock)\n  finally:\n   patcher.stop()\n  self.assertIs(something, original)\n  \n  \n def test_stop_without_start(self):\n  patcher = patch(foo_name, 'bar', 3)\n  \n  \n  self.assertRaises(RuntimeError, patcher.stop)\n  \n  \n def test_patchobject_start_stop(self):\n  original = something\n  patcher = patch.object(PTModule, 'something', 'foo')\n  self.assertIs(something, original)\n  replaced = patcher.start()\n  try:\n   self.assertEqual(replaced, 'foo')\n   self.assertIs(something, replaced)\n  finally:\n   patcher.stop()\n  self.assertIs(something, original)\n  \n  \n def test_patch_dict_start_stop(self):\n  d = {'foo': 'bar'}\n  original = d.copy()\n  patcher = patch.dict(d, [('spam', 'eggs')], clear=True)\n  self.assertEqual(d, original)\n  \n  patcher.start()\n  try:\n   self.assertEqual(d, {'spam': 'eggs'})\n  finally:\n   patcher.stop()\n  self.assertEqual(d, original)\n  \n  \n def test_patch_dict_class_decorator(self):\n  this = self\n  d = {'spam': 'eggs'}\n  original = d.copy()\n  \n  class Test(object):\n   def test_first(self):\n    this.assertEqual(d, {'foo': 'bar'})\n   def test_second(self):\n    this.assertEqual(d, {'foo': 'bar'})\n    \n  Test = patch.dict(d, {'foo': 'bar'}, clear=True)(Test)\n  self.assertEqual(d, original)\n  \n  test = Test()\n  \n  test.test_first()\n  self.assertEqual(d, original)\n  \n  test.test_second()\n  self.assertEqual(d, original)\n  \n  test = Test()\n  \n  test.test_first()\n  self.assertEqual(d, original)\n  \n  test.test_second()\n  self.assertEqual(d, original)\n  \n  \n def test_get_only_proxy(self):\n  class Something(object):\n   foo = 'foo'\n  class SomethingElse:\n   foo = 'foo'\n   \n  for thing in Something, SomethingElse, Something(), SomethingElse:\n   proxy = _get_proxy(thing)\n   \n   @patch.object(proxy, 'foo', 'bar')\n   def test():\n    self.assertEqual(proxy.foo, 'bar')\n   test()\n   self.assertEqual(proxy.foo, 'foo')\n   self.assertEqual(thing.foo, 'foo')\n   self.assertNotIn('foo', proxy.__dict__)\n   \n   \n def test_get_set_delete_proxy(self):\n  class Something(object):\n   foo = 'foo'\n  class SomethingElse:\n   foo = 'foo'\n   \n  for thing in Something, SomethingElse, Something(), SomethingElse:\n   proxy = _get_proxy(Something, get_only=False)\n   \n   @patch.object(proxy, 'foo', 'bar')\n   def test():\n    self.assertEqual(proxy.foo, 'bar')\n   test()\n   self.assertEqual(proxy.foo, 'foo')\n   self.assertEqual(thing.foo, 'foo')\n   self.assertNotIn('foo', proxy.__dict__)\n   \n   \n def test_patch_keyword_args(self):\n  kwargs = {'side_effect': KeyError, 'foo.bar.return_value': 33,\n  'foo': MagicMock()}\n  \n  patcher = patch(foo_name, **kwargs)\n  mock = patcher.start()\n  patcher.stop()\n  \n  self.assertRaises(KeyError, mock)\n  self.assertEqual(mock.foo.bar(), 33)\n  self.assertIsInstance(mock.foo, MagicMock)\n  \n  \n def test_patch_object_keyword_args(self):\n  kwargs = {'side_effect': KeyError, 'foo.bar.return_value': 33,\n  'foo': MagicMock()}\n  \n  patcher = patch.object(Foo, 'f', **kwargs)\n  mock = patcher.start()\n  patcher.stop()\n  \n  self.assertRaises(KeyError, mock)\n  self.assertEqual(mock.foo.bar(), 33)\n  self.assertIsInstance(mock.foo, MagicMock)\n  \n  \n def test_patch_dict_keyword_args(self):\n  original = {'foo': 'bar'}\n  copy = original.copy()\n  \n  patcher = patch.dict(original, foo=3, bar=4, baz=5)\n  patcher.start()\n  \n  try:\n   self.assertEqual(original, dict(foo=3, bar=4, baz=5))\n  finally:\n   patcher.stop()\n   \n  self.assertEqual(original, copy)\n  \n  \n def test_autospec(self):\n  class Boo(object):\n   def __init__(self, a):\n    pass\n   def f(self, a):\n    pass\n   def g(self):\n    pass\n   foo = 'bar'\n   \n   class Bar(object):\n    def a(self):\n     pass\n     \n  def _test(mock):\n   mock(1)\n   mock.assert_called_with(1)\n   self.assertRaises(TypeError, mock)\n   \n  def _test2(mock):\n   mock.f(1)\n   mock.f.assert_called_with(1)\n   self.assertRaises(TypeError, mock.f)\n   \n   mock.g()\n   mock.g.assert_called_with()\n   self.assertRaises(TypeError, mock.g, 1)\n   \n   self.assertRaises(AttributeError, getattr, mock, 'h')\n   \n   mock.foo.lower()\n   mock.foo.lower.assert_called_with()\n   self.assertRaises(AttributeError, getattr, mock.foo, 'bar')\n   \n   mock.Bar()\n   mock.Bar.assert_called_with()\n   \n   mock.Bar.a()\n   mock.Bar.a.assert_called_with()\n   self.assertRaises(TypeError, mock.Bar.a, 1)\n   \n   mock.Bar().a()\n   mock.Bar().a.assert_called_with()\n   self.assertRaises(TypeError, mock.Bar().a, 1)\n   \n   self.assertRaises(AttributeError, getattr, mock.Bar, 'b')\n   self.assertRaises(AttributeError, getattr, mock.Bar(), 'b')\n   \n  def function(mock):\n   _test(mock)\n   _test2(mock)\n   _test2(mock(1))\n   self.assertIs(mock, Foo)\n   return mock\n   \n  test = patch(foo_name, autospec=True)(function)\n  \n  mock = test()\n  self.assertIsNot(Foo, mock)\n  \n  test()\n  \n  module = sys.modules[__name__]\n  test = patch.object(module, 'Foo', autospec=True)(function)\n  \n  mock = test()\n  self.assertIsNot(Foo, mock)\n  \n  test()\n  \n  \n def test_autospec_function(self):\n  @patch('%s.function' % __name__, autospec=True)\n  def test(mock):\n   function(1)\n   function.assert_called_with(1)\n   function(2, 3)\n   function.assert_called_with(2, 3)\n   \n   self.assertRaises(TypeError, function)\n   self.assertRaises(AttributeError, getattr, function, 'foo')\n   \n  test()\n  \n  \n def test_autospec_keywords(self):\n  @patch('%s.function' % __name__, autospec=True,\n  return_value=3)\n  def test(mock_function):\n  \n   return function(1, 2)\n   \n  result = test()\n  self.assertEqual(result, 3)\n  \n  \n def test_autospec_with_new(self):\n  patcher = patch('%s.function' % __name__, new=3, autospec=True)\n  self.assertRaises(TypeError, patcher.start)\n  \n  module = sys.modules[__name__]\n  patcher = patch.object(module, 'function', new=3, autospec=True)\n  self.assertRaises(TypeError, patcher.start)\n  \n  \n def test_autospec_with_object(self):\n  class Bar(Foo):\n   extra = []\n   \n  patcher = patch(foo_name, autospec=Bar)\n  mock = patcher.start()\n  try:\n   self.assertIsInstance(mock, Bar)\n   self.assertIsInstance(mock.extra, list)\n  finally:\n   patcher.stop()\n   \n   \n def test_autospec_inherits(self):\n  FooClass = Foo\n  patcher = patch(foo_name, autospec=True)\n  mock = patcher.start()\n  try:\n   self.assertIsInstance(mock, FooClass)\n   self.assertIsInstance(mock(3), FooClass)\n  finally:\n   patcher.stop()\n   \n   \n def test_autospec_name(self):\n  patcher = patch(foo_name, autospec=True)\n  mock = patcher.start()\n  \n  try:\n   self.assertIn(\" name='Foo'\", repr(mock))\n   self.assertIn(\" name='Foo.f'\", repr(mock.f))\n   self.assertIn(\" name='Foo()'\", repr(mock(None)))\n   self.assertIn(\" name='Foo().f'\", repr(mock(None).f))\n  finally:\n   patcher.stop()\n   \n   \n def test_tracebacks(self):\n  @patch.object(Foo, 'f', object())\n  def test():\n   raise AssertionError\n  try:\n   test()\n  except:\n   err = sys.exc_info()\n   \n  result = unittest.TextTestResult(None, None, 0)\n  traceback = result._exc_info_to_string(err, self)\n  self.assertIn('raise AssertionError', traceback)\n  \n  \n def test_new_callable_patch(self):\n  patcher = patch(foo_name, new_callable=NonCallableMagicMock)\n  \n  m1 = patcher.start()\n  patcher.stop()\n  m2 = patcher.start()\n  patcher.stop()\n  \n  self.assertIsNot(m1, m2)\n  for mock in m1, m2:\n   self.assertNotCallable(m1)\n   \n   \n def test_new_callable_patch_object(self):\n  patcher = patch.object(Foo, 'f', new_callable=NonCallableMagicMock)\n  \n  m1 = patcher.start()\n  patcher.stop()\n  m2 = patcher.start()\n  patcher.stop()\n  \n  self.assertIsNot(m1, m2)\n  for mock in m1, m2:\n   self.assertNotCallable(m1)\n   \n   \n def test_new_callable_keyword_arguments(self):\n  class Bar(object):\n   kwargs = None\n   def __init__(self, **kwargs):\n    Bar.kwargs = kwargs\n    \n  patcher = patch(foo_name, new_callable=Bar, arg1=1, arg2=2)\n  m = patcher.start()\n  try:\n   self.assertIs(type(m), Bar)\n   self.assertEqual(Bar.kwargs, dict(arg1=1, arg2=2))\n  finally:\n   patcher.stop()\n   \n   \n def test_new_callable_spec(self):\n  class Bar(object):\n   kwargs = None\n   def __init__(self, **kwargs):\n    Bar.kwargs = kwargs\n    \n  patcher = patch(foo_name, new_callable=Bar, spec=Bar)\n  patcher.start()\n  try:\n   self.assertEqual(Bar.kwargs, dict(spec=Bar))\n  finally:\n   patcher.stop()\n   \n  patcher = patch(foo_name, new_callable=Bar, spec_set=Bar)\n  patcher.start()\n  try:\n   self.assertEqual(Bar.kwargs, dict(spec_set=Bar))\n  finally:\n   patcher.stop()\n   \n   \n def test_new_callable_create(self):\n  non_existent_attr = '%s.weeeee' % foo_name\n  p = patch(non_existent_attr, new_callable=NonCallableMock)\n  self.assertRaises(AttributeError, p.start)\n  \n  p = patch(non_existent_attr, new_callable=NonCallableMock,\n  create=True)\n  m = p.start()\n  try:\n   self.assertNotCallable(m, magic=False)\n  finally:\n   p.stop()\n   \n   \n def test_new_callable_incompatible_with_new(self):\n  self.assertRaises(\n  ValueError, patch, foo_name, new=object(), new_callable=MagicMock\n  )\n  self.assertRaises(\n  ValueError, patch.object, Foo, 'f', new=object(),\n  new_callable=MagicMock\n  )\n  \n  \n def test_new_callable_incompatible_with_autospec(self):\n  self.assertRaises(\n  ValueError, patch, foo_name, new_callable=MagicMock,\n  autospec=True\n  )\n  self.assertRaises(\n  ValueError, patch.object, Foo, 'f', new_callable=MagicMock,\n  autospec=True\n  )\n  \n  \n def test_new_callable_inherit_for_mocks(self):\n  class MockSub(Mock):\n   pass\n   \n  MockClasses = (\n  NonCallableMock, NonCallableMagicMock, MagicMock, Mock, MockSub\n  )\n  for Klass in MockClasses:\n   for arg in 'spec', 'spec_set':\n    kwargs = {arg: True}\n    p = patch(foo_name, new_callable=Klass, **kwargs)\n    m = p.start()\n    try:\n     instance = m.return_value\n     self.assertRaises(AttributeError, getattr, instance, 'x')\n    finally:\n     p.stop()\n     \n     \n def test_new_callable_inherit_non_mock(self):\n  class NotAMock(object):\n   def __init__(self, spec):\n    self.spec = spec\n    \n  p = patch(foo_name, new_callable=NotAMock, spec=True)\n  m = p.start()\n  try:\n   self.assertTrue(is_instance(m, NotAMock))\n   self.assertRaises(AttributeError, getattr, m, 'return_value')\n  finally:\n   p.stop()\n   \n  self.assertEqual(m.spec, Foo)\n  \n  \n def test_new_callable_class_decorating(self):\n  test = self\n  original = Foo\n  class SomeTest(object):\n  \n   def _test(self, mock_foo):\n    test.assertIsNot(Foo, original)\n    test.assertIs(Foo, mock_foo)\n    test.assertIsInstance(Foo, SomeClass)\n    \n   def test_two(self, mock_foo):\n    self._test(mock_foo)\n   def test_one(self, mock_foo):\n    self._test(mock_foo)\n    \n  SomeTest = patch(foo_name, new_callable=SomeClass)(SomeTest)\n  SomeTest().test_one()\n  SomeTest().test_two()\n  self.assertIs(Foo, original)\n  \n  \n def test_patch_multiple(self):\n  original_foo = Foo\n  original_f = Foo.f\n  original_g = Foo.g\n  \n  patcher1 = patch.multiple(foo_name, f=1, g=2)\n  patcher2 = patch.multiple(Foo, f=1, g=2)\n  \n  for patcher in patcher1, patcher2:\n   patcher.start()\n   try:\n    self.assertIs(Foo, original_foo)\n    self.assertEqual(Foo.f, 1)\n    self.assertEqual(Foo.g, 2)\n   finally:\n    patcher.stop()\n    \n   self.assertIs(Foo, original_foo)\n   self.assertEqual(Foo.f, original_f)\n   self.assertEqual(Foo.g, original_g)\n   \n   \n  @patch.multiple(foo_name, f=3, g=4)\n  def test():\n   self.assertIs(Foo, original_foo)\n   self.assertEqual(Foo.f, 3)\n   self.assertEqual(Foo.g, 4)\n   \n  test()\n  \n  \n def test_patch_multiple_no_kwargs(self):\n  self.assertRaises(ValueError, patch.multiple, foo_name)\n  self.assertRaises(ValueError, patch.multiple, Foo)\n  \n  \n def test_patch_multiple_create_mocks(self):\n  original_foo = Foo\n  original_f = Foo.f\n  original_g = Foo.g\n  \n  @patch.multiple(foo_name, f=DEFAULT, g=3, foo=DEFAULT)\n  def test(f, foo):\n   self.assertIs(Foo, original_foo)\n   self.assertIs(Foo.f, f)\n   self.assertEqual(Foo.g, 3)\n   self.assertIs(Foo.foo, foo)\n   self.assertTrue(is_instance(f, MagicMock))\n   self.assertTrue(is_instance(foo, MagicMock))\n   \n  test()\n  self.assertEqual(Foo.f, original_f)\n  self.assertEqual(Foo.g, original_g)\n  \n  \n def test_patch_multiple_create_mocks_different_order(self):\n \n  original_f = Foo.f\n  original_g = Foo.g\n  \n  patcher = patch.object(Foo, 'f', 3)\n  patcher.attribute_name = 'f'\n  \n  other = patch.object(Foo, 'g', DEFAULT)\n  other.attribute_name = 'g'\n  patcher.additional_patchers = [other]\n  \n  @patcher\n  def test(g):\n   self.assertIs(Foo.g, g)\n   self.assertEqual(Foo.f, 3)\n   \n  test()\n  self.assertEqual(Foo.f, original_f)\n  self.assertEqual(Foo.g, original_g)\n  \n  \n def test_patch_multiple_stacked_decorators(self):\n  original_foo = Foo\n  original_f = Foo.f\n  original_g = Foo.g\n  \n  @patch.multiple(foo_name, f=DEFAULT)\n  @patch.multiple(foo_name, foo=DEFAULT)\n  @patch(foo_name + '.g')\n  def test1(g, **kwargs):\n   _test(g, **kwargs)\n   \n  @patch.multiple(foo_name, f=DEFAULT)\n  @patch(foo_name + '.g')\n  @patch.multiple(foo_name, foo=DEFAULT)\n  def test2(g, **kwargs):\n   _test(g, **kwargs)\n   \n  @patch(foo_name + '.g')\n  @patch.multiple(foo_name, f=DEFAULT)\n  @patch.multiple(foo_name, foo=DEFAULT)\n  def test3(g, **kwargs):\n   _test(g, **kwargs)\n   \n  def _test(g, **kwargs):\n   f = kwargs.pop('f')\n   foo = kwargs.pop('foo')\n   self.assertFalse(kwargs)\n   \n   self.assertIs(Foo, original_foo)\n   self.assertIs(Foo.f, f)\n   self.assertIs(Foo.g, g)\n   self.assertIs(Foo.foo, foo)\n   self.assertTrue(is_instance(f, MagicMock))\n   self.assertTrue(is_instance(g, MagicMock))\n   self.assertTrue(is_instance(foo, MagicMock))\n   \n  test1()\n  test2()\n  test3()\n  self.assertEqual(Foo.f, original_f)\n  self.assertEqual(Foo.g, original_g)\n  \n  \n def test_patch_multiple_create_mocks_patcher(self):\n  original_foo = Foo\n  original_f = Foo.f\n  original_g = Foo.g\n  \n  patcher = patch.multiple(foo_name, f=DEFAULT, g=3, foo=DEFAULT)\n  \n  result = patcher.start()\n  try:\n   f = result['f']\n   foo = result['foo']\n   self.assertEqual(set(result), set(['f', 'foo']))\n   \n   self.assertIs(Foo, original_foo)\n   self.assertIs(Foo.f, f)\n   self.assertIs(Foo.foo, foo)\n   self.assertTrue(is_instance(f, MagicMock))\n   self.assertTrue(is_instance(foo, MagicMock))\n  finally:\n   patcher.stop()\n   \n  self.assertEqual(Foo.f, original_f)\n  self.assertEqual(Foo.g, original_g)\n  \n  \n def test_patch_multiple_decorating_class(self):\n  test = self\n  original_foo = Foo\n  original_f = Foo.f\n  original_g = Foo.g\n  \n  class SomeTest(object):\n  \n   def _test(self, f, foo):\n    test.assertIs(Foo, original_foo)\n    test.assertIs(Foo.f, f)\n    test.assertEqual(Foo.g, 3)\n    test.assertIs(Foo.foo, foo)\n    test.assertTrue(is_instance(f, MagicMock))\n    test.assertTrue(is_instance(foo, MagicMock))\n    \n   def test_two(self, f, foo):\n    self._test(f, foo)\n   def test_one(self, f, foo):\n    self._test(f, foo)\n    \n  SomeTest = patch.multiple(\n  foo_name, f=DEFAULT, g=3, foo=DEFAULT\n  )(SomeTest)\n  \n  thing = SomeTest()\n  thing.test_one()\n  thing.test_two()\n  \n  self.assertEqual(Foo.f, original_f)\n  self.assertEqual(Foo.g, original_g)\n  \n  \n def test_patch_multiple_create(self):\n  patcher = patch.multiple(Foo, blam='blam')\n  self.assertRaises(AttributeError, patcher.start)\n  \n  patcher = patch.multiple(Foo, blam='blam', create=True)\n  patcher.start()\n  try:\n   self.assertEqual(Foo.blam, 'blam')\n  finally:\n   patcher.stop()\n   \n  self.assertFalse(hasattr(Foo, 'blam'))\n  \n  \n def test_patch_multiple_spec_set(self):\n \n \n  patcher = patch.multiple(Foo, foo=DEFAULT, spec_set=['a', 'b'])\n  result = patcher.start()\n  try:\n   self.assertEqual(Foo.foo, result['foo'])\n   Foo.foo.a(1)\n   Foo.foo.b(2)\n   Foo.foo.a.assert_called_with(1)\n   Foo.foo.b.assert_called_with(2)\n   self.assertRaises(AttributeError, setattr, Foo.foo, 'c', None)\n  finally:\n   patcher.stop()\n   \n   \n def test_patch_multiple_new_callable(self):\n  class Thing(object):\n   pass\n   \n  patcher = patch.multiple(\n  Foo, f=DEFAULT, g=DEFAULT, new_callable=Thing\n  )\n  result = patcher.start()\n  try:\n   self.assertIs(Foo.f, result['f'])\n   self.assertIs(Foo.g, result['g'])\n   self.assertIsInstance(Foo.f, Thing)\n   self.assertIsInstance(Foo.g, Thing)\n   self.assertIsNot(Foo.f, Foo.g)\n  finally:\n   patcher.stop()\n   \n   \n def test_nested_patch_failure(self):\n  original_f = Foo.f\n  original_g = Foo.g\n  \n  @patch.object(Foo, 'g', 1)\n  @patch.object(Foo, 'missing', 1)\n  @patch.object(Foo, 'f', 1)\n  def thing1():\n   pass\n   \n  @patch.object(Foo, 'missing', 1)\n  @patch.object(Foo, 'g', 1)\n  @patch.object(Foo, 'f', 1)\n  def thing2():\n   pass\n   \n  @patch.object(Foo, 'g', 1)\n  @patch.object(Foo, 'f', 1)\n  @patch.object(Foo, 'missing', 1)\n  def thing3():\n   pass\n   \n  for func in thing1, thing2, thing3:\n   self.assertRaises(AttributeError, func)\n   self.assertEqual(Foo.f, original_f)\n   self.assertEqual(Foo.g, original_g)\n   \n   \n def test_new_callable_failure(self):\n  original_f = Foo.f\n  original_g = Foo.g\n  original_foo = Foo.foo\n  \n  def crasher():\n   raise NameError('crasher')\n   \n  @patch.object(Foo, 'g', 1)\n  @patch.object(Foo, 'foo', new_callable=crasher)\n  @patch.object(Foo, 'f', 1)\n  def thing1():\n   pass\n   \n  @patch.object(Foo, 'foo', new_callable=crasher)\n  @patch.object(Foo, 'g', 1)\n  @patch.object(Foo, 'f', 1)\n  def thing2():\n   pass\n   \n  @patch.object(Foo, 'g', 1)\n  @patch.object(Foo, 'f', 1)\n  @patch.object(Foo, 'foo', new_callable=crasher)\n  def thing3():\n   pass\n   \n  for func in thing1, thing2, thing3:\n   self.assertRaises(NameError, func)\n   self.assertEqual(Foo.f, original_f)\n   self.assertEqual(Foo.g, original_g)\n   self.assertEqual(Foo.foo, original_foo)\n   \n   \n def test_patch_multiple_failure(self):\n  original_f = Foo.f\n  original_g = Foo.g\n  \n  patcher = patch.object(Foo, 'f', 1)\n  patcher.attribute_name = 'f'\n  \n  good = patch.object(Foo, 'g', 1)\n  good.attribute_name = 'g'\n  \n  bad = patch.object(Foo, 'missing', 1)\n  bad.attribute_name = 'missing'\n  \n  for additionals in [good, bad], [bad, good]:\n   patcher.additional_patchers = additionals\n   \n   @patcher\n   def func():\n    pass\n    \n   self.assertRaises(AttributeError, func)\n   self.assertEqual(Foo.f, original_f)\n   self.assertEqual(Foo.g, original_g)\n   \n   \n def test_patch_multiple_new_callable_failure(self):\n  original_f = Foo.f\n  original_g = Foo.g\n  original_foo = Foo.foo\n  \n  def crasher():\n   raise NameError('crasher')\n   \n  patcher = patch.object(Foo, 'f', 1)\n  patcher.attribute_name = 'f'\n  \n  good = patch.object(Foo, 'g', 1)\n  good.attribute_name = 'g'\n  \n  bad = patch.object(Foo, 'foo', new_callable=crasher)\n  bad.attribute_name = 'foo'\n  \n  for additionals in [good, bad], [bad, good]:\n   patcher.additional_patchers = additionals\n   \n   @patcher\n   def func():\n    pass\n    \n   self.assertRaises(NameError, func)\n   self.assertEqual(Foo.f, original_f)\n   self.assertEqual(Foo.g, original_g)\n   self.assertEqual(Foo.foo, original_foo)\n   \n   \n def test_patch_multiple_string_subclasses(self):\n  Foo = type('Foo', (str,), {'fish': 'tasty'})\n  foo = Foo()\n  @patch.multiple(foo, fish='nearly gone')\n  def test():\n   self.assertEqual(foo.fish, 'nearly gone')\n   \n  test()\n  self.assertEqual(foo.fish, 'tasty')\n  \n  \n @patch('unittest.mock.patch.TEST_PREFIX', 'foo')\n def test_patch_test_prefix(self):\n  class Foo(object):\n   thing = 'original'\n   \n   def foo_one(self):\n    return self.thing\n   def foo_two(self):\n    return self.thing\n   def test_one(self):\n    return self.thing\n   def test_two(self):\n    return self.thing\n    \n  Foo = patch.object(Foo, 'thing', 'changed')(Foo)\n  \n  foo = Foo()\n  self.assertEqual(foo.foo_one(), 'changed')\n  self.assertEqual(foo.foo_two(), 'changed')\n  self.assertEqual(foo.test_one(), 'original')\n  self.assertEqual(foo.test_two(), 'original')\n  \n  \n @patch('unittest.mock.patch.TEST_PREFIX', 'bar')\n def test_patch_dict_test_prefix(self):\n  class Foo(object):\n   def bar_one(self):\n    return dict(the_dict)\n   def bar_two(self):\n    return dict(the_dict)\n   def test_one(self):\n    return dict(the_dict)\n   def test_two(self):\n    return dict(the_dict)\n    \n  the_dict = {'key': 'original'}\n  Foo = patch.dict(the_dict, key='changed')(Foo)\n  \n  foo =Foo()\n  self.assertEqual(foo.bar_one(), {'key': 'changed'})\n  self.assertEqual(foo.bar_two(), {'key': 'changed'})\n  self.assertEqual(foo.test_one(), {'key': 'original'})\n  self.assertEqual(foo.test_two(), {'key': 'original'})\n  \n  \n def test_patch_with_spec_mock_repr(self):\n  for arg in ('spec', 'autospec', 'spec_set'):\n   p = patch('%s.SomeClass' % __name__, **{arg: True})\n   m = p.start()\n   try:\n    self.assertIn(\" name='SomeClass'\", repr(m))\n    self.assertIn(\" name='SomeClass.class_attribute'\",\n    repr(m.class_attribute))\n    self.assertIn(\" name='SomeClass()'\", repr(m()))\n    self.assertIn(\" name='SomeClass().class_attribute'\",\n    repr(m().class_attribute))\n   finally:\n    p.stop()\n    \n    \n def test_patch_nested_autospec_repr(self):\n  with patch('unittest.test.testmock.support', autospec=True) as m:\n   self.assertIn(\" name='support.SomeClass.wibble()'\",\n   repr(m.SomeClass.wibble()))\n   self.assertIn(\" name='support.SomeClass().wibble()'\",\n   repr(m.SomeClass().wibble()))\n   \n   \n   \n def test_mock_calls_with_patch(self):\n  for arg in ('spec', 'autospec', 'spec_set'):\n   p = patch('%s.SomeClass' % __name__, **{arg: True})\n   m = p.start()\n   try:\n    m.wibble()\n    \n    kalls = [call.wibble()]\n    self.assertEqual(m.mock_calls, kalls)\n    self.assertEqual(m.method_calls, kalls)\n    self.assertEqual(m.wibble.mock_calls, [call()])\n    \n    result = m()\n    kalls.append(call())\n    self.assertEqual(m.mock_calls, kalls)\n    \n    result.wibble()\n    kalls.append(call().wibble())\n    self.assertEqual(m.mock_calls, kalls)\n    \n    self.assertEqual(result.mock_calls, [call.wibble()])\n    self.assertEqual(result.wibble.mock_calls, [call()])\n    self.assertEqual(result.method_calls, [call.wibble()])\n   finally:\n    p.stop()\n    \n    \n def test_patch_imports_lazily(self):\n  sys.modules.pop('squizz', None)\n  \n  p1 = patch('squizz.squozz')\n  self.assertRaises(ImportError, p1.start)\n  \n  squizz = Mock()\n  squizz.squozz = 6\n  sys.modules['squizz'] = squizz\n  p1 = patch('squizz.squozz')\n  squizz.squozz = 3\n  p1.start()\n  p1.stop()\n  self.assertEqual(squizz.squozz, 3)\n  \n  \n def test_patch_propogrates_exc_on_exit(self):\n  class holder:\n   exc_info = None, None, None\n   \n  class custom_patch(_patch):\n   def __exit__(self, etype=None, val=None, tb=None):\n    _patch.__exit__(self, etype, val, tb)\n    holder.exc_info = etype, val, tb\n   stop = __exit__\n   \n  def with_custom_patch(target):\n   getter, attribute = _get_target(target)\n   return custom_patch(\n   getter, attribute, DEFAULT, None, False, None,\n   None, None, {}\n   )\n   \n  @with_custom_patch('squizz.squozz')\n  def test(mock):\n   raise RuntimeError\n   \n  self.assertRaises(RuntimeError, test)\n  self.assertIs(holder.exc_info[0], RuntimeError)\n  self.assertIsNotNone(holder.exc_info[1],\n  'exception value not propgated')\n  self.assertIsNotNone(holder.exc_info[2],\n  'exception traceback not propgated')\n  \n  \n def test_create_and_specs(self):\n  for kwarg in ('spec', 'spec_set', 'autospec'):\n   p = patch('%s.doesnotexist' % __name__, create=True,\n   **{kwarg: True})\n   self.assertRaises(TypeError, p.start)\n   self.assertRaises(NameError, lambda: doesnotexist)\n   \n   \n   p = patch(MODNAME, create=True, **{kwarg: True})\n   p.start()\n   p.stop()\n   \n   \n def test_multiple_specs(self):\n  original = PTModule\n  for kwarg in ('spec', 'spec_set'):\n   p = patch(MODNAME, autospec=0, **{kwarg: 0})\n   self.assertRaises(TypeError, p.start)\n   self.assertIs(PTModule, original)\n   \n  for kwarg in ('spec', 'autospec'):\n   p = patch(MODNAME, spec_set=0, **{kwarg: 0})\n   self.assertRaises(TypeError, p.start)\n   self.assertIs(PTModule, original)\n   \n  for kwarg in ('spec_set', 'autospec'):\n   p = patch(MODNAME, spec=0, **{kwarg: 0})\n   self.assertRaises(TypeError, p.start)\n   self.assertIs(PTModule, original)\n   \n   \n def test_specs_false_instead_of_none(self):\n  p = patch(MODNAME, spec=False, spec_set=False, autospec=False)\n  mock = p.start()\n  try:\n  \n   mock.does_not_exist\n   mock.does_not_exist = 3\n  finally:\n   p.stop()\n   \n   \n def test_falsey_spec(self):\n  for kwarg in ('spec', 'autospec', 'spec_set'):\n   p = patch(MODNAME, **{kwarg: 0})\n   m = p.start()\n   try:\n    self.assertRaises(AttributeError, getattr, m, 'doesnotexit')\n   finally:\n    p.stop()\n    \n    \n def test_spec_set_true(self):\n  for kwarg in ('spec', 'autospec'):\n   p = patch(MODNAME, spec_set=True, **{kwarg: True})\n   m = p.start()\n   try:\n    self.assertRaises(AttributeError, setattr, m,\n    'doesnotexist', 'something')\n    self.assertRaises(AttributeError, getattr, m, 'doesnotexist')\n   finally:\n    p.stop()\n    \n    \n def test_callable_spec_as_list(self):\n  spec = ('__call__',)\n  p = patch(MODNAME, spec=spec)\n  m = p.start()\n  try:\n   self.assertTrue(callable(m))\n  finally:\n   p.stop()\n   \n   \n def test_not_callable_spec_as_list(self):\n  spec = ('foo', 'bar')\n  p = patch(MODNAME, spec=spec)\n  m = p.start()\n  try:\n   self.assertFalse(callable(m))\n  finally:\n   p.stop()\n   \n   \n def test_patch_stopall(self):\n  unlink = os.unlink\n  chdir = os.chdir\n  path = os.path\n  patch('os.unlink', something).start()\n  patch('os.chdir', something_else).start()\n  \n  @patch('os.path')\n  def patched(mock_path):\n   patch.stopall()\n   self.assertIs(os.path, mock_path)\n   self.assertIs(os.unlink, unlink)\n   self.assertIs(os.chdir, chdir)\n   \n  patched()\n  self.assertIs(os.path, path)\n  \n  \n  \nif __name__ == '__main__':\n unittest.main()\n"], "json": [".js", "var $module = (function($B){\n\nvar _b_ = $B.builtins\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\n//for(var $py_builtin in _b_) eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")\n\nfunction _py(obj){\n    if(obj===null){return None}\n    if(isinstance(obj,list)){\n        var res = []\n        for(var i=0;i<obj.length;i++){\n            res.push(_py(obj[i]))\n        }\n        return res\n    }\n    if(obj.__class__!==undefined){\n        if(obj.__class__===list){\n            for(var i=0;i<obj.length;i++){\n                obj[i] = _py(obj[i])\n            }\n        }\n        return obj\n    }\n    if(typeof obj==='object' && obj.__class__===undefined){\n        // transform JS object into a Python dict\n        var res = dict()\n        for(var attr in obj){\n            getattr(res,'__setitem__')(attr,_py(obj[attr]))\n        }\n        return res\n    }\n    return $B.JSObject(obj)\n}\nfunction _js(obj){\n    // obj is a Python object\n    if (isinstance(obj,[int,str])) return obj\n    if(obj===None) return null\n    if(obj===True) return true\n    if(obj===False) return false\n    if(isinstance(obj,float)) return obj.value\n    if(isinstance(obj,[list,tuple])){\n        var res = []\n        for(var i=0;i<obj.length;i++){res.push(_js(obj[i]))}\n        return res\n    }\n    if(isinstance(obj,dict)){\n        var res = new Object()\n        try {\n            itr = $B.$dict_iterator(obj)\n            while (true) {\n                itm = itr.next()  // k,v pair\n                res[_js(itm[0])]=_js(itm[1])\n            }\n        } catch (err) {\n            if (err.__name__ !== \"StopIteration\") { throw err } else { $B.$pop_exc() }\n        }\n        return res\n    }\n    throw _b_.TypeError(str(obj)+' is not JSON serializable')\n}\n\nreturn  {\n    loads : function(json_obj){return _py(JSON.parse(json_obj))},\n    dumps : function(obj){return JSON.stringify(_js(obj))},\n}\n\n})(__BRYTHON__)\n"], "logging.config": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\n\nimport sys, logging, logging.handlers, socket, struct, traceback, re\nimport io\n\ntry:\n import _thread as thread\n import threading\nexcept ImportError: \n thread = None\n \nfrom socketserver import ThreadingTCPServer, StreamRequestHandler\n\n\nDEFAULT_LOGGING_CONFIG_PORT = 9030\n\nif sys.platform == \"win32\":\n RESET_ERROR = 10054 \nelse:\n RESET_ERROR = 104 \n \n \n \n \n \n \n_listener = None\n\ndef fileConfig(fname, defaults=None, disable_existing_loggers=True):\n \"\"\n import configparser\n \n cp = configparser.ConfigParser(defaults)\n if hasattr(fname, 'readline'):\n  cp.read_file(fname)\n else:\n  cp.read(fname)\n  \n formatters = _create_formatters(cp)\n \n \n logging._acquireLock()\n try:\n  logging._handlers.clear()\n  del logging._handlerList[:]\n  \n  handlers = _install_handlers(cp, formatters)\n  _install_loggers(cp, handlers, disable_existing_loggers)\n finally:\n  logging._releaseLock()\n  \n  \ndef _resolve(name):\n \"\"\n name = name.split('.')\n used = name.pop(0)\n found = __import__(used)\n for n in name:\n  used = used + '.' + n\n  try:\n   found = getattr(found, n)\n  except AttributeError:\n   __import__(used)\n   found = getattr(found, n)\n return found\n \ndef _strip_spaces(alist):\n return map(lambda x: x.strip(), alist)\n \ndef _create_formatters(cp):\n \"\"\n flist = cp[\"formatters\"][\"keys\"]\n if not len(flist):\n  return {}\n flist = flist.split(\",\")\n flist = _strip_spaces(flist)\n formatters = {}\n for form in flist:\n  sectname = \"formatter_%s\" % form\n  fs = cp.get(sectname, \"format\", raw=True, fallback=None)\n  dfs = cp.get(sectname, \"datefmt\", raw=True, fallback=None)\n  c = logging.Formatter\n  class_name = cp[sectname].get(\"class\")\n  if class_name:\n   c = _resolve(class_name)\n  f = c(fs, dfs)\n  formatters[form] = f\n return formatters\n \n \ndef _install_handlers(cp, formatters):\n \"\"\n hlist = cp[\"handlers\"][\"keys\"]\n if not len(hlist):\n  return {}\n hlist = hlist.split(\",\")\n hlist = _strip_spaces(hlist)\n handlers = {}\n fixups = [] \n for hand in hlist:\n  section = cp[\"handler_%s\" % hand]\n  klass = section[\"class\"]\n  fmt = section.get(\"formatter\", \"\")\n  try:\n   klass = eval(klass, vars(logging))\n  except (AttributeError, NameError):\n   klass = _resolve(klass)\n  args = section[\"args\"]\n  args = eval(args, vars(logging))\n  h = klass(*args)\n  if \"level\" in section:\n   level = section[\"level\"]\n   h.setLevel(logging._levelNames[level])\n  if len(fmt):\n   h.setFormatter(formatters[fmt])\n  if issubclass(klass, logging.handlers.MemoryHandler):\n   target = section.get(\"target\", \"\")\n   if len(target): \n    fixups.append((h, target))\n  handlers[hand] = h\n  \n for h, t in fixups:\n  h.setTarget(handlers[t])\n return handlers\n \ndef _handle_existing_loggers(existing, child_loggers, disable_existing):\n \"\"\n root = logging.root\n for log in existing:\n  logger = root.manager.loggerDict[log]\n  if log in child_loggers:\n   logger.level = logging.NOTSET\n   logger.handlers = []\n   logger.propagate = True\n  else:\n   logger.disabled = disable_existing\n   \ndef _install_loggers(cp, handlers, disable_existing):\n \"\"\n \n \n llist = cp[\"loggers\"][\"keys\"]\n llist = llist.split(\",\")\n llist = list(map(lambda x: x.strip(), llist))\n llist.remove(\"root\")\n section = cp[\"logger_root\"]\n root = logging.root\n log = root\n if \"level\" in section:\n  level = section[\"level\"]\n  log.setLevel(logging._levelNames[level])\n for h in root.handlers[:]:\n  root.removeHandler(h)\n hlist = section[\"handlers\"]\n if len(hlist):\n  hlist = hlist.split(\",\")\n  hlist = _strip_spaces(hlist)\n  for hand in hlist:\n   log.addHandler(handlers[hand])\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n existing = list(root.manager.loggerDict.keys())\n \n \n \n \n existing.sort()\n \n \n child_loggers = []\n \n for log in llist:\n  section = cp[\"logger_%s\" % log]\n  qn = section[\"qualname\"]\n  propagate = section.getint(\"propagate\", fallback=1)\n  logger = logging.getLogger(qn)\n  if qn in existing:\n   i = existing.index(qn) + 1 \n   prefixed = qn + \".\"\n   pflen = len(prefixed)\n   num_existing = len(existing)\n   while i < num_existing:\n    if existing[i][:pflen] == prefixed:\n     child_loggers.append(existing[i])\n    i += 1\n   existing.remove(qn)\n  if \"level\" in section:\n   level = section[\"level\"]\n   logger.setLevel(logging._levelNames[level])\n  for h in logger.handlers[:]:\n   logger.removeHandler(h)\n  logger.propagate = propagate\n  logger.disabled = 0\n  hlist = section[\"handlers\"]\n  if len(hlist):\n   hlist = hlist.split(\",\")\n   hlist = _strip_spaces(hlist)\n   for hand in hlist:\n    logger.addHandler(handlers[hand])\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n _handle_existing_loggers(existing, child_loggers, disable_existing)\n \nIDENTIFIER = re.compile('^[a-z_][a-z0-9_]*$', re.I)\n\n\ndef valid_ident(s):\n m = IDENTIFIER.match(s)\n if not m:\n  raise ValueError('Not a valid Python identifier: %r' % s)\n return True\n \n \n \n \n \n \n \n \n \n \n \nclass ConvertingDict(dict):\n \"\"\n \n def __getitem__(self, key):\n  value = dict.__getitem__(self, key)\n  result = self.configurator.convert(value)\n  \n  if value is not result:\n   self[key] = result\n   if type(result) in (ConvertingDict, ConvertingList,\n   ConvertingTuple):\n    result.parent = self\n    result.key = key\n  return result\n  \n def get(self, key, default=None):\n  value = dict.get(self, key, default)\n  result = self.configurator.convert(value)\n  \n  if value is not result:\n   self[key] = result\n   if type(result) in (ConvertingDict, ConvertingList,\n   ConvertingTuple):\n    result.parent = self\n    result.key = key\n  return result\n  \n def pop(self, key, default=None):\n  value = dict.pop(self, key, default)\n  result = self.configurator.convert(value)\n  if value is not result:\n   if type(result) in (ConvertingDict, ConvertingList,\n   ConvertingTuple):\n    result.parent = self\n    result.key = key\n  return result\n  \nclass ConvertingList(list):\n \"\"\n def __getitem__(self, key):\n  value = list.__getitem__(self, key)\n  result = self.configurator.convert(value)\n  \n  if value is not result:\n   self[key] = result\n   if type(result) in (ConvertingDict, ConvertingList,\n   ConvertingTuple):\n    result.parent = self\n    result.key = key\n  return result\n  \n def pop(self, idx=-1):\n  value = list.pop(self, idx)\n  result = self.configurator.convert(value)\n  if value is not result:\n   if type(result) in (ConvertingDict, ConvertingList,\n   ConvertingTuple):\n    result.parent = self\n  return result\n  \nclass ConvertingTuple(tuple):\n \"\"\n def __getitem__(self, key):\n  value = tuple.__getitem__(self, key)\n  result = self.configurator.convert(value)\n  if value is not result:\n   if type(result) in (ConvertingDict, ConvertingList,\n   ConvertingTuple):\n    result.parent = self\n    result.key = key\n  return result\n  \nclass BaseConfigurator(object):\n \"\"\n \n CONVERT_PATTERN = re.compile(r'^(?P<prefix>[a-z]+)://(?P<suffix>.*)$')\n \n WORD_PATTERN = re.compile(r'^\\s*(\\w+)\\s*')\n DOT_PATTERN = re.compile(r'^\\.\\s*(\\w+)\\s*')\n INDEX_PATTERN = re.compile(r'^\\[\\s*(\\w+)\\s*\\]\\s*')\n DIGIT_PATTERN = re.compile(r'^\\d+$')\n \n value_converters = {\n 'ext' : 'ext_convert',\n 'cfg' : 'cfg_convert',\n }\n \n \n importer = staticmethod(__import__)\n \n def __init__(self, config):\n  self.config = ConvertingDict(config)\n  self.config.configurator = self\n  \n def resolve(self, s):\n  \"\"\n  name = s.split('.')\n  used = name.pop(0)\n  try:\n   found = self.importer(used)\n   for frag in name:\n    used += '.' + frag\n    try:\n     found = getattr(found, frag)\n    except AttributeError:\n     self.importer(used)\n     found = getattr(found, frag)\n   return found\n  except ImportError:\n   e, tb = sys.exc_info()[1:]\n   v = ValueError('Cannot resolve %r: %s' % (s, e))\n   v.__cause__, v.__traceback__ = e, tb\n   raise v\n   \n def ext_convert(self, value):\n  \"\"\n  return self.resolve(value)\n  \n def cfg_convert(self, value):\n  \"\"\n  rest = value\n  m = self.WORD_PATTERN.match(rest)\n  if m is None:\n   raise ValueError(\"Unable to convert %r\" % value)\n  else:\n   rest = rest[m.end():]\n   d = self.config[m.groups()[0]]\n   \n   while rest:\n    m = self.DOT_PATTERN.match(rest)\n    if m:\n     d = d[m.groups()[0]]\n    else:\n     m = self.INDEX_PATTERN.match(rest)\n     if m:\n      idx = m.groups()[0]\n      if not self.DIGIT_PATTERN.match(idx):\n       d = d[idx]\n      else:\n       try:\n        n = int(idx) \n        d = d[n]\n       except TypeError:\n        d = d[idx]\n    if m:\n     rest = rest[m.end():]\n    else:\n     raise ValueError('Unable to convert '\n     '%r at %r' % (value, rest))\n     \n  return d\n  \n def convert(self, value):\n  \"\"\n  if not isinstance(value, ConvertingDict) and isinstance(value, dict):\n   value = ConvertingDict(value)\n   value.configurator = self\n  elif not isinstance(value, ConvertingList) and isinstance(value, list):\n   value = ConvertingList(value)\n   value.configurator = self\n  elif not isinstance(value, ConvertingTuple) and isinstance(value, tuple):\n   value = ConvertingTuple(value)\n   value.configurator = self\n  elif isinstance(value, str): \n   m = self.CONVERT_PATTERN.match(value)\n   if m:\n    d = m.groupdict()\n    prefix = d['prefix']\n    converter = self.value_converters.get(prefix, None)\n    if converter:\n     suffix = d['suffix']\n     converter = getattr(self, converter)\n     value = converter(suffix)\n  return value\n  \n def configure_custom(self, config):\n  \"\"\n  c = config.pop('()')\n  if not callable(c):\n   c = self.resolve(c)\n  props = config.pop('.', None)\n  \n  kwargs = dict([(k, config[k]) for k in config if valid_ident(k)])\n  result = c(**kwargs)\n  if props:\n   for name, value in props.items():\n    setattr(result, name, value)\n  return result\n  \n def as_tuple(self, value):\n  \"\"\n  if isinstance(value, list):\n   value = tuple(value)\n  return value\n  \nclass DictConfigurator(BaseConfigurator):\n \"\"\n \n def configure(self):\n  \"\"\n  \n  config = self.config\n  if 'version' not in config:\n   raise ValueError(\"dictionary doesn't specify a version\")\n  if config['version'] != 1:\n   raise ValueError(\"Unsupported version: %s\" % config['version'])\n  incremental = config.pop('incremental', False)\n  EMPTY_DICT = {}\n  logging._acquireLock()\n  try:\n   if incremental:\n    handlers = config.get('handlers', EMPTY_DICT)\n    for name in handlers:\n     if name not in logging._handlers:\n      raise ValueError('No handler found with '\n      'name %r' % name)\n     else:\n      try:\n       handler = logging._handlers[name]\n       handler_config = handlers[name]\n       level = handler_config.get('level', None)\n       if level:\n        handler.setLevel(logging._checkLevel(level))\n      except Exception as e:\n       raise ValueError('Unable to configure handler '\n       '%r: %s' % (name, e))\n    loggers = config.get('loggers', EMPTY_DICT)\n    for name in loggers:\n     try:\n      self.configure_logger(name, loggers[name], True)\n     except Exception as e:\n      raise ValueError('Unable to configure logger '\n      '%r: %s' % (name, e))\n    root = config.get('root', None)\n    if root:\n     try:\n      self.configure_root(root, True)\n     except Exception as e:\n      raise ValueError('Unable to configure root '\n      'logger: %s' % e)\n   else:\n    disable_existing = config.pop('disable_existing_loggers', True)\n    \n    logging._handlers.clear()\n    del logging._handlerList[:]\n    \n    \n    formatters = config.get('formatters', EMPTY_DICT)\n    for name in formatters:\n     try:\n      formatters[name] = self.configure_formatter(\n      formatters[name])\n     except Exception as e:\n      raise ValueError('Unable to configure '\n      'formatter %r: %s' % (name, e))\n      \n    filters = config.get('filters', EMPTY_DICT)\n    for name in filters:\n     try:\n      filters[name] = self.configure_filter(filters[name])\n     except Exception as e:\n      raise ValueError('Unable to configure '\n      'filter %r: %s' % (name, e))\n      \n      \n      \n      \n    handlers = config.get('handlers', EMPTY_DICT)\n    deferred = []\n    for name in sorted(handlers):\n     try:\n      handler = self.configure_handler(handlers[name])\n      handler.name = name\n      handlers[name] = handler\n     except Exception as e:\n      if 'target not configured yet' in str(e):\n       deferred.append(name)\n      else:\n       raise ValueError('Unable to configure handler '\n       '%r: %s' % (name, e))\n       \n       \n    for name in deferred:\n     try:\n      handler = self.configure_handler(handlers[name])\n      handler.name = name\n      handlers[name] = handler\n     except Exception as e:\n      raise ValueError('Unable to configure handler '\n      '%r: %s' % (name, e))\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    root = logging.root\n    existing = list(root.manager.loggerDict.keys())\n    \n    \n    \n    \n    existing.sort()\n    \n    \n    child_loggers = []\n    \n    loggers = config.get('loggers', EMPTY_DICT)\n    for name in loggers:\n     if name in existing:\n      i = existing.index(name) + 1 \n      prefixed = name + \".\"\n      pflen = len(prefixed)\n      num_existing = len(existing)\n      while i < num_existing:\n       if existing[i][:pflen] == prefixed:\n        child_loggers.append(existing[i])\n       i += 1\n      existing.remove(name)\n     try:\n      self.configure_logger(name, loggers[name])\n     except Exception as e:\n      raise ValueError('Unable to configure logger '\n      '%r: %s' % (name, e))\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    _handle_existing_loggers(existing, child_loggers,\n    disable_existing)\n    \n    \n    root = config.get('root', None)\n    if root:\n     try:\n      self.configure_root(root)\n     except Exception as e:\n      raise ValueError('Unable to configure root '\n      'logger: %s' % e)\n  finally:\n   logging._releaseLock()\n   \n def configure_formatter(self, config):\n  \"\"\n  if '()' in config:\n   factory = config['()'] \n   try:\n    result = self.configure_custom(config)\n   except TypeError as te:\n    if \"'format'\" not in str(te):\n     raise\n     \n     \n     \n     \n    config['fmt'] = config.pop('format')\n    config['()'] = factory\n    result = self.configure_custom(config)\n  else:\n   fmt = config.get('format', None)\n   dfmt = config.get('datefmt', None)\n   style = config.get('style', '%')\n   result = logging.Formatter(fmt, dfmt, style)\n  return result\n  \n def configure_filter(self, config):\n  \"\"\n  if '()' in config:\n   result = self.configure_custom(config)\n  else:\n   name = config.get('name', '')\n   result = logging.Filter(name)\n  return result\n  \n def add_filters(self, filterer, filters):\n  \"\"\n  for f in filters:\n   try:\n    filterer.addFilter(self.config['filters'][f])\n   except Exception as e:\n    raise ValueError('Unable to add filter %r: %s' % (f, e))\n    \n def configure_handler(self, config):\n  \"\"\n  config_copy = dict(config) \n  formatter = config.pop('formatter', None)\n  if formatter:\n   try:\n    formatter = self.config['formatters'][formatter]\n   except Exception as e:\n    raise ValueError('Unable to set formatter '\n    '%r: %s' % (formatter, e))\n  level = config.pop('level', None)\n  filters = config.pop('filters', None)\n  if '()' in config:\n   c = config.pop('()')\n   if not callable(c):\n    c = self.resolve(c)\n   factory = c\n  else:\n   cname = config.pop('class')\n   klass = self.resolve(cname)\n   \n   if issubclass(klass, logging.handlers.MemoryHandler) and 'target' in config:\n    try:\n     th = self.config['handlers'][config['target']]\n     if not isinstance(th, logging.Handler):\n      config.update(config_copy) \n      raise TypeError('target not configured yet')\n     config['target'] = th\n    except Exception as e:\n     raise ValueError('Unable to set target handler '\n     '%r: %s' % (config['target'], e))\n   elif issubclass(klass, logging.handlers.SMTPHandler) and 'mailhost' in config:\n    config['mailhost'] = self.as_tuple(config['mailhost'])\n   elif issubclass(klass, logging.handlers.SysLogHandler) and 'address' in config:\n    config['address'] = self.as_tuple(config['address'])\n   factory = klass\n  kwargs = dict([(k, config[k]) for k in config if valid_ident(k)])\n  try:\n   result = factory(**kwargs)\n  except TypeError as te:\n   if \"'stream'\" not in str(te):\n    raise\n    \n    \n    \n    \n   kwargs['strm'] = kwargs.pop('stream')\n   result = factory(**kwargs)\n  if formatter:\n   result.setFormatter(formatter)\n  if level is not None:\n   result.setLevel(logging._checkLevel(level))\n  if filters:\n   self.add_filters(result, filters)\n  return result\n  \n def add_handlers(self, logger, handlers):\n  \"\"\n  for h in handlers:\n   try:\n    logger.addHandler(self.config['handlers'][h])\n   except Exception as e:\n    raise ValueError('Unable to add handler %r: %s' % (h, e))\n    \n def common_logger_config(self, logger, config, incremental=False):\n  \"\"\n  level = config.get('level', None)\n  if level is not None:\n   logger.setLevel(logging._checkLevel(level))\n  if not incremental:\n  \n   for h in logger.handlers[:]:\n    logger.removeHandler(h)\n   handlers = config.get('handlers', None)\n   if handlers:\n    self.add_handlers(logger, handlers)\n   filters = config.get('filters', None)\n   if filters:\n    self.add_filters(logger, filters)\n    \n def configure_logger(self, name, config, incremental=False):\n  \"\"\n  logger = logging.getLogger(name)\n  self.common_logger_config(logger, config, incremental)\n  propagate = config.get('propagate', None)\n  if propagate is not None:\n   logger.propagate = propagate\n   \n def configure_root(self, config, incremental=False):\n  \"\"\n  root = logging.getLogger()\n  self.common_logger_config(root, config, incremental)\n  \ndictConfigClass = DictConfigurator\n\ndef dictConfig(config):\n \"\"\n dictConfigClass(config).configure()\n \n \ndef listen(port=DEFAULT_LOGGING_CONFIG_PORT):\n \"\"\n if not thread: \n  raise NotImplementedError(\"listen() needs threading to work\")\n  \n class ConfigStreamHandler(StreamRequestHandler):\n  \"\"\n  def handle(self):\n   \"\"\n   try:\n    conn = self.connection\n    chunk = conn.recv(4)\n    if len(chunk) == 4:\n     slen = struct.unpack(\">L\", chunk)[0]\n     chunk = self.connection.recv(slen)\n     while len(chunk) < slen:\n      chunk = chunk + conn.recv(slen - len(chunk))\n     chunk = chunk.decode(\"utf-8\")\n     try:\n      import json\n      d =json.loads(chunk)\n      assert isinstance(d, dict)\n      dictConfig(d)\n     except:\n     \n     \n      file = io.StringIO(chunk)\n      try:\n       fileConfig(file)\n      except (KeyboardInterrupt, SystemExit): \n       raise\n      except:\n       traceback.print_exc()\n     if self.server.ready:\n      self.server.ready.set()\n   except socket.error as e:\n    if not isinstance(e.args, tuple):\n     raise\n    else:\n     errcode = e.args[0]\n     if errcode != RESET_ERROR:\n      raise\n      \n class ConfigSocketReceiver(ThreadingTCPServer):\n  \"\"\n  \n  allow_reuse_address = 1\n  \n  def __init__(self, host='localhost', port=DEFAULT_LOGGING_CONFIG_PORT,\n  handler=None, ready=None):\n   ThreadingTCPServer.__init__(self, (host, port), handler)\n   logging._acquireLock()\n   self.abort = 0\n   logging._releaseLock()\n   self.timeout = 1\n   self.ready = ready\n   \n  def serve_until_stopped(self):\n   import select\n   abort = 0\n   while not abort:\n    rd, wr, ex = select.select([self.socket.fileno()],\n    [], [],\n    self.timeout)\n    if rd:\n     self.handle_request()\n    logging._acquireLock()\n    abort = self.abort\n    logging._releaseLock()\n   self.socket.close()\n   \n class Server(threading.Thread):\n \n  def __init__(self, rcvr, hdlr, port):\n   super(Server, self).__init__()\n   self.rcvr = rcvr\n   self.hdlr = hdlr\n   self.port = port\n   self.ready = threading.Event()\n   \n  def run(self):\n   server = self.rcvr(port=self.port, handler=self.hdlr,\n   ready=self.ready)\n   if self.port == 0:\n    self.port = server.server_address[1]\n   self.ready.set()\n   global _listener\n   logging._acquireLock()\n   _listener = server\n   logging._releaseLock()\n   server.serve_until_stopped()\n   \n return Server(ConfigSocketReceiver, ConfigStreamHandler, port)\n \ndef stopListening():\n \"\"\n global _listener\n logging._acquireLock()\n try:\n  if _listener:\n   _listener.abort = 1\n   _listener = None\n finally:\n  logging._releaseLock()\n"], "xml.sax.handler": [".py", "\"\"\n\nversion = '2.0beta'\n\n\n\n\n\n\n\n\n\nclass ErrorHandler:\n \"\"\n \n def error(self, exception):\n  \"\"\n  raise exception\n  \n def fatalError(self, exception):\n  \"\"\n  raise exception\n  \n def warning(self, exception):\n  \"\"\n  print(exception)\n  \n  \n  \n  \nclass ContentHandler:\n \"\"\n \n def __init__(self):\n  self._locator = None\n  \n def setDocumentLocator(self, locator):\n  \"\"\n  self._locator = locator\n  \n def startDocument(self):\n  \"\"\n  \n def endDocument(self):\n  \"\"\n  \n def startPrefixMapping(self, prefix, uri):\n  \"\"\n  \n def endPrefixMapping(self, prefix):\n  \"\"\n  \n def startElement(self, name, attrs):\n  \"\"\n  \n def endElement(self, name):\n  \"\"\n  \n def startElementNS(self, name, qname, attrs):\n  \"\"\n  \n def endElementNS(self, name, qname):\n  \"\"\n  \n def characters(self, content):\n  \"\"\n  \n def ignorableWhitespace(self, whitespace):\n  \"\"\n  \n def processingInstruction(self, target, data):\n  \"\"\n  \n def skippedEntity(self, name):\n  \"\"\n  \n  \n  \n  \nclass DTDHandler:\n \"\"\n \n def notationDecl(self, name, publicId, systemId):\n  \"\"\n  \n def unparsedEntityDecl(self, name, publicId, systemId, ndata):\n  \"\"\n  \n  \n  \n  \nclass EntityResolver:\n \"\"\n \n def resolveEntity(self, publicId, systemId):\n  \"\"\n  return systemId\n  \n  \n  \n  \n  \n  \n  \n  \nfeature_namespaces = \"http://xml.org/sax/features/namespaces\"\n\n\n\n\n\nfeature_namespace_prefixes = \"http://xml.org/sax/features/namespace-prefixes\"\n\n\n\n\n\n\nfeature_string_interning = \"http://xml.org/sax/features/string-interning\"\n\n\n\n\n\nfeature_validation = \"http://xml.org/sax/features/validation\"\n\n\n\n\n\nfeature_external_ges = \"http://xml.org/sax/features/external-general-entities\"\n\n\n\n\nfeature_external_pes = \"http://xml.org/sax/features/external-parameter-entities\"\n\n\n\n\n\n\nall_features = [feature_namespaces,\nfeature_namespace_prefixes,\nfeature_string_interning,\nfeature_validation,\nfeature_external_ges,\nfeature_external_pes]\n\n\n\n\n\n\n\n\nproperty_lexical_handler = \"http://xml.org/sax/properties/lexical-handler\"\n\n\n\n\nproperty_declaration_handler = \"http://xml.org/sax/properties/declaration-handler\"\n\n\n\n\n\nproperty_dom_node = \"http://xml.org/sax/properties/dom-node\"\n\n\n\n\n\n\nproperty_xml_string = \"http://xml.org/sax/properties/xml-string\"\n\n\n\n\n\nproperty_encoding = \"http://www.python.org/sax/properties/encoding\"\n\n\n\n\n\n\n\n\n\n\nproperty_interning_dict = \"http://www.python.org/sax/properties/interning-dict\"\n\n\n\n\n\n\n\nall_properties = [property_lexical_handler,\nproperty_dom_node,\nproperty_declaration_handler,\nproperty_xml_string,\nproperty_encoding,\nproperty_interning_dict]\n"], "importlib.machinery": [".py", "\"\"\n\nimport _imp\n\nfrom ._bootstrap import (SOURCE_SUFFIXES, DEBUG_BYTECODE_SUFFIXES,\nOPTIMIZED_BYTECODE_SUFFIXES, \nEXTENSION_SUFFIXES)\nfrom ._bootstrap import BuiltinImporter\nfrom ._bootstrap import FrozenImporter\nfrom ._bootstrap import WindowsRegistryFinder\nfrom ._bootstrap import PathFinder\nfrom ._bootstrap import FileFinder\nfrom ._bootstrap import SourceFileLoader\nfrom ._bootstrap import SourcelessFileLoader\nfrom ._bootstrap import ExtensionFileLoader\n\n\n\n\n\n"], "tokenize": [".py", "\"\"\n\n__author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__credits__ = ('GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, '\n'Skip Montanaro, Raymond Hettinger, Trent Nelson, '\n'Michael Foord')\nimport builtins\nimport re\nimport sys\nfrom token import *\nfrom codecs import lookup, BOM_UTF8\nimport collections\nfrom io import TextIOWrapper\ncookie_re = re.compile(r'^[ \\t\\f]*#.*coding[:=][ \\t]*([-\\w.]+)', re.ASCII)\n\nimport token\n__all__ = token.__all__ + [\"COMMENT\", \"tokenize\", \"detect_encoding\",\n\"NL\", \"untokenize\", \"ENCODING\", \"TokenInfo\"]\ndel token\n\nCOMMENT = N_TOKENS\ntok_name[COMMENT] = 'COMMENT'\nNL = N_TOKENS + 1\ntok_name[NL] = 'NL'\nENCODING = N_TOKENS + 2\ntok_name[ENCODING] = 'ENCODING'\nN_TOKENS += 3\nEXACT_TOKEN_TYPES = {\n'(': LPAR,\n')': RPAR,\n'[': LSQB,\n']': RSQB,\n':': COLON,\n',': COMMA,\n';': SEMI,\n'+': PLUS,\n'-': MINUS,\n'*': STAR,\n'/': SLASH,\n'|': VBAR,\n'&': AMPER,\n'<': LESS,\n'>': GREATER,\n'=': EQUAL,\n'.': DOT,\n'%': PERCENT,\n'{': LBRACE,\n'}': RBRACE,\n'==': EQEQUAL,\n'!=': NOTEQUAL,\n'<=': LESSEQUAL,\n'>=': GREATEREQUAL,\n'~': TILDE,\n'^': CIRCUMFLEX,\n'<<': LEFTSHIFT,\n'>>': RIGHTSHIFT,\n'**': DOUBLESTAR,\n'+=': PLUSEQUAL,\n'-=': MINEQUAL,\n'*=': STAREQUAL,\n'/=': SLASHEQUAL,\n'%=': PERCENTEQUAL,\n'&=': AMPEREQUAL,\n'|=': VBAREQUAL,\n'^=': CIRCUMFLEXEQUAL,\n'<<=': LEFTSHIFTEQUAL,\n'>>=': RIGHTSHIFTEQUAL,\n'**=': DOUBLESTAREQUAL,\n'//': DOUBLESLASH,\n'//=': DOUBLESLASHEQUAL,\n'@': AT\n}\n\nclass TokenInfo(collections.namedtuple('TokenInfo', 'type string start end line')):\n def __repr__(self):\n  annotated_type = '%d (%s)' % (self.type, tok_name[self.type])\n  return ('TokenInfo(type=%s, string=%r, start=%r, end=%r, line=%r)' %\n  self._replace(type=annotated_type))\n  \n @property\n def exact_type(self):\n  if self.type == OP and self.string in EXACT_TOKEN_TYPES:\n   return EXACT_TOKEN_TYPES[self.string]\n  else:\n   return self.type\n   \ndef group(*choices): return '(' + '|'.join(choices) + ')'\ndef any(*choices): return group(*choices) + '*'\ndef maybe(*choices): return group(*choices) + '?'\n\n\n\nWhitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'\n\nHexnumber = r'0[xX][0-9a-fA-F]+'\nBinnumber = r'0[bB][01]+'\nOctnumber = r'0[oO][0-7]+'\nDecnumber = r'(?:0+|[1-9][0-9]*)'\nIntnumber = group(Hexnumber, Binnumber, Octnumber, Decnumber)\nExponent = r'[eE][-+]?[0-9]+'\nPointfloat = group(r'[0-9]+\\.[0-9]*', r'\\.[0-9]+') + maybe(Exponent)\nExpfloat = r'[0-9]+' + Exponent\nFloatnumber = group(Pointfloat, Expfloat)\nImagnumber = group(r'[0-9]+[jJ]', Floatnumber + r'[jJ]')\nNumber = group(Imagnumber, Floatnumber, Intnumber)\n\nStringPrefix = r'(?:[bB][rR]?|[rR][bB]?|[uU])?'\n\n\nSingle = r\"[^'\\\\]*(?:\\\\.[^'\\\\]*)*'\"\n\nDouble = r'[^\"\\\\]*(?:\\\\.[^\"\\\\]*)*\"'\n\nSingle3 = r\"[^'\\\\]*(?:(?:\\\\.|'(?!''))[^'\\\\]*)*'''\"\n\nDouble3 = r'[^\"\\\\]*(?:(?:\\\\.|\"(?!\"\"))[^\"\\\\]*)*\"\"\"'\nTriple = group(StringPrefix + \"'''\", StringPrefix + '\"\"\"')\n\nString = group(StringPrefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\nStringPrefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"')\n\n\n\n\nOperator = group(r\"\\*\\*=?\", r\">>=?\", r\"<<=?\", r\"!=\",\nr\"//=?\", r\"->\",\nr\"[+\\-*/%&|^=<>]=?\",\nr\"~\")\n\nBracket = '[][(){}]'\nSpecial = group(r'\\r?\\n', r'\\.\\.\\.', r'[:;.,@]')\nFunny = group(Operator, Bracket, Special)\n\nPlainToken = group(Number, Funny, String, Name)\nToken = Ignore + PlainToken\n\n\nContStr = group(StringPrefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\ngroup(\"'\", r'\\\\\\r?\\n'),\nStringPrefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\ngroup('\"', r'\\\\\\r?\\n'))\nPseudoExtras = group(r'\\\\\\r?\\n|\\Z', Comment, Triple)\nPseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)\n\ndef _compile(expr):\n return re.compile(expr, re.UNICODE)\n \nendpats = {\"'\": Single, '\"': Double,\n\"'''\": Single3, '\"\"\"': Double3,\n\"r'''\": Single3, 'r\"\"\"': Double3,\n\"b'''\": Single3, 'b\"\"\"': Double3,\n\"R'''\": Single3, 'R\"\"\"': Double3,\n\"B'''\": Single3, 'B\"\"\"': Double3,\n\"br'''\": Single3, 'br\"\"\"': Double3,\n\"bR'''\": Single3, 'bR\"\"\"': Double3,\n\"Br'''\": Single3, 'Br\"\"\"': Double3,\n\"BR'''\": Single3, 'BR\"\"\"': Double3,\n\"rb'''\": Single3, 'rb\"\"\"': Double3,\n\"Rb'''\": Single3, 'Rb\"\"\"': Double3,\n\"rB'''\": Single3, 'rB\"\"\"': Double3,\n\"RB'''\": Single3, 'RB\"\"\"': Double3,\n\"u'''\": Single3, 'u\"\"\"': Double3,\n\"R'''\": Single3, 'R\"\"\"': Double3,\n\"U'''\": Single3, 'U\"\"\"': Double3,\n'r': None, 'R': None, 'b': None, 'B': None,\n'u': None, 'U': None}\n\ntriple_quoted = {}\nfor t in (\"'''\", '\"\"\"',\n\"r'''\", 'r\"\"\"', \"R'''\", 'R\"\"\"',\n\"b'''\", 'b\"\"\"', \"B'''\", 'B\"\"\"',\n\"br'''\", 'br\"\"\"', \"Br'''\", 'Br\"\"\"',\n\"bR'''\", 'bR\"\"\"', \"BR'''\", 'BR\"\"\"',\n\"rb'''\", 'rb\"\"\"', \"rB'''\", 'rB\"\"\"',\n\"Rb'''\", 'Rb\"\"\"', \"RB'''\", 'RB\"\"\"',\n\"u'''\", 'u\"\"\"', \"U'''\", 'U\"\"\"',\n):\n triple_quoted[t] = t\nsingle_quoted = {}\nfor t in (\"'\", '\"',\n\"r'\", 'r\"', \"R'\", 'R\"',\n\"b'\", 'b\"', \"B'\", 'B\"',\n\"br'\", 'br\"', \"Br'\", 'Br\"',\n\"bR'\", 'bR\"', \"BR'\", 'BR\"' ,\n\"rb'\", 'rb\"', \"rB'\", 'rB\"',\n\"Rb'\", 'Rb\"', \"RB'\", 'RB\"' ,\n\"u'\", 'u\"', \"U'\", 'U\"',\n):\n single_quoted[t] = t\n \ntabsize = 8\n\nclass TokenError(Exception): pass\n\nclass StopTokenizing(Exception): pass\n\n\nclass Untokenizer:\n\n def __init__(self):\n  self.tokens = []\n  self.prev_row = 1\n  self.prev_col = 0\n  self.encoding = None\n  \n def add_whitespace(self, start):\n  row, col = start\n  assert row <= self.prev_row\n  col_offset = col - self.prev_col\n  if col_offset:\n   self.tokens.append(\" \" * col_offset)\n   \n def untokenize(self, iterable):\n  for t in iterable:\n   if len(t) == 2:\n    self.compat(t, iterable)\n    break\n   tok_type, token, start, end, line = t\n   if tok_type == ENCODING:\n    self.encoding = token\n    continue\n   self.add_whitespace(start)\n   self.tokens.append(token)\n   self.prev_row, self.prev_col = end\n   if tok_type in (NEWLINE, NL):\n    self.prev_row += 1\n    self.prev_col = 0\n  return \"\".join(self.tokens)\n  \n def compat(self, token, iterable):\n  startline = False\n  indents = []\n  toks_append = self.tokens.append\n  toknum, tokval = token\n  \n  if toknum in (NAME, NUMBER):\n   tokval += ' '\n  if toknum in (NEWLINE, NL):\n   startline = True\n  prevstring = False\n  for tok in iterable:\n   toknum, tokval = tok[:2]\n   if toknum == ENCODING:\n    self.encoding = tokval\n    continue\n    \n   if toknum in (NAME, NUMBER):\n    tokval += ' '\n    \n    \n   if toknum == STRING:\n    if prevstring:\n     tokval = ' ' + tokval\n    prevstring = True\n   else:\n    prevstring = False\n    \n   if toknum == INDENT:\n    indents.append(tokval)\n    continue\n   elif toknum == DEDENT:\n    indents.pop()\n    continue\n   elif toknum in (NEWLINE, NL):\n    startline = True\n   elif startline and indents:\n    toks_append(indents[-1])\n    startline = False\n   toks_append(tokval)\n   \n   \ndef untokenize(iterable):\n \"\"\n ut = Untokenizer()\n out = ut.untokenize(iterable)\n if ut.encoding is not None:\n  out = out.encode(ut.encoding)\n return out\n \n \ndef _get_normal_name(orig_enc):\n \"\"\n \n enc = orig_enc[:12].lower().replace(\"_\", \"-\")\n if enc == \"utf-8\" or enc.startswith(\"utf-8-\"):\n  return \"utf-8\"\n if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or enc.startswith((\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")):\n  return \"iso-8859-1\"\n return orig_enc\n \ndef detect_encoding(readline):\n \"\"\n try:\n  filename = readline.__self__.name\n except AttributeError:\n  filename = None\n bom_found = False\n encoding = None\n default = 'utf-8'\n def read_or_stop():\n  try:\n   return readline()\n  except StopIteration:\n   return b''\n   \n def find_cookie(line):\n  try:\n  \n  \n  \n   line_string = line.decode('utf-8')\n  except UnicodeDecodeError:\n   msg = \"invalid or missing encoding declaration\"\n   if filename is not None:\n    msg = '{} for {!r}'.format(msg, filename)\n   raise SyntaxError(msg)\n   \n  match = cookie_re.match(line_string)\n  if not match:\n   return None\n  encoding = _get_normal_name(match.group(1))\n  try:\n   codec = lookup(encoding)\n  except LookupError:\n  \n   if filename is None:\n    msg = \"unknown encoding: \" + encoding\n   else:\n    msg = \"unknown encoding for {!r}: {}\".format(filename,\n    encoding)\n   raise SyntaxError(msg)\n   \n  if bom_found:\n   if encoding != 'utf-8':\n   \n    if filename is None:\n     msg = 'encoding problem: utf-8'\n    else:\n     msg = 'encoding problem for {!r}: utf-8'.format(filename)\n    raise SyntaxError(msg)\n   encoding += '-sig'\n  return encoding\n  \n first = read_or_stop()\n if first.startswith(BOM_UTF8):\n  bom_found = True\n  first = first[3:]\n  default = 'utf-8-sig'\n if not first:\n  return default, []\n  \n encoding = find_cookie(first)\n if encoding:\n  return encoding, [first]\n  \n second = read_or_stop()\n if not second:\n  return default, [first]\n  \n encoding = find_cookie(second)\n if encoding:\n  return encoding, [first, second]\n  \n return default, [first, second]\n \n \ndef open(filename):\n \"\"\n buffer = builtins.open(filename, 'rb')\n encoding, lines = detect_encoding(buffer.readline)\n buffer.seek(0)\n text = TextIOWrapper(buffer, encoding, line_buffering=True)\n text.mode = 'r'\n return text\n \n \ndef tokenize(readline):\n \"\"\n \n \n from itertools import chain, repeat\n encoding, consumed = detect_encoding(readline)\n rl_gen = iter(readline, b\"\")\n empty = repeat(b\"\")\n return _tokenize(chain(consumed, rl_gen, empty).__next__, encoding)\n \n \ndef _tokenize(readline, encoding):\n lnum = parenlev = continued = 0\n numchars = '0123456789'\n contstr, needcont = '', 0\n contline = None\n indents = [0]\n \n if encoding is not None:\n  if encoding == \"utf-8-sig\":\n  \n   encoding = \"utf-8\"\n  yield TokenInfo(ENCODING, encoding, (0, 0), (0, 0), '')\n while True: \n  try:\n   line = readline()\n  except StopIteration:\n   line = b''\n   \n  if encoding is not None:\n   line = line.decode(encoding)\n  lnum += 1\n  pos, max = 0, len(line)\n  \n  if contstr: \n   if not line:\n    raise TokenError(\"EOF in multi-line string\", strstart)\n   endmatch = endprog.match(line)\n   if endmatch:\n    pos = end = endmatch.end(0)\n    yield TokenInfo(STRING, contstr + line[:end],\n    strstart, (lnum, end), contline + line)\n    contstr, needcont = '', 0\n    contline = None\n   elif needcont and line[-2:] != '\\\\\\n' and line[-3:] != '\\\\\\r\\n':\n    yield TokenInfo(ERRORTOKEN, contstr + line,\n    strstart, (lnum, len(line)), contline)\n    contstr = ''\n    contline = None\n    continue\n   else:\n    contstr = contstr + line\n    contline = contline + line\n    continue\n    \n  elif parenlev == 0 and not continued: \n   if not line: break\n   column = 0\n   while pos < max: \n    if line[pos] == ' ':\n     column += 1\n    elif line[pos] == '\\t':\n     column = (column//tabsize + 1)*tabsize\n    elif line[pos] == '\\f':\n     column = 0\n    else:\n     break\n    pos += 1\n   if pos == max:\n    break\n    \n   if line[pos] in '#\\r\\n': \n    if line[pos] == '#':\n     comment_token = line[pos:].rstrip('\\r\\n')\n     nl_pos = pos + len(comment_token)\n     yield TokenInfo(COMMENT, comment_token,\n     (lnum, pos), (lnum, pos + len(comment_token)), line)\n     yield TokenInfo(NL, line[nl_pos:],\n     (lnum, nl_pos), (lnum, len(line)), line)\n    else:\n     yield TokenInfo((NL, COMMENT)[line[pos] == '#'], line[pos:],\n     (lnum, pos), (lnum, len(line)), line)\n    continue\n    \n   if column > indents[-1]: \n    indents.append(column)\n    yield TokenInfo(INDENT, line[:pos], (lnum, 0), (lnum, pos), line)\n   while column < indents[-1]:\n    if column not in indents:\n     raise IndentationError(\n     \"unindent does not match any outer indentation level\",\n     (\"<tokenize>\", lnum, pos, line))\n    indents = indents[:-1]\n    yield TokenInfo(DEDENT, '', (lnum, pos), (lnum, pos), line)\n    \n  else: \n   if not line:\n    raise TokenError(\"EOF in multi-line statement\", (lnum, 0))\n   continued = 0\n   \n  while pos < max:\n   pseudomatch = _compile(PseudoToken).match(line, pos)\n   if pseudomatch: \n    start, end = pseudomatch.span(1)\n    spos, epos, pos = (lnum, start), (lnum, end), end\n    if start == end:\n     continue\n    token, initial = line[start:end], line[start]\n    \n    if (initial in numchars or \n    (initial == '.' and token != '.' and token != '...')):\n     yield TokenInfo(NUMBER, token, spos, epos, line)\n    elif initial in '\\r\\n':\n     yield TokenInfo(NL if parenlev > 0 else NEWLINE,\n     token, spos, epos, line)\n    elif initial == '#':\n     assert not token.endswith(\"\\n\")\n     yield TokenInfo(COMMENT, token, spos, epos, line)\n    elif token in triple_quoted:\n     endprog = _compile(endpats[token])\n     endmatch = endprog.match(line, pos)\n     if endmatch: \n      pos = endmatch.end(0)\n      token = line[start:pos]\n      yield TokenInfo(STRING, token, spos, (lnum, pos), line)\n     else:\n      strstart = (lnum, start) \n      contstr = line[start:]\n      contline = line\n      break\n    elif initial in single_quoted or token[:2] in single_quoted or token[:3] in single_quoted:\n     if token[-1] == '\\n': \n      strstart = (lnum, start)\n      endprog = _compile(endpats[initial] or\n      endpats[token[1]] or\n      endpats[token[2]])\n      contstr, needcont = line[start:], 1\n      contline = line\n      break\n     else: \n      yield TokenInfo(STRING, token, spos, epos, line)\n    elif initial.isidentifier(): \n     yield TokenInfo(NAME, token, spos, epos, line)\n    elif initial == '\\\\': \n     continued = 1\n    else:\n     if initial in '([{':\n      parenlev += 1\n     elif initial in ')]}':\n      parenlev -= 1\n     yield TokenInfo(OP, token, spos, epos, line)\n   else:\n    yield TokenInfo(ERRORTOKEN, line[pos],\n    (lnum, pos), (lnum, pos+1), line)\n    pos += 1\n    \n for indent in indents[1:]: \n  yield TokenInfo(DEDENT, '', (lnum, 0), (lnum, 0), '')\n yield TokenInfo(ENDMARKER, '', (lnum, 0), (lnum, 0), '')\n \n \n \n \ndef generate_tokens(readline):\n return _tokenize(readline, None)\n \ndef main():\n import argparse\n \n \n def perror(message):\n  print(message, file=sys.stderr)\n  \n def error(message, filename=None, location=None):\n  if location:\n   args = (filename,) + location + (message,)\n   perror(\"%s:%d:%d: error: %s\" % args)\n  elif filename:\n   perror(\"%s: error: %s\" % (filename, message))\n  else:\n   perror(\"error: %s\" % message)\n  sys.exit(1)\n  \n  \n parser = argparse.ArgumentParser(prog='python -m tokenize')\n parser.add_argument(dest='filename', nargs='?',\n metavar='filename.py',\n help='the file to tokenize; defaults to stdin')\n parser.add_argument('-e', '--exact', dest='exact', action='store_true',\n help='display token names using the exact type')\n args = parser.parse_args()\n \n try:\n \n  if args.filename:\n   filename = args.filename\n   with builtins.open(filename, 'rb') as f:\n    tokens = list(tokenize(f.readline))\n  else:\n   filename = \"<stdin>\"\n   tokens = _tokenize(sys.stdin.readline, None)\n   \n   \n  for token in tokens:\n   token_type = token.type\n   if args.exact:\n    token_type = token.exact_type\n   token_range = \"%d,%d-%d,%d:\" % (token.start + token.end)\n   print(\"%-20s%-15s%-15r\" %\n   (token_range, tok_name[token_type], token.string))\n except IndentationError as err:\n  line, column = err.args[1][1:3]\n  error(err.args[0], filename, (line, column))\n except TokenError as err:\n  line, column = err.args[1]\n  error(err.args[0], filename, (line, column))\n except SyntaxError as err:\n  error(err, filename)\n except IOError as err:\n  error(err)\n except KeyboardInterrupt:\n  print(\"interrupted\\n\")\n except Exception as err:\n  perror(\"unexpected error: %s\" % err)\n  raise\n  \nif __name__ == \"__main__\":\n main()\n"], "_warnings": [".py", "\"\"\n\n\ndefault_action = \"\"\"default\"\"\"\n\nfilters = \"[('ignore', None, <type 'exceptions.DeprecationWarning'>, None, 0), \n('ignore', None, <type 'exceptions.PendingDeprecationWarning'>, None, 0), \n('ignore', None, <type 'exceptions.ImportWarning'>, None, 0), \n('ignore', None, <type 'exceptions.BytesWarning'>, None, 0)]\"\n\nonce_registry = {}\n\ndef warn(*args,**kw):\n \"\"\n pass\n \ndef warn_explicit(*args,**kw):\n \"\"\n pass\n"], "ui.dialog": [".py", "from . import widget\nfrom browser import html, document\n\nclass Dialog(widget.DraggableWidget):\n def __init__(self, id=None):\n  self._div_shell=html.DIV(\n  Class=\"ui-dialog ui-widget ui-widget-content ui-corner-all ui-front ui-draggable ui-resizable\",\n  style={'position': 'absolute', 'height': 'auto', 'width': '300px',\n  'top': '98px', 'left': '140px', 'display': 'block'})\n  \n  widget.DraggableWidget.__init__(self, self._div_shell, 'dialog', id)\n  \n  _div_titlebar=html.DIV(Id=\"titlebar\",\n  Class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix\")\n  self._div_shell <= _div_titlebar\n  \n  self._div_title=html.SPAN(Id=\"title\", Class=\"ui-dialog-title\")\n  \n  _div_titlebar <= self._div_title\n  \n  self._title_button=html.BUTTON(Title=\"close\",\n  Class=\"ui-button ui-widget ui-state-default ui-corner-all ui-button-icon-only ui-dialog-titlebar-close\")\n  \n  def dialog_close(e):\n  \n   del document[self._div_shell.id]\n   \n  self._title_button.bind('click', dialog_close)\n  _span=html.SPAN(Class=\"ui-button-icon-primary ui-icon ui-icon-closethick\")\n  self._title_button <= _span\n  \n  _span=html.SPAN('close', Class=\"ui-button-text\")\n  self._title_button <= _span\n  \n  _div_titlebar <= self._title_button\n  \n  self._div_dialog=html.DIV(Class=\"ui-dialog-content ui-widget-content\",\n  style={'width': 'auto', 'min-height': '105px', \n  'max-height': 'none', 'height': 'auto'})\n  \n  self._div_shell <= self._div_dialog\n  \n  for _i in ['n', 'e', 's', 'w', 'se', 'sw', 'ne', 'nw']:\n   if _i == 'se':\n    _class=\"ui-resizable-handle ui-resizable-%s ui-icon ui-icon-gripsmall-diagonal-%s\" % (_i, _i)\n   else:\n    _class=\"ui-resizable-handle ui-resizable-%s\" % _i\n    \n   self._div_shell <= html.DIV(Class=_class, style={'z-index': '90'})\n   \n  document <= self._div_shell\n  \n def set_title(self, title):\n  self._div_title.set_text(title)\n  \n def set_body(self, body):\n  self._div_dialog.set_html(body)\n  \nclass EntryDialog(Dialog):\n\n def __init__(self, title, prompt, action, _id=None):\n  Dialog.__init__(self, _id)\n  self.set_title(title)\n  self.action = action\n  d_prompt = html.DIV(prompt, Class=\"ui-widget\", \n  style=dict(float=\"left\",paddingRight=\"10px\"))\n  self.entry = html.INPUT()\n  body = html.DIV(d_prompt+self.entry,\n  style={'padding':'15px'})\n  b_ok = html.BUTTON(\"Ok\")\n  b_ok.bind('click', self.ok)\n  b_cancel = html.BUTTON(\"Cancel\")\n  b_cancel.bind('click', self.cancel)\n  body += html.DIV(b_ok+b_cancel, style={'padding':'15px'})\n  self._div_dialog <= body\n  \n def ok(self, ev):\n  self.result = self._div_shell.get(selector='INPUT')[0].value\n  self.action(self.result)\n  document.remove(self._div_shell)\n  \n def cancel(self, ev):\n  document.remove(self._div_shell)\n  \nclass SelectDialog(Dialog):\n\n def __init__(self, title, prompt, options, action, _id=None):\n  Dialog.__init__(self, _id)\n  self.set_title(title)\n  self.options = options\n  self.action = action\n  d_prompt = html.DIV(prompt, Class=\"ui-widget\", \n  style=dict(float=\"left\",paddingRight=\"10px\"))\n  self.select = html.SELECT()\n  for option in options:\n   self.select <= html.OPTION(option)\n  body = html.DIV(d_prompt+self.select,\n  style={'padding':'15px'})\n  b_ok = html.BUTTON(\"Ok\")\n  b_ok.bind('click', self.ok)\n  b_cancel = html.BUTTON(\"Cancel\")\n  b_cancel.bind('click', self.cancel)\n  body += html.DIV(b_ok+b_cancel, style={'padding':'15px'})\n  self._div_dialog <= body\n  \n def ok(self, ev):\n  ix = self._div_shell.get(selector='SELECT')[0].selectedIndex\n  document.remove(self._div_shell)\n  self.action(self.options[ix])\n  \n def cancel(self, ev):\n  document.remove(self._div_shell)\n  \nclass YesNoDialog(Dialog):\n\n def __init__(self, title, prompt, action_if_yes, action_if_no, _id=None):\n  Dialog.__init__(self, _id)\n  self.set_title(title)\n  \n  self.action_if_yes = action_if_yes\n  self.action_if_no = action_if_no\n  \n  d_prompt = html.DIV(prompt, Class=\"ui-widget\", \n  style=dict(float=\"left\",paddingRight=\"10px\"))\n  body = html.DIV(d_prompt, style={'padding':'15px'})\n  b_ok = html.BUTTON(\"Yes\")\n  b_ok.bind('click', self.yes)\n  b_cancel = html.BUTTON(\"No\")\n  b_cancel.bind('click', self.no)\n  body += html.DIV(b_ok+b_cancel, style={'padding':'15px'})\n  self._div_dialog <= body\n  \n def yes(self, ev):\n  document.remove(self._div_shell)\n  self.action_if_yes(self)\n  \n def no(self, ev):\n  document.remove(self._div_shell)\n  if self.action_if_no is not None:\n   self.action_if_no(self)\n"], "fractions": [".py", "\n\n\n\"\"\n\nfrom decimal import Decimal\nimport math\nimport numbers\nimport operator\nimport re\nimport sys\n\n__all__ = ['Fraction', 'gcd']\n\n\n\ndef gcd(a, b):\n \"\"\n while b:\n  a, b = b, a%b\n return a\n \n \n \n_PyHASH_MODULUS = sys.hash_info.modulus\n\n\n_PyHASH_INF = sys.hash_info.inf\n\n_RATIONAL_FORMAT = re.compile(r\"\"\"\n    \\A\\s*                      # optional whitespace at the start, then\n    (?P<sign>[-+]?)            # an optional sign, then\n    (?=\\d|\\.\\d)                # lookahead for digit or .digit\n    (?P<num>\\d*)               # numerator (possibly empty)\n    (?:                        # followed by\n       (?:/(?P<denom>\\d+))?    # an optional denominator\n    |                          # or\n       (?:\\.(?P<decimal>\\d*))? # an optional fractional part\n       (?:E(?P<exp>[-+]?\\d+))? # and optional exponent\n    )\n    \\s*\\Z                      # and optional whitespace to finish\n\"\"\", re.VERBOSE | re.IGNORECASE)\n\n\nclass Fraction(numbers.Rational):\n \"\"\n \n __slots__ = ('_numerator', '_denominator')\n \n \n def __new__(cls, numerator=0, denominator=None):\n  \"\"\n  self = super(Fraction, cls).__new__(cls)\n  \n  if denominator is None:\n   if isinstance(numerator, numbers.Rational):\n    self._numerator = numerator.numerator\n    self._denominator = numerator.denominator\n    return self\n    \n   elif isinstance(numerator, float):\n   \n    value = Fraction.from_float(numerator)\n    self._numerator = value._numerator\n    self._denominator = value._denominator\n    return self\n    \n   elif isinstance(numerator, Decimal):\n    value = Fraction.from_decimal(numerator)\n    self._numerator = value._numerator\n    self._denominator = value._denominator\n    return self\n    \n   elif isinstance(numerator, str):\n   \n    m = _RATIONAL_FORMAT.match(numerator)\n    if m is None:\n     raise ValueError('Invalid literal for Fraction: %r' %\n     numerator)\n    numerator = int(m.group('num') or '0')\n    denom = m.group('denom')\n    if denom:\n     denominator = int(denom)\n    else:\n     denominator = 1\n     decimal = m.group('decimal')\n     if decimal:\n      scale = 10**len(decimal)\n      numerator = numerator * scale + int(decimal)\n      denominator *= scale\n     exp = m.group('exp')\n     if exp:\n      exp = int(exp)\n      if exp >= 0:\n       numerator *= 10**exp\n      else:\n       denominator *= 10**-exp\n    if m.group('sign') == '-':\n     numerator = -numerator\n     \n   else:\n    raise TypeError(\"argument should be a string \"\n    \"or a Rational instance\")\n    \n  elif (isinstance(numerator, numbers.Rational) and\n  isinstance(denominator, numbers.Rational)):\n   numerator, denominator = (\n   numerator.numerator * denominator.denominator,\n   denominator.numerator * numerator.denominator\n   )\n  else:\n   raise TypeError(\"both arguments should be \"\n   \"Rational instances\")\n   \n  if denominator == 0:\n   raise ZeroDivisionError('Fraction(%s, 0)' % numerator)\n  g = gcd(numerator, denominator)\n  self._numerator = numerator // g\n  self._denominator = denominator // g\n  return self\n  \n @classmethod\n def from_float(cls, f):\n  \"\"\n  if isinstance(f, numbers.Integral):\n   return cls(f)\n  elif not isinstance(f, float):\n   raise TypeError(\"%s.from_float() only takes floats, not %r (%s)\" %\n   (cls.__name__, f, type(f).__name__))\n  if math.isnan(f):\n   raise ValueError(\"Cannot convert %r to %s.\" % (f, cls.__name__))\n  if math.isinf(f):\n   raise OverflowError(\"Cannot convert %r to %s.\" % (f, cls.__name__))\n  return cls(*f.as_integer_ratio())\n  \n @classmethod\n def from_decimal(cls, dec):\n  \"\"\n  from decimal import Decimal\n  if isinstance(dec, numbers.Integral):\n   dec = Decimal(int(dec))\n  elif not isinstance(dec, Decimal):\n   raise TypeError(\n   \"%s.from_decimal() only takes Decimals, not %r (%s)\" %\n   (cls.__name__, dec, type(dec).__name__))\n  if dec.is_infinite():\n   raise OverflowError(\n   \"Cannot convert %s to %s.\" % (dec, cls.__name__))\n  if dec.is_nan():\n   raise ValueError(\"Cannot convert %s to %s.\" % (dec, cls.__name__))\n  sign, digits, exp = dec.as_tuple()\n  digits = int(''.join(map(str, digits)))\n  if sign:\n   digits = -digits\n  if exp >= 0:\n   return cls(digits * 10 ** exp)\n  else:\n   return cls(digits, 10 ** -exp)\n   \n def limit_denominator(self, max_denominator=1000000):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  if max_denominator < 1:\n   raise ValueError(\"max_denominator should be at least 1\")\n  if self._denominator <= max_denominator:\n   return Fraction(self)\n   \n  p0, q0, p1, q1 = 0, 1, 1, 0\n  n, d = self._numerator, self._denominator\n  while True:\n   a = n//d\n   q2 = q0+a*q1\n   if q2 > max_denominator:\n    break\n   p0, q0, p1, q1 = p1, q1, p0+a*p1, q2\n   n, d = d, n-a*d\n   \n  k = (max_denominator-q0)//q1\n  bound1 = Fraction(p0+k*p1, q0+k*q1)\n  bound2 = Fraction(p1, q1)\n  if abs(bound2 - self) <= abs(bound1-self):\n   return bound2\n  else:\n   return bound1\n   \n @property\n def numerator(a):\n  return a._numerator\n  \n @property\n def denominator(a):\n  return a._denominator\n  \n def __repr__(self):\n  \"\"\n  return ('Fraction(%s, %s)' % (self._numerator, self._denominator))\n  \n def __str__(self):\n  \"\"\n  if self._denominator == 1:\n   return str(self._numerator)\n  else:\n   return '%s/%s' % (self._numerator, self._denominator)\n   \n def _operator_fallbacks(monomorphic_operator, fallback_operator):\n  \"\"\n  def forward(a, b):\n   if isinstance(b, (int, Fraction)):\n    return monomorphic_operator(a, b)\n   elif isinstance(b, float):\n    return fallback_operator(float(a), b)\n   elif isinstance(b, complex):\n    return fallback_operator(complex(a), b)\n   else:\n    return NotImplemented\n  forward.__name__ = '__' + fallback_operator.__name__ + '__'\n  forward.__doc__ = monomorphic_operator.__doc__\n  \n  def reverse(b, a):\n   if isinstance(a, numbers.Rational):\n   \n    return monomorphic_operator(a, b)\n   elif isinstance(a, numbers.Real):\n    return fallback_operator(float(a), float(b))\n   elif isinstance(a, numbers.Complex):\n    return fallback_operator(complex(a), complex(b))\n   else:\n    return NotImplemented\n  reverse.__name__ = '__r' + fallback_operator.__name__ + '__'\n  reverse.__doc__ = monomorphic_operator.__doc__\n  \n  return forward, reverse\n  \n def _add(a, b):\n  \"\"\n  return Fraction(a.numerator * b.denominator +\n  b.numerator * a.denominator,\n  a.denominator * b.denominator)\n  \n __add__, __radd__ = _operator_fallbacks(_add, operator.add)\n \n def _sub(a, b):\n  \"\"\n  return Fraction(a.numerator * b.denominator -\n  b.numerator * a.denominator,\n  a.denominator * b.denominator)\n  \n __sub__, __rsub__ = _operator_fallbacks(_sub, operator.sub)\n \n def _mul(a, b):\n  \"\"\n  return Fraction(a.numerator * b.numerator, a.denominator * b.denominator)\n  \n __mul__, __rmul__ = _operator_fallbacks(_mul, operator.mul)\n \n def _div(a, b):\n  \"\"\n  return Fraction(a.numerator * b.denominator,\n  a.denominator * b.numerator)\n  \n __truediv__, __rtruediv__ = _operator_fallbacks(_div, operator.truediv)\n \n def __floordiv__(a, b):\n  \"\"\n  return math.floor(a / b)\n  \n def __rfloordiv__(b, a):\n  \"\"\n  return math.floor(a / b)\n  \n def __mod__(a, b):\n  \"\"\n  div = a // b\n  return a - b * div\n  \n def __rmod__(b, a):\n  \"\"\n  div = a // b\n  return a - b * div\n  \n def __pow__(a, b):\n  \"\"\n  if isinstance(b, numbers.Rational):\n   if b.denominator == 1:\n    power = b.numerator\n    if power >= 0:\n     return Fraction(a._numerator ** power,\n     a._denominator ** power)\n    else:\n     return Fraction(a._denominator ** -power,\n     a._numerator ** -power)\n   else:\n   \n   \n    return float(a) ** float(b)\n  else:\n   return float(a) ** b\n   \n def __rpow__(b, a):\n  \"\"\n  if b._denominator == 1 and b._numerator >= 0:\n  \n   return a ** b._numerator\n   \n  if isinstance(a, numbers.Rational):\n   return Fraction(a.numerator, a.denominator) ** b\n   \n  if b._denominator == 1:\n   return a ** b._numerator\n   \n  return a ** float(b)\n  \n def __pos__(a):\n  \"\"\n  return Fraction(a._numerator, a._denominator)\n  \n def __neg__(a):\n  \"\"\n  return Fraction(-a._numerator, a._denominator)\n  \n def __abs__(a):\n  \"\"\n  return Fraction(abs(a._numerator), a._denominator)\n  \n def __trunc__(a):\n  \"\"\n  if a._numerator < 0:\n   return -(-a._numerator // a._denominator)\n  else:\n   return a._numerator // a._denominator\n   \n def __floor__(a):\n  \"\"\n  return a.numerator // a.denominator\n  \n def __ceil__(a):\n  \"\"\n  \n  return -(-a.numerator // a.denominator)\n  \n def __round__(self, ndigits=None):\n  \"\"\n  if ndigits is None:\n   floor, remainder = divmod(self.numerator, self.denominator)\n   if remainder * 2 < self.denominator:\n    return floor\n   elif remainder * 2 > self.denominator:\n    return floor + 1\n    \n   elif floor % 2 == 0:\n    return floor\n   else:\n    return floor + 1\n  shift = 10**abs(ndigits)\n  \n  \n  \n  if ndigits > 0:\n   return Fraction(round(self * shift), shift)\n  else:\n   return Fraction(round(self / shift) * shift)\n   \n def __hash__(self):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  dinv = pow(self._denominator, _PyHASH_MODULUS - 2, _PyHASH_MODULUS)\n  if not dinv:\n   hash_ = _PyHASH_INF\n  else:\n   hash_ = abs(self._numerator) * dinv % _PyHASH_MODULUS\n  result = hash_ if self >= 0 else -hash_\n  return -2 if result == -1 else result\n  \n def __eq__(a, b):\n  \"\"\n  if isinstance(b, numbers.Rational):\n   return (a._numerator == b.numerator and\n   a._denominator == b.denominator)\n  if isinstance(b, numbers.Complex) and b.imag == 0:\n   b = b.real\n  if isinstance(b, float):\n   if math.isnan(b) or math.isinf(b):\n   \n   \n    return 0.0 == b\n   else:\n    return a == a.from_float(b)\n  else:\n  \n  \n   return NotImplemented\n   \n def _richcmp(self, other, op):\n  \"\"\n  \n  if isinstance(other, numbers.Rational):\n   return op(self._numerator * other.denominator,\n   self._denominator * other.numerator)\n  if isinstance(other, float):\n   if math.isnan(other) or math.isinf(other):\n    return op(0.0, other)\n   else:\n    return op(self, self.from_float(other))\n  else:\n   return NotImplemented\n   \n def __lt__(a, b):\n  \"\"\n  return a._richcmp(b, operator.lt)\n  \n def __gt__(a, b):\n  \"\"\n  return a._richcmp(b, operator.gt)\n  \n def __le__(a, b):\n  \"\"\n  return a._richcmp(b, operator.le)\n  \n def __ge__(a, b):\n  \"\"\n  return a._richcmp(b, operator.ge)\n  \n def __bool__(a):\n  \"\"\n  return a._numerator != 0\n  \n  \n  \n def __reduce__(self):\n  return (self.__class__, (str(self),))\n  \n def __copy__(self):\n  if type(self) == Fraction:\n   return self \n  return self.__class__(self._numerator, self._denominator)\n  \n def __deepcopy__(self, memo):\n  if type(self) == Fraction:\n   return self \n  return self.__class__(self._numerator, self._denominator)\n"], "xml.dom.NodeFilter": [".py", "\n\n\nclass NodeFilter:\n \"\"\n FILTER_ACCEPT = 1\n FILTER_REJECT = 2\n FILTER_SKIP = 3\n \n SHOW_ALL = 0xFFFFFFFF\n SHOW_ELEMENT = 0x00000001\n SHOW_ATTRIBUTE = 0x00000002\n SHOW_TEXT = 0x00000004\n SHOW_CDATA_SECTION = 0x00000008\n SHOW_ENTITY_REFERENCE = 0x00000010\n SHOW_ENTITY = 0x00000020\n SHOW_PROCESSING_INSTRUCTION = 0x00000040\n SHOW_COMMENT = 0x00000080\n SHOW_DOCUMENT = 0x00000100\n SHOW_DOCUMENT_TYPE = 0x00000200\n SHOW_DOCUMENT_FRAGMENT = 0x00000400\n SHOW_NOTATION = 0x00000800\n \n def acceptNode(self, node):\n  raise NotImplementedError\n"], "__random": [".js", "$module = (function($B){\n\n    var _b_ = $B.builtins\n    var $s=[]\n    for(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\n    eval($s.join(';'))\n\n    //for(var $py_builtin in _b_){eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")}\n    \n    return {\n        choice:function(seq){\n            var rank = parseInt(getattr(seq,'__len__')()*Math.random())\n            return getattr(seq,'__getitem__')(rank)\n        },\n        random:function(){\n          if(arguments.length > 0){\n            throw TypeError(\"random() takes no arguments (\"+arguments.length+\" given)\")\n          } else {\n            return float(Math.random());\n          }\n        },\n        randint:function(a,b){\n           if (a == undefined) throw _b_.TypeError(\"randint missing 2 required positional arguments: 'a' and 'b'\");\n           if (b == undefined) throw _b_.TypeError(\"randint missing 1 required positional argument: 'b'\");\n\n           if (!(isinstance(a, _b_.int) || isinstance(b, _b_.int))) throw _b_.ValueError(\"non-integer arg 1 for randrange\")\n\n           return int(Math.floor(Math.random()*(b-a+1)+a))\n        },\n        randrange:function(start,stop,step){\n          if(step === undefined) {\n            step=1;\n          } else if(step == 0) { \n            //raise ValueError(\"zero step for randrange()\");\n          }\n    \n          if(stop === undefined) {\n             stop=start;\n             start=0;\n          }\n          var width=stop-start;\n          if (step==1 && width > 0) {\n            return start + int(Math.floor(Math.random()*width));\n          } else {\n            // raise ValueError(\"empty range for randrange() (\"+start+\",\"+stop+','+step+')');\n          }\n          \n          var n;\n          if (step > 0) {\n             n=Math.floor((width+step-1)/step);\n          } else {\n             n=Math.floor((width+step+1)/step);\n          }\n          return start + step*int(Math.floor(Math.random()*n))\n          //return int(Math.random()*(stop/step-start/step)*step + start)\n        },\n        shuffle:function(x, rnd){\n          if (x.length <= 1) { return x}\n    \n          if (rnd === undefined) {\n             rnd=Math.random\n          }\n    \n          for(var j, o, i = x.length; i; j = parseInt(rnd() * i), o = x[--i], x[i] = x[j], x[j] = o);\n        }\n    }\n\n})(__BRYTHON__)\n"], "xml.etree.ElementInclude": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport copy\nfrom . import ElementTree\n\nXINCLUDE = \"{http://www.w3.org/2001/XInclude}\"\n\nXINCLUDE_INCLUDE = XINCLUDE + \"include\"\nXINCLUDE_FALLBACK = XINCLUDE + \"fallback\"\n\n\n\n\nclass FatalIncludeError(SyntaxError):\n pass\n \n \n \n \n \n \n \n \n \n \n \n \n \ndef default_loader(href, parse, encoding=None):\n if parse == \"xml\":\n  file = open(href, 'rb')\n  data = ElementTree.parse(file).getroot()\n else:\n  if not encoding:\n   encoding = 'UTF-8'\n  file = open(href, 'r', encoding=encoding)\n  data = file.read()\n file.close()\n return data\n \n \n \n \n \n \n \n \n \n \n \n \ndef include(elem, loader=None):\n if loader is None:\n  loader = default_loader\n  \n i = 0\n while i < len(elem):\n  e = elem[i]\n  if e.tag == XINCLUDE_INCLUDE:\n  \n   href = e.get(\"href\")\n   parse = e.get(\"parse\", \"xml\")\n   if parse == \"xml\":\n    node = loader(href, parse)\n    if node is None:\n     raise FatalIncludeError(\n     \"cannot load %r as %r\" % (href, parse)\n     )\n    node = copy.copy(node)\n    if e.tail:\n     node.tail = (node.tail or \"\") + e.tail\n    elem[i] = node\n   elif parse == \"text\":\n    text = loader(href, parse, e.get(\"encoding\"))\n    if text is None:\n     raise FatalIncludeError(\n     \"cannot load %r as %r\" % (href, parse)\n     )\n    if i:\n     node = elem[i-1]\n     node.tail = (node.tail or \"\") + text + (e.tail or \"\")\n    else:\n     elem.text = (elem.text or \"\") + text + (e.tail or \"\")\n    del elem[i]\n    continue\n   else:\n    raise FatalIncludeError(\n    \"unknown parse type in xi:include tag (%r)\" % parse\n    )\n  elif e.tag == XINCLUDE_FALLBACK:\n   raise FatalIncludeError(\n   \"xi:fallback tag must be child of xi:include (%r)\" % e.tag\n   )\n  else:\n   include(e, loader)\n  i = i + 1\n"], "site-packages.test_sp": [".py", "test = \"site package\"\n"], "_codecs": [".py", "\ndef ascii_decode(*args,**kw):\n pass\n \ndef ascii_encode(*args,**kw):\n pass\n \ndef charbuffer_encode(*args,**kw):\n pass\n \ndef charmap_build(*args,**kw):\n pass\n \ndef charmap_decode(*args,**kw):\n pass\n \ndef charmap_encode(*args,**kw):\n pass\n \ndef decode(*args,**kw):\n \"\"\n pass\n \ndef encode(*args,**kw):\n \"\"\n pass\n \ndef escape_decode(*args,**kw):\n pass\n \ndef escape_encode(*args,**kw):\n pass\n \ndef latin_1_decode(*args,**kw):\n pass\n \ndef latin_1_encode(*args,**kw):\n pass\n \ndef lookup(encoding):\n \"\"\n \n if encoding in ('utf-8', 'utf_8'):\n  from javascript import console\n  console.log('encoding', encoding)\n  import encodings.utf_8\n  return encodings.utf_8.getregentry()\n  \n LookupError(encoding)\n \ndef lookup_error(*args,**kw):\n \"\"\n pass\n \ndef mbcs_decode(*args,**kw):\n pass\n \ndef mbcs_encode(*args,**kw):\n pass\n \ndef raw_unicode_escape_decode(*args,**kw):\n pass\n \ndef raw_unicode_escape_encode(*args,**kw):\n pass\n \ndef readbuffer_encode(*args,**kw):\n pass\n \ndef register(*args,**kw):\n \"\"\n pass\n \ndef register_error(*args,**kw):\n \"\"\n pass\n \ndef unicode_escape_decode(*args,**kw):\n pass\n \ndef unicode_escape_encode(*args,**kw):\n pass\n \ndef unicode_internal_decode(*args,**kw):\n pass\n \ndef unicode_internal_encode(*args,**kw):\n pass\n \ndef utf_16_be_decode(*args,**kw):\n pass\n \ndef utf_16_be_encode(*args,**kw):\n pass\n \ndef utf_16_decode(*args,**kw):\n pass\n \ndef utf_16_encode(*args,**kw):\n pass\n \ndef utf_16_ex_decode(*args,**kw):\n pass\n \ndef utf_16_le_decode(*args,**kw):\n pass\n \ndef utf_16_le_encode(*args,**kw):\n pass\n \ndef utf_32_be_decode(*args,**kw):\n pass\n \ndef utf_32_be_encode(*args,**kw):\n pass\n \ndef utf_32_decode(*args,**kw):\n pass\n \ndef utf_32_encode(*args,**kw):\n pass\n \ndef utf_32_ex_decode(*args,**kw):\n pass\n \ndef utf_32_le_decode(*args,**kw):\n pass\n \ndef utf_32_le_encode(*args,**kw):\n pass\n \ndef utf_7_decode(*args,**kw):\n pass\n \ndef utf_7_encode(*args,**kw):\n pass\n \ndef utf_8_decode(*args,**kw):\n pass\n \ndef utf_8_encode(*args,**kw):\n input=args[0]\n if len(args) == 2:\n  errors = args[1]\n else:\n  errors=kw.get('errors', 'strict')\n  \n  \n  \n return (bytes([_f for _f in input], 'utf-8'), len(input))\n"], "xml.etree.ElementTree": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n__all__ = [\n\n\"Comment\",\n\"dump\",\n\"Element\", \"ElementTree\",\n\"fromstring\", \"fromstringlist\",\n\"iselement\", \"iterparse\",\n\"parse\", \"ParseError\",\n\"PI\", \"ProcessingInstruction\",\n\"QName\",\n\"SubElement\",\n\"tostring\", \"tostringlist\",\n\"TreeBuilder\",\n\"VERSION\",\n\"XML\", \"XMLID\",\n\"XMLParser\", \"XMLTreeBuilder\",\n\"register_namespace\",\n]\n\nVERSION = \"1.3.0\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport sys\nimport re\nimport warnings\nimport io\nimport contextlib\n\nfrom . import ElementPath\n\n\n\n\n\n\n\n\n\nclass ParseError(SyntaxError):\n pass\n \n \n \n \n \n \n \n \n \n \ndef iselement(element):\n\n\n return hasattr(element, 'tag')\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nclass Element:\n\n\n\n\n\n tag = None\n \n \n \n \n \n \n \n \n \n attrib = None\n \n \n \n \n \n \n \n text = None\n \n \n \n \n \n \n \n tail = None \n \n \n \n def __init__(self, tag, attrib={}, **extra):\n  if not isinstance(attrib, dict):\n   raise TypeError(\"attrib must be dict, not %s\" % (\n   attrib.__class__.__name__,))\n  attrib = attrib.copy()\n  attrib.update(extra)\n  self.tag = tag\n  self.attrib = attrib\n  self._children = []\n  \n def __repr__(self):\n  return \"<Element %s at 0x%x>\" % (repr(self.tag), id(self))\n  \n  \n  \n  \n  \n  \n  \n  \n def makeelement(self, tag, attrib):\n  return self.__class__(tag, attrib)\n  \n  \n  \n  \n  \n  \n  \n def copy(self):\n  elem = self.makeelement(self.tag, self.attrib)\n  elem.text = self.text\n  elem.tail = self.tail\n  elem[:] = self\n  return elem\n  \n  \n  \n  \n  \n  \n  \n  \n def __len__(self):\n  return len(self._children)\n  \n def __bool__(self):\n  warnings.warn(\n  \"The behavior of this method will change in future versions.  \"\n  \"Use specific 'len(elem)' or 'elem is not None' test instead.\",\n  FutureWarning, stacklevel=2\n  )\n  return len(self._children) != 0 \n  \n  \n  \n  \n  \n  \n  \n  \n def __getitem__(self, index):\n  return self._children[index]\n  \n  \n  \n  \n  \n  \n  \n  \n def __setitem__(self, index, element):\n \n \n \n \n \n  self._children[index] = element\n  \n  \n  \n  \n  \n  \n  \n def __delitem__(self, index):\n  del self._children[index]\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def append(self, element):\n  self._assert_is_element(element)\n  self._children.append(element)\n  \n  \n  \n  \n  \n  \n  \n def extend(self, elements):\n  for element in elements:\n   self._assert_is_element(element)\n  self._children.extend(elements)\n  \n  \n  \n  \n  \n  \n def insert(self, index, element):\n  self._assert_is_element(element)\n  self._children.insert(index, element)\n  \n def _assert_is_element(self, e):\n \n \n  if not isinstance(e, _Element):\n   raise TypeError('expected an Element, not %s' % type(e).__name__)\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n def remove(self, element):\n \n  self._children.remove(element)\n  \n  \n  \n  \n  \n  \n  \n  \n def getchildren(self):\n  warnings.warn(\n  \"This method will be removed in future versions.  \"\n  \"Use 'list(elem)' or iteration over elem instead.\",\n  DeprecationWarning, stacklevel=2\n  )\n  return self._children\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def find(self, path, namespaces=None):\n  return ElementPath.find(self, path, namespaces)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def findtext(self, path, default=None, namespaces=None):\n  return ElementPath.findtext(self, path, default, namespaces)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def findall(self, path, namespaces=None):\n  return ElementPath.findall(self, path, namespaces)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def iterfind(self, path, namespaces=None):\n  return ElementPath.iterfind(self, path, namespaces)\n  \n  \n  \n  \n  \n  \n def clear(self):\n  self.attrib.clear()\n  self._children = []\n  self.text = self.tail = None\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def get(self, key, default=None):\n  return self.attrib.get(key, default)\n  \n  \n  \n  \n  \n  \n  \n  \n def set(self, key, value):\n  self.attrib[key] = value\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def keys(self):\n  return self.attrib.keys()\n  \n  \n  \n  \n  \n  \n  \n  \n def items(self):\n  return self.attrib.items()\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def iter(self, tag=None):\n  if tag == \"*\":\n   tag = None\n  if tag is None or self.tag == tag:\n   yield self\n  for e in self._children:\n   for e in e.iter(tag):\n    yield e\n    \n    \n def getiterator(self, tag=None):\n \n  warnings.warn(\n  \"This method will be removed in future versions.  \"\n  \"Use 'elem.iter()' or 'list(elem.iter())' instead.\",\n  PendingDeprecationWarning, stacklevel=2\n  )\n  return list(self.iter(tag))\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def itertext(self):\n  tag = self.tag\n  if not isinstance(tag, str) and tag is not None:\n   return\n  if self.text:\n   yield self.text\n  for e in self:\n   for s in e.itertext():\n    yield s\n   if e.tail:\n    yield e.tail\n    \n    \n_Element = _ElementInterface = Element\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef SubElement(parent, tag, attrib={}, **extra):\n attrib = attrib.copy()\n attrib.update(extra)\n element = parent.makeelement(tag, attrib)\n parent.append(element)\n return element\n \n \n \n \n \n \n \n \n \n \n \n \n \ndef Comment(text=None):\n element = Element(Comment)\n element.text = text\n return element\n \n \n \n \n \n \n \n \n \n \n \ndef ProcessingInstruction(target, text=None):\n element = Element(ProcessingInstruction)\n element.text = target\n if text:\n  element.text = element.text + \" \" + text\n return element\n \nPI = ProcessingInstruction\n\n\n\n\n\n\n\n\n\n\n\nclass QName:\n def __init__(self, text_or_uri, tag=None):\n  if tag:\n   text_or_uri = \"{%s}%s\" % (text_or_uri, tag)\n  self.text = text_or_uri\n def __str__(self):\n  return self.text\n def __repr__(self):\n  return '<QName %r>' % (self.text,)\n def __hash__(self):\n  return hash(self.text)\n def __le__(self, other):\n  if isinstance(other, QName):\n   return self.text <= other.text\n  return self.text <= other\n def __lt__(self, other):\n  if isinstance(other, QName):\n   return self.text < other.text\n  return self.text < other\n def __ge__(self, other):\n  if isinstance(other, QName):\n   return self.text >= other.text\n  return self.text >= other\n def __gt__(self, other):\n  if isinstance(other, QName):\n   return self.text > other.text\n  return self.text > other\n def __eq__(self, other):\n  if isinstance(other, QName):\n   return self.text == other.text\n  return self.text == other\n def __ne__(self, other):\n  if isinstance(other, QName):\n   return self.text != other.text\n  return self.text != other\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \nclass ElementTree:\n\n def __init__(self, element=None, file=None):\n \n  self._root = element \n  if file:\n   self.parse(file)\n   \n   \n   \n   \n   \n   \n   \n def getroot(self):\n  return self._root\n  \n  \n  \n  \n  \n  \n  \n  \n def _setroot(self, element):\n \n  self._root = element\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def parse(self, source, parser=None):\n  close_source = False\n  if not hasattr(source, \"read\"):\n   source = open(source, \"rb\")\n   close_source = True\n  try:\n   if not parser:\n    parser = XMLParser(target=TreeBuilder())\n   while 1:\n    data = source.read(65536)\n    if not data:\n     break\n    parser.feed(data)\n   self._root = parser.close()\n   return self._root\n  finally:\n   if close_source:\n    source.close()\n    \n    \n    \n    \n    \n    \n    \n    \n    \n def iter(self, tag=None):\n \n  return self._root.iter(tag)\n  \n  \n def getiterator(self, tag=None):\n \n  warnings.warn(\n  \"This method will be removed in future versions.  \"\n  \"Use 'tree.iter()' or 'list(tree.iter())' instead.\",\n  PendingDeprecationWarning, stacklevel=2\n  )\n  return list(self.iter(tag))\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def find(self, path, namespaces=None):\n \n  if path[:1] == \"/\":\n   path = \".\" + path\n   warnings.warn(\n   \"This search is broken in 1.3 and earlier, and will be \"\n   \"fixed in a future version.  If you rely on the current \"\n   \"behaviour, change it to %r\" % path,\n   FutureWarning, stacklevel=2\n   )\n  return self._root.find(path, namespaces)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def findtext(self, path, default=None, namespaces=None):\n \n  if path[:1] == \"/\":\n   path = \".\" + path\n   warnings.warn(\n   \"This search is broken in 1.3 and earlier, and will be \"\n   \"fixed in a future version.  If you rely on the current \"\n   \"behaviour, change it to %r\" % path,\n   FutureWarning, stacklevel=2\n   )\n  return self._root.findtext(path, default, namespaces)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def findall(self, path, namespaces=None):\n \n  if path[:1] == \"/\":\n   path = \".\" + path\n   warnings.warn(\n   \"This search is broken in 1.3 and earlier, and will be \"\n   \"fixed in a future version.  If you rely on the current \"\n   \"behaviour, change it to %r\" % path,\n   FutureWarning, stacklevel=2\n   )\n  return self._root.findall(path, namespaces)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def iterfind(self, path, namespaces=None):\n \n  if path[:1] == \"/\":\n   path = \".\" + path\n   warnings.warn(\n   \"This search is broken in 1.3 and earlier, and will be \"\n   \"fixed in a future version.  If you rely on the current \"\n   \"behaviour, change it to %r\" % path,\n   FutureWarning, stacklevel=2\n   )\n  return self._root.iterfind(path, namespaces)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def write(self, file_or_filename,\n encoding=None,\n xml_declaration=None,\n default_namespace=None,\n method=None):\n  if not method:\n   method = \"xml\"\n  elif method not in _serialize:\n   raise ValueError(\"unknown method %r\" % method)\n  if not encoding:\n   if method == \"c14n\":\n    encoding = \"utf-8\"\n   else:\n    encoding = \"us-ascii\"\n  else:\n   encoding = encoding.lower()\n  with _get_writer(file_or_filename, encoding) as write:\n   if method == \"xml\" and (xml_declaration or\n   (xml_declaration is None and\n   encoding not in (\"utf-8\", \"us-ascii\", \"unicode\"))):\n    declared_encoding = encoding\n    if encoding == \"unicode\":\n    \n     import locale\n     declared_encoding = locale.getpreferredencoding()\n    write(\"<?xml version='1.0' encoding='%s'?>\\n\" % (\n    declared_encoding,))\n   if method == \"text\":\n    _serialize_text(write, self._root)\n   else:\n    qnames, namespaces = _namespaces(self._root, default_namespace)\n    serialize = _serialize[method]\n    serialize(write, self._root, qnames, namespaces)\n    \n def write_c14n(self, file):\n \n  return self.write(file, method=\"c14n\")\n  \n  \n  \n  \n@contextlib.contextmanager\ndef _get_writer(file_or_filename, encoding):\n\n try:\n  write = file_or_filename.write\n except AttributeError:\n \n  if encoding == \"unicode\":\n   file = open(file_or_filename, \"w\")\n  else:\n   file = open(file_or_filename, \"w\", encoding=encoding,\n   errors=\"xmlcharrefreplace\")\n  with file:\n   yield file.write\n else:\n \n \n  if encoding == \"unicode\":\n  \n   yield write\n  else:\n  \n   with contextlib.ExitStack() as stack:\n    if isinstance(file_or_filename, io.BufferedIOBase):\n     file = file_or_filename\n    elif isinstance(file_or_filename, io.RawIOBase):\n     file = io.BufferedWriter(file_or_filename)\n     \n     \n     stack.callback(file.detach)\n    else:\n    \n    \n     file = io.BufferedIOBase()\n     file.writable = lambda: True\n     file.write = write\n     try:\n     \n     \n      file.seekable = file_or_filename.seekable\n      file.tell = file_or_filename.tell\n     except AttributeError:\n      pass\n    file = io.TextIOWrapper(file,\n    encoding=encoding,\n    errors=\"xmlcharrefreplace\",\n    newline=\"\\n\")\n    \n    \n    stack.callback(file.detach)\n    yield file.write\n    \ndef _namespaces(elem, default_namespace=None):\n\n\n\n qnames = {None: None}\n \n \n namespaces = {}\n if default_namespace:\n  namespaces[default_namespace] = \"\"\n  \n def add_qname(qname):\n \n  try:\n   if qname[:1] == \"{\":\n    uri, tag = qname[1:].rsplit(\"}\", 1)\n    prefix = namespaces.get(uri)\n    if prefix is None:\n     prefix = _namespace_map.get(uri)\n     if prefix is None:\n      prefix = \"ns%d\" % len(namespaces)\n     if prefix != \"xml\":\n      namespaces[uri] = prefix\n    if prefix:\n     qnames[qname] = \"%s:%s\" % (prefix, tag)\n    else:\n     qnames[qname] = tag \n   else:\n    if default_namespace:\n    \n     raise ValueError(\n     \"cannot use non-qualified names with \"\n     \"default_namespace option\"\n     )\n    qnames[qname] = qname\n  except TypeError:\n   _raise_serialization_error(qname)\n   \n   \n for elem in elem.iter():\n  tag = elem.tag\n  if isinstance(tag, QName):\n   if tag.text not in qnames:\n    add_qname(tag.text)\n  elif isinstance(tag, str):\n   if tag not in qnames:\n    add_qname(tag)\n  elif tag is not None and tag is not Comment and tag is not PI:\n   _raise_serialization_error(tag)\n  for key, value in elem.items():\n   if isinstance(key, QName):\n    key = key.text\n   if key not in qnames:\n    add_qname(key)\n   if isinstance(value, QName) and value.text not in qnames:\n    add_qname(value.text)\n  text = elem.text\n  if isinstance(text, QName) and text.text not in qnames:\n   add_qname(text.text)\n return qnames, namespaces\n \ndef _serialize_xml(write, elem, qnames, namespaces):\n tag = elem.tag\n text = elem.text\n if tag is Comment:\n  write(\"<!--%s-->\" % text)\n elif tag is ProcessingInstruction:\n  write(\"<?%s?>\" % text)\n else:\n  tag = qnames[tag]\n  if tag is None:\n   if text:\n    write(_escape_cdata(text))\n   for e in elem:\n    _serialize_xml(write, e, qnames, None)\n  else:\n   write(\"<\" + tag)\n   items = list(elem.items())\n   if items or namespaces:\n    if namespaces:\n     for v, k in sorted(namespaces.items(),\n     key=lambda x: x[1]): \n      if k:\n       k = \":\" + k\n      write(\" xmlns%s=\\\"%s\\\"\" % (\n      k,\n      _escape_attrib(v)\n      ))\n    for k, v in sorted(items): \n     if isinstance(k, QName):\n      k = k.text\n     if isinstance(v, QName):\n      v = qnames[v.text]\n     else:\n      v = _escape_attrib(v)\n     write(\" %s=\\\"%s\\\"\" % (qnames[k], v))\n   if text or len(elem):\n    write(\">\")\n    if text:\n     write(_escape_cdata(text))\n    for e in elem:\n     _serialize_xml(write, e, qnames, None)\n    write(\"</\" + tag + \">\")\n   else:\n    write(\" />\")\n if elem.tail:\n  write(_escape_cdata(elem.tail))\n  \nHTML_EMPTY = (\"area\", \"base\", \"basefont\", \"br\", \"col\", \"frame\", \"hr\",\n\"img\", \"input\", \"isindex\", \"link\", \"meta\", \"param\")\n\ntry:\n HTML_EMPTY = set(HTML_EMPTY)\nexcept NameError:\n pass\n \ndef _serialize_html(write, elem, qnames, namespaces):\n tag = elem.tag\n text = elem.text\n if tag is Comment:\n  write(\"<!--%s-->\" % _escape_cdata(text))\n elif tag is ProcessingInstruction:\n  write(\"<?%s?>\" % _escape_cdata(text))\n else:\n  tag = qnames[tag]\n  if tag is None:\n   if text:\n    write(_escape_cdata(text))\n   for e in elem:\n    _serialize_html(write, e, qnames, None)\n  else:\n   write(\"<\" + tag)\n   items = list(elem.items())\n   if items or namespaces:\n    if namespaces:\n     for v, k in sorted(namespaces.items(),\n     key=lambda x: x[1]): \n      if k:\n       k = \":\" + k\n      write(\" xmlns%s=\\\"%s\\\"\" % (\n      k,\n      _escape_attrib(v)\n      ))\n    for k, v in sorted(items): \n     if isinstance(k, QName):\n      k = k.text\n     if isinstance(v, QName):\n      v = qnames[v.text]\n     else:\n      v = _escape_attrib_html(v)\n      \n     write(\" %s=\\\"%s\\\"\" % (qnames[k], v))\n   write(\">\")\n   tag = tag.lower()\n   if text:\n    if tag == \"script\" or tag == \"style\":\n     write(text)\n    else:\n     write(_escape_cdata(text))\n   for e in elem:\n    _serialize_html(write, e, qnames, None)\n   if tag not in HTML_EMPTY:\n    write(\"</\" + tag + \">\")\n if elem.tail:\n  write(_escape_cdata(elem.tail))\n  \ndef _serialize_text(write, elem):\n for part in elem.itertext():\n  write(part)\n if elem.tail:\n  write(elem.tail)\n  \n_serialize = {\n\"xml\": _serialize_xml,\n\"html\": _serialize_html,\n\"text\": _serialize_text,\n\n\n}\n\n\n\n\n\n\n\n\n\n\n\n\ndef register_namespace(prefix, uri):\n if re.match(\"ns\\d+$\", prefix):\n  raise ValueError(\"Prefix format reserved for internal use\")\n for k, v in list(_namespace_map.items()):\n  if k == uri or v == prefix:\n   del _namespace_map[k]\n _namespace_map[uri] = prefix\n \n_namespace_map = {\n\n\"http://www.w3.org/XML/1998/namespace\": \"xml\",\n\"http://www.w3.org/1999/xhtml\": \"html\",\n\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\": \"rdf\",\n\"http://schemas.xmlsoap.org/wsdl/\": \"wsdl\",\n\n\"http://www.w3.org/2001/XMLSchema\": \"xs\",\n\"http://www.w3.org/2001/XMLSchema-instance\": \"xsi\",\n\n\"http://purl.org/dc/elements/1.1/\": \"dc\",\n}\n\nregister_namespace._namespace_map = _namespace_map\n\ndef _raise_serialization_error(text):\n raise TypeError(\n \"cannot serialize %r (type %s)\" % (text, type(text).__name__)\n )\n \ndef _escape_cdata(text):\n\n try:\n \n \n \n  if \"&\" in text:\n   text = text.replace(\"&\", \"&amp;\")\n  if \"<\" in text:\n   text = text.replace(\"<\", \"&lt;\")\n  if \">\" in text:\n   text = text.replace(\">\", \"&gt;\")\n  return text\n except (TypeError, AttributeError):\n  _raise_serialization_error(text)\n  \ndef _escape_attrib(text):\n\n try:\n  if \"&\" in text:\n   text = text.replace(\"&\", \"&amp;\")\n  if \"<\" in text:\n   text = text.replace(\"<\", \"&lt;\")\n  if \">\" in text:\n   text = text.replace(\">\", \"&gt;\")\n  if \"\\\"\" in text:\n   text = text.replace(\"\\\"\", \"&quot;\")\n  if \"\\n\" in text:\n   text = text.replace(\"\\n\", \"&#10;\")\n  return text\n except (TypeError, AttributeError):\n  _raise_serialization_error(text)\n  \ndef _escape_attrib_html(text):\n\n try:\n  if \"&\" in text:\n   text = text.replace(\"&\", \"&amp;\")\n  if \">\" in text:\n   text = text.replace(\">\", \"&gt;\")\n  if \"\\\"\" in text:\n   text = text.replace(\"\\\"\", \"&quot;\")\n  return text\n except (TypeError, AttributeError):\n  _raise_serialization_error(text)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \ndef tostring(element, encoding=None, method=None):\n stream = io.StringIO() if encoding == 'unicode' else io.BytesIO()\n ElementTree(element).write(stream, encoding, method=method)\n return stream.getvalue()\n \n \n \n \n \n \n \n \n \n \n \n \n \n \nclass _ListDataStream(io.BufferedIOBase):\n \"\"\n def __init__(self, lst):\n  self.lst = lst\n  \n def writable(self):\n  return True\n  \n def seekable(self):\n  return True\n  \n def write(self, b):\n  self.lst.append(b)\n  \n def tell(self):\n  return len(self.lst)\n  \ndef tostringlist(element, encoding=None, method=None):\n lst = []\n stream = _ListDataStream(lst)\n ElementTree(element).write(stream, encoding, method=method)\n return lst\n \n \n \n \n \n \n \n \n \n \ndef dump(elem):\n\n if not isinstance(elem, ElementTree):\n  elem = ElementTree(elem)\n elem.write(sys.stdout, encoding=\"unicode\")\n tail = elem.getroot().tail\n if not tail or tail[-1] != \"\\n\":\n  sys.stdout.write(\"\\n\")\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \ndef parse(source, parser=None):\n tree = ElementTree()\n tree.parse(source, parser)\n return tree\n \n \n \n \n \n \n \n \n \n \n \n \ndef iterparse(source, events=None, parser=None):\n close_source = False\n if not hasattr(source, \"read\"):\n  source = open(source, \"rb\")\n  close_source = True\n if not parser:\n  parser = XMLParser(target=TreeBuilder())\n return _IterParseIterator(source, events, parser, close_source)\n \nclass _IterParseIterator:\n\n def __init__(self, source, events, parser, close_source=False):\n  self._file = source\n  self._close_file = close_source\n  self._events = []\n  self._index = 0\n  self._error = None\n  self.root = self._root = None\n  self._parser = parser\n  \n  parser = self._parser._parser\n  append = self._events.append\n  if events is None:\n   events = [\"end\"]\n  for event in events:\n   if event == \"start\":\n    try:\n     parser.ordered_attributes = 1\n     parser.specified_attributes = 1\n     def handler(tag, attrib_in, event=event, append=append,\n     start=self._parser._start_list):\n      append((event, start(tag, attrib_in)))\n     parser.StartElementHandler = handler\n    except AttributeError:\n     def handler(tag, attrib_in, event=event, append=append,\n     start=self._parser._start):\n      append((event, start(tag, attrib_in)))\n     parser.StartElementHandler = handler\n   elif event == \"end\":\n    def handler(tag, event=event, append=append,\n    end=self._parser._end):\n     append((event, end(tag)))\n    parser.EndElementHandler = handler\n   elif event == \"start-ns\":\n    def handler(prefix, uri, event=event, append=append):\n     append((event, (prefix or \"\", uri or \"\")))\n    parser.StartNamespaceDeclHandler = handler\n   elif event == \"end-ns\":\n    def handler(prefix, event=event, append=append):\n     append((event, None))\n    parser.EndNamespaceDeclHandler = handler\n   else:\n    raise ValueError(\"unknown event %r\" % event)\n    \n def __next__(self):\n  while 1:\n   try:\n    item = self._events[self._index]\n    self._index += 1\n    return item\n   except IndexError:\n    pass\n   if self._error:\n    e = self._error\n    self._error = None\n    raise e\n   if self._parser is None:\n    self.root = self._root\n    if self._close_file:\n     self._file.close()\n    raise StopIteration\n    \n   del self._events[:]\n   self._index = 0\n   data = self._file.read(16384)\n   if data:\n    try:\n     self._parser.feed(data)\n    except SyntaxError as exc:\n     self._error = exc\n   else:\n    self._root = self._parser.close()\n    self._parser = None\n    \n def __iter__(self):\n  return self\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \ndef XML(text, parser=None):\n if not parser:\n  parser = XMLParser(target=TreeBuilder())\n parser.feed(text)\n return parser.close()\n \n \n \n \n \n \n \n \n \n \n \ndef XMLID(text, parser=None):\n if not parser:\n  parser = XMLParser(target=TreeBuilder())\n parser.feed(text)\n tree = parser.close()\n ids = {}\n for elem in tree.iter():\n  id = elem.get(\"id\")\n  if id:\n   ids[id] = elem\n return tree, ids\n \n \n \n \n \n \n \n \n \nfromstring = XML\n\n\n\n\n\n\n\n\n\n\n\ndef fromstringlist(sequence, parser=None):\n if not parser:\n  parser = XMLParser(target=TreeBuilder())\n for text in sequence:\n  parser.feed(text)\n return parser.close()\n \n \n \n \n \n \n \n \n \n \n \n \n \n \nclass TreeBuilder:\n\n def __init__(self, element_factory=None):\n  self._data = [] \n  self._elem = [] \n  self._last = None \n  self._tail = None \n  if element_factory is None:\n   element_factory = Element\n  self._factory = element_factory\n  \n  \n  \n  \n  \n  \n  \n  \n def close(self):\n  assert len(self._elem) == 0, \"missing end tags\"\n  assert self._last is not None, \"missing toplevel element\"\n  return self._last\n  \n def _flush(self):\n  if self._data:\n   if self._last is not None:\n    text = \"\".join(self._data)\n    if self._tail:\n     assert self._last.tail is None, \"internal error (tail)\"\n     self._last.tail = text\n    else:\n     assert self._last.text is None, \"internal error (text)\"\n     self._last.text = text\n   self._data = []\n   \n   \n   \n   \n   \n   \n   \n def data(self, data):\n  self._data.append(data)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def start(self, tag, attrs):\n  self._flush()\n  self._last = elem = self._factory(tag, attrs)\n  if self._elem:\n   self._elem[-1].append(elem)\n  self._elem.append(elem)\n  self._tail = 0\n  return elem\n  \n  \n  \n  \n  \n  \n  \n  \n def end(self, tag):\n  self._flush()\n  self._last = self._elem.pop()\n  assert self._last.tag == tag, \"end tag mismatch (expected %s, got %s)\" % (\n  self._last.tag, tag)\n  self._tail = 1\n  return self._last\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \nclass XMLParser:\n\n def __init__(self, html=0, target=None, encoding=None):\n  try:\n   from xml.parsers import expat\n  except ImportError:\n   try:\n    import pyexpat as expat\n   except ImportError:\n    raise ImportError(\n    \"No module named expat; use SimpleXMLTreeBuilder instead\"\n    )\n  parser = expat.ParserCreate(encoding, \"}\")\n  if target is None:\n   target = TreeBuilder()\n   \n  self.parser = self._parser = parser\n  self.target = self._target = target\n  self._error = expat.error\n  self._names = {} \n  \n  parser.DefaultHandlerExpand = self._default\n  if hasattr(target, 'start'):\n   parser.StartElementHandler = self._start\n  if hasattr(target, 'end'):\n   parser.EndElementHandler = self._end\n  if hasattr(target, 'data'):\n   parser.CharacterDataHandler = target.data\n   \n  if hasattr(target, 'comment'):\n   parser.CommentHandler = target.comment\n  if hasattr(target, 'pi'):\n   parser.ProcessingInstructionHandler = target.pi\n   \n  try:\n   parser.buffer_text = 1\n  except AttributeError:\n   pass\n   \n  try:\n   parser.ordered_attributes = 1\n   parser.specified_attributes = 1\n   if hasattr(target, 'start'):\n    parser.StartElementHandler = self._start_list\n  except AttributeError:\n   pass\n  self._doctype = None\n  self.entity = {}\n  try:\n   self.version = \"Expat %d.%d.%d\" % expat.version_info\n  except AttributeError:\n   pass \n   \n def _raiseerror(self, value):\n  err = ParseError(value)\n  err.code = value.code\n  err.position = value.lineno, value.offset\n  raise err\n  \n def _fixname(self, key):\n \n  try:\n   name = self._names[key]\n  except KeyError:\n   name = key\n   if \"}\" in name:\n    name = \"{\" + name\n   self._names[key] = name\n  return name\n  \n def _start(self, tag, attrib_in):\n  fixname = self._fixname\n  tag = fixname(tag)\n  attrib = {}\n  for key, value in attrib_in.items():\n   attrib[fixname(key)] = value\n  return self.target.start(tag, attrib)\n  \n def _start_list(self, tag, attrib_in):\n  fixname = self._fixname\n  tag = fixname(tag)\n  attrib = {}\n  if attrib_in:\n   for i in range(0, len(attrib_in), 2):\n    attrib[fixname(attrib_in[i])] = attrib_in[i+1]\n  return self.target.start(tag, attrib)\n  \n def _end(self, tag):\n  return self.target.end(self._fixname(tag))\n  \n def _default(self, text):\n  prefix = text[:1]\n  if prefix == \"&\":\n  \n   try:\n    data_handler = self.target.data\n   except AttributeError:\n    return\n   try:\n    data_handler(self.entity[text[1:-1]])\n   except KeyError:\n    from xml.parsers import expat\n    err = expat.error(\n    \"undefined entity %s: line %d, column %d\" %\n    (text, self.parser.ErrorLineNumber,\n    self.parser.ErrorColumnNumber)\n    )\n    err.code = 11 \n    err.lineno = self.parser.ErrorLineNumber\n    err.offset = self.parser.ErrorColumnNumber\n    raise err\n  elif prefix == \"<\" and text[:9] == \"<!DOCTYPE\":\n   self._doctype = [] \n  elif self._doctype is not None:\n  \n   if prefix == \">\":\n    self._doctype = None\n    return\n   text = text.strip()\n   if not text:\n    return\n   self._doctype.append(text)\n   n = len(self._doctype)\n   if n > 2:\n    type = self._doctype[1]\n    if type == \"PUBLIC\" and n == 4:\n     name, type, pubid, system = self._doctype\n     if pubid:\n      pubid = pubid[1:-1]\n    elif type == \"SYSTEM\" and n == 3:\n     name, type, system = self._doctype\n     pubid = None\n    else:\n     return\n    if hasattr(self.target, \"doctype\"):\n     self.target.doctype(name, pubid, system[1:-1])\n    elif self.doctype != self._XMLParser__doctype:\n    \n     self._XMLParser__doctype(name, pubid, system[1:-1])\n     self.doctype(name, pubid, system[1:-1])\n    self._doctype = None\n    \n    \n    \n    \n    \n    \n    \n    \n def doctype(self, name, pubid, system):\n  \"\"\n  warnings.warn(\n  \"This method of XMLParser is deprecated.  Define doctype() \"\n  \"method on the TreeBuilder target.\",\n  DeprecationWarning,\n  )\n  \n  \n __doctype = doctype\n \n \n \n \n \n \n def feed(self, data):\n  try:\n   self.parser.Parse(data, 0)\n  except self._error as v:\n   self._raiseerror(v)\n   \n   \n   \n   \n   \n   \n   \n def close(self):\n  try:\n   self.parser.Parse(\"\", 1) \n  except self._error as v:\n   self._raiseerror(v)\n  try:\n   close_handler = self.target.close\n  except AttributeError:\n   pass\n  else:\n   return close_handler()\n  finally:\n  \n   del self.parser, self._parser\n   del self.target, self._target\n   \n   \n   \ntry:\n\n from _elementtree import *\nexcept ImportError:\n pass\nelse:\n\n\n class ElementTree(ElementTree):\n  def parse(self, source, parser=None):\n   close_source = False\n   if not hasattr(source, 'read'):\n    source = open(source, 'rb')\n    close_source = True\n   try:\n    if parser is not None:\n     while True:\n      data = source.read(65536)\n      if not data:\n       break\n      parser.feed(data)\n     self._root = parser.close()\n    else:\n     parser = XMLParser()\n     self._root = parser._parse(source)\n    return self._root\n   finally:\n    if close_source:\n     source.close()\n     \n class iterparse:\n  \"\"\n  \n  root = None\n  def __init__(self, file, events=None, parser=None):\n   self._close_file = False\n   if not hasattr(file, 'read'):\n    file = open(file, 'rb')\n    self._close_file = True\n   self._file = file\n   self._events = []\n   self._index = 0\n   self._error = None\n   self.root = self._root = None\n   if parser is None:\n    parser = XMLParser(target=TreeBuilder())\n   self._parser = parser\n   self._parser._setevents(self._events, events)\n   \n  def __next__(self):\n   while True:\n    try:\n     item = self._events[self._index]\n     self._index += 1\n     return item\n    except IndexError:\n     pass\n    if self._error:\n     e = self._error\n     self._error = None\n     raise e\n    if self._parser is None:\n     self.root = self._root\n     if self._close_file:\n      self._file.close()\n     raise StopIteration\n     \n    del self._events[:]\n    self._index = 0\n    data = self._file.read(16384)\n    if data:\n     try:\n      self._parser.feed(data)\n     except SyntaxError as exc:\n      self._error = exc\n    else:\n     self._root = self._parser.close()\n     self._parser = None\n     \n  def __iter__(self):\n   return self\n   \n   \nXMLTreeBuilder = XMLParser\n\n\ntry:\n from ElementC14N import _serialize_c14n\n _serialize[\"c14n\"] = _serialize_c14n\nexcept ImportError:\n pass\n"], "_ajax": [".js", "// ajax\nvar $module = (function($B){\n\nvar _b_ = $B.builtins\n\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n//for(var $py_builtin in _b_){eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")}\n\nvar $XMLHttpDict = {__class__:$B.$type,__name__:'XMLHttp'}\n\n$XMLHttpDict.__getattribute__ = function(self,attr){\n    if(['headers','text','xml'].indexOf(attr)>-1){\n        return $XMLHttpDict[attr](self)\n    }\n    return _b_.object.$dict.__getattribute__(self,attr)\n}\n\n$XMLHttpDict.__mro__ = [$XMLHttpDict, _b_.object.$dict]\n\n$XMLHttpDict.__repr__ = function(self){return '<object XMLHttp>'}\n\n$XMLHttpDict.__str__ = $XMLHttpDict.toString = $XMLHttpDict.__repr__\n\n$XMLHttpDict.text = function(self){return self.responseText}\n    \n$XMLHttpDict.xml = function(self){return $DomObject(self.responseXML)}\n\n$XMLHttpDict.headers = function(self){\n    return list(self.getAllResponseHeaders().split('\\n'))\n}\n\n$XMLHttpDict.get_header = function(){\n    var reqobj = self;\n    return function(header){ return reqobj.getResponseHeader(header) }\n}\n\nvar $AjaxDict = {__class__:$B.$type,__name__:'ajax'}\n\n$AjaxDict.__mro__ = [$AjaxDict, _b_.object.$dict]\n\n$AjaxDict.__repr__ = function(self){return '<object Ajax>'}\n\n$AjaxDict.__str__ = $AjaxDict.toString = $AjaxDict.__repr__\n\n$AjaxDict.bind = function(self,evt,func){\n    // req.bind(evt,func) is the same as req.on_evt = func\n    self['on_'+evt]=func\n}\n\n$AjaxDict.open = function(self,method,url,async){\n    self.$xmlhttp.open(method,url,async)\n}\n\n$AjaxDict.send = function(self,params){\n    // params is a Python dictionary\n    var res = ''\n    if(!params || $B.$dict_length(params)==0){self.$xmlhttp.send();return}\n    else if(isinstance(params,str)){\n        res = params\n    }else if(isinstance(params,dict)){\n        itr = $B.$dict_iterator(params)\n        try {\n            while(true) {\n                itm = itr.next()\n                res += encodeURIComponent(str(itm[0]))+'='+encodeURIComponent(str(itm[1]))+'&'\n            }\n        } catch (err) {\n            if (err.__name__ !== \"StopIteration\") { throw err } else { $B.$pop_exc() }\n        }\n        res = res.substr(0,res.length-1)\n    }else{\n        throw _b_.TypeError(\"send() argument must be string or dictonary, not '\"+str(params.__class__)+\"'\")\n    }\n    self.$xmlhttp.send(res)\n}\n\n$AjaxDict.set_header = function(self,key,value){\n    self.$xmlhttp.setRequestHeader(key,value)\n}\n\n$AjaxDict.set_timeout = function(self,seconds,func){\n    self.$xmlhttp.$requestTimer = setTimeout(\n        function() {self.$xmlhttp.abort();func()}, \n        seconds*1000); \n}\n\nfunction ajax(){\n\n    var res = {\n        __class__:$AjaxDict\n    }\n\n    if (window.XMLHttpRequest){// code for IE7+, Firefox, Chrome, Opera, Safari\n        var $xmlhttp=new XMLHttpRequest();\n    }else{// code for IE6, IE5\n        var $xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\");\n    }\n    $xmlhttp.$requestTimer = null\n    $xmlhttp.__class__ = $XMLHttpDict\n    \n    $xmlhttp.onreadystatechange = function(){\n        // here, \"this\" refers to $xmlhttp\n        var state = this.readyState\n        var req = this.$ajax\n        var timer = this.$requestTimer\n        var obj = this\n        if(state===0 && 'on_uninitialized' in req){req.on_uninitialized(obj)}\n        else if(state===1 && 'on_loading' in req){req.on_loading(obj)}\n        else if(state===2 && 'on_loaded' in req){req.on_loaded(obj)}\n        else if(state===3 && 'on_interactive' in req){req.on_interactive(obj)}\n        else if(state===4 && 'on_complete' in req){\n            if(timer !== null){window.clearTimeout(timer)}\n            req.on_complete(obj)\n        }\n    }\n    $xmlhttp.$ajax = res\n    res.$xmlhttp = $xmlhttp\n    return res\n}\n\najax.__class__ = $B.$factory\najax.$dict = $AjaxDict\n\nreturn {ajax:ajax}\n\n})(__BRYTHON__)\n"], "unittest.test.test_program": [".py", "import io\n\nimport os\nimport sys\nimport unittest\n\n\nclass Test_TestProgram(unittest.TestCase):\n\n def test_discovery_from_dotted_path(self):\n  loader = unittest.TestLoader()\n  \n  tests = [self]\n  expectedPath = os.path.abspath(os.path.dirname(unittest.test.__file__))\n  \n  self.wasRun = False\n  def _find_tests(start_dir, pattern):\n   self.wasRun = True\n   self.assertEqual(start_dir, expectedPath)\n   return tests\n  loader._find_tests = _find_tests\n  suite = loader.discover('unittest.test')\n  self.assertTrue(self.wasRun)\n  self.assertEqual(suite._tests, tests)\n  \n  \n def testNoExit(self):\n  result = object()\n  test = object()\n  \n  class FakeRunner(object):\n   def run(self, test):\n    self.test = test\n    return result\n    \n  runner = FakeRunner()\n  \n  oldParseArgs = unittest.TestProgram.parseArgs\n  def restoreParseArgs():\n   unittest.TestProgram.parseArgs = oldParseArgs\n  unittest.TestProgram.parseArgs = lambda *args: None\n  self.addCleanup(restoreParseArgs)\n  \n  def removeTest():\n   del unittest.TestProgram.test\n  unittest.TestProgram.test = test\n  self.addCleanup(removeTest)\n  \n  program = unittest.TestProgram(testRunner=runner, exit=False, verbosity=2)\n  \n  self.assertEqual(program.result, result)\n  self.assertEqual(runner.test, test)\n  self.assertEqual(program.verbosity, 2)\n  \n class FooBar(unittest.TestCase):\n  def testPass(self):\n   assert True\n  def testFail(self):\n   assert False\n   \n class FooBarLoader(unittest.TestLoader):\n  \"\"\n  def loadTestsFromModule(self, module):\n   return self.suiteClass(\n   [self.loadTestsFromTestCase(Test_TestProgram.FooBar)])\n   \n   \n def test_NonExit(self):\n  program = unittest.main(exit=False,\n  argv=[\"foobar\"],\n  testRunner=unittest.TextTestRunner(stream=io.StringIO()),\n  testLoader=self.FooBarLoader())\n  self.assertTrue(hasattr(program, 'result'))\n  \n  \n def test_Exit(self):\n  self.assertRaises(\n  SystemExit,\n  unittest.main,\n  argv=[\"foobar\"],\n  testRunner=unittest.TextTestRunner(stream=io.StringIO()),\n  exit=True,\n  testLoader=self.FooBarLoader())\n  \n  \n def test_ExitAsDefault(self):\n  self.assertRaises(\n  SystemExit,\n  unittest.main,\n  argv=[\"foobar\"],\n  testRunner=unittest.TextTestRunner(stream=io.StringIO()),\n  testLoader=self.FooBarLoader())\n  \n  \nclass InitialisableProgram(unittest.TestProgram):\n exit = False\n result = None\n verbosity = 1\n defaultTest = None\n testRunner = None\n testLoader = unittest.defaultTestLoader\n module = '__main__'\n progName = 'test'\n test = 'test'\n def __init__(self, *args):\n  pass\n  \nRESULT = object()\n\nclass FakeRunner(object):\n initArgs = None\n test = None\n raiseError = False\n \n def __init__(self, **kwargs):\n  FakeRunner.initArgs = kwargs\n  if FakeRunner.raiseError:\n   FakeRunner.raiseError = False\n   raise TypeError\n   \n def run(self, test):\n  FakeRunner.test = test\n  return RESULT\n  \nclass TestCommandLineArgs(unittest.TestCase):\n\n def setUp(self):\n  self.program = InitialisableProgram()\n  self.program.createTests = lambda: None\n  FakeRunner.initArgs = None\n  FakeRunner.test = None\n  FakeRunner.raiseError = False\n  \n def testVerbosity(self):\n  program = self.program\n  \n  for opt in '-q', '--quiet':\n   program.verbosity = 1\n   program.parseArgs([None, opt])\n   self.assertEqual(program.verbosity, 0)\n   \n  for opt in '-v', '--verbose':\n   program.verbosity = 1\n   program.parseArgs([None, opt])\n   self.assertEqual(program.verbosity, 2)\n   \n def testBufferCatchFailfast(self):\n  program = self.program\n  for arg, attr in (('buffer', 'buffer'), ('failfast', 'failfast'),\n  ('catch', 'catchbreak')):\n   if attr == 'catch' and not hasInstallHandler:\n    continue\n    \n   short_opt = '-%s' % arg[0]\n   long_opt = '--%s' % arg\n   for opt in short_opt, long_opt:\n    setattr(program, attr, None)\n    \n    program.parseArgs([None, opt])\n    self.assertTrue(getattr(program, attr))\n    \n   for opt in short_opt, long_opt:\n    not_none = object()\n    setattr(program, attr, not_none)\n    \n    program.parseArgs([None, opt])\n    self.assertEqual(getattr(program, attr), not_none)\n    \n def testWarning(self):\n  \"\"\n  \n  class FakeTP(unittest.TestProgram):\n   def parseArgs(self, *args, **kw): pass\n   def runTests(self, *args, **kw): pass\n  warnoptions = sys.warnoptions[:]\n  try:\n   sys.warnoptions[:] = []\n   \n   self.assertEqual(FakeTP().warnings, 'default')\n   \n   self.assertEqual(FakeTP(warnings='ignore').warnings, 'ignore')\n   sys.warnoptions[:] = ['somevalue']\n   \n   \n   self.assertEqual(FakeTP().warnings, None)\n   self.assertEqual(FakeTP(warnings='ignore').warnings, 'ignore')\n  finally:\n   sys.warnoptions[:] = warnoptions\n   \n def testRunTestsRunnerClass(self):\n  program = self.program\n  \n  program.testRunner = FakeRunner\n  program.verbosity = 'verbosity'\n  program.failfast = 'failfast'\n  program.buffer = 'buffer'\n  program.warnings = 'warnings'\n  \n  program.runTests()\n  \n  self.assertEqual(FakeRunner.initArgs, {'verbosity': 'verbosity',\n  'failfast': 'failfast',\n  'buffer': 'buffer',\n  'warnings': 'warnings'})\n  self.assertEqual(FakeRunner.test, 'test')\n  self.assertIs(program.result, RESULT)\n  \n def testRunTestsRunnerInstance(self):\n  program = self.program\n  \n  program.testRunner = FakeRunner()\n  FakeRunner.initArgs = None\n  \n  program.runTests()\n  \n  \n  self.assertIsNone(FakeRunner.initArgs)\n  \n  self.assertEqual(FakeRunner.test, 'test')\n  self.assertIs(program.result, RESULT)\n  \n def testRunTestsOldRunnerClass(self):\n  program = self.program\n  \n  FakeRunner.raiseError = True\n  program.testRunner = FakeRunner\n  program.verbosity = 'verbosity'\n  program.failfast = 'failfast'\n  program.buffer = 'buffer'\n  program.test = 'test'\n  \n  program.runTests()\n  \n  \n  \n  self.assertEqual(FakeRunner.initArgs, {})\n  self.assertEqual(FakeRunner.test, 'test')\n  self.assertIs(program.result, RESULT)\n  \n def testCatchBreakInstallsHandler(self):\n  module = sys.modules['unittest.main']\n  original = module.installHandler\n  def restore():\n   module.installHandler = original\n  self.addCleanup(restore)\n  \n  self.installed = False\n  def fakeInstallHandler():\n   self.installed = True\n  module.installHandler = fakeInstallHandler\n  \n  program = self.program\n  program.catchbreak = True\n  \n  program.testRunner = FakeRunner\n  \n  program.runTests()\n  self.assertTrue(self.installed)\n  \n def _patch_isfile(self, names, exists=True):\n  def isfile(path):\n   return path in names\n  original = os.path.isfile\n  os.path.isfile = isfile\n  def restore():\n   os.path.isfile = original\n  self.addCleanup(restore)\n  \n  \n def testParseArgsFileNames(self):\n \n  program = self.program\n  argv = ['progname', 'foo.py', 'bar.Py', 'baz.PY', 'wing.txt']\n  self._patch_isfile(argv)\n  \n  program.createTests = lambda: None\n  program.parseArgs(argv)\n  \n  \n  \n  expected = ['foo', 'bar', 'baz', 'wing.txt']\n  self.assertEqual(program.testNames, expected)\n  \n  \n def testParseArgsFilePaths(self):\n  program = self.program\n  argv = ['progname', 'foo/bar/baz.py', 'green\\\\red.py']\n  self._patch_isfile(argv)\n  \n  program.createTests = lambda: None\n  program.parseArgs(argv)\n  \n  expected = ['foo.bar.baz', 'green.red']\n  self.assertEqual(program.testNames, expected)\n  \n  \n def testParseArgsNonExistentFiles(self):\n  program = self.program\n  argv = ['progname', 'foo/bar/baz.py', 'green\\\\red.py']\n  self._patch_isfile([])\n  \n  program.createTests = lambda: None\n  program.parseArgs(argv)\n  \n  self.assertEqual(program.testNames, argv[1:])\n  \n def testParseArgsAbsolutePathsThatCanBeConverted(self):\n  cur_dir = os.getcwd()\n  program = self.program\n  def _join(name):\n   return os.path.join(cur_dir, name)\n  argv = ['progname', _join('foo/bar/baz.py'), _join('green\\\\red.py')]\n  self._patch_isfile(argv)\n  \n  program.createTests = lambda: None\n  program.parseArgs(argv)\n  \n  expected = ['foo.bar.baz', 'green.red']\n  self.assertEqual(program.testNames, expected)\n  \n def testParseArgsAbsolutePathsThatCannotBeConverted(self):\n  program = self.program\n  \n  argv = ['progname', '/foo/bar/baz.py', '/green/red.py']\n  self._patch_isfile(argv)\n  \n  program.createTests = lambda: None\n  program.parseArgs(argv)\n  \n  self.assertEqual(program.testNames, argv[1:])\n  \n  \n  \n  \n  \n  \n  \n  \n  \nif __name__ == '__main__':\n unittest.main()\n"], "pwd": [".py", "\ndef getpwuid():\n pass\n"], "webbrowser": [".py", "from browser import window\n\n__all__ = [\"Error\", \"open\", \"open_new\", \"open_new_tab\"]\n\nclass Error(Exception):\n pass\n \n_target = { 0: '', 1: '_blank', 2: '_new' } \n\n\ndef open(url, new=0, autoraise=True):\n \"\"\n if window.open(url, _target[new]):\n  return True\n return False\n \ndef open_new(url):\n return open(url, 1)\n \ndef open_new_tab(url):\n return open(url, 2)\n \n \n"], "copy": [".py", "\"\"\n\nimport types\nimport weakref\nfrom copyreg import dispatch_table\nimport builtins\n\nclass Error(Exception):\n pass\nerror = Error \n\ntry:\n from org.python.core import PyStringMap\nexcept ImportError:\n PyStringMap = None\n \n__all__ = [\"Error\", \"copy\", \"deepcopy\"]\n\ndef copy(x):\n \"\"\n \n cls = type(x)\n \n copier = _copy_dispatch.get(cls)\n if copier:\n  return copier(x)\n  \n copier = getattr(cls, \"__copy__\", None)\n if copier:\n  return copier(x)\n  \n reductor = dispatch_table.get(cls)\n if reductor:\n  rv = reductor(x)\n else:\n  reductor = getattr(x, \"__reduce_ex__\", None)\n  if reductor:\n   rv = reductor(2)\n  else:\n   reductor = getattr(x, \"__reduce__\", None)\n   if reductor:\n    rv = reductor()\n   else:\n    raise Error(\"un(shallow)copyable object of type %s\" % cls)\n    \n return _reconstruct(x, rv, 0)\n \n \n_copy_dispatch = d = {}\n\ndef _copy_immutable(x):\n return x\nfor t in (type(None), int, float, bool, str, tuple,\nfrozenset, type, range,\ntypes.BuiltinFunctionType, type(Ellipsis),\ntypes.FunctionType, weakref.ref):\n d[t] = _copy_immutable\nt = getattr(types, \"CodeType\", None)\nif t is not None:\n d[t] = _copy_immutable\nfor name in (\"complex\", \"unicode\"):\n t = getattr(builtins, name, None)\n if t is not None:\n  d[t] = _copy_immutable\n  \ndef _copy_with_constructor(x):\n return type(x)(x)\nfor t in (list, dict, set):\n d[t] = _copy_with_constructor\n \ndef _copy_with_copy_method(x):\n return x.copy()\nif PyStringMap is not None:\n d[PyStringMap] = _copy_with_copy_method\n \ndel d\n\ndef deepcopy(x, memo=None, _nil=[]):\n \"\"\n \n if memo is None:\n  memo = {}\n  \n d = id(x)\n y = memo.get(d, _nil)\n if y is not _nil:\n  return y\n  \n cls = type(x)\n \n copier = _deepcopy_dispatch.get(cls)\n if copier:\n  y = copier(x, memo)\n else:\n  try:\n   issc = issubclass(cls, type)\n  except TypeError: \n   issc = 0\n  if issc:\n   y = _deepcopy_atomic(x, memo)\n  else:\n   copier = getattr(x, \"__deepcopy__\", None)\n   if copier:\n    y = copier(memo)\n   else:\n    reductor = dispatch_table.get(cls)\n    if reductor:\n     rv = reductor(x)\n    else:\n     reductor = getattr(x, \"__reduce_ex__\", None)\n     if reductor:\n      rv = reductor(2)\n     else:\n      reductor = getattr(x, \"__reduce__\", None)\n      if reductor:\n       rv = reductor()\n      else:\n       raise Error(\n       \"un(deep)copyable object of type %s\" % cls)\n    y = _reconstruct(x, rv, 1, memo)\n    \n    \n if y is not x:\n  memo[d] = y\n  _keep_alive(x, memo) \n return y\n \n_deepcopy_dispatch = d = {}\n\ndef _deepcopy_atomic(x, memo):\n return x\nd[type(None)] = _deepcopy_atomic\nd[type(Ellipsis)] = _deepcopy_atomic\nd[int] = _deepcopy_atomic\nd[float] = _deepcopy_atomic\nd[bool] = _deepcopy_atomic\ntry:\n d[complex] = _deepcopy_atomic\nexcept NameError:\n pass\nd[bytes] = _deepcopy_atomic\nd[str] = _deepcopy_atomic\ntry:\n d[types.CodeType] = _deepcopy_atomic\nexcept AttributeError:\n pass\nd[type] = _deepcopy_atomic\nd[range] = _deepcopy_atomic\nd[types.BuiltinFunctionType] = _deepcopy_atomic\nd[types.FunctionType] = _deepcopy_atomic\nd[weakref.ref] = _deepcopy_atomic\n\ndef _deepcopy_list(x, memo):\n y = []\n memo[id(x)] = y\n for a in x:\n  y.append(deepcopy(a, memo))\n return y\nd[list] = _deepcopy_list\n\ndef _deepcopy_tuple(x, memo):\n y = []\n for a in x:\n  y.append(deepcopy(a, memo))\n  \n  \n try:\n  return memo[id(x)]\n except KeyError:\n  pass\n for i in range(len(x)):\n  if x[i] is not y[i]:\n   y = tuple(y)\n   break\n else:\n  y = x\n return y\nd[tuple] = _deepcopy_tuple\n\ndef _deepcopy_dict(x, memo):\n y = {}\n memo[id(x)] = y\n for key, value in x.items():\n  y[deepcopy(key, memo)] = deepcopy(value, memo)\n return y\nd[dict] = _deepcopy_dict\nif PyStringMap is not None:\n d[PyStringMap] = _deepcopy_dict\n \ndef _deepcopy_method(x, memo): \n return type(x)(x.__func__, deepcopy(x.__self__, memo))\n_deepcopy_dispatch[types.MethodType] = _deepcopy_method\n\ndef _keep_alive(x, memo):\n \"\"\n try:\n  memo[id(memo)].append(x)\n except KeyError:\n \n  memo[id(memo)]=[x]\n  \ndef _reconstruct(x, info, deep, memo=None):\n if isinstance(info, str):\n  return x\n assert isinstance(info, tuple)\n if memo is None:\n  memo = {}\n n = len(info)\n assert n in (2, 3, 4, 5)\n callable, args = info[:2]\n if n > 2:\n  state = info[2]\n else:\n  state = {}\n if n > 3:\n  listiter = info[3]\n else:\n  listiter = None\n if n > 4:\n  dictiter = info[4]\n else:\n  dictiter = None\n if deep:\n  args = deepcopy(args, memo)\n y = callable(*args)\n memo[id(x)] = y\n \n if state:\n  if deep:\n   state = deepcopy(state, memo)\n  if hasattr(y, '__setstate__'):\n   y.__setstate__(state)\n  else:\n   if isinstance(state, tuple) and len(state) == 2:\n    state, slotstate = state\n   else:\n    slotstate = None\n   if state is not None:\n    y.__dict__.update(state)\n   if slotstate is not None:\n    for key, value in slotstate.items():\n     setattr(y, key, value)\n     \n if listiter is not None:\n  for item in listiter:\n   if deep:\n    item = deepcopy(item, memo)\n   y.append(item)\n if dictiter is not None:\n  for key, value in dictiter:\n   if deep:\n    key = deepcopy(key, memo)\n    value = deepcopy(value, memo)\n   y[key] = value\n return y\n \ndel d\n\ndel types\n\n\nclass _EmptyClass:\n pass\n"], "_sysconfigdata": [".py", "build_time_vars={'HAVE_SYS_WAIT_H': 1, 'HAVE_UTIL_H': 0, 'HAVE_SYMLINKAT': 1, 'HAVE_LIBSENDFILE': 0, 'SRCDIRS': 'Parser Grammar Objects Python Modules Mac', 'SIZEOF_OFF_T': 8, 'BASECFLAGS': '-Wno-unused-result', 'HAVE_UTIME_H': 1, 'EXTRAMACHDEPPATH': '', 'HAVE_SYS_TIME_H': 1, 'CFLAGSFORSHARED': '-fPIC', 'HAVE_HYPOT': 1, 'PGSRCS': '\\\\', 'HAVE_LIBUTIL_H': 0, 'HAVE_COMPUTED_GOTOS': 1, 'HAVE_LUTIMES': 1, 'HAVE_MAKEDEV': 1, 'HAVE_REALPATH': 1, 'HAVE_LINUX_TIPC_H': 1, 'MULTIARCH': 'i386-linux-gnu', 'HAVE_GETWD': 1, 'HAVE_GCC_ASM_FOR_X64': 0, 'HAVE_INET_PTON': 1, 'HAVE_GETHOSTBYNAME_R_6_ARG': 1, 'SIZEOF__BOOL': 1, 'HAVE_ZLIB_COPY': 1, 'ASDLGEN': 'python3.3 ../Parser/asdl_c.py', 'GRAMMAR_INPUT': '../Grammar/Grammar', 'HOST_GNU_TYPE': 'i686-pc-linux-gnu', 'HAVE_SCHED_RR_GET_INTERVAL': 1, 'HAVE_BLUETOOTH_H': 0, 'HAVE_MKFIFO': 1, 'TIMEMODULE_LIB': 0, 'LIBM': '-lm', 'PGENOBJS': '\\\\ \\\\', 'PYTHONFRAMEWORK': '', 'GETPGRP_HAVE_ARG': 0, 'HAVE_MMAP': 1, 'SHLIB_SUFFIX': '.so', 'SIZEOF_FLOAT': 4, 'HAVE_RENAMEAT': 1, 'HAVE_LANGINFO_H': 1, 'HAVE_STDLIB_H': 1, 'PY_CORE_CFLAGS': '-Wno-unused-result -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security   -I. -IInclude -I../Include -D_FORTIFY_SOURCE=2 -fPIC -DPy_BUILD_CORE', 'HAVE_BROKEN_PIPE_BUF': 0, 'HAVE_CONFSTR': 1, 'HAVE_SIGTIMEDWAIT': 1, 'HAVE_FTELLO': 1, 'READELF': 'readelf', 'HAVE_SIGALTSTACK': 1, 'TESTTIMEOUT': 3600, 'PYTHONPATH': ':plat-i386-linux-gnu', 'SIZEOF_WCHAR_T': 4, 'LIBOBJS': '', 'HAVE_SYSCONF': 1, 'MAKESETUP': '../Modules/makesetup', 'HAVE_UTIMENSAT': 1, 'HAVE_FCHOWNAT': 1, 'HAVE_WORKING_TZSET': 1, 'HAVE_FINITE': 1, 'HAVE_ASINH': 1, 'HAVE_SETEUID': 1, 'CONFIGFILES': 'configure configure.ac acconfig.h pyconfig.h.in Makefile.pre.in', 'HAVE_SETGROUPS': 1, 'PARSER_OBJS': '\\\\ Parser/myreadline.o Parser/parsetok.o Parser/tokenizer.o', 'HAVE_MBRTOWC': 1, 'SIZEOF_INT': 4, 'HAVE_STDARG_PROTOTYPES': 1, 'TM_IN_SYS_TIME': 0, 'HAVE_SYS_TIMES_H': 1, 'HAVE_LCHOWN': 1, 'HAVE_SSIZE_T': 1, 'HAVE_PAUSE': 1, 'SYSLIBS': '-lm', 'POSIX_SEMAPHORES_NOT_ENABLED': 0, 'HAVE_DEVICE_MACROS': 1, 'BLDSHARED': 'i686-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wno-unused-result -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security  ', 'LIBSUBDIRS': 'tkinter tkinter/test tkinter/test/test_tkinter \\\\', 'HAVE_SYS_UN_H': 1, 'HAVE_SYS_STAT_H': 1, 'VPATH': '..', 'INCLDIRSTOMAKE': '/usr/include /usr/include /usr/include/python3.3m /usr/include/python3.3m', 'HAVE_BROKEN_SEM_GETVALUE': 0, 'HAVE_TIMEGM': 1, 'PACKAGE_VERSION': 0, 'MAJOR_IN_SYSMACROS': 0, 'HAVE_ATANH': 1, 'HAVE_GAI_STRERROR': 1, 'HAVE_SYS_POLL_H': 1, 'SIZEOF_PTHREAD_T': 4, 'SIZEOF_FPOS_T': 16, 'HAVE_CTERMID': 1, 'HAVE_TMPFILE': 1, 'HAVE_SETUID': 1, 'CXX': 'i686-linux-gnu-g++ -pthread', 'srcdir': '..', 'HAVE_UINT32_T': 1, 'HAVE_ADDRINFO': 1, 'HAVE_GETSPENT': 1, 'SIZEOF_DOUBLE': 8, 'HAVE_INT32_T': 1, 'LIBRARY_OBJS_OMIT_FROZEN': '\\\\', 'HAVE_FUTIMES': 1, 'CONFINCLUDEPY': '/usr/include/python3.3m', 'HAVE_RL_COMPLETION_APPEND_CHARACTER': 1, 'LIBFFI_INCLUDEDIR': '', 'HAVE_SETGID': 1, 'HAVE_UINT64_T': 1, 'EXEMODE': 755, 'UNIVERSALSDK': '', 'HAVE_LIBDL': 1, 'HAVE_GETNAMEINFO': 1, 'HAVE_STDINT_H': 1, 'COREPYTHONPATH': ':plat-i386-linux-gnu', 'HAVE_SOCKADDR_STORAGE': 1, 'HAVE_WAITID': 1, 'EXTRAPLATDIR': '@EXTRAPLATDIR@', 'HAVE_ACCEPT4': 1, 'RUNSHARED': 'LD_LIBRARY_PATH=/build/buildd/python3.3-3.3.1/build-shared:', 'EXE': '', 'HAVE_SIGACTION': 1, 'HAVE_CHOWN': 1, 'HAVE_GETLOGIN': 1, 'HAVE_TZNAME': 0, 'PACKAGE_NAME': 0, 'HAVE_GETPGID': 1, 'HAVE_GLIBC_MEMMOVE_BUG': 0, 'BUILD_GNU_TYPE': 'i686-pc-linux-gnu', 'HAVE_LINUX_CAN_H': 1, 'DYNLOADFILE': 'dynload_shlib.o', 'HAVE_PWRITE': 1, 'BUILDEXE': '', 'HAVE_OPENPTY': 1, 'HAVE_LOCKF': 1, 'HAVE_COPYSIGN': 1, 'HAVE_PREAD': 1, 'HAVE_DLOPEN': 1, 'HAVE_SYS_KERN_CONTROL_H': 0, 'PY_FORMAT_LONG_LONG': '\"ll\"', 'HAVE_TCSETPGRP': 1, 'HAVE_SETSID': 1, 'HAVE_STRUCT_STAT_ST_BIRTHTIME': 0, 'HAVE_STRING_H': 1, 'LDLIBRARY': 'libpython3.3m.so', 'INSTALL_SCRIPT': '/usr/bin/install -c', 'HAVE_SYS_XATTR_H': 1, 'HAVE_CURSES_IS_TERM_RESIZED': 1, 'HAVE_TMPNAM_R': 1, 'STRICT_SYSV_CURSES': \"/* Don't use ncurses extensions */\", 'WANT_SIGFPE_HANDLER': 1, 'HAVE_INT64_T': 1, 'HAVE_STAT_TV_NSEC': 1, 'HAVE_SYS_MKDEV_H': 0, 'HAVE_BROKEN_POLL': 0, 'HAVE_IF_NAMEINDEX': 1, 'HAVE_GETPWENT': 1, 'PSRCS': '\\\\', 'RANLIB': 'ranlib', 'HAVE_WCSCOLL': 1, 'WITH_NEXT_FRAMEWORK': 0, 'ASDLGEN_FILES': '../Parser/asdl.py ../Parser/asdl_c.py', 'HAVE_RL_PRE_INPUT_HOOK': 1, 'PACKAGE_URL': 0, 'SHLIB_EXT': 0, 'HAVE_SYS_LOADAVG_H': 0, 'HAVE_LIBIEEE': 0, 'HAVE_SEM_OPEN': 1, 'HAVE_TERM_H': 1, 'IO_OBJS': '\\\\', 'IO_H': 'Modules/_io/_iomodule.h', 'HAVE_STATVFS': 1, 'VERSION': '3.3', 'HAVE_GETC_UNLOCKED': 1, 'MACHDEPS': 'plat-i386-linux-gnu @EXTRAPLATDIR@', 'SUBDIRSTOO': 'Include Lib Misc', 'HAVE_SETREUID': 1, 'HAVE_ERFC': 1, 'HAVE_SETRESUID': 1, 'LINKFORSHARED': '-Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions', 'HAVE_SYS_TYPES_H': 1, 'HAVE_GETPAGESIZE': 1, 'HAVE_SETEGID': 1, 'HAVE_PTY_H': 1, 'HAVE_STRUCT_STAT_ST_FLAGS': 0, 'HAVE_WCHAR_H': 1, 'HAVE_FSEEKO': 1, 'Py_ENABLE_SHARED': 1, 'HAVE_SIGRELSE': 1, 'HAVE_PTHREAD_INIT': 0, 'FILEMODE': 644, 'HAVE_SYS_RESOURCE_H': 1, 'HAVE_READLINKAT': 1, 'PYLONG_BITS_IN_DIGIT': 0, 'LINKCC': 'i686-linux-gnu-gcc -pthread', 'HAVE_SETLOCALE': 1, 'HAVE_CHROOT': 1, 'HAVE_OPENAT': 1, 'HAVE_FEXECVE': 1, 'LDCXXSHARED': 'i686-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions', 'DIST': 'README ChangeLog configure configure.ac acconfig.h pyconfig.h.in Makefile.pre.in Include Lib Misc Ext-dummy', 'HAVE_MKNOD': 1, 'PY_LDFLAGS': '-Wl,-Bsymbolic-functions -Wl,-z,relro', 'HAVE_BROKEN_MBSTOWCS': 0, 'LIBRARY_OBJS': '\\\\', 'HAVE_LOG1P': 1, 'SIZEOF_VOID_P': 4, 'HAVE_FCHOWN': 1, 'PYTHONFRAMEWORKPREFIX': '', 'HAVE_LIBDLD': 0, 'HAVE_TGAMMA': 1, 'HAVE_ERRNO_H': 1, 'HAVE_IO_H': 0, 'OTHER_LIBTOOL_OPT': '', 'HAVE_POLL_H': 1, 'PY_CPPFLAGS': '-I. -IInclude -I../Include -D_FORTIFY_SOURCE=2', 'XMLLIBSUBDIRS': 'xml xml/dom xml/etree xml/parsers xml/sax', 'GRAMMAR_H': 'Include/graminit.h', 'TANH_PRESERVES_ZERO_SIGN': 1, 'HAVE_GETLOADAVG': 1, 'UNICODE_DEPS': '\\\\ \\\\', 'HAVE_GETCWD': 1, 'MANDIR': '/usr/share/man', 'MACHDESTLIB': '/usr/lib/python3.3', 'GRAMMAR_C': 'Python/graminit.c', 'PGOBJS': '\\\\', 'HAVE_DEV_PTMX': 1, 'HAVE_UINTPTR_T': 1, 'HAVE_SCHED_SETAFFINITY': 1, 'PURIFY': '', 'HAVE_DECL_ISINF': 1, 'HAVE_RL_CALLBACK': 1, 'HAVE_WRITEV': 1, 'HAVE_GETHOSTBYNAME_R_5_ARG': 0, 'HAVE_SYS_AUDIOIO_H': 0, 'EXT_SUFFIX': '.cpython-33m.so', 'SIZEOF_LONG_LONG': 8, 'DLINCLDIR': '.', 'HAVE_PATHCONF': 1, 'HAVE_UNLINKAT': 1, 'MKDIR_P': '/bin/mkdir -p', 'HAVE_ALTZONE': 0, 'SCRIPTDIR': '/usr/lib', 'OPCODETARGETGEN_FILES': '\\\\', 'HAVE_GETSPNAM': 1, 'HAVE_SYS_TERMIO_H': 0, 'HAVE_ATTRIBUTE_FORMAT_PARSETUPLE': 0, 'HAVE_PTHREAD_H': 1, 'Py_DEBUG': 0, 'HAVE_STRUCT_STAT_ST_BLOCKS': 1, 'X87_DOUBLE_ROUNDING': 1, 'SIZEOF_TIME_T': 4, 'HAVE_DYNAMIC_LOADING': 1, 'HAVE_DIRECT_H': 0, 'SRC_GDB_HOOKS': '../Tools/gdb/libpython.py', 'HAVE_GETADDRINFO': 1, 'HAVE_BROKEN_NICE': 0, 'HAVE_DIRENT_H': 1, 'HAVE_WCSXFRM': 1, 'HAVE_RL_COMPLETION_DISPLAY_MATCHES_HOOK': 1, 'HAVE_FSTATVFS': 1, 'PYTHON': 'python', 'HAVE_OSX105_SDK': 0, 'BINDIR': '/usr/bin', 'TESTPYTHON': 'LD_LIBRARY_PATH=/build/buildd/python3.3-3.3.1/build-shared: ./python', 'ARFLAGS': 'rc', 'PLATDIR': 'plat-i386-linux-gnu', 'HAVE_ASM_TYPES_H': 1, 'PY3LIBRARY': 'libpython3.so', 'HAVE_PLOCK': 0, 'FLOCK_NEEDS_LIBBSD': 0, 'WITH_TSC': 0, 'HAVE_LIBREADLINE': 1, 'MACHDEP': 'linux', 'HAVE_SELECT': 1, 'LDFLAGS': '-Wl,-Bsymbolic-functions -Wl,-z,relro', 'HAVE_HSTRERROR': 1, 'SOABI': 'cpython-33m', 'HAVE_GETTIMEOFDAY': 1, 'HAVE_LIBRESOLV': 0, 'HAVE_UNSETENV': 1, 'HAVE_TM_ZONE': 1, 'HAVE_GETPGRP': 1, 'HAVE_FLOCK': 1, 'HAVE_SYS_BSDTTY_H': 0, 'SUBDIRS': '', 'PYTHONFRAMEWORKINSTALLDIR': '', 'PACKAGE_BUGREPORT': 0, 'HAVE_CLOCK': 1, 'HAVE_GETPEERNAME': 1, 'SIZEOF_PID_T': 4, 'HAVE_CONIO_H': 0, 'HAVE_FSTATAT': 1, 'HAVE_NETPACKET_PACKET_H': 1, 'HAVE_WAIT3': 1, 'DESTPATH': '', 'HAVE_STAT_TV_NSEC2': 0, 'HAVE_GETRESGID': 1, 'HAVE_UCS4_TCL': 0, 'SIGNED_RIGHT_SHIFT_ZERO_FILLS': 0, 'HAVE_TIMES': 1, 'HAVE_UNAME': 1, 'HAVE_ERF': 1, 'SIZEOF_SHORT': 2, 'HAVE_NCURSES_H': 1, 'HAVE_SYS_SENDFILE_H': 1, 'HAVE_CTERMID_R': 0, 'HAVE_TMPNAM': 1, 'prefix': '/usr', 'HAVE_NICE': 1, 'WITH_THREAD': 1, 'LN': 'ln', 'TESTRUNNER': 'LD_LIBRARY_PATH=/build/buildd/python3.3-3.3.1/build-shared: ./python ../Tools/scripts/run_tests.py', 'HAVE_SIGINTERRUPT': 1, 'HAVE_SETPGID': 1, 'RETSIGTYPE': 'void', 'HAVE_SCHED_GET_PRIORITY_MAX': 1, 'HAVE_SYS_SYS_DOMAIN_H': 0, 'HAVE_SYS_DIR_H': 0, 'HAVE__GETPTY': 0, 'HAVE_BLUETOOTH_BLUETOOTH_H': 1, 'HAVE_BIND_TEXTDOMAIN_CODESET': 1, 'HAVE_POLL': 1, 'PYTHON_OBJS': '\\\\', 'HAVE_WAITPID': 1, 'USE_INLINE': 1, 'HAVE_FUTIMENS': 1, 'USE_COMPUTED_GOTOS': 1, 'MAINCC': 'i686-linux-gnu-gcc -pthread', 'HAVE_SOCKETPAIR': 1, 'HAVE_PROCESS_H': 0, 'HAVE_SETVBUF': 1, 'HAVE_FDOPENDIR': 1, 'CONFINCLUDEDIR': '/usr/include', 'BINLIBDEST': '/usr/lib/python3.3', 'HAVE_SYS_IOCTL_H': 1, 'HAVE_SYSEXITS_H': 1, 'LDLAST': '', 'HAVE_SYS_FILE_H': 1, 'HAVE_RL_COMPLETION_SUPPRESS_APPEND': 1, 'HAVE_RL_COMPLETION_MATCHES': 1, 'HAVE_TCGETPGRP': 1, 'SIZEOF_SIZE_T': 4, 'HAVE_EPOLL_CREATE1': 1, 'HAVE_SYS_SELECT_H': 1, 'HAVE_CLOCK_GETTIME': 1, 'CFLAGS': '-Wno-unused-result -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security  ', 'HAVE_SNPRINTF': 1, 'BLDLIBRARY': '-lpython3.3m', 'PARSER_HEADERS': '\\\\', 'SO': '.so', 'LIBRARY': 'libpython3.3m.a', 'HAVE_FPATHCONF': 1, 'HAVE_TERMIOS_H': 1, 'HAVE_BROKEN_PTHREAD_SIGMASK': 0, 'AST_H': 'Include/Python-ast.h', 'HAVE_GCC_UINT128_T': 0, 'HAVE_ACOSH': 1, 'MODOBJS': 'Modules/_threadmodule.o  Modules/signalmodule.o  Modules/arraymodule.o  Modules/mathmodule.o Modules/_math.o  Modules/_struct.o  Modules/timemodule.o  Modules/_randommodule.o  Modules/atexitmodule.o  Modules/_elementtree.o  Modules/_pickle.o  Modules/_datetimemodule.o  Modules/_bisectmodule.o  Modules/_heapqmodule.o  Modules/unicodedata.o  Modules/fcntlmodule.o  Modules/spwdmodule.o  Modules/grpmodule.o  Modules/selectmodule.o  Modules/socketmodule.o  Modules/_posixsubprocess.o  Modules/md5module.o  Modules/sha1module.o  Modules/sha256module.o  Modules/sha512module.o  Modules/syslogmodule.o  Modules/binascii.o  Modules/zlibmodule.o  Modules/pyexpat.o  Modules/posixmodule.o  Modules/errnomodule.o  Modules/pwdmodule.o  Modules/_sre.o  Modules/_codecsmodule.o  Modules/_weakref.o  Modules/_functoolsmodule.o  Modules/operator.o  Modules/_collectionsmodule.o  Modules/itertoolsmodule.o  Modules/_localemodule.o  Modules/_iomodule.o Modules/iobase.o Modules/fileio.o Modules/bytesio.o Modules/bufferedio.o Modules/textio.o Modules/stringio.o  Modules/zipimport.o  Modules/faulthandler.o  Modules/symtablemodule.o  Modules/xxsubtype.o', 'AST_C': 'Python/Python-ast.c', 'HAVE_SYS_NDIR_H': 0, 'DESTDIRS': '/usr /usr/lib /usr/lib/python3.3 /usr/lib/python3.3/lib-dynload', 'HAVE_SIGNAL_H': 1, 'PACKAGE_TARNAME': 0, 'HAVE_GETPRIORITY': 1, 'INCLUDEDIR': '/usr/include', 'HAVE_INTTYPES_H': 1, 'SIGNAL_OBJS': '', 'HAVE_READV': 1, 'HAVE_SETHOSTNAME': 1, 'MODLIBS': '-lrt    -lexpat                   -L/usr/lib -lz  -lexpat', 'CC': 'i686-linux-gnu-gcc -pthread', 'HAVE_LCHMOD': 0, 'SIZEOF_UINTPTR_T': 4, 'LIBPC': '/usr/lib/i386-linux-gnu/pkgconfig', 'BYTESTR_DEPS': '\\\\', 'HAVE_MKDIRAT': 1, 'LIBPL': '/usr/lib/python3.3/config-3.3m-i386-linux-gnu', 'HAVE_SHADOW_H': 1, 'HAVE_SYS_EVENT_H': 0, 'INSTALL': '/usr/bin/install -c', 'HAVE_GCC_ASM_FOR_X87': 1, 'HAVE_BROKEN_UNSETENV': 0, 'BASECPPFLAGS': '', 'DOUBLE_IS_BIG_ENDIAN_IEEE754': 0, 'HAVE_STRUCT_STAT_ST_RDEV': 1, 'HAVE_SEM_UNLINK': 1, 'BUILDPYTHON': 'python', 'HAVE_RL_CATCH_SIGNAL': 1, 'HAVE_DECL_TZNAME': 0, 'RESSRCDIR': 'Mac/Resources/framework', 'HAVE_PTHREAD_SIGMASK': 1, 'HAVE_UTIMES': 1, 'DISTDIRS': 'Include Lib Misc Ext-dummy', 'HAVE_FDATASYNC': 1, 'HAVE_USABLE_WCHAR_T': 0, 'PY_FORMAT_SIZE_T': '\"z\"', 'HAVE_SCHED_SETSCHEDULER': 1, 'VA_LIST_IS_ARRAY': 0, 'HAVE_LINUX_NETLINK_H': 1, 'HAVE_SETREGID': 1, 'HAVE_STROPTS_H': 1, 'LDVERSION': '3.3m', 'abs_builddir': '/build/buildd/python3.3-3.3.1/build-shared', 'SITEPATH': '', 'HAVE_GETHOSTBYNAME': 0, 'HAVE_SIGPENDING': 1, 'HAVE_KQUEUE': 0, 'HAVE_SYNC': 1, 'HAVE_GETSID': 1, 'HAVE_ROUND': 1, 'HAVE_STRFTIME': 1, 'AST_H_DIR': 'Include', 'HAVE_PIPE2': 1, 'AST_C_DIR': 'Python', 'TESTPYTHONOPTS': '', 'HAVE_DEV_PTC': 0, 'GETTIMEOFDAY_NO_TZ': 0, 'HAVE_NET_IF_H': 1, 'HAVE_SENDFILE': 1, 'HAVE_SETPGRP': 1, 'HAVE_SEM_GETVALUE': 1, 'CONFIGURE_LDFLAGS': '-Wl,-Bsymbolic-functions -Wl,-z,relro', 'DLLLIBRARY': '', 'PYTHON_FOR_BUILD': './python -E', 'SETPGRP_HAVE_ARG': 0, 'HAVE_INET_ATON': 1, 'INSTALL_SHARED': '/usr/bin/install -c -m 555', 'WITH_DOC_STRINGS': 1, 'OPCODETARGETS_H': '\\\\', 'HAVE_INITGROUPS': 1, 'HAVE_LINKAT': 1, 'BASEMODLIBS': '', 'SGI_ABI': '', 'HAVE_SCHED_SETPARAM': 1, 'OPT': '-DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes', 'HAVE_POSIX_FADVISE': 1, 'datarootdir': '/usr/share', 'HAVE_MEMRCHR': 1, 'HGTAG': '', 'HAVE_MEMMOVE': 1, 'HAVE_GETRESUID': 1, 'DOUBLE_IS_ARM_MIXED_ENDIAN_IEEE754': 0, 'HAVE_LSTAT': 1, 'AR': 'ar', 'HAVE_WAIT4': 1, 'HAVE_SYS_MODEM_H': 0, 'INSTSONAME': 'libpython3.3m.so.1.0', 'HAVE_SYS_STATVFS_H': 1, 'HAVE_LGAMMA': 1, 'HAVE_PROTOTYPES': 1, 'HAVE_SYS_UIO_H': 1, 'MAJOR_IN_MKDEV': 0, 'QUICKTESTOPTS': '-x test_subprocess test_io test_lib2to3 \\\\', 'HAVE_SYS_DEVPOLL_H': 0, 'HAVE_CHFLAGS': 0, 'HAVE_FSYNC': 1, 'HAVE_FCHMOD': 1, 'INCLUDEPY': '/usr/include/python3.3m', 'HAVE_SEM_TIMEDWAIT': 1, 'LDLIBRARYDIR': '', 'HAVE_STRUCT_TM_TM_ZONE': 1, 'HAVE_CURSES_H': 1, 'TIME_WITH_SYS_TIME': 1, 'HAVE_DUP2': 1, 'ENABLE_IPV6': 1, 'WITH_VALGRIND': 0, 'HAVE_SETITIMER': 1, 'THREADOBJ': 'Python/thread.o', 'LOCALMODLIBS': '-lrt    -lexpat                   -L/usr/lib -lz  -lexpat', 'HAVE_MEMORY_H': 1, 'HAVE_GETITIMER': 1, 'HAVE_C99_BOOL': 1, 'INSTALL_DATA': '/usr/bin/install -c -m 644', 'PGEN': 'Parser/pgen', 'HAVE_GRP_H': 1, 'HAVE_WCSFTIME': 1, 'AIX_GENUINE_CPLUSPLUS': 0, 'HAVE_LIBINTL_H': 1, 'SHELL': '/bin/sh', 'HAVE_UNISTD_H': 1, 'EXTRATESTOPTS': '', 'HAVE_EXECV': 1, 'HAVE_FSEEK64': 0, 'MVWDELCH_IS_EXPRESSION': 1, 'DESTSHARED': '/usr/lib/python3.3/lib-dynload', 'OPCODETARGETGEN': '\\\\', 'LIBDEST': '/usr/lib/python3.3', 'CCSHARED': '-fPIC', 'HAVE_EXPM1': 1, 'HAVE_DLFCN_H': 1, 'exec_prefix': '/usr', 'HAVE_READLINK': 1, 'WINDOW_HAS_FLAGS': 1, 'HAVE_FTELL64': 0, 'HAVE_STRLCPY': 0, 'MACOSX_DEPLOYMENT_TARGET': '', 'HAVE_SYS_SYSCALL_H': 1, 'DESTLIB': '/usr/lib/python3.3', 'LDSHARED': 'i686-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wno-unused-result -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security  ', 'HGVERSION': '', 'PYTHON_HEADERS': '\\\\', 'HAVE_STRINGS_H': 1, 'DOUBLE_IS_LITTLE_ENDIAN_IEEE754': 1, 'HAVE_POSIX_FALLOCATE': 1, 'HAVE_DIRFD': 1, 'HAVE_LOG2': 1, 'HAVE_GETPID': 1, 'HAVE_ALARM': 1, 'MACHDEP_OBJS': '', 'HAVE_SPAWN_H': 1, 'HAVE_FORK': 1, 'HAVE_SETRESGID': 1, 'HAVE_FCHMODAT': 1, 'HAVE_CLOCK_GETRES': 1, 'MACHDEPPATH': ':plat-i386-linux-gnu', 'STDC_HEADERS': 1, 'HAVE_SETPRIORITY': 1, 'LIBC': '', 'HAVE_SYS_EPOLL_H': 1, 'HAVE_SYS_UTSNAME_H': 1, 'HAVE_PUTENV': 1, 'HAVE_CURSES_RESIZE_TERM': 1, 'HAVE_FUTIMESAT': 1, 'WITH_DYLD': 0, 'INSTALL_PROGRAM': '/usr/bin/install -c', 'LIBS': '-lpthread -ldl  -lutil', 'HAVE_TRUNCATE': 1, 'TESTOPTS': '', 'PROFILE_TASK': '../Tools/pybench/pybench.py -n 2 --with-gc --with-syscheck', 'HAVE_CURSES_RESIZETERM': 1, 'ABIFLAGS': 'm', 'HAVE_GETGROUPLIST': 1, 'OBJECT_OBJS': '\\\\', 'HAVE_MKNODAT': 1, 'HAVE_ST_BLOCKS': 1, 'HAVE_STRUCT_STAT_ST_GEN': 0, 'SYS_SELECT_WITH_SYS_TIME': 1, 'SHLIBS': '-lpthread -ldl  -lutil', 'HAVE_GETGROUPS': 1, 'MODULE_OBJS': '\\\\', 'PYTHONFRAMEWORKDIR': 'no-framework', 'HAVE_FCNTL_H': 1, 'HAVE_LINK': 1, 'HAVE_SIGWAIT': 1, 'HAVE_GAMMA': 1, 'HAVE_SYS_LOCK_H': 0, 'HAVE_FORKPTY': 1, 'HAVE_SOCKADDR_SA_LEN': 0, 'HAVE_TEMPNAM': 1, 'HAVE_STRUCT_STAT_ST_BLKSIZE': 1, 'HAVE_MKFIFOAT': 1, 'HAVE_SIGWAITINFO': 1, 'HAVE_FTIME': 1, 'HAVE_EPOLL': 1, 'HAVE_SYS_SOCKET_H': 1, 'HAVE_LARGEFILE_SUPPORT': 1, 'CONFIGURE_CFLAGS': '-g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security', 'HAVE_PTHREAD_DESTRUCTOR': 0, 'CONFIGURE_CPPFLAGS': '-D_FORTIFY_SOURCE=2', 'HAVE_SYMLINK': 1, 'HAVE_LONG_LONG': 1, 'HAVE_IEEEFP_H': 0, 'LIBDIR': '/usr/lib', 'HAVE_PTHREAD_KILL': 1, 'TESTPATH': '', 'HAVE_STRDUP': 1, 'POBJS': '\\\\', 'NO_AS_NEEDED': '-Wl,--no-as-needed', 'HAVE_LONG_DOUBLE': 1, 'HGBRANCH': '', 'DISTFILES': 'README ChangeLog configure configure.ac acconfig.h pyconfig.h.in Makefile.pre.in', 'PTHREAD_SYSTEM_SCHED_SUPPORTED': 1, 'HAVE_FACCESSAT': 1, 'AST_ASDL': '../Parser/Python.asdl', 'CPPFLAGS': '-I. -IInclude -I../Include -D_FORTIFY_SOURCE=2', 'HAVE_MKTIME': 1, 'HAVE_NDIR_H': 0, 'PY_CFLAGS': '-Wno-unused-result -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security  ', 'LIBOBJDIR': 'Python/', 'HAVE_LINUX_CAN_RAW_H': 1, 'HAVE_GETHOSTBYNAME_R_3_ARG': 0, 'PACKAGE_STRING': 0, 'GNULD': 'yes', 'LOG1P_DROPS_ZERO_SIGN': 0, 'HAVE_FTRUNCATE': 1, 'WITH_LIBINTL': 0, 'HAVE_MREMAP': 1, 'HAVE_DECL_ISNAN': 1, 'HAVE_KILLPG': 1, 'SIZEOF_LONG': 4, 'HAVE_DECL_ISFINITE': 1, 'HAVE_IPA_PURE_CONST_BUG': 0, 'WITH_PYMALLOC': 1, 'abs_srcdir': '/build/buildd/python3.3-3.3.1/build-shared/..', 'HAVE_FCHDIR': 1, 'HAVE_BROKEN_POSIX_SEMAPHORES': 0, 'AC_APPLE_UNIVERSAL_BUILD': 0, 'PGENSRCS': '\\\\ \\\\', 'DIRMODE': 755, 'HAVE_GETHOSTBYNAME_R': 1, 'HAVE_LCHFLAGS': 0, 'HAVE_SYS_PARAM_H': 1, 'SIZEOF_LONG_DOUBLE': 12, 'CONFIG_ARGS': \"'--enable-shared' '--prefix=/usr' '--enable-ipv6' '--enable-loadable-sqlite-extensions' '--with-dbmliborder=bdb:gdbm' '--with-computed-gotos' '--with-system-expat' '--with-system-ffi' '--with-fpectl' 'CC=i686-linux-gnu-gcc' 'CFLAGS=-g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security ' 'LDFLAGS=-Wl,-Bsymbolic-functions -Wl,-z,relro' 'CPPFLAGS=-D_FORTIFY_SOURCE=2'\", 'HAVE_SCHED_H': 1, 'HAVE_KILL': 1}\n\n"], "_struct": [".py", "\n\n\n\n\n\n\n\n\n\n\"\"\n\nimport math, sys\n\n\nclass StructError(Exception):\n pass\nerror = StructError\ndef unpack_int(data,index,size,le):\n bytes = [b for b in data[index:index+size]]\n if le == 'little':\n  bytes.reverse()\n number = 0\n for b in bytes:\n  number = number << 8 | b\n return int(number)\n \ndef unpack_signed_int(data,index,size,le):\n number = unpack_int(data,index,size,le)\n max = 2**(size*8)\n if number > 2**(size*8 - 1) - 1:\n  number = int(-1*(max - number))\n return number\n \nINFINITY = 1e200 * 1e200\nNAN = INFINITY / INFINITY\n\ndef unpack_char(data,index,size,le):\n return data[index:index+size]\n \ndef pack_int(number,size,le):\n x=number\n res=[]\n for i in range(size):\n  res.append(x&0xff)\n  x >>= 8\n if le == 'big':\n  res.reverse()\n return bytes(res)\n \ndef pack_signed_int(number,size,le):\n if not isinstance(number, int):\n  raise StructError(\"argument for i,I,l,L,q,Q,h,H must be integer\")\n if number > 2**(8*size-1)-1 or number < -1*2**(8*size-1):\n  raise OverflowError(\"Number:%i too large to convert\" % number)\n return pack_int(number,size,le)\n \ndef pack_unsigned_int(number,size,le):\n if not isinstance(number, int):\n  raise StructError(\"argument for i,I,l,L,q,Q,h,H must be integer\")\n if number < 0:\n  raise TypeError(\"can't convert negative long to unsigned\")\n if number > 2**(8*size)-1:\n  raise OverflowError(\"Number:%i too large to convert\" % number)\n return pack_int(number,size,le)\n \ndef pack_char(char,size,le):\n return bytes(char)\n \ndef isinf(x):\n return x != 0.0 and x / 2 == x\ndef isnan(v):\n return v != v*1.0 or (v == 1.0 and v == 2.0)\n \ndef pack_float(x, size, le):\n unsigned = float_pack(x, size)\n result = []\n for i in range(8):\n  result.append((unsigned >> (i * 8)) & 0xFF)\n if le == \"big\":\n  result.reverse()\n return bytes(result)\n \ndef unpack_float(data, index, size, le):\n binary = [data[i] for i in range(index, index + 8)]\n if le == \"big\":\n  binary.reverse()\n unsigned = 0\n for i in range(8):\n  unsigned |= binary[i] << (i * 8)\n return float_unpack(unsigned, size, le)\n \ndef round_to_nearest(x):\n \"\"\n int_part = int(x)\n frac_part = x - int_part\n if frac_part > 0.5 or frac_part == 0.5 and int_part & 1 == 1:\n  int_part += 1\n return int_part\n \ndef float_unpack(Q, size, le):\n \"\"\n \n if size == 8:\n  MIN_EXP = -1021 \n  MAX_EXP = 1024 \n  MANT_DIG = 53 \n  BITS = 64\n elif size == 4:\n  MIN_EXP = -125 \n  MAX_EXP = 128 \n  MANT_DIG = 24 \n  BITS = 32\n else:\n  raise ValueError(\"invalid size value\")\n  \n if Q >> BITS:\n  raise ValueError(\"input out of range\")\n  \n  \n sign = Q >> BITS - 1\n exp = (Q & ((1 << BITS - 1) - (1 << MANT_DIG - 1))) >> MANT_DIG - 1\n mant = Q & ((1 << MANT_DIG - 1) - 1)\n \n if exp == MAX_EXP - MIN_EXP + 2:\n \n  result = float('nan') if mant else float('inf')\n elif exp == 0:\n \n  result = math.ldexp(float(mant), MIN_EXP - MANT_DIG)\n else:\n \n  mant += 1 << MANT_DIG - 1\n  result = math.ldexp(float(mant), exp + MIN_EXP - MANT_DIG - 1)\n return -result if sign else result\n \n \ndef float_pack(x, size):\n \"\"\n \n if size == 8:\n  MIN_EXP = -1021 \n  MAX_EXP = 1024 \n  MANT_DIG = 53 \n  BITS = 64\n elif size == 4:\n  MIN_EXP = -125 \n  MAX_EXP = 128 \n  MANT_DIG = 24 \n  BITS = 32\n else:\n  raise ValueError(\"invalid size value\")\n  \n sign = math.copysign(1.0, x) < 0.0\n if math.isinf(x):\n  mant = 0\n  exp = MAX_EXP - MIN_EXP + 2\n elif math.isnan(x):\n  mant = 1 << (MANT_DIG-2) \n  exp = MAX_EXP - MIN_EXP + 2\n elif x == 0.0:\n  mant = 0\n  exp = 0\n else:\n  m, e = math.frexp(abs(x)) \n  exp = e - (MIN_EXP - 1)\n  if exp > 0:\n  \n   mant = round_to_nearest(m * (1 << MANT_DIG))\n   mant -= 1 << MANT_DIG - 1\n  else:\n  \n   if exp + MANT_DIG - 1 >= 0:\n    mant = round_to_nearest(m * (1 << exp + MANT_DIG - 1))\n   else:\n    mant = 0\n   exp = 0\n   \n   \n  assert 0 <= mant <= 1 << MANT_DIG - 1\n  if mant == 1 << MANT_DIG - 1:\n   mant = 0\n   exp += 1\n   \n   \n   \n  if exp >= MAX_EXP - MIN_EXP + 2:\n   raise OverflowError(\"float too large to pack in this format\")\n   \n   \n assert 0 <= mant < 1 << MANT_DIG - 1\n assert 0 <= exp <= MAX_EXP - MIN_EXP + 2\n assert 0 <= sign <= 1\n return ((sign << BITS - 1) | (exp << MANT_DIG - 1)) | mant\n \n \nbig_endian_format = {\n'x':{ 'size' : 1, 'alignment' : 0, 'pack' : None, 'unpack' : None},\n'b':{ 'size' : 1, 'alignment' : 0, 'pack' : pack_signed_int, 'unpack' : unpack_signed_int},\n'B':{ 'size' : 1, 'alignment' : 0, 'pack' : pack_unsigned_int, 'unpack' : unpack_int},\n'c':{ 'size' : 1, 'alignment' : 0, 'pack' : pack_char, 'unpack' : unpack_char},\n's':{ 'size' : 1, 'alignment' : 0, 'pack' : None, 'unpack' : None},\n'p':{ 'size' : 1, 'alignment' : 0, 'pack' : None, 'unpack' : None},\n'h':{ 'size' : 2, 'alignment' : 0, 'pack' : pack_signed_int, 'unpack' : unpack_signed_int},\n'H':{ 'size' : 2, 'alignment' : 0, 'pack' : pack_unsigned_int, 'unpack' : unpack_int},\n'i':{ 'size' : 4, 'alignment' : 0, 'pack' : pack_signed_int, 'unpack' : unpack_signed_int},\n'I':{ 'size' : 4, 'alignment' : 0, 'pack' : pack_unsigned_int, 'unpack' : unpack_int},\n'l':{ 'size' : 4, 'alignment' : 0, 'pack' : pack_signed_int, 'unpack' : unpack_signed_int},\n'L':{ 'size' : 4, 'alignment' : 0, 'pack' : pack_unsigned_int, 'unpack' : unpack_int},\n'q':{ 'size' : 8, 'alignment' : 0, 'pack' : pack_signed_int, 'unpack' : unpack_signed_int},\n'Q':{ 'size' : 8, 'alignment' : 0, 'pack' : pack_unsigned_int, 'unpack' : unpack_int},\n'f':{ 'size' : 4, 'alignment' : 0, 'pack' : pack_float, 'unpack' : unpack_float},\n'd':{ 'size' : 8, 'alignment' : 0, 'pack' : pack_float, 'unpack' : unpack_float},\n}\ndefault = big_endian_format\nformatmode={ '<' : (default, 'little'),\n'>' : (default, 'big'),\n'!' : (default, 'big'),\n'=' : (default, sys.byteorder),\n'@' : (default, sys.byteorder)\n}\n\ndef getmode(fmt):\n try:\n  formatdef,endianness = formatmode[fmt[0]]\n  index = 1\n except (IndexError, KeyError):\n  formatdef,endianness = formatmode['@']\n  index = 0\n return formatdef,endianness,index\ndef getNum(fmt,i):\n num=None\n cur = fmt[i]\n while ('0'<= cur ) and ( cur <= '9'):\n  if num == None:\n   num = int(cur)\n  else:\n   num = 10*num + int(cur)\n  i += 1\n  cur = fmt[i]\n return num,i\n \ndef calcsize(fmt):\n \"\"\n \n formatdef,endianness,i = getmode(fmt)\n num = 0\n result = 0\n while i<len(fmt):\n  num,i = getNum(fmt,i)\n  cur = fmt[i]\n  try:\n   format = formatdef[cur]\n  except KeyError:\n   raise StructError(\"%s is not a valid format\" % cur)\n  if num != None :\n   result += num*format['size']\n  else:\n   result += format['size']\n  num = 0\n  i += 1\n return result\n \ndef pack(fmt,*args):\n \"\"\n formatdef,endianness,i = getmode(fmt)\n args = list(args)\n n_args = len(args)\n result = []\n while i<len(fmt):\n  num,i = getNum(fmt,i)\n  cur = fmt[i]\n  try:\n   format = formatdef[cur]\n  except KeyError:\n   raise StructError(\"%s is not a valid format\" % cur)\n  if num == None :\n   num_s = 0\n   num = 1\n  else:\n   num_s = num\n   \n  if cur == 'x':\n   result += [b'\\0'*num]\n  elif cur == 's':\n   if isinstance(args[0], bytes):\n    padding = num - len(args[0])\n    result += [args[0][:num] + b'\\0'*padding]\n    args.pop(0)\n   else:\n    raise StructError(\"arg for string format not a string\")\n  elif cur == 'p':\n   if isinstance(args[0], bytes):\n    padding = num - len(args[0]) - 1\n    \n    if padding > 0:\n     result += [bytes([len(args[0])]) + args[0][:num-1] + b'\\0'*padding]\n    else:\n     if num<255:\n      result += [bytes([num-1]) + args[0][:num-1]]\n     else:\n      result += [bytes([255]) + args[0][:num-1]]\n    args.pop(0)\n   else:\n    raise StructError(\"arg for string format not a string\")\n    \n  else:\n   if len(args) < num:\n    raise StructError(\"insufficient arguments to pack\")\n   for var in args[:num]:\n    result += [format['pack'](var,format['size'],endianness)]\n   args=args[num:]\n  num = None\n  i += 1\n if len(args) != 0:\n  raise StructError(\"too many arguments for pack format\")\n return b''.join(result)\n \ndef unpack(fmt,data):\n \"\"\n formatdef,endianness,i = getmode(fmt)\n j = 0\n num = 0\n result = []\n length= calcsize(fmt)\n if length != len (data):\n  raise StructError(\"unpack str size does not match format\")\n while i<len(fmt):\n  num,i=getNum(fmt,i)\n  cur = fmt[i]\n  i += 1\n  try:\n   format = formatdef[cur]\n  except KeyError:\n   raise StructError(\"%s is not a valid format\" % cur)\n   \n  if not num :\n   num = 1\n   \n  if cur == 'x':\n   j += num\n  elif cur == 's':\n   result.append(data[j:j+num])\n   j += num\n  elif cur == 'p':\n   n=data[j]\n   if n >= num:\n    n = num-1\n   result.append(data[j+1:j+n+1])\n   j += num\n  else:\n   for n in range(num):\n    result += [format['unpack'](data,j,format['size'],endianness)]\n    j += format['size']\n    \n return tuple(result)\n \ndef pack_into(fmt, buf, offset, *args):\n data = pack(fmt, *args)\n buffer(buf)[offset:offset+len(data)] = data\n \ndef unpack_from(fmt, buf, offset=0):\n size = calcsize(fmt)\n data = buffer(buf)[offset:offset+size]\n if len(data) != size:\n  raise error(\"unpack_from requires a buffer of at least %d bytes\"\n  % (size,))\n return unpack(fmt, data)\n \ndef _clearcache():\n \"\"\n \n"], "xml.parsers.expat": [".py", "\"\"\nimport sys\n\nfrom pyexpat import *\n\n\nsys.modules['xml.parsers.expat.model'] = model\nsys.modules['xml.parsers.expat.errors'] = errors\n"], "hashlib": [".js", "var $module=(function($B){\n\nvar _b_ = $B.builtins\n\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n//for(var $py_builtin in _b_){eval(\"var \"+$py_builtin+\"=_b_[$py_builtin]\")}\n\nvar $mod = {\n\n    __getattr__ : function(attr){\n        if (attr == 'new') return $hashlib_new;\n        return this[attr]\n    },\n    md5: function() {return $hashlib_new('md5')},\n    sha1: function() {return $hashlib_new('sha1')},\n    sha224: function() {return $hashlib_new('sha224')},\n    sha256: function() {return $hashlib_new('sha256')},\n    sha384: function() {return $hashlib_new('sha384')},\n    sha512: function() {return $hashlib_new('sha512')},\n\n    algorithms_guaranteed: ['md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512'],\n    algorithms_available:  ['md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512']\n}\n\n\n//todo: eventually move this function to a \"utility\" file or use ajax module?\nfunction $get_CryptoJS_lib(alg) {\n   var imp=$importer()\n   var $xmlhttp=imp[0], fake_qs=imp[1], timer=imp[2], res=null\n\n   $xmlhttp.onreadystatechange = function(){\n        if($xmlhttp.readyState==4){\n            window.clearTimeout(timer)\n            if($xmlhttp.status==200 || $xmlhttp.status==0){res=$xmlhttp.responseText}\n            else{\n                // don't throw an exception here, it will not be caught (issue #30)\n                res = Error()\n                res.name = 'NotFoundError'\n                res.message = \"No CryptoJS lib named '\"+alg+\"'\"\n            }\n        }\n   }\n\n   $xmlhttp.open('GET', $B.brython_path+'libs/crypto_js/rollups/'+alg+'.js'+fake_qs,false)\n   if('overrideMimeType' in $xmlhttp){$xmlhttp.overrideMimeType(\"text/plain\")}\n   $xmlhttp.send()\n   if(res.constructor===Error){throw res} // module not found\n\n   try{\n      eval(res + \"; $B.CryptoJS=CryptoJS;\")\n   } catch (err) { \n      throw Error(\"JS Eval Error\", \"Cannot eval CryptoJS algorithm '\" + alg + \"' : error:\" + err);\n   }\n}\n\nfunction $hashlib_new(alg) {\n    if (alg == 'md5') {\n       if ($B.Crypto === undefined || \n           $B.CryptoJS.algo.MD5 === undefined) $get_CryptoJS_lib('md5')\n       this.hash = $B.CryptoJS.algo.MD5.create()\n    } else if (alg == 'sha1') {\n       if ($B.Crypto === undefined ||\n           $B.CryptoJS.algo.SHA1 === undefined) $get_CryptoJS_lib('sha1')\n       this.hash = $B.CryptoJS.algo.SHA1.create()\n    } else if (alg == 'sha224') {\n       if ($B.Crypto === undefined || \n           $B.CryptoJS.algo.SHA224 === undefined) $get_CryptoJS_lib('sha224')\n       this.hash = $B.CryptoJS.algo.SHA224.create()\n    } else if (alg == 'sha256') {\n       if ($B.Crypto === undefined || \n           $B.CryptoJS.algo.SHA256 === undefined) $get_CryptoJS_lib('sha256')\n       this.hash = $B.CryptoJS.algo.SHA256.create()\n    } else if (alg == 'sha384') {\n       if ($B.Crypto === undefined || \n           $B.CryptoJS.algo.SHA384 === undefined) $get_CryptoJS_lib('sha384')\n       this.hash = $B.CryptoJS.algo.SHA384.create()\n    } else if (alg == 'sha512') {\n       if ($B.Crypto === undefined || \n           $B.CryptoJS.algo.SHA512 === undefined) $get_CryptoJS_lib('sha512')\n       this.hash = $B.CryptoJS.algo.SHA512.create()\n    } else {\n       $raise('AttributeError', 'Invalid hash algorithm:' + alg)\n    }\n \n    this.__class__ = $B.$type\n    this.__getattr__ = function(attr){return $getattr(this,attr)}\n    this.__str__ = function(){return this.hexdigest()}\n    this.update = function(msg){this.hash.update(msg)}\n    this.copy = function(){return this.hash.clone()}\n\n    this.hexdigest = function() {\n        var temp=this.hash.clone();\n        temp=temp.finalize();\n        return temp.toString();\n    }\n\n    return this;\n}\n\nreturn $mod\n\n})(__BRYTHON__)\n"], "keyword": [".py", "\n\n\"\"\n\n__all__ = [\"iskeyword\", \"kwlist\"]\n\nkwlist = [\n\n'False',\n'None',\n'True',\n'and',\n'as',\n'assert',\n'break',\n'class',\n'continue',\n'def',\n'del',\n'elif',\n'else',\n'except',\n'finally',\n'for',\n'from',\n'global',\n'if',\n'import',\n'in',\n'is',\n'lambda',\n'nonlocal',\n'not',\n'or',\n'pass',\n'raise',\n'return',\n'try',\n'while',\n'with',\n'yield',\n\n]\n\niskeyword = frozenset(kwlist).__contains__\n\ndef main():\n import sys, re\n \n args = sys.argv[1:]\n iptfile = args and args[0] or \"Python/graminit.c\"\n if len(args) > 1: optfile = args[1]\n else: optfile = \"Lib/keyword.py\"\n \n \n with open(iptfile) as fp:\n  strprog = re.compile('\"([^\"]+)\"')\n  lines = []\n  for line in fp:\n   if '{1, \"' in line:\n    match = strprog.search(line)\n    if match:\n     lines.append(\"        '\" + match.group(1) + \"',\\n\")\n lines.sort()\n \n \n with open(optfile) as fp:\n  format = fp.readlines()\n  \n  \n try:\n  start = format.index(\"#--start keywords--\\n\") + 1\n  end = format.index(\"#--end keywords--\\n\")\n  format[start:end] = lines\n except ValueError:\n  sys.stderr.write(\"target does not contain format markers\\n\")\n  sys.exit(1)\n  \n  \n fp = open(optfile, 'w')\n fp.write(''.join(format))\n fp.close()\n \nif __name__ == \"__main__\":\n main()\n"], "unittest.test.testmock.testhelpers": [".py", "import unittest\n\nfrom unittest.mock import (\ncall, _Call, create_autospec, MagicMock,\nMock, ANY, _CallList, patch, PropertyMock\n)\n\nfrom datetime import datetime\n\nclass SomeClass(object):\n def one(self, a, b):\n  pass\n def two(self):\n  pass\n def three(self, a=None):\n  pass\n  \n  \n  \nclass AnyTest(unittest.TestCase):\n\n def test_any(self):\n  self.assertEqual(ANY, object())\n  \n  mock = Mock()\n  mock(ANY)\n  mock.assert_called_with(ANY)\n  \n  mock = Mock()\n  mock(foo=ANY)\n  mock.assert_called_with(foo=ANY)\n  \n def test_repr(self):\n  self.assertEqual(repr(ANY), '<ANY>')\n  self.assertEqual(str(ANY), '<ANY>')\n  \n  \n def test_any_and_datetime(self):\n  mock = Mock()\n  mock(datetime.now(), foo=datetime.now())\n  \n  mock.assert_called_with(ANY, foo=ANY)\n  \n  \n def test_any_mock_calls_comparison_order(self):\n  mock = Mock()\n  d = datetime.now()\n  class Foo(object):\n   def __eq__(self, other):\n    return False\n   def __ne__(self, other):\n    return True\n    \n  for d in datetime.now(), Foo():\n   mock.reset_mock()\n   \n   mock(d, foo=d, bar=d)\n   mock.method(d, zinga=d, alpha=d)\n   mock().method(a1=d, z99=d)\n   \n   expected = [\n   call(ANY, foo=ANY, bar=ANY),\n   call.method(ANY, zinga=ANY, alpha=ANY),\n   call(), call().method(a1=ANY, z99=ANY)\n   ]\n   self.assertEqual(expected, mock.mock_calls)\n   self.assertEqual(mock.mock_calls, expected)\n   \n   \n   \nclass CallTest(unittest.TestCase):\n\n def test_call_with_call(self):\n  kall = _Call()\n  self.assertEqual(kall, _Call())\n  self.assertEqual(kall, _Call(('',)))\n  self.assertEqual(kall, _Call(((),)))\n  self.assertEqual(kall, _Call(({},)))\n  self.assertEqual(kall, _Call(('', ())))\n  self.assertEqual(kall, _Call(('', {})))\n  self.assertEqual(kall, _Call(('', (), {})))\n  self.assertEqual(kall, _Call(('foo',)))\n  self.assertEqual(kall, _Call(('bar', ())))\n  self.assertEqual(kall, _Call(('baz', {})))\n  self.assertEqual(kall, _Call(('spam', (), {})))\n  \n  kall = _Call(((1, 2, 3),))\n  self.assertEqual(kall, _Call(((1, 2, 3),)))\n  self.assertEqual(kall, _Call(('', (1, 2, 3))))\n  self.assertEqual(kall, _Call(((1, 2, 3), {})))\n  self.assertEqual(kall, _Call(('', (1, 2, 3), {})))\n  \n  kall = _Call(((1, 2, 4),))\n  self.assertNotEqual(kall, _Call(('', (1, 2, 3))))\n  self.assertNotEqual(kall, _Call(('', (1, 2, 3), {})))\n  \n  kall = _Call(('foo', (1, 2, 4),))\n  self.assertNotEqual(kall, _Call(('', (1, 2, 4))))\n  self.assertNotEqual(kall, _Call(('', (1, 2, 4), {})))\n  self.assertNotEqual(kall, _Call(('bar', (1, 2, 4))))\n  self.assertNotEqual(kall, _Call(('bar', (1, 2, 4), {})))\n  \n  kall = _Call(({'a': 3},))\n  self.assertEqual(kall, _Call(('', (), {'a': 3})))\n  self.assertEqual(kall, _Call(('', {'a': 3})))\n  self.assertEqual(kall, _Call(((), {'a': 3})))\n  self.assertEqual(kall, _Call(({'a': 3},)))\n  \n  \n def test_empty__Call(self):\n  args = _Call()\n  \n  self.assertEqual(args, ())\n  self.assertEqual(args, ('foo',))\n  self.assertEqual(args, ((),))\n  self.assertEqual(args, ('foo', ()))\n  self.assertEqual(args, ('foo',(), {}))\n  self.assertEqual(args, ('foo', {}))\n  self.assertEqual(args, ({},))\n  \n  \n def test_named_empty_call(self):\n  args = _Call(('foo', (), {}))\n  \n  self.assertEqual(args, ('foo',))\n  self.assertEqual(args, ('foo', ()))\n  self.assertEqual(args, ('foo',(), {}))\n  self.assertEqual(args, ('foo', {}))\n  \n  self.assertNotEqual(args, ((),))\n  self.assertNotEqual(args, ())\n  self.assertNotEqual(args, ({},))\n  self.assertNotEqual(args, ('bar',))\n  self.assertNotEqual(args, ('bar', ()))\n  self.assertNotEqual(args, ('bar', {}))\n  \n  \n def test_call_with_args(self):\n  args = _Call(((1, 2, 3), {}))\n  \n  self.assertEqual(args, ((1, 2, 3),))\n  self.assertEqual(args, ('foo', (1, 2, 3)))\n  self.assertEqual(args, ('foo', (1, 2, 3), {}))\n  self.assertEqual(args, ((1, 2, 3), {}))\n  \n  \n def test_named_call_with_args(self):\n  args = _Call(('foo', (1, 2, 3), {}))\n  \n  self.assertEqual(args, ('foo', (1, 2, 3)))\n  self.assertEqual(args, ('foo', (1, 2, 3), {}))\n  \n  self.assertNotEqual(args, ((1, 2, 3),))\n  self.assertNotEqual(args, ((1, 2, 3), {}))\n  \n  \n def test_call_with_kwargs(self):\n  args = _Call(((), dict(a=3, b=4)))\n  \n  self.assertEqual(args, (dict(a=3, b=4),))\n  self.assertEqual(args, ('foo', dict(a=3, b=4)))\n  self.assertEqual(args, ('foo', (), dict(a=3, b=4)))\n  self.assertEqual(args, ((), dict(a=3, b=4)))\n  \n  \n def test_named_call_with_kwargs(self):\n  args = _Call(('foo', (), dict(a=3, b=4)))\n  \n  self.assertEqual(args, ('foo', dict(a=3, b=4)))\n  self.assertEqual(args, ('foo', (), dict(a=3, b=4)))\n  \n  self.assertNotEqual(args, (dict(a=3, b=4),))\n  self.assertNotEqual(args, ((), dict(a=3, b=4)))\n  \n  \n def test_call_with_args_call_empty_name(self):\n  args = _Call(((1, 2, 3), {}))\n  self.assertEqual(args, call(1, 2, 3))\n  self.assertEqual(call(1, 2, 3), args)\n  self.assertTrue(call(1, 2, 3) in [args])\n  \n  \n def test_call_ne(self):\n  self.assertNotEqual(_Call(((1, 2, 3),)), call(1, 2))\n  self.assertFalse(_Call(((1, 2, 3),)) != call(1, 2, 3))\n  self.assertTrue(_Call(((1, 2), {})) != call(1, 2, 3))\n  \n  \n def test_call_non_tuples(self):\n  kall = _Call(((1, 2, 3),))\n  for value in 1, None, self, int:\n   self.assertNotEqual(kall, value)\n   self.assertFalse(kall == value)\n   \n   \n def test_repr(self):\n  self.assertEqual(repr(_Call()), 'call()')\n  self.assertEqual(repr(_Call(('foo',))), 'call.foo()')\n  \n  self.assertEqual(repr(_Call(((1, 2, 3), {'a': 'b'}))),\n  \"call(1, 2, 3, a='b')\")\n  self.assertEqual(repr(_Call(('bar', (1, 2, 3), {'a': 'b'}))),\n  \"call.bar(1, 2, 3, a='b')\")\n  \n  self.assertEqual(repr(call), 'call')\n  self.assertEqual(str(call), 'call')\n  \n  self.assertEqual(repr(call()), 'call()')\n  self.assertEqual(repr(call(1)), 'call(1)')\n  self.assertEqual(repr(call(zz='thing')), \"call(zz='thing')\")\n  \n  self.assertEqual(repr(call().foo), 'call().foo')\n  self.assertEqual(repr(call(1).foo.bar(a=3).bing),\n  'call().foo.bar().bing')\n  self.assertEqual(\n  repr(call().foo(1, 2, a=3)),\n  \"call().foo(1, 2, a=3)\"\n  )\n  self.assertEqual(repr(call()()), \"call()()\")\n  self.assertEqual(repr(call(1)(2)), \"call()(2)\")\n  self.assertEqual(\n  repr(call()().bar().baz.beep(1)),\n  \"call()().bar().baz.beep(1)\"\n  )\n  \n  \n def test_call(self):\n  self.assertEqual(call(), ('', (), {}))\n  self.assertEqual(call('foo', 'bar', one=3, two=4),\n  ('', ('foo', 'bar'), {'one': 3, 'two': 4}))\n  \n  mock = Mock()\n  mock(1, 2, 3)\n  mock(a=3, b=6)\n  self.assertEqual(mock.call_args_list,\n  [call(1, 2, 3), call(a=3, b=6)])\n  \n def test_attribute_call(self):\n  self.assertEqual(call.foo(1), ('foo', (1,), {}))\n  self.assertEqual(call.bar.baz(fish='eggs'),\n  ('bar.baz', (), {'fish': 'eggs'}))\n  \n  mock = Mock()\n  mock.foo(1, 2 ,3)\n  mock.bar.baz(a=3, b=6)\n  self.assertEqual(mock.method_calls,\n  [call.foo(1, 2, 3), call.bar.baz(a=3, b=6)])\n  \n  \n def test_extended_call(self):\n  result = call(1).foo(2).bar(3, a=4)\n  self.assertEqual(result, ('().foo().bar', (3,), dict(a=4)))\n  \n  mock = MagicMock()\n  mock(1, 2, a=3, b=4)\n  self.assertEqual(mock.call_args, call(1, 2, a=3, b=4))\n  self.assertNotEqual(mock.call_args, call(1, 2, 3))\n  \n  self.assertEqual(mock.call_args_list, [call(1, 2, a=3, b=4)])\n  self.assertEqual(mock.mock_calls, [call(1, 2, a=3, b=4)])\n  \n  mock = MagicMock()\n  mock.foo(1).bar()().baz.beep(a=6)\n  \n  last_call = call.foo(1).bar()().baz.beep(a=6)\n  self.assertEqual(mock.mock_calls[-1], last_call)\n  self.assertEqual(mock.mock_calls, last_call.call_list())\n  \n  \n def test_call_list(self):\n  mock = MagicMock()\n  mock(1)\n  self.assertEqual(call(1).call_list(), mock.mock_calls)\n  \n  mock = MagicMock()\n  mock(1).method(2)\n  self.assertEqual(call(1).method(2).call_list(),\n  mock.mock_calls)\n  \n  mock = MagicMock()\n  mock(1).method(2)(3)\n  self.assertEqual(call(1).method(2)(3).call_list(),\n  mock.mock_calls)\n  \n  mock = MagicMock()\n  int(mock(1).method(2)(3).foo.bar.baz(4)(5))\n  kall = call(1).method(2)(3).foo.bar.baz(4)(5).__int__()\n  self.assertEqual(kall.call_list(), mock.mock_calls)\n  \n  \n def test_call_any(self):\n  self.assertEqual(call, ANY)\n  \n  m = MagicMock()\n  int(m)\n  self.assertEqual(m.mock_calls, [ANY])\n  self.assertEqual([ANY], m.mock_calls)\n  \n  \n def test_two_args_call(self):\n  args = _Call(((1, 2), {'a': 3}), two=True)\n  self.assertEqual(len(args), 2)\n  self.assertEqual(args[0], (1, 2))\n  self.assertEqual(args[1], {'a': 3})\n  \n  other_args = _Call(((1, 2), {'a': 3}))\n  self.assertEqual(args, other_args)\n  \n  \nclass SpecSignatureTest(unittest.TestCase):\n\n def _check_someclass_mock(self, mock):\n  self.assertRaises(AttributeError, getattr, mock, 'foo')\n  mock.one(1, 2)\n  mock.one.assert_called_with(1, 2)\n  self.assertRaises(AssertionError,\n  mock.one.assert_called_with, 3, 4)\n  self.assertRaises(TypeError, mock.one, 1)\n  \n  mock.two()\n  mock.two.assert_called_with()\n  self.assertRaises(AssertionError,\n  mock.two.assert_called_with, 3)\n  self.assertRaises(TypeError, mock.two, 1)\n  \n  mock.three()\n  mock.three.assert_called_with()\n  self.assertRaises(AssertionError,\n  mock.three.assert_called_with, 3)\n  self.assertRaises(TypeError, mock.three, 3, 2)\n  \n  mock.three(1)\n  mock.three.assert_called_with(1)\n  \n  mock.three(a=1)\n  mock.three.assert_called_with(a=1)\n  \n  \n def test_basic(self):\n  for spec in (SomeClass, SomeClass()):\n   mock = create_autospec(spec)\n   self._check_someclass_mock(mock)\n   \n   \n def test_create_autospec_return_value(self):\n  def f():\n   pass\n  mock = create_autospec(f, return_value='foo')\n  self.assertEqual(mock(), 'foo')\n  \n  class Foo(object):\n   pass\n   \n  mock = create_autospec(Foo, return_value='foo')\n  self.assertEqual(mock(), 'foo')\n  \n  \n def test_autospec_reset_mock(self):\n  m = create_autospec(int)\n  int(m)\n  m.reset_mock()\n  self.assertEqual(m.__int__.call_count, 0)\n  \n  \n def test_mocking_unbound_methods(self):\n  class Foo(object):\n   def foo(self, foo):\n    pass\n  p = patch.object(Foo, 'foo')\n  mock_foo = p.start()\n  Foo().foo(1)\n  \n  mock_foo.assert_called_with(1)\n  \n  \n def test_create_autospec_unbound_methods(self):\n \n \n  return\n  class Foo(object):\n   def foo(self):\n    pass\n    \n  klass = create_autospec(Foo)\n  instance = klass()\n  self.assertRaises(TypeError, instance.foo, 1)\n  \n  \n  klass.foo(1)\n  klass.foo.assert_called_with(1)\n  self.assertRaises(TypeError, klass.foo)\n  \n  \n def test_create_autospec_keyword_arguments(self):\n  class Foo(object):\n   a = 3\n  m = create_autospec(Foo, a='3')\n  self.assertEqual(m.a, '3')\n  \n  \n def test_create_autospec_keyword_only_arguments(self):\n  def foo(a, *, b=None):\n   pass\n   \n  m = create_autospec(foo)\n  m(1)\n  m.assert_called_with(1)\n  self.assertRaises(TypeError, m, 1, 2)\n  \n  m(2, b=3)\n  m.assert_called_with(2, b=3)\n  \n  \n def test_function_as_instance_attribute(self):\n  obj = SomeClass()\n  def f(a):\n   pass\n  obj.f = f\n  \n  mock = create_autospec(obj)\n  mock.f('bing')\n  mock.f.assert_called_with('bing')\n  \n  \n def test_spec_as_list(self):\n \n \n  mock = create_autospec([])\n  mock.append('foo')\n  mock.append.assert_called_with('foo')\n  \n  self.assertRaises(AttributeError, getattr, mock, 'foo')\n  \n  class Foo(object):\n   foo = []\n   \n  mock = create_autospec(Foo)\n  mock.foo.append(3)\n  mock.foo.append.assert_called_with(3)\n  self.assertRaises(AttributeError, getattr, mock.foo, 'foo')\n  \n  \n def test_attributes(self):\n  class Sub(SomeClass):\n   attr = SomeClass()\n   \n  sub_mock = create_autospec(Sub)\n  \n  for mock in (sub_mock, sub_mock.attr):\n   self._check_someclass_mock(mock)\n   \n   \n def test_builtin_functions_types(self):\n \n \n \n  class BuiltinSubclass(list):\n   def bar(self, arg):\n    pass\n   sorted = sorted\n   attr = {}\n   \n  mock = create_autospec(BuiltinSubclass)\n  mock.append(3)\n  mock.append.assert_called_with(3)\n  self.assertRaises(AttributeError, getattr, mock.append, 'foo')\n  \n  mock.bar('foo')\n  mock.bar.assert_called_with('foo')\n  self.assertRaises(TypeError, mock.bar, 'foo', 'bar')\n  self.assertRaises(AttributeError, getattr, mock.bar, 'foo')\n  \n  mock.sorted([1, 2])\n  mock.sorted.assert_called_with([1, 2])\n  self.assertRaises(AttributeError, getattr, mock.sorted, 'foo')\n  \n  mock.attr.pop(3)\n  mock.attr.pop.assert_called_with(3)\n  self.assertRaises(AttributeError, getattr, mock.attr, 'foo')\n  \n  \n def test_method_calls(self):\n  class Sub(SomeClass):\n   attr = SomeClass()\n   \n  mock = create_autospec(Sub)\n  mock.one(1, 2)\n  mock.two()\n  mock.three(3)\n  \n  expected = [call.one(1, 2), call.two(), call.three(3)]\n  self.assertEqual(mock.method_calls, expected)\n  \n  mock.attr.one(1, 2)\n  mock.attr.two()\n  mock.attr.three(3)\n  \n  expected.extend(\n  [call.attr.one(1, 2), call.attr.two(), call.attr.three(3)]\n  )\n  self.assertEqual(mock.method_calls, expected)\n  \n  \n def test_magic_methods(self):\n  class BuiltinSubclass(list):\n   attr = {}\n   \n  mock = create_autospec(BuiltinSubclass)\n  self.assertEqual(list(mock), [])\n  self.assertRaises(TypeError, int, mock)\n  self.assertRaises(TypeError, int, mock.attr)\n  self.assertEqual(list(mock), [])\n  \n  self.assertIsInstance(mock['foo'], MagicMock)\n  self.assertIsInstance(mock.attr['foo'], MagicMock)\n  \n  \n def test_spec_set(self):\n  class Sub(SomeClass):\n   attr = SomeClass()\n   \n  for spec in (Sub, Sub()):\n   mock = create_autospec(spec, spec_set=True)\n   self._check_someclass_mock(mock)\n   \n   self.assertRaises(AttributeError, setattr, mock, 'foo', 'bar')\n   self.assertRaises(AttributeError, setattr, mock.attr, 'foo', 'bar')\n   \n   \n def test_descriptors(self):\n  class Foo(object):\n   @classmethod\n   def f(cls, a, b):\n    pass\n   @staticmethod\n   def g(a, b):\n    pass\n    \n  class Bar(Foo):\n   pass\n   \n  class Baz(SomeClass, Bar):\n   pass\n   \n  for spec in (Foo, Foo(), Bar, Bar(), Baz, Baz()):\n   mock = create_autospec(spec)\n   mock.f(1, 2)\n   mock.f.assert_called_once_with(1, 2)\n   \n   mock.g(3, 4)\n   mock.g.assert_called_once_with(3, 4)\n   \n   \n def test_recursive(self):\n  class A(object):\n   def a(self):\n    pass\n   foo = 'foo bar baz'\n   bar = foo\n   \n  A.B = A\n  mock = create_autospec(A)\n  \n  mock()\n  self.assertFalse(mock.B.called)\n  \n  mock.a()\n  mock.B.a()\n  self.assertEqual(mock.method_calls, [call.a(), call.B.a()])\n  \n  self.assertIs(A.foo, A.bar)\n  self.assertIsNot(mock.foo, mock.bar)\n  mock.foo.lower()\n  self.assertRaises(AssertionError, mock.bar.lower.assert_called_with)\n  \n  \n def test_spec_inheritance_for_classes(self):\n  class Foo(object):\n   def a(self):\n    pass\n   class Bar(object):\n    def f(self):\n     pass\n     \n  class_mock = create_autospec(Foo)\n  \n  self.assertIsNot(class_mock, class_mock())\n  \n  for this_mock in class_mock, class_mock():\n   this_mock.a()\n   this_mock.a.assert_called_with()\n   self.assertRaises(TypeError, this_mock.a, 'foo')\n   self.assertRaises(AttributeError, getattr, this_mock, 'b')\n   \n  instance_mock = create_autospec(Foo())\n  instance_mock.a()\n  instance_mock.a.assert_called_with()\n  self.assertRaises(TypeError, instance_mock.a, 'foo')\n  self.assertRaises(AttributeError, getattr, instance_mock, 'b')\n  \n  \n  self.assertRaises(TypeError, instance_mock)\n  \n  instance_mock.Bar.f()\n  instance_mock.Bar.f.assert_called_with()\n  self.assertRaises(AttributeError, getattr, instance_mock.Bar, 'g')\n  \n  instance_mock.Bar().f()\n  instance_mock.Bar().f.assert_called_with()\n  self.assertRaises(AttributeError, getattr, instance_mock.Bar(), 'g')\n  \n  \n def test_inherit(self):\n  class Foo(object):\n   a = 3\n   \n  Foo.Foo = Foo\n  \n  \n  mock = create_autospec(Foo)\n  instance = mock()\n  self.assertRaises(AttributeError, getattr, instance, 'b')\n  \n  attr_instance = mock.Foo()\n  self.assertRaises(AttributeError, getattr, attr_instance, 'b')\n  \n  \n  mock = create_autospec(Foo())\n  self.assertRaises(AttributeError, getattr, mock, 'b')\n  self.assertRaises(TypeError, mock)\n  \n  \n  call_result = mock.Foo()\n  self.assertRaises(AttributeError, getattr, call_result, 'b')\n  \n  \n def test_builtins(self):\n \n  create_autospec(1)\n  \n  create_autospec(int)\n  create_autospec('foo')\n  create_autospec(str)\n  create_autospec({})\n  create_autospec(dict)\n  create_autospec([])\n  create_autospec(list)\n  create_autospec(set())\n  create_autospec(set)\n  create_autospec(1.0)\n  create_autospec(float)\n  create_autospec(1j)\n  create_autospec(complex)\n  create_autospec(False)\n  create_autospec(True)\n  \n  \n def test_function(self):\n  def f(a, b):\n   pass\n   \n  mock = create_autospec(f)\n  self.assertRaises(TypeError, mock)\n  mock(1, 2)\n  mock.assert_called_with(1, 2)\n  \n  f.f = f\n  mock = create_autospec(f)\n  self.assertRaises(TypeError, mock.f)\n  mock.f(3, 4)\n  mock.f.assert_called_with(3, 4)\n  \n  \n def test_skip_attributeerrors(self):\n  class Raiser(object):\n   def __get__(self, obj, type=None):\n    if obj is None:\n     raise AttributeError('Can only be accessed via an instance')\n     \n  class RaiserClass(object):\n   raiser = Raiser()\n   \n   @staticmethod\n   def existing(a, b):\n    return a + b\n    \n  s = create_autospec(RaiserClass)\n  self.assertRaises(TypeError, lambda x: s.existing(1, 2, 3))\n  s.existing(1, 2)\n  self.assertRaises(AttributeError, lambda: s.nonexisting)\n  \n  \n  obj = s.raiser\n  obj.foo, obj.bar\n  \n  \n def test_signature_class(self):\n  class Foo(object):\n   def __init__(self, a, b=3):\n    pass\n    \n  mock = create_autospec(Foo)\n  \n  self.assertRaises(TypeError, mock)\n  mock(1)\n  mock.assert_called_once_with(1)\n  \n  mock(4, 5)\n  mock.assert_called_with(4, 5)\n  \n  \n def test_class_with_no_init(self):\n \n \n  class Foo(object):\n   pass\n  create_autospec(Foo)\n  \n  \n def test_signature_callable(self):\n  class Callable(object):\n   def __init__(self):\n    pass\n   def __call__(self, a):\n    pass\n    \n  mock = create_autospec(Callable)\n  mock()\n  mock.assert_called_once_with()\n  self.assertRaises(TypeError, mock, 'a')\n  \n  instance = mock()\n  self.assertRaises(TypeError, instance)\n  instance(a='a')\n  instance.assert_called_once_with(a='a')\n  instance('a')\n  instance.assert_called_with('a')\n  \n  mock = create_autospec(Callable())\n  mock(a='a')\n  mock.assert_called_once_with(a='a')\n  self.assertRaises(TypeError, mock)\n  mock('a')\n  mock.assert_called_with('a')\n  \n  \n def test_signature_noncallable(self):\n  class NonCallable(object):\n   def __init__(self):\n    pass\n    \n  mock = create_autospec(NonCallable)\n  instance = mock()\n  mock.assert_called_once_with()\n  self.assertRaises(TypeError, mock, 'a')\n  self.assertRaises(TypeError, instance)\n  self.assertRaises(TypeError, instance, 'a')\n  \n  mock = create_autospec(NonCallable())\n  self.assertRaises(TypeError, mock)\n  self.assertRaises(TypeError, mock, 'a')\n  \n  \n def test_create_autospec_none(self):\n  class Foo(object):\n   bar = None\n   \n  mock = create_autospec(Foo)\n  none = mock.bar\n  self.assertNotIsInstance(none, type(None))\n  \n  none.foo()\n  none.foo.assert_called_once_with()\n  \n  \n def test_autospec_functions_with_self_in_odd_place(self):\n  class Foo(object):\n   def f(a, self):\n    pass\n    \n  a = create_autospec(Foo)\n  a.f(self=10)\n  a.f.assert_called_with(self=10)\n  \n  \n def test_autospec_property(self):\n  class Foo(object):\n   @property\n   def foo(self):\n    return 3\n    \n  foo = create_autospec(Foo)\n  mock_property = foo.foo\n  \n  \n  self.assertTrue(isinstance(mock_property, MagicMock))\n  mock_property(1, 2, 3)\n  mock_property.abc(4, 5, 6)\n  mock_property.assert_called_once_with(1, 2, 3)\n  mock_property.abc.assert_called_once_with(4, 5, 6)\n  \n  \n def test_autospec_slots(self):\n  class Foo(object):\n   __slots__ = ['a']\n   \n  foo = create_autospec(Foo)\n  mock_slot = foo.a\n  \n  \n  mock_slot(1, 2, 3)\n  mock_slot.abc(4, 5, 6)\n  mock_slot.assert_called_once_with(1, 2, 3)\n  mock_slot.abc.assert_called_once_with(4, 5, 6)\n  \n  \nclass TestCallList(unittest.TestCase):\n\n def test_args_list_contains_call_list(self):\n  mock = Mock()\n  self.assertIsInstance(mock.call_args_list, _CallList)\n  \n  mock(1, 2)\n  mock(a=3)\n  mock(3, 4)\n  mock(b=6)\n  \n  for kall in call(1, 2), call(a=3), call(3, 4), call(b=6):\n   self.assertTrue(kall in mock.call_args_list)\n   \n  calls = [call(a=3), call(3, 4)]\n  self.assertTrue(calls in mock.call_args_list)\n  calls = [call(1, 2), call(a=3)]\n  self.assertTrue(calls in mock.call_args_list)\n  calls = [call(3, 4), call(b=6)]\n  self.assertTrue(calls in mock.call_args_list)\n  calls = [call(3, 4)]\n  self.assertTrue(calls in mock.call_args_list)\n  \n  self.assertFalse(call('fish') in mock.call_args_list)\n  self.assertFalse([call('fish')] in mock.call_args_list)\n  \n  \n def test_call_list_str(self):\n  mock = Mock()\n  mock(1, 2)\n  mock.foo(a=3)\n  mock.foo.bar().baz('fish', cat='dog')\n  \n  expected = (\n  \"[call(1, 2),\\n\"\n  \" call.foo(a=3),\\n\"\n  \" call.foo.bar(),\\n\"\n  \" call.foo.bar().baz('fish', cat='dog')]\"\n  )\n  self.assertEqual(str(mock.mock_calls), expected)\n  \n  \n def test_propertymock(self):\n  p = patch('%s.SomeClass.one' % __name__, new_callable=PropertyMock)\n  mock = p.start()\n  try:\n   SomeClass.one\n   mock.assert_called_once_with()\n   \n   s = SomeClass()\n   s.one\n   mock.assert_called_with()\n   self.assertEqual(mock.mock_calls, [call(), call()])\n   \n   s.one = 3\n   self.assertEqual(mock.mock_calls, [call(), call(), call(3)])\n  finally:\n   p.stop()\n   \n   \n def test_propertymock_returnvalue(self):\n  m = MagicMock()\n  p = PropertyMock()\n  type(m).foo = p\n  \n  returned = m.foo\n  p.assert_called_once_with()\n  self.assertIsInstance(returned, MagicMock)\n  self.assertNotIsInstance(returned, PropertyMock)\n  \n  \nif __name__ == '__main__':\n unittest.main()\n"], "this": [".py", "s = \"\"\"Gur Mra bs Clguba, ol Gvz Crgref\n\nOrnhgvshy vf orggre guna htyl.\nRkcyvpvg vf orggre guna vzcyvpvg.\nFvzcyr vf orggre guna pbzcyrk.\nPbzcyrk vf orggre guna pbzcyvpngrq.\nSyng vf orggre guna arfgrq.\nFcnefr vf orggre guna qrafr.\nErnqnovyvgl pbhagf.\nFcrpvny pnfrf nera'g fcrpvny rabhtu gb oernx gur ehyrf.\nNygubhtu cenpgvpnyvgl orngf chevgl.\nReebef fubhyq arire cnff fvyragyl.\nHayrff rkcyvpvgyl fvyraprq.\nVa gur snpr bs nzovthvgl, ershfr gur grzcgngvba gb thrff.\nGurer fubhyq or bar-- naq cersrenoyl bayl bar --boivbhf jnl gb qb vg.\nNygubhtu gung jnl znl abg or boivbhf ng svefg hayrff lbh'er Qhgpu.\nAbj vf orggre guna arire.\nNygubhtu arire vf bsgra orggre guna *evtug* abj.\nVs gur vzcyrzragngvba vf uneq gb rkcynva, vg'f n onq vqrn.\nVs gur vzcyrzragngvba vf rnfl gb rkcynva, vg znl or n tbbq vqrn.\nAnzrfcnprf ner bar ubaxvat terng vqrn -- yrg'f qb zber bs gubfr!\"\"\"\n\nd = {}\nfor c in (65, 97):\n for i in range(26):\n  d[chr(i+c)] = chr((i+13) % 26 + c)\n  \nprint(\"\".join([d.get(c, c) for c in s]))\n"], "_csv": [".py", "\"\"\n\n__version__ = \"1.0\"\n\nQUOTE_MINIMAL, QUOTE_ALL, QUOTE_NONNUMERIC, QUOTE_NONE = range(4)\n_dialects = {}\n_field_limit = 128 * 1024 \n\nclass Error(Exception):\n pass\n \nclass Dialect(object):\n \"\"\n \n __slots__ = [\"_delimiter\", \"_doublequote\", \"_escapechar\",\n \"_lineterminator\", \"_quotechar\", \"_quoting\",\n \"_skipinitialspace\", \"_strict\"]\n \n def __new__(cls, dialect, **kwargs):\n \n  for name in kwargs:\n   if '_' + name not in Dialect.__slots__:\n    raise TypeError(\"unexpected keyword argument '%s'\" %\n    (name,))\n    \n  if dialect is not None:\n   if isinstance(dialect, str):\n    dialect = get_dialect(dialect)\n    \n    \n   if (isinstance(dialect, Dialect)\n   and all(value is None for value in kwargs.values())):\n    return dialect\n    \n  self = object.__new__(cls)\n  \n  \n  def set_char(x):\n   if x is None:\n    return None\n   if isinstance(x, str) and len(x) <= 1:\n    return x\n   raise TypeError(\"%r must be a 1-character string\" % (name,))\n  def set_str(x):\n   if isinstance(x, str):\n    return x\n   raise TypeError(\"%r must be a string\" % (name,))\n  def set_quoting(x):\n   if x in range(4):\n    return x\n   raise TypeError(\"bad 'quoting' value\")\n   \n  attributes = {\"delimiter\": (',', set_char),\n  \"doublequote\": (True, bool),\n  \"escapechar\": (None, set_char),\n  \"lineterminator\": (\"\\r\\n\", set_str),\n  \"quotechar\": ('\"', set_char),\n  \"quoting\": (QUOTE_MINIMAL, set_quoting),\n  \"skipinitialspace\": (False, bool),\n  \"strict\": (False, bool),\n  }\n  \n  \n  notset = object()\n  for name in Dialect.__slots__:\n   name = name[1:]\n   value = notset\n   if name in kwargs:\n    value = kwargs[name]\n   elif dialect is not None:\n    value = getattr(dialect, name, notset)\n    \n    \n   if value is notset:\n    value = attributes[name][0]\n    if name == 'quoting' and not self.quotechar:\n     value = QUOTE_NONE\n   else:\n    converter = attributes[name][1]\n    if converter:\n     value = converter(value)\n     \n   setattr(self, '_' + name, value)\n   \n  if not self.delimiter:\n   raise TypeError(\"delimiter must be set\")\n   \n  if self.quoting != QUOTE_NONE and not self.quotechar:\n   raise TypeError(\"quotechar must be set if quoting enabled\")\n   \n  if not self.lineterminator:\n   raise TypeError(\"lineterminator must be set\")\n   \n  return self\n  \n delimiter = property(lambda self: self._delimiter)\n doublequote = property(lambda self: self._doublequote)\n escapechar = property(lambda self: self._escapechar)\n lineterminator = property(lambda self: self._lineterminator)\n quotechar = property(lambda self: self._quotechar)\n quoting = property(lambda self: self._quoting)\n skipinitialspace = property(lambda self: self._skipinitialspace)\n strict = property(lambda self: self._strict)\n \n \ndef _call_dialect(dialect_inst, kwargs):\n return Dialect(dialect_inst, **kwargs)\n \ndef register_dialect(name, dialect=None, **kwargs):\n \"\"\n if not isinstance(name, str):\n  raise TypeError(\"dialect name must be a string or unicode\")\n  \n dialect = _call_dialect(dialect, kwargs)\n _dialects[name] = dialect\n \ndef unregister_dialect(name):\n \"\"\n try:\n  del _dialects[name]\n except KeyError:\n  raise Error(\"unknown dialect\")\n  \ndef get_dialect(name):\n \"\"\n try:\n  return _dialects[name]\n except KeyError:\n  raise Error(\"unknown dialect\")\n  \ndef list_dialects():\n \"\"\n return list(_dialects)\n \nclass Reader(object):\n \"\"\n \n \n (START_RECORD, START_FIELD, ESCAPED_CHAR, IN_FIELD,\n IN_QUOTED_FIELD, ESCAPE_IN_QUOTED_FIELD, QUOTE_IN_QUOTED_FIELD,\n EAT_CRNL) = range(8)\n \n def __init__(self, iterator, dialect=None, **kwargs):\n  self.dialect = _call_dialect(dialect, kwargs)\n  \n  \n  \n  self._delimiter = self.dialect.delimiter if self.dialect.delimiter else '\\0'\n  self._quotechar = self.dialect.quotechar if self.dialect.quotechar else '\\0'\n  self._escapechar = self.dialect.escapechar if self.dialect.escapechar else '\\0'\n  self._doublequote = self.dialect.doublequote\n  self._quoting = self.dialect.quoting\n  self._skipinitialspace = self.dialect.skipinitialspace\n  self._strict = self.dialect.strict\n  \n  self.input_iter = iter(iterator)\n  self.line_num = 0\n  \n  self._parse_reset()\n  \n def _parse_reset(self):\n  self.field = ''\n  self.fields = []\n  self.state = self.START_RECORD\n  self.numeric_field = False\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  self._parse_reset()\n  while True:\n   try:\n    line = next(self.input_iter)\n   except StopIteration:\n   \n    if len(self.field) > 0:\n     raise Error(\"newline inside string\")\n    raise\n    \n   self.line_num += 1\n   \n   if '\\0' in line:\n    raise Error(\"line contains NULL byte\")\n   self._parse_process_char(line)\n   self._parse_eol()\n   \n   if self.state == self.START_RECORD:\n    break\n    \n  fields = self.fields\n  self.fields = []\n  return fields\n  \n def _parse_process_char(self, line):\n  pos = 0\n  while pos < len(line):\n   if self.state == self.IN_FIELD:\n   \n    pos2 = pos\n    while pos2 < len(line):\n     if line[pos2] == '\\n' or line[pos2] == '\\r':\n     \n      if pos2 > pos:\n       self._parse_add_str(line[pos:pos2])\n       pos = pos2\n      self._parse_save_field()\n      self.state = self.EAT_CRNL\n      break\n     elif line[pos2] == self._escapechar[0]:\n     \n      if pos2 > pos:\n       self._parse_add_str(line[pos:pos2])\n      pos = pos2\n      self.state = self.ESCAPED_CHAR\n      break\n     elif line[pos2] == self._delimiter[0]:\n     \n      if pos2 > pos:\n       self._parse_add_str(line[pos:pos2])\n       pos = pos2\n      self._parse_save_field()\n      self.state = self.START_FIELD\n      break\n      \n     pos2 += 1\n    else:\n     if pos2 > pos:\n      self._parse_add_str(line[pos:pos2])\n      pos = pos2\n      continue\n      \n   elif self.state == self.START_RECORD:\n    if line[pos] == '\\n' or line[pos] == '\\r':\n     self.state = self.EAT_CRNL\n    else:\n     self.state = self.START_FIELD\n     \n     continue\n     \n   elif self.state == self.START_FIELD:\n    if line[pos] == '\\n' or line[pos] == '\\r':\n    \n     self._parse_save_field()\n     self.state = self.EAT_CRNL\n    elif (line[pos] == self._quotechar[0]\n    and self._quoting != QUOTE_NONE):\n    \n     self.state = self.IN_QUOTED_FIELD\n    elif line[pos] == self._escapechar[0]:\n    \n     self.state = self.ESCAPED_CHAR\n    elif self._skipinitialspace and line[pos] == ' ':\n    \n     pass\n    elif line[pos] == self._delimiter[0]:\n    \n     self._parse_save_field()\n    else:\n    \n     if self._quoting == QUOTE_NONNUMERIC:\n      self.numeric_field = True\n     self.state = self.IN_FIELD\n     continue\n     \n   elif self.state == self.ESCAPED_CHAR:\n    self._parse_add_char(line[pos])\n    self.state = self.IN_FIELD\n    \n   elif self.state == self.IN_QUOTED_FIELD:\n    if line[pos] == self._escapechar:\n    \n     self.state = self.ESCAPE_IN_QUOTED_FIELD\n    elif (line[pos] == self._quotechar\n    and self._quoting != QUOTE_NONE):\n     if self._doublequote:\n     \n      self.state = self.QUOTE_IN_QUOTED_FIELD\n     else:\n     \n      self.state = self.IN_FIELD\n    else:\n    \n     self._parse_add_char(line[pos])\n     \n   elif self.state == self.ESCAPE_IN_QUOTED_FIELD:\n    self._parse_add_char(line[pos])\n    self.state = self.IN_QUOTED_FIELD\n    \n   elif self.state == self.QUOTE_IN_QUOTED_FIELD:\n   \n    if (line[pos] == self._quotechar\n    and self._quoting != QUOTE_NONE):\n    \n     self._parse_add_char(line[pos])\n     self.state = self.IN_QUOTED_FIELD\n    elif line[pos] == self._delimiter[0]:\n    \n     self._parse_save_field()\n     self.state = self.START_FIELD\n    elif line[pos] == '\\r' or line[pos] == '\\n':\n    \n     self._parse_save_field()\n     self.state = self.EAT_CRNL\n    elif not self._strict:\n     self._parse_add_char(line[pos])\n     self.state = self.IN_FIELD\n    else:\n     raise Error(\"'%c' expected after '%c'\" %\n     (self._delimiter, self._quotechar))\n     \n   elif self.state == self.EAT_CRNL:\n    if line[pos] == '\\r' or line[pos] == '\\n':\n     pass\n    else:\n     raise Error(\"new-line character seen in unquoted field - \"\n     \"do you need to open the file \"\n     \"in universal-newline mode?\")\n     \n   else:\n    raise RuntimeError(\"unknown state: %r\" % (self.state,))\n    \n   pos += 1\n   \n def _parse_eol(self):\n  if self.state == self.EAT_CRNL:\n   self.state = self.START_RECORD\n  elif self.state == self.START_RECORD:\n  \n   pass\n  elif self.state == self.IN_FIELD:\n  \n  \n   self._parse_save_field()\n   self.state = self.START_RECORD\n  elif self.state == self.START_FIELD:\n  \n   self._parse_save_field()\n   self.state = self.START_RECORD\n  elif self.state == self.ESCAPED_CHAR:\n   self._parse_add_char('\\n')\n   self.state = self.IN_FIELD\n  elif self.state == self.IN_QUOTED_FIELD:\n   pass\n  elif self.state == self.ESCAPE_IN_QUOTED_FIELD:\n   self._parse_add_char('\\n')\n   self.state = self.IN_QUOTED_FIELD\n  elif self.state == self.QUOTE_IN_QUOTED_FIELD:\n  \n   self._parse_save_field()\n   self.state = self.START_RECORD\n  else:\n   raise RuntimeError(\"unknown state: %r\" % (self.state,))\n   \n def _parse_save_field(self):\n  field, self.field = self.field, ''\n  if self.numeric_field:\n   self.numeric_field = False\n   field = float(field)\n  self.fields.append(field)\n  \n def _parse_add_char(self, c):\n  if len(self.field) + 1 > _field_limit:\n   raise Error(\"field larget than field limit (%d)\" % (_field_limit))\n  self.field += c\n  \n def _parse_add_str(self, s):\n  if len(self.field) + len(s) > _field_limit:\n   raise Error(\"field larget than field limit (%d)\" % (_field_limit))\n  self.field += s\n  \n  \nclass Writer(object):\n \"\"\n \n def __init__(self, file, dialect=None, **kwargs):\n  if not (hasattr(file, 'write') and callable(file.write)):\n   raise TypeError(\"argument 1 must have a 'write' method\")\n  self.writeline = file.write\n  self.dialect = _call_dialect(dialect, kwargs)\n  \n def _join_reset(self):\n  self.rec = []\n  self.num_fields = 0\n  \n def _join_append(self, field, quoted, quote_empty):\n  dialect = self.dialect\n  \n  if self.num_fields > 0:\n   self.rec.append(dialect.delimiter)\n   \n  if dialect.quoting == QUOTE_NONE:\n   need_escape = tuple(dialect.lineterminator) + (\n   dialect.escapechar, \n   dialect.delimiter, dialect.quotechar)\n   \n  else:\n   for c in tuple(dialect.lineterminator) + (\n   dialect.delimiter, dialect.escapechar):\n    if c and c in field:\n     quoted = True\n     \n   need_escape = ()\n   if dialect.quotechar in field:\n    if dialect.doublequote:\n     field = field.replace(dialect.quotechar,\n     dialect.quotechar * 2)\n     quoted = True\n    else:\n     need_escape = (dialect.quotechar,)\n     \n     \n  for c in need_escape:\n   if c and c in field:\n    if not dialect.escapechar:\n     raise Error(\"need to escape, but no escapechar set\")\n    field = field.replace(c, dialect.escapechar + c)\n    \n    \n  if field == '' and quote_empty:\n   if dialect.quoting == QUOTE_NONE:\n    raise Error(\"single empty field record must be quoted\")\n   quoted = 1\n   \n  if quoted:\n   field = dialect.quotechar + field + dialect.quotechar\n   \n  self.rec.append(field)\n  self.num_fields += 1\n  \n  \n  \n def writerow(self, row):\n  dialect = self.dialect\n  try:\n   rowlen = len(row)\n  except TypeError:\n   raise Error(\"sequence expected\")\n   \n   \n  self._join_reset()\n  \n  for field in row:\n   quoted = False\n   if dialect.quoting == QUOTE_NONNUMERIC:\n    try:\n     float(field)\n    except:\n     quoted = True\n     \n     \n   elif dialect.quoting == QUOTE_ALL:\n    quoted = True\n    \n   if field is None:\n    self._join_append(\"\", quoted, rowlen == 1)\n   else:\n    self._join_append(str(field), quoted, rowlen == 1)\n    \n    \n  self.rec.append(dialect.lineterminator)\n  \n  self.writeline(''.join(self.rec))\n  \n def writerows(self, rows):\n  for row in rows:\n   self.writerow(row)\n   \ndef reader(*args, **kwargs):\n \"\"\n \n return Reader(*args, **kwargs)\n \ndef writer(*args, **kwargs):\n \"\"\n return Writer(*args, **kwargs)\n \n \nundefined = object()\ndef field_size_limit(limit=undefined):\n \"\"\n \n global _field_limit\n old_limit = _field_limit\n \n if limit is not undefined:\n  if not isinstance(limit, (int, long)):\n   raise TypeError(\"int expected, got %s\" %\n   (limit.__class__.__name__,))\n  _field_limit = limit\n  \n return old_limit\n"], "unittest.test.test_functiontestcase": [".py", "import unittest\n\nfrom .support import LoggingResult\n\n\nclass Test_FunctionTestCase(unittest.TestCase):\n\n\n\n def test_countTestCases(self):\n  test = unittest.FunctionTestCase(lambda: None)\n  \n  self.assertEqual(test.countTestCases(), 1)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_run_call_order__error_in_setUp(self):\n  events = []\n  result = LoggingResult(events)\n  \n  def setUp():\n   events.append('setUp')\n   raise RuntimeError('raised by setUp')\n   \n  def test():\n   events.append('test')\n   \n  def tearDown():\n   events.append('tearDown')\n   \n  expected = ['startTest', 'setUp', 'addError', 'stopTest']\n  unittest.FunctionTestCase(test, setUp, tearDown).run(result)\n  self.assertEqual(events, expected)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_run_call_order__error_in_test(self):\n  events = []\n  result = LoggingResult(events)\n  \n  def setUp():\n   events.append('setUp')\n   \n  def test():\n   events.append('test')\n   raise RuntimeError('raised by test')\n   \n  def tearDown():\n   events.append('tearDown')\n   \n  expected = ['startTest', 'setUp', 'test', 'tearDown',\n  'addError', 'stopTest']\n  unittest.FunctionTestCase(test, setUp, tearDown).run(result)\n  self.assertEqual(events, expected)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_run_call_order__failure_in_test(self):\n  events = []\n  result = LoggingResult(events)\n  \n  def setUp():\n   events.append('setUp')\n   \n  def test():\n   events.append('test')\n   self.fail('raised by test')\n   \n  def tearDown():\n   events.append('tearDown')\n   \n  expected = ['startTest', 'setUp', 'test', 'tearDown',\n  'addFailure', 'stopTest']\n  unittest.FunctionTestCase(test, setUp, tearDown).run(result)\n  self.assertEqual(events, expected)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_run_call_order__error_in_tearDown(self):\n  events = []\n  result = LoggingResult(events)\n  \n  def setUp():\n   events.append('setUp')\n   \n  def test():\n   events.append('test')\n   \n  def tearDown():\n   events.append('tearDown')\n   raise RuntimeError('raised by tearDown')\n   \n  expected = ['startTest', 'setUp', 'test', 'tearDown', 'addError',\n  'stopTest']\n  unittest.FunctionTestCase(test, setUp, tearDown).run(result)\n  self.assertEqual(events, expected)\n  \n  \n  \n  \n  \n  \n  \n def test_id(self):\n  test = unittest.FunctionTestCase(lambda: None)\n  \n  self.assertIsInstance(test.id(), str)\n  \n  \n  \n  \n def test_shortDescription__no_docstring(self):\n  test = unittest.FunctionTestCase(lambda: None)\n  \n  self.assertEqual(test.shortDescription(), None)\n  \n  \n  \n  \n def test_shortDescription__singleline_docstring(self):\n  desc = \"this tests foo\"\n  test = unittest.FunctionTestCase(lambda: None, description=desc)\n  \n  self.assertEqual(test.shortDescription(), \"this tests foo\")\n"], "xml.dom.minidom": [".py", "\"\"\n\nimport io\nimport xml.dom\n\nfrom xml.dom import EMPTY_NAMESPACE, EMPTY_PREFIX, XMLNS_NAMESPACE, domreg\nfrom xml.dom.minicompat import *\nfrom xml.dom.xmlbuilder import DOMImplementationLS, DocumentLS\n\n\n\n\n\n\n_nodeTypes_with_children = (xml.dom.Node.ELEMENT_NODE,\nxml.dom.Node.ENTITY_REFERENCE_NODE)\n\n\nclass Node(xml.dom.Node):\n namespaceURI = None \n parentNode = None\n ownerDocument = None\n nextSibling = None\n previousSibling = None\n \n prefix = EMPTY_PREFIX \n \n def __bool__(self):\n  return True\n  \n def toxml(self, encoding=None):\n  return self.toprettyxml(\"\", \"\", encoding)\n  \n def toprettyxml(self, indent=\"\\t\", newl=\"\\n\", encoding=None):\n  if encoding is None:\n   writer = io.StringIO()\n  else:\n   writer = io.TextIOWrapper(io.BytesIO(),\n   encoding=encoding,\n   errors=\"xmlcharrefreplace\",\n   newline='\\n')\n  if self.nodeType == Node.DOCUMENT_NODE:\n  \n   self.writexml(writer, \"\", indent, newl, encoding)\n  else:\n   self.writexml(writer, \"\", indent, newl)\n  if encoding is None:\n   return writer.getvalue()\n  else:\n   return writer.detach().getvalue()\n   \n def hasChildNodes(self):\n  return bool(self.childNodes)\n  \n def _get_childNodes(self):\n  return self.childNodes\n  \n def _get_firstChild(self):\n  if self.childNodes:\n   return self.childNodes[0]\n   \n def _get_lastChild(self):\n  if self.childNodes:\n   return self.childNodes[-1]\n   \n def insertBefore(self, newChild, refChild):\n  if newChild.nodeType == self.DOCUMENT_FRAGMENT_NODE:\n   for c in tuple(newChild.childNodes):\n    self.insertBefore(c, refChild)\n    \n   return newChild\n  if newChild.nodeType not in self._child_node_types:\n   raise xml.dom.HierarchyRequestErr(\n   \"%s cannot be child of %s\" % (repr(newChild), repr(self)))\n  if newChild.parentNode is not None:\n   newChild.parentNode.removeChild(newChild)\n  if refChild is None:\n   self.appendChild(newChild)\n  else:\n   try:\n    index = self.childNodes.index(refChild)\n   except ValueError:\n    raise xml.dom.NotFoundErr()\n   if newChild.nodeType in _nodeTypes_with_children:\n    _clear_id_cache(self)\n   self.childNodes.insert(index, newChild)\n   newChild.nextSibling = refChild\n   refChild.previousSibling = newChild\n   if index:\n    node = self.childNodes[index-1]\n    node.nextSibling = newChild\n    newChild.previousSibling = node\n   else:\n    newChild.previousSibling = None\n   newChild.parentNode = self\n  return newChild\n  \n def appendChild(self, node):\n  if node.nodeType == self.DOCUMENT_FRAGMENT_NODE:\n   for c in tuple(node.childNodes):\n    self.appendChild(c)\n    \n   return node\n  if node.nodeType not in self._child_node_types:\n   raise xml.dom.HierarchyRequestErr(\n   \"%s cannot be child of %s\" % (repr(node), repr(self)))\n  elif node.nodeType in _nodeTypes_with_children:\n   _clear_id_cache(self)\n  if node.parentNode is not None:\n   node.parentNode.removeChild(node)\n  _append_child(self, node)\n  node.nextSibling = None\n  return node\n  \n def replaceChild(self, newChild, oldChild):\n  if newChild.nodeType == self.DOCUMENT_FRAGMENT_NODE:\n   refChild = oldChild.nextSibling\n   self.removeChild(oldChild)\n   return self.insertBefore(newChild, refChild)\n  if newChild.nodeType not in self._child_node_types:\n   raise xml.dom.HierarchyRequestErr(\n   \"%s cannot be child of %s\" % (repr(newChild), repr(self)))\n  if newChild is oldChild:\n   return\n  if newChild.parentNode is not None:\n   newChild.parentNode.removeChild(newChild)\n  try:\n   index = self.childNodes.index(oldChild)\n  except ValueError:\n   raise xml.dom.NotFoundErr()\n  self.childNodes[index] = newChild\n  newChild.parentNode = self\n  oldChild.parentNode = None\n  if (newChild.nodeType in _nodeTypes_with_children\n  or oldChild.nodeType in _nodeTypes_with_children):\n   _clear_id_cache(self)\n  newChild.nextSibling = oldChild.nextSibling\n  newChild.previousSibling = oldChild.previousSibling\n  oldChild.nextSibling = None\n  oldChild.previousSibling = None\n  if newChild.previousSibling:\n   newChild.previousSibling.nextSibling = newChild\n  if newChild.nextSibling:\n   newChild.nextSibling.previousSibling = newChild\n  return oldChild\n  \n def removeChild(self, oldChild):\n  try:\n   self.childNodes.remove(oldChild)\n  except ValueError:\n   raise xml.dom.NotFoundErr()\n  if oldChild.nextSibling is not None:\n   oldChild.nextSibling.previousSibling = oldChild.previousSibling\n  if oldChild.previousSibling is not None:\n   oldChild.previousSibling.nextSibling = oldChild.nextSibling\n  oldChild.nextSibling = oldChild.previousSibling = None\n  if oldChild.nodeType in _nodeTypes_with_children:\n   _clear_id_cache(self)\n   \n  oldChild.parentNode = None\n  return oldChild\n  \n def normalize(self):\n  L = []\n  for child in self.childNodes:\n   if child.nodeType == Node.TEXT_NODE:\n    if not child.data:\n    \n     if L:\n      L[-1].nextSibling = child.nextSibling\n     if child.nextSibling:\n      child.nextSibling.previousSibling = child.previousSibling\n     child.unlink()\n    elif L and L[-1].nodeType == child.nodeType:\n    \n     node = L[-1]\n     node.data = node.data + child.data\n     node.nextSibling = child.nextSibling\n     if child.nextSibling:\n      child.nextSibling.previousSibling = node\n     child.unlink()\n    else:\n     L.append(child)\n   else:\n    L.append(child)\n    if child.nodeType == Node.ELEMENT_NODE:\n     child.normalize()\n  self.childNodes[:] = L\n  \n def cloneNode(self, deep):\n  return _clone_node(self, deep, self.ownerDocument or self)\n  \n def isSupported(self, feature, version):\n  return self.ownerDocument.implementation.hasFeature(feature, version)\n  \n def _get_localName(self):\n \n  return None\n  \n  \n  \n def isSameNode(self, other):\n  return self is other\n  \n def getInterface(self, feature):\n  if self.isSupported(feature, None):\n   return self\n  else:\n   return None\n   \n   \n   \n   \n   \n def getUserData(self, key):\n  try:\n   return self._user_data[key][0]\n  except (AttributeError, KeyError):\n   return None\n   \n def setUserData(self, key, data, handler):\n  old = None\n  try:\n   d = self._user_data\n  except AttributeError:\n   d = {}\n   self._user_data = d\n  if key in d:\n   old = d[key][0]\n  if data is None:\n  \n   handler = None\n   if old is not None:\n    del d[key]\n  else:\n   d[key] = (data, handler)\n  return old\n  \n def _call_user_data_handler(self, operation, src, dst):\n  if hasattr(self, \"_user_data\"):\n   for key, (data, handler) in list(self._user_data.items()):\n    if handler is not None:\n     handler.handle(operation, key, data, src, dst)\n     \n     \n     \n def unlink(self):\n  self.parentNode = self.ownerDocument = None\n  if self.childNodes:\n   for child in self.childNodes:\n    child.unlink()\n   self.childNodes = NodeList()\n  self.previousSibling = None\n  self.nextSibling = None\n  \n  \n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, et, ev, tb):\n  self.unlink()\n  \ndefproperty(Node, \"firstChild\", doc=\"First child node, or None.\")\ndefproperty(Node, \"lastChild\", doc=\"Last child node, or None.\")\ndefproperty(Node, \"localName\", doc=\"Namespace-local name of this node.\")\n\n\ndef _append_child(self, node):\n\n childNodes = self.childNodes\n if childNodes:\n  last = childNodes[-1]\n  node.previousSibling = last\n  last.nextSibling = node\n childNodes.append(node)\n node.parentNode = self\n \ndef _in_document(node):\n\n while node is not None:\n  if node.nodeType == Node.DOCUMENT_NODE:\n   return True\n  node = node.parentNode\n return False\n \ndef _write_data(writer, data):\n \"\"\n if data:\n  data = data.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\"). replace(\"\\\"\", \"&quot;\").replace(\">\", \"&gt;\")\n  writer.write(data)\n  \ndef _get_elements_by_tagName_helper(parent, name, rc):\n for node in parent.childNodes:\n  if node.nodeType == Node.ELEMENT_NODE and (name == \"*\" or node.tagName == name):\n   rc.append(node)\n  _get_elements_by_tagName_helper(node, name, rc)\n return rc\n \ndef _get_elements_by_tagName_ns_helper(parent, nsURI, localName, rc):\n for node in parent.childNodes:\n  if node.nodeType == Node.ELEMENT_NODE:\n   if ((localName == \"*\" or node.localName == localName) and\n   (nsURI == \"*\" or node.namespaceURI == nsURI)):\n    rc.append(node)\n   _get_elements_by_tagName_ns_helper(node, nsURI, localName, rc)\n return rc\n \nclass DocumentFragment(Node):\n nodeType = Node.DOCUMENT_FRAGMENT_NODE\n nodeName = \"#document-fragment\"\n nodeValue = None\n attributes = None\n parentNode = None\n _child_node_types = (Node.ELEMENT_NODE,\n Node.TEXT_NODE,\n Node.CDATA_SECTION_NODE,\n Node.ENTITY_REFERENCE_NODE,\n Node.PROCESSING_INSTRUCTION_NODE,\n Node.COMMENT_NODE,\n Node.NOTATION_NODE)\n \n def __init__(self):\n  self.childNodes = NodeList()\n  \n  \nclass Attr(Node):\n __slots__=('_name', '_value', 'namespaceURI',\n '_prefix', 'childNodes', '_localName', 'ownerDocument', 'ownerElement')\n nodeType = Node.ATTRIBUTE_NODE\n attributes = None\n specified = False\n _is_id = False\n \n _child_node_types = (Node.TEXT_NODE, Node.ENTITY_REFERENCE_NODE)\n \n def __init__(self, qName, namespaceURI=EMPTY_NAMESPACE, localName=None,\n prefix=None):\n  self.ownerElement = None\n  self._name = qName\n  self.namespaceURI = namespaceURI\n  self._prefix = prefix\n  self.childNodes = NodeList()\n  \n  \n  self.childNodes.append(Text())\n  \n  \n  \n def _get_localName(self):\n  try:\n   return self._localName\n  except AttributeError:\n   return self.nodeName.split(\":\", 1)[-1]\n   \n def _get_name(self):\n  return self.name\n  \n def _get_specified(self):\n  return self.specified\n  \n def _get_name(self):\n  return self._name\n  \n def _set_name(self, value):\n  self._name = value\n  if self.ownerElement is not None:\n   _clear_id_cache(self.ownerElement)\n   \n nodeName = name = property(_get_name, _set_name)\n \n def _get_value(self):\n  return self._value\n  \n def _set_value(self, value):\n  self._value = value\n  self.childNodes[0].data = value\n  if self.ownerElement is not None:\n   _clear_id_cache(self.ownerElement)\n  self.childNodes[0].data = value\n  \n nodeValue = value = property(_get_value, _set_value)\n \n def _get_prefix(self):\n  return self._prefix\n  \n def _set_prefix(self, prefix):\n  nsuri = self.namespaceURI\n  if prefix == \"xmlns\":\n   if nsuri and nsuri != XMLNS_NAMESPACE:\n    raise xml.dom.NamespaceErr(\n    \"illegal use of 'xmlns' prefix for the wrong namespace\")\n  self._prefix = prefix\n  if prefix is None:\n   newName = self.localName\n  else:\n   newName = \"%s:%s\" % (prefix, self.localName)\n  if self.ownerElement:\n   _clear_id_cache(self.ownerElement)\n  self.name = newName\n  \n prefix = property(_get_prefix, _set_prefix)\n \n def unlink(self):\n \n \n \n \n  elem = self.ownerElement\n  if elem is not None:\n   del elem._attrs[self.nodeName]\n   del elem._attrsNS[(self.namespaceURI, self.localName)]\n   if self._is_id:\n    self._is_id = False\n    elem._magic_id_nodes -= 1\n    self.ownerDocument._magic_id_count -= 1\n  for child in self.childNodes:\n   child.unlink()\n  del self.childNodes[:]\n  \n def _get_isId(self):\n  if self._is_id:\n   return True\n  doc = self.ownerDocument\n  elem = self.ownerElement\n  if doc is None or elem is None:\n   return False\n   \n  info = doc._get_elem_info(elem)\n  if info is None:\n   return False\n  if self.namespaceURI:\n   return info.isIdNS(self.namespaceURI, self.localName)\n  else:\n   return info.isId(self.nodeName)\n   \n def _get_schemaType(self):\n  doc = self.ownerDocument\n  elem = self.ownerElement\n  if doc is None or elem is None:\n   return _no_type\n   \n  info = doc._get_elem_info(elem)\n  if info is None:\n   return _no_type\n  if self.namespaceURI:\n   return info.getAttributeTypeNS(self.namespaceURI, self.localName)\n  else:\n   return info.getAttributeType(self.nodeName)\n   \ndefproperty(Attr, \"isId\", doc=\"True if this attribute is an ID.\")\ndefproperty(Attr, \"localName\", doc=\"Namespace-local name of this attribute.\")\ndefproperty(Attr, \"schemaType\", doc=\"Schema type for this attribute.\")\n\n\nclass NamedNodeMap(object):\n \"\"\n \n __slots__ = ('_attrs', '_attrsNS', '_ownerElement')\n \n def __init__(self, attrs, attrsNS, ownerElement):\n  self._attrs = attrs\n  self._attrsNS = attrsNS\n  self._ownerElement = ownerElement\n  \n def _get_length(self):\n  return len(self._attrs)\n  \n def item(self, index):\n  try:\n   return self[list(self._attrs.keys())[index]]\n  except IndexError:\n   return None\n   \n def items(self):\n  L = []\n  for node in self._attrs.values():\n   L.append((node.nodeName, node.value))\n  return L\n  \n def itemsNS(self):\n  L = []\n  for node in self._attrs.values():\n   L.append(((node.namespaceURI, node.localName), node.value))\n  return L\n  \n def __contains__(self, key):\n  if isinstance(key, str):\n   return key in self._attrs\n  else:\n   return key in self._attrsNS\n   \n def keys(self):\n  return self._attrs.keys()\n  \n def keysNS(self):\n  return self._attrsNS.keys()\n  \n def values(self):\n  return self._attrs.values()\n  \n def get(self, name, value=None):\n  return self._attrs.get(name, value)\n  \n __len__ = _get_length\n \n def _cmp(self, other):\n  if self._attrs is getattr(other, \"_attrs\", None):\n   return 0\n  else:\n   return (id(self) > id(other)) - (id(self) < id(other))\n   \n def __eq__(self, other):\n  return self._cmp(other) == 0\n  \n def __ge__(self, other):\n  return self._cmp(other) >= 0\n  \n def __gt__(self, other):\n  return self._cmp(other) > 0\n  \n def __le__(self, other):\n  return self._cmp(other) <= 0\n  \n def __lt__(self, other):\n  return self._cmp(other) < 0\n  \n def __ne__(self, other):\n  return self._cmp(other) != 0\n  \n def __getitem__(self, attname_or_tuple):\n  if isinstance(attname_or_tuple, tuple):\n   return self._attrsNS[attname_or_tuple]\n  else:\n   return self._attrs[attname_or_tuple]\n   \n   \n def __setitem__(self, attname, value):\n  if isinstance(value, str):\n   try:\n    node = self._attrs[attname]\n   except KeyError:\n    node = Attr(attname)\n    node.ownerDocument = self._ownerElement.ownerDocument\n    self.setNamedItem(node)\n   node.value = value\n  else:\n   if not isinstance(value, Attr):\n    raise TypeError(\"value must be a string or Attr object\")\n   node = value\n   self.setNamedItem(node)\n   \n def getNamedItem(self, name):\n  try:\n   return self._attrs[name]\n  except KeyError:\n   return None\n   \n def getNamedItemNS(self, namespaceURI, localName):\n  try:\n   return self._attrsNS[(namespaceURI, localName)]\n  except KeyError:\n   return None\n   \n def removeNamedItem(self, name):\n  n = self.getNamedItem(name)\n  if n is not None:\n   _clear_id_cache(self._ownerElement)\n   del self._attrs[n.nodeName]\n   del self._attrsNS[(n.namespaceURI, n.localName)]\n   if hasattr(n, 'ownerElement'):\n    n.ownerElement = None\n   return n\n  else:\n   raise xml.dom.NotFoundErr()\n   \n def removeNamedItemNS(self, namespaceURI, localName):\n  n = self.getNamedItemNS(namespaceURI, localName)\n  if n is not None:\n   _clear_id_cache(self._ownerElement)\n   del self._attrsNS[(n.namespaceURI, n.localName)]\n   del self._attrs[n.nodeName]\n   if hasattr(n, 'ownerElement'):\n    n.ownerElement = None\n   return n\n  else:\n   raise xml.dom.NotFoundErr()\n   \n def setNamedItem(self, node):\n  if not isinstance(node, Attr):\n   raise xml.dom.HierarchyRequestErr(\n   \"%s cannot be child of %s\" % (repr(node), repr(self)))\n  old = self._attrs.get(node.name)\n  if old:\n   old.unlink()\n  self._attrs[node.name] = node\n  self._attrsNS[(node.namespaceURI, node.localName)] = node\n  node.ownerElement = self._ownerElement\n  _clear_id_cache(node.ownerElement)\n  return old\n  \n def setNamedItemNS(self, node):\n  return self.setNamedItem(node)\n  \n def __delitem__(self, attname_or_tuple):\n  node = self[attname_or_tuple]\n  _clear_id_cache(node.ownerElement)\n  node.unlink()\n  \n def __getstate__(self):\n  return self._attrs, self._attrsNS, self._ownerElement\n  \n def __setstate__(self, state):\n  self._attrs, self._attrsNS, self._ownerElement = state\n  \ndefproperty(NamedNodeMap, \"length\",\ndoc=\"Number of nodes in the NamedNodeMap.\")\n\nAttributeList = NamedNodeMap\n\n\nclass TypeInfo(object):\n __slots__ = 'namespace', 'name'\n \n def __init__(self, namespace, name):\n  self.namespace = namespace\n  self.name = name\n  \n def __repr__(self):\n  if self.namespace:\n   return \"<TypeInfo %r (from %r)>\" % (self.name, self.namespace)\n  else:\n   return \"<TypeInfo %r>\" % self.name\n   \n def _get_name(self):\n  return self.name\n  \n def _get_namespace(self):\n  return self.namespace\n  \n_no_type = TypeInfo(None, None)\n\nclass Element(Node):\n __slots__=('ownerDocument', 'parentNode', 'tagName', 'nodeName', 'prefix',\n 'namespaceURI', '_localName', 'childNodes', '_attrs', '_attrsNS',\n 'nextSibling', 'previousSibling')\n nodeType = Node.ELEMENT_NODE\n nodeValue = None\n schemaType = _no_type\n \n _magic_id_nodes = 0\n \n _child_node_types = (Node.ELEMENT_NODE,\n Node.PROCESSING_INSTRUCTION_NODE,\n Node.COMMENT_NODE,\n Node.TEXT_NODE,\n Node.CDATA_SECTION_NODE,\n Node.ENTITY_REFERENCE_NODE)\n \n def __init__(self, tagName, namespaceURI=EMPTY_NAMESPACE, prefix=None,\n localName=None):\n  self.parentNode = None\n  self.tagName = self.nodeName = tagName\n  self.prefix = prefix\n  self.namespaceURI = namespaceURI\n  self.childNodes = NodeList()\n  self.nextSibling = self.previousSibling = None\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  self._attrs = None\n  self._attrsNS = None\n  \n def _ensure_attributes(self):\n  if self._attrs is None:\n   self._attrs = {}\n   self._attrsNS = {}\n   \n def _get_localName(self):\n  try:\n   return self._localName\n  except AttributeError:\n   return self.tagName.split(\":\", 1)[-1]\n   \n def _get_tagName(self):\n  return self.tagName\n  \n def unlink(self):\n  if self._attrs is not None:\n   for attr in list(self._attrs.values()):\n    attr.unlink()\n  self._attrs = None\n  self._attrsNS = None\n  Node.unlink(self)\n  \n def getAttribute(self, attname):\n  if self._attrs is None:\n   return \"\"\n  try:\n   return self._attrs[attname].value\n  except KeyError:\n   return \"\"\n   \n def getAttributeNS(self, namespaceURI, localName):\n  if self._attrsNS is None:\n   return \"\"\n  try:\n   return self._attrsNS[(namespaceURI, localName)].value\n  except KeyError:\n   return \"\"\n   \n def setAttribute(self, attname, value):\n  attr = self.getAttributeNode(attname)\n  if attr is None:\n   attr = Attr(attname)\n   attr.value = value \n   attr.ownerDocument = self.ownerDocument\n   self.setAttributeNode(attr)\n  elif value != attr.value:\n   attr.value = value\n   if attr.isId:\n    _clear_id_cache(self)\n    \n def setAttributeNS(self, namespaceURI, qualifiedName, value):\n  prefix, localname = _nssplit(qualifiedName)\n  attr = self.getAttributeNodeNS(namespaceURI, localname)\n  if attr is None:\n   attr = Attr(qualifiedName, namespaceURI, localname, prefix)\n   attr.value = value\n   attr.ownerDocument = self.ownerDocument\n   self.setAttributeNode(attr)\n  else:\n   if value != attr.value:\n    attr.value = value\n    if attr.isId:\n     _clear_id_cache(self)\n   if attr.prefix != prefix:\n    attr.prefix = prefix\n    attr.nodeName = qualifiedName\n    \n def getAttributeNode(self, attrname):\n  if self._attrs is None:\n   return None\n  return self._attrs.get(attrname)\n  \n def getAttributeNodeNS(self, namespaceURI, localName):\n  if self._attrsNS is None:\n   return None\n  return self._attrsNS.get((namespaceURI, localName))\n  \n def setAttributeNode(self, attr):\n  if attr.ownerElement not in (None, self):\n   raise xml.dom.InuseAttributeErr(\"attribute node already owned\")\n  self._ensure_attributes()\n  old1 = self._attrs.get(attr.name, None)\n  if old1 is not None:\n   self.removeAttributeNode(old1)\n  old2 = self._attrsNS.get((attr.namespaceURI, attr.localName), None)\n  if old2 is not None and old2 is not old1:\n   self.removeAttributeNode(old2)\n  _set_attribute_node(self, attr)\n  \n  if old1 is not attr:\n  \n  \n   return old1\n  if old2 is not attr:\n   return old2\n   \n setAttributeNodeNS = setAttributeNode\n \n def removeAttribute(self, name):\n  if self._attrsNS is None:\n   raise xml.dom.NotFoundErr()\n  try:\n   attr = self._attrs[name]\n  except KeyError:\n   raise xml.dom.NotFoundErr()\n  self.removeAttributeNode(attr)\n  \n def removeAttributeNS(self, namespaceURI, localName):\n  if self._attrsNS is None:\n   raise xml.dom.NotFoundErr()\n  try:\n   attr = self._attrsNS[(namespaceURI, localName)]\n  except KeyError:\n   raise xml.dom.NotFoundErr()\n  self.removeAttributeNode(attr)\n  \n def removeAttributeNode(self, node):\n  if node is None:\n   raise xml.dom.NotFoundErr()\n  try:\n   self._attrs[node.name]\n  except KeyError:\n   raise xml.dom.NotFoundErr()\n  _clear_id_cache(self)\n  node.unlink()\n  \n  \n  node.ownerDocument = self.ownerDocument\n  \n removeAttributeNodeNS = removeAttributeNode\n \n def hasAttribute(self, name):\n  if self._attrs is None:\n   return False\n  return name in self._attrs\n  \n def hasAttributeNS(self, namespaceURI, localName):\n  if self._attrsNS is None:\n   return False\n  return (namespaceURI, localName) in self._attrsNS\n  \n def getElementsByTagName(self, name):\n  return _get_elements_by_tagName_helper(self, name, NodeList())\n  \n def getElementsByTagNameNS(self, namespaceURI, localName):\n  return _get_elements_by_tagName_ns_helper(\n  self, namespaceURI, localName, NodeList())\n  \n def __repr__(self):\n  return \"<DOM Element: %s at %#x>\" % (self.tagName, id(self))\n  \n def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n \n \n \n  writer.write(indent+\"<\" + self.tagName)\n  \n  attrs = self._get_attributes()\n  a_names = sorted(attrs.keys())\n  \n  for a_name in a_names:\n   writer.write(\" %s=\\\"\" % a_name)\n   _write_data(writer, attrs[a_name].value)\n   writer.write(\"\\\"\")\n  if self.childNodes:\n   writer.write(\">\")\n   if (len(self.childNodes) == 1 and\n   self.childNodes[0].nodeType == Node.TEXT_NODE):\n    self.childNodes[0].writexml(writer, '', '', '')\n   else:\n    writer.write(newl)\n    for node in self.childNodes:\n     node.writexml(writer, indent+addindent, addindent, newl)\n    writer.write(indent)\n   writer.write(\"</%s>%s\" % (self.tagName, newl))\n  else:\n   writer.write(\"/>%s\"%(newl))\n   \n def _get_attributes(self):\n  self._ensure_attributes()\n  return NamedNodeMap(self._attrs, self._attrsNS, self)\n  \n def hasAttributes(self):\n  if self._attrs:\n   return True\n  else:\n   return False\n   \n   \n   \n def setIdAttribute(self, name):\n  idAttr = self.getAttributeNode(name)\n  self.setIdAttributeNode(idAttr)\n  \n def setIdAttributeNS(self, namespaceURI, localName):\n  idAttr = self.getAttributeNodeNS(namespaceURI, localName)\n  self.setIdAttributeNode(idAttr)\n  \n def setIdAttributeNode(self, idAttr):\n  if idAttr is None or not self.isSameNode(idAttr.ownerElement):\n   raise xml.dom.NotFoundErr()\n  if _get_containing_entref(self) is not None:\n   raise xml.dom.NoModificationAllowedErr()\n  if not idAttr._is_id:\n   idAttr._is_id = True\n   self._magic_id_nodes += 1\n   self.ownerDocument._magic_id_count += 1\n   _clear_id_cache(self)\n   \ndefproperty(Element, \"attributes\",\ndoc=\"NamedNodeMap of attributes on the element.\")\ndefproperty(Element, \"localName\",\ndoc=\"Namespace-local name of this element.\")\n\n\ndef _set_attribute_node(element, attr):\n _clear_id_cache(element)\n element._ensure_attributes()\n element._attrs[attr.name] = attr\n element._attrsNS[(attr.namespaceURI, attr.localName)] = attr\n \n \n \n \n attr.ownerElement = element\n \nclass Childless:\n \"\"\n __slots__ = ()\n \n attributes = None\n childNodes = EmptyNodeList()\n firstChild = None\n lastChild = None\n \n def _get_firstChild(self):\n  return None\n  \n def _get_lastChild(self):\n  return None\n  \n def appendChild(self, node):\n  raise xml.dom.HierarchyRequestErr(\n  self.nodeName + \" nodes cannot have children\")\n  \n def hasChildNodes(self):\n  return False\n  \n def insertBefore(self, newChild, refChild):\n  raise xml.dom.HierarchyRequestErr(\n  self.nodeName + \" nodes do not have children\")\n  \n def removeChild(self, oldChild):\n  raise xml.dom.NotFoundErr(\n  self.nodeName + \" nodes do not have children\")\n  \n def normalize(self):\n \n  pass\n  \n def replaceChild(self, newChild, oldChild):\n  raise xml.dom.HierarchyRequestErr(\n  self.nodeName + \" nodes do not have children\")\n  \n  \nclass ProcessingInstruction(Childless, Node):\n nodeType = Node.PROCESSING_INSTRUCTION_NODE\n __slots__ = ('target', 'data')\n \n def __init__(self, target, data):\n  self.target = target\n  self.data = data\n  \n  \n def _get_nodeValue(self):\n  return self.data\n def _set_nodeValue(self, value):\n  self.data = data\n nodeValue = property(_get_nodeValue, _set_nodeValue)\n \n \n def _get_nodeName(self):\n  return self.target\n def _set_nodeName(self, value):\n  self.target = value\n nodeName = property(_get_nodeName, _set_nodeName)\n \n def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n  writer.write(\"%s<?%s %s?>%s\" % (indent,self.target, self.data, newl))\n  \n  \nclass CharacterData(Childless, Node):\n __slots__=('_data', 'ownerDocument','parentNode', 'previousSibling', 'nextSibling')\n \n def __init__(self):\n  self.ownerDocument = self.parentNode = None\n  self.previousSibling = self.nextSibling = None\n  self._data = ''\n  Node.__init__(self)\n  \n def _get_length(self):\n  return len(self.data)\n __len__ = _get_length\n \n def _get_data(self):\n  return self._data\n def _set_data(self, data):\n  self._data = data\n  \n data = nodeValue = property(_get_data, _set_data)\n \n def __repr__(self):\n  data = self.data\n  if len(data) > 10:\n   dotdotdot = \"...\"\n  else:\n   dotdotdot = \"\"\n  return '<DOM %s node \"%r%s\">' % (\n  self.__class__.__name__, data[0:10], dotdotdot)\n  \n def substringData(self, offset, count):\n  if offset < 0:\n   raise xml.dom.IndexSizeErr(\"offset cannot be negative\")\n  if offset >= len(self.data):\n   raise xml.dom.IndexSizeErr(\"offset cannot be beyond end of data\")\n  if count < 0:\n   raise xml.dom.IndexSizeErr(\"count cannot be negative\")\n  return self.data[offset:offset+count]\n  \n def appendData(self, arg):\n  self.data = self.data + arg\n  \n def insertData(self, offset, arg):\n  if offset < 0:\n   raise xml.dom.IndexSizeErr(\"offset cannot be negative\")\n  if offset >= len(self.data):\n   raise xml.dom.IndexSizeErr(\"offset cannot be beyond end of data\")\n  if arg:\n   self.data = \"%s%s%s\" % (\n   self.data[:offset], arg, self.data[offset:])\n   \n def deleteData(self, offset, count):\n  if offset < 0:\n   raise xml.dom.IndexSizeErr(\"offset cannot be negative\")\n  if offset >= len(self.data):\n   raise xml.dom.IndexSizeErr(\"offset cannot be beyond end of data\")\n  if count < 0:\n   raise xml.dom.IndexSizeErr(\"count cannot be negative\")\n  if count:\n   self.data = self.data[:offset] + self.data[offset+count:]\n   \n def replaceData(self, offset, count, arg):\n  if offset < 0:\n   raise xml.dom.IndexSizeErr(\"offset cannot be negative\")\n  if offset >= len(self.data):\n   raise xml.dom.IndexSizeErr(\"offset cannot be beyond end of data\")\n  if count < 0:\n   raise xml.dom.IndexSizeErr(\"count cannot be negative\")\n  if count:\n   self.data = \"%s%s%s\" % (\n   self.data[:offset], arg, self.data[offset+count:])\n   \ndefproperty(CharacterData, \"length\", doc=\"Length of the string data.\")\n\n\nclass Text(CharacterData):\n __slots__ = ()\n \n nodeType = Node.TEXT_NODE\n nodeName = \"#text\"\n attributes = None\n \n def splitText(self, offset):\n  if offset < 0 or offset > len(self.data):\n   raise xml.dom.IndexSizeErr(\"illegal offset value\")\n  newText = self.__class__()\n  newText.data = self.data[offset:]\n  newText.ownerDocument = self.ownerDocument\n  next = self.nextSibling\n  if self.parentNode and self in self.parentNode.childNodes:\n   if next is None:\n    self.parentNode.appendChild(newText)\n   else:\n    self.parentNode.insertBefore(newText, next)\n  self.data = self.data[:offset]\n  return newText\n  \n def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n  _write_data(writer, \"%s%s%s\" % (indent, self.data, newl))\n  \n  \n  \n def _get_wholeText(self):\n  L = [self.data]\n  n = self.previousSibling\n  while n is not None:\n   if n.nodeType in (Node.TEXT_NODE, Node.CDATA_SECTION_NODE):\n    L.insert(0, n.data)\n    n = n.previousSibling\n   else:\n    break\n  n = self.nextSibling\n  while n is not None:\n   if n.nodeType in (Node.TEXT_NODE, Node.CDATA_SECTION_NODE):\n    L.append(n.data)\n    n = n.nextSibling\n   else:\n    break\n  return ''.join(L)\n  \n def replaceWholeText(self, content):\n \n \n  parent = self.parentNode\n  n = self.previousSibling\n  while n is not None:\n   if n.nodeType in (Node.TEXT_NODE, Node.CDATA_SECTION_NODE):\n    next = n.previousSibling\n    parent.removeChild(n)\n    n = next\n   else:\n    break\n  n = self.nextSibling\n  if not content:\n   parent.removeChild(self)\n  while n is not None:\n   if n.nodeType in (Node.TEXT_NODE, Node.CDATA_SECTION_NODE):\n    next = n.nextSibling\n    parent.removeChild(n)\n    n = next\n   else:\n    break\n  if content:\n   self.data = content\n   return self\n  else:\n   return None\n   \n def _get_isWhitespaceInElementContent(self):\n  if self.data.strip():\n   return False\n  elem = _get_containing_element(self)\n  if elem is None:\n   return False\n  info = self.ownerDocument._get_elem_info(elem)\n  if info is None:\n   return False\n  else:\n   return info.isElementContent()\n   \ndefproperty(Text, \"isWhitespaceInElementContent\",\ndoc=\"True iff this text node contains only whitespace\"\n\" and is in element content.\")\ndefproperty(Text, \"wholeText\",\ndoc=\"The text of all logically-adjacent text nodes.\")\n\n\ndef _get_containing_element(node):\n c = node.parentNode\n while c is not None:\n  if c.nodeType == Node.ELEMENT_NODE:\n   return c\n  c = c.parentNode\n return None\n \ndef _get_containing_entref(node):\n c = node.parentNode\n while c is not None:\n  if c.nodeType == Node.ENTITY_REFERENCE_NODE:\n   return c\n  c = c.parentNode\n return None\n \n \nclass Comment(CharacterData):\n nodeType = Node.COMMENT_NODE\n nodeName = \"#comment\"\n \n def __init__(self, data):\n  CharacterData.__init__(self)\n  self._data = data\n  \n def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n  if \"--\" in self.data:\n   raise ValueError(\"'--' is not allowed in a comment node\")\n  writer.write(\"%s<!--%s-->%s\" % (indent, self.data, newl))\n  \n  \nclass CDATASection(Text):\n __slots__ = ()\n \n nodeType = Node.CDATA_SECTION_NODE\n nodeName = \"#cdata-section\"\n \n def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n  if self.data.find(\"]]>\") >= 0:\n   raise ValueError(\"']]>' not allowed in a CDATA section\")\n  writer.write(\"<![CDATA[%s]]>\" % self.data)\n  \n  \nclass ReadOnlySequentialNamedNodeMap(object):\n __slots__ = '_seq',\n \n def __init__(self, seq=()):\n \n  self._seq = seq\n  \n def __len__(self):\n  return len(self._seq)\n  \n def _get_length(self):\n  return len(self._seq)\n  \n def getNamedItem(self, name):\n  for n in self._seq:\n   if n.nodeName == name:\n    return n\n    \n def getNamedItemNS(self, namespaceURI, localName):\n  for n in self._seq:\n   if n.namespaceURI == namespaceURI and n.localName == localName:\n    return n\n    \n def __getitem__(self, name_or_tuple):\n  if isinstance(name_or_tuple, tuple):\n   node = self.getNamedItemNS(*name_or_tuple)\n  else:\n   node = self.getNamedItem(name_or_tuple)\n  if node is None:\n   raise KeyError(name_or_tuple)\n  return node\n  \n def item(self, index):\n  if index < 0:\n   return None\n  try:\n   return self._seq[index]\n  except IndexError:\n   return None\n   \n def removeNamedItem(self, name):\n  raise xml.dom.NoModificationAllowedErr(\n  \"NamedNodeMap instance is read-only\")\n  \n def removeNamedItemNS(self, namespaceURI, localName):\n  raise xml.dom.NoModificationAllowedErr(\n  \"NamedNodeMap instance is read-only\")\n  \n def setNamedItem(self, node):\n  raise xml.dom.NoModificationAllowedErr(\n  \"NamedNodeMap instance is read-only\")\n  \n def setNamedItemNS(self, node):\n  raise xml.dom.NoModificationAllowedErr(\n  \"NamedNodeMap instance is read-only\")\n  \n def __getstate__(self):\n  return [self._seq]\n  \n def __setstate__(self, state):\n  self._seq = state[0]\n  \ndefproperty(ReadOnlySequentialNamedNodeMap, \"length\",\ndoc=\"Number of entries in the NamedNodeMap.\")\n\n\nclass Identified:\n \"\"\n \n __slots__ = 'publicId', 'systemId'\n \n def _identified_mixin_init(self, publicId, systemId):\n  self.publicId = publicId\n  self.systemId = systemId\n  \n def _get_publicId(self):\n  return self.publicId\n  \n def _get_systemId(self):\n  return self.systemId\n  \nclass DocumentType(Identified, Childless, Node):\n nodeType = Node.DOCUMENT_TYPE_NODE\n nodeValue = None\n name = None\n publicId = None\n systemId = None\n internalSubset = None\n \n def __init__(self, qualifiedName):\n  self.entities = ReadOnlySequentialNamedNodeMap()\n  self.notations = ReadOnlySequentialNamedNodeMap()\n  if qualifiedName:\n   prefix, localname = _nssplit(qualifiedName)\n   self.name = localname\n  self.nodeName = self.name\n  \n def _get_internalSubset(self):\n  return self.internalSubset\n  \n def cloneNode(self, deep):\n  if self.ownerDocument is None:\n  \n   clone = DocumentType(None)\n   clone.name = self.name\n   clone.nodeName = self.name\n   operation = xml.dom.UserDataHandler.NODE_CLONED\n   if deep:\n    clone.entities._seq = []\n    clone.notations._seq = []\n    for n in self.notations._seq:\n     notation = Notation(n.nodeName, n.publicId, n.systemId)\n     clone.notations._seq.append(notation)\n     n._call_user_data_handler(operation, n, notation)\n    for e in self.entities._seq:\n     entity = Entity(e.nodeName, e.publicId, e.systemId,\n     e.notationName)\n     entity.actualEncoding = e.actualEncoding\n     entity.encoding = e.encoding\n     entity.version = e.version\n     clone.entities._seq.append(entity)\n     e._call_user_data_handler(operation, n, entity)\n   self._call_user_data_handler(operation, self, clone)\n   return clone\n  else:\n   return None\n   \n def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n  writer.write(\"<!DOCTYPE \")\n  writer.write(self.name)\n  if self.publicId:\n   writer.write(\"%s  PUBLIC '%s'%s  '%s'\"\n   % (newl, self.publicId, newl, self.systemId))\n  elif self.systemId:\n   writer.write(\"%s  SYSTEM '%s'\" % (newl, self.systemId))\n  if self.internalSubset is not None:\n   writer.write(\" [\")\n   writer.write(self.internalSubset)\n   writer.write(\"]\")\n  writer.write(\">\"+newl)\n  \nclass Entity(Identified, Node):\n attributes = None\n nodeType = Node.ENTITY_NODE\n nodeValue = None\n \n actualEncoding = None\n encoding = None\n version = None\n \n def __init__(self, name, publicId, systemId, notation):\n  self.nodeName = name\n  self.notationName = notation\n  self.childNodes = NodeList()\n  self._identified_mixin_init(publicId, systemId)\n  \n def _get_actualEncoding(self):\n  return self.actualEncoding\n  \n def _get_encoding(self):\n  return self.encoding\n  \n def _get_version(self):\n  return self.version\n  \n def appendChild(self, newChild):\n  raise xml.dom.HierarchyRequestErr(\n  \"cannot append children to an entity node\")\n  \n def insertBefore(self, newChild, refChild):\n  raise xml.dom.HierarchyRequestErr(\n  \"cannot insert children below an entity node\")\n  \n def removeChild(self, oldChild):\n  raise xml.dom.HierarchyRequestErr(\n  \"cannot remove children from an entity node\")\n  \n def replaceChild(self, newChild, oldChild):\n  raise xml.dom.HierarchyRequestErr(\n  \"cannot replace children of an entity node\")\n  \nclass Notation(Identified, Childless, Node):\n nodeType = Node.NOTATION_NODE\n nodeValue = None\n \n def __init__(self, name, publicId, systemId):\n  self.nodeName = name\n  self._identified_mixin_init(publicId, systemId)\n  \n  \nclass DOMImplementation(DOMImplementationLS):\n _features = [(\"core\", \"1.0\"),\n (\"core\", \"2.0\"),\n (\"core\", None),\n (\"xml\", \"1.0\"),\n (\"xml\", \"2.0\"),\n (\"xml\", None),\n (\"ls-load\", \"3.0\"),\n (\"ls-load\", None),\n ]\n \n def hasFeature(self, feature, version):\n  if version == \"\":\n   version = None\n  return (feature.lower(), version) in self._features\n  \n def createDocument(self, namespaceURI, qualifiedName, doctype):\n  if doctype and doctype.parentNode is not None:\n   raise xml.dom.WrongDocumentErr(\n   \"doctype object owned by another DOM tree\")\n  doc = self._create_document()\n  \n  add_root_element = not (namespaceURI is None\n  and qualifiedName is None\n  and doctype is None)\n  \n  if not qualifiedName and add_root_element:\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n   raise xml.dom.InvalidCharacterErr(\"Element with no name\")\n   \n  if add_root_element:\n   prefix, localname = _nssplit(qualifiedName)\n   if prefix == \"xml\" and namespaceURI != \"http://www.w3.org/XML/1998/namespace\":\n    raise xml.dom.NamespaceErr(\"illegal use of 'xml' prefix\")\n   if prefix and not namespaceURI:\n    raise xml.dom.NamespaceErr(\n    \"illegal use of prefix without namespaces\")\n   element = doc.createElementNS(namespaceURI, qualifiedName)\n   if doctype:\n    doc.appendChild(doctype)\n   doc.appendChild(element)\n   \n  if doctype:\n   doctype.parentNode = doctype.ownerDocument = doc\n   \n  doc.doctype = doctype\n  doc.implementation = self\n  return doc\n  \n def createDocumentType(self, qualifiedName, publicId, systemId):\n  doctype = DocumentType(qualifiedName)\n  doctype.publicId = publicId\n  doctype.systemId = systemId\n  return doctype\n  \n  \n  \n def getInterface(self, feature):\n  if self.hasFeature(feature, None):\n   return self\n  else:\n   return None\n   \n   \n def _create_document(self):\n  return Document()\n  \nclass ElementInfo(object):\n \"\"\n \n __slots__ = 'tagName',\n \n def __init__(self, name):\n  self.tagName = name\n  \n def getAttributeType(self, aname):\n  return _no_type\n  \n def getAttributeTypeNS(self, namespaceURI, localName):\n  return _no_type\n  \n def isElementContent(self):\n  return False\n  \n def isEmpty(self):\n  \"\"\n  return False\n  \n def isId(self, aname):\n  \"\"\n  return False\n  \n def isIdNS(self, namespaceURI, localName):\n  \"\"\n  return False\n  \n def __getstate__(self):\n  return self.tagName\n  \n def __setstate__(self, state):\n  self.tagName = state\n  \ndef _clear_id_cache(node):\n if node.nodeType == Node.DOCUMENT_NODE:\n  node._id_cache.clear()\n  node._id_search_stack = None\n elif _in_document(node):\n  node.ownerDocument._id_cache.clear()\n  node.ownerDocument._id_search_stack= None\n  \nclass Document(Node, DocumentLS):\n __slots__ = ('_elem_info', 'doctype',\n '_id_search_stack', 'childNodes', '_id_cache')\n _child_node_types = (Node.ELEMENT_NODE, Node.PROCESSING_INSTRUCTION_NODE,\n Node.COMMENT_NODE, Node.DOCUMENT_TYPE_NODE)\n \n implementation = DOMImplementation()\n nodeType = Node.DOCUMENT_NODE\n nodeName = \"#document\"\n nodeValue = None\n attributes = None\n parentNode = None\n previousSibling = nextSibling = None\n \n \n \n \n actualEncoding = None\n encoding = None\n standalone = None\n version = None\n strictErrorChecking = False\n errorHandler = None\n documentURI = None\n \n _magic_id_count = 0\n \n def __init__(self):\n  self.doctype = None\n  self.childNodes = NodeList()\n  \n  \n  self._elem_info = {}\n  self._id_cache = {}\n  self._id_search_stack = None\n  \n def _get_elem_info(self, element):\n  if element.namespaceURI:\n   key = element.namespaceURI, element.localName\n  else:\n   key = element.tagName\n  return self._elem_info.get(key)\n  \n def _get_actualEncoding(self):\n  return self.actualEncoding\n  \n def _get_doctype(self):\n  return self.doctype\n  \n def _get_documentURI(self):\n  return self.documentURI\n  \n def _get_encoding(self):\n  return self.encoding\n  \n def _get_errorHandler(self):\n  return self.errorHandler\n  \n def _get_standalone(self):\n  return self.standalone\n  \n def _get_strictErrorChecking(self):\n  return self.strictErrorChecking\n  \n def _get_version(self):\n  return self.version\n  \n def appendChild(self, node):\n  if node.nodeType not in self._child_node_types:\n   raise xml.dom.HierarchyRequestErr(\n   \"%s cannot be child of %s\" % (repr(node), repr(self)))\n  if node.parentNode is not None:\n  \n  \n  \n   node.parentNode.removeChild(node)\n   \n  if node.nodeType == Node.ELEMENT_NODE and self._get_documentElement():\n   raise xml.dom.HierarchyRequestErr(\n   \"two document elements disallowed\")\n  return Node.appendChild(self, node)\n  \n def removeChild(self, oldChild):\n  try:\n   self.childNodes.remove(oldChild)\n  except ValueError:\n   raise xml.dom.NotFoundErr()\n  oldChild.nextSibling = oldChild.previousSibling = None\n  oldChild.parentNode = None\n  if self.documentElement is oldChild:\n   self.documentElement = None\n   \n  return oldChild\n  \n def _get_documentElement(self):\n  for node in self.childNodes:\n   if node.nodeType == Node.ELEMENT_NODE:\n    return node\n    \n def unlink(self):\n  if self.doctype is not None:\n   self.doctype.unlink()\n   self.doctype = None\n  Node.unlink(self)\n  \n def cloneNode(self, deep):\n  if not deep:\n   return None\n  clone = self.implementation.createDocument(None, None, None)\n  clone.encoding = self.encoding\n  clone.standalone = self.standalone\n  clone.version = self.version\n  for n in self.childNodes:\n   childclone = _clone_node(n, deep, clone)\n   assert childclone.ownerDocument.isSameNode(clone)\n   clone.childNodes.append(childclone)\n   if childclone.nodeType == Node.DOCUMENT_NODE:\n    assert clone.documentElement is None\n   elif childclone.nodeType == Node.DOCUMENT_TYPE_NODE:\n    assert clone.doctype is None\n    clone.doctype = childclone\n   childclone.parentNode = clone\n  self._call_user_data_handler(xml.dom.UserDataHandler.NODE_CLONED,\n  self, clone)\n  return clone\n  \n def createDocumentFragment(self):\n  d = DocumentFragment()\n  d.ownerDocument = self\n  return d\n  \n def createElement(self, tagName):\n  e = Element(tagName)\n  e.ownerDocument = self\n  return e\n  \n def createTextNode(self, data):\n  if not isinstance(data, str):\n   raise TypeError(\"node contents must be a string\")\n  t = Text()\n  t.data = data\n  t.ownerDocument = self\n  return t\n  \n def createCDATASection(self, data):\n  if not isinstance(data, str):\n   raise TypeError(\"node contents must be a string\")\n  c = CDATASection()\n  c.data = data\n  c.ownerDocument = self\n  return c\n  \n def createComment(self, data):\n  c = Comment(data)\n  c.ownerDocument = self\n  return c\n  \n def createProcessingInstruction(self, target, data):\n  p = ProcessingInstruction(target, data)\n  p.ownerDocument = self\n  return p\n  \n def createAttribute(self, qName):\n  a = Attr(qName)\n  a.ownerDocument = self\n  a.value = \"\"\n  return a\n  \n def createElementNS(self, namespaceURI, qualifiedName):\n  prefix, localName = _nssplit(qualifiedName)\n  e = Element(qualifiedName, namespaceURI, prefix)\n  e.ownerDocument = self\n  return e\n  \n def createAttributeNS(self, namespaceURI, qualifiedName):\n  prefix, localName = _nssplit(qualifiedName)\n  a = Attr(qualifiedName, namespaceURI, localName, prefix)\n  a.ownerDocument = self\n  a.value = \"\"\n  return a\n  \n  \n  \n  \n def _create_entity(self, name, publicId, systemId, notationName):\n  e = Entity(name, publicId, systemId, notationName)\n  e.ownerDocument = self\n  return e\n  \n def _create_notation(self, name, publicId, systemId):\n  n = Notation(name, publicId, systemId)\n  n.ownerDocument = self\n  return n\n  \n def getElementById(self, id):\n  if id in self._id_cache:\n   return self._id_cache[id]\n  if not (self._elem_info or self._magic_id_count):\n   return None\n   \n  stack = self._id_search_stack\n  if stack is None:\n  \n   stack = [self.documentElement]\n   self._id_search_stack = stack\n  elif not stack:\n  \n  \n   return None\n   \n  result = None\n  while stack:\n   node = stack.pop()\n   \n   stack.extend([child for child in node.childNodes\n   if child.nodeType in _nodeTypes_with_children])\n   \n   info = self._get_elem_info(node)\n   if info:\n   \n   \n   \n    for attr in node.attributes.values():\n     if attr.namespaceURI:\n      if info.isIdNS(attr.namespaceURI, attr.localName):\n       self._id_cache[attr.value] = node\n       if attr.value == id:\n        result = node\n       elif not node._magic_id_nodes:\n        break\n     elif info.isId(attr.name):\n      self._id_cache[attr.value] = node\n      if attr.value == id:\n       result = node\n      elif not node._magic_id_nodes:\n       break\n     elif attr._is_id:\n      self._id_cache[attr.value] = node\n      if attr.value == id:\n       result = node\n      elif node._magic_id_nodes == 1:\n       break\n   elif node._magic_id_nodes:\n    for attr in node.attributes.values():\n     if attr._is_id:\n      self._id_cache[attr.value] = node\n      if attr.value == id:\n       result = node\n   if result is not None:\n    break\n  return result\n  \n def getElementsByTagName(self, name):\n  return _get_elements_by_tagName_helper(self, name, NodeList())\n  \n def getElementsByTagNameNS(self, namespaceURI, localName):\n  return _get_elements_by_tagName_ns_helper(\n  self, namespaceURI, localName, NodeList())\n  \n def isSupported(self, feature, version):\n  return self.implementation.hasFeature(feature, version)\n  \n def importNode(self, node, deep):\n  if node.nodeType == Node.DOCUMENT_NODE:\n   raise xml.dom.NotSupportedErr(\"cannot import document nodes\")\n  elif node.nodeType == Node.DOCUMENT_TYPE_NODE:\n   raise xml.dom.NotSupportedErr(\"cannot import document type nodes\")\n  return _clone_node(node, deep, self)\n  \n def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\", encoding=None):\n  if encoding is None:\n   writer.write('<?xml version=\"1.0\" ?>'+newl)\n  else:\n   writer.write('<?xml version=\"1.0\" encoding=\"%s\"?>%s' % (\n   encoding, newl))\n  for node in self.childNodes:\n   node.writexml(writer, indent, addindent, newl)\n   \n   \n   \n def renameNode(self, n, namespaceURI, name):\n  if n.ownerDocument is not self:\n   raise xml.dom.WrongDocumentErr(\n   \"cannot rename nodes from other documents;\\n\"\n   \"expected %s,\\nfound %s\" % (self, n.ownerDocument))\n  if n.nodeType not in (Node.ELEMENT_NODE, Node.ATTRIBUTE_NODE):\n   raise xml.dom.NotSupportedErr(\n   \"renameNode() only applies to element and attribute nodes\")\n  if namespaceURI != EMPTY_NAMESPACE:\n   if ':' in name:\n    prefix, localName = name.split(':', 1)\n    if ( prefix == \"xmlns\"\n    and namespaceURI != xml.dom.XMLNS_NAMESPACE):\n     raise xml.dom.NamespaceErr(\n     \"illegal use of 'xmlns' prefix\")\n   else:\n    if ( name == \"xmlns\"\n    and namespaceURI != xml.dom.XMLNS_NAMESPACE\n    and n.nodeType == Node.ATTRIBUTE_NODE):\n     raise xml.dom.NamespaceErr(\n     \"illegal use of the 'xmlns' attribute\")\n    prefix = None\n    localName = name\n  else:\n   prefix = None\n   localName = None\n  if n.nodeType == Node.ATTRIBUTE_NODE:\n   element = n.ownerElement\n   if element is not None:\n    is_id = n._is_id\n    element.removeAttributeNode(n)\n  else:\n   element = None\n  n.prefix = prefix\n  n._localName = localName\n  n.namespaceURI = namespaceURI\n  n.nodeName = name\n  if n.nodeType == Node.ELEMENT_NODE:\n   n.tagName = name\n  else:\n  \n   n.name = name\n   if element is not None:\n    element.setAttributeNode(n)\n    if is_id:\n     element.setIdAttributeNode(n)\n     \n     \n     \n     \n     \n  return n\n  \ndefproperty(Document, \"documentElement\",\ndoc=\"Top-level element of this document.\")\n\n\ndef _clone_node(node, deep, newOwnerDocument):\n \"\"\n if node.ownerDocument.isSameNode(newOwnerDocument):\n  operation = xml.dom.UserDataHandler.NODE_CLONED\n else:\n  operation = xml.dom.UserDataHandler.NODE_IMPORTED\n if node.nodeType == Node.ELEMENT_NODE:\n  clone = newOwnerDocument.createElementNS(node.namespaceURI,\n  node.nodeName)\n  for attr in node.attributes.values():\n   clone.setAttributeNS(attr.namespaceURI, attr.nodeName, attr.value)\n   a = clone.getAttributeNodeNS(attr.namespaceURI, attr.localName)\n   a.specified = attr.specified\n   \n  if deep:\n   for child in node.childNodes:\n    c = _clone_node(child, deep, newOwnerDocument)\n    clone.appendChild(c)\n    \n elif node.nodeType == Node.DOCUMENT_FRAGMENT_NODE:\n  clone = newOwnerDocument.createDocumentFragment()\n  if deep:\n   for child in node.childNodes:\n    c = _clone_node(child, deep, newOwnerDocument)\n    clone.appendChild(c)\n    \n elif node.nodeType == Node.TEXT_NODE:\n  clone = newOwnerDocument.createTextNode(node.data)\n elif node.nodeType == Node.CDATA_SECTION_NODE:\n  clone = newOwnerDocument.createCDATASection(node.data)\n elif node.nodeType == Node.PROCESSING_INSTRUCTION_NODE:\n  clone = newOwnerDocument.createProcessingInstruction(node.target,\n  node.data)\n elif node.nodeType == Node.COMMENT_NODE:\n  clone = newOwnerDocument.createComment(node.data)\n elif node.nodeType == Node.ATTRIBUTE_NODE:\n  clone = newOwnerDocument.createAttributeNS(node.namespaceURI,\n  node.nodeName)\n  clone.specified = True\n  clone.value = node.value\n elif node.nodeType == Node.DOCUMENT_TYPE_NODE:\n  assert node.ownerDocument is not newOwnerDocument\n  operation = xml.dom.UserDataHandler.NODE_IMPORTED\n  clone = newOwnerDocument.implementation.createDocumentType(\n  node.name, node.publicId, node.systemId)\n  clone.ownerDocument = newOwnerDocument\n  if deep:\n   clone.entities._seq = []\n   clone.notations._seq = []\n   for n in node.notations._seq:\n    notation = Notation(n.nodeName, n.publicId, n.systemId)\n    notation.ownerDocument = newOwnerDocument\n    clone.notations._seq.append(notation)\n    if hasattr(n, '_call_user_data_handler'):\n     n._call_user_data_handler(operation, n, notation)\n   for e in node.entities._seq:\n    entity = Entity(e.nodeName, e.publicId, e.systemId,\n    e.notationName)\n    entity.actualEncoding = e.actualEncoding\n    entity.encoding = e.encoding\n    entity.version = e.version\n    entity.ownerDocument = newOwnerDocument\n    clone.entities._seq.append(entity)\n    if hasattr(e, '_call_user_data_handler'):\n     e._call_user_data_handler(operation, n, entity)\n else:\n \n \n \n  raise xml.dom.NotSupportedErr(\"Cannot clone node %s\" % repr(node))\n  \n  \n  \n  \n if hasattr(node, '_call_user_data_handler'):\n  node._call_user_data_handler(operation, node, clone)\n return clone\n \n \ndef _nssplit(qualifiedName):\n fields = qualifiedName.split(':', 1)\n if len(fields) == 2:\n  return fields\n else:\n  return (None, fields[0])\n  \n  \ndef _do_pulldom_parse(func, args, kwargs):\n events = func(*args, **kwargs)\n toktype, rootNode = events.getEvent()\n events.expandNode(rootNode)\n events.clear()\n return rootNode\n \ndef parse(file, parser=None, bufsize=None):\n \"\"\n if parser is None and not bufsize:\n  from xml.dom import expatbuilder\n  return expatbuilder.parse(file)\n else:\n  from xml.dom import pulldom\n  return _do_pulldom_parse(pulldom.parse, (file,),\n  {'parser': parser, 'bufsize': bufsize})\n  \ndef parseString(string, parser=None):\n \"\"\n if parser is None:\n  from xml.dom import expatbuilder\n  return expatbuilder.parseString(string)\n else:\n  from xml.dom import pulldom\n  return _do_pulldom_parse(pulldom.parseString, (string,),\n  {'parser': parser})\n  \ndef getDOMImplementation(features=None):\n if features:\n  if isinstance(features, str):\n   features = domreg._parse_feature_string(features)\n  for f, v in features:\n   if not Document.implementation.hasFeature(f, v):\n    return None\n return Document.implementation\n"], "modulefinder": [".js", "var $module=(function($B){\n\nvar _b_=$B.builtins\nvar _mod = {}\n\n$ModuleFinderDict = {__class__:$B.$type,__name__:'ModuleFinder'}\n$ModuleFinderDict.__mro__ = [$ModuleFinderDict,_b_.object.$dict]\n\n$ModuleFinderDict.run_script = function(self, pathname){\n    // pathname is the url of a Python script\n    var py_src = _b_.$open(pathname).read()\n    // transform into internal Brython tree structure\n    var root = $B.py2js(py_src)\n    // walk the tree to find occurences of imports\n    function walk(node){\n        var modules = []\n        var ctx = node.context\n        if(ctx && ctx.type=='node'){ctx = ctx.tree[0]}\n\n        if(ctx && ctx.type==\"import\"){\n            for(var i=0;i<ctx.tree.length;i++){\n                if(modules.indexOf(ctx.tree[i].name)==-1){\n                    modules.push(ctx.tree[i].name)\n                }\n            }\n        }else if(ctx && ctx.type==\"from\"){\n            if(modules.indexOf(ctx.module)==-1){\n                modules.push(ctx.module)\n            }\n        }\n        \n        for(var i=0;i<node.children.length;i++){\n            mods = walk(node.children[i])\n            for(var j=0;j<mods.length;j++){\n                if(modules.indexOf(mods[j])==-1){modules.push(mods[j])}\n            }\n        }\n        return modules\n    }\n    self.modules = walk(root)\n}\n\n_mod.ModuleFinder = function(){return {__class__:$ModuleFinderDict}\n}\n_mod.ModuleFinder.$dict = $ModuleFinderDict\n_mod.ModuleFinder.__class__ = $B.$factory\n$ModuleFinderDict.$factory = _mod.ModuleFinder\n\nreturn _mod\n})(__BRYTHON__)\n"], "unittest.test.support": [".py", "import unittest\n\n\nclass TestEquality(object):\n \"\"\n \n \n def test_eq(self):\n  for obj_1, obj_2 in self.eq_pairs:\n   self.assertEqual(obj_1, obj_2)\n   self.assertEqual(obj_2, obj_1)\n   \n   \n def test_ne(self):\n  for obj_1, obj_2 in self.ne_pairs:\n   self.assertNotEqual(obj_1, obj_2)\n   self.assertNotEqual(obj_2, obj_1)\n   \nclass TestHashing(object):\n \"\"\n \n \n def test_hash(self):\n  for obj_1, obj_2 in self.eq_pairs:\n   try:\n    if not hash(obj_1) == hash(obj_2):\n     self.fail(\"%r and %r do not hash equal\" % (obj_1, obj_2))\n   except KeyboardInterrupt:\n    raise\n   except Exception as e:\n    self.fail(\"Problem hashing %r and %r: %s\" % (obj_1, obj_2, e))\n    \n  for obj_1, obj_2 in self.ne_pairs:\n   try:\n    if hash(obj_1) == hash(obj_2):\n     self.fail(\"%s and %s hash equal, but shouldn't\" %\n     (obj_1, obj_2))\n   except KeyboardInterrupt:\n    raise\n   except Exception as e:\n    self.fail(\"Problem hashing %s and %s: %s\" % (obj_1, obj_2, e))\n    \n    \nclass LoggingResult(unittest.TestResult):\n def __init__(self, log):\n  self._events = log\n  super().__init__()\n  \n def startTest(self, test):\n  self._events.append('startTest')\n  super().startTest(test)\n  \n def startTestRun(self):\n  self._events.append('startTestRun')\n  super(LoggingResult, self).startTestRun()\n  \n def stopTest(self, test):\n  self._events.append('stopTest')\n  super().stopTest(test)\n  \n def stopTestRun(self):\n  self._events.append('stopTestRun')\n  super(LoggingResult, self).stopTestRun()\n  \n def addFailure(self, *args):\n  self._events.append('addFailure')\n  super().addFailure(*args)\n  \n def addSuccess(self, *args):\n  self._events.append('addSuccess')\n  super(LoggingResult, self).addSuccess(*args)\n  \n def addError(self, *args):\n  self._events.append('addError')\n  super().addError(*args)\n  \n def addSkip(self, *args):\n  self._events.append('addSkip')\n  super(LoggingResult, self).addSkip(*args)\n  \n def addExpectedFailure(self, *args):\n  self._events.append('addExpectedFailure')\n  super(LoggingResult, self).addExpectedFailure(*args)\n  \n def addUnexpectedSuccess(self, *args):\n  self._events.append('addUnexpectedSuccess')\n  super(LoggingResult, self).addUnexpectedSuccess(*args)\n  \n  \nclass ResultWithNoStartTestRunStopTestRun(object):\n \"\"\n \n def __init__(self):\n  self.failures = []\n  self.errors = []\n  self.testsRun = 0\n  self.skipped = []\n  self.expectedFailures = []\n  self.unexpectedSuccesses = []\n  self.shouldStop = False\n  \n def startTest(self, test):\n  pass\n  \n def stopTest(self, test):\n  pass\n  \n def addError(self, test):\n  pass\n  \n def addFailure(self, test):\n  pass\n  \n def addSuccess(self, test):\n  pass\n  \n def wasSuccessful(self):\n  return True\n"], "_jsre": [".js", "var $module=(function($B){\n\n    var _b_ = $B.builtins\n    var $s=[]\n    for(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\n    eval($s.join(';'))\n\n    var JSObject = $B.JSObject\n\n    var obj = {__class__:$module,\n        __str__: function(){return \"<module 're'>\"}\n    }\n    obj.A = obj.ASCII = 256\n    obj.I = obj.IGNORECASE = 2 // 'i'\n    obj.L = obj.LOCALE = 4\n    obj.M = obj.MULTILINE = 8 // 'm'\n    obj.S = obj.DOTALL = 16\n    obj.U = obj.UNICODE = 32\n    obj.X = obj.VERBOSE = 64\n    obj._is_valid = function(pattern) {\n        if ($B.$options.re=='pyre') return false  //force use of python's re module\n        if ($B.$options.re=='jsre') return true   //force use of brythons re module\n        // FIXME: Improve\n\n        if (!isinstance(pattern, str)) {\n           // this is probably a SRE_PATTERN, so return false, and let\n           // python's re module handle this.\n           return false\n        }\n        var is_valid = false;\n        try {\n            new RegExp(pattern);\n            is_valid = true;\n        }\n        catch(e) {}\n        if (!is_valid) return false  //if js won't parse the pattern return false\n\n        // using reference http://www.regular-expressions.info/\n        // to compare python re and javascript regex libraries\n\n        // look for things javascript does not support\n        // check for name capturing group\n        var mylist=['?P=', '?P<', '(?#', '(?<=', '(?<!', '(?(']\n        for(var i=0; i < mylist.length; i++) {\n           if (pattern.indexOf(mylist[i]) > -1) return false\n        }\n\n        var re_list=['\\{,\\d+\\}']\n        for(var i=0; i < re_list.length; i++) {\n           var _re=new RegExp(re_list[i])\n           if (_re.test(pattern)) return false\n        }\n\n        // it looks like the pattern has passed all our tests so lets assume\n        // javascript can handle this pattern.\n        return true\n    }\n    var $SRE_PatternDict = {\n        __class__:$B.$type,\n        __name__:'SRE_Pattern'\n    }\n    $SRE_PatternDict.__mro__ = [$SRE_PatternDict,object.$dict]\n    $SRE_PatternDict.findall = function(self,string){\n        return obj.findall(self.pattern,string,self.flags)\n    }\n    $SRE_PatternDict.finditer = function(self,string){\n        return obj.finditer(self.pattern,string,self.flags)\n    }\n    $SRE_PatternDict.match = function(self,string){\n        return obj.match(self.pattern,string,self.flags)\n    }\n    $SRE_PatternDict.search = function(self,string){\n        return obj.search(self.pattern,string,self.flags)\n    }\n    function normflags(flags) {\n        return ((flags & obj.I)? 'i' : '') + ((flags & obj.M)? 'm' : '');\n    }\n    obj.compile = function(pattern,flags){\n        return {\n            __class__:$SRE_PatternDict,\n            pattern:pattern,\n            flags:normflags(flags)\n        }\n    }\n    obj.escape = function(string){\n        // Escape all the characters in pattern except ASCII letters, numbers \n        // and '_'. This is useful if you want to match an arbitrary literal \n        // string that may have regular expression metacharacters in it.\n        var res = ''\n        var ok = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_'\n        for(var i=0;i<string.length;i++){\n            if(ok.search(string.charAt(i))>-1){res += string.charAt(i)}\n        }\n        return res\n    }\n    obj.findall = function(pattern,string,flags){\n        var $ns=$B.$MakeArgs('re.findall',arguments,['pattern','string'],[],'args','kw') ,\n            args = $ns['args'] ,\n            _flags = 0;\n        if(args.length>0){var flags=args[0]}\n        else{var _flags = getattr($ns['kw'], 'get')('flags',0)}\n        \n        var flags = normflags();\n        flags += 'gm'\n        var jsp = new RegExp(pattern,flags) ,\n            jsmatch = string.match(jsp);\n        if(jsmatch===null){return []}\n        return jsmatch\n    }\n    obj.finditer = function(pattern,string,flags){\n        var $ns=$B.$MakeArgs('re.finditer',arguments,['pattern','string'],[],'args','kw'),\n            args = $ns['args'],\n            _flags = 0;\n        if(args.length>0){var flags=args[0]}\n        else{var _flags = getattr($ns['kw'], 'get')('flags',0)}\n        \n        var flags = normflags();\n        flags += 'gm'\n        var jsp = new RegExp(pattern,flags),\n            jsmatch = string.match(jsp);\n        if(jsmatch===null){return []}\n        \n        var _list=[]\n        for (var j=0; j < jsmatch.length; j++) {\n            var mo = {}\n            mo._match=jsmatch[j]\n            mo.group = function(){\n               var res = []\n               for(var i=0;i<arguments.length;i++){\n                   if(jsmatch[arguments[i]]===undefined){res.push(None)}\n                   else{res.push(jsmatch[arguments[i]])}\n               }\n               if(arguments.length===1){return res[0]}\n               return tuple(res)\n            }\n            mo.groups = function(_default){\n               if(_default===undefined){_default=None}\n               var res = []\n               for(var i=1;i<jsmatch.length;i++){\n                  if(jsmatch[i]===undefined){res.push(_default)}\n                  else{res.push(jsmatch[i])}\n               }\n               return tuple(res)\n            }\n            mo.start = function(){return mo._match.index}\n            mo.end = function(){return mo._match.length-mo._match.index}\n            mo.string = string\n            _list.push(JSObject(mo))\n        }\n        return _list\n    }\n    obj.search = function(pattern,string){\n        var $ns=$B.$MakeArgs('re.search',arguments,['pattern','string'],[],'args','kw')\n        var args = $ns['args']\n        if(args.length>0){var flags=args[0]}\n        else{var flags = getattr($ns['kw'],'get')('flags','')}\n        flags = normflags(flags);\n        var jsp = new RegExp(pattern,flags)\n        var jsmatch = string.match(jsp)\n        if(jsmatch===null){return None}\n        var mo = new Object()\n        mo.group = function(){\n            var res = []\n            for(var i=0;i<arguments.length;i++){\n                if(jsmatch[arguments[i]]===undefined){res.push(None)}\n                else{res.push(jsmatch[arguments[i]])}\n            }\n            if(arguments.length===1){return res[0]}\n            return tuple(res)\n        }\n        mo.groups = function(_default){\n            if(_default===undefined){_default=None}\n            var res = []\n            for(var i=1;i<jsmatch.length;i++){\n                if(jsmatch[i]===undefined){res.push(_default)}\n                else{res.push(jsmatch[i])}\n            }\n            return tuple(res)\n        }\n        mo.start = function(){return jsmatch.index}\n        mo.end = function(){return jsmatch.length-jsmatch.index}\n        mo.string = string\n        return JSObject(mo)\n    }\n    obj.sub = function(pattern,repl,string){\n        var $ns=$B.$MakeArgs('re.search',arguments,['pattern','repl','string'],[],'args','kw')\n        for($var in $ns){eval(\"var \"+$var+\"=$ns[$var]\")}\n        var args = $ns['args']\n        var count = _b_.dict.$dict.get($ns['kw'],'count',0)\n        var flags = _b_.dict.$dict.get($ns['kw'],'flags','')\n        if(args.length>0){var count=args[0]}\n        if(args.length>1){var flags=args[1]}\n        flags = normflags(flags);\n        if(typeof repl===\"string\"){\n            // backreferences are \\1, \\2... in Python but $1,$2... in Javascript\n            repl = repl.replace(/\\\\(\\d+)/g,'$$$1')\n        }else if(typeof repl===\"function\"){\n            // the argument passed to the Python function is the match object\n            // the arguments passed to the Javascript function are :\n            // - the matched substring\n            // - the matched groups\n            // - the offset of the matched substring inside the string\n            // - the string being examined\n            var $repl1 = function(){\n                var mo = Object()\n                mo.string = arguments[arguments.length-1]\n                var start = arguments[arguments.length-2]\n                var end = start + arguments[0].length\n                mo.start = function(){return start}\n                mo.end = function(){return end}\n                groups = []\n                for(var i=1;i<arguments.length-2;i++){groups.push(arguments[i])}\n                mo.groups = function(_default){\n                    if(_default===undefined){_default=None}\n                    var res = []\n                    for(var i=0;i<groups.length;i++){\n                        if(groups[i]===undefined){res.push(_default)}\n                        else{res.push(groups[i])}\n                    }\n                    return res\n                }\n                return repl(JSObject(mo))\n            }\n        }\n        if(count==0){flags+='g'}\n        var jsp = new RegExp(pattern,flags)\n        if(typeof repl==='function'){return string.replace(jsp,$repl1)}\n        else{return string.replace(jsp,repl)}\n    }\n    obj.match = (function(search_func){\n        return function(){\n            // match is like search but pattern must start with ^\n            var pattern = arguments[0]\n            if(pattern.charAt(0)!=='^'){pattern = '^'+pattern}\n            var args = [pattern]\n            for(var i=1;i<arguments.length;i++){args.push(arguments[i])}\n            return search_func.apply(null,args)\n        }\n    })(obj.search)\n\n    return obj\n}\n)(__BRYTHON__)\n"], "posix": [".py", "\"\"\n\nimport datetime\n\nF_OK = 0\n\nO_APPEND = 8\n\nO_BINARY = 32768\n\nO_CREAT = 256\n\nO_EXCL = 1024\n\nO_NOINHERIT = 128\n\nO_RANDOM = 16\n\nO_RDONLY = 0\n\nO_RDWR = 2\n\nO_SEQUENTIAL = 32\n\nO_SHORT_LIVED = 4096\n\nO_TEMPORARY = 64\n\nO_TEXT = 16384\n\nO_TRUNC = 512\n\nO_WRONLY = 1\n\nP_DETACH = 4\n\nP_NOWAIT = 1\n\nP_NOWAITO = 3\n\nP_OVERLAY = 2\n\nP_WAIT = 0\n\nR_OK = 4\n\nTMP_MAX = 32767\n\nW_OK = 2\n\nX_OK = 1\n\nclass __loader__:\n pass\n \ndef _exit(*args,**kw):\n \"\"\n pass\n \ndef _getdiskusage(*args,**kw):\n \"\"\n pass\n \ndef _getfileinformation(*args,**kw):\n pass\n \ndef _getfinalpathname(*args,**kw):\n pass\n \ndef _getfullpathname(*args,**kw):\n pass\n \n_have_functions = ['MS_WINDOWS']\n\ndef _isdir(*args,**kw):\n \"\"\n pass\n \ndef abort(*args,**kw):\n \"\"\n pass\n \ndef access(*args,**kw):\n \"\"\n pass\n \ndef chdir(*args,**kw):\n \"\"\n pass\n \ndef chmod(*args,**kw):\n \"\"\n pass\n \ndef close(*args,**kw):\n \"\"\n pass\n \ndef closerange(*args,**kw):\n \"\"\n pass\n \ndef device_encoding(*args,**kw):\n \"\"\n pass\n \ndef dup(*args,**kw):\n \"\"\n pass\n \ndef dup2(*args,**kw):\n \"\"\n pass\n \nenviron = {'PYTHONUSERBASE': ' '}\n\nerror = OSError\n\ndef execv(*args,**kw):\n \"\"\n pass\n \ndef execve(*args,**kw):\n \"\"\n pass\n \ndef fstat(*args,**kw):\n \"\"\n pass\n \ndef fsync(*args,**kw):\n \"\"\n pass\n \ndef get_terminal_size(*args,**kw):\n \"\"\n pass\n \ndef getcwd(*args,**kw):\n \"\"\n return __BRYTHON__.brython_path \n \ndef getcwdb(*args,**kw):\n \"\"\n pass\n \ndef getlogin(*args,**kw):\n \"\"\n pass\n \ndef getpid(*args,**kw):\n \"\"\n return 0\n \ndef getppid(*args,**kw):\n \"\"\n pass\n \ndef isatty(*args,**kw):\n \"\"\n pass\n \ndef kill(*args,**kw):\n \"\"\n pass\n \ndef link(*args,**kw):\n \"\"\n pass\n \ndef listdir(*args,**kw):\n \"\"\n pass\n \ndef lseek(*args,**kw):\n \"\"\n pass\n \ndef lstat(*args,**kw):\n \"\"\n return stat_result()\n \ndef mkdir(*args,**kw):\n \"\"\n pass\n \ndef open(*args,**kw):\n \"\"\n pass\n \ndef pipe(*args,**kw):\n \"\"\n pass\n \ndef putenv(*args,**kw):\n \"\"\n pass\n \ndef read(*args,**kw):\n \"\"\n pass\n \ndef readlink(*args,**kw):\n \"\"\n pass\n \ndef remove(*args,**kw):\n \"\"\n pass\n \ndef rename(*args,**kw):\n \"\"\n pass\n \ndef replace(*args,**kw):\n \"\"\n pass\n \ndef rmdir(*args,**kw):\n \"\"\n pass\n \ndef spawnv(*args,**kw):\n \"\"\n pass\n \ndef spawnve(*args,**kw):\n \"\"\n pass\n \ndef startfile(*args,**kw):\n \"\"\n pass\n \ndef stat(*args,**kw):\n \"\"\n return stat_result()\n \ndef stat_float_times(*args,**kw):\n \"\"\n pass\n \nclass stat_result:\n\n def __init__(self):\n  \"\"\n  \n  self.st_atime = datetime.datetime.now()\n  self.st_mtime = self.st_ctime = self.st_atime_ns = self.st_mtime_ns = self.st_ctime_ns = self.st_atime\n  self.st_uid = self.st_gid = self.st_ino = -1\n  self.st_mode = 0\n  self.st_size = 1\n  \nclass statvfs_result:\n pass\n \ndef strerror(*args,**kw):\n \"\"\n pass\n \ndef symlink(*args,**kw):\n \"\"\n pass\n \ndef system(*args,**kw):\n \"\"\n pass\n \nclass terminal_size:\n pass\n \ndef times(*args,**kw):\n \"\"\n pass\n \nclass times_result:\n pass\n \ndef umask(*args,**kw):\n \"\"\n pass\n \nclass uname_result:\n pass\n \ndef unlink(*args,**kw):\n \"\"\n pass\n \ndef urandom(n):\n \"\"\n import __random\n randbytes= [__random.randint(0,255) for i in range(n)]\n return bytes(randbytes)\n \ndef utime(*args,**kw):\n \"\"\n pass\n \ndef waitpid(*args,**kw):\n \"\"\n pass\n \ndef write(*args,**kw):\n \"\"\n pass\n \n \n \ndef WIFSIGNALED(a):\n return False\n \ndef WTERMSIG(status):\n return 0\n \ndef WIFSIGNALED(status):\n \"\"\n return False\n \ndef WIFEXITED(status):\n return False\n \ndef WEXITSTATUS(status):\n pass\n \ndef WNOHANG():\n return (0,0)\n"], "encodings.aliases": [".py", "\"\"\naliases = {\n\n\n\n\n'646' : 'ascii',\n'ansi_x3.4_1968' : 'ascii',\n'ansi_x3_4_1968' : 'ascii', \n'ansi_x3.4_1986' : 'ascii',\n'cp367' : 'ascii',\n'csascii' : 'ascii',\n'ibm367' : 'ascii',\n'iso646_us' : 'ascii',\n'iso_646.irv_1991' : 'ascii',\n'iso_ir_6' : 'ascii',\n'us' : 'ascii',\n'us_ascii' : 'ascii',\n\n\n'base64' : 'base64_codec',\n'base_64' : 'base64_codec',\n\n\n'big5_tw' : 'big5',\n'csbig5' : 'big5',\n\n\n'big5_hkscs' : 'big5hkscs',\n'hkscs' : 'big5hkscs',\n\n\n'bz2' : 'bz2_codec',\n\n\n'037' : 'cp037',\n'csibm037' : 'cp037',\n'ebcdic_cp_ca' : 'cp037',\n'ebcdic_cp_nl' : 'cp037',\n'ebcdic_cp_us' : 'cp037',\n'ebcdic_cp_wt' : 'cp037',\n'ibm037' : 'cp037',\n'ibm039' : 'cp037',\n\n\n'1026' : 'cp1026',\n'csibm1026' : 'cp1026',\n'ibm1026' : 'cp1026',\n\n\n'1125' : 'cp1125',\n'ibm1125' : 'cp1125',\n'cp866u' : 'cp1125',\n'ruscii' : 'cp1125',\n\n\n'1140' : 'cp1140',\n'ibm1140' : 'cp1140',\n\n\n'1250' : 'cp1250',\n'windows_1250' : 'cp1250',\n\n\n'1251' : 'cp1251',\n'windows_1251' : 'cp1251',\n\n\n'1252' : 'cp1252',\n'windows_1252' : 'cp1252',\n\n\n'1253' : 'cp1253',\n'windows_1253' : 'cp1253',\n\n\n'1254' : 'cp1254',\n'windows_1254' : 'cp1254',\n\n\n'1255' : 'cp1255',\n'windows_1255' : 'cp1255',\n\n\n'1256' : 'cp1256',\n'windows_1256' : 'cp1256',\n\n\n'1257' : 'cp1257',\n'windows_1257' : 'cp1257',\n\n\n'1258' : 'cp1258',\n'windows_1258' : 'cp1258',\n\n\n'273' : 'cp273',\n'ibm273' : 'cp273',\n'csibm273' : 'cp273',\n\n\n'424' : 'cp424',\n'csibm424' : 'cp424',\n'ebcdic_cp_he' : 'cp424',\n'ibm424' : 'cp424',\n\n\n'437' : 'cp437',\n'cspc8codepage437' : 'cp437',\n'ibm437' : 'cp437',\n\n\n'500' : 'cp500',\n'csibm500' : 'cp500',\n'ebcdic_cp_be' : 'cp500',\n'ebcdic_cp_ch' : 'cp500',\n'ibm500' : 'cp500',\n\n\n'775' : 'cp775',\n'cspc775baltic' : 'cp775',\n'ibm775' : 'cp775',\n\n\n'850' : 'cp850',\n'cspc850multilingual' : 'cp850',\n'ibm850' : 'cp850',\n\n\n'852' : 'cp852',\n'cspcp852' : 'cp852',\n'ibm852' : 'cp852',\n\n\n'855' : 'cp855',\n'csibm855' : 'cp855',\n'ibm855' : 'cp855',\n\n\n'857' : 'cp857',\n'csibm857' : 'cp857',\n'ibm857' : 'cp857',\n\n\n'858' : 'cp858',\n'csibm858' : 'cp858',\n'ibm858' : 'cp858',\n\n\n'860' : 'cp860',\n'csibm860' : 'cp860',\n'ibm860' : 'cp860',\n\n\n'861' : 'cp861',\n'cp_is' : 'cp861',\n'csibm861' : 'cp861',\n'ibm861' : 'cp861',\n\n\n'862' : 'cp862',\n'cspc862latinhebrew' : 'cp862',\n'ibm862' : 'cp862',\n\n\n'863' : 'cp863',\n'csibm863' : 'cp863',\n'ibm863' : 'cp863',\n\n\n'864' : 'cp864',\n'csibm864' : 'cp864',\n'ibm864' : 'cp864',\n\n\n'865' : 'cp865',\n'csibm865' : 'cp865',\n'ibm865' : 'cp865',\n\n\n'866' : 'cp866',\n'csibm866' : 'cp866',\n'ibm866' : 'cp866',\n\n\n'869' : 'cp869',\n'cp_gr' : 'cp869',\n'csibm869' : 'cp869',\n'ibm869' : 'cp869',\n\n\n'932' : 'cp932',\n'ms932' : 'cp932',\n'mskanji' : 'cp932',\n'ms_kanji' : 'cp932',\n\n\n'949' : 'cp949',\n'ms949' : 'cp949',\n'uhc' : 'cp949',\n\n\n'950' : 'cp950',\n'ms950' : 'cp950',\n\n\n'jisx0213' : 'euc_jis_2004',\n'eucjis2004' : 'euc_jis_2004',\n'euc_jis2004' : 'euc_jis_2004',\n\n\n'eucjisx0213' : 'euc_jisx0213',\n\n\n'eucjp' : 'euc_jp',\n'ujis' : 'euc_jp',\n'u_jis' : 'euc_jp',\n\n\n'euckr' : 'euc_kr',\n'korean' : 'euc_kr',\n'ksc5601' : 'euc_kr',\n'ks_c_5601' : 'euc_kr',\n'ks_c_5601_1987' : 'euc_kr',\n'ksx1001' : 'euc_kr',\n'ks_x_1001' : 'euc_kr',\n\n\n'gb18030_2000' : 'gb18030',\n\n\n'chinese' : 'gb2312',\n'csiso58gb231280' : 'gb2312',\n'euc_cn' : 'gb2312',\n'euccn' : 'gb2312',\n'eucgb2312_cn' : 'gb2312',\n'gb2312_1980' : 'gb2312',\n'gb2312_80' : 'gb2312',\n'iso_ir_58' : 'gb2312',\n\n\n'936' : 'gbk',\n'cp936' : 'gbk',\n'ms936' : 'gbk',\n\n\n'hex' : 'hex_codec',\n\n\n'roman8' : 'hp_roman8',\n'r8' : 'hp_roman8',\n'csHPRoman8' : 'hp_roman8',\n\n\n'hzgb' : 'hz',\n'hz_gb' : 'hz',\n'hz_gb_2312' : 'hz',\n\n\n'csiso2022jp' : 'iso2022_jp',\n'iso2022jp' : 'iso2022_jp',\n'iso_2022_jp' : 'iso2022_jp',\n\n\n'iso2022jp_1' : 'iso2022_jp_1',\n'iso_2022_jp_1' : 'iso2022_jp_1',\n\n\n'iso2022jp_2' : 'iso2022_jp_2',\n'iso_2022_jp_2' : 'iso2022_jp_2',\n\n\n'iso_2022_jp_2004' : 'iso2022_jp_2004',\n'iso2022jp_2004' : 'iso2022_jp_2004',\n\n\n'iso2022jp_3' : 'iso2022_jp_3',\n'iso_2022_jp_3' : 'iso2022_jp_3',\n\n\n'iso2022jp_ext' : 'iso2022_jp_ext',\n'iso_2022_jp_ext' : 'iso2022_jp_ext',\n\n\n'csiso2022kr' : 'iso2022_kr',\n'iso2022kr' : 'iso2022_kr',\n'iso_2022_kr' : 'iso2022_kr',\n\n\n'csisolatin6' : 'iso8859_10',\n'iso_8859_10' : 'iso8859_10',\n'iso_8859_10_1992' : 'iso8859_10',\n'iso_ir_157' : 'iso8859_10',\n'l6' : 'iso8859_10',\n'latin6' : 'iso8859_10',\n\n\n'thai' : 'iso8859_11',\n'iso_8859_11' : 'iso8859_11',\n'iso_8859_11_2001' : 'iso8859_11',\n\n\n'iso_8859_13' : 'iso8859_13',\n'l7' : 'iso8859_13',\n'latin7' : 'iso8859_13',\n\n\n'iso_8859_14' : 'iso8859_14',\n'iso_8859_14_1998' : 'iso8859_14',\n'iso_celtic' : 'iso8859_14',\n'iso_ir_199' : 'iso8859_14',\n'l8' : 'iso8859_14',\n'latin8' : 'iso8859_14',\n\n\n'iso_8859_15' : 'iso8859_15',\n'l9' : 'iso8859_15',\n'latin9' : 'iso8859_15',\n\n\n'iso_8859_16' : 'iso8859_16',\n'iso_8859_16_2001' : 'iso8859_16',\n'iso_ir_226' : 'iso8859_16',\n'l10' : 'iso8859_16',\n'latin10' : 'iso8859_16',\n\n\n'csisolatin2' : 'iso8859_2',\n'iso_8859_2' : 'iso8859_2',\n'iso_8859_2_1987' : 'iso8859_2',\n'iso_ir_101' : 'iso8859_2',\n'l2' : 'iso8859_2',\n'latin2' : 'iso8859_2',\n\n\n'csisolatin3' : 'iso8859_3',\n'iso_8859_3' : 'iso8859_3',\n'iso_8859_3_1988' : 'iso8859_3',\n'iso_ir_109' : 'iso8859_3',\n'l3' : 'iso8859_3',\n'latin3' : 'iso8859_3',\n\n\n'csisolatin4' : 'iso8859_4',\n'iso_8859_4' : 'iso8859_4',\n'iso_8859_4_1988' : 'iso8859_4',\n'iso_ir_110' : 'iso8859_4',\n'l4' : 'iso8859_4',\n'latin4' : 'iso8859_4',\n\n\n'csisolatincyrillic' : 'iso8859_5',\n'cyrillic' : 'iso8859_5',\n'iso_8859_5' : 'iso8859_5',\n'iso_8859_5_1988' : 'iso8859_5',\n'iso_ir_144' : 'iso8859_5',\n\n\n'arabic' : 'iso8859_6',\n'asmo_708' : 'iso8859_6',\n'csisolatinarabic' : 'iso8859_6',\n'ecma_114' : 'iso8859_6',\n'iso_8859_6' : 'iso8859_6',\n'iso_8859_6_1987' : 'iso8859_6',\n'iso_ir_127' : 'iso8859_6',\n\n\n'csisolatingreek' : 'iso8859_7',\n'ecma_118' : 'iso8859_7',\n'elot_928' : 'iso8859_7',\n'greek' : 'iso8859_7',\n'greek8' : 'iso8859_7',\n'iso_8859_7' : 'iso8859_7',\n'iso_8859_7_1987' : 'iso8859_7',\n'iso_ir_126' : 'iso8859_7',\n\n\n'csisolatinhebrew' : 'iso8859_8',\n'hebrew' : 'iso8859_8',\n'iso_8859_8' : 'iso8859_8',\n'iso_8859_8_1988' : 'iso8859_8',\n'iso_ir_138' : 'iso8859_8',\n\n\n'csisolatin5' : 'iso8859_9',\n'iso_8859_9' : 'iso8859_9',\n'iso_8859_9_1989' : 'iso8859_9',\n'iso_ir_148' : 'iso8859_9',\n'l5' : 'iso8859_9',\n'latin5' : 'iso8859_9',\n\n\n'cp1361' : 'johab',\n'ms1361' : 'johab',\n\n\n'cskoi8r' : 'koi8_r',\n\n\n\n\n\n\n\n\n'8859' : 'latin_1',\n'cp819' : 'latin_1',\n'csisolatin1' : 'latin_1',\n'ibm819' : 'latin_1',\n'iso8859' : 'latin_1',\n'iso8859_1' : 'latin_1',\n'iso_8859_1' : 'latin_1',\n'iso_8859_1_1987' : 'latin_1',\n'iso_ir_100' : 'latin_1',\n'l1' : 'latin_1',\n'latin' : 'latin_1',\n'latin1' : 'latin_1',\n\n\n'maccyrillic' : 'mac_cyrillic',\n\n\n'macgreek' : 'mac_greek',\n\n\n'maciceland' : 'mac_iceland',\n\n\n'maccentraleurope' : 'mac_latin2',\n'maclatin2' : 'mac_latin2',\n\n\n'macintosh' : 'mac_roman',\n'macroman' : 'mac_roman',\n\n\n'macturkish' : 'mac_turkish',\n\n\n'dbcs' : 'mbcs',\n\n\n'csptcp154' : 'ptcp154',\n'pt154' : 'ptcp154',\n'cp154' : 'ptcp154',\n'cyrillic_asian' : 'ptcp154',\n\n\n'quopri' : 'quopri_codec',\n'quoted_printable' : 'quopri_codec',\n'quotedprintable' : 'quopri_codec',\n\n\n'rot13' : 'rot_13',\n\n\n'csshiftjis' : 'shift_jis',\n'shiftjis' : 'shift_jis',\n'sjis' : 'shift_jis',\n's_jis' : 'shift_jis',\n\n\n'shiftjis2004' : 'shift_jis_2004',\n'sjis_2004' : 'shift_jis_2004',\n's_jis_2004' : 'shift_jis_2004',\n\n\n'shiftjisx0213' : 'shift_jisx0213',\n'sjisx0213' : 'shift_jisx0213',\n's_jisx0213' : 'shift_jisx0213',\n\n\n'tis260' : 'tactis',\n\n\n'tis620' : 'tis_620',\n'tis_620_0' : 'tis_620',\n'tis_620_2529_0' : 'tis_620',\n'tis_620_2529_1' : 'tis_620',\n'iso_ir_166' : 'tis_620',\n\n\n'u16' : 'utf_16',\n'utf16' : 'utf_16',\n\n\n'unicodebigunmarked' : 'utf_16_be',\n'utf_16be' : 'utf_16_be',\n\n\n'unicodelittleunmarked' : 'utf_16_le',\n'utf_16le' : 'utf_16_le',\n\n\n'u32' : 'utf_32',\n'utf32' : 'utf_32',\n\n\n'utf_32be' : 'utf_32_be',\n\n\n'utf_32le' : 'utf_32_le',\n\n\n'u7' : 'utf_7',\n'utf7' : 'utf_7',\n'unicode_1_1_utf_7' : 'utf_7',\n\n\n'u8' : 'utf_8',\n'utf' : 'utf_8',\n'utf8' : 'utf_8',\n'utf8_ucs2' : 'utf_8',\n'utf8_ucs4' : 'utf_8',\n\n\n'uu' : 'uu_codec',\n\n\n'zip' : 'zlib_codec',\n'zlib' : 'zlib_codec',\n\n\n'x_mac_japanese' : 'shift_jis',\n'x_mac_korean' : 'euc_kr',\n'x_mac_simp_chinese' : 'gb2312',\n'x_mac_trad_chinese' : 'big5',\n}\n"], "fnmatch": [".py", "\"\"\nimport os\nimport posixpath\nimport re\nimport functools\n\n__all__ = [\"filter\", \"fnmatch\", \"fnmatchcase\", \"translate\"]\n\ndef fnmatch(name, pat):\n \"\"\n name = os.path.normcase(name)\n pat = os.path.normcase(pat)\n return fnmatchcase(name, pat)\n \n@functools.lru_cache(maxsize=256, typed=True)\ndef _compile_pattern(pat):\n if isinstance(pat, bytes):\n  pat_str = str(pat, 'ISO-8859-1')\n  res_str = translate(pat_str)\n  res = bytes(res_str, 'ISO-8859-1')\n else:\n  res = translate(pat)\n return re.compile(res).match\n \ndef filter(names, pat):\n \"\"\n result = []\n pat = os.path.normcase(pat)\n match = _compile_pattern(pat)\n if os.path is posixpath:\n \n  for name in names:\n   if match(name):\n    result.append(name)\n else:\n  for name in names:\n   if match(os.path.normcase(name)):\n    result.append(name)\n return result\n \ndef fnmatchcase(name, pat):\n \"\"\n match = _compile_pattern(pat)\n return match(name) is not None\n \n \ndef translate(pat):\n \"\"\n \n i, n = 0, len(pat)\n res = ''\n while i < n:\n  c = pat[i]\n  i = i+1\n  if c == '*':\n   res = res + '.*'\n  elif c == '?':\n   res = res + '.'\n  elif c == '[':\n   j = i\n   if j < n and pat[j] == '!':\n    j = j+1\n   if j < n and pat[j] == ']':\n    j = j+1\n   while j < n and pat[j] != ']':\n    j = j+1\n   if j >= n:\n    res = res + '\\\\['\n   else:\n    stuff = pat[i:j].replace('\\\\','\\\\\\\\')\n    i = j+1\n    if stuff[0] == '!':\n     stuff = '^' + stuff[1:]\n    elif stuff[0] == '^':\n     stuff = '\\\\' + stuff\n    res = '%s[%s]' % (res, stuff)\n  else:\n   res = res + re.escape(c)\n return res + '\\Z(?ms)'\n"], "sre_parse": [".py", "\n\n\n\n\n\n\n\n\n\n\"\"\n\n\n\nimport sys\n\nfrom sre_constants import *\nfrom _sre import MAXREPEAT\n\nSPECIAL_CHARS = \".\\\\[{()*+?^$|\"\nREPEAT_CHARS = \"*+?{\"\n\nDIGITS = set(\"0123456789\")\n\nOCTDIGITS = set(\"01234567\")\nHEXDIGITS = set(\"0123456789abcdefABCDEF\")\n\nWHITESPACE = set(\" \\t\\n\\r\\v\\f\")\n\nESCAPES = {\nr\"\\a\": (LITERAL, ord(\"\\a\")),\nr\"\\b\": (LITERAL, ord(\"\\b\")),\nr\"\\f\": (LITERAL, ord(\"\\f\")),\nr\"\\n\": (LITERAL, ord(\"\\n\")),\nr\"\\r\": (LITERAL, ord(\"\\r\")),\nr\"\\t\": (LITERAL, ord(\"\\t\")),\nr\"\\v\": (LITERAL, ord(\"\\v\")),\nr\"\\\\\": (LITERAL, ord(\"\\\\\"))\n}\n\nCATEGORIES = {\nr\"\\A\": (AT, AT_BEGINNING_STRING), \nr\"\\b\": (AT, AT_BOUNDARY),\nr\"\\B\": (AT, AT_NON_BOUNDARY),\nr\"\\d\": (IN, [(CATEGORY, CATEGORY_DIGIT)]),\nr\"\\D\": (IN, [(CATEGORY, CATEGORY_NOT_DIGIT)]),\nr\"\\s\": (IN, [(CATEGORY, CATEGORY_SPACE)]),\nr\"\\S\": (IN, [(CATEGORY, CATEGORY_NOT_SPACE)]),\nr\"\\w\": (IN, [(CATEGORY, CATEGORY_WORD)]),\nr\"\\W\": (IN, [(CATEGORY, CATEGORY_NOT_WORD)]),\nr\"\\Z\": (AT, AT_END_STRING), \n}\n\nFLAGS = {\n\n\"i\": SRE_FLAG_IGNORECASE,\n\"L\": SRE_FLAG_LOCALE,\n\"m\": SRE_FLAG_MULTILINE,\n\"s\": SRE_FLAG_DOTALL,\n\"x\": SRE_FLAG_VERBOSE,\n\n\"a\": SRE_FLAG_ASCII,\n\"t\": SRE_FLAG_TEMPLATE,\n\"u\": SRE_FLAG_UNICODE,\n}\n\nclass Pattern:\n\n def __init__(self):\n  self.flags = 0\n  self.open = []\n  self.groups = 1\n  self.groupdict = {}\n def opengroup(self, name=None):\n  gid = self.groups\n  self.groups = gid + 1\n  if name is not None:\n   ogid = self.groupdict.get(name, None)\n   if ogid is not None:\n    raise error(\"redefinition of group name %s as group %d; \"\n    \"was group %d\" % (repr(name), gid, ogid))\n   self.groupdict[name] = gid\n  self.open.append(gid)\n  return gid\n def closegroup(self, gid):\n  self.open.remove(gid)\n def checkgroup(self, gid):\n  return gid < self.groups and gid not in self.open\n  \nclass SubPattern:\n\n def __init__(self, pattern, data=None):\n  self.pattern = pattern\n  if data is None:\n   data = []\n  self.data = data\n  self.width = None\n def __iter__(self):\n  return iter(self.data)\n  \n def dump(self, level=0):\n  nl = 1\n  seqtypes = (tuple, list)\n  for op, av in self.data:\n   print(level*\"  \" + op, end=' '); nl = 0\n   if op == \"in\":\n   \n    print(); nl = 1\n    for op, a in av:\n     print((level+1)*\"  \" + op, a)\n   elif op == \"branch\":\n    print(); nl = 1\n    i = 0\n    for a in av[1]:\n     if i > 0:\n      print(level*\"  \" + \"or\")\n     a.dump(level+1); nl = 1\n     i = i + 1\n   elif isinstance(av, seqtypes):\n    for a in av:\n     if isinstance(a, SubPattern):\n      if not nl: print()\n      a.dump(level+1); nl = 1\n     else:\n      print(a, end=' ') ; nl = 0\n   else:\n    print(av, end=' ') ; nl = 0\n   if not nl: print()\n def __repr__(self):\n  return repr(self.data)\n def __len__(self):\n  return len(self.data)\n def __delitem__(self, index):\n  del self.data[index]\n def __getitem__(self, index):\n  if isinstance(index, slice):\n   return SubPattern(self.pattern, self.data[index])\n  return self.data[index]\n def __setitem__(self, index, code):\n  self.data[index] = code\n def insert(self, index, code):\n  self.data.insert(index, code)\n def append(self, code):\n  self.data.append(code)\n def getwidth(self):\n \n  if self.width:\n   return self.width\n  lo = hi = 0\n  UNITCODES = (ANY, RANGE, IN, LITERAL, NOT_LITERAL, CATEGORY)\n  REPEATCODES = (MIN_REPEAT, MAX_REPEAT)\n  for op, av in self.data:\n   if op is BRANCH:\n    i = sys.maxsize\n    j = 0\n    for av in av[1]:\n     l, h = av.getwidth()\n     i = min(i, l)\n     j = max(j, h)\n    lo = lo + i\n    hi = hi + j\n   elif op is CALL:\n    i, j = av.getwidth()\n    lo = lo + i\n    hi = hi + j\n   elif op is SUBPATTERN:\n    i, j = av[1].getwidth()\n    lo = lo + i\n    hi = hi + j\n   elif op in REPEATCODES:\n    i, j = av[2].getwidth()\n    lo = lo + int(i) * av[0]\n    hi = hi + int(j) * av[1]\n   elif op in UNITCODES:\n    lo = lo + 1\n    hi = hi + 1\n   elif op == SUCCESS:\n    break\n  self.width = int(min(lo, sys.maxsize)), int(min(hi, sys.maxsize))\n  return self.width\n  \nclass Tokenizer:\n def __init__(self, string):\n  self.istext = isinstance(string, str)\n  self.string = string\n  self.index = 0\n  self.__next()\n def __next(self):\n  if self.index >= len(self.string):\n   self.next = None\n   return\n  char = self.string[self.index:self.index+1]\n  \n  \n  if char and not self.istext:\n   char = chr(char[0])\n  if char == \"\\\\\":\n   try:\n    c = self.string[self.index + 1]\n   except IndexError:\n    raise error(\"bogus escape (end of line)\")\n   if not self.istext:\n    c = chr(c)\n   char = char + c\n  self.index = self.index + len(char)\n  self.next = char\n def match(self, char, skip=1):\n  if char == self.next:\n   if skip:\n    self.__next()\n   return 1\n  return 0\n def get(self):\n  this = self.next\n  self.__next()\n  return this\n def getwhile(self, n, charset):\n  result = ''\n  for _ in range(n):\n   c = self.next\n   if c not in charset:\n    break\n   result += c\n   self.__next()\n  return result\n def tell(self):\n  return self.index, self.next\n def seek(self, index):\n  self.index, self.next = index\n  \ndef isident(char):\n return \"a\" <= char <= \"z\" or \"A\" <= char <= \"Z\" or char == \"_\"\n \ndef isdigit(char):\n return \"0\" <= char <= \"9\"\n \ndef isname(name):\n\n if not isident(name[0]):\n  return False\n for char in name[1:]:\n  if not isident(char) and not isdigit(char):\n   return False\n return True\n \ndef _class_escape(source, escape):\n\n code = ESCAPES.get(escape)\n if code:\n  return code\n code = CATEGORIES.get(escape)\n if code and code[0] == IN:\n  return code\n try:\n  c = escape[1:2]\n  if c == \"x\":\n  \n   escape += source.getwhile(2, HEXDIGITS)\n   if len(escape) != 4:\n    raise ValueError\n   return LITERAL, int(escape[2:], 16) & 0xff\n  elif c == \"u\" and source.istext:\n  \n   escape += source.getwhile(4, HEXDIGITS)\n   if len(escape) != 6:\n    raise ValueError\n   return LITERAL, int(escape[2:], 16)\n  elif c == \"U\" and source.istext:\n  \n   escape += source.getwhile(8, HEXDIGITS)\n   if len(escape) != 10:\n    raise ValueError\n   c = int(escape[2:], 16)\n   chr(c) \n   return LITERAL, c\n  elif c in OCTDIGITS:\n  \n   escape += source.getwhile(2, OCTDIGITS)\n   return LITERAL, int(escape[1:], 8) & 0xff\n  elif c in DIGITS:\n   raise ValueError\n  if len(escape) == 2:\n   return LITERAL, ord(escape[1])\n except ValueError:\n  pass\n raise error(\"bogus escape: %s\" % repr(escape))\n \ndef _escape(source, escape, state):\n\n code = CATEGORIES.get(escape)\n if code:\n  return code\n code = ESCAPES.get(escape)\n if code:\n  return code\n try:\n  c = escape[1:2]\n  if c == \"x\":\n  \n   escape += source.getwhile(2, HEXDIGITS)\n   if len(escape) != 4:\n    raise ValueError\n   return LITERAL, int(escape[2:], 16) & 0xff\n  elif c == \"u\" and source.istext:\n  \n   escape += source.getwhile(4, HEXDIGITS)\n   if len(escape) != 6:\n    raise ValueError\n   return LITERAL, int(escape[2:], 16)\n  elif c == \"U\" and source.istext:\n  \n   escape += source.getwhile(8, HEXDIGITS)\n   if len(escape) != 10:\n    raise ValueError\n   c = int(escape[2:], 16)\n   chr(c) \n   return LITERAL, c\n  elif c == \"0\":\n  \n   escape += source.getwhile(2, OCTDIGITS)\n   return LITERAL, int(escape[1:], 8) & 0xff\n  elif c in DIGITS:\n  \n   if source.next in DIGITS:\n    escape = escape + source.get()\n    if (escape[1] in OCTDIGITS and escape[2] in OCTDIGITS and\n    source.next in OCTDIGITS):\n    \n     escape = escape + source.get()\n     return LITERAL, int(escape[1:], 8) & 0xff\n     \n   group = int(escape[1:])\n   if group < state.groups:\n    if not state.checkgroup(group):\n     raise error(\"cannot refer to open group\")\n    return GROUPREF, group\n   raise ValueError\n  if len(escape) == 2:\n   return LITERAL, ord(escape[1])\n except ValueError:\n  pass\n raise error(\"bogus escape: %s\" % repr(escape))\n \ndef _parse_sub(source, state, nested=1):\n\n\n items = []\n itemsappend = items.append\n sourcematch = source.match\n while 1:\n  itemsappend(_parse(source, state))\n  if sourcematch(\"|\"):\n   continue\n  if not nested:\n   break\n  if not source.next or sourcematch(\")\", 0):\n   break\n  else:\n   raise error(\"pattern not properly closed\")\n   \n if len(items) == 1:\n  return items[0]\n  \n subpattern = SubPattern(state)\n subpatternappend = subpattern.append\n \n \n while 1:\n  prefix = None\n  for item in items:\n   if not item:\n    break\n   if prefix is None:\n    prefix = item[0]\n   elif item[0] != prefix:\n    break\n  else:\n  \n  \n   for item in items:\n    del item[0]\n   subpatternappend(prefix)\n   continue \n  break\n  \n  \n for item in items:\n  if len(item) != 1 or item[0][0] != LITERAL:\n   break\n else:\n \n \n  set = []\n  setappend = set.append\n  for item in items:\n   setappend(item[0])\n  subpatternappend((IN, set))\n  return subpattern\n  \n subpattern.append((BRANCH, (None, items)))\n return subpattern\n \ndef _parse_sub_cond(source, state, condgroup):\n item_yes = _parse(source, state)\n if source.match(\"|\"):\n  item_no = _parse(source, state)\n  if source.match(\"|\"):\n   raise error(\"conditional backref with more than two branches\")\n else:\n  item_no = None\n if source.next and not source.match(\")\", 0):\n  raise error(\"pattern not properly closed\")\n subpattern = SubPattern(state)\n subpattern.append((GROUPREF_EXISTS, (condgroup, item_yes, item_no)))\n return subpattern\n \n_PATTERNENDERS = set(\"|)\")\n_ASSERTCHARS = set(\"=!<\")\n_LOOKBEHINDASSERTCHARS = set(\"=!\")\n_REPEATCODES = set([MIN_REPEAT, MAX_REPEAT])\n\ndef _parse(source, state):\n\n subpattern = SubPattern(state)\n \n \n subpatternappend = subpattern.append\n sourceget = source.get\n sourcematch = source.match\n _len = len\n PATTERNENDERS = _PATTERNENDERS\n ASSERTCHARS = _ASSERTCHARS\n LOOKBEHINDASSERTCHARS = _LOOKBEHINDASSERTCHARS\n REPEATCODES = _REPEATCODES\n \n while 1:\n \n  if source.next in PATTERNENDERS:\n   break \n  this = sourceget()\n  if this is None:\n   break \n   \n  if state.flags & SRE_FLAG_VERBOSE:\n  \n   if this in WHITESPACE:\n    continue\n   if this == \"#\":\n    while 1:\n     this = sourceget()\n     if this in (None, \"\\n\"):\n      break\n    continue\n    \n  if this and this[0] not in SPECIAL_CHARS:\n   subpatternappend((LITERAL, ord(this)))\n   \n  elif this == \"[\":\n  \n   set = []\n   setappend = set.append\n   \n   \n   if sourcematch(\"^\"):\n    setappend((NEGATE, None))\n    \n   start = set[:]\n   while 1:\n    this = sourceget()\n    if this == \"]\" and set != start:\n     break\n    elif this and this[0] == \"\\\\\":\n     code1 = _class_escape(source, this)\n    elif this:\n     code1 = LITERAL, ord(this)\n    else:\n     raise error(\"unexpected end of regular expression\")\n    if sourcematch(\"-\"):\n    \n     this = sourceget()\n     if this == \"]\":\n      if code1[0] is IN:\n       code1 = code1[1][0]\n      setappend(code1)\n      setappend((LITERAL, ord(\"-\")))\n      break\n     elif this:\n      if this[0] == \"\\\\\":\n       code2 = _class_escape(source, this)\n      else:\n       code2 = LITERAL, ord(this)\n      if code1[0] != LITERAL or code2[0] != LITERAL:\n       raise error(\"bad character range\")\n      lo = code1[1]\n      hi = code2[1]\n      if hi < lo:\n       raise error(\"bad character range\")\n      setappend((RANGE, (lo, hi)))\n     else:\n      raise error(\"unexpected end of regular expression\")\n    else:\n     if code1[0] is IN:\n      code1 = code1[1][0]\n     setappend(code1)\n     \n     \n   if _len(set)==1 and set[0][0] is LITERAL:\n    subpatternappend(set[0]) \n   elif _len(set)==2 and set[0][0] is NEGATE and set[1][0] is LITERAL:\n    subpatternappend((NOT_LITERAL, set[1][1])) \n   else:\n   \n    subpatternappend((IN, set))\n    \n  elif this and this[0] in REPEAT_CHARS:\n  \n   if this == \"?\":\n    min, max = 0, 1\n   elif this == \"*\":\n    min, max = 0, MAXREPEAT\n    \n   elif this == \"+\":\n    min, max = 1, MAXREPEAT\n   elif this == \"{\":\n    if source.next == \"}\":\n     subpatternappend((LITERAL, ord(this)))\n     continue\n    here = source.tell()\n    min, max = 0, MAXREPEAT\n    lo = hi = \"\"\n    while source.next in DIGITS:\n     lo = lo + source.get()\n    if sourcematch(\",\"):\n     while source.next in DIGITS:\n      hi = hi + sourceget()\n    else:\n     hi = lo\n    if not sourcematch(\"}\"):\n     subpatternappend((LITERAL, ord(this)))\n     source.seek(here)\n     continue\n    if lo:\n     min = int(lo)\n     if min >= MAXREPEAT:\n      raise OverflowError(\"the repetition number is too large\")\n    if hi:\n     max = int(hi)\n     if max >= MAXREPEAT:\n      raise OverflowError(\"the repetition number is too large\")\n     if max < min:\n      raise error(\"bad repeat interval\")\n   else:\n    raise error(\"not supported\")\n    \n   if subpattern:\n    item = subpattern[-1:]\n   else:\n    item = None\n   if not item or (_len(item) == 1 and item[0][0] == AT):\n    raise error(\"nothing to repeat\")\n   if item[0][0] in REPEATCODES:\n    raise error(\"multiple repeat\")\n   if sourcematch(\"?\"):\n    subpattern[-1] = (MIN_REPEAT, (min, max, item))\n   else:\n    subpattern[-1] = (MAX_REPEAT, (min, max, item))\n    \n  elif this == \".\":\n   subpatternappend((ANY, None))\n   \n  elif this == \"(\":\n   group = 1\n   name = None\n   condgroup = None\n   if sourcematch(\"?\"):\n    group = 0\n    \n    if sourcematch(\"P\"):\n    \n     if sourcematch(\"<\"):\n     \n      name = \"\"\n      while 1:\n       char = sourceget()\n       if char is None:\n        raise error(\"unterminated name\")\n       if char == \">\":\n        break\n       name = name + char\n      group = 1\n      if not name:\n       raise error(\"missing group name\")\n      if not isname(name):\n       raise error(\"bad character in group name\")\n     elif sourcematch(\"=\"):\n     \n      name = \"\"\n      while 1:\n       char = sourceget()\n       if char is None:\n        raise error(\"unterminated name\")\n       if char == \")\":\n        break\n       name = name + char\n      if not name:\n       raise error(\"missing group name\")\n      if not isname(name):\n       raise error(\"bad character in group name\")\n      gid = state.groupdict.get(name)\n      if gid is None:\n       raise error(\"unknown group name\")\n      subpatternappend((GROUPREF, gid))\n      continue\n     else:\n      char = sourceget()\n      if char is None:\n       raise error(\"unexpected end of pattern\")\n      raise error(\"unknown specifier: ?P%s\" % char)\n    elif sourcematch(\":\"):\n    \n     group = 2\n    elif sourcematch(\"#\"):\n    \n     while 1:\n      if source.next is None or source.next == \")\":\n       break\n      sourceget()\n     if not sourcematch(\")\"):\n      raise error(\"unbalanced parenthesis\")\n     continue\n    elif source.next in ASSERTCHARS:\n    \n     char = sourceget()\n     dir = 1\n     if char == \"<\":\n      if source.next not in LOOKBEHINDASSERTCHARS:\n       raise error(\"syntax error\")\n      dir = -1 \n      char = sourceget()\n     p = _parse_sub(source, state)\n     if not sourcematch(\")\"):\n      raise error(\"unbalanced parenthesis\")\n     if char == \"=\":\n      subpatternappend((ASSERT, (dir, p)))\n     else:\n      subpatternappend((ASSERT_NOT, (dir, p)))\n     continue\n    elif sourcematch(\"(\"):\n    \n     condname = \"\"\n     while 1:\n      char = sourceget()\n      if char is None:\n       raise error(\"unterminated name\")\n      if char == \")\":\n       break\n      condname = condname + char\n     group = 2\n     if not condname:\n      raise error(\"missing group name\")\n     if isname(condname):\n      condgroup = state.groupdict.get(condname)\n      if condgroup is None:\n       raise error(\"unknown group name\")\n     else:\n      try:\n       condgroup = int(condname)\n      except ValueError:\n       raise error(\"bad character in group name\")\n    else:\n    \n     if not source.next in FLAGS:\n      raise error(\"unexpected end of pattern\")\n     while source.next in FLAGS:\n      state.flags = state.flags | FLAGS[sourceget()]\n   if group:\n   \n    if group == 2:\n    \n     group = None\n    else:\n     group = state.opengroup(name)\n    if condgroup:\n     p = _parse_sub_cond(source, state, condgroup)\n    else:\n     p = _parse_sub(source, state)\n    if not sourcematch(\")\"):\n     raise error(\"unbalanced parenthesis\")\n    if group is not None:\n     state.closegroup(group)\n    subpatternappend((SUBPATTERN, (group, p)))\n   else:\n    while 1:\n     char = sourceget()\n     if char is None:\n      raise error(\"unexpected end of pattern\")\n     if char == \")\":\n      break\n     raise error(\"unknown extension\")\n     \n  elif this == \"^\":\n   subpatternappend((AT, AT_BEGINNING))\n   \n  elif this == \"$\":\n   subpattern.append((AT, AT_END))\n   \n  elif this and this[0] == \"\\\\\":\n   code = _escape(source, this, state)\n   subpatternappend(code)\n   \n  else:\n   raise error(\"parser error\")\n   \n return subpattern\n \ndef fix_flags(src, flags):\n\n if isinstance(src, str):\n  if not flags & SRE_FLAG_ASCII:\n   flags |= SRE_FLAG_UNICODE\n  elif flags & SRE_FLAG_UNICODE:\n   raise ValueError(\"ASCII and UNICODE flags are incompatible\")\n else:\n  if flags & SRE_FLAG_UNICODE:\n   raise ValueError(\"can't use UNICODE flag with a bytes pattern\")\n return flags\n \ndef parse(str, flags=0, pattern=None):\n\n source = Tokenizer(str)\n \n if pattern is None:\n  pattern = Pattern()\n pattern.flags = flags\n pattern.str = str\n p = _parse_sub(source, pattern, 0)\n p.pattern.flags = fix_flags(str, p.pattern.flags)\n \n tail = source.get()\n if tail == \")\":\n  raise error(\"unbalanced parenthesis\")\n elif tail:\n  raise error(\"bogus characters at end of regular expression\")\n  \n if flags & SRE_FLAG_DEBUG:\n  p.dump()\n  \n if not (flags & SRE_FLAG_VERBOSE) and p.pattern.flags & SRE_FLAG_VERBOSE:\n \n \n  return parse(str, p.pattern.flags)\n  \n return p\n \ndef parse_template(source, pattern):\n\n\n s = Tokenizer(source)\n sget = s.get\n p = []\n a = p.append\n def literal(literal, p=p, pappend=a):\n  if p and p[-1][0] is LITERAL:\n   p[-1] = LITERAL, p[-1][1] + literal\n  else:\n   pappend((LITERAL, literal))\n sep = source[:0]\n if isinstance(sep, str):\n  makechar = chr\n else:\n  makechar = chr\n while 1:\n  this = sget()\n  if this is None:\n   break \n  if this and this[0] == \"\\\\\":\n  \n   c = this[1:2]\n   if c == \"g\":\n    name = \"\"\n    if s.match(\"<\"):\n     while 1:\n      char = sget()\n      if char is None:\n       raise error(\"unterminated group name\")\n      if char == \">\":\n       break\n      name = name + char\n    if not name:\n     raise error(\"missing group name\")\n    try:\n     index = int(name)\n     if index < 0:\n      raise error(\"negative group number\")\n    except ValueError:\n     if not isname(name):\n      raise error(\"bad character in group name\")\n     try:\n      index = pattern.groupindex[name]\n     except KeyError:\n      raise IndexError(\"unknown group name\")\n    a((MARK, index))\n   elif c == \"0\":\n    if s.next in OCTDIGITS:\n     this = this + sget()\n     if s.next in OCTDIGITS:\n      this = this + sget()\n    literal(makechar(int(this[1:], 8) & 0xff))\n   elif c in DIGITS:\n    isoctal = False\n    if s.next in DIGITS:\n     this = this + sget()\n     if (c in OCTDIGITS and this[2] in OCTDIGITS and\n     s.next in OCTDIGITS):\n      this = this + sget()\n      isoctal = True\n      literal(makechar(int(this[1:], 8) & 0xff))\n    if not isoctal:\n     a((MARK, int(this[1:])))\n   else:\n    try:\n     this = makechar(ESCAPES[this][1])\n    except KeyError:\n     pass\n    literal(this)\n  else:\n   literal(this)\n   \n i = 0\n groups = []\n groupsappend = groups.append\n literals = [None] * len(p)\n if isinstance(source, str):\n  encode = lambda x: x\n else:\n \n \n  encode = lambda x: x.encode('latin-1')\n for c, s in p:\n  if c is MARK:\n   groupsappend((i, s))\n   \n  else:\n   literals[i] = encode(s)\n  i = i + 1\n return groups, literals\n \ndef expand_template(template, match):\n g = match.group\n sep = match.string[:0]\n groups, literals = template\n literals = literals[:]\n try:\n  for index, group in groups:\n   literals[index] = s = g(group)\n   if s is None:\n    raise error(\"unmatched group\")\n except IndexError:\n  raise error(\"invalid group reference\")\n return sep.join(literals)\n \n \n"], "pickle": [".py", "from json import *"], "unittest.test.testmock": [".py", "import os\nimport sys\nimport unittest\n\n\nhere = os.path.dirname(__file__)\nloader = unittest.defaultTestLoader\n\ndef load_tests(*args):\n suite = unittest.TestSuite()\n for fn in os.listdir(here):\n  if fn.startswith(\"test\") and fn.endswith(\".py\"):\n   modname = \"unittest.test.testmock.\" + fn[:-3]\n   __import__(modname)\n   module = sys.modules[modname]\n   suite.addTest(loader.loadTestsFromModule(module))\n return suite\n", 1], "browser": [".py", "from _browser import *\n\nfrom .local_storage import Local_Storage\nfrom .session_storage import Session_Storage\nfrom .object_storage import Object_Storage", 1], "reprlib": [".py", "\"\"\n\n__all__ = [\"Repr\", \"repr\", \"recursive_repr\"]\n\nimport builtins\nfrom itertools import islice\ntry:\n from _thread import get_ident\nexcept ImportError:\n from _dummy_thread import get_ident\n \ndef recursive_repr(fillvalue='...'):\n \"\"\n \n def decorating_function(user_function):\n  repr_running = set()\n  \n  def wrapper(self):\n   key = id(self), get_ident()\n   if key in repr_running:\n    return fillvalue\n   repr_running.add(key)\n   try:\n    result = user_function(self)\n   finally:\n    repr_running.discard(key)\n   return result\n   \n   \n  wrapper.__module__ = getattr(user_function, '__module__')\n  wrapper.__doc__ = getattr(user_function, '__doc__')\n  wrapper.__name__ = getattr(user_function, '__name__')\n  wrapper.__annotations__ = getattr(user_function, '__annotations__', {})\n  return wrapper\n  \n return decorating_function\n \nclass Repr:\n\n def __init__(self):\n  self.maxlevel = 6\n  self.maxtuple = 6\n  self.maxlist = 6\n  self.maxarray = 5\n  self.maxdict = 4\n  self.maxset = 6\n  self.maxfrozenset = 6\n  self.maxdeque = 6\n  self.maxstring = 30\n  self.maxlong = 40\n  self.maxother = 30\n  \n def repr(self, x):\n  return self.repr1(x, self.maxlevel)\n  \n def repr1(self, x, level):\n  typename = type(x).__name__\n  if ' ' in typename:\n   parts = typename.split()\n   typename = '_'.join(parts)\n  if hasattr(self, 'repr_' + typename):\n   return getattr(self, 'repr_' + typename)(x, level)\n  else:\n   return self.repr_instance(x, level)\n   \n def _repr_iterable(self, x, level, left, right, maxiter, trail=''):\n  n = len(x)\n  if level <= 0 and n:\n   s = '...'\n  else:\n   newlevel = level - 1\n   repr1 = self.repr1\n   pieces = [repr1(elem, newlevel) for elem in islice(x, maxiter)]\n   if n > maxiter: pieces.append('...')\n   s = ', '.join(pieces)\n   if n == 1 and trail: right = trail + right\n  return '%s%s%s' % (left, s, right)\n  \n def repr_tuple(self, x, level):\n  return self._repr_iterable(x, level, '(', ')', self.maxtuple, ',')\n  \n def repr_list(self, x, level):\n  return self._repr_iterable(x, level, '[', ']', self.maxlist)\n  \n def repr_array(self, x, level):\n  header = \"array('%s', [\" % x.typecode\n  return self._repr_iterable(x, level, header, '])', self.maxarray)\n  \n def repr_set(self, x, level):\n  x = _possibly_sorted(x)\n  return self._repr_iterable(x, level, 'set([', '])', self.maxset)\n  \n def repr_frozenset(self, x, level):\n  x = _possibly_sorted(x)\n  return self._repr_iterable(x, level, 'frozenset([', '])',\n  self.maxfrozenset)\n  \n def repr_deque(self, x, level):\n  return self._repr_iterable(x, level, 'deque([', '])', self.maxdeque)\n  \n def repr_dict(self, x, level):\n  n = len(x)\n  if n == 0: return '{}'\n  if level <= 0: return '{...}'\n  newlevel = level - 1\n  repr1 = self.repr1\n  pieces = []\n  for key in islice(_possibly_sorted(x), self.maxdict):\n   keyrepr = repr1(key, newlevel)\n   valrepr = repr1(x[key], newlevel)\n   pieces.append('%s: %s' % (keyrepr, valrepr))\n  if n > self.maxdict: pieces.append('...')\n  s = ', '.join(pieces)\n  return '{%s}' % (s,)\n  \n def repr_str(self, x, level):\n  s = builtins.repr(x[:self.maxstring])\n  if len(s) > self.maxstring:\n   i = max(0, (self.maxstring-3)//2)\n   j = max(0, self.maxstring-3-i)\n   s = builtins.repr(x[:i] + x[len(x)-j:])\n   s = s[:i] + '...' + s[len(s)-j:]\n  return s\n  \n def repr_int(self, x, level):\n  s = builtins.repr(x) \n  if len(s) > self.maxlong:\n   i = max(0, (self.maxlong-3)//2)\n   j = max(0, self.maxlong-3-i)\n   s = s[:i] + '...' + s[len(s)-j:]\n  return s\n  \n def repr_instance(self, x, level):\n  try:\n   s = builtins.repr(x)\n   \n   \n  except Exception:\n   return '<%s instance at %x>' % (x.__class__.__name__, id(x))\n  if len(s) > self.maxother:\n   i = max(0, (self.maxother-3)//2)\n   j = max(0, self.maxother-3-i)\n   s = s[:i] + '...' + s[len(s)-j:]\n  return s\n  \n  \ndef _possibly_sorted(x):\n\n\n\n try:\n  return sorted(x)\n except Exception:\n  return list(x)\n  \naRepr = Repr()\nrepr = aRepr.repr\n"], "browser.indexed_db": [".py", "class EventListener:\n def __init__(self, events=[]):\n  self._events=events\n  \n def append(self, event):\n  self._events.append(event)\n  \n def fire(self, e):\n  for _event in self._events:\n   _event(e)\n   \nclass IndexedDB:\n def __init__(self):\n  if not __BRYTHON__.has_indexedDB:\n   raise NotImplementedError(\"Your browser doesn't support indexedDB\")\n   return\n   \n  self._indexedDB=__BRYTHON__.indexedDB()\n  self._db=None\n  self._version=None\n  \n def _onsuccess(self, event):\n  self._db=event.target.result\n  \n def open(self, name, onsuccess, version=1.0, onerror=None, \n onupgradeneeded=None):\n  self._version=version\n  _result=self._indexedDB.open(name, version)\n  _success=EventListener([self._onsuccess, onsuccess])\n  _result.onsuccess=_success.fire\n  _result.onupgradeneeded=onupgradeneeded\n  \n  \n  def onerror(e):\n   print(\"onerror: %s:%s\" % (e.type, e.target.result))\n   \n  def onblocked(e):\n   print(\"blocked: %s:%s\" % (e.type, e.result))\n   \n  _result.onerror=onerror\n  _result.onblocked=onblocked\n  \n def transaction(self, entities, mode='read'):\n  return Transaction(self._db.transaction(entities, mode))\n  \nclass Transaction:\n\n def __init__(self, transaction):\n  self._transaction=transaction\n  \n def objectStore(self, name):\n  return ObjectStore(self._transaction.objectStore(name))\n  \nclass ObjectStore:\n\n def __init__(self, objectStore):\n  self._objectStore=objectStore\n  self._data=[]\n  \n def clear(self, onsuccess=None, onerror=None):\n  _result=self._objectStore.clear()\n  \n  if onsuccess is not None:\n   _result.onsuccess=onsuccess\n   \n  if onerror is not None:\n   _result.onerror=onerror\n   \n def _helper(self, func, object, onsuccess=None, onerror=None):\n  _result=func(object)\n  \n  if onsuccess is not None:\n   _result.onsuccess=onsuccess\n   \n  if onerror is not None:\n   _result.onerror=onerror\n   \n def put(self, obj, key=None, onsuccess=None, onerror=None):\n  _r = self._objectStore.put(obj, key)\n  _r.onsuccess = onsuccess\n  _r.onerror = onerror\n  \n def add(self, obj, key, onsuccess=None, onerror=None):\n  _r = self._objectStore.add(obj, key)\n  _r.onsuccess = onsuccess\n  _r.onerror = onerror\n  \n  \n def delete(self, index, onsuccess=None, onerror=None): \n  self._helper(self._objectStore.delete, index, onsuccess, onerror)\n  \n def query(self, *args):\n  self._data=[]\n  def onsuccess(event):\n   cursor=event.target.result\n   if cursor is not None:\n    self._data.append(cursor.value)\n    getattr(cursor,\"continue\")() \n    \n  self._objectStore.openCursor(args).onsuccess=onsuccess\n  \n def fetchall(self):\n  yield self._data\n  \n def get(self, key, onsuccess=None, onerror=None):\n  self._helper(self._objectStore.get, key, onsuccess, onerror)\n"], "sre_compile": [".py", "\n\n\n\n\n\n\n\n\n\n\"\"\n\n\nimport sys\nimport _sre\nimport sre_parse\nfrom sre_constants import *\nfrom _sre import MAXREPEAT\n\n\nassert _sre.MAGIC == MAGIC, \"SRE module mismatch\"\n\nif _sre.CODESIZE == 2:\n MAXCODE = 65535\nelse:\n MAXCODE = 0xFFFFFFFF\n \ndef _identityfunction(x):\n return x\n \n \n_LITERAL_CODES = set([LITERAL, NOT_LITERAL])\n_REPEATING_CODES = set([REPEAT, MIN_REPEAT, MAX_REPEAT])\n_SUCCESS_CODES = set([SUCCESS, FAILURE])\n_ASSERT_CODES = set([ASSERT, ASSERT_NOT])\n\ndef _compile(code, pattern, flags):\n\n emit = code.append\n _len = len\n LITERAL_CODES = _LITERAL_CODES\n REPEATING_CODES = _REPEATING_CODES\n SUCCESS_CODES = _SUCCESS_CODES\n ASSERT_CODES = _ASSERT_CODES\n for op, av in pattern:\n \n \n  if op in LITERAL_CODES:\n   if flags & SRE_FLAG_IGNORECASE:\n    emit(OPCODES[OP_IGNORE[op]])\n    emit(_sre.getlower(av, flags))\n   else:\n    emit(OPCODES[op])\n    emit(av)\n  elif op is IN:\n   if flags & SRE_FLAG_IGNORECASE:\n    emit(OPCODES[OP_IGNORE[op]])\n    def fixup(literal, flags=flags):\n     return _sre.getlower(literal, flags)\n   else:\n    emit(OPCODES[op])\n    fixup = _identityfunction\n   skip = _len(code); emit(0)\n   _compile_charset(av, flags, code, fixup)\n   code[skip] = _len(code) - skip\n  elif op is ANY:\n   if flags & SRE_FLAG_DOTALL:\n    emit(OPCODES[ANY_ALL])\n   else:\n    emit(OPCODES[ANY])\n  elif op in REPEATING_CODES:\n   if flags & SRE_FLAG_TEMPLATE:\n    raise error(\"internal: unsupported template operator\")\n    emit(OPCODES[REPEAT])\n    skip = _len(code); emit(0)\n    emit(av[0])\n    emit(av[1])\n    _compile(code, av[2], flags)\n    emit(OPCODES[SUCCESS])\n    code[skip] = _len(code) - skip\n   elif _simple(av) and op is not REPEAT:\n    if op is MAX_REPEAT:\n     emit(OPCODES[REPEAT_ONE])\n    else:\n     emit(OPCODES[MIN_REPEAT_ONE])\n    skip = _len(code); emit(0)\n    emit(av[0])\n    emit(av[1])\n    _compile(code, av[2], flags)\n    emit(OPCODES[SUCCESS])\n    code[skip] = _len(code) - skip\n   else:\n    emit(OPCODES[REPEAT])\n    skip = _len(code); emit(0)\n    emit(av[0])\n    emit(av[1])\n    _compile(code, av[2], flags)\n    code[skip] = _len(code) - skip\n    if op is MAX_REPEAT:\n     emit(OPCODES[MAX_UNTIL])\n    else:\n     emit(OPCODES[MIN_UNTIL])\n  elif op is SUBPATTERN:\n   if av[0]:\n    emit(OPCODES[MARK])\n    emit((av[0]-1)*2)\n    \n   _compile(code, av[1], flags)\n   if av[0]:\n    emit(OPCODES[MARK])\n    emit((av[0]-1)*2+1)\n  elif op in SUCCESS_CODES:\n   emit(OPCODES[op])\n  elif op in ASSERT_CODES:\n   emit(OPCODES[op])\n   skip = _len(code); emit(0)\n   if av[0] >= 0:\n    emit(0) \n   else:\n    lo, hi = av[1].getwidth()\n    if lo != hi:\n     raise error(\"look-behind requires fixed-width pattern\")\n    emit(lo) \n   _compile(code, av[1], flags)\n   emit(OPCODES[SUCCESS])\n   code[skip] = _len(code) - skip\n  elif op is CALL:\n   emit(OPCODES[op])\n   skip = _len(code); emit(0)\n   _compile(code, av, flags)\n   emit(OPCODES[SUCCESS])\n   code[skip] = _len(code) - skip\n  elif op is AT:\n   emit(OPCODES[op])\n   if flags & SRE_FLAG_MULTILINE:\n    av = AT_MULTILINE.get(av, av)\n   if flags & SRE_FLAG_LOCALE:\n    av = AT_LOCALE.get(av, av)\n   elif flags & SRE_FLAG_UNICODE:\n    av = AT_UNICODE.get(av, av)\n   emit(ATCODES[av])\n  elif op is BRANCH:\n   emit(OPCODES[op])\n   tail = []\n   tailappend = tail.append\n   for av in av[1]:\n    skip = _len(code); emit(0)\n    \n    _compile(code, av, flags)\n    emit(OPCODES[JUMP])\n    tailappend(_len(code)); emit(0)\n    code[skip] = _len(code) - skip\n   emit(0) \n   for tail in tail:\n    code[tail] = _len(code) - tail\n  elif op is CATEGORY:\n   emit(OPCODES[op])\n   if flags & SRE_FLAG_LOCALE:\n    av = CH_LOCALE[av]\n   elif flags & SRE_FLAG_UNICODE:\n    av = CH_UNICODE[av]\n   emit(CHCODES[av])\n  elif op is GROUPREF:\n   if flags & SRE_FLAG_IGNORECASE:\n    emit(OPCODES[OP_IGNORE[op]])\n   else:\n    emit(OPCODES[op])\n   emit(av-1)\n  elif op is GROUPREF_EXISTS:\n   emit(OPCODES[op])\n   emit(av[0]-1)\n   skipyes = _len(code); emit(0)\n   _compile(code, av[1], flags)\n   if av[2]:\n    emit(OPCODES[JUMP])\n    skipno = _len(code); emit(0)\n    code[skipyes] = _len(code) - skipyes + 1\n    _compile(code, av[2], flags)\n    code[skipno] = _len(code) - skipno\n   else:\n    code[skipyes] = _len(code) - skipyes + 1\n  else:\n   raise ValueError(\"unsupported operand type\", op)\n   \ndef _compile_charset(charset, flags, code, fixup=None):\n\n emit = code.append\n if fixup is None:\n  fixup = _identityfunction\n for op, av in _optimize_charset(charset, fixup):\n  emit(OPCODES[op])\n  if op is NEGATE:\n   pass\n  elif op is LITERAL:\n   emit(fixup(av))\n  elif op is RANGE:\n   emit(fixup(av[0]))\n   emit(fixup(av[1]))\n  elif op is CHARSET:\n   code.extend(av)\n  elif op is BIGCHARSET:\n   code.extend(av)\n  elif op is CATEGORY:\n   if flags & SRE_FLAG_LOCALE:\n    emit(CHCODES[CH_LOCALE[av]])\n   elif flags & SRE_FLAG_UNICODE:\n    emit(CHCODES[CH_UNICODE[av]])\n   else:\n    emit(CHCODES[av])\n  else:\n   raise error(\"internal: unsupported set operator\")\n emit(OPCODES[FAILURE])\n \n \ndef _optimize_charset(charset, fixup):\n\n out = []\n outappend = out.append\n charmap = [0]*256\n try:\n  for op, av in charset:\n   if op is NEGATE:\n    outappend((op, av))\n   elif op is LITERAL:\n    charmap[fixup(av)] = 1\n   elif op is RANGE:\n    for i in range(fixup(av[0]), fixup(av[1])+1):\n     charmap[i] = 1\n   elif op is CATEGORY:\n   \n    return charset \n except IndexError:\n \n  return _optimize_unicode(charset, fixup)\n  \n i = p = n = 0\n runs = []\n runsappend = runs.append\n for c in charmap:\n  if c:\n   if n == 0:\n    p = i\n   n = n + 1\n  elif n:\n   runsappend((p, n))\n   n = 0\n  i = i + 1\n if n:\n  runsappend((p, n))\n if len(runs) <= 2:\n \n  for p, n in runs:\n   if n == 1:\n    outappend((LITERAL, p))\n   else:\n    outappend((RANGE, (p, p+n-1)))\n  if len(out) < len(charset):\n   return out\n else:\n \n  data = _mk_bitmap(charmap)\n  outappend((CHARSET, data))\n  return out\n return charset\n \ndef _mk_bitmap(bits):\n data = []\n dataappend = data.append\n if _sre.CODESIZE == 2:\n  start = (1, 0)\n else:\n  start = (1, 0)\n m, v = start\n for c in bits:\n  if c:\n   v = v + m\n  m = m + m\n  if m > MAXCODE:\n   dataappend(v)\n   m, v = start\n return data\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \ndef _optimize_unicode(charset, fixup):\n try:\n  import array\n except ImportError:\n  return charset\n charmap = [0]*65536\n negate = 0\n try:\n  for op, av in charset:\n   if op is NEGATE:\n    negate = 1\n   elif op is LITERAL:\n    charmap[fixup(av)] = 1\n   elif op is RANGE:\n    for i in range(fixup(av[0]), fixup(av[1])+1):\n     charmap[i] = 1\n   elif op is CATEGORY:\n   \n    return charset \n except IndexError:\n \n  return charset\n if negate:\n  if sys.maxunicode != 65535:\n  \n  \n  \n   return charset\n  for i in range(65536):\n   charmap[i] = not charmap[i]\n comps = {}\n mapping = [0]*256\n block = 0\n data = []\n for i in range(256):\n  chunk = tuple(charmap[i*256:(i+1)*256])\n  new = comps.setdefault(chunk, block)\n  mapping[i] = new\n  if new == block:\n   block = block + 1\n   data = data + _mk_bitmap(chunk)\n header = [block]\n if _sre.CODESIZE == 2:\n  code = 'H'\n else:\n  code = 'I'\n  \n mapping = array.array('b', mapping).tobytes()\n \n mapping = array.array(code, mapping)\n assert mapping.itemsize == _sre.CODESIZE\n assert len(mapping) * mapping.itemsize == 256\n header = header + mapping.tolist()\n data[0:0] = header\n return [(BIGCHARSET, data)]\n \ndef _simple(av):\n\n lo, hi = av[2].getwidth()\n if lo == 0 and hi == MAXREPEAT:\n  raise error(\"nothing to repeat\")\n return lo == hi == 1 and av[2][0][0] != SUBPATTERN\n \ndef _compile_info(code, pattern, flags):\n\n\n\n lo, hi = pattern.getwidth()\n \n if lo == 0:\n  return \n  \n prefix = []\n prefixappend = prefix.append\n prefix_skip = 0\n charset = [] \n charsetappend = charset.append\n if not (flags & SRE_FLAG_IGNORECASE):\n \n  for op, av in pattern.data:\n  \n   if op is LITERAL:\n    if len(prefix) == prefix_skip:\n     prefix_skip = prefix_skip + 1\n    prefixappend(av)\n   elif op is SUBPATTERN and len(av[1]) == 1:\n    op, av = av[1][0]\n    if op is LITERAL:\n     prefixappend(av)\n    else:\n     break\n   else:\n    break\n    \n  if not prefix and pattern.data:\n   op, av = pattern.data[0]\n   if op is SUBPATTERN and av[1]:\n    op, av = av[1][0]\n    if op is LITERAL:\n     charsetappend((op, av))\n    elif op is BRANCH:\n     c = []\n     cappend = c.append\n     for p in av[1]:\n      if not p:\n       break\n      op, av = p[0]\n      if op is LITERAL:\n       cappend((op, av))\n      else:\n       break\n     else:\n      charset = c\n   elif op is BRANCH:\n    c = []\n    cappend = c.append\n    for p in av[1]:\n     if not p:\n      break\n     op, av = p[0]\n     if op is LITERAL:\n      cappend((op, av))\n     else:\n      break\n    else:\n     charset = c\n   elif op is IN:\n    charset = av\n    \n    \n    \n    \n    \n    \n    \n emit = code.append\n emit(OPCODES[INFO])\n skip = len(code); emit(0)\n \n mask = 0\n if prefix:\n  mask = SRE_INFO_PREFIX\n  if len(prefix) == prefix_skip == len(pattern.data):\n   mask = mask + SRE_INFO_LITERAL\n elif charset:\n  mask = mask + SRE_INFO_CHARSET\n emit(mask)\n \n if lo < MAXCODE:\n  emit(lo)\n else:\n  emit(MAXCODE)\n  prefix = prefix[:MAXCODE]\n if hi < MAXCODE:\n  emit(hi)\n else:\n  emit(0)\n  \n  \n if prefix:\n  emit(len(prefix)) \n  emit(prefix_skip) \n  code.extend(prefix)\n  \n  table = [-1] + ([0]*len(prefix))\n  for i in range(len(prefix)):\n   table[i+1] = table[i]+1\n   while table[i+1] > 0 and prefix[i] != prefix[table[i+1]-1]:\n    table[i+1] = table[table[i+1]-1]+1\n  code.extend(table[1:]) \n elif charset:\n  _compile_charset(charset, flags, code)\n code[skip] = len(code) - skip\n \ndef isstring(obj):\n return isinstance(obj, (str, bytes))\n \ndef _code(p, flags):\n\n flags = p.pattern.flags | flags\n code = []\n \n \n _compile_info(code, p, flags)\n \n \n _compile(code, p.data, flags)\n \n code.append(OPCODES[SUCCESS])\n \n return code\n \ndef compile(p, flags=0):\n\n\n\n if isstring(p):\n  pattern = p\n  p = sre_parse.parse(p, flags)\n else:\n  pattern = None\n  \n  \n code = _code(p, flags)\n \n \n \n \n \n if p.pattern.groups > 100:\n  raise AssertionError(\n  \"sorry, but this version only supports 100 named groups\"\n  )\n  \n  \n groupindex = p.pattern.groupdict\n indexgroup = [None] * p.pattern.groups\n for k, i in groupindex.items():\n  indexgroup[i] = k\n  \n return _sre.compile(\n pattern, flags | p.pattern.flags, code,\n p.pattern.groups-1,\n groupindex, indexgroup\n )\n"], "xml.sax": [".py", "\"\"\n\nfrom .xmlreader import InputSource\nfrom .handler import ContentHandler, ErrorHandler\nfrom ._exceptions import SAXException, SAXNotRecognizedException, SAXParseException, SAXNotSupportedException, SAXReaderNotAvailable\n\n\ndef parse(source, handler, errorHandler=ErrorHandler()):\n parser = make_parser()\n parser.setContentHandler(handler)\n parser.setErrorHandler(errorHandler)\n parser.parse(source)\n \ndef parseString(string, handler, errorHandler=ErrorHandler()):\n from io import BytesIO\n \n if errorHandler is None:\n  errorHandler = ErrorHandler()\n parser = make_parser()\n parser.setContentHandler(handler)\n parser.setErrorHandler(errorHandler)\n \n inpsrc = InputSource()\n inpsrc.setByteStream(BytesIO(string))\n parser.parse(inpsrc)\n \n \n \n \ndefault_parser_list = [\"xml.sax.expatreader\"]\n\n\n_false = 0\nif _false:\n import xml.sax.expatreader\n \nimport os, sys\n\n\ndel os\n\n_key = \"python.xml.sax.parser\"\nif sys.platform[:4] == \"java\" and sys.registry.containsKey(_key):\n default_parser_list = sys.registry.getProperty(_key).split(\",\")\n \n \ndef make_parser(parser_list = []):\n \"\"\n \n for parser_name in parser_list + default_parser_list:\n  try:\n   return _create_parser(parser_name)\n  except ImportError as e:\n   import sys\n   if parser_name in sys.modules:\n   \n   \n    raise\n  except SAXReaderNotAvailable:\n  \n  \n   pass\n   \n raise SAXReaderNotAvailable(\"No parsers found\", None)\n \n \n \nif sys.platform[ : 4] == \"java\":\n def _create_parser(parser_name):\n  from org.python.core import imp\n  drv_module = imp.importName(parser_name, 0, globals())\n  return drv_module.create_parser()\n  \nelse:\n def _create_parser(parser_name):\n  drv_module = __import__(parser_name,{},{},['create_parser'])\n  return drv_module.create_parser()\n  \ndel sys\n", 1], "_random": [".py", "import _os\nfrom os import urandom as _urandom\nclass Random:\n \"\"\n \n \n \n \n \n \n VERSION = 3 \n \n def __init__(self, x=None):\n  \"\"\n  \n  self._state=x\n  \n def seed(self, a=None, version=2):\n  \"\"\n  \n  self._state=a\n  self.gauss_next = None\n  \n def getstate(self):\n  \"\"\n  return self._state\n  \n def setstate(self, state):\n  \"\"\n  self._state=state\n  \n def random(self):\n  \"\"\n  return _os.random()\n  \n def getrandbits(self, k):\n  \"\"\n  if k <= 0:\n   raise ValueError('number of bits must be greater than zero')\n  if k != int(k):\n   raise TypeError('number of bits should be an integer')\n  numbytes = (k + 7) // 8 \n  x = int.from_bytes(_urandom(numbytes), 'big')\n  return x >> (numbytes * 8 - k) \n"], "browser.timer": [".py", "from _timer import *"], "site": [".py", "import sys\n"], "unittest.test.test_result": [".py", "import io\nimport sys\nimport textwrap\n\nfrom test import support\n\nimport traceback\nimport unittest\n\n\nclass Test_TestResult(unittest.TestCase):\n\n\n\n\n\n\n\n\n\n def test_init(self):\n  result = unittest.TestResult()\n  \n  self.assertTrue(result.wasSuccessful())\n  self.assertEqual(len(result.errors), 0)\n  self.assertEqual(len(result.failures), 0)\n  self.assertEqual(result.testsRun, 0)\n  self.assertEqual(result.shouldStop, False)\n  self.assertIsNone(result._stdout_buffer)\n  self.assertIsNone(result._stderr_buffer)\n  \n  \n  \n  \n def test_stop(self):\n  result = unittest.TestResult()\n  \n  result.stop()\n  \n  self.assertEqual(result.shouldStop, True)\n  \n  \n  \n def test_startTest(self):\n  class Foo(unittest.TestCase):\n   def test_1(self):\n    pass\n    \n  test = Foo('test_1')\n  \n  result = unittest.TestResult()\n  \n  result.startTest(test)\n  \n  self.assertTrue(result.wasSuccessful())\n  self.assertEqual(len(result.errors), 0)\n  self.assertEqual(len(result.failures), 0)\n  self.assertEqual(result.testsRun, 1)\n  self.assertEqual(result.shouldStop, False)\n  \n  result.stopTest(test)\n  \n  \n  \n def test_stopTest(self):\n  class Foo(unittest.TestCase):\n   def test_1(self):\n    pass\n    \n  test = Foo('test_1')\n  \n  result = unittest.TestResult()\n  \n  result.startTest(test)\n  \n  self.assertTrue(result.wasSuccessful())\n  self.assertEqual(len(result.errors), 0)\n  self.assertEqual(len(result.failures), 0)\n  self.assertEqual(result.testsRun, 1)\n  self.assertEqual(result.shouldStop, False)\n  \n  result.stopTest(test)\n  \n  \n  self.assertTrue(result.wasSuccessful())\n  self.assertEqual(len(result.errors), 0)\n  self.assertEqual(len(result.failures), 0)\n  self.assertEqual(result.testsRun, 1)\n  self.assertEqual(result.shouldStop, False)\n  \n  \n def test_startTestRun_stopTestRun(self):\n  result = unittest.TestResult()\n  result.startTestRun()\n  result.stopTestRun()\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_addSuccess(self):\n  class Foo(unittest.TestCase):\n   def test_1(self):\n    pass\n    \n  test = Foo('test_1')\n  \n  result = unittest.TestResult()\n  \n  result.startTest(test)\n  result.addSuccess(test)\n  result.stopTest(test)\n  \n  self.assertTrue(result.wasSuccessful())\n  self.assertEqual(len(result.errors), 0)\n  self.assertEqual(len(result.failures), 0)\n  self.assertEqual(result.testsRun, 1)\n  self.assertEqual(result.shouldStop, False)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_addFailure(self):\n  class Foo(unittest.TestCase):\n   def test_1(self):\n    pass\n    \n  test = Foo('test_1')\n  try:\n   test.fail(\"foo\")\n  except:\n   exc_info_tuple = sys.exc_info()\n   \n  result = unittest.TestResult()\n  \n  result.startTest(test)\n  result.addFailure(test, exc_info_tuple)\n  result.stopTest(test)\n  \n  self.assertFalse(result.wasSuccessful())\n  self.assertEqual(len(result.errors), 0)\n  self.assertEqual(len(result.failures), 1)\n  self.assertEqual(result.testsRun, 1)\n  self.assertEqual(result.shouldStop, False)\n  \n  test_case, formatted_exc = result.failures[0]\n  self.assertTrue(test_case is test)\n  self.assertIsInstance(formatted_exc, str)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_addError(self):\n  class Foo(unittest.TestCase):\n   def test_1(self):\n    pass\n    \n  test = Foo('test_1')\n  try:\n   raise TypeError()\n  except:\n   exc_info_tuple = sys.exc_info()\n   \n  result = unittest.TestResult()\n  \n  result.startTest(test)\n  result.addError(test, exc_info_tuple)\n  result.stopTest(test)\n  \n  self.assertFalse(result.wasSuccessful())\n  self.assertEqual(len(result.errors), 1)\n  self.assertEqual(len(result.failures), 0)\n  self.assertEqual(result.testsRun, 1)\n  self.assertEqual(result.shouldStop, False)\n  \n  test_case, formatted_exc = result.errors[0]\n  self.assertTrue(test_case is test)\n  self.assertIsInstance(formatted_exc, str)\n  \n def testGetDescriptionWithoutDocstring(self):\n  result = unittest.TextTestResult(None, True, 1)\n  self.assertEqual(\n  result.getDescription(self),\n  'testGetDescriptionWithoutDocstring (' + __name__ +\n  '.Test_TestResult)')\n  \n @unittest.skipIf(sys.flags.optimize >= 2,\n \"Docstrings are omitted with -O2 and above\")\n def testGetDescriptionWithOneLineDocstring(self):\n  \"\"\n  result = unittest.TextTestResult(None, True, 1)\n  self.assertEqual(\n  result.getDescription(self),\n  ('testGetDescriptionWithOneLineDocstring '\n  '(' + __name__ + '.Test_TestResult)\\n'\n  'Tests getDescription() for a method with a docstring.'))\n  \n @unittest.skipIf(sys.flags.optimize >= 2,\n \"Docstrings are omitted with -O2 and above\")\n def testGetDescriptionWithMultiLineDocstring(self):\n  \"\"\n  result = unittest.TextTestResult(None, True, 1)\n  self.assertEqual(\n  result.getDescription(self),\n  ('testGetDescriptionWithMultiLineDocstring '\n  '(' + __name__ + '.Test_TestResult)\\n'\n  'Tests getDescription() for a method with a longer '\n  'docstring.'))\n  \n def testStackFrameTrimming(self):\n  class Frame(object):\n   class tb_frame(object):\n    f_globals = {}\n  result = unittest.TestResult()\n  self.assertFalse(result._is_relevant_tb_level(Frame))\n  \n  Frame.tb_frame.f_globals['__unittest'] = True\n  self.assertTrue(result._is_relevant_tb_level(Frame))\n  \n def testFailFast(self):\n  result = unittest.TestResult()\n  result._exc_info_to_string = lambda *_: ''\n  result.failfast = True\n  result.addError(None, None)\n  self.assertTrue(result.shouldStop)\n  \n  result = unittest.TestResult()\n  result._exc_info_to_string = lambda *_: ''\n  result.failfast = True\n  result.addFailure(None, None)\n  self.assertTrue(result.shouldStop)\n  \n  result = unittest.TestResult()\n  result._exc_info_to_string = lambda *_: ''\n  result.failfast = True\n  result.addUnexpectedSuccess(None)\n  self.assertTrue(result.shouldStop)\n  \n def testFailFastSetByRunner(self):\n  runner = unittest.TextTestRunner(stream=io.StringIO(), failfast=True)\n  def test(result):\n   self.assertTrue(result.failfast)\n  result = runner.run(test)\n  \n  \nclassDict = dict(unittest.TestResult.__dict__)\nfor m in ('addSkip', 'addExpectedFailure', 'addUnexpectedSuccess',\n'__init__'):\n del classDict[m]\n \ndef __init__(self, stream=None, descriptions=None, verbosity=None):\n self.failures = []\n self.errors = []\n self.testsRun = 0\n self.shouldStop = False\n self.buffer = False\n \nclassDict['__init__'] = __init__\nOldResult = type('OldResult', (object,), classDict)\n\nclass Test_OldTestResult(unittest.TestCase):\n\n def assertOldResultWarning(self, test, failures):\n  with support.check_warnings((\"TestResult has no add.+ method,\",\n  RuntimeWarning)):\n   result = OldResult()\n   test.run(result)\n   self.assertEqual(len(result.failures), failures)\n   \n def testOldTestResult(self):\n  class Test(unittest.TestCase):\n   def testSkip(self):\n    self.skipTest('foobar')\n   @unittest.expectedFailure\n   def testExpectedFail(self):\n    raise TypeError\n   @unittest.expectedFailure\n   def testUnexpectedSuccess(self):\n    pass\n    \n  for test_name, should_pass in (('testSkip', True),\n  ('testExpectedFail', True),\n  ('testUnexpectedSuccess', False)):\n   test = Test(test_name)\n   self.assertOldResultWarning(test, int(not should_pass))\n   \n def testOldTestTesultSetup(self):\n  class Test(unittest.TestCase):\n   def setUp(self):\n    self.skipTest('no reason')\n   def testFoo(self):\n    pass\n  self.assertOldResultWarning(Test('testFoo'), 0)\n  \n def testOldTestResultClass(self):\n  @unittest.skip('no reason')\n  class Test(unittest.TestCase):\n   def testFoo(self):\n    pass\n  self.assertOldResultWarning(Test('testFoo'), 0)\n  \n def testOldResultWithRunner(self):\n  class Test(unittest.TestCase):\n   def testFoo(self):\n    pass\n  runner = unittest.TextTestRunner(resultclass=OldResult,\n  stream=io.StringIO())\n  \n  \n  runner.run(Test('testFoo'))\n  \n  \nclass MockTraceback(object):\n @staticmethod\n def format_exception(*_):\n  return ['A traceback']\n  \ndef restore_traceback():\n unittest.result.traceback = traceback\n \n \nclass TestOutputBuffering(unittest.TestCase):\n\n def setUp(self):\n  self._real_out = sys.stdout\n  self._real_err = sys.stderr\n  \n def tearDown(self):\n  sys.stdout = self._real_out\n  sys.stderr = self._real_err\n  \n def testBufferOutputOff(self):\n  real_out = self._real_out\n  real_err = self._real_err\n  \n  result = unittest.TestResult()\n  self.assertFalse(result.buffer)\n  \n  self.assertIs(real_out, sys.stdout)\n  self.assertIs(real_err, sys.stderr)\n  \n  result.startTest(self)\n  \n  self.assertIs(real_out, sys.stdout)\n  self.assertIs(real_err, sys.stderr)\n  \n def testBufferOutputStartTestAddSuccess(self):\n  real_out = self._real_out\n  real_err = self._real_err\n  \n  result = unittest.TestResult()\n  self.assertFalse(result.buffer)\n  \n  result.buffer = True\n  \n  self.assertIs(real_out, sys.stdout)\n  self.assertIs(real_err, sys.stderr)\n  \n  result.startTest(self)\n  \n  self.assertIsNot(real_out, sys.stdout)\n  self.assertIsNot(real_err, sys.stderr)\n  self.assertIsInstance(sys.stdout, io.StringIO)\n  self.assertIsInstance(sys.stderr, io.StringIO)\n  self.assertIsNot(sys.stdout, sys.stderr)\n  \n  out_stream = sys.stdout\n  err_stream = sys.stderr\n  \n  result._original_stdout = io.StringIO()\n  result._original_stderr = io.StringIO()\n  \n  print('foo')\n  print('bar', file=sys.stderr)\n  \n  self.assertEqual(out_stream.getvalue(), 'foo\\n')\n  self.assertEqual(err_stream.getvalue(), 'bar\\n')\n  \n  self.assertEqual(result._original_stdout.getvalue(), '')\n  self.assertEqual(result._original_stderr.getvalue(), '')\n  \n  result.addSuccess(self)\n  result.stopTest(self)\n  \n  self.assertIs(sys.stdout, result._original_stdout)\n  self.assertIs(sys.stderr, result._original_stderr)\n  \n  self.assertEqual(result._original_stdout.getvalue(), '')\n  self.assertEqual(result._original_stderr.getvalue(), '')\n  \n  self.assertEqual(out_stream.getvalue(), '')\n  self.assertEqual(err_stream.getvalue(), '')\n  \n  \n def getStartedResult(self):\n  result = unittest.TestResult()\n  result.buffer = True\n  result.startTest(self)\n  return result\n  \n def testBufferOutputAddErrorOrFailure(self):\n  unittest.result.traceback = MockTraceback\n  self.addCleanup(restore_traceback)\n  \n  for message_attr, add_attr, include_error in [\n  ('errors', 'addError', True),\n  ('failures', 'addFailure', False),\n  ('errors', 'addError', True),\n  ('failures', 'addFailure', False)\n  ]:\n   result = self.getStartedResult()\n   buffered_out = sys.stdout\n   buffered_err = sys.stderr\n   result._original_stdout = io.StringIO()\n   result._original_stderr = io.StringIO()\n   \n   print('foo', file=sys.stdout)\n   if include_error:\n    print('bar', file=sys.stderr)\n    \n    \n   addFunction = getattr(result, add_attr)\n   addFunction(self, (None, None, None))\n   result.stopTest(self)\n   \n   result_list = getattr(result, message_attr)\n   self.assertEqual(len(result_list), 1)\n   \n   test, message = result_list[0]\n   expectedOutMessage = textwrap.dedent(\"\"\"\n                Stdout:\n                foo\n            \"\"\"   )\n   expectedErrMessage = ''\n   if include_error:\n    expectedErrMessage = textwrap.dedent(\"\"\"\n                Stderr:\n                bar\n            \"\"\"    )\n    \n   expectedFullMessage = 'A traceback%s%s' % (expectedOutMessage, expectedErrMessage)\n   \n   self.assertIs(test, self)\n   self.assertEqual(result._original_stdout.getvalue(), expectedOutMessage)\n   self.assertEqual(result._original_stderr.getvalue(), expectedErrMessage)\n   self.assertMultiLineEqual(message, expectedFullMessage)\n   \n def testBufferSetupClass(self):\n  result = unittest.TestResult()\n  result.buffer = True\n  \n  class Foo(unittest.TestCase):\n   @classmethod\n   def setUpClass(cls):\n    1/0\n   def test_foo(self):\n    pass\n  suite = unittest.TestSuite([Foo('test_foo')])\n  suite(result)\n  self.assertEqual(len(result.errors), 1)\n  \n def testBufferTearDownClass(self):\n  result = unittest.TestResult()\n  result.buffer = True\n  \n  class Foo(unittest.TestCase):\n   @classmethod\n   def tearDownClass(cls):\n    1/0\n   def test_foo(self):\n    pass\n  suite = unittest.TestSuite([Foo('test_foo')])\n  suite(result)\n  self.assertEqual(len(result.errors), 1)\n  \n def testBufferSetUpModule(self):\n  result = unittest.TestResult()\n  result.buffer = True\n  \n  class Foo(unittest.TestCase):\n   def test_foo(self):\n    pass\n  class Module(object):\n   @staticmethod\n   def setUpModule():\n    1/0\n    \n  Foo.__module__ = 'Module'\n  sys.modules['Module'] = Module\n  self.addCleanup(sys.modules.pop, 'Module')\n  suite = unittest.TestSuite([Foo('test_foo')])\n  suite(result)\n  self.assertEqual(len(result.errors), 1)\n  \n def testBufferTearDownModule(self):\n  result = unittest.TestResult()\n  result.buffer = True\n  \n  class Foo(unittest.TestCase):\n   def test_foo(self):\n    pass\n  class Module(object):\n   @staticmethod\n   def tearDownModule():\n    1/0\n    \n  Foo.__module__ = 'Module'\n  sys.modules['Module'] = Module\n  self.addCleanup(sys.modules.pop, 'Module')\n  suite = unittest.TestSuite([Foo('test_foo')])\n  suite(result)\n  self.assertEqual(len(result.errors), 1)\n  \n  \nif __name__ == '__main__':\n unittest.main()\n"], "test.regrtest": [".py", "\n\n\"\"\n\n\nimport importlib\n\nimport builtins\nimport faulthandler\nimport getopt\nimport io\nimport json\nimport logging\nimport os\nimport platform\nimport random\nimport re\nimport shutil\nimport signal\nimport sys\nimport sysconfig\nimport tempfile\nimport time\nimport traceback\nimport unittest\nimport warnings\nfrom inspect import isabstract\n\ntry:\n import threading\nexcept ImportError:\n threading = None\ntry:\n import multiprocessing.process\nexcept ImportError:\n multiprocessing = None\n \n \n \n \n \n \n \n \n \n \n \n \nfor module in sys.modules.values():\n if hasattr(module, '__path__'):\n  module.__path__ = [os.path.abspath(path) for path in module.__path__]\n if hasattr(module, '__file__'):\n  module.__file__ = os.path.abspath(module.__file__)\n  \n  \n  \n  \n  \n  \n  \n  \nif sys.platform == 'darwin':\n try:\n  import resource\n except ImportError:\n  pass\n else:\n  soft, hard = resource.getrlimit(resource.RLIMIT_STACK)\n  newsoft = min(hard, max(soft, 1024*2048))\n  resource.setrlimit(resource.RLIMIT_STACK, (newsoft, hard))\n  \n  \nPASSED = 1\nFAILED = 0\nENV_CHANGED = -1\nSKIPPED = -2\nRESOURCE_DENIED = -3\nINTERRUPTED = -4\nCHILD_ERROR = -5 \n\nfrom test import support\n\nRESOURCE_NAMES = ('audio', 'curses', 'largefile', 'network',\n'decimal', 'cpu', 'subprocess', 'urlfetch', 'gui')\n\nTEMPDIR = os.path.abspath(tempfile.gettempdir())\n\ndef usage(msg):\n print(msg, file=sys.stderr)\n print(\"Use --help for usage\", file=sys.stderr)\n sys.exit(2)\n \n \ndef main(tests=None, testdir=None, verbose=0, quiet=False,\nexclude=False, single=0, randomize=False, fromfile=None,\nfindleaks=False, use_resources=None, trace=False, coverdir='coverage',\nrunleaks=False, huntrleaks=False, verbose2=False, print_slow=False,\nrandom_seed=None, use_mp=None, verbose3=False, forever=False,\nheader=False, failfast=False, match_tests=None):\n \"\"\n \n \n faulthandler.enable(all_threads=True)\n \n \n signals = []\n if hasattr(signal, 'SIGALRM'):\n  signals.append(signal.SIGALRM)\n if hasattr(signal, 'SIGUSR1'):\n  signals.append(signal.SIGUSR1)\n for signum in signals:\n  faulthandler.register(signum, chain=True)\n  \n replace_stdout()\n \n support.record_original_stdout(sys.stdout)\n try:\n  opts, args = getopt.getopt(sys.argv[1:], 'hvqxsoS:rf:lu:t:TD:NLR:FdwWM:nj:Gm:',\n  ['help', 'verbose', 'verbose2', 'verbose3', 'quiet',\n  'exclude', 'single', 'slow', 'randomize', 'fromfile=', 'findleaks',\n  'use=', 'threshold=', 'coverdir=', 'nocoverdir',\n  'runleaks', 'huntrleaks=', 'memlimit=', 'randseed=',\n  'multiprocess=', 'coverage', 'slaveargs=', 'forever', 'debug',\n  'start=', 'nowindows', 'header', 'testdir=', 'timeout=', 'wait',\n  'failfast', 'match=', 'next='])\n except getopt.error as msg:\n  usage(msg)\n  \n  \n if random_seed is None:\n  random_seed = random.randrange(10000000)\n if use_resources is None:\n  use_resources = []\n debug = False\n start = None\n timeout = None\n for o, a in opts:\n  if o in ('-h', '--help'):\n   print(__doc__)\n   return\n  elif o in ('-v', '--verbose'):\n   verbose += 1\n  elif o in ('-w', '--verbose2'):\n   verbose2 = True\n  elif o in ('-d', '--debug'):\n   debug = True\n  elif o in ('-W', '--verbose3'):\n   verbose3 = True\n  elif o in ('-G', '--failfast'):\n   failfast = True\n  elif o in ('-q', '--quiet'):\n   quiet = True;\n   verbose = 0\n  elif o in ('-x', '--exclude'):\n   exclude = True\n  elif o in ('-S', '--start'):\n   start = a\n  elif o in ('-s', '--single'):\n   single = 1\n  elif o == '--next':\n   single = int(a)\n  elif o in ('-o', '--slow'):\n   print_slow = True\n  elif o in ('-r', '--randomize'):\n   randomize = True\n  elif o == '--randseed':\n   random_seed = int(a)\n  elif o in ('-f', '--fromfile'):\n   fromfile = a\n  elif o in ('-m', '--match'):\n   match_tests = a\n  elif o in ('-l', '--findleaks'):\n   findleaks = True\n  elif o in ('-L', '--runleaks'):\n   runleaks = True\n  elif o in ('-t', '--threshold'):\n   import gc\n   gc.set_threshold(int(a))\n  elif o in ('-T', '--coverage'):\n   trace = True\n  elif o in ('-D', '--coverdir'):\n  \n  \n   coverdir = os.path.join(support.SAVEDCWD, a)\n  elif o in ('-N', '--nocoverdir'):\n   coverdir = None\n  elif o in ('-R', '--huntrleaks'):\n   huntrleaks = a.split(':')\n   if len(huntrleaks) not in (2, 3):\n    print(a, huntrleaks)\n    usage('-R takes 2 or 3 colon-separated arguments')\n   if not huntrleaks[0]:\n    huntrleaks[0] = 5\n   else:\n    huntrleaks[0] = int(huntrleaks[0])\n   if not huntrleaks[1]:\n    huntrleaks[1] = 4\n   else:\n    huntrleaks[1] = int(huntrleaks[1])\n   if len(huntrleaks) == 2 or not huntrleaks[2]:\n    huntrleaks[2:] = [\"reflog.txt\"]\n    \n    \n   warm_caches()\n  elif o in ('-M', '--memlimit'):\n   support.set_memlimit(a)\n  elif o in ('-u', '--use'):\n   u = [x.lower() for x in a.split(',')]\n   for r in u:\n    if r == 'all':\n     use_resources[:] = RESOURCE_NAMES\n     continue\n    if r == 'none':\n     del use_resources[:]\n     continue\n    remove = False\n    if r[0] == '-':\n     remove = True\n     r = r[1:]\n    if r not in RESOURCE_NAMES:\n     usage('Invalid -u/--use option: ' + a)\n    if remove:\n     if r in use_resources:\n      use_resources.remove(r)\n    elif r not in use_resources:\n     use_resources.append(r)\n  elif o in ('-n', '--nowindows'):\n   import msvcrt\n   msvcrt.SetErrorMode(msvcrt.SEM_FAILCRITICALERRORS|\n   msvcrt.SEM_NOALIGNMENTFAULTEXCEPT|\n   msvcrt.SEM_NOGPFAULTERRORBOX|\n   msvcrt.SEM_NOOPENFILEERRORBOX)\n   try:\n    msvcrt.CrtSetReportMode\n   except AttributeError:\n   \n    pass\n   else:\n    for m in [msvcrt.CRT_WARN, msvcrt.CRT_ERROR, msvcrt.CRT_ASSERT]:\n     msvcrt.CrtSetReportMode(m, msvcrt.CRTDBG_MODE_FILE)\n     msvcrt.CrtSetReportFile(m, msvcrt.CRTDBG_FILE_STDERR)\n  elif o in ('-F', '--forever'):\n   forever = True\n  elif o in ('-j', '--multiprocess'):\n   use_mp = int(a)\n   if use_mp <= 0:\n    try:\n     import multiprocessing\n     \n     use_mp = 2 + multiprocessing.cpu_count()\n    except (ImportError, NotImplementedError):\n     use_mp = 3\n   if use_mp == 1:\n    use_mp = None\n  elif o == '--header':\n   header = True\n  elif o == '--slaveargs':\n   args, kwargs = json.loads(a)\n   try:\n    result = runtest(*args, **kwargs)\n   except KeyboardInterrupt:\n    result = INTERRUPTED, ''\n   except BaseException as e:\n    traceback.print_exc()\n    result = CHILD_ERROR, str(e)\n   sys.stdout.flush()\n   print() \n   print(json.dumps(result))\n   sys.exit(0)\n  elif o == '--testdir':\n  \n  \n   testdir = os.path.join(support.SAVEDCWD, a)\n  elif o == '--timeout':\n   if hasattr(faulthandler, 'dump_tracebacks_later'):\n    timeout = float(a)\n    if timeout <= 0:\n     timeout = None\n   else:\n    print(\"Warning: The timeout option requires \"\n    \"faulthandler.dump_tracebacks_later\")\n    timeout = None\n  elif o == '--wait':\n   input(\"Press any key to continue...\")\n  else:\n   print((\"No handler for option {}.  Please report this as a bug \"\n   \"at http://bugs.python.org.\").format(o), file=sys.stderr)\n   sys.exit(1)\n if single and fromfile:\n  usage(\"-s and -f don't go together!\")\n if use_mp and trace:\n  usage(\"-T and -j don't go together!\")\n if use_mp and findleaks:\n  usage(\"-l and -j don't go together!\")\n if use_mp and support.max_memuse:\n  usage(\"-M and -j don't go together!\")\n if failfast and not (verbose or verbose3):\n  usage(\"-G/--failfast needs either -v or -W\")\n  \n good = []\n bad = []\n skipped = []\n resource_denieds = []\n environment_changed = []\n interrupted = False\n \n if findleaks:\n  try:\n   import gc\n  except ImportError:\n   print('No GC available, disabling findleaks.')\n   findleaks = False\n  else:\n  \n  \n  \n  \n   found_garbage = []\n   \n if single:\n  filename = os.path.join(TEMPDIR, 'pynexttest')\n  try:\n   fp = open(filename, 'r')\n   next_test = fp.read().strip()\n   tests = [next_test]\n   fp.close()\n  except IOError:\n   pass\n   \n if fromfile:\n  tests = []\n  fp = open(os.path.join(support.SAVEDCWD, fromfile))\n  count_pat = re.compile(r'\\[\\s*\\d+/\\s*\\d+\\]')\n  for line in fp:\n   line = count_pat.sub('', line)\n   guts = line.split() \n   if guts and not guts[0].startswith('#'):\n    tests.extend(guts)\n  fp.close()\n  \n  \n removepy(args)\n removepy(tests)\n \n stdtests = STDTESTS[:]\n nottests = NOTTESTS.copy()\n if exclude:\n  for arg in args:\n   if arg in stdtests:\n    stdtests.remove(arg)\n   nottests.add(arg)\n  args = []\n  \n  \n if verbose or header or not (quiet or single != 1 or tests or args):\n \n  print(\"==\", platform.python_implementation(), *sys.version.split())\n  print(\"==  \", platform.platform(aliased=True),\n  \"%s-endian\" % sys.byteorder)\n  print(\"==  \", os.getcwd())\n  print(\"Testing with flags:\", sys.flags)\n  \n  \n  \n if testdir:\n  alltests = findtests(testdir, list(), set())\n else:\n  alltests = findtests(testdir, stdtests, nottests)\n  \n selected = tests or args or alltests\n if single:\n  first_selected = selected[0]\n  index_selected = alltests.index(first_selected)\n  if index_selected + single > len(alltests):\n   single = len(alltests) - index_selected\n  selected = alltests[index_selected:index_selected+single]\n  try:\n   next_single_test = alltests[index_selected+single]\n  except IndexError:\n   next_single_test = None\n   \n if start:\n  try:\n   del selected[:selected.index(start)]\n  except ValueError:\n   print(\"Couldn't find starting test (%s), using all tests\" % start)\n if randomize:\n  random.seed(random_seed)\n  print(\"Using random seed\", random_seed)\n  random.shuffle(selected)\n if trace:\n  import trace, tempfile\n  tracer = trace.Trace(ignoredirs=[sys.base_prefix, sys.base_exec_prefix,\n  tempfile.gettempdir()],\n  trace=False, count=True)\n  \n test_times = []\n support.verbose = verbose \n support.use_resources = use_resources\n save_modules = sys.modules.keys()\n \n def accumulate_result(test, result):\n  ok, test_time = result\n  test_times.append((test_time, test))\n  if ok == PASSED:\n   good.append(test)\n  elif ok == FAILED:\n   bad.append(test)\n  elif ok == ENV_CHANGED:\n   environment_changed.append(test)\n  elif ok == SKIPPED:\n   skipped.append(test)\n  elif ok == RESOURCE_DENIED:\n   skipped.append(test)\n   resource_denieds.append(test)\n   \n if forever:\n  def test_forever(tests=list(selected)):\n   while True:\n    for test in tests:\n     yield test\n     if bad:\n      return\n  tests = test_forever()\n  test_count = ''\n  test_count_width = 3\n else:\n  tests = iter(selected)\n  test_count = '/{}'.format(len(selected))\n  test_count_width = len(test_count) - 1\n  \n if use_mp:\n  try:\n   from threading import Thread\n  except ImportError:\n   print(\"Multiprocess option requires thread support\")\n   sys.exit(2)\n  from queue import Queue\n  from subprocess import Popen, PIPE\n  debug_output_pat = re.compile(r\"\\[\\d+ refs\\]$\")\n  output = Queue()\n  pending = MultiprocessTests(tests)\n  opt_args = support.args_from_interpreter_flags()\n  base_cmd = [sys.executable] + opt_args + ['-m', 'test.regrtest']\n  def work():\n  \n   try:\n    while True:\n     try:\n      test = next(pending)\n     except StopIteration:\n      output.put((None, None, None, None))\n      return\n     args_tuple = (\n     (test, verbose, quiet),\n     dict(huntrleaks=huntrleaks, use_resources=use_resources,\n     debug=debug, output_on_failure=verbose3,\n     timeout=timeout, failfast=failfast,\n     match_tests=match_tests)\n     )\n     \n     \n     \n     \n     popen = Popen(base_cmd + ['--slaveargs', json.dumps(args_tuple)],\n     stdout=PIPE, stderr=PIPE,\n     universal_newlines=True,\n     close_fds=(os.name != 'nt'),\n     cwd=support.SAVEDCWD)\n     stdout, stderr = popen.communicate()\n     retcode = popen.wait()\n     \n     \n     stderr = debug_output_pat.sub(\"\", stderr)\n     stdout, _, result = stdout.strip().rpartition(\"\\n\")\n     if retcode != 0:\n      result = (CHILD_ERROR, \"Exit code %s\" % retcode)\n      output.put((test, stdout.rstrip(), stderr.rstrip(), result))\n      return\n     if not result:\n      output.put((None, None, None, None))\n      return\n     result = json.loads(result)\n     output.put((test, stdout.rstrip(), stderr.rstrip(), result))\n   except BaseException:\n    output.put((None, None, None, None))\n    raise\n  workers = [Thread(target=work) for i in range(use_mp)]\n  for worker in workers:\n   worker.start()\n  finished = 0\n  test_index = 1\n  try:\n   while finished < use_mp:\n    test, stdout, stderr, result = output.get()\n    if test is None:\n     finished += 1\n     continue\n    accumulate_result(test, result)\n    if not quiet:\n     fmt = \"[{1:{0}}{2}/{3}] {4}\" if bad else \"[{1:{0}}{2}] {4}\"\n     print(fmt.format(\n     test_count_width, test_index, test_count,\n     len(bad), test))\n    if stdout:\n     print(stdout)\n    if stderr:\n     print(stderr, file=sys.stderr)\n    sys.stdout.flush()\n    sys.stderr.flush()\n    if result[0] == INTERRUPTED:\n     raise KeyboardInterrupt\n    if result[0] == CHILD_ERROR:\n     raise Exception(\"Child error on {}: {}\".format(test, result[1]))\n    test_index += 1\n  except KeyboardInterrupt:\n   interrupted = True\n   pending.interrupted = True\n  for worker in workers:\n   worker.join()\n else:\n  for test_index, test in enumerate(tests, 1):\n   if not quiet:\n    fmt = \"[{1:{0}}{2}/{3}] {4}\" if bad else \"[{1:{0}}{2}] {4}\"\n    print(fmt.format(\n    test_count_width, test_index, test_count, len(bad), test))\n    sys.stdout.flush()\n   if trace:\n   \n   \n    tracer.runctx('runtest(test, verbose, quiet, timeout=timeout)',\n    globals=globals(), locals=vars())\n   else:\n    try:\n     result = runtest(test, verbose, quiet, huntrleaks, debug,\n     output_on_failure=verbose3,\n     timeout=timeout, failfast=failfast,\n     match_tests=match_tests)\n     accumulate_result(test, result)\n    except KeyboardInterrupt:\n     interrupted = True\n     break\n    except:\n     raise\n   if findleaks:\n    gc.collect()\n    if gc.garbage:\n     print(\"Warning: test created\", len(gc.garbage), end=' ')\n     print(\"uncollectable object(s).\")\n     \n     \n     found_garbage.extend(gc.garbage)\n     del gc.garbage[:]\n     \n   for module in sys.modules.keys():\n    if module not in save_modules and module.startswith(\"test.\"):\n     support.unload(module)\n     \n if interrupted:\n \n  print()\n  print(\"Test suite interrupted by signal SIGINT.\")\n  omitted = set(selected) - set(good) - set(bad) - set(skipped)\n  print(count(len(omitted), \"test\"), \"omitted:\")\n  printlist(omitted)\n if good and not quiet:\n  if not bad and not skipped and not interrupted and len(good) > 1:\n   print(\"All\", end=' ')\n  print(count(len(good), \"test\"), \"OK.\")\n if print_slow:\n  test_times.sort(reverse=True)\n  print(\"10 slowest tests:\")\n  for time, test in test_times[:10]:\n   print(\"%s: %.1fs\" % (test, time))\n if bad:\n  bad = sorted(set(bad) - set(environment_changed))\n  if bad:\n   print(count(len(bad), \"test\"), \"failed:\")\n   printlist(bad)\n if environment_changed:\n  print(\"{} altered the execution environment:\".format(\n  count(len(environment_changed), \"test\")))\n  printlist(environment_changed)\n if skipped and not quiet:\n  print(count(len(skipped), \"test\"), \"skipped:\")\n  printlist(skipped)\n  \n  e = _ExpectedSkips()\n  plat = sys.platform\n  if e.isvalid():\n   surprise = set(skipped) - e.getexpected() - set(resource_denieds)\n   if surprise:\n    print(count(len(surprise), \"skip\"), \"unexpected on\", plat + \":\")\n    printlist(surprise)\n   else:\n    print(\"Those skips are all expected on\", plat + \".\")\n  else:\n   print(\"Ask someone to teach regrtest.py about which tests are\")\n   print(\"expected to get skipped on\", plat + \".\")\n   \n if verbose2 and bad:\n  print(\"Re-running failed tests in verbose mode\")\n  for test in bad:\n   print(\"Re-running test %r in verbose mode\" % test)\n   sys.stdout.flush()\n   try:\n    verbose = True\n    ok = runtest(test, True, quiet, huntrleaks, debug, timeout=timeout)\n   except KeyboardInterrupt:\n   \n    print()\n    break\n   except:\n    raise\n    \n if single:\n  if next_single_test:\n   with open(filename, 'w') as fp:\n    fp.write(next_single_test + '\\n')\n  else:\n   os.unlink(filename)\n   \n if trace:\n  r = tracer.results()\n  r.write_results(show_missing=True, summary=True, coverdir=coverdir)\n  \n if runleaks:\n  os.system(\"leaks %d\" % os.getpid())\n  \n sys.exit(len(bad) > 0 or interrupted)\n \n \n \n \nSTDTESTS = [\n'test_grammar',\n'test_opcodes',\n'test_dict',\n'test_builtin',\n'test_exceptions',\n'test_types',\n'test_unittest',\n'test_doctest',\n'test_doctest2',\n'test_support'\n]\n\n\nNOTTESTS = set()\n\ndef findtests(testdir=None, stdtests=STDTESTS, nottests=NOTTESTS):\n \"\"\n testdir = findtestdir(testdir)\n names = os.listdir(testdir)\n tests = []\n others = set(stdtests) | nottests\n for name in names:\n  mod, ext = os.path.splitext(name)\n  if mod[:5] == \"test_\" and ext in (\".py\", \"\") and mod not in others:\n   tests.append(mod)\n return stdtests + sorted(tests)\n \n \nclass MultiprocessTests(object):\n\n \"\"\n \n def __init__(self, tests):\n  self.interrupted = False\n  self.lock = threading.Lock()\n  self.tests = tests\n  \n def __iter__(self):\n  return self\n  \n def __next__(self):\n  with self.lock:\n   if self.interrupted:\n    raise StopIteration('tests interrupted')\n   return next(self.tests)\n   \ndef replace_stdout():\n \"\"\n import atexit\n \n stdout = sys.stdout\n sys.stdout = open(stdout.fileno(), 'w',\n encoding=stdout.encoding,\n errors=\"backslashreplace\",\n closefd=False,\n newline='\\n')\n \n def restore_stdout():\n  sys.stdout.close()\n  sys.stdout = stdout\n atexit.register(restore_stdout)\n \ndef runtest(test, verbose, quiet,\nhuntrleaks=False, debug=False, use_resources=None,\noutput_on_failure=False, failfast=False, match_tests=None,\ntimeout=None):\n \"\"\n \n if use_resources is not None:\n  support.use_resources = use_resources\n use_timeout = (timeout is not None)\n if use_timeout:\n  faulthandler.dump_tracebacks_later(timeout, exit=True)\n try:\n  support.match_tests = match_tests\n  if failfast:\n   support.failfast = True\n  if output_on_failure:\n   support.verbose = True\n   \n   \n   \n   \n   if runtest.stringio is None:\n    stream = io.StringIO()\n    runtest.stringio = stream\n   else:\n    stream = runtest.stringio\n    stream.seek(0)\n    stream.truncate()\n    \n   orig_stdout = sys.stdout\n   orig_stderr = sys.stderr\n   try:\n    sys.stdout = stream\n    sys.stderr = stream\n    result = runtest_inner(test, verbose, quiet, huntrleaks,\n    debug, display_failure=False)\n    if result[0] == FAILED:\n     output = stream.getvalue()\n     orig_stderr.write(output)\n     orig_stderr.flush()\n   finally:\n    sys.stdout = orig_stdout\n    sys.stderr = orig_stderr\n  else:\n   support.verbose = verbose \n   result = runtest_inner(test, verbose, quiet, huntrleaks, debug,\n   display_failure=not verbose)\n  return result\n finally:\n  if use_timeout:\n   faulthandler.cancel_dump_tracebacks_later()\n  cleanup_test_droppings(test, verbose)\nruntest.stringio = None\n\n\n\n\n\n\n\n\n\nclass saved_test_environment:\n \"\"\n \n changed = False\n \n def __init__(self, testname, verbose=0, quiet=False):\n  self.testname = testname\n  self.verbose = verbose\n  self.quiet = quiet\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n resources = ('sys.argv', 'cwd', 'sys.stdin', 'sys.stdout', 'sys.stderr',\n 'os.environ', 'sys.path', 'sys.path_hooks', '__import__',\n 'warnings.filters', 'asyncore.socket_map',\n 'logging._handlers', 'logging._handlerList', 'sys.gettrace',\n 'sys.warnoptions', 'threading._dangling',\n 'multiprocessing.process._dangling',\n 'sysconfig._CONFIG_VARS', 'sysconfig._INSTALL_SCHEMES',\n 'support.TESTFN',\n )\n \n def get_sys_argv(self):\n  return id(sys.argv), sys.argv, sys.argv[:]\n def restore_sys_argv(self, saved_argv):\n  sys.argv = saved_argv[1]\n  sys.argv[:] = saved_argv[2]\n  \n def get_cwd(self):\n  return os.getcwd()\n def restore_cwd(self, saved_cwd):\n  os.chdir(saved_cwd)\n  \n def get_sys_stdout(self):\n  return sys.stdout\n def restore_sys_stdout(self, saved_stdout):\n  sys.stdout = saved_stdout\n  \n def get_sys_stderr(self):\n  return sys.stderr\n def restore_sys_stderr(self, saved_stderr):\n  sys.stderr = saved_stderr\n  \n def get_sys_stdin(self):\n  return sys.stdin\n def restore_sys_stdin(self, saved_stdin):\n  sys.stdin = saved_stdin\n  \n def get_os_environ(self):\n  return id(os.environ), os.environ, dict(os.environ)\n def restore_os_environ(self, saved_environ):\n  os.environ = saved_environ[1]\n  os.environ.clear()\n  os.environ.update(saved_environ[2])\n  \n def get_sys_path(self):\n  return id(sys.path), sys.path, sys.path[:]\n def restore_sys_path(self, saved_path):\n  sys.path = saved_path[1]\n  sys.path[:] = saved_path[2]\n  \n def get_sys_path_hooks(self):\n  return id(sys.path_hooks), sys.path_hooks, sys.path_hooks[:]\n def restore_sys_path_hooks(self, saved_hooks):\n  sys.path_hooks = saved_hooks[1]\n  sys.path_hooks[:] = saved_hooks[2]\n  \n def get_sys_gettrace(self):\n  return sys.gettrace()\n def restore_sys_gettrace(self, trace_fxn):\n  sys.settrace(trace_fxn)\n  \n def get___import__(self):\n  return builtins.__import__\n def restore___import__(self, import_):\n  builtins.__import__ = import_\n  \n def get_warnings_filters(self):\n  return id(warnings.filters), warnings.filters, warnings.filters[:]\n def restore_warnings_filters(self, saved_filters):\n  warnings.filters = saved_filters[1]\n  warnings.filters[:] = saved_filters[2]\n  \n def get_asyncore_socket_map(self):\n  asyncore = sys.modules.get('asyncore')\n  \n  return asyncore and asyncore.socket_map.copy() or {}\n def restore_asyncore_socket_map(self, saved_map):\n  asyncore = sys.modules.get('asyncore')\n  if asyncore is not None:\n   asyncore.close_all(ignore_all=True)\n   asyncore.socket_map.update(saved_map)\n   \n def get_shutil_archive_formats(self):\n \n \n \n  return shutil._ARCHIVE_FORMATS, shutil._ARCHIVE_FORMATS.copy()\n def restore_shutil_archive_formats(self, saved):\n  shutil._ARCHIVE_FORMATS = saved[0]\n  shutil._ARCHIVE_FORMATS.clear()\n  shutil._ARCHIVE_FORMATS.update(saved[1])\n  \n def get_shutil_unpack_formats(self):\n  return shutil._UNPACK_FORMATS, shutil._UNPACK_FORMATS.copy()\n def restore_shutil_unpack_formats(self, saved):\n  shutil._UNPACK_FORMATS = saved[0]\n  shutil._UNPACK_FORMATS.clear()\n  shutil._UNPACK_FORMATS.update(saved[1])\n  \n def get_logging__handlers(self):\n \n  return id(logging._handlers), logging._handlers, logging._handlers.copy()\n def restore_logging__handlers(self, saved_handlers):\n \n  pass\n  \n def get_logging__handlerList(self):\n \n  return id(logging._handlerList), logging._handlerList, logging._handlerList[:]\n def restore_logging__handlerList(self, saved_handlerList):\n \n  pass\n  \n def get_sys_warnoptions(self):\n  return id(sys.warnoptions), sys.warnoptions, sys.warnoptions[:]\n def restore_sys_warnoptions(self, saved_options):\n  sys.warnoptions = saved_options[1]\n  sys.warnoptions[:] = saved_options[2]\n  \n  \n  \n def get_threading__dangling(self):\n  if not threading:\n   return None\n   \n  return threading._dangling.copy()\n def restore_threading__dangling(self, saved):\n  if not threading:\n   return\n  threading._dangling.clear()\n  threading._dangling.update(saved)\n  \n  \n def get_multiprocessing_process__dangling(self):\n  if not multiprocessing:\n   return None\n   \n  return multiprocessing.process._dangling.copy()\n def restore_multiprocessing_process__dangling(self, saved):\n  if not multiprocessing:\n   return\n  multiprocessing.process._dangling.clear()\n  multiprocessing.process._dangling.update(saved)\n  \n def get_sysconfig__CONFIG_VARS(self):\n \n  sysconfig.get_config_var('prefix')\n  return (id(sysconfig._CONFIG_VARS), sysconfig._CONFIG_VARS,\n  dict(sysconfig._CONFIG_VARS))\n def restore_sysconfig__CONFIG_VARS(self, saved):\n  sysconfig._CONFIG_VARS = saved[1]\n  sysconfig._CONFIG_VARS.clear()\n  sysconfig._CONFIG_VARS.update(saved[2])\n  \n def get_sysconfig__INSTALL_SCHEMES(self):\n  return (id(sysconfig._INSTALL_SCHEMES), sysconfig._INSTALL_SCHEMES,\n  sysconfig._INSTALL_SCHEMES.copy())\n def restore_sysconfig__INSTALL_SCHEMES(self, saved):\n  sysconfig._INSTALL_SCHEMES = saved[1]\n  sysconfig._INSTALL_SCHEMES.clear()\n  sysconfig._INSTALL_SCHEMES.update(saved[2])\n  \n def get_support_TESTFN(self):\n  if os.path.isfile(support.TESTFN):\n   result = 'f'\n  elif os.path.isdir(support.TESTFN):\n   result = 'd'\n  else:\n   result = None\n  return result\n def restore_support_TESTFN(self, saved_value):\n  if saved_value is None:\n   if os.path.isfile(support.TESTFN):\n    os.unlink(support.TESTFN)\n   elif os.path.isdir(support.TESTFN):\n    shutil.rmtree(support.TESTFN)\n    \n def resource_info(self):\n  for name in self.resources:\n   method_suffix = name.replace('.', '_')\n   get_name = 'get_' + method_suffix\n   restore_name = 'restore_' + method_suffix\n   yield name, getattr(self, get_name), getattr(self, restore_name)\n   \n def __enter__(self):\n  self.saved_values = dict((name, get()) for name, get, restore\n  in self.resource_info())\n  return self\n  \n def __exit__(self, exc_type, exc_val, exc_tb):\n  saved_values = self.saved_values\n  del self.saved_values\n  for name, get, restore in self.resource_info():\n   current = get()\n   original = saved_values.pop(name)\n   \n   if current != original:\n    self.changed = True\n    restore(original)\n    if not self.quiet:\n     print(\"Warning -- {} was modified by {}\".format(\n     name, self.testname),\n     file=sys.stderr)\n     if self.verbose > 1:\n      print(\"  Before: {}\\n  After:  {} \".format(\n      original, current),\n      file=sys.stderr)\n  return False\n  \n  \ndef runtest_inner(test, verbose, quiet,\nhuntrleaks=False, debug=False, display_failure=True):\n support.unload(test)\n \n test_time = 0.0\n refleak = False \n try:\n  if test.startswith('test.'):\n   abstest = test\n  else:\n  \n   abstest = 'test.' + test\n  with saved_test_environment(test, verbose, quiet) as environment:\n   start_time = time.time()\n   the_package = __import__(abstest, globals(), locals(), [])\n   the_module = getattr(the_package, test)\n   \n   \n   test_runner = getattr(the_module, \"test_main\", None)\n   if test_runner is None:\n    tests = unittest.TestLoader().loadTestsFromModule(the_module)\n    test_runner = lambda: support.run_unittest(tests)\n   test_runner()\n   if huntrleaks:\n    refleak = dash_R(the_module, test, test_runner,\n    huntrleaks)\n   test_time = time.time() - start_time\n except support.ResourceDenied as msg:\n  if not quiet:\n   print(test, \"skipped --\", msg)\n   sys.stdout.flush()\n  return RESOURCE_DENIED, test_time\n except unittest.SkipTest as msg:\n  if not quiet:\n   print(test, \"skipped --\", msg)\n   sys.stdout.flush()\n  return SKIPPED, test_time\n except KeyboardInterrupt:\n  raise\n except support.TestFailed as msg:\n  if display_failure:\n   print(\"test\", test, \"failed --\", msg, file=sys.stderr)\n  else:\n   print(\"test\", test, \"failed\", file=sys.stderr)\n  sys.stderr.flush()\n  return FAILED, test_time\n except:\n  msg = traceback.format_exc()\n  print(\"test\", test, \"crashed --\", msg, file=sys.stderr)\n  sys.stderr.flush()\n  return FAILED, test_time\n else:\n  if refleak:\n   return FAILED, test_time\n  if environment.changed:\n   return ENV_CHANGED, test_time\n  return PASSED, test_time\n  \ndef cleanup_test_droppings(testname, verbose):\n import shutil\n import stat\n import gc\n \n \n \n \n gc.collect()\n \n \n \n \n \n \n \n for name in (support.TESTFN,\n \"db_home\",\n ):\n  if not os.path.exists(name):\n   continue\n   \n  if os.path.isdir(name):\n   kind, nuker = \"directory\", shutil.rmtree\n  elif os.path.isfile(name):\n   kind, nuker = \"file\", os.unlink\n  else:\n   raise SystemError(\"os.path says %r exists but is neither \"\n   \"directory nor file\" % name)\n   \n  if verbose:\n   print(\"%r left behind %s %r\" % (testname, kind, name))\n  try:\n  \n  \n   if (hasattr(os, 'chmod')):\n    os.chmod(name, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n   nuker(name)\n  except Exception as msg:\n   print((\"%r left behind %s %r and it couldn't be \"\n   \"removed: %s\" % (testname, kind, name, msg)), file=sys.stderr)\n   \ndef dash_R(the_module, test, indirect_test, huntrleaks):\n \"\"\n \n import copyreg\n import collections.abc\n \n if not hasattr(sys, 'gettotalrefcount'):\n  raise Exception(\"Tracking reference leaks requires a debug build \"\n  \"of Python\")\n  \n  \n fs = warnings.filters[:]\n ps = copyreg.dispatch_table.copy()\n pic = sys.path_importer_cache.copy()\n try:\n  import zipimport\n except ImportError:\n  zdc = None \n else:\n  zdc = zipimport._zip_directory_cache.copy()\n abcs = {}\n for abc in [getattr(collections.abc, a) for a in collections.abc.__all__]:\n  if not isabstract(abc):\n   continue\n  for obj in abc.__subclasses__() + [abc]:\n   abcs[obj] = obj._abc_registry.copy()\n   \n if indirect_test:\n  def run_the_test():\n   indirect_test()\n else:\n  def run_the_test():\n   del sys.modules[the_module.__name__]\n   exec('import ' + the_module.__name__)\n   \n deltas = []\n nwarmup, ntracked, fname = huntrleaks\n fname = os.path.join(support.SAVEDCWD, fname)\n repcount = nwarmup + ntracked\n print(\"beginning\", repcount, \"repetitions\", file=sys.stderr)\n print((\"1234567890\"*(repcount//10 + 1))[:repcount], file=sys.stderr)\n sys.stderr.flush()\n dash_R_cleanup(fs, ps, pic, zdc, abcs)\n for i in range(repcount):\n  rc_before = sys.gettotalrefcount()\n  run_the_test()\n  sys.stderr.write('.')\n  sys.stderr.flush()\n  dash_R_cleanup(fs, ps, pic, zdc, abcs)\n  rc_after = sys.gettotalrefcount()\n  if i >= nwarmup:\n   deltas.append(rc_after - rc_before)\n print(file=sys.stderr)\n if any(deltas):\n  msg = '%s leaked %s references, sum=%s' % (test, deltas, sum(deltas))\n  print(msg, file=sys.stderr)\n  sys.stderr.flush()\n  with open(fname, \"a\") as refrep:\n   print(msg, file=refrep)\n   refrep.flush()\n  return True\n return False\n \ndef dash_R_cleanup(fs, ps, pic, zdc, abcs):\n import gc, copyreg\n import _strptime, linecache\n import urllib.parse, urllib.request, mimetypes, doctest\n import struct, filecmp, collections.abc\n from distutils.dir_util import _path_created\n from weakref import WeakSet\n \n \n for mod in sys.modules.values():\n  if hasattr(mod, '__warningregistry__'):\n   del mod.__warningregistry__\n   \n   \n warnings.filters[:] = fs\n copyreg.dispatch_table.clear()\n copyreg.dispatch_table.update(ps)\n sys.path_importer_cache.clear()\n sys.path_importer_cache.update(pic)\n try:\n  import zipimport\n except ImportError:\n  pass \n else:\n  zipimport._zip_directory_cache.clear()\n  zipimport._zip_directory_cache.update(zdc)\n  \n  \n sys._clear_type_cache()\n \n \n for abc in [getattr(collections.abc, a) for a in collections.abc.__all__]:\n  if not isabstract(abc):\n   continue\n  for obj in abc.__subclasses__() + [abc]:\n   obj._abc_registry = abcs.get(obj, WeakSet()).copy()\n   obj._abc_cache.clear()\n   obj._abc_negative_cache.clear()\n   \n   \n   \n for stream in (sys.stdout, sys.stderr, sys.__stdout__, sys.__stderr__):\n  if stream is not None:\n   stream.flush()\n   \n   \n _path_created.clear()\n re.purge()\n _strptime._regex_cache.clear()\n urllib.parse.clear_cache()\n urllib.request.urlcleanup()\n linecache.clearcache()\n mimetypes._default_mime_types()\n filecmp._cache.clear()\n struct._clearcache()\n doctest.master = None\n try:\n  import ctypes\n except ImportError:\n \n  pass\n else:\n  ctypes._reset_cache()\n  \n  \n gc.collect()\n \ndef warm_caches():\n\n s = bytes(range(256))\n for i in range(256):\n  s[i:i+1]\n  \n x = [chr(i) for i in range(256)]\n \n x = list(range(-5, 257))\n \ndef findtestdir(path=None):\n return path or os.path.dirname(__file__) or os.curdir\n \ndef removepy(names):\n if not names:\n  return\n for idx, name in enumerate(names):\n  basename, ext = os.path.splitext(name)\n  if ext == '.py':\n   names[idx] = basename\n   \ndef count(n, word):\n if n == 1:\n  return \"%d %s\" % (n, word)\n else:\n  return \"%d %ss\" % (n, word)\n  \ndef printlist(x, width=70, indent=4):\n \"\"\n \n from textwrap import fill\n blanks = ' ' * indent\n \n print(fill(' '.join(str(elt) for elt in sorted(x)), width,\n initial_indent=blanks, subsequent_indent=blanks))\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n_expectations = (\n('win32',\n\"\"\"\n        test__locale\n        test_crypt\n        test_curses\n        test_dbm\n        test_devpoll\n        test_fcntl\n        test_fork1\n        test_epoll\n        test_dbm_gnu\n        test_dbm_ndbm\n        test_grp\n        test_ioctl\n        test_largefile\n        test_kqueue\n        test_openpty\n        test_ossaudiodev\n        test_pipes\n        test_poll\n        test_posix\n        test_pty\n        test_pwd\n        test_resource\n        test_signal\n        test_syslog\n        test_threadsignals\n        test_wait3\n        test_wait4\n        \"\"\"),\n('linux',\n\"\"\"\n        test_curses\n        test_devpoll\n        test_largefile\n        test_kqueue\n        test_ossaudiodev\n        \"\"\"),\n('unixware',\n\"\"\"\n        test_epoll\n        test_largefile\n        test_kqueue\n        test_minidom\n        test_openpty\n        test_pyexpat\n        test_sax\n        test_sundry\n        \"\"\"),\n('openunix',\n\"\"\"\n        test_epoll\n        test_largefile\n        test_kqueue\n        test_minidom\n        test_openpty\n        test_pyexpat\n        test_sax\n        test_sundry\n        \"\"\"),\n('sco_sv',\n\"\"\"\n        test_asynchat\n        test_fork1\n        test_epoll\n        test_gettext\n        test_largefile\n        test_locale\n        test_kqueue\n        test_minidom\n        test_openpty\n        test_pyexpat\n        test_queue\n        test_sax\n        test_sundry\n        test_thread\n        test_threaded_import\n        test_threadedtempfile\n        test_threading\n        \"\"\"),\n('darwin',\n\"\"\"\n        test__locale\n        test_curses\n        test_devpoll\n        test_epoll\n        test_dbm_gnu\n        test_gdb\n        test_largefile\n        test_locale\n        test_minidom\n        test_ossaudiodev\n        test_poll\n        \"\"\"),\n('sunos',\n\"\"\"\n        test_curses\n        test_dbm\n        test_epoll\n        test_kqueue\n        test_dbm_gnu\n        test_gzip\n        test_openpty\n        test_zipfile\n        test_zlib\n        \"\"\"),\n('hp-ux',\n\"\"\"\n        test_curses\n        test_epoll\n        test_dbm_gnu\n        test_gzip\n        test_largefile\n        test_locale\n        test_kqueue\n        test_minidom\n        test_openpty\n        test_pyexpat\n        test_sax\n        test_zipfile\n        test_zlib\n        \"\"\"),\n('cygwin',\n\"\"\"\n        test_curses\n        test_dbm\n        test_devpoll\n        test_epoll\n        test_ioctl\n        test_kqueue\n        test_largefile\n        test_locale\n        test_ossaudiodev\n        test_socketserver\n        \"\"\"),\n('os2emx',\n\"\"\"\n        test_audioop\n        test_curses\n        test_epoll\n        test_kqueue\n        test_largefile\n        test_mmap\n        test_openpty\n        test_ossaudiodev\n        test_pty\n        test_resource\n        test_signal\n        \"\"\"),\n('freebsd',\n\"\"\"\n        test_devpoll\n        test_epoll\n        test_dbm_gnu\n        test_locale\n        test_ossaudiodev\n        test_pep277\n        test_pty\n        test_socketserver\n        test_tcl\n        test_tk\n        test_ttk_guionly\n        test_ttk_textonly\n        test_timeout\n        test_urllibnet\n        test_multiprocessing\n        \"\"\"),\n('aix',\n\"\"\"\n        test_bz2\n        test_epoll\n        test_dbm_gnu\n        test_gzip\n        test_kqueue\n        test_ossaudiodev\n        test_tcl\n        test_tk\n        test_ttk_guionly\n        test_ttk_textonly\n        test_zipimport\n        test_zlib\n        \"\"\"),\n('openbsd',\n\"\"\"\n        test_ctypes\n        test_devpoll\n        test_epoll\n        test_dbm_gnu\n        test_locale\n        test_normalization\n        test_ossaudiodev\n        test_pep277\n        test_tcl\n        test_tk\n        test_ttk_guionly\n        test_ttk_textonly\n        test_multiprocessing\n        \"\"\"),\n('netbsd',\n\"\"\"\n        test_ctypes\n        test_curses\n        test_devpoll\n        test_epoll\n        test_dbm_gnu\n        test_locale\n        test_ossaudiodev\n        test_pep277\n        test_tcl\n        test_tk\n        test_ttk_guionly\n        test_ttk_textonly\n        test_multiprocessing\n        \"\"\"),\n)\n\nclass _ExpectedSkips:\n def __init__(self):\n  import os.path\n  from test import test_timeout\n  \n  self.valid = False\n  expected = None\n  for item in _expectations:\n   if sys.platform.startswith(item[0]):\n    expected = item[1]\n    break\n  if expected is not None:\n   self.expected = set(expected.split())\n   \n   \n   \n   self.expected.add('test_nis')\n   \n   \n   if not os.path.supports_unicode_filenames:\n    self.expected.add('test_pep277')\n    \n    \n    \n    \n   encs = (\"utf-8\", \"latin-1\", \"ascii\", \"mbcs\", \"utf-16\", \"utf-32\")\n   if sys.getfilesystemencoding().lower() not in encs:\n    self.expected.add('test_profile')\n    self.expected.add('test_cProfile')\n    self.expected.add('test_doctest')\n    \n   if test_timeout.skip_expected:\n    self.expected.add('test_timeout')\n    \n   if sys.platform != \"win32\":\n   \n   \n    WIN_ONLY = {\"test_unicode_file\", \"test_winreg\",\n    \"test_winsound\", \"test_startfile\",\n    \"test_sqlite\", \"test_msilib\"}\n    self.expected |= WIN_ONLY\n    \n   if sys.platform != 'sunos5':\n    self.expected.add('test_nis')\n    \n   if support.python_is_optimized():\n    self.expected.add(\"test_gdb\")\n    \n   self.valid = True\n   \n def isvalid(self):\n  \"\"\n  return self.valid\n  \n def getexpected(self):\n  \"\"\n  \n  assert self.isvalid()\n  return self.expected\n  \ndef _make_temp_dir_for_build(TEMPDIR):\n\n\n\n if sysconfig.is_python_build():\n  TEMPDIR = os.path.join(sysconfig.get_config_var('srcdir'), 'build')\n  TEMPDIR = os.path.abspath(TEMPDIR)\n  try:\n   os.mkdir(TEMPDIR)\n  except FileExistsError:\n   pass\n   \n   \n   \n   \n TESTCWD = 'test_python_{}'.format(os.getpid())\n \n TESTCWD = os.path.join(TEMPDIR, TESTCWD)\n return TEMPDIR, TESTCWD\n \nif __name__ == '__main__':\n\n\n\n\n\n mydir = os.path.abspath(os.path.normpath(os.path.dirname(sys.argv[0])))\n i = len(sys.path)\n while i >= 0:\n  i -= 1\n  if os.path.abspath(os.path.normpath(sys.path[i])) == mydir:\n   del sys.path[i]\n   \n   \n   \n   \n   \n __file__ = os.path.abspath(__file__)\n \n \n assert __file__ == os.path.abspath(sys.argv[0])\n \n TEMPDIR, TESTCWD = _make_temp_dir_for_build(TEMPDIR)\n \n \n \n \n \n with support.temp_cwd(TESTCWD, quiet=True):\n  main()\n"], "contextlib": [".py", "\"\"\n\nimport sys\nfrom collections import deque\nfrom functools import wraps\n\n__all__ = [\"contextmanager\", \"closing\", \"ContextDecorator\", \"ExitStack\"]\n\n\nclass ContextDecorator(object):\n \"\"\n \n def _recreate_cm(self):\n  \"\"\n  return self\n  \n def __call__(self, func):\n  @wraps(func)\n  def inner(*args, **kwds):\n   with self._recreate_cm():\n    return func(*args, **kwds)\n  return inner\n  \n  \nclass _GeneratorContextManager(ContextDecorator):\n \"\"\n \n def __init__(self, func, *args, **kwds):\n  self.gen = func(*args, **kwds)\n  self.func, self.args, self.kwds = func, args, kwds\n  \n def _recreate_cm(self):\n \n \n \n  return self.__class__(self.func, *self.args, **self.kwds)\n  \n def __enter__(self):\n  try:\n   return next(self.gen)\n  except StopIteration:\n   raise RuntimeError(\"generator didn't yield\")\n   \n def __exit__(self, type, value, traceback):\n  if type is None:\n   try:\n    next(self.gen)\n   except StopIteration:\n    return\n   else:\n    raise RuntimeError(\"generator didn't stop\")\n  else:\n   if value is None:\n   \n   \n    value = type()\n   try:\n    self.gen.throw(type, value, traceback)\n    raise RuntimeError(\"generator didn't stop after throw()\")\n   except StopIteration as exc:\n   \n   \n   \n    return exc is not value\n   except:\n   \n   \n   \n   \n   \n   \n   \n    if sys.exc_info()[1] is not value:\n     raise\n     \n     \ndef contextmanager(func):\n \"\"\n @wraps(func)\n def helper(*args, **kwds):\n  return _GeneratorContextManager(func, *args, **kwds)\n return helper\n \n \nclass closing(object):\n \"\"\n def __init__(self, thing):\n  self.thing = thing\n def __enter__(self):\n  return self.thing\n def __exit__(self, *exc_info):\n  self.thing.close()\n  \n  \n  \nclass ExitStack(object):\n \"\"\n def __init__(self):\n  self._exit_callbacks = deque()\n  \n def pop_all(self):\n  \"\"\n  new_stack = type(self)()\n  new_stack._exit_callbacks = self._exit_callbacks\n  self._exit_callbacks = deque()\n  return new_stack\n  \n def _push_cm_exit(self, cm, cm_exit):\n  \"\"\n  def _exit_wrapper(*exc_details):\n   return cm_exit(cm, *exc_details)\n  _exit_wrapper.__self__ = cm\n  self.push(_exit_wrapper)\n  \n def push(self, exit):\n  \"\"\n  \n  \n  _cb_type = type(exit)\n  try:\n   exit_method = _cb_type.__exit__\n  except AttributeError:\n  \n   self._exit_callbacks.append(exit)\n  else:\n   self._push_cm_exit(exit, exit_method)\n  return exit \n  \n def callback(self, callback, *args, **kwds):\n  \"\"\n  def _exit_wrapper(exc_type, exc, tb):\n   callback(*args, **kwds)\n   \n   \n  _exit_wrapper.__wrapped__ = callback\n  self.push(_exit_wrapper)\n  return callback \n  \n def enter_context(self, cm):\n  \"\"\n  \n  _cm_type = type(cm)\n  _exit = _cm_type.__exit__\n  result = _cm_type.__enter__(cm)\n  self._push_cm_exit(cm, _exit)\n  return result\n  \n def close(self):\n  \"\"\n  self.__exit__(None, None, None)\n  \n def __enter__(self):\n  return self\n  \n def __exit__(self, *exc_details):\n  received_exc = exc_details[0] is not None\n  \n  \n  \n  frame_exc = sys.exc_info()[1]\n  def _fix_exception_context(new_exc, old_exc):\n   while 1:\n    exc_context = new_exc.__context__\n    if exc_context in (None, frame_exc):\n     break\n    new_exc = exc_context\n   new_exc.__context__ = old_exc\n   \n   \n   \n  suppressed_exc = False\n  pending_raise = False\n  while self._exit_callbacks:\n   cb = self._exit_callbacks.pop()\n   try:\n    if cb(*exc_details):\n     suppressed_exc = True\n     pending_raise = False\n     exc_details = (None, None, None)\n   except:\n    new_exc_details = sys.exc_info()\n    \n    _fix_exception_context(new_exc_details[1], exc_details[1])\n    pending_raise = True\n    exc_details = new_exc_details\n  if pending_raise:\n   try:\n   \n   \n    fixed_ctx = exc_details[1].__context__\n    raise exc_details[1]\n   except BaseException:\n    exc_details[1].__context__ = fixed_ctx\n    raise\n  return received_exc and suppressed_exc\n"], "numbers": [".py", "\n\n\n\"\"\n\nfrom abc import ABCMeta, abstractmethod\n\n__all__ = [\"Number\", \"Complex\", \"Real\", \"Rational\", \"Integral\"]\n\nclass Number(metaclass=ABCMeta):\n \"\"\n __slots__ = ()\n \n \n __hash__ = None\n \n \n \n \n \n \n \n \n \n \nclass Complex(Number):\n \"\"\n \n __slots__ = ()\n \n @abstractmethod\n def __complex__(self):\n  \"\"\n  \n def __bool__(self):\n  \"\"\n  return self != 0\n  \n @property\n @abstractmethod\n def real(self):\n  \"\"\n  raise NotImplementedError\n  \n @property\n @abstractmethod\n def imag(self):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __add__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __radd__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __neg__(self):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __pos__(self):\n  \"\"\n  raise NotImplementedError\n  \n def __sub__(self, other):\n  \"\"\n  return self + -other\n  \n def __rsub__(self, other):\n  \"\"\n  return -self + other\n  \n @abstractmethod\n def __mul__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __rmul__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __truediv__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __rtruediv__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __pow__(self, exponent):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __rpow__(self, base):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __abs__(self):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def conjugate(self):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __eq__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n def __ne__(self, other):\n  \"\"\n  \n  return not (self == other)\n  \nComplex.register(complex)\n\n\nclass Real(Complex):\n \"\"\n \n __slots__ = ()\n \n @abstractmethod\n def __float__(self):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __trunc__(self):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __floor__(self):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __ceil__(self):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __round__(self, ndigits=None):\n  \"\"\n  raise NotImplementedError\n  \n def __divmod__(self, other):\n  \"\"\n  return (self // other, self % other)\n  \n def __rdivmod__(self, other):\n  \"\"\n  return (other // self, other % self)\n  \n @abstractmethod\n def __floordiv__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __rfloordiv__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __mod__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __rmod__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __lt__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __le__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n  \n def __complex__(self):\n  \"\"\n  return complex(float(self))\n  \n @property\n def real(self):\n  \"\"\n  return +self\n  \n @property\n def imag(self):\n  \"\"\n  return 0\n  \n def conjugate(self):\n  \"\"\n  return +self\n  \nReal.register(float)\n\n\nclass Rational(Real):\n \"\"\n \n __slots__ = ()\n \n @property\n @abstractmethod\n def numerator(self):\n  raise NotImplementedError\n  \n @property\n @abstractmethod\n def denominator(self):\n  raise NotImplementedError\n  \n  \n def __float__(self):\n  \"\"\n  return self.numerator / self.denominator\n  \n  \nclass Integral(Rational):\n \"\"\n \n __slots__ = ()\n \n @abstractmethod\n def __int__(self):\n  \"\"\n  raise NotImplementedError\n  \n def __index__(self):\n  \"\"\n  return int(self)\n  \n @abstractmethod\n def __pow__(self, exponent, modulus=None):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __lshift__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __rlshift__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __rshift__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __rrshift__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __and__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __rand__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __xor__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __rxor__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __or__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __ror__(self, other):\n  \"\"\n  raise NotImplementedError\n  \n @abstractmethod\n def __invert__(self):\n  \"\"\n  raise NotImplementedError\n  \n  \n def __float__(self):\n  \"\"\n  return float(int(self))\n  \n @property\n def numerator(self):\n  \"\"\n  return +self\n  \n @property\n def denominator(self):\n  \"\"\n  return 1\n  \nIntegral.register(int)\n"], "io": [".py", "import builtins\n\nopen = builtins.open\n\n\nSEEK_SET = 0\nSEEK_CUR = 1\nSEEK_END = 2\n\n\"\"\ntry:\n from errno import EINVAL\nexcept ImportError:\n EINVAL = 22\n \n__all__ = [\"StringIO\"]\n\ndef _complain_ifclosed(closed):\n if closed:\n  raise ValueError(\"I/O operation on closed file\")\n  \nclass StringIO:\n \"\"\n def __init__(self, buf = ''):\n  self.buf = buf\n  self.len = len(buf)\n  self.buflist = []\n  self.pos = 0\n  self.closed = False\n  self.softspace = 0\n  \n def __iter__(self):\n  return self\n  \n def next(self):\n  \"\"\n  _complain_ifclosed(self.closed)\n  r = self.readline()\n  if not r:\n   raise StopIteration\n  return r\n  \n def close(self):\n  \"\"\n  if not self.closed:\n   self.closed = True\n   del self.buf, self.pos\n   \n def isatty(self):\n  \"\"\n  _complain_ifclosed(self.closed)\n  return False\n  \n def seek(self, pos, mode = 0):\n  \"\"\n  _complain_ifclosed(self.closed)\n  if self.buflist:\n   self.buf += ''.join(self.buflist)\n   self.buflist = []\n  if mode == 1:\n   pos += self.pos\n  elif mode == 2:\n   pos += self.len\n  self.pos = max(0, pos)\n  \n def tell(self):\n  \"\"\n  _complain_ifclosed(self.closed)\n  return self.pos\n  \n def read(self, n = -1):\n  \"\"\n  _complain_ifclosed(self.closed)\n  if self.buflist:\n   self.buf += ''.join(self.buflist)\n   self.buflist = []\n  if n is None or n < 0:\n   newpos = self.len\n  else:\n   newpos = min(self.pos+n, self.len)\n  r = self.buf[self.pos:newpos]\n  self.pos = newpos\n  return r\n  \n def readline(self, length=None):\n  \"\"\n  _complain_ifclosed(self.closed)\n  if self.buflist:\n   self.buf += ''.join(self.buflist)\n   self.buflist = []\n  i = self.buf.find('\\n', self.pos)\n  if i < 0:\n   newpos = self.len\n  else:\n   newpos = i+1\n  if length is not None and length >= 0:\n   if self.pos + length < newpos:\n    newpos = self.pos + length\n  r = self.buf[self.pos:newpos]\n  self.pos = newpos\n  return r\n  \n def readlines(self, sizehint = 0):\n  \"\"\n  total = 0\n  lines = []\n  line = self.readline()\n  while line:\n   lines.append(line)\n   total += len(line)\n   if 0 < sizehint <= total:\n    break\n   line = self.readline()\n  return lines\n  \n def truncate(self, size=None):\n  \"\"\n  _complain_ifclosed(self.closed)\n  if size is None:\n   size = self.pos\n  elif size < 0:\n   raise IOError(EINVAL, \"Negative size not allowed\")\n  elif size < self.pos:\n   self.pos = size\n  self.buf = self.getvalue()[:size]\n  self.len = size\n  \n def write(self, s):\n  \"\"\n  _complain_ifclosed(self.closed)\n  if not s: return\n  spos = self.pos\n  slen = self.len\n  if spos == slen:\n   self.buflist.append(s)\n   self.len = self.pos = spos + len(s)\n   return\n  if spos > slen:\n   self.buflist.append('\\0'*(spos - slen))\n   slen = spos\n  newpos = spos + len(s)\n  if spos < slen:\n   if self.buflist:\n    self.buf += ''.join(self.buflist)\n   self.buflist = [self.buf[:spos], s, self.buf[newpos:]]\n   self.buf = ''\n   if newpos > slen:\n    slen = newpos\n  else:\n   self.buflist.append(s)\n   slen = newpos\n  self.len = slen\n  self.pos = newpos\n  \n def writelines(self, iterable):\n  \"\"\n  write = self.write\n  for line in iterable:\n   write(line)\n   \n def flush(self):\n  \"\"\n  _complain_ifclosed(self.closed)\n  \n def getvalue(self):\n  \"\"\n  _complain_ifclosed(self.closed)\n  if self.buflist:\n   self.buf += ''.join(self.buflist)\n   self.buflist = []\n  return self.buf\n  \n  \nTextIOWrapper = StringIO\n\nclass RawIOBase:\n\n def read(self,n=-1):\n  pass\n def readall(self):\n  pass\n def readinto(self,b):\n  pass\n def write(self,b):\n  pass\n  \nBufferedReader = RawIOBase\n\n\n"], "copyreg": [".py", "\"\"\n\n__all__ = [\"pickle\", \"constructor\",\n\"add_extension\", \"remove_extension\", \"clear_extension_cache\"]\n\ndispatch_table = {}\n\ndef pickle(ob_type, pickle_function, constructor_ob=None):\n if not callable(pickle_function):\n  raise TypeError(\"reduction functions must be callable\")\n dispatch_table[ob_type] = pickle_function\n \n \n \n if constructor_ob is not None:\n  constructor(constructor_ob)\n  \ndef constructor(object):\n if not callable(object):\n  raise TypeError(\"constructors must be callable\")\n  \n  \n  \ntry:\n complex\nexcept NameError:\n pass\nelse:\n\n def pickle_complex(c):\n  return complex, (c.real, c.imag)\n  \n pickle(complex, pickle_complex, complex)\n \n \n \ndef _reconstructor(cls, base, state):\n if base is object:\n  obj = object.__new__(cls)\n else:\n  obj = base.__new__(cls, state)\n  if base.__init__ != object.__init__:\n   base.__init__(obj, state)\n return obj\n \n_HEAPTYPE = 1<<9\n\n\n\ndef _reduce_ex(self, proto):\n assert proto < 2\n for base in self.__class__.__mro__:\n  if hasattr(base, '__flags__') and not base.__flags__ & _HEAPTYPE:\n   break\n else:\n  base = object \n if base is object:\n  state = None\n else:\n  if base is self.__class__:\n   raise TypeError(\"can't pickle %s objects\" % base.__name__)\n  state = base(self)\n args = (self.__class__, base, state)\n try:\n  getstate = self.__getstate__\n except AttributeError:\n  if getattr(self, \"__slots__\", None):\n   raise TypeError(\"a class that defines __slots__ without \"\n   \"defining __getstate__ cannot be pickled\")\n  try:\n   dict = self.__dict__\n  except AttributeError:\n   dict = None\n else:\n  dict = getstate()\n if dict:\n  return _reconstructor, args, dict\n else:\n  return _reconstructor, args\n  \n  \n  \ndef __newobj__(cls, *args):\n return cls.__new__(cls, *args)\n \ndef _slotnames(cls):\n \"\"\n \n \n names = cls.__dict__.get(\"__slotnames__\")\n if names is not None:\n  return names\n  \n  \n names = []\n if not hasattr(cls, \"__slots__\"):\n \n  pass\n else:\n \n  for c in cls.__mro__:\n   if \"__slots__\" in c.__dict__:\n    slots = c.__dict__['__slots__']\n    \n    if isinstance(slots, str):\n     slots = (slots,)\n    for name in slots:\n    \n     if name in (\"__dict__\", \"__weakref__\"):\n      continue\n      \n     elif name.startswith('__') and not name.endswith('__'):\n      names.append('_%s%s' % (c.__name__, name))\n     else:\n      names.append(name)\n      \n      \n try:\n  cls.__slotnames__ = names\n except:\n  pass \n  \n return names\n \n \n \n \n \n \n \n \n \n \n_extension_registry = {} \n_inverted_registry = {} \n_extension_cache = {} \n\n\n\ndef add_extension(module, name, code):\n \"\"\n code = int(code)\n if not 1 <= code <= 0x7fffffff:\n  raise ValueError(\"code out of range\")\n key = (module, name)\n if (_extension_registry.get(key) == code and\n _inverted_registry.get(code) == key):\n  return \n if key in _extension_registry:\n  raise ValueError(\"key %s is already registered with code %s\" %\n  (key, _extension_registry[key]))\n if code in _inverted_registry:\n  raise ValueError(\"code %s is already in use for key %s\" %\n  (code, _inverted_registry[code]))\n _extension_registry[key] = code\n _inverted_registry[code] = key\n \ndef remove_extension(module, name, code):\n \"\"\n key = (module, name)\n if (_extension_registry.get(key) != code or\n _inverted_registry.get(code) != key):\n  raise ValueError(\"key %s is not registered with code %s\" %\n  (key, code))\n del _extension_registry[key]\n del _inverted_registry[code]\n if code in _extension_cache:\n  del _extension_cache[code]\n  \ndef clear_extension_cache():\n _extension_cache.clear()\n \n \n \n \n \n \n \n \n \n \n \n \n \n"], "pydoc_data.topics": [".py", "\n\ntopics = {'assert': '\\nThe ``assert`` statement\\n************************\\n\\nAssert statements are a convenient way to insert debugging assertions\\ninto a program:\\n\\n   assert_stmt ::= \"assert\" expression [\",\" expression]\\n\\nThe simple form, ``assert expression``, is equivalent to\\n\\n   if __debug__:\\n      if not expression: raise AssertionError\\n\\nThe extended form, ``assert expression1, expression2``, is equivalent\\nto\\n\\n   if __debug__:\\n      if not expression1: raise AssertionError(expression2)\\n\\nThese equivalences assume that ``__debug__`` and ``AssertionError``\\nrefer to the built-in variables with those names.  In the current\\nimplementation, the built-in variable ``__debug__`` is ``True`` under\\nnormal circumstances, ``False`` when optimization is requested\\n(command line option -O).  The current code generator emits no code\\nfor an assert statement when optimization is requested at compile\\ntime.  Note that it is unnecessary to include the source code for the\\nexpression that failed in the error message; it will be displayed as\\npart of the stack trace.\\n\\nAssignments to ``__debug__`` are illegal.  The value for the built-in\\nvariable is determined when the interpreter starts.\\n',\n'assignment': '\\nAssignment statements\\n*********************\\n\\nAssignment statements are used to (re)bind names to values and to\\nmodify attributes or items of mutable objects:\\n\\n   assignment_stmt ::= (target_list \"=\")+ (expression_list | yield_expression)\\n   target_list     ::= target (\",\" target)* [\",\"]\\n   target          ::= identifier\\n              | \"(\" target_list \")\"\\n              | \"[\" target_list \"]\"\\n              | attributeref\\n              | subscription\\n              | slicing\\n              | \"*\" target\\n\\n(See section *Primaries* for the syntax definitions for the last three\\nsymbols.)\\n\\nAn assignment statement evaluates the expression list (remember that\\nthis can be a single expression or a comma-separated list, the latter\\nyielding a tuple) and assigns the single resulting object to each of\\nthe target lists, from left to right.\\n\\nAssignment is defined recursively depending on the form of the target\\n(list). When a target is part of a mutable object (an attribute\\nreference, subscription or slicing), the mutable object must\\nultimately perform the assignment and decide about its validity, and\\nmay raise an exception if the assignment is unacceptable.  The rules\\nobserved by various types and the exceptions raised are given with the\\ndefinition of the object types (see section *The standard type\\nhierarchy*).\\n\\nAssignment of an object to a target list, optionally enclosed in\\nparentheses or square brackets, is recursively defined as follows.\\n\\n* If the target list is a single target: The object is assigned to\\n  that target.\\n\\n* If the target list is a comma-separated list of targets: The object\\n  must be an iterable with the same number of items as there are\\n  targets in the target list, and the items are assigned, from left to\\n  right, to the corresponding targets.\\n\\n  * If the target list contains one target prefixed with an asterisk,\\n    called a \"starred\" target: The object must be a sequence with at\\n    least as many items as there are targets in the target list, minus\\n    one.  The first items of the sequence are assigned, from left to\\n    right, to the targets before the starred target.  The final items\\n    of the sequence are assigned to the targets after the starred\\n    target.  A list of the remaining items in the sequence is then\\n    assigned to the starred target (the list can be empty).\\n\\n  * Else: The object must be a sequence with the same number of items\\n    as there are targets in the target list, and the items are\\n    assigned, from left to right, to the corresponding targets.\\n\\nAssignment of an object to a single target is recursively defined as\\nfollows.\\n\\n* If the target is an identifier (name):\\n\\n  * If the name does not occur in a ``global`` or ``nonlocal``\\n    statement in the current code block: the name is bound to the\\n    object in the current local namespace.\\n\\n  * Otherwise: the name is bound to the object in the global namespace\\n    or the outer namespace determined by ``nonlocal``, respectively.\\n\\n  The name is rebound if it was already bound.  This may cause the\\n  reference count for the object previously bound to the name to reach\\n  zero, causing the object to be deallocated and its destructor (if it\\n  has one) to be called.\\n\\n* If the target is a target list enclosed in parentheses or in square\\n  brackets: The object must be an iterable with the same number of\\n  items as there are targets in the target list, and its items are\\n  assigned, from left to right, to the corresponding targets.\\n\\n* If the target is an attribute reference: The primary expression in\\n  the reference is evaluated.  It should yield an object with\\n  assignable attributes; if this is not the case, ``TypeError`` is\\n  raised.  That object is then asked to assign the assigned object to\\n  the given attribute; if it cannot perform the assignment, it raises\\n  an exception (usually but not necessarily ``AttributeError``).\\n\\n  Note: If the object is a class instance and the attribute reference\\n  occurs on both sides of the assignment operator, the RHS expression,\\n  ``a.x`` can access either an instance attribute or (if no instance\\n  attribute exists) a class attribute.  The LHS target ``a.x`` is\\n  always set as an instance attribute, creating it if necessary.\\n  Thus, the two occurrences of ``a.x`` do not necessarily refer to the\\n  same attribute: if the RHS expression refers to a class attribute,\\n  the LHS creates a new instance attribute as the target of the\\n  assignment:\\n\\n     class Cls:\\n         x = 3             # class variable\\n     inst = Cls()\\n     inst.x = inst.x + 1   # writes inst.x as 4 leaving Cls.x as 3\\n\\n  This description does not necessarily apply to descriptor\\n  attributes, such as properties created with ``property()``.\\n\\n* If the target is a subscription: The primary expression in the\\n  reference is evaluated.  It should yield either a mutable sequence\\n  object (such as a list) or a mapping object (such as a dictionary).\\n  Next, the subscript expression is evaluated.\\n\\n  If the primary is a mutable sequence object (such as a list), the\\n  subscript must yield an integer.  If it is negative, the sequence\\'s\\n  length is added to it.  The resulting value must be a nonnegative\\n  integer less than the sequence\\'s length, and the sequence is asked\\n  to assign the assigned object to its item with that index.  If the\\n  index is out of range, ``IndexError`` is raised (assignment to a\\n  subscripted sequence cannot add new items to a list).\\n\\n  If the primary is a mapping object (such as a dictionary), the\\n  subscript must have a type compatible with the mapping\\'s key type,\\n  and the mapping is then asked to create a key/datum pair which maps\\n  the subscript to the assigned object.  This can either replace an\\n  existing key/value pair with the same key value, or insert a new\\n  key/value pair (if no key with the same value existed).\\n\\n  For user-defined objects, the ``__setitem__()`` method is called\\n  with appropriate arguments.\\n\\n* If the target is a slicing: The primary expression in the reference\\n  is evaluated.  It should yield a mutable sequence object (such as a\\n  list).  The assigned object should be a sequence object of the same\\n  type.  Next, the lower and upper bound expressions are evaluated,\\n  insofar they are present; defaults are zero and the sequence\\'s\\n  length.  The bounds should evaluate to integers. If either bound is\\n  negative, the sequence\\'s length is added to it.  The resulting\\n  bounds are clipped to lie between zero and the sequence\\'s length,\\n  inclusive.  Finally, the sequence object is asked to replace the\\n  slice with the items of the assigned sequence.  The length of the\\n  slice may be different from the length of the assigned sequence,\\n  thus changing the length of the target sequence, if the object\\n  allows it.\\n\\n**CPython implementation detail:** In the current implementation, the\\nsyntax for targets is taken to be the same as for expressions, and\\ninvalid syntax is rejected during the code generation phase, causing\\nless detailed error messages.\\n\\nWARNING: Although the definition of assignment implies that overlaps\\nbetween the left-hand side and the right-hand side are \\'safe\\' (for\\nexample ``a, b = b, a`` swaps two variables), overlaps *within* the\\ncollection of assigned-to variables are not safe!  For instance, the\\nfollowing program prints ``[0, 2]``:\\n\\n   x = [0, 1]\\n   i = 0\\n   i, x[i] = 1, 2\\n   print(x)\\n\\nSee also:\\n\\n   **PEP 3132** - Extended Iterable Unpacking\\n      The specification for the ``*target`` feature.\\n\\n\\nAugmented assignment statements\\n===============================\\n\\nAugmented assignment is the combination, in a single statement, of a\\nbinary operation and an assignment statement:\\n\\n   augmented_assignment_stmt ::= augtarget augop (expression_list | yield_expression)\\n   augtarget                 ::= identifier | attributeref | subscription | slicing\\n   augop                     ::= \"+=\" | \"-=\" | \"*=\" | \"/=\" | \"//=\" | \"%=\" | \"**=\"\\n             | \">>=\" | \"<<=\" | \"&=\" | \"^=\" | \"|=\"\\n\\n(See section *Primaries* for the syntax definitions for the last three\\nsymbols.)\\n\\nAn augmented assignment evaluates the target (which, unlike normal\\nassignment statements, cannot be an unpacking) and the expression\\nlist, performs the binary operation specific to the type of assignment\\non the two operands, and assigns the result to the original target.\\nThe target is only evaluated once.\\n\\nAn augmented assignment expression like ``x += 1`` can be rewritten as\\n``x = x + 1`` to achieve a similar, but not exactly equal effect. In\\nthe augmented version, ``x`` is only evaluated once. Also, when\\npossible, the actual operation is performed *in-place*, meaning that\\nrather than creating a new object and assigning that to the target,\\nthe old object is modified instead.\\n\\nWith the exception of assigning to tuples and multiple targets in a\\nsingle statement, the assignment done by augmented assignment\\nstatements is handled the same way as normal assignments. Similarly,\\nwith the exception of the possible *in-place* behavior, the binary\\noperation performed by augmented assignment is the same as the normal\\nbinary operations.\\n\\nFor targets which are attribute references, the same *caveat about\\nclass and instance attributes* applies as for regular assignments.\\n',\n'atom-identifiers': '\\nIdentifiers (Names)\\n*******************\\n\\nAn identifier occurring as an atom is a name.  See section\\n*Identifiers and keywords* for lexical definition and section *Naming\\nand binding* for documentation of naming and binding.\\n\\nWhen the name is bound to an object, evaluation of the atom yields\\nthat object. When a name is not bound, an attempt to evaluate it\\nraises a ``NameError`` exception.\\n\\n**Private name mangling:** When an identifier that textually occurs in\\na class definition begins with two or more underscore characters and\\ndoes not end in two or more underscores, it is considered a *private\\nname* of that class. Private names are transformed to a longer form\\nbefore code is generated for them.  The transformation inserts the\\nclass name in front of the name, with leading underscores removed, and\\na single underscore inserted in front of the class name.  For example,\\nthe identifier ``__spam`` occurring in a class named ``Ham`` will be\\ntransformed to ``_Ham__spam``.  This transformation is independent of\\nthe syntactical context in which the identifier is used.  If the\\ntransformed name is extremely long (longer than 255 characters),\\nimplementation defined truncation may happen.  If the class name\\nconsists only of underscores, no transformation is done.\\n',\n'atom-literals': \"\\nLiterals\\n********\\n\\nPython supports string and bytes literals and various numeric\\nliterals:\\n\\n   literal ::= stringliteral | bytesliteral\\n               | integer | floatnumber | imagnumber\\n\\nEvaluation of a literal yields an object of the given type (string,\\nbytes, integer, floating point number, complex number) with the given\\nvalue.  The value may be approximated in the case of floating point\\nand imaginary (complex) literals.  See section *Literals* for details.\\n\\nAll literals correspond to immutable data types, and hence the\\nobject's identity is less important than its value.  Multiple\\nevaluations of literals with the same value (either the same\\noccurrence in the program text or a different occurrence) may obtain\\nthe same object or a different object with the same value.\\n\",\n'attribute-access': '\\nCustomizing attribute access\\n****************************\\n\\nThe following methods can be defined to customize the meaning of\\nattribute access (use of, assignment to, or deletion of ``x.name``)\\nfor class instances.\\n\\nobject.__getattr__(self, name)\\n\\n   Called when an attribute lookup has not found the attribute in the\\n   usual places (i.e. it is not an instance attribute nor is it found\\n   in the class tree for ``self``).  ``name`` is the attribute name.\\n   This method should return the (computed) attribute value or raise\\n   an ``AttributeError`` exception.\\n\\n   Note that if the attribute is found through the normal mechanism,\\n   ``__getattr__()`` is not called.  (This is an intentional asymmetry\\n   between ``__getattr__()`` and ``__setattr__()``.) This is done both\\n   for efficiency reasons and because otherwise ``__getattr__()``\\n   would have no way to access other attributes of the instance.  Note\\n   that at least for instance variables, you can fake total control by\\n   not inserting any values in the instance attribute dictionary (but\\n   instead inserting them in another object).  See the\\n   ``__getattribute__()`` method below for a way to actually get total\\n   control over attribute access.\\n\\nobject.__getattribute__(self, name)\\n\\n   Called unconditionally to implement attribute accesses for\\n   instances of the class. If the class also defines\\n   ``__getattr__()``, the latter will not be called unless\\n   ``__getattribute__()`` either calls it explicitly or raises an\\n   ``AttributeError``. This method should return the (computed)\\n   attribute value or raise an ``AttributeError`` exception. In order\\n   to avoid infinite recursion in this method, its implementation\\n   should always call the base class method with the same name to\\n   access any attributes it needs, for example,\\n   ``object.__getattribute__(self, name)``.\\n\\n   Note: This method may still be bypassed when looking up special methods\\n     as the result of implicit invocation via language syntax or\\n     built-in functions. See *Special method lookup*.\\n\\nobject.__setattr__(self, name, value)\\n\\n   Called when an attribute assignment is attempted.  This is called\\n   instead of the normal mechanism (i.e. store the value in the\\n   instance dictionary). *name* is the attribute name, *value* is the\\n   value to be assigned to it.\\n\\n   If ``__setattr__()`` wants to assign to an instance attribute, it\\n   should call the base class method with the same name, for example,\\n   ``object.__setattr__(self, name, value)``.\\n\\nobject.__delattr__(self, name)\\n\\n   Like ``__setattr__()`` but for attribute deletion instead of\\n   assignment.  This should only be implemented if ``del obj.name`` is\\n   meaningful for the object.\\n\\nobject.__dir__(self)\\n\\n   Called when ``dir()`` is called on the object. A sequence must be\\n   returned. ``dir()`` converts the returned sequence to a list and\\n   sorts it.\\n\\n\\nImplementing Descriptors\\n========================\\n\\nThe following methods only apply when an instance of the class\\ncontaining the method (a so-called *descriptor* class) appears in an\\n*owner* class (the descriptor must be in either the owner\\'s class\\ndictionary or in the class dictionary for one of its parents).  In the\\nexamples below, \"the attribute\" refers to the attribute whose name is\\nthe key of the property in the owner class\\' ``__dict__``.\\n\\nobject.__get__(self, instance, owner)\\n\\n   Called to get the attribute of the owner class (class attribute\\n   access) or of an instance of that class (instance attribute\\n   access). *owner* is always the owner class, while *instance* is the\\n   instance that the attribute was accessed through, or ``None`` when\\n   the attribute is accessed through the *owner*.  This method should\\n   return the (computed) attribute value or raise an\\n   ``AttributeError`` exception.\\n\\nobject.__set__(self, instance, value)\\n\\n   Called to set the attribute on an instance *instance* of the owner\\n   class to a new value, *value*.\\n\\nobject.__delete__(self, instance)\\n\\n   Called to delete the attribute on an instance *instance* of the\\n   owner class.\\n\\n\\nInvoking Descriptors\\n====================\\n\\nIn general, a descriptor is an object attribute with \"binding\\nbehavior\", one whose attribute access has been overridden by methods\\nin the descriptor protocol:  ``__get__()``, ``__set__()``, and\\n``__delete__()``. If any of those methods are defined for an object,\\nit is said to be a descriptor.\\n\\nThe default behavior for attribute access is to get, set, or delete\\nthe attribute from an object\\'s dictionary. For instance, ``a.x`` has a\\nlookup chain starting with ``a.__dict__[\\'x\\']``, then\\n``type(a).__dict__[\\'x\\']``, and continuing through the base classes of\\n``type(a)`` excluding metaclasses.\\n\\nHowever, if the looked-up value is an object defining one of the\\ndescriptor methods, then Python may override the default behavior and\\ninvoke the descriptor method instead.  Where this occurs in the\\nprecedence chain depends on which descriptor methods were defined and\\nhow they were called.\\n\\nThe starting point for descriptor invocation is a binding, ``a.x``.\\nHow the arguments are assembled depends on ``a``:\\n\\nDirect Call\\n   The simplest and least common call is when user code directly\\n   invokes a descriptor method:    ``x.__get__(a)``.\\n\\nInstance Binding\\n   If binding to an object instance, ``a.x`` is transformed into the\\n   call: ``type(a).__dict__[\\'x\\'].__get__(a, type(a))``.\\n\\nClass Binding\\n   If binding to a class, ``A.x`` is transformed into the call:\\n   ``A.__dict__[\\'x\\'].__get__(None, A)``.\\n\\nSuper Binding\\n   If ``a`` is an instance of ``super``, then the binding ``super(B,\\n   obj).m()`` searches ``obj.__class__.__mro__`` for the base class\\n   ``A`` immediately preceding ``B`` and then invokes the descriptor\\n   with the call: ``A.__dict__[\\'m\\'].__get__(obj, obj.__class__)``.\\n\\nFor instance bindings, the precedence of descriptor invocation depends\\non the which descriptor methods are defined.  A descriptor can define\\nany combination of ``__get__()``, ``__set__()`` and ``__delete__()``.\\nIf it does not define ``__get__()``, then accessing the attribute will\\nreturn the descriptor object itself unless there is a value in the\\nobject\\'s instance dictionary.  If the descriptor defines ``__set__()``\\nand/or ``__delete__()``, it is a data descriptor; if it defines\\nneither, it is a non-data descriptor.  Normally, data descriptors\\ndefine both ``__get__()`` and ``__set__()``, while non-data\\ndescriptors have just the ``__get__()`` method.  Data descriptors with\\n``__set__()`` and ``__get__()`` defined always override a redefinition\\nin an instance dictionary.  In contrast, non-data descriptors can be\\noverridden by instances.\\n\\nPython methods (including ``staticmethod()`` and ``classmethod()``)\\nare implemented as non-data descriptors.  Accordingly, instances can\\nredefine and override methods.  This allows individual instances to\\nacquire behaviors that differ from other instances of the same class.\\n\\nThe ``property()`` function is implemented as a data descriptor.\\nAccordingly, instances cannot override the behavior of a property.\\n\\n\\n__slots__\\n=========\\n\\nBy default, instances of classes have a dictionary for attribute\\nstorage.  This wastes space for objects having very few instance\\nvariables.  The space consumption can become acute when creating large\\nnumbers of instances.\\n\\nThe default can be overridden by defining *__slots__* in a class\\ndefinition. The *__slots__* declaration takes a sequence of instance\\nvariables and reserves just enough space in each instance to hold a\\nvalue for each variable.  Space is saved because *__dict__* is not\\ncreated for each instance.\\n\\nobject.__slots__\\n\\n   This class variable can be assigned a string, iterable, or sequence\\n   of strings with variable names used by instances.  If defined in a\\n   class, *__slots__* reserves space for the declared variables and\\n   prevents the automatic creation of *__dict__* and *__weakref__* for\\n   each instance.\\n\\n\\nNotes on using *__slots__*\\n--------------------------\\n\\n* When inheriting from a class without *__slots__*, the *__dict__*\\n  attribute of that class will always be accessible, so a *__slots__*\\n  definition in the subclass is meaningless.\\n\\n* Without a *__dict__* variable, instances cannot be assigned new\\n  variables not listed in the *__slots__* definition.  Attempts to\\n  assign to an unlisted variable name raises ``AttributeError``. If\\n  dynamic assignment of new variables is desired, then add\\n  ``\\'__dict__\\'`` to the sequence of strings in the *__slots__*\\n  declaration.\\n\\n* Without a *__weakref__* variable for each instance, classes defining\\n  *__slots__* do not support weak references to its instances. If weak\\n  reference support is needed, then add ``\\'__weakref__\\'`` to the\\n  sequence of strings in the *__slots__* declaration.\\n\\n* *__slots__* are implemented at the class level by creating\\n  descriptors (*Implementing Descriptors*) for each variable name.  As\\n  a result, class attributes cannot be used to set default values for\\n  instance variables defined by *__slots__*; otherwise, the class\\n  attribute would overwrite the descriptor assignment.\\n\\n* The action of a *__slots__* declaration is limited to the class\\n  where it is defined.  As a result, subclasses will have a *__dict__*\\n  unless they also define *__slots__* (which must only contain names\\n  of any *additional* slots).\\n\\n* If a class defines a slot also defined in a base class, the instance\\n  variable defined by the base class slot is inaccessible (except by\\n  retrieving its descriptor directly from the base class). This\\n  renders the meaning of the program undefined.  In the future, a\\n  check may be added to prevent this.\\n\\n* Nonempty *__slots__* does not work for classes derived from\\n  \"variable-length\" built-in types such as ``int``, ``str`` and\\n  ``tuple``.\\n\\n* Any non-string iterable may be assigned to *__slots__*. Mappings may\\n  also be used; however, in the future, special meaning may be\\n  assigned to the values corresponding to each key.\\n\\n* *__class__* assignment works only if both classes have the same\\n  *__slots__*.\\n',\n'attribute-references': '\\nAttribute references\\n********************\\n\\nAn attribute reference is a primary followed by a period and a name:\\n\\n   attributeref ::= primary \".\" identifier\\n\\nThe primary must evaluate to an object of a type that supports\\nattribute references, which most objects do.  This object is then\\nasked to produce the attribute whose name is the identifier (which can\\nbe customized by overriding the ``__getattr__()`` method).  If this\\nattribute is not available, the exception ``AttributeError`` is\\nraised.  Otherwise, the type and value of the object produced is\\ndetermined by the object.  Multiple evaluations of the same attribute\\nreference may yield different objects.\\n',\n'augassign': '\\nAugmented assignment statements\\n*******************************\\n\\nAugmented assignment is the combination, in a single statement, of a\\nbinary operation and an assignment statement:\\n\\n   augmented_assignment_stmt ::= augtarget augop (expression_list | yield_expression)\\n   augtarget                 ::= identifier | attributeref | subscription | slicing\\n   augop                     ::= \"+=\" | \"-=\" | \"*=\" | \"/=\" | \"//=\" | \"%=\" | \"**=\"\\n             | \">>=\" | \"<<=\" | \"&=\" | \"^=\" | \"|=\"\\n\\n(See section *Primaries* for the syntax definitions for the last three\\nsymbols.)\\n\\nAn augmented assignment evaluates the target (which, unlike normal\\nassignment statements, cannot be an unpacking) and the expression\\nlist, performs the binary operation specific to the type of assignment\\non the two operands, and assigns the result to the original target.\\nThe target is only evaluated once.\\n\\nAn augmented assignment expression like ``x += 1`` can be rewritten as\\n``x = x + 1`` to achieve a similar, but not exactly equal effect. In\\nthe augmented version, ``x`` is only evaluated once. Also, when\\npossible, the actual operation is performed *in-place*, meaning that\\nrather than creating a new object and assigning that to the target,\\nthe old object is modified instead.\\n\\nWith the exception of assigning to tuples and multiple targets in a\\nsingle statement, the assignment done by augmented assignment\\nstatements is handled the same way as normal assignments. Similarly,\\nwith the exception of the possible *in-place* behavior, the binary\\noperation performed by augmented assignment is the same as the normal\\nbinary operations.\\n\\nFor targets which are attribute references, the same *caveat about\\nclass and instance attributes* applies as for regular assignments.\\n',\n'binary': '\\nBinary arithmetic operations\\n****************************\\n\\nThe binary arithmetic operations have the conventional priority\\nlevels.  Note that some of these operations also apply to certain non-\\nnumeric types.  Apart from the power operator, there are only two\\nlevels, one for multiplicative operators and one for additive\\noperators:\\n\\n   m_expr ::= u_expr | m_expr \"*\" u_expr | m_expr \"//\" u_expr | m_expr \"/\" u_expr\\n              | m_expr \"%\" u_expr\\n   a_expr ::= m_expr | a_expr \"+\" m_expr | a_expr \"-\" m_expr\\n\\nThe ``*`` (multiplication) operator yields the product of its\\narguments.  The arguments must either both be numbers, or one argument\\nmust be an integer and the other must be a sequence. In the former\\ncase, the numbers are converted to a common type and then multiplied\\ntogether.  In the latter case, sequence repetition is performed; a\\nnegative repetition factor yields an empty sequence.\\n\\nThe ``/`` (division) and ``//`` (floor division) operators yield the\\nquotient of their arguments.  The numeric arguments are first\\nconverted to a common type. Integer division yields a float, while\\nfloor division of integers results in an integer; the result is that\\nof mathematical division with the \\'floor\\' function applied to the\\nresult.  Division by zero raises the ``ZeroDivisionError`` exception.\\n\\nThe ``%`` (modulo) operator yields the remainder from the division of\\nthe first argument by the second.  The numeric arguments are first\\nconverted to a common type.  A zero right argument raises the\\n``ZeroDivisionError`` exception.  The arguments may be floating point\\nnumbers, e.g., ``3.14%0.7`` equals ``0.34`` (since ``3.14`` equals\\n``4*0.7 + 0.34``.)  The modulo operator always yields a result with\\nthe same sign as its second operand (or zero); the absolute value of\\nthe result is strictly smaller than the absolute value of the second\\noperand [1].\\n\\nThe floor division and modulo operators are connected by the following\\nidentity: ``x == (x//y)*y + (x%y)``.  Floor division and modulo are\\nalso connected with the built-in function ``divmod()``: ``divmod(x, y)\\n== (x//y, x%y)``. [2].\\n\\nIn addition to performing the modulo operation on numbers, the ``%``\\noperator is also overloaded by string objects to perform old-style\\nstring formatting (also known as interpolation).  The syntax for\\nstring formatting is described in the Python Library Reference,\\nsection *printf-style String Formatting*.\\n\\nThe floor division operator, the modulo operator, and the ``divmod()``\\nfunction are not defined for complex numbers.  Instead, convert to a\\nfloating point number using the ``abs()`` function if appropriate.\\n\\nThe ``+`` (addition) operator yields the sum of its arguments.  The\\narguments must either both be numbers or both sequences of the same\\ntype.  In the former case, the numbers are converted to a common type\\nand then added together.  In the latter case, the sequences are\\nconcatenated.\\n\\nThe ``-`` (subtraction) operator yields the difference of its\\narguments.  The numeric arguments are first converted to a common\\ntype.\\n',\n'bitwise': '\\nBinary bitwise operations\\n*************************\\n\\nEach of the three bitwise operations has a different priority level:\\n\\n   and_expr ::= shift_expr | and_expr \"&\" shift_expr\\n   xor_expr ::= and_expr | xor_expr \"^\" and_expr\\n   or_expr  ::= xor_expr | or_expr \"|\" xor_expr\\n\\nThe ``&`` operator yields the bitwise AND of its arguments, which must\\nbe integers.\\n\\nThe ``^`` operator yields the bitwise XOR (exclusive OR) of its\\narguments, which must be integers.\\n\\nThe ``|`` operator yields the bitwise (inclusive) OR of its arguments,\\nwhich must be integers.\\n',\n'bltin-code-objects': '\\nCode Objects\\n************\\n\\nCode objects are used by the implementation to represent \"pseudo-\\ncompiled\" executable Python code such as a function body. They differ\\nfrom function objects because they don\\'t contain a reference to their\\nglobal execution environment.  Code objects are returned by the built-\\nin ``compile()`` function and can be extracted from function objects\\nthrough their ``__code__`` attribute. See also the ``code`` module.\\n\\nA code object can be executed or evaluated by passing it (instead of a\\nsource string) to the ``exec()`` or ``eval()``  built-in functions.\\n\\nSee *The standard type hierarchy* for more information.\\n',\n'bltin-ellipsis-object': '\\nThe Ellipsis Object\\n*******************\\n\\nThis object is commonly used by slicing (see *Slicings*).  It supports\\nno special operations.  There is exactly one ellipsis object, named\\n``Ellipsis`` (a built-in name).  ``type(Ellipsis)()`` produces the\\n``Ellipsis`` singleton.\\n\\nIt is written as ``Ellipsis`` or ``...``.\\n',\n'bltin-null-object': \"\\nThe Null Object\\n***************\\n\\nThis object is returned by functions that don't explicitly return a\\nvalue.  It supports no special operations.  There is exactly one null\\nobject, named ``None`` (a built-in name).  ``type(None)()`` produces\\nthe same singleton.\\n\\nIt is written as ``None``.\\n\",\n'bltin-type-objects': \"\\nType Objects\\n************\\n\\nType objects represent the various object types.  An object's type is\\naccessed by the built-in function ``type()``.  There are no special\\noperations on types.  The standard module ``types`` defines names for\\nall standard built-in types.\\n\\nTypes are written like this: ``<class 'int'>``.\\n\",\n'booleans': '\\nBoolean operations\\n******************\\n\\n   or_test  ::= and_test | or_test \"or\" and_test\\n   and_test ::= not_test | and_test \"and\" not_test\\n   not_test ::= comparison | \"not\" not_test\\n\\nIn the context of Boolean operations, and also when expressions are\\nused by control flow statements, the following values are interpreted\\nas false: ``False``, ``None``, numeric zero of all types, and empty\\nstrings and containers (including strings, tuples, lists,\\ndictionaries, sets and frozensets).  All other values are interpreted\\nas true.  User-defined objects can customize their truth value by\\nproviding a ``__bool__()`` method.\\n\\nThe operator ``not`` yields ``True`` if its argument is false,\\n``False`` otherwise.\\n\\nThe expression ``x and y`` first evaluates *x*; if *x* is false, its\\nvalue is returned; otherwise, *y* is evaluated and the resulting value\\nis returned.\\n\\nThe expression ``x or y`` first evaluates *x*; if *x* is true, its\\nvalue is returned; otherwise, *y* is evaluated and the resulting value\\nis returned.\\n\\n(Note that neither ``and`` nor ``or`` restrict the value and type they\\nreturn to ``False`` and ``True``, but rather return the last evaluated\\nargument.  This is sometimes useful, e.g., if ``s`` is a string that\\nshould be replaced by a default value if it is empty, the expression\\n``s or \\'foo\\'`` yields the desired value.  Because ``not`` has to\\ninvent a value anyway, it does not bother to return a value of the\\nsame type as its argument, so e.g., ``not \\'foo\\'`` yields ``False``,\\nnot ``\\'\\'``.)\\n',\n'break': '\\nThe ``break`` statement\\n***********************\\n\\n   break_stmt ::= \"break\"\\n\\n``break`` may only occur syntactically nested in a ``for`` or\\n``while`` loop, but not nested in a function or class definition\\nwithin that loop.\\n\\nIt terminates the nearest enclosing loop, skipping the optional\\n``else`` clause if the loop has one.\\n\\nIf a ``for`` loop is terminated by ``break``, the loop control target\\nkeeps its current value.\\n\\nWhen ``break`` passes control out of a ``try`` statement with a\\n``finally`` clause, that ``finally`` clause is executed before really\\nleaving the loop.\\n',\n'callable-types': '\\nEmulating callable objects\\n**************************\\n\\nobject.__call__(self[, args...])\\n\\n   Called when the instance is \"called\" as a function; if this method\\n   is defined, ``x(arg1, arg2, ...)`` is a shorthand for\\n   ``x.__call__(arg1, arg2, ...)``.\\n',\n'calls': '\\nCalls\\n*****\\n\\nA call calls a callable object (e.g., a *function*) with a possibly\\nempty series of *arguments*:\\n\\n   call                 ::= primary \"(\" [argument_list [\",\"] | comprehension] \")\"\\n   argument_list        ::= positional_arguments [\",\" keyword_arguments]\\n                       [\",\" \"*\" expression] [\",\" keyword_arguments]\\n                       [\",\" \"**\" expression]\\n                     | keyword_arguments [\",\" \"*\" expression]\\n                       [\",\" keyword_arguments] [\",\" \"**\" expression]\\n                     | \"*\" expression [\",\" keyword_arguments] [\",\" \"**\" expression]\\n                     | \"**\" expression\\n   positional_arguments ::= expression (\",\" expression)*\\n   keyword_arguments    ::= keyword_item (\",\" keyword_item)*\\n   keyword_item         ::= identifier \"=\" expression\\n\\nA trailing comma may be present after the positional and keyword\\narguments but does not affect the semantics.\\n\\nThe primary must evaluate to a callable object (user-defined\\nfunctions, built-in functions, methods of built-in objects, class\\nobjects, methods of class instances, and all objects having a\\n``__call__()`` method are callable).  All argument expressions are\\nevaluated before the call is attempted.  Please refer to section\\n*Function definitions* for the syntax of formal *parameter* lists.\\n\\nIf keyword arguments are present, they are first converted to\\npositional arguments, as follows.  First, a list of unfilled slots is\\ncreated for the formal parameters.  If there are N positional\\narguments, they are placed in the first N slots.  Next, for each\\nkeyword argument, the identifier is used to determine the\\ncorresponding slot (if the identifier is the same as the first formal\\nparameter name, the first slot is used, and so on).  If the slot is\\nalready filled, a ``TypeError`` exception is raised. Otherwise, the\\nvalue of the argument is placed in the slot, filling it (even if the\\nexpression is ``None``, it fills the slot).  When all arguments have\\nbeen processed, the slots that are still unfilled are filled with the\\ncorresponding default value from the function definition.  (Default\\nvalues are calculated, once, when the function is defined; thus, a\\nmutable object such as a list or dictionary used as default value will\\nbe shared by all calls that don\\'t specify an argument value for the\\ncorresponding slot; this should usually be avoided.)  If there are any\\nunfilled slots for which no default value is specified, a\\n``TypeError`` exception is raised.  Otherwise, the list of filled\\nslots is used as the argument list for the call.\\n\\n**CPython implementation detail:** An implementation may provide\\nbuilt-in functions whose positional parameters do not have names, even\\nif they are \\'named\\' for the purpose of documentation, and which\\ntherefore cannot be supplied by keyword.  In CPython, this is the case\\nfor functions implemented in C that use ``PyArg_ParseTuple()`` to\\nparse their arguments.\\n\\nIf there are more positional arguments than there are formal parameter\\nslots, a ``TypeError`` exception is raised, unless a formal parameter\\nusing the syntax ``*identifier`` is present; in this case, that formal\\nparameter receives a tuple containing the excess positional arguments\\n(or an empty tuple if there were no excess positional arguments).\\n\\nIf any keyword argument does not correspond to a formal parameter\\nname, a ``TypeError`` exception is raised, unless a formal parameter\\nusing the syntax ``**identifier`` is present; in this case, that\\nformal parameter receives a dictionary containing the excess keyword\\narguments (using the keywords as keys and the argument values as\\ncorresponding values), or a (new) empty dictionary if there were no\\nexcess keyword arguments.\\n\\nIf the syntax ``*expression`` appears in the function call,\\n``expression`` must evaluate to an iterable.  Elements from this\\niterable are treated as if they were additional positional arguments;\\nif there are positional arguments *x1*, ..., *xN*, and ``expression``\\nevaluates to a sequence *y1*, ..., *yM*, this is equivalent to a call\\nwith M+N positional arguments *x1*, ..., *xN*, *y1*, ..., *yM*.\\n\\nA consequence of this is that although the ``*expression`` syntax may\\nappear *after* some keyword arguments, it is processed *before* the\\nkeyword arguments (and the ``**expression`` argument, if any -- see\\nbelow).  So:\\n\\n   >>> def f(a, b):\\n   ...  print(a, b)\\n   ...\\n   >>> f(b=1, *(2,))\\n   2 1\\n   >>> f(a=1, *(2,))\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 1, in ?\\n   TypeError: f() got multiple values for keyword argument \\'a\\'\\n   >>> f(1, *(2,))\\n   1 2\\n\\nIt is unusual for both keyword arguments and the ``*expression``\\nsyntax to be used in the same call, so in practice this confusion does\\nnot arise.\\n\\nIf the syntax ``**expression`` appears in the function call,\\n``expression`` must evaluate to a mapping, the contents of which are\\ntreated as additional keyword arguments.  In the case of a keyword\\nappearing in both ``expression`` and as an explicit keyword argument,\\na ``TypeError`` exception is raised.\\n\\nFormal parameters using the syntax ``*identifier`` or ``**identifier``\\ncannot be used as positional argument slots or as keyword argument\\nnames.\\n\\nA call always returns some value, possibly ``None``, unless it raises\\nan exception.  How this value is computed depends on the type of the\\ncallable object.\\n\\nIf it is---\\n\\na user-defined function:\\n   The code block for the function is executed, passing it the\\n   argument list.  The first thing the code block will do is bind the\\n   formal parameters to the arguments; this is described in section\\n   *Function definitions*.  When the code block executes a ``return``\\n   statement, this specifies the return value of the function call.\\n\\na built-in function or method:\\n   The result is up to the interpreter; see *Built-in Functions* for\\n   the descriptions of built-in functions and methods.\\n\\na class object:\\n   A new instance of that class is returned.\\n\\na class instance method:\\n   The corresponding user-defined function is called, with an argument\\n   list that is one longer than the argument list of the call: the\\n   instance becomes the first argument.\\n\\na class instance:\\n   The class must define a ``__call__()`` method; the effect is then\\n   the same as if that method was called.\\n',\n'class': '\\nClass definitions\\n*****************\\n\\nA class definition defines a class object (see section *The standard\\ntype hierarchy*):\\n\\n   classdef    ::= [decorators] \"class\" classname [inheritance] \":\" suite\\n   inheritance ::= \"(\" [parameter_list] \")\"\\n   classname   ::= identifier\\n\\nA class definition is an executable statement.  The inheritance list\\nusually gives a list of base classes (see *Customizing class creation*\\nfor more advanced uses), so each item in the list should evaluate to a\\nclass object which allows subclassing.  Classes without an inheritance\\nlist inherit, by default, from the base class ``object``; hence,\\n\\n   class Foo:\\n       pass\\n\\nis equivalent to\\n\\n   class Foo(object):\\n       pass\\n\\nThe class\\'s suite is then executed in a new execution frame (see\\n*Naming and binding*), using a newly created local namespace and the\\noriginal global namespace. (Usually, the suite contains mostly\\nfunction definitions.)  When the class\\'s suite finishes execution, its\\nexecution frame is discarded but its local namespace is saved. [4] A\\nclass object is then created using the inheritance list for the base\\nclasses and the saved local namespace for the attribute dictionary.\\nThe class name is bound to this class object in the original local\\nnamespace.\\n\\nClass creation can be customized heavily using *metaclasses*.\\n\\nClasses can also be decorated: just like when decorating functions,\\n\\n   @f1(arg)\\n   @f2\\n   class Foo: pass\\n\\nis equivalent to\\n\\n   class Foo: pass\\n   Foo = f1(arg)(f2(Foo))\\n\\nThe evaluation rules for the decorator expressions are the same as for\\nfunction decorators.  The result must be a class object, which is then\\nbound to the class name.\\n\\n**Programmer\\'s note:** Variables defined in the class definition are\\nclass attributes; they are shared by instances.  Instance attributes\\ncan be set in a method with ``self.name = value``.  Both class and\\ninstance attributes are accessible through the notation\\n\"``self.name``\", and an instance attribute hides a class attribute\\nwith the same name when accessed in this way.  Class attributes can be\\nused as defaults for instance attributes, but using mutable values\\nthere can lead to unexpected results.  *Descriptors* can be used to\\ncreate instance variables with different implementation details.\\n\\nSee also:\\n\\n   **PEP 3115** - Metaclasses in Python 3 **PEP 3129** - Class\\n   Decorators\\n\\n-[ Footnotes ]-\\n\\n[1] The exception is propagated to the invocation stack unless there\\n    is a ``finally`` clause which happens to raise another exception.\\n    That new exception causes the old one to be lost.\\n\\n[2] Currently, control \"flows off the end\" except in the case of an\\n    exception or the execution of a ``return``, ``continue``, or\\n    ``break`` statement.\\n\\n[3] A string literal appearing as the first statement in the function\\n    body is transformed into the function\\'s ``__doc__`` attribute and\\n    therefore the function\\'s *docstring*.\\n\\n[4] A string literal appearing as the first statement in the class\\n    body is transformed into the namespace\\'s ``__doc__`` item and\\n    therefore the class\\'s *docstring*.\\n',\n'comparisons': '\\nComparisons\\n***********\\n\\nUnlike C, all comparison operations in Python have the same priority,\\nwhich is lower than that of any arithmetic, shifting or bitwise\\noperation.  Also unlike C, expressions like ``a < b < c`` have the\\ninterpretation that is conventional in mathematics:\\n\\n   comparison    ::= or_expr ( comp_operator or_expr )*\\n   comp_operator ::= \"<\" | \">\" | \"==\" | \">=\" | \"<=\" | \"!=\"\\n                     | \"is\" [\"not\"] | [\"not\"] \"in\"\\n\\nComparisons yield boolean values: ``True`` or ``False``.\\n\\nComparisons can be chained arbitrarily, e.g., ``x < y <= z`` is\\nequivalent to ``x < y and y <= z``, except that ``y`` is evaluated\\nonly once (but in both cases ``z`` is not evaluated at all when ``x <\\ny`` is found to be false).\\n\\nFormally, if *a*, *b*, *c*, ..., *y*, *z* are expressions and *op1*,\\n*op2*, ..., *opN* are comparison operators, then ``a op1 b op2 c ... y\\nopN z`` is equivalent to ``a op1 b and b op2 c and ... y opN z``,\\nexcept that each expression is evaluated at most once.\\n\\nNote that ``a op1 b op2 c`` doesn\\'t imply any kind of comparison\\nbetween *a* and *c*, so that, e.g., ``x < y > z`` is perfectly legal\\n(though perhaps not pretty).\\n\\nThe operators ``<``, ``>``, ``==``, ``>=``, ``<=``, and ``!=`` compare\\nthe values of two objects.  The objects need not have the same type.\\nIf both are numbers, they are converted to a common type.  Otherwise,\\nthe ``==`` and ``!=`` operators *always* consider objects of different\\ntypes to be unequal, while the ``<``, ``>``, ``>=`` and ``<=``\\noperators raise a ``TypeError`` when comparing objects of different\\ntypes that do not implement these operators for the given pair of\\ntypes.  You can control comparison behavior of objects of non-built-in\\ntypes by defining rich comparison methods like ``__gt__()``, described\\nin section *Basic customization*.\\n\\nComparison of objects of the same type depends on the type:\\n\\n* Numbers are compared arithmetically.\\n\\n* The values ``float(\\'NaN\\')`` and ``Decimal(\\'NaN\\')`` are special. The\\n  are identical to themselves, ``x is x`` but are not equal to\\n  themselves, ``x != x``.  Additionally, comparing any value to a\\n  not-a-number value will return ``False``.  For example, both ``3 <\\n  float(\\'NaN\\')`` and ``float(\\'NaN\\') < 3`` will return ``False``.\\n\\n* Bytes objects are compared lexicographically using the numeric\\n  values of their elements.\\n\\n* Strings are compared lexicographically using the numeric equivalents\\n  (the result of the built-in function ``ord()``) of their characters.\\n  [3] String and bytes object can\\'t be compared!\\n\\n* Tuples and lists are compared lexicographically using comparison of\\n  corresponding elements.  This means that to compare equal, each\\n  element must compare equal and the two sequences must be of the same\\n  type and have the same length.\\n\\n  If not equal, the sequences are ordered the same as their first\\n  differing elements.  For example, ``[1,2,x] <= [1,2,y]`` has the\\n  same value as ``x <= y``.  If the corresponding element does not\\n  exist, the shorter sequence is ordered first (for example, ``[1,2] <\\n  [1,2,3]``).\\n\\n* Mappings (dictionaries) compare equal if and only if they have the\\n  same ``(key, value)`` pairs. Order comparisons ``(\\'<\\', \\'<=\\', \\'>=\\',\\n  \\'>\\')`` raise ``TypeError``.\\n\\n* Sets and frozensets define comparison operators to mean subset and\\n  superset tests.  Those relations do not define total orderings (the\\n  two sets ``{1,2}`` and {2,3} are not equal, nor subsets of one\\n  another, nor supersets of one another).  Accordingly, sets are not\\n  appropriate arguments for functions which depend on total ordering.\\n  For example, ``min()``, ``max()``, and ``sorted()`` produce\\n  undefined results given a list of sets as inputs.\\n\\n* Most other objects of built-in types compare unequal unless they are\\n  the same object; the choice whether one object is considered smaller\\n  or larger than another one is made arbitrarily but consistently\\n  within one execution of a program.\\n\\nComparison of objects of the differing types depends on whether either\\nof the types provide explicit support for the comparison.  Most\\nnumeric types can be compared with one another.  When cross-type\\ncomparison is not supported, the comparison method returns\\n``NotImplemented``.\\n\\nThe operators ``in`` and ``not in`` test for membership.  ``x in s``\\nevaluates to true if *x* is a member of *s*, and false otherwise.  ``x\\nnot in s`` returns the negation of ``x in s``.  All built-in sequences\\nand set types support this as well as dictionary, for which ``in``\\ntests whether a the dictionary has a given key. For container types\\nsuch as list, tuple, set, frozenset, dict, or collections.deque, the\\nexpression ``x in y`` is equivalent to ``any(x is e or x == e for e in\\ny)``.\\n\\nFor the string and bytes types, ``x in y`` is true if and only if *x*\\nis a substring of *y*.  An equivalent test is ``y.find(x) != -1``.\\nEmpty strings are always considered to be a substring of any other\\nstring, so ``\"\" in \"abc\"`` will return ``True``.\\n\\nFor user-defined classes which define the ``__contains__()`` method,\\n``x in y`` is true if and only if ``y.__contains__(x)`` is true.\\n\\nFor user-defined classes which do not define ``__contains__()`` but do\\ndefine ``__iter__()``, ``x in y`` is true if some value ``z`` with ``x\\n== z`` is produced while iterating over ``y``.  If an exception is\\nraised during the iteration, it is as if ``in`` raised that exception.\\n\\nLastly, the old-style iteration protocol is tried: if a class defines\\n``__getitem__()``, ``x in y`` is true if and only if there is a non-\\nnegative integer index *i* such that ``x == y[i]``, and all lower\\ninteger indices do not raise ``IndexError`` exception.  (If any other\\nexception is raised, it is as if ``in`` raised that exception).\\n\\nThe operator ``not in`` is defined to have the inverse true value of\\n``in``.\\n\\nThe operators ``is`` and ``is not`` test for object identity: ``x is\\ny`` is true if and only if *x* and *y* are the same object.  ``x is\\nnot y`` yields the inverse truth value. [4]\\n',\n'compound': '\\nCompound statements\\n*******************\\n\\nCompound statements contain (groups of) other statements; they affect\\nor control the execution of those other statements in some way.  In\\ngeneral, compound statements span multiple lines, although in simple\\nincarnations a whole compound statement may be contained in one line.\\n\\nThe ``if``, ``while`` and ``for`` statements implement traditional\\ncontrol flow constructs.  ``try`` specifies exception handlers and/or\\ncleanup code for a group of statements, while the ``with`` statement\\nallows the execution of initialization and finalization code around a\\nblock of code.  Function and class definitions are also syntactically\\ncompound statements.\\n\\nCompound statements consist of one or more \\'clauses.\\'  A clause\\nconsists of a header and a \\'suite.\\'  The clause headers of a\\nparticular compound statement are all at the same indentation level.\\nEach clause header begins with a uniquely identifying keyword and ends\\nwith a colon.  A suite is a group of statements controlled by a\\nclause.  A suite can be one or more semicolon-separated simple\\nstatements on the same line as the header, following the header\\'s\\ncolon, or it can be one or more indented statements on subsequent\\nlines.  Only the latter form of suite can contain nested compound\\nstatements; the following is illegal, mostly because it wouldn\\'t be\\nclear to which ``if`` clause a following ``else`` clause would belong:\\n\\n   if test1: if test2: print(x)\\n\\nAlso note that the semicolon binds tighter than the colon in this\\ncontext, so that in the following example, either all or none of the\\n``print()`` calls are executed:\\n\\n   if x < y < z: print(x); print(y); print(z)\\n\\nSummarizing:\\n\\n   compound_stmt ::= if_stmt\\n                     | while_stmt\\n                     | for_stmt\\n                     | try_stmt\\n                     | with_stmt\\n                     | funcdef\\n                     | classdef\\n   suite         ::= stmt_list NEWLINE | NEWLINE INDENT statement+ DEDENT\\n   statement     ::= stmt_list NEWLINE | compound_stmt\\n   stmt_list     ::= simple_stmt (\";\" simple_stmt)* [\";\"]\\n\\nNote that statements always end in a ``NEWLINE`` possibly followed by\\na ``DEDENT``.  Also note that optional continuation clauses always\\nbegin with a keyword that cannot start a statement, thus there are no\\nambiguities (the \\'dangling ``else``\\' problem is solved in Python by\\nrequiring nested ``if`` statements to be indented).\\n\\nThe formatting of the grammar rules in the following sections places\\neach clause on a separate line for clarity.\\n\\n\\nThe ``if`` statement\\n====================\\n\\nThe ``if`` statement is used for conditional execution:\\n\\n   if_stmt ::= \"if\" expression \":\" suite\\n               ( \"elif\" expression \":\" suite )*\\n               [\"else\" \":\" suite]\\n\\nIt selects exactly one of the suites by evaluating the expressions one\\nby one until one is found to be true (see section *Boolean operations*\\nfor the definition of true and false); then that suite is executed\\n(and no other part of the ``if`` statement is executed or evaluated).\\nIf all expressions are false, the suite of the ``else`` clause, if\\npresent, is executed.\\n\\n\\nThe ``while`` statement\\n=======================\\n\\nThe ``while`` statement is used for repeated execution as long as an\\nexpression is true:\\n\\n   while_stmt ::= \"while\" expression \":\" suite\\n                  [\"else\" \":\" suite]\\n\\nThis repeatedly tests the expression and, if it is true, executes the\\nfirst suite; if the expression is false (which may be the first time\\nit is tested) the suite of the ``else`` clause, if present, is\\nexecuted and the loop terminates.\\n\\nA ``break`` statement executed in the first suite terminates the loop\\nwithout executing the ``else`` clause\\'s suite.  A ``continue``\\nstatement executed in the first suite skips the rest of the suite and\\ngoes back to testing the expression.\\n\\n\\nThe ``for`` statement\\n=====================\\n\\nThe ``for`` statement is used to iterate over the elements of a\\nsequence (such as a string, tuple or list) or other iterable object:\\n\\n   for_stmt ::= \"for\" target_list \"in\" expression_list \":\" suite\\n                [\"else\" \":\" suite]\\n\\nThe expression list is evaluated once; it should yield an iterable\\nobject.  An iterator is created for the result of the\\n``expression_list``.  The suite is then executed once for each item\\nprovided by the iterator, in the order of ascending indices.  Each\\nitem in turn is assigned to the target list using the standard rules\\nfor assignments (see *Assignment statements*), and then the suite is\\nexecuted.  When the items are exhausted (which is immediately when the\\nsequence is empty or an iterator raises a ``StopIteration``\\nexception), the suite in the ``else`` clause, if present, is executed,\\nand the loop terminates.\\n\\nA ``break`` statement executed in the first suite terminates the loop\\nwithout executing the ``else`` clause\\'s suite.  A ``continue``\\nstatement executed in the first suite skips the rest of the suite and\\ncontinues with the next item, or with the ``else`` clause if there was\\nno next item.\\n\\nThe suite may assign to the variable(s) in the target list; this does\\nnot affect the next item assigned to it.\\n\\nNames in the target list are not deleted when the loop is finished,\\nbut if the sequence is empty, it will not have been assigned to at all\\nby the loop.  Hint: the built-in function ``range()`` returns an\\niterator of integers suitable to emulate the effect of Pascal\\'s ``for\\ni := a to b do``; e.g., ``list(range(3))`` returns the list ``[0, 1,\\n2]``.\\n\\nNote: There is a subtlety when the sequence is being modified by the loop\\n  (this can only occur for mutable sequences, i.e. lists).  An\\n  internal counter is used to keep track of which item is used next,\\n  and this is incremented on each iteration.  When this counter has\\n  reached the length of the sequence the loop terminates.  This means\\n  that if the suite deletes the current (or a previous) item from the\\n  sequence, the next item will be skipped (since it gets the index of\\n  the current item which has already been treated).  Likewise, if the\\n  suite inserts an item in the sequence before the current item, the\\n  current item will be treated again the next time through the loop.\\n  This can lead to nasty bugs that can be avoided by making a\\n  temporary copy using a slice of the whole sequence, e.g.,\\n\\n     for x in a[:]:\\n         if x < 0: a.remove(x)\\n\\n\\nThe ``try`` statement\\n=====================\\n\\nThe ``try`` statement specifies exception handlers and/or cleanup code\\nfor a group of statements:\\n\\n   try_stmt  ::= try1_stmt | try2_stmt\\n   try1_stmt ::= \"try\" \":\" suite\\n                 (\"except\" [expression [\"as\" target]] \":\" suite)+\\n                 [\"else\" \":\" suite]\\n                 [\"finally\" \":\" suite]\\n   try2_stmt ::= \"try\" \":\" suite\\n                 \"finally\" \":\" suite\\n\\nThe ``except`` clause(s) specify one or more exception handlers. When\\nno exception occurs in the ``try`` clause, no exception handler is\\nexecuted. When an exception occurs in the ``try`` suite, a search for\\nan exception handler is started.  This search inspects the except\\nclauses in turn until one is found that matches the exception.  An\\nexpression-less except clause, if present, must be last; it matches\\nany exception.  For an except clause with an expression, that\\nexpression is evaluated, and the clause matches the exception if the\\nresulting object is \"compatible\" with the exception.  An object is\\ncompatible with an exception if it is the class or a base class of the\\nexception object or a tuple containing an item compatible with the\\nexception.\\n\\nIf no except clause matches the exception, the search for an exception\\nhandler continues in the surrounding code and on the invocation stack.\\n[1]\\n\\nIf the evaluation of an expression in the header of an except clause\\nraises an exception, the original search for a handler is canceled and\\na search starts for the new exception in the surrounding code and on\\nthe call stack (it is treated as if the entire ``try`` statement\\nraised the exception).\\n\\nWhen a matching except clause is found, the exception is assigned to\\nthe target specified after the ``as`` keyword in that except clause,\\nif present, and the except clause\\'s suite is executed.  All except\\nclauses must have an executable block.  When the end of this block is\\nreached, execution continues normally after the entire try statement.\\n(This means that if two nested handlers exist for the same exception,\\nand the exception occurs in the try clause of the inner handler, the\\nouter handler will not handle the exception.)\\n\\nWhen an exception has been assigned using ``as target``, it is cleared\\nat the end of the except clause.  This is as if\\n\\n   except E as N:\\n       foo\\n\\nwas translated to\\n\\n   except E as N:\\n       try:\\n           foo\\n       finally:\\n           del N\\n\\nThis means the exception must be assigned to a different name to be\\nable to refer to it after the except clause.  Exceptions are cleared\\nbecause with the traceback attached to them, they form a reference\\ncycle with the stack frame, keeping all locals in that frame alive\\nuntil the next garbage collection occurs.\\n\\nBefore an except clause\\'s suite is executed, details about the\\nexception are stored in the ``sys`` module and can be access via\\n``sys.exc_info()``. ``sys.exc_info()`` returns a 3-tuple consisting of\\nthe exception class, the exception instance and a traceback object\\n(see section *The standard type hierarchy*) identifying the point in\\nthe program where the exception occurred.  ``sys.exc_info()`` values\\nare restored to their previous values (before the call) when returning\\nfrom a function that handled an exception.\\n\\nThe optional ``else`` clause is executed if and when control flows off\\nthe end of the ``try`` clause. [2] Exceptions in the ``else`` clause\\nare not handled by the preceding ``except`` clauses.\\n\\nIf ``finally`` is present, it specifies a \\'cleanup\\' handler.  The\\n``try`` clause is executed, including any ``except`` and ``else``\\nclauses.  If an exception occurs in any of the clauses and is not\\nhandled, the exception is temporarily saved. The ``finally`` clause is\\nexecuted.  If there is a saved exception it is re-raised at the end of\\nthe ``finally`` clause.  If the ``finally`` clause raises another\\nexception, the saved exception is set as the context of the new\\nexception. If the ``finally`` clause executes a ``return`` or\\n``break`` statement, the saved exception is discarded:\\n\\n   def f():\\n       try:\\n           1/0\\n       finally:\\n           return 42\\n\\n   >>> f()\\n   42\\n\\nThe exception information is not available to the program during\\nexecution of the ``finally`` clause.\\n\\nWhen a ``return``, ``break`` or ``continue`` statement is executed in\\nthe ``try`` suite of a ``try``...``finally`` statement, the\\n``finally`` clause is also executed \\'on the way out.\\' A ``continue``\\nstatement is illegal in the ``finally`` clause. (The reason is a\\nproblem with the current implementation --- this restriction may be\\nlifted in the future).\\n\\nAdditional information on exceptions can be found in section\\n*Exceptions*, and information on using the ``raise`` statement to\\ngenerate exceptions may be found in section *The raise statement*.\\n\\n\\nThe ``with`` statement\\n======================\\n\\nThe ``with`` statement is used to wrap the execution of a block with\\nmethods defined by a context manager (see section *With Statement\\nContext Managers*). This allows common\\n``try``...``except``...``finally`` usage patterns to be encapsulated\\nfor convenient reuse.\\n\\n   with_stmt ::= \"with\" with_item (\",\" with_item)* \":\" suite\\n   with_item ::= expression [\"as\" target]\\n\\nThe execution of the ``with`` statement with one \"item\" proceeds as\\nfollows:\\n\\n1. The context expression (the expression given in the ``with_item``)\\n   is evaluated to obtain a context manager.\\n\\n2. The context manager\\'s ``__exit__()`` is loaded for later use.\\n\\n3. The context manager\\'s ``__enter__()`` method is invoked.\\n\\n4. If a target was included in the ``with`` statement, the return\\n   value from ``__enter__()`` is assigned to it.\\n\\n   Note: The ``with`` statement guarantees that if the ``__enter__()``\\n     method returns without an error, then ``__exit__()`` will always\\n     be called. Thus, if an error occurs during the assignment to the\\n     target list, it will be treated the same as an error occurring\\n     within the suite would be. See step 6 below.\\n\\n5. The suite is executed.\\n\\n6. The context manager\\'s ``__exit__()`` method is invoked.  If an\\n   exception caused the suite to be exited, its type, value, and\\n   traceback are passed as arguments to ``__exit__()``. Otherwise,\\n   three ``None`` arguments are supplied.\\n\\n   If the suite was exited due to an exception, and the return value\\n   from the ``__exit__()`` method was false, the exception is\\n   reraised.  If the return value was true, the exception is\\n   suppressed, and execution continues with the statement following\\n   the ``with`` statement.\\n\\n   If the suite was exited for any reason other than an exception, the\\n   return value from ``__exit__()`` is ignored, and execution proceeds\\n   at the normal location for the kind of exit that was taken.\\n\\nWith more than one item, the context managers are processed as if\\nmultiple ``with`` statements were nested:\\n\\n   with A() as a, B() as b:\\n       suite\\n\\nis equivalent to\\n\\n   with A() as a:\\n       with B() as b:\\n           suite\\n\\nChanged in version 3.1: Support for multiple context expressions.\\n\\nSee also:\\n\\n   **PEP 0343** - The \"with\" statement\\n      The specification, background, and examples for the Python\\n      ``with`` statement.\\n\\n\\nFunction definitions\\n====================\\n\\nA function definition defines a user-defined function object (see\\nsection *The standard type hierarchy*):\\n\\n   funcdef        ::= [decorators] \"def\" funcname \"(\" [parameter_list] \")\" [\"->\" expression] \":\" suite\\n   decorators     ::= decorator+\\n   decorator      ::= \"@\" dotted_name [\"(\" [parameter_list [\",\"]] \")\"] NEWLINE\\n   dotted_name    ::= identifier (\".\" identifier)*\\n   parameter_list ::= (defparameter \",\")*\\n                      ( \"*\" [parameter] (\",\" defparameter)* [\",\" \"**\" parameter]\\n                      | \"**\" parameter\\n                      | defparameter [\",\"] )\\n   parameter      ::= identifier [\":\" expression]\\n   defparameter   ::= parameter [\"=\" expression]\\n   funcname       ::= identifier\\n\\nA function definition is an executable statement.  Its execution binds\\nthe function name in the current local namespace to a function object\\n(a wrapper around the executable code for the function).  This\\nfunction object contains a reference to the current global namespace\\nas the global namespace to be used when the function is called.\\n\\nThe function definition does not execute the function body; this gets\\nexecuted only when the function is called. [3]\\n\\nA function definition may be wrapped by one or more *decorator*\\nexpressions. Decorator expressions are evaluated when the function is\\ndefined, in the scope that contains the function definition.  The\\nresult must be a callable, which is invoked with the function object\\nas the only argument. The returned value is bound to the function name\\ninstead of the function object.  Multiple decorators are applied in\\nnested fashion. For example, the following code\\n\\n   @f1(arg)\\n   @f2\\n   def func(): pass\\n\\nis equivalent to\\n\\n   def func(): pass\\n   func = f1(arg)(f2(func))\\n\\nWhen one or more *parameters* have the form *parameter* ``=``\\n*expression*, the function is said to have \"default parameter values.\"\\nFor a parameter with a default value, the corresponding *argument* may\\nbe omitted from a call, in which case the parameter\\'s default value is\\nsubstituted.  If a parameter has a default value, all following\\nparameters up until the \"``*``\" must also have a default value ---\\nthis is a syntactic restriction that is not expressed by the grammar.\\n\\n**Default parameter values are evaluated when the function definition\\nis executed.** This means that the expression is evaluated once, when\\nthe function is defined, and that the same \"pre-computed\" value is\\nused for each call.  This is especially important to understand when a\\ndefault parameter is a mutable object, such as a list or a dictionary:\\nif the function modifies the object (e.g. by appending an item to a\\nlist), the default value is in effect modified. This is generally not\\nwhat was intended.  A way around this is to use ``None`` as the\\ndefault, and explicitly test for it in the body of the function, e.g.:\\n\\n   def whats_on_the_telly(penguin=None):\\n       if penguin is None:\\n           penguin = []\\n       penguin.append(\"property of the zoo\")\\n       return penguin\\n\\nFunction call semantics are described in more detail in section\\n*Calls*. A function call always assigns values to all parameters\\nmentioned in the parameter list, either from position arguments, from\\nkeyword arguments, or from default values.  If the form\\n\"``*identifier``\" is present, it is initialized to a tuple receiving\\nany excess positional parameters, defaulting to the empty tuple.  If\\nthe form \"``**identifier``\" is present, it is initialized to a new\\ndictionary receiving any excess keyword arguments, defaulting to a new\\nempty dictionary. Parameters after \"``*``\" or \"``*identifier``\" are\\nkeyword-only parameters and may only be passed used keyword arguments.\\n\\nParameters may have annotations of the form \"``: expression``\"\\nfollowing the parameter name.  Any parameter may have an annotation\\neven those of the form ``*identifier`` or ``**identifier``.  Functions\\nmay have \"return\" annotation of the form \"``-> expression``\" after the\\nparameter list.  These annotations can be any valid Python expression\\nand are evaluated when the function definition is executed.\\nAnnotations may be evaluated in a different order than they appear in\\nthe source code.  The presence of annotations does not change the\\nsemantics of a function.  The annotation values are available as\\nvalues of a dictionary keyed by the parameters\\' names in the\\n``__annotations__`` attribute of the function object.\\n\\nIt is also possible to create anonymous functions (functions not bound\\nto a name), for immediate use in expressions.  This uses lambda forms,\\ndescribed in section *Lambdas*.  Note that the lambda form is merely a\\nshorthand for a simplified function definition; a function defined in\\na \"``def``\" statement can be passed around or assigned to another name\\njust like a function defined by a lambda form.  The \"``def``\" form is\\nactually more powerful since it allows the execution of multiple\\nstatements and annotations.\\n\\n**Programmer\\'s note:** Functions are first-class objects.  A \"``def``\"\\nform executed inside a function definition defines a local function\\nthat can be returned or passed around.  Free variables used in the\\nnested function can access the local variables of the function\\ncontaining the def.  See section *Naming and binding* for details.\\n\\nSee also:\\n\\n   **PEP 3107** - Function Annotations\\n      The original specification for function annotations.\\n\\n\\nClass definitions\\n=================\\n\\nA class definition defines a class object (see section *The standard\\ntype hierarchy*):\\n\\n   classdef    ::= [decorators] \"class\" classname [inheritance] \":\" suite\\n   inheritance ::= \"(\" [parameter_list] \")\"\\n   classname   ::= identifier\\n\\nA class definition is an executable statement.  The inheritance list\\nusually gives a list of base classes (see *Customizing class creation*\\nfor more advanced uses), so each item in the list should evaluate to a\\nclass object which allows subclassing.  Classes without an inheritance\\nlist inherit, by default, from the base class ``object``; hence,\\n\\n   class Foo:\\n       pass\\n\\nis equivalent to\\n\\n   class Foo(object):\\n       pass\\n\\nThe class\\'s suite is then executed in a new execution frame (see\\n*Naming and binding*), using a newly created local namespace and the\\noriginal global namespace. (Usually, the suite contains mostly\\nfunction definitions.)  When the class\\'s suite finishes execution, its\\nexecution frame is discarded but its local namespace is saved. [4] A\\nclass object is then created using the inheritance list for the base\\nclasses and the saved local namespace for the attribute dictionary.\\nThe class name is bound to this class object in the original local\\nnamespace.\\n\\nClass creation can be customized heavily using *metaclasses*.\\n\\nClasses can also be decorated: just like when decorating functions,\\n\\n   @f1(arg)\\n   @f2\\n   class Foo: pass\\n\\nis equivalent to\\n\\n   class Foo: pass\\n   Foo = f1(arg)(f2(Foo))\\n\\nThe evaluation rules for the decorator expressions are the same as for\\nfunction decorators.  The result must be a class object, which is then\\nbound to the class name.\\n\\n**Programmer\\'s note:** Variables defined in the class definition are\\nclass attributes; they are shared by instances.  Instance attributes\\ncan be set in a method with ``self.name = value``.  Both class and\\ninstance attributes are accessible through the notation\\n\"``self.name``\", and an instance attribute hides a class attribute\\nwith the same name when accessed in this way.  Class attributes can be\\nused as defaults for instance attributes, but using mutable values\\nthere can lead to unexpected results.  *Descriptors* can be used to\\ncreate instance variables with different implementation details.\\n\\nSee also:\\n\\n   **PEP 3115** - Metaclasses in Python 3 **PEP 3129** - Class\\n   Decorators\\n\\n-[ Footnotes ]-\\n\\n[1] The exception is propagated to the invocation stack unless there\\n    is a ``finally`` clause which happens to raise another exception.\\n    That new exception causes the old one to be lost.\\n\\n[2] Currently, control \"flows off the end\" except in the case of an\\n    exception or the execution of a ``return``, ``continue``, or\\n    ``break`` statement.\\n\\n[3] A string literal appearing as the first statement in the function\\n    body is transformed into the function\\'s ``__doc__`` attribute and\\n    therefore the function\\'s *docstring*.\\n\\n[4] A string literal appearing as the first statement in the class\\n    body is transformed into the namespace\\'s ``__doc__`` item and\\n    therefore the class\\'s *docstring*.\\n',\n'context-managers': '\\nWith Statement Context Managers\\n*******************************\\n\\nA *context manager* is an object that defines the runtime context to\\nbe established when executing a ``with`` statement. The context\\nmanager handles the entry into, and the exit from, the desired runtime\\ncontext for the execution of the block of code.  Context managers are\\nnormally invoked using the ``with`` statement (described in section\\n*The with statement*), but can also be used by directly invoking their\\nmethods.\\n\\nTypical uses of context managers include saving and restoring various\\nkinds of global state, locking and unlocking resources, closing opened\\nfiles, etc.\\n\\nFor more information on context managers, see *Context Manager Types*.\\n\\nobject.__enter__(self)\\n\\n   Enter the runtime context related to this object. The ``with``\\n   statement will bind this method\\'s return value to the target(s)\\n   specified in the ``as`` clause of the statement, if any.\\n\\nobject.__exit__(self, exc_type, exc_value, traceback)\\n\\n   Exit the runtime context related to this object. The parameters\\n   describe the exception that caused the context to be exited. If the\\n   context was exited without an exception, all three arguments will\\n   be ``None``.\\n\\n   If an exception is supplied, and the method wishes to suppress the\\n   exception (i.e., prevent it from being propagated), it should\\n   return a true value. Otherwise, the exception will be processed\\n   normally upon exit from this method.\\n\\n   Note that ``__exit__()`` methods should not reraise the passed-in\\n   exception; this is the caller\\'s responsibility.\\n\\nSee also:\\n\\n   **PEP 0343** - The \"with\" statement\\n      The specification, background, and examples for the Python\\n      ``with`` statement.\\n',\n'continue': '\\nThe ``continue`` statement\\n**************************\\n\\n   continue_stmt ::= \"continue\"\\n\\n``continue`` may only occur syntactically nested in a ``for`` or\\n``while`` loop, but not nested in a function or class definition or\\n``finally`` clause within that loop.  It continues with the next cycle\\nof the nearest enclosing loop.\\n\\nWhen ``continue`` passes control out of a ``try`` statement with a\\n``finally`` clause, that ``finally`` clause is executed before really\\nstarting the next loop cycle.\\n',\n'conversions': '\\nArithmetic conversions\\n**********************\\n\\nWhen a description of an arithmetic operator below uses the phrase\\n\"the numeric arguments are converted to a common type,\" this means\\nthat the operator implementation for built-in types works that way:\\n\\n* If either argument is a complex number, the other is converted to\\n  complex;\\n\\n* otherwise, if either argument is a floating point number, the other\\n  is converted to floating point;\\n\\n* otherwise, both must be integers and no conversion is necessary.\\n\\nSome additional rules apply for certain operators (e.g., a string left\\nargument to the \\'%\\' operator).  Extensions must define their own\\nconversion behavior.\\n',\n'customization': '\\nBasic customization\\n*******************\\n\\nobject.__new__(cls[, ...])\\n\\n   Called to create a new instance of class *cls*.  ``__new__()`` is a\\n   static method (special-cased so you need not declare it as such)\\n   that takes the class of which an instance was requested as its\\n   first argument.  The remaining arguments are those passed to the\\n   object constructor expression (the call to the class).  The return\\n   value of ``__new__()`` should be the new object instance (usually\\n   an instance of *cls*).\\n\\n   Typical implementations create a new instance of the class by\\n   invoking the superclass\\'s ``__new__()`` method using\\n   ``super(currentclass, cls).__new__(cls[, ...])`` with appropriate\\n   arguments and then modifying the newly-created instance as\\n   necessary before returning it.\\n\\n   If ``__new__()`` returns an instance of *cls*, then the new\\n   instance\\'s ``__init__()`` method will be invoked like\\n   ``__init__(self[, ...])``, where *self* is the new instance and the\\n   remaining arguments are the same as were passed to ``__new__()``.\\n\\n   If ``__new__()`` does not return an instance of *cls*, then the new\\n   instance\\'s ``__init__()`` method will not be invoked.\\n\\n   ``__new__()`` is intended mainly to allow subclasses of immutable\\n   types (like int, str, or tuple) to customize instance creation.  It\\n   is also commonly overridden in custom metaclasses in order to\\n   customize class creation.\\n\\nobject.__init__(self[, ...])\\n\\n   Called when the instance is created.  The arguments are those\\n   passed to the class constructor expression.  If a base class has an\\n   ``__init__()`` method, the derived class\\'s ``__init__()`` method,\\n   if any, must explicitly call it to ensure proper initialization of\\n   the base class part of the instance; for example:\\n   ``BaseClass.__init__(self, [args...])``.  As a special constraint\\n   on constructors, no value may be returned; doing so will cause a\\n   ``TypeError`` to be raised at runtime.\\n\\nobject.__del__(self)\\n\\n   Called when the instance is about to be destroyed.  This is also\\n   called a destructor.  If a base class has a ``__del__()`` method,\\n   the derived class\\'s ``__del__()`` method, if any, must explicitly\\n   call it to ensure proper deletion of the base class part of the\\n   instance.  Note that it is possible (though not recommended!) for\\n   the ``__del__()`` method to postpone destruction of the instance by\\n   creating a new reference to it.  It may then be called at a later\\n   time when this new reference is deleted.  It is not guaranteed that\\n   ``__del__()`` methods are called for objects that still exist when\\n   the interpreter exits.\\n\\n   Note: ``del x`` doesn\\'t directly call ``x.__del__()`` --- the former\\n     decrements the reference count for ``x`` by one, and the latter\\n     is only called when ``x``\\'s reference count reaches zero.  Some\\n     common situations that may prevent the reference count of an\\n     object from going to zero include: circular references between\\n     objects (e.g., a doubly-linked list or a tree data structure with\\n     parent and child pointers); a reference to the object on the\\n     stack frame of a function that caught an exception (the traceback\\n     stored in ``sys.exc_info()[2]`` keeps the stack frame alive); or\\n     a reference to the object on the stack frame that raised an\\n     unhandled exception in interactive mode (the traceback stored in\\n     ``sys.last_traceback`` keeps the stack frame alive).  The first\\n     situation can only be remedied by explicitly breaking the cycles;\\n     the latter two situations can be resolved by storing ``None`` in\\n     ``sys.last_traceback``. Circular references which are garbage are\\n     detected when the option cycle detector is enabled (it\\'s on by\\n     default), but can only be cleaned up if there are no Python-\\n     level ``__del__()`` methods involved. Refer to the documentation\\n     for the ``gc`` module for more information about how\\n     ``__del__()`` methods are handled by the cycle detector,\\n     particularly the description of the ``garbage`` value.\\n\\n   Warning: Due to the precarious circumstances under which ``__del__()``\\n     methods are invoked, exceptions that occur during their execution\\n     are ignored, and a warning is printed to ``sys.stderr`` instead.\\n     Also, when ``__del__()`` is invoked in response to a module being\\n     deleted (e.g., when execution of the program is done), other\\n     globals referenced by the ``__del__()`` method may already have\\n     been deleted or in the process of being torn down (e.g. the\\n     import machinery shutting down).  For this reason, ``__del__()``\\n     methods should do the absolute minimum needed to maintain\\n     external invariants.  Starting with version 1.5, Python\\n     guarantees that globals whose name begins with a single\\n     underscore are deleted from their module before other globals are\\n     deleted; if no other references to such globals exist, this may\\n     help in assuring that imported modules are still available at the\\n     time when the ``__del__()`` method is called.\\n\\nobject.__repr__(self)\\n\\n   Called by the ``repr()`` built-in function to compute the\\n   \"official\" string representation of an object.  If at all possible,\\n   this should look like a valid Python expression that could be used\\n   to recreate an object with the same value (given an appropriate\\n   environment).  If this is not possible, a string of the form\\n   ``<...some useful description...>`` should be returned. The return\\n   value must be a string object. If a class defines ``__repr__()``\\n   but not ``__str__()``, then ``__repr__()`` is also used when an\\n   \"informal\" string representation of instances of that class is\\n   required.\\n\\n   This is typically used for debugging, so it is important that the\\n   representation is information-rich and unambiguous.\\n\\nobject.__str__(self)\\n\\n   Called by ``str(object)`` and the built-in functions ``format()``\\n   and ``print()`` to compute the \"informal\" or nicely printable\\n   string representation of an object.  The return value must be a\\n   *string* object.\\n\\n   This method differs from ``object.__repr__()`` in that there is no\\n   expectation that ``__str__()`` return a valid Python expression: a\\n   more convenient or concise representation can be used.\\n\\n   The default implementation defined by the built-in type ``object``\\n   calls ``object.__repr__()``.\\n\\nobject.__bytes__(self)\\n\\n   Called by ``bytes()`` to compute a byte-string representation of an\\n   object. This should return a ``bytes`` object.\\n\\nobject.__format__(self, format_spec)\\n\\n   Called by the ``format()`` built-in function (and by extension, the\\n   ``str.format()`` method of class ``str``) to produce a \"formatted\"\\n   string representation of an object. The ``format_spec`` argument is\\n   a string that contains a description of the formatting options\\n   desired. The interpretation of the ``format_spec`` argument is up\\n   to the type implementing ``__format__()``, however most classes\\n   will either delegate formatting to one of the built-in types, or\\n   use a similar formatting option syntax.\\n\\n   See *Format Specification Mini-Language* for a description of the\\n   standard formatting syntax.\\n\\n   The return value must be a string object.\\n\\nobject.__lt__(self, other)\\nobject.__le__(self, other)\\nobject.__eq__(self, other)\\nobject.__ne__(self, other)\\nobject.__gt__(self, other)\\nobject.__ge__(self, other)\\n\\n   These are the so-called \"rich comparison\" methods. The\\n   correspondence between operator symbols and method names is as\\n   follows: ``x<y`` calls ``x.__lt__(y)``, ``x<=y`` calls\\n   ``x.__le__(y)``, ``x==y`` calls ``x.__eq__(y)``, ``x!=y`` calls\\n   ``x.__ne__(y)``, ``x>y`` calls ``x.__gt__(y)``, and ``x>=y`` calls\\n   ``x.__ge__(y)``.\\n\\n   A rich comparison method may return the singleton\\n   ``NotImplemented`` if it does not implement the operation for a\\n   given pair of arguments. By convention, ``False`` and ``True`` are\\n   returned for a successful comparison. However, these methods can\\n   return any value, so if the comparison operator is used in a\\n   Boolean context (e.g., in the condition of an ``if`` statement),\\n   Python will call ``bool()`` on the value to determine if the result\\n   is true or false.\\n\\n   There are no implied relationships among the comparison operators.\\n   The truth of ``x==y`` does not imply that ``x!=y`` is false.\\n   Accordingly, when defining ``__eq__()``, one should also define\\n   ``__ne__()`` so that the operators will behave as expected.  See\\n   the paragraph on ``__hash__()`` for some important notes on\\n   creating *hashable* objects which support custom comparison\\n   operations and are usable as dictionary keys.\\n\\n   There are no swapped-argument versions of these methods (to be used\\n   when the left argument does not support the operation but the right\\n   argument does); rather, ``__lt__()`` and ``__gt__()`` are each\\n   other\\'s reflection, ``__le__()`` and ``__ge__()`` are each other\\'s\\n   reflection, and ``__eq__()`` and ``__ne__()`` are their own\\n   reflection.\\n\\n   Arguments to rich comparison methods are never coerced.\\n\\n   To automatically generate ordering operations from a single root\\n   operation, see ``functools.total_ordering()``.\\n\\nobject.__hash__(self)\\n\\n   Called by built-in function ``hash()`` and for operations on\\n   members of hashed collections including ``set``, ``frozenset``, and\\n   ``dict``.  ``__hash__()`` should return an integer.  The only\\n   required property is that objects which compare equal have the same\\n   hash value; it is advised to somehow mix together (e.g. using\\n   exclusive or) the hash values for the components of the object that\\n   also play a part in comparison of objects.\\n\\n   If a class does not define an ``__eq__()`` method it should not\\n   define a ``__hash__()`` operation either; if it defines\\n   ``__eq__()`` but not ``__hash__()``, its instances will not be\\n   usable as items in hashable collections.  If a class defines\\n   mutable objects and implements an ``__eq__()`` method, it should\\n   not implement ``__hash__()``, since the implementation of hashable\\n   collections requires that a key\\'s hash value is immutable (if the\\n   object\\'s hash value changes, it will be in the wrong hash bucket).\\n\\n   User-defined classes have ``__eq__()`` and ``__hash__()`` methods\\n   by default; with them, all objects compare unequal (except with\\n   themselves) and ``x.__hash__()`` returns an appropriate value such\\n   that ``x == y`` implies both that ``x is y`` and ``hash(x) ==\\n   hash(y)``.\\n\\n   A class that overrides ``__eq__()`` and does not define\\n   ``__hash__()`` will have its ``__hash__()`` implicitly set to\\n   ``None``.  When the ``__hash__()`` method of a class is ``None``,\\n   instances of the class will raise an appropriate ``TypeError`` when\\n   a program attempts to retrieve their hash value, and will also be\\n   correctly identified as unhashable when checking ``isinstance(obj,\\n   collections.Hashable``).\\n\\n   If a class that overrides ``__eq__()`` needs to retain the\\n   implementation of ``__hash__()`` from a parent class, the\\n   interpreter must be told this explicitly by setting ``__hash__ =\\n   <ParentClass>.__hash__``.\\n\\n   If a class that does not override ``__eq__()`` wishes to suppress\\n   hash support, it should include ``__hash__ = None`` in the class\\n   definition. A class which defines its own ``__hash__()`` that\\n   explicitly raises a ``TypeError`` would be incorrectly identified\\n   as hashable by an ``isinstance(obj, collections.Hashable)`` call.\\n\\n   Note: By default, the ``__hash__()`` values of str, bytes and datetime\\n     objects are \"salted\" with an unpredictable random value.\\n     Although they remain constant within an individual Python\\n     process, they are not predictable between repeated invocations of\\n     Python.This is intended to provide protection against a denial-\\n     of-service caused by carefully-chosen inputs that exploit the\\n     worst case performance of a dict insertion, O(n^2) complexity.\\n     See http://www.ocert.org/advisories/ocert-2011-003.html for\\n     details.Changing hash values affects the iteration order of\\n     dicts, sets and other mappings.  Python has never made guarantees\\n     about this ordering (and it typically varies between 32-bit and\\n     64-bit builds).See also ``PYTHONHASHSEED``.\\n\\n   Changed in version 3.3: Hash randomization is enabled by default.\\n\\nobject.__bool__(self)\\n\\n   Called to implement truth value testing and the built-in operation\\n   ``bool()``; should return ``False`` or ``True``.  When this method\\n   is not defined, ``__len__()`` is called, if it is defined, and the\\n   object is considered true if its result is nonzero.  If a class\\n   defines neither ``__len__()`` nor ``__bool__()``, all its instances\\n   are considered true.\\n',\n'debugger': '\\n``pdb`` --- The Python Debugger\\n*******************************\\n\\nThe module ``pdb`` defines an interactive source code debugger for\\nPython programs.  It supports setting (conditional) breakpoints and\\nsingle stepping at the source line level, inspection of stack frames,\\nsource code listing, and evaluation of arbitrary Python code in the\\ncontext of any stack frame.  It also supports post-mortem debugging\\nand can be called under program control.\\n\\nThe debugger is extensible -- it is actually defined as the class\\n``Pdb``. This is currently undocumented but easily understood by\\nreading the source.  The extension interface uses the modules ``bdb``\\nand ``cmd``.\\n\\nThe debugger\\'s prompt is ``(Pdb)``. Typical usage to run a program\\nunder control of the debugger is:\\n\\n   >>> import pdb\\n   >>> import mymodule\\n   >>> pdb.run(\\'mymodule.test()\\')\\n   > <string>(0)?()\\n   (Pdb) continue\\n   > <string>(1)?()\\n   (Pdb) continue\\n   NameError: \\'spam\\'\\n   > <string>(1)?()\\n   (Pdb)\\n\\nChanged in version 3.3: Tab-completion via the ``readline`` module is\\navailable for commands and command arguments, e.g. the current global\\nand local names are offered as arguments of the ``print`` command.\\n\\n``pdb.py`` can also be invoked as a script to debug other scripts.\\nFor example:\\n\\n   python3 -m pdb myscript.py\\n\\nWhen invoked as a script, pdb will automatically enter post-mortem\\ndebugging if the program being debugged exits abnormally.  After post-\\nmortem debugging (or after normal exit of the program), pdb will\\nrestart the program.  Automatic restarting preserves pdb\\'s state (such\\nas breakpoints) and in most cases is more useful than quitting the\\ndebugger upon program\\'s exit.\\n\\nNew in version 3.2: ``pdb.py`` now accepts a ``-c`` option that\\nexecutes commands as if given in a ``.pdbrc`` file, see *Debugger\\nCommands*.\\n\\nThe typical usage to break into the debugger from a running program is\\nto insert\\n\\n   import pdb; pdb.set_trace()\\n\\nat the location you want to break into the debugger.  You can then\\nstep through the code following this statement, and continue running\\nwithout the debugger using the ``continue`` command.\\n\\nThe typical usage to inspect a crashed program is:\\n\\n   >>> import pdb\\n   >>> import mymodule\\n   >>> mymodule.test()\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 1, in ?\\n     File \"./mymodule.py\", line 4, in test\\n       test2()\\n     File \"./mymodule.py\", line 3, in test2\\n       print(spam)\\n   NameError: spam\\n   >>> pdb.pm()\\n   > ./mymodule.py(3)test2()\\n   -> print(spam)\\n   (Pdb)\\n\\nThe module defines the following functions; each enters the debugger\\nin a slightly different way:\\n\\npdb.run(statement, globals=None, locals=None)\\n\\n   Execute the *statement* (given as a string or a code object) under\\n   debugger control.  The debugger prompt appears before any code is\\n   executed; you can set breakpoints and type ``continue``, or you can\\n   step through the statement using ``step`` or ``next`` (all these\\n   commands are explained below).  The optional *globals* and *locals*\\n   arguments specify the environment in which the code is executed; by\\n   default the dictionary of the module ``__main__`` is used.  (See\\n   the explanation of the built-in ``exec()`` or ``eval()``\\n   functions.)\\n\\npdb.runeval(expression, globals=None, locals=None)\\n\\n   Evaluate the *expression* (given as a string or a code object)\\n   under debugger control.  When ``runeval()`` returns, it returns the\\n   value of the expression.  Otherwise this function is similar to\\n   ``run()``.\\n\\npdb.runcall(function, *args, **kwds)\\n\\n   Call the *function* (a function or method object, not a string)\\n   with the given arguments.  When ``runcall()`` returns, it returns\\n   whatever the function call returned.  The debugger prompt appears\\n   as soon as the function is entered.\\n\\npdb.set_trace()\\n\\n   Enter the debugger at the calling stack frame.  This is useful to\\n   hard-code a breakpoint at a given point in a program, even if the\\n   code is not otherwise being debugged (e.g. when an assertion\\n   fails).\\n\\npdb.post_mortem(traceback=None)\\n\\n   Enter post-mortem debugging of the given *traceback* object.  If no\\n   *traceback* is given, it uses the one of the exception that is\\n   currently being handled (an exception must be being handled if the\\n   default is to be used).\\n\\npdb.pm()\\n\\n   Enter post-mortem debugging of the traceback found in\\n   ``sys.last_traceback``.\\n\\nThe ``run*`` functions and ``set_trace()`` are aliases for\\ninstantiating the ``Pdb`` class and calling the method of the same\\nname.  If you want to access further features, you have to do this\\nyourself:\\n\\nclass class pdb.Pdb(completekey=\\'tab\\', stdin=None, stdout=None, skip=None, nosigint=False)\\n\\n   ``Pdb`` is the debugger class.\\n\\n   The *completekey*, *stdin* and *stdout* arguments are passed to the\\n   underlying ``cmd.Cmd`` class; see the description there.\\n\\n   The *skip* argument, if given, must be an iterable of glob-style\\n   module name patterns.  The debugger will not step into frames that\\n   originate in a module that matches one of these patterns. [1]\\n\\n   By default, Pdb sets a handler for the SIGINT signal (which is sent\\n   when the user presses Ctrl-C on the console) when you give a\\n   ``continue`` command. This allows you to break into the debugger\\n   again by pressing Ctrl-C.  If you want Pdb not to touch the SIGINT\\n   handler, set *nosigint* tot true.\\n\\n   Example call to enable tracing with *skip*:\\n\\n      import pdb; pdb.Pdb(skip=[\\'django.*\\']).set_trace()\\n\\n   New in version 3.1: The *skip* argument.\\n\\n   New in version 3.2: The *nosigint* argument.  Previously, a SIGINT\\n   handler was never set by Pdb.\\n\\n   run(statement, globals=None, locals=None)\\n   runeval(expression, globals=None, locals=None)\\n   runcall(function, *args, **kwds)\\n   set_trace()\\n\\n      See the documentation for the functions explained above.\\n\\n\\nDebugger Commands\\n=================\\n\\nThe commands recognized by the debugger are listed below.  Most\\ncommands can be abbreviated to one or two letters as indicated; e.g.\\n``h(elp)`` means that either ``h`` or ``help`` can be used to enter\\nthe help command (but not ``he`` or ``hel``, nor ``H`` or ``Help`` or\\n``HELP``).  Arguments to commands must be separated by whitespace\\n(spaces or tabs).  Optional arguments are enclosed in square brackets\\n(``[]``) in the command syntax; the square brackets must not be typed.\\nAlternatives in the command syntax are separated by a vertical bar\\n(``|``).\\n\\nEntering a blank line repeats the last command entered.  Exception: if\\nthe last command was a ``list`` command, the next 11 lines are listed.\\n\\nCommands that the debugger doesn\\'t recognize are assumed to be Python\\nstatements and are executed in the context of the program being\\ndebugged.  Python statements can also be prefixed with an exclamation\\npoint (``!``).  This is a powerful way to inspect the program being\\ndebugged; it is even possible to change a variable or call a function.\\nWhen an exception occurs in such a statement, the exception name is\\nprinted but the debugger\\'s state is not changed.\\n\\nThe debugger supports *aliases*.  Aliases can have parameters which\\nallows one a certain level of adaptability to the context under\\nexamination.\\n\\nMultiple commands may be entered on a single line, separated by\\n``;;``.  (A single ``;`` is not used as it is the separator for\\nmultiple commands in a line that is passed to the Python parser.)  No\\nintelligence is applied to separating the commands; the input is split\\nat the first ``;;`` pair, even if it is in the middle of a quoted\\nstring.\\n\\nIf a file ``.pdbrc`` exists in the user\\'s home directory or in the\\ncurrent directory, it is read in and executed as if it had been typed\\nat the debugger prompt.  This is particularly useful for aliases.  If\\nboth files exist, the one in the home directory is read first and\\naliases defined there can be overridden by the local file.\\n\\nChanged in version 3.2: ``.pdbrc`` can now contain commands that\\ncontinue debugging, such as ``continue`` or ``next``.  Previously,\\nthese commands had no effect.\\n\\nh(elp) [command]\\n\\n   Without argument, print the list of available commands.  With a\\n   *command* as argument, print help about that command.  ``help pdb``\\n   displays the full documentation (the docstring of the ``pdb``\\n   module).  Since the *command* argument must be an identifier,\\n   ``help exec`` must be entered to get help on the ``!`` command.\\n\\nw(here)\\n\\n   Print a stack trace, with the most recent frame at the bottom.  An\\n   arrow indicates the current frame, which determines the context of\\n   most commands.\\n\\nd(own) [count]\\n\\n   Move the current frame *count* (default one) levels down in the\\n   stack trace (to a newer frame).\\n\\nu(p) [count]\\n\\n   Move the current frame *count* (default one) levels up in the stack\\n   trace (to an older frame).\\n\\nb(reak) [([filename:]lineno | function) [, condition]]\\n\\n   With a *lineno* argument, set a break there in the current file.\\n   With a *function* argument, set a break at the first executable\\n   statement within that function.  The line number may be prefixed\\n   with a filename and a colon, to specify a breakpoint in another\\n   file (probably one that hasn\\'t been loaded yet).  The file is\\n   searched on ``sys.path``.  Note that each breakpoint is assigned a\\n   number to which all the other breakpoint commands refer.\\n\\n   If a second argument is present, it is an expression which must\\n   evaluate to true before the breakpoint is honored.\\n\\n   Without argument, list all breaks, including for each breakpoint,\\n   the number of times that breakpoint has been hit, the current\\n   ignore count, and the associated condition if any.\\n\\ntbreak [([filename:]lineno | function) [, condition]]\\n\\n   Temporary breakpoint, which is removed automatically when it is\\n   first hit. The arguments are the same as for ``break``.\\n\\ncl(ear) [filename:lineno | bpnumber [bpnumber ...]]\\n\\n   With a *filename:lineno* argument, clear all the breakpoints at\\n   this line. With a space separated list of breakpoint numbers, clear\\n   those breakpoints. Without argument, clear all breaks (but first\\n   ask confirmation).\\n\\ndisable [bpnumber [bpnumber ...]]\\n\\n   Disable the breakpoints given as a space separated list of\\n   breakpoint numbers.  Disabling a breakpoint means it cannot cause\\n   the program to stop execution, but unlike clearing a breakpoint, it\\n   remains in the list of breakpoints and can be (re-)enabled.\\n\\nenable [bpnumber [bpnumber ...]]\\n\\n   Enable the breakpoints specified.\\n\\nignore bpnumber [count]\\n\\n   Set the ignore count for the given breakpoint number.  If count is\\n   omitted, the ignore count is set to 0.  A breakpoint becomes active\\n   when the ignore count is zero.  When non-zero, the count is\\n   decremented each time the breakpoint is reached and the breakpoint\\n   is not disabled and any associated condition evaluates to true.\\n\\ncondition bpnumber [condition]\\n\\n   Set a new *condition* for the breakpoint, an expression which must\\n   evaluate to true before the breakpoint is honored.  If *condition*\\n   is absent, any existing condition is removed; i.e., the breakpoint\\n   is made unconditional.\\n\\ncommands [bpnumber]\\n\\n   Specify a list of commands for breakpoint number *bpnumber*.  The\\n   commands themselves appear on the following lines.  Type a line\\n   containing just ``end`` to terminate the commands. An example:\\n\\n      (Pdb) commands 1\\n      (com) print some_variable\\n      (com) end\\n      (Pdb)\\n\\n   To remove all commands from a breakpoint, type commands and follow\\n   it immediately with ``end``; that is, give no commands.\\n\\n   With no *bpnumber* argument, commands refers to the last breakpoint\\n   set.\\n\\n   You can use breakpoint commands to start your program up again.\\n   Simply use the continue command, or step, or any other command that\\n   resumes execution.\\n\\n   Specifying any command resuming execution (currently continue,\\n   step, next, return, jump, quit and their abbreviations) terminates\\n   the command list (as if that command was immediately followed by\\n   end). This is because any time you resume execution (even with a\\n   simple next or step), you may encounter another breakpoint--which\\n   could have its own command list, leading to ambiguities about which\\n   list to execute.\\n\\n   If you use the \\'silent\\' command in the command list, the usual\\n   message about stopping at a breakpoint is not printed.  This may be\\n   desirable for breakpoints that are to print a specific message and\\n   then continue.  If none of the other commands print anything, you\\n   see no sign that the breakpoint was reached.\\n\\ns(tep)\\n\\n   Execute the current line, stop at the first possible occasion\\n   (either in a function that is called or on the next line in the\\n   current function).\\n\\nn(ext)\\n\\n   Continue execution until the next line in the current function is\\n   reached or it returns.  (The difference between ``next`` and\\n   ``step`` is that ``step`` stops inside a called function, while\\n   ``next`` executes called functions at (nearly) full speed, only\\n   stopping at the next line in the current function.)\\n\\nunt(il) [lineno]\\n\\n   Without argument, continue execution until the line with a number\\n   greater than the current one is reached.\\n\\n   With a line number, continue execution until a line with a number\\n   greater or equal to that is reached.  In both cases, also stop when\\n   the current frame returns.\\n\\n   Changed in version 3.2: Allow giving an explicit line number.\\n\\nr(eturn)\\n\\n   Continue execution until the current function returns.\\n\\nc(ont(inue))\\n\\n   Continue execution, only stop when a breakpoint is encountered.\\n\\nj(ump) lineno\\n\\n   Set the next line that will be executed.  Only available in the\\n   bottom-most frame.  This lets you jump back and execute code again,\\n   or jump forward to skip code that you don\\'t want to run.\\n\\n   It should be noted that not all jumps are allowed -- for instance\\n   it is not possible to jump into the middle of a ``for`` loop or out\\n   of a ``finally`` clause.\\n\\nl(ist) [first[, last]]\\n\\n   List source code for the current file.  Without arguments, list 11\\n   lines around the current line or continue the previous listing.\\n   With ``.`` as argument, list 11 lines around the current line.\\n   With one argument, list 11 lines around at that line.  With two\\n   arguments, list the given range; if the second argument is less\\n   than the first, it is interpreted as a count.\\n\\n   The current line in the current frame is indicated by ``->``.  If\\n   an exception is being debugged, the line where the exception was\\n   originally raised or propagated is indicated by ``>>``, if it\\n   differs from the current line.\\n\\n   New in version 3.2: The ``>>`` marker.\\n\\nll | longlist\\n\\n   List all source code for the current function or frame.\\n   Interesting lines are marked as for ``list``.\\n\\n   New in version 3.2.\\n\\na(rgs)\\n\\n   Print the argument list of the current function.\\n\\np(rint) expression\\n\\n   Evaluate the *expression* in the current context and print its\\n   value.\\n\\npp expression\\n\\n   Like the ``print`` command, except the value of the expression is\\n   pretty-printed using the ``pprint`` module.\\n\\nwhatis expression\\n\\n   Print the type of the *expression*.\\n\\nsource expression\\n\\n   Try to get source code for the given object and display it.\\n\\n   New in version 3.2.\\n\\ndisplay [expression]\\n\\n   Display the value of the expression if it changed, each time\\n   execution stops in the current frame.\\n\\n   Without expression, list all display expressions for the current\\n   frame.\\n\\n   New in version 3.2.\\n\\nundisplay [expression]\\n\\n   Do not display the expression any more in the current frame.\\n   Without expression, clear all display expressions for the current\\n   frame.\\n\\n   New in version 3.2.\\n\\ninteract\\n\\n   Start an interative interpreter (using the ``code`` module) whose\\n   global namespace contains all the (global and local) names found in\\n   the current scope.\\n\\n   New in version 3.2.\\n\\nalias [name [command]]\\n\\n   Create an alias called *name* that executes *command*.  The command\\n   must *not* be enclosed in quotes.  Replaceable parameters can be\\n   indicated by ``%1``, ``%2``, and so on, while ``%*`` is replaced by\\n   all the parameters. If no command is given, the current alias for\\n   *name* is shown. If no arguments are given, all aliases are listed.\\n\\n   Aliases may be nested and can contain anything that can be legally\\n   typed at the pdb prompt.  Note that internal pdb commands *can* be\\n   overridden by aliases.  Such a command is then hidden until the\\n   alias is removed.  Aliasing is recursively applied to the first\\n   word of the command line; all other words in the line are left\\n   alone.\\n\\n   As an example, here are two useful aliases (especially when placed\\n   in the ``.pdbrc`` file):\\n\\n      # Print instance variables (usage \"pi classInst\")\\n      alias pi for k in %1.__dict__.keys(): print(\"%1.\",k,\"=\",%1.__dict__[k])\\n      # Print instance variables in self\\n      alias ps pi self\\n\\nunalias name\\n\\n   Delete the specified alias.\\n\\n! statement\\n\\n   Execute the (one-line) *statement* in the context of the current\\n   stack frame. The exclamation point can be omitted unless the first\\n   word of the statement resembles a debugger command.  To set a\\n   global variable, you can prefix the assignment command with a\\n   ``global`` statement on the same line, e.g.:\\n\\n      (Pdb) global list_options; list_options = [\\'-l\\']\\n      (Pdb)\\n\\nrun [args ...]\\nrestart [args ...]\\n\\n   Restart the debugged Python program.  If an argument is supplied,\\n   it is split with ``shlex`` and the result is used as the new\\n   ``sys.argv``. History, breakpoints, actions and debugger options\\n   are preserved. ``restart`` is an alias for ``run``.\\n\\nq(uit)\\n\\n   Quit from the debugger.  The program being executed is aborted.\\n\\n-[ Footnotes ]-\\n\\n[1] Whether a frame is considered to originate in a certain module is\\n    determined by the ``__name__`` in the frame globals.\\n',\n'del': '\\nThe ``del`` statement\\n*********************\\n\\n   del_stmt ::= \"del\" target_list\\n\\nDeletion is recursively defined very similar to the way assignment is\\ndefined. Rather than spelling it out in full details, here are some\\nhints.\\n\\nDeletion of a target list recursively deletes each target, from left\\nto right.\\n\\nDeletion of a name removes the binding of that name from the local or\\nglobal namespace, depending on whether the name occurs in a ``global``\\nstatement in the same code block.  If the name is unbound, a\\n``NameError`` exception will be raised.\\n\\nDeletion of attribute references, subscriptions and slicings is passed\\nto the primary object involved; deletion of a slicing is in general\\nequivalent to assignment of an empty slice of the right type (but even\\nthis is determined by the sliced object).\\n\\nChanged in version 3.2: Previously it was illegal to delete a name\\nfrom the local namespace if it occurs as a free variable in a nested\\nblock.\\n',\n'dict': '\\nDictionary displays\\n*******************\\n\\nA dictionary display is a possibly empty series of key/datum pairs\\nenclosed in curly braces:\\n\\n   dict_display       ::= \"{\" [key_datum_list | dict_comprehension] \"}\"\\n   key_datum_list     ::= key_datum (\",\" key_datum)* [\",\"]\\n   key_datum          ::= expression \":\" expression\\n   dict_comprehension ::= expression \":\" expression comp_for\\n\\nA dictionary display yields a new dictionary object.\\n\\nIf a comma-separated sequence of key/datum pairs is given, they are\\nevaluated from left to right to define the entries of the dictionary:\\neach key object is used as a key into the dictionary to store the\\ncorresponding datum.  This means that you can specify the same key\\nmultiple times in the key/datum list, and the final dictionary\\'s value\\nfor that key will be the last one given.\\n\\nA dict comprehension, in contrast to list and set comprehensions,\\nneeds two expressions separated with a colon followed by the usual\\n\"for\" and \"if\" clauses. When the comprehension is run, the resulting\\nkey and value elements are inserted in the new dictionary in the order\\nthey are produced.\\n\\nRestrictions on the types of the key values are listed earlier in\\nsection *The standard type hierarchy*.  (To summarize, the key type\\nshould be *hashable*, which excludes all mutable objects.)  Clashes\\nbetween duplicate keys are not detected; the last datum (textually\\nrightmost in the display) stored for a given key value prevails.\\n',\n'dynamic-features': '\\nInteraction with dynamic features\\n*********************************\\n\\nThere are several cases where Python statements are illegal when used\\nin conjunction with nested scopes that contain free variables.\\n\\nIf a variable is referenced in an enclosing scope, it is illegal to\\ndelete the name.  An error will be reported at compile time.\\n\\nIf the wild card form of import --- ``import *`` --- is used in a\\nfunction and the function contains or is a nested block with free\\nvariables, the compiler will raise a ``SyntaxError``.\\n\\nThe ``eval()`` and ``exec()`` functions do not have access to the full\\nenvironment for resolving names.  Names may be resolved in the local\\nand global namespaces of the caller.  Free variables are not resolved\\nin the nearest enclosing namespace, but in the global namespace.  [1]\\nThe ``exec()`` and ``eval()`` functions have optional arguments to\\noverride the global and local namespace.  If only one namespace is\\nspecified, it is used for both.\\n',\n'else': '\\nThe ``if`` statement\\n********************\\n\\nThe ``if`` statement is used for conditional execution:\\n\\n   if_stmt ::= \"if\" expression \":\" suite\\n               ( \"elif\" expression \":\" suite )*\\n               [\"else\" \":\" suite]\\n\\nIt selects exactly one of the suites by evaluating the expressions one\\nby one until one is found to be true (see section *Boolean operations*\\nfor the definition of true and false); then that suite is executed\\n(and no other part of the ``if`` statement is executed or evaluated).\\nIf all expressions are false, the suite of the ``else`` clause, if\\npresent, is executed.\\n',\n'exceptions': '\\nExceptions\\n**********\\n\\nExceptions are a means of breaking out of the normal flow of control\\nof a code block in order to handle errors or other exceptional\\nconditions.  An exception is *raised* at the point where the error is\\ndetected; it may be *handled* by the surrounding code block or by any\\ncode block that directly or indirectly invoked the code block where\\nthe error occurred.\\n\\nThe Python interpreter raises an exception when it detects a run-time\\nerror (such as division by zero).  A Python program can also\\nexplicitly raise an exception with the ``raise`` statement. Exception\\nhandlers are specified with the ``try`` ... ``except`` statement.  The\\n``finally`` clause of such a statement can be used to specify cleanup\\ncode which does not handle the exception, but is executed whether an\\nexception occurred or not in the preceding code.\\n\\nPython uses the \"termination\" model of error handling: an exception\\nhandler can find out what happened and continue execution at an outer\\nlevel, but it cannot repair the cause of the error and retry the\\nfailing operation (except by re-entering the offending piece of code\\nfrom the top).\\n\\nWhen an exception is not handled at all, the interpreter terminates\\nexecution of the program, or returns to its interactive main loop.  In\\neither case, it prints a stack backtrace, except when the exception is\\n``SystemExit``.\\n\\nExceptions are identified by class instances.  The ``except`` clause\\nis selected depending on the class of the instance: it must reference\\nthe class of the instance or a base class thereof.  The instance can\\nbe received by the handler and can carry additional information about\\nthe exceptional condition.\\n\\nNote: Exception messages are not part of the Python API.  Their contents\\n  may change from one version of Python to the next without warning\\n  and should not be relied on by code which will run under multiple\\n  versions of the interpreter.\\n\\nSee also the description of the ``try`` statement in section *The try\\nstatement* and ``raise`` statement in section *The raise statement*.\\n\\n-[ Footnotes ]-\\n\\n[1] This limitation occurs because the code that is executed by these\\n    operations is not available at the time the module is compiled.\\n',\n'execmodel': '\\nExecution model\\n***************\\n\\n\\nNaming and binding\\n==================\\n\\n*Names* refer to objects.  Names are introduced by name binding\\noperations. Each occurrence of a name in the program text refers to\\nthe *binding* of that name established in the innermost function block\\ncontaining the use.\\n\\nA *block* is a piece of Python program text that is executed as a\\nunit. The following are blocks: a module, a function body, and a class\\ndefinition. Each command typed interactively is a block.  A script\\nfile (a file given as standard input to the interpreter or specified\\non the interpreter command line the first argument) is a code block.\\nA script command (a command specified on the interpreter command line\\nwith the \\'**-c**\\' option) is a code block.  The string argument passed\\nto the built-in functions ``eval()`` and ``exec()`` is a code block.\\n\\nA code block is executed in an *execution frame*.  A frame contains\\nsome administrative information (used for debugging) and determines\\nwhere and how execution continues after the code block\\'s execution has\\ncompleted.\\n\\nA *scope* defines the visibility of a name within a block.  If a local\\nvariable is defined in a block, its scope includes that block.  If the\\ndefinition occurs in a function block, the scope extends to any blocks\\ncontained within the defining one, unless a contained block introduces\\na different binding for the name.  The scope of names defined in a\\nclass block is limited to the class block; it does not extend to the\\ncode blocks of methods -- this includes comprehensions and generator\\nexpressions since they are implemented using a function scope.  This\\nmeans that the following will fail:\\n\\n   class A:\\n       a = 42\\n       b = list(a + i for i in range(10))\\n\\nWhen a name is used in a code block, it is resolved using the nearest\\nenclosing scope.  The set of all such scopes visible to a code block\\nis called the block\\'s *environment*.\\n\\nIf a name is bound in a block, it is a local variable of that block,\\nunless declared as ``nonlocal``.  If a name is bound at the module\\nlevel, it is a global variable.  (The variables of the module code\\nblock are local and global.)  If a variable is used in a code block\\nbut not defined there, it is a *free variable*.\\n\\nWhen a name is not found at all, a ``NameError`` exception is raised.\\nIf the name refers to a local variable that has not been bound, a\\n``UnboundLocalError`` exception is raised.  ``UnboundLocalError`` is a\\nsubclass of ``NameError``.\\n\\nThe following constructs bind names: formal parameters to functions,\\n``import`` statements, class and function definitions (these bind the\\nclass or function name in the defining block), and targets that are\\nidentifiers if occurring in an assignment, ``for`` loop header, or\\nafter ``as`` in a ``with`` statement or ``except`` clause. The\\n``import`` statement of the form ``from ... import *`` binds all names\\ndefined in the imported module, except those beginning with an\\nunderscore.  This form may only be used at the module level.\\n\\nA target occurring in a ``del`` statement is also considered bound for\\nthis purpose (though the actual semantics are to unbind the name).\\n\\nEach assignment or import statement occurs within a block defined by a\\nclass or function definition or at the module level (the top-level\\ncode block).\\n\\nIf a name binding operation occurs anywhere within a code block, all\\nuses of the name within the block are treated as references to the\\ncurrent block.  This can lead to errors when a name is used within a\\nblock before it is bound.  This rule is subtle.  Python lacks\\ndeclarations and allows name binding operations to occur anywhere\\nwithin a code block.  The local variables of a code block can be\\ndetermined by scanning the entire text of the block for name binding\\noperations.\\n\\nIf the ``global`` statement occurs within a block, all uses of the\\nname specified in the statement refer to the binding of that name in\\nthe top-level namespace.  Names are resolved in the top-level\\nnamespace by searching the global namespace, i.e. the namespace of the\\nmodule containing the code block, and the builtins namespace, the\\nnamespace of the module ``builtins``.  The global namespace is\\nsearched first.  If the name is not found there, the builtins\\nnamespace is searched.  The global statement must precede all uses of\\nthe name.\\n\\nThe builtins namespace associated with the execution of a code block\\nis actually found by looking up the name ``__builtins__`` in its\\nglobal namespace; this should be a dictionary or a module (in the\\nlatter case the module\\'s dictionary is used).  By default, when in the\\n``__main__`` module, ``__builtins__`` is the built-in module\\n``builtins``; when in any other module, ``__builtins__`` is an alias\\nfor the dictionary of the ``builtins`` module itself.\\n``__builtins__`` can be set to a user-created dictionary to create a\\nweak form of restricted execution.\\n\\n**CPython implementation detail:** Users should not touch\\n``__builtins__``; it is strictly an implementation detail.  Users\\nwanting to override values in the builtins namespace should ``import``\\nthe ``builtins`` module and modify its attributes appropriately.\\n\\nThe namespace for a module is automatically created the first time a\\nmodule is imported.  The main module for a script is always called\\n``__main__``.\\n\\nThe ``global`` statement has the same scope as a name binding\\noperation in the same block.  If the nearest enclosing scope for a\\nfree variable contains a global statement, the free variable is\\ntreated as a global.\\n\\nA class definition is an executable statement that may use and define\\nnames. These references follow the normal rules for name resolution.\\nThe namespace of the class definition becomes the attribute dictionary\\nof the class.  Names defined at the class scope are not visible in\\nmethods.\\n\\n\\nInteraction with dynamic features\\n---------------------------------\\n\\nThere are several cases where Python statements are illegal when used\\nin conjunction with nested scopes that contain free variables.\\n\\nIf a variable is referenced in an enclosing scope, it is illegal to\\ndelete the name.  An error will be reported at compile time.\\n\\nIf the wild card form of import --- ``import *`` --- is used in a\\nfunction and the function contains or is a nested block with free\\nvariables, the compiler will raise a ``SyntaxError``.\\n\\nThe ``eval()`` and ``exec()`` functions do not have access to the full\\nenvironment for resolving names.  Names may be resolved in the local\\nand global namespaces of the caller.  Free variables are not resolved\\nin the nearest enclosing namespace, but in the global namespace.  [1]\\nThe ``exec()`` and ``eval()`` functions have optional arguments to\\noverride the global and local namespace.  If only one namespace is\\nspecified, it is used for both.\\n\\n\\nExceptions\\n==========\\n\\nExceptions are a means of breaking out of the normal flow of control\\nof a code block in order to handle errors or other exceptional\\nconditions.  An exception is *raised* at the point where the error is\\ndetected; it may be *handled* by the surrounding code block or by any\\ncode block that directly or indirectly invoked the code block where\\nthe error occurred.\\n\\nThe Python interpreter raises an exception when it detects a run-time\\nerror (such as division by zero).  A Python program can also\\nexplicitly raise an exception with the ``raise`` statement. Exception\\nhandlers are specified with the ``try`` ... ``except`` statement.  The\\n``finally`` clause of such a statement can be used to specify cleanup\\ncode which does not handle the exception, but is executed whether an\\nexception occurred or not in the preceding code.\\n\\nPython uses the \"termination\" model of error handling: an exception\\nhandler can find out what happened and continue execution at an outer\\nlevel, but it cannot repair the cause of the error and retry the\\nfailing operation (except by re-entering the offending piece of code\\nfrom the top).\\n\\nWhen an exception is not handled at all, the interpreter terminates\\nexecution of the program, or returns to its interactive main loop.  In\\neither case, it prints a stack backtrace, except when the exception is\\n``SystemExit``.\\n\\nExceptions are identified by class instances.  The ``except`` clause\\nis selected depending on the class of the instance: it must reference\\nthe class of the instance or a base class thereof.  The instance can\\nbe received by the handler and can carry additional information about\\nthe exceptional condition.\\n\\nNote: Exception messages are not part of the Python API.  Their contents\\n  may change from one version of Python to the next without warning\\n  and should not be relied on by code which will run under multiple\\n  versions of the interpreter.\\n\\nSee also the description of the ``try`` statement in section *The try\\nstatement* and ``raise`` statement in section *The raise statement*.\\n\\n-[ Footnotes ]-\\n\\n[1] This limitation occurs because the code that is executed by these\\n    operations is not available at the time the module is compiled.\\n',\n'exprlists': '\\nExpression lists\\n****************\\n\\n   expression_list ::= expression ( \",\" expression )* [\",\"]\\n\\nAn expression list containing at least one comma yields a tuple.  The\\nlength of the tuple is the number of expressions in the list.  The\\nexpressions are evaluated from left to right.\\n\\nThe trailing comma is required only to create a single tuple (a.k.a. a\\n*singleton*); it is optional in all other cases.  A single expression\\nwithout a trailing comma doesn\\'t create a tuple, but rather yields the\\nvalue of that expression. (To create an empty tuple, use an empty pair\\nof parentheses: ``()``.)\\n',\n'floating': '\\nFloating point literals\\n***********************\\n\\nFloating point literals are described by the following lexical\\ndefinitions:\\n\\n   floatnumber   ::= pointfloat | exponentfloat\\n   pointfloat    ::= [intpart] fraction | intpart \".\"\\n   exponentfloat ::= (intpart | pointfloat) exponent\\n   intpart       ::= digit+\\n   fraction      ::= \".\" digit+\\n   exponent      ::= (\"e\" | \"E\") [\"+\" | \"-\"] digit+\\n\\nNote that the integer and exponent parts are always interpreted using\\nradix 10. For example, ``077e010`` is legal, and denotes the same\\nnumber as ``77e10``. The allowed range of floating point literals is\\nimplementation-dependent. Some examples of floating point literals:\\n\\n   3.14    10.    .001    1e100    3.14e-10    0e0\\n\\nNote that numeric literals do not include a sign; a phrase like ``-1``\\nis actually an expression composed of the unary operator ``-`` and the\\nliteral ``1``.\\n',\n'for': '\\nThe ``for`` statement\\n*********************\\n\\nThe ``for`` statement is used to iterate over the elements of a\\nsequence (such as a string, tuple or list) or other iterable object:\\n\\n   for_stmt ::= \"for\" target_list \"in\" expression_list \":\" suite\\n                [\"else\" \":\" suite]\\n\\nThe expression list is evaluated once; it should yield an iterable\\nobject.  An iterator is created for the result of the\\n``expression_list``.  The suite is then executed once for each item\\nprovided by the iterator, in the order of ascending indices.  Each\\nitem in turn is assigned to the target list using the standard rules\\nfor assignments (see *Assignment statements*), and then the suite is\\nexecuted.  When the items are exhausted (which is immediately when the\\nsequence is empty or an iterator raises a ``StopIteration``\\nexception), the suite in the ``else`` clause, if present, is executed,\\nand the loop terminates.\\n\\nA ``break`` statement executed in the first suite terminates the loop\\nwithout executing the ``else`` clause\\'s suite.  A ``continue``\\nstatement executed in the first suite skips the rest of the suite and\\ncontinues with the next item, or with the ``else`` clause if there was\\nno next item.\\n\\nThe suite may assign to the variable(s) in the target list; this does\\nnot affect the next item assigned to it.\\n\\nNames in the target list are not deleted when the loop is finished,\\nbut if the sequence is empty, it will not have been assigned to at all\\nby the loop.  Hint: the built-in function ``range()`` returns an\\niterator of integers suitable to emulate the effect of Pascal\\'s ``for\\ni := a to b do``; e.g., ``list(range(3))`` returns the list ``[0, 1,\\n2]``.\\n\\nNote: There is a subtlety when the sequence is being modified by the loop\\n  (this can only occur for mutable sequences, i.e. lists).  An\\n  internal counter is used to keep track of which item is used next,\\n  and this is incremented on each iteration.  When this counter has\\n  reached the length of the sequence the loop terminates.  This means\\n  that if the suite deletes the current (or a previous) item from the\\n  sequence, the next item will be skipped (since it gets the index of\\n  the current item which has already been treated).  Likewise, if the\\n  suite inserts an item in the sequence before the current item, the\\n  current item will be treated again the next time through the loop.\\n  This can lead to nasty bugs that can be avoided by making a\\n  temporary copy using a slice of the whole sequence, e.g.,\\n\\n     for x in a[:]:\\n         if x < 0: a.remove(x)\\n',\n'formatstrings': '\\nFormat String Syntax\\n********************\\n\\nThe ``str.format()`` method and the ``Formatter`` class share the same\\nsyntax for format strings (although in the case of ``Formatter``,\\nsubclasses can define their own format string syntax).\\n\\nFormat strings contain \"replacement fields\" surrounded by curly braces\\n``{}``. Anything that is not contained in braces is considered literal\\ntext, which is copied unchanged to the output.  If you need to include\\na brace character in the literal text, it can be escaped by doubling:\\n``{{`` and ``}}``.\\n\\nThe grammar for a replacement field is as follows:\\n\\n      replacement_field ::= \"{\" [field_name] [\"!\" conversion] [\":\" format_spec] \"}\"\\n      field_name        ::= arg_name (\".\" attribute_name | \"[\" element_index \"]\")*\\n      arg_name          ::= [identifier | integer]\\n      attribute_name    ::= identifier\\n      element_index     ::= integer | index_string\\n      index_string      ::= <any source character except \"]\"> +\\n      conversion        ::= \"r\" | \"s\" | \"a\"\\n      format_spec       ::= <described in the next section>\\n\\nIn less formal terms, the replacement field can start with a\\n*field_name* that specifies the object whose value is to be formatted\\nand inserted into the output instead of the replacement field. The\\n*field_name* is optionally followed by a  *conversion* field, which is\\npreceded by an exclamation point ``\\'!\\'``, and a *format_spec*, which\\nis preceded by a colon ``\\':\\'``.  These specify a non-default format\\nfor the replacement value.\\n\\nSee also the *Format Specification Mini-Language* section.\\n\\nThe *field_name* itself begins with an *arg_name* that is either a\\nnumber or a keyword.  If it\\'s a number, it refers to a positional\\nargument, and if it\\'s a keyword, it refers to a named keyword\\nargument.  If the numerical arg_names in a format string are 0, 1, 2,\\n... in sequence, they can all be omitted (not just some) and the\\nnumbers 0, 1, 2, ... will be automatically inserted in that order.\\nBecause *arg_name* is not quote-delimited, it is not possible to\\nspecify arbitrary dictionary keys (e.g., the strings ``\\'10\\'`` or\\n``\\':-]\\'``) within a format string. The *arg_name* can be followed by\\nany number of index or attribute expressions. An expression of the\\nform ``\\'.name\\'`` selects the named attribute using ``getattr()``,\\nwhile an expression of the form ``\\'[index]\\'`` does an index lookup\\nusing ``__getitem__()``.\\n\\nChanged in version 3.1: The positional argument specifiers can be\\nomitted, so ``\\'{} {}\\'`` is equivalent to ``\\'{0} {1}\\'``.\\n\\nSome simple format string examples:\\n\\n   \"First, thou shalt count to {0}\" # References first positional argument\\n   \"Bring me a {}\"                  # Implicitly references the first positional argument\\n   \"From {} to {}\"                  # Same as \"From {0} to {1}\"\\n   \"My quest is {name}\"             # References keyword argument \\'name\\'\\n   \"Weight in tons {0.weight}\"      # \\'weight\\' attribute of first positional arg\\n   \"Units destroyed: {players[0]}\"  # First element of keyword argument \\'players\\'.\\n\\nThe *conversion* field causes a type coercion before formatting.\\nNormally, the job of formatting a value is done by the\\n``__format__()`` method of the value itself.  However, in some cases\\nit is desirable to force a type to be formatted as a string,\\noverriding its own definition of formatting.  By converting the value\\nto a string before calling ``__format__()``, the normal formatting\\nlogic is bypassed.\\n\\nThree conversion flags are currently supported: ``\\'!s\\'`` which calls\\n``str()`` on the value, ``\\'!r\\'`` which calls ``repr()`` and ``\\'!a\\'``\\nwhich calls ``ascii()``.\\n\\nSome examples:\\n\\n   \"Harold\\'s a clever {0!s}\"        # Calls str() on the argument first\\n   \"Bring out the holy {name!r}\"    # Calls repr() on the argument first\\n   \"More {!a}\"                      # Calls ascii() on the argument first\\n\\nThe *format_spec* field contains a specification of how the value\\nshould be presented, including such details as field width, alignment,\\npadding, decimal precision and so on.  Each value type can define its\\nown \"formatting mini-language\" or interpretation of the *format_spec*.\\n\\nMost built-in types support a common formatting mini-language, which\\nis described in the next section.\\n\\nA *format_spec* field can also include nested replacement fields\\nwithin it. These nested replacement fields can contain only a field\\nname; conversion flags and format specifications are not allowed.  The\\nreplacement fields within the format_spec are substituted before the\\n*format_spec* string is interpreted. This allows the formatting of a\\nvalue to be dynamically specified.\\n\\nSee the *Format examples* section for some examples.\\n\\n\\nFormat Specification Mini-Language\\n==================================\\n\\n\"Format specifications\" are used within replacement fields contained\\nwithin a format string to define how individual values are presented\\n(see *Format String Syntax*).  They can also be passed directly to the\\nbuilt-in ``format()`` function.  Each formattable type may define how\\nthe format specification is to be interpreted.\\n\\nMost built-in types implement the following options for format\\nspecifications, although some of the formatting options are only\\nsupported by the numeric types.\\n\\nA general convention is that an empty format string (``\"\"``) produces\\nthe same result as if you had called ``str()`` on the value. A non-\\nempty format string typically modifies the result.\\n\\nThe general form of a *standard format specifier* is:\\n\\n   format_spec ::= [[fill]align][sign][#][0][width][,][.precision][type]\\n   fill        ::= <a character other than \\'{\\' or \\'}\\'>\\n   align       ::= \"<\" | \">\" | \"=\" | \"^\"\\n   sign        ::= \"+\" | \"-\" | \" \"\\n   width       ::= integer\\n   precision   ::= integer\\n   type        ::= \"b\" | \"c\" | \"d\" | \"e\" | \"E\" | \"f\" | \"F\" | \"g\" | \"G\" | \"n\" | \"o\" | \"s\" | \"x\" | \"X\" | \"%\"\\n\\nThe *fill* character can be any character other than \\'{\\' or \\'}\\'.  The\\npresence of a fill character is signaled by the character following\\nit, which must be one of the alignment options.  If the second\\ncharacter of *format_spec* is not a valid alignment option, then it is\\nassumed that both the fill character and the alignment option are\\nabsent.\\n\\nThe meaning of the various alignment options is as follows:\\n\\n   +-----------+------------------------------------------------------------+\\n   | Option    | Meaning                                                    |\\n   +===========+============================================================+\\n   | ``\\'<\\'``   | Forces the field to be left-aligned within the available   |\\n   |           | space (this is the default for most objects).              |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'>\\'``   | Forces the field to be right-aligned within the available  |\\n   |           | space (this is the default for numbers).                   |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'=\\'``   | Forces the padding to be placed after the sign (if any)    |\\n   |           | but before the digits.  This is used for printing fields   |\\n   |           | in the form \\'+000000120\\'. This alignment option is only    |\\n   |           | valid for numeric types.                                   |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'^\\'``   | Forces the field to be centered within the available       |\\n   |           | space.                                                     |\\n   +-----------+------------------------------------------------------------+\\n\\nNote that unless a minimum field width is defined, the field width\\nwill always be the same size as the data to fill it, so that the\\nalignment option has no meaning in this case.\\n\\nThe *sign* option is only valid for number types, and can be one of\\nthe following:\\n\\n   +-----------+------------------------------------------------------------+\\n   | Option    | Meaning                                                    |\\n   +===========+============================================================+\\n   | ``\\'+\\'``   | indicates that a sign should be used for both positive as  |\\n   |           | well as negative numbers.                                  |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'-\\'``   | indicates that a sign should be used only for negative     |\\n   |           | numbers (this is the default behavior).                    |\\n   +-----------+------------------------------------------------------------+\\n   | space     | indicates that a leading space should be used on positive  |\\n   |           | numbers, and a minus sign on negative numbers.             |\\n   +-----------+------------------------------------------------------------+\\n\\nThe ``\\'#\\'`` option causes the \"alternate form\" to be used for the\\nconversion.  The alternate form is defined differently for different\\ntypes.  This option is only valid for integer, float, complex and\\nDecimal types. For integers, when binary, octal, or hexadecimal output\\nis used, this option adds the prefix respective ``\\'0b\\'``, ``\\'0o\\'``, or\\n``\\'0x\\'`` to the output value. For floats, complex and Decimal the\\nalternate form causes the result of the conversion to always contain a\\ndecimal-point character, even if no digits follow it. Normally, a\\ndecimal-point character appears in the result of these conversions\\nonly if a digit follows it. In addition, for ``\\'g\\'`` and ``\\'G\\'``\\nconversions, trailing zeros are not removed from the result.\\n\\nThe ``\\',\\'`` option signals the use of a comma for a thousands\\nseparator. For a locale aware separator, use the ``\\'n\\'`` integer\\npresentation type instead.\\n\\nChanged in version 3.1: Added the ``\\',\\'`` option (see also **PEP\\n378**).\\n\\n*width* is a decimal integer defining the minimum field width.  If not\\nspecified, then the field width will be determined by the content.\\n\\nPreceding the *width* field by a zero (``\\'0\\'``) character enables\\nsign-aware zero-padding for numeric types.  This is equivalent to a\\n*fill* character of ``\\'0\\'`` with an *alignment* type of ``\\'=\\'``.\\n\\nThe *precision* is a decimal number indicating how many digits should\\nbe displayed after the decimal point for a floating point value\\nformatted with ``\\'f\\'`` and ``\\'F\\'``, or before and after the decimal\\npoint for a floating point value formatted with ``\\'g\\'`` or ``\\'G\\'``.\\nFor non-number types the field indicates the maximum field size - in\\nother words, how many characters will be used from the field content.\\nThe *precision* is not allowed for integer values.\\n\\nFinally, the *type* determines how the data should be presented.\\n\\nThe available string presentation types are:\\n\\n   +-----------+------------------------------------------------------------+\\n   | Type      | Meaning                                                    |\\n   +===========+============================================================+\\n   | ``\\'s\\'``   | String format. This is the default type for strings and    |\\n   |           | may be omitted.                                            |\\n   +-----------+------------------------------------------------------------+\\n   | None      | The same as ``\\'s\\'``.                                       |\\n   +-----------+------------------------------------------------------------+\\n\\nThe available integer presentation types are:\\n\\n   +-----------+------------------------------------------------------------+\\n   | Type      | Meaning                                                    |\\n   +===========+============================================================+\\n   | ``\\'b\\'``   | Binary format. Outputs the number in base 2.               |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'c\\'``   | Character. Converts the integer to the corresponding       |\\n   |           | unicode character before printing.                         |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'d\\'``   | Decimal Integer. Outputs the number in base 10.            |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'o\\'``   | Octal format. Outputs the number in base 8.                |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'x\\'``   | Hex format. Outputs the number in base 16, using lower-    |\\n   |           | case letters for the digits above 9.                       |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'X\\'``   | Hex format. Outputs the number in base 16, using upper-    |\\n   |           | case letters for the digits above 9.                       |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'n\\'``   | Number. This is the same as ``\\'d\\'``, except that it uses   |\\n   |           | the current locale setting to insert the appropriate       |\\n   |           | number separator characters.                               |\\n   +-----------+------------------------------------------------------------+\\n   | None      | The same as ``\\'d\\'``.                                       |\\n   +-----------+------------------------------------------------------------+\\n\\nIn addition to the above presentation types, integers can be formatted\\nwith the floating point presentation types listed below (except\\n``\\'n\\'`` and None). When doing so, ``float()`` is used to convert the\\ninteger to a floating point number before formatting.\\n\\nThe available presentation types for floating point and decimal values\\nare:\\n\\n   +-----------+------------------------------------------------------------+\\n   | Type      | Meaning                                                    |\\n   +===========+============================================================+\\n   | ``\\'e\\'``   | Exponent notation. Prints the number in scientific         |\\n   |           | notation using the letter \\'e\\' to indicate the exponent.    |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'E\\'``   | Exponent notation. Same as ``\\'e\\'`` except it uses an upper |\\n   |           | case \\'E\\' as the separator character.                       |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'f\\'``   | Fixed point. Displays the number as a fixed-point number.  |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'F\\'``   | Fixed point. Same as ``\\'f\\'``, but converts ``nan`` to      |\\n   |           | ``NAN`` and ``inf`` to ``INF``.                            |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'g\\'``   | General format.  For a given precision ``p >= 1``, this    |\\n   |           | rounds the number to ``p`` significant digits and then     |\\n   |           | formats the result in either fixed-point format or in      |\\n   |           | scientific notation, depending on its magnitude.  The      |\\n   |           | precise rules are as follows: suppose that the result      |\\n   |           | formatted with presentation type ``\\'e\\'`` and precision     |\\n   |           | ``p-1`` would have exponent ``exp``.  Then if ``-4 <= exp  |\\n   |           | < p``, the number is formatted with presentation type      |\\n   |           | ``\\'f\\'`` and precision ``p-1-exp``. Otherwise, the number   |\\n   |           | is formatted with presentation type ``\\'e\\'`` and precision  |\\n   |           | ``p-1``. In both cases insignificant trailing zeros are    |\\n   |           | removed from the significand, and the decimal point is     |\\n   |           | also removed if there are no remaining digits following    |\\n   |           | it.  Positive and negative infinity, positive and negative |\\n   |           | zero, and nans, are formatted as ``inf``, ``-inf``, ``0``, |\\n   |           | ``-0`` and ``nan`` respectively, regardless of the         |\\n   |           | precision.  A precision of ``0`` is treated as equivalent  |\\n   |           | to a precision of ``1``.                                   |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'G\\'``   | General format. Same as ``\\'g\\'`` except switches to ``\\'E\\'`` |\\n   |           | if the number gets too large. The representations of       |\\n   |           | infinity and NaN are uppercased, too.                      |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'n\\'``   | Number. This is the same as ``\\'g\\'``, except that it uses   |\\n   |           | the current locale setting to insert the appropriate       |\\n   |           | number separator characters.                               |\\n   +-----------+------------------------------------------------------------+\\n   | ``\\'%\\'``   | Percentage. Multiplies the number by 100 and displays in   |\\n   |           | fixed (``\\'f\\'``) format, followed by a percent sign.        |\\n   +-----------+------------------------------------------------------------+\\n   | None      | Similar to ``\\'g\\'``, except with at least one digit past    |\\n   |           | the decimal point and a default precision of 12. This is   |\\n   |           | intended to match ``str()``, except you can add the other  |\\n   |           | format modifiers.                                          |\\n   +-----------+------------------------------------------------------------+\\n\\n\\nFormat examples\\n===============\\n\\nThis section contains examples of the new format syntax and comparison\\nwith the old ``%``-formatting.\\n\\nIn most of the cases the syntax is similar to the old\\n``%``-formatting, with the addition of the ``{}`` and with ``:`` used\\ninstead of ``%``. For example, ``\\'%03.2f\\'`` can be translated to\\n``\\'{:03.2f}\\'``.\\n\\nThe new format syntax also supports new and different options, shown\\nin the follow examples.\\n\\nAccessing arguments by position:\\n\\n   >>> \\'{0}, {1}, {2}\\'.format(\\'a\\', \\'b\\', \\'c\\')\\n   \\'a, b, c\\'\\n   >>> \\'{}, {}, {}\\'.format(\\'a\\', \\'b\\', \\'c\\')  # 3.1+ only\\n   \\'a, b, c\\'\\n   >>> \\'{2}, {1}, {0}\\'.format(\\'a\\', \\'b\\', \\'c\\')\\n   \\'c, b, a\\'\\n   >>> \\'{2}, {1}, {0}\\'.format(*\\'abc\\')      # unpacking argument sequence\\n   \\'c, b, a\\'\\n   >>> \\'{0}{1}{0}\\'.format(\\'abra\\', \\'cad\\')   # arguments\\' indices can be repeated\\n   \\'abracadabra\\'\\n\\nAccessing arguments by name:\\n\\n   >>> \\'Coordinates: {latitude}, {longitude}\\'.format(latitude=\\'37.24N\\', longitude=\\'-115.81W\\')\\n   \\'Coordinates: 37.24N, -115.81W\\'\\n   >>> coord = {\\'latitude\\': \\'37.24N\\', \\'longitude\\': \\'-115.81W\\'}\\n   >>> \\'Coordinates: {latitude}, {longitude}\\'.format(**coord)\\n   \\'Coordinates: 37.24N, -115.81W\\'\\n\\nAccessing arguments\\' attributes:\\n\\n   >>> c = 3-5j\\n   >>> (\\'The complex number {0} is formed from the real part {0.real} \\'\\n   ...  \\'and the imaginary part {0.imag}.\\').format(c)\\n   \\'The complex number (3-5j) is formed from the real part 3.0 and the imaginary part -5.0.\\'\\n   >>> class Point:\\n   ...     def __init__(self, x, y):\\n   ...         self.x, self.y = x, y\\n   ...     def __str__(self):\\n   ...         return \\'Point({self.x}, {self.y})\\'.format(self=self)\\n   ...\\n   >>> str(Point(4, 2))\\n   \\'Point(4, 2)\\'\\n\\nAccessing arguments\\' items:\\n\\n   >>> coord = (3, 5)\\n   >>> \\'X: {0[0]};  Y: {0[1]}\\'.format(coord)\\n   \\'X: 3;  Y: 5\\'\\n\\nReplacing ``%s`` and ``%r``:\\n\\n   >>> \"repr() shows quotes: {!r}; str() doesn\\'t: {!s}\".format(\\'test1\\', \\'test2\\')\\n   \"repr() shows quotes: \\'test1\\'; str() doesn\\'t: test2\"\\n\\nAligning the text and specifying a width:\\n\\n   >>> \\'{:<30}\\'.format(\\'left aligned\\')\\n   \\'left aligned                  \\'\\n   >>> \\'{:>30}\\'.format(\\'right aligned\\')\\n   \\'                 right aligned\\'\\n   >>> \\'{:^30}\\'.format(\\'centered\\')\\n   \\'           centered           \\'\\n   >>> \\'{:*^30}\\'.format(\\'centered\\')  # use \\'*\\' as a fill char\\n   \\'***********centered***********\\'\\n\\nReplacing ``%+f``, ``%-f``, and ``% f`` and specifying a sign:\\n\\n   >>> \\'{:+f}; {:+f}\\'.format(3.14, -3.14)  # show it always\\n   \\'+3.140000; -3.140000\\'\\n   >>> \\'{: f}; {: f}\\'.format(3.14, -3.14)  # show a space for positive numbers\\n   \\' 3.140000; -3.140000\\'\\n   >>> \\'{:-f}; {:-f}\\'.format(3.14, -3.14)  # show only the minus -- same as \\'{:f}; {:f}\\'\\n   \\'3.140000; -3.140000\\'\\n\\nReplacing ``%x`` and ``%o`` and converting the value to different\\nbases:\\n\\n   >>> # format also supports binary numbers\\n   >>> \"int: {0:d};  hex: {0:x};  oct: {0:o};  bin: {0:b}\".format(42)\\n   \\'int: 42;  hex: 2a;  oct: 52;  bin: 101010\\'\\n   >>> # with 0x, 0o, or 0b as prefix:\\n   >>> \"int: {0:d};  hex: {0:#x};  oct: {0:#o};  bin: {0:#b}\".format(42)\\n   \\'int: 42;  hex: 0x2a;  oct: 0o52;  bin: 0b101010\\'\\n\\nUsing the comma as a thousands separator:\\n\\n   >>> \\'{:,}\\'.format(1234567890)\\n   \\'1,234,567,890\\'\\n\\nExpressing a percentage:\\n\\n   >>> points = 19\\n   >>> total = 22\\n   >>> \\'Correct answers: {:.2%}\\'.format(points/total)\\n   \\'Correct answers: 86.36%\\'\\n\\nUsing type-specific formatting:\\n\\n   >>> import datetime\\n   >>> d = datetime.datetime(2010, 7, 4, 12, 15, 58)\\n   >>> \\'{:%Y-%m-%d %H:%M:%S}\\'.format(d)\\n   \\'2010-07-04 12:15:58\\'\\n\\nNesting arguments and more complex examples:\\n\\n   >>> for align, text in zip(\\'<^>\\', [\\'left\\', \\'center\\', \\'right\\']):\\n   ...     \\'{0:{fill}{align}16}\\'.format(text, fill=align, align=align)\\n   ...\\n   \\'left<<<<<<<<<<<<\\'\\n   \\'^^^^^center^^^^^\\'\\n   \\'>>>>>>>>>>>right\\'\\n   >>>\\n   >>> octets = [192, 168, 0, 1]\\n   >>> \\'{:02X}{:02X}{:02X}{:02X}\\'.format(*octets)\\n   \\'C0A80001\\'\\n   >>> int(_, 16)\\n   3232235521\\n   >>>\\n   >>> width = 5\\n   >>> for num in range(5,12): #doctest: +NORMALIZE_WHITESPACE\\n   ...     for base in \\'dXob\\':\\n   ...         print(\\'{0:{width}{base}}\\'.format(num, base=base, width=width), end=\\' \\')\\n   ...     print()\\n   ...\\n       5     5     5   101\\n       6     6     6   110\\n       7     7     7   111\\n       8     8    10  1000\\n       9     9    11  1001\\n      10     A    12  1010\\n      11     B    13  1011\\n',\n'function': '\\nFunction definitions\\n********************\\n\\nA function definition defines a user-defined function object (see\\nsection *The standard type hierarchy*):\\n\\n   funcdef        ::= [decorators] \"def\" funcname \"(\" [parameter_list] \")\" [\"->\" expression] \":\" suite\\n   decorators     ::= decorator+\\n   decorator      ::= \"@\" dotted_name [\"(\" [parameter_list [\",\"]] \")\"] NEWLINE\\n   dotted_name    ::= identifier (\".\" identifier)*\\n   parameter_list ::= (defparameter \",\")*\\n                      ( \"*\" [parameter] (\",\" defparameter)* [\",\" \"**\" parameter]\\n                      | \"**\" parameter\\n                      | defparameter [\",\"] )\\n   parameter      ::= identifier [\":\" expression]\\n   defparameter   ::= parameter [\"=\" expression]\\n   funcname       ::= identifier\\n\\nA function definition is an executable statement.  Its execution binds\\nthe function name in the current local namespace to a function object\\n(a wrapper around the executable code for the function).  This\\nfunction object contains a reference to the current global namespace\\nas the global namespace to be used when the function is called.\\n\\nThe function definition does not execute the function body; this gets\\nexecuted only when the function is called. [3]\\n\\nA function definition may be wrapped by one or more *decorator*\\nexpressions. Decorator expressions are evaluated when the function is\\ndefined, in the scope that contains the function definition.  The\\nresult must be a callable, which is invoked with the function object\\nas the only argument. The returned value is bound to the function name\\ninstead of the function object.  Multiple decorators are applied in\\nnested fashion. For example, the following code\\n\\n   @f1(arg)\\n   @f2\\n   def func(): pass\\n\\nis equivalent to\\n\\n   def func(): pass\\n   func = f1(arg)(f2(func))\\n\\nWhen one or more *parameters* have the form *parameter* ``=``\\n*expression*, the function is said to have \"default parameter values.\"\\nFor a parameter with a default value, the corresponding *argument* may\\nbe omitted from a call, in which case the parameter\\'s default value is\\nsubstituted.  If a parameter has a default value, all following\\nparameters up until the \"``*``\" must also have a default value ---\\nthis is a syntactic restriction that is not expressed by the grammar.\\n\\n**Default parameter values are evaluated when the function definition\\nis executed.** This means that the expression is evaluated once, when\\nthe function is defined, and that the same \"pre-computed\" value is\\nused for each call.  This is especially important to understand when a\\ndefault parameter is a mutable object, such as a list or a dictionary:\\nif the function modifies the object (e.g. by appending an item to a\\nlist), the default value is in effect modified. This is generally not\\nwhat was intended.  A way around this is to use ``None`` as the\\ndefault, and explicitly test for it in the body of the function, e.g.:\\n\\n   def whats_on_the_telly(penguin=None):\\n       if penguin is None:\\n           penguin = []\\n       penguin.append(\"property of the zoo\")\\n       return penguin\\n\\nFunction call semantics are described in more detail in section\\n*Calls*. A function call always assigns values to all parameters\\nmentioned in the parameter list, either from position arguments, from\\nkeyword arguments, or from default values.  If the form\\n\"``*identifier``\" is present, it is initialized to a tuple receiving\\nany excess positional parameters, defaulting to the empty tuple.  If\\nthe form \"``**identifier``\" is present, it is initialized to a new\\ndictionary receiving any excess keyword arguments, defaulting to a new\\nempty dictionary. Parameters after \"``*``\" or \"``*identifier``\" are\\nkeyword-only parameters and may only be passed used keyword arguments.\\n\\nParameters may have annotations of the form \"``: expression``\"\\nfollowing the parameter name.  Any parameter may have an annotation\\neven those of the form ``*identifier`` or ``**identifier``.  Functions\\nmay have \"return\" annotation of the form \"``-> expression``\" after the\\nparameter list.  These annotations can be any valid Python expression\\nand are evaluated when the function definition is executed.\\nAnnotations may be evaluated in a different order than they appear in\\nthe source code.  The presence of annotations does not change the\\nsemantics of a function.  The annotation values are available as\\nvalues of a dictionary keyed by the parameters\\' names in the\\n``__annotations__`` attribute of the function object.\\n\\nIt is also possible to create anonymous functions (functions not bound\\nto a name), for immediate use in expressions.  This uses lambda forms,\\ndescribed in section *Lambdas*.  Note that the lambda form is merely a\\nshorthand for a simplified function definition; a function defined in\\na \"``def``\" statement can be passed around or assigned to another name\\njust like a function defined by a lambda form.  The \"``def``\" form is\\nactually more powerful since it allows the execution of multiple\\nstatements and annotations.\\n\\n**Programmer\\'s note:** Functions are first-class objects.  A \"``def``\"\\nform executed inside a function definition defines a local function\\nthat can be returned or passed around.  Free variables used in the\\nnested function can access the local variables of the function\\ncontaining the def.  See section *Naming and binding* for details.\\n\\nSee also:\\n\\n   **PEP 3107** - Function Annotations\\n      The original specification for function annotations.\\n',\n'global': '\\nThe ``global`` statement\\n************************\\n\\n   global_stmt ::= \"global\" identifier (\",\" identifier)*\\n\\nThe ``global`` statement is a declaration which holds for the entire\\ncurrent code block.  It means that the listed identifiers are to be\\ninterpreted as globals.  It would be impossible to assign to a global\\nvariable without ``global``, although free variables may refer to\\nglobals without being declared global.\\n\\nNames listed in a ``global`` statement must not be used in the same\\ncode block textually preceding that ``global`` statement.\\n\\nNames listed in a ``global`` statement must not be defined as formal\\nparameters or in a ``for`` loop control target, ``class`` definition,\\nfunction definition, or ``import`` statement.\\n\\n**CPython implementation detail:** The current implementation does not\\nenforce the latter two restrictions, but programs should not abuse\\nthis freedom, as future implementations may enforce them or silently\\nchange the meaning of the program.\\n\\n**Programmer\\'s note:** the ``global`` is a directive to the parser.\\nIt applies only to code parsed at the same time as the ``global``\\nstatement. In particular, a ``global`` statement contained in a string\\nor code object supplied to the built-in ``exec()`` function does not\\naffect the code block *containing* the function call, and code\\ncontained in such a string is unaffected by ``global`` statements in\\nthe code containing the function call.  The same applies to the\\n``eval()`` and ``compile()`` functions.\\n',\n'id-classes': '\\nReserved classes of identifiers\\n*******************************\\n\\nCertain classes of identifiers (besides keywords) have special\\nmeanings.  These classes are identified by the patterns of leading and\\ntrailing underscore characters:\\n\\n``_*``\\n   Not imported by ``from module import *``.  The special identifier\\n   ``_`` is used in the interactive interpreter to store the result of\\n   the last evaluation; it is stored in the ``builtins`` module.  When\\n   not in interactive mode, ``_`` has no special meaning and is not\\n   defined. See section *The import statement*.\\n\\n   Note: The name ``_`` is often used in conjunction with\\n     internationalization; refer to the documentation for the\\n     ``gettext`` module for more information on this convention.\\n\\n``__*__``\\n   System-defined names. These names are defined by the interpreter\\n   and its implementation (including the standard library).  Current\\n   system names are discussed in the *Special method names* section\\n   and elsewhere.  More will likely be defined in future versions of\\n   Python.  *Any* use of ``__*__`` names, in any context, that does\\n   not follow explicitly documented use, is subject to breakage\\n   without warning.\\n\\n``__*``\\n   Class-private names.  Names in this category, when used within the\\n   context of a class definition, are re-written to use a mangled form\\n   to help avoid name clashes between \"private\" attributes of base and\\n   derived classes. See section *Identifiers (Names)*.\\n',\n'identifiers': '\\nIdentifiers and keywords\\n************************\\n\\nIdentifiers (also referred to as *names*) are described by the\\nfollowing lexical definitions.\\n\\nThe syntax of identifiers in Python is based on the Unicode standard\\nannex UAX-31, with elaboration and changes as defined below; see also\\n**PEP 3131** for further details.\\n\\nWithin the ASCII range (U+0001..U+007F), the valid characters for\\nidentifiers are the same as in Python 2.x: the uppercase and lowercase\\nletters ``A`` through ``Z``, the underscore ``_`` and, except for the\\nfirst character, the digits ``0`` through ``9``.\\n\\nPython 3.0 introduces additional characters from outside the ASCII\\nrange (see **PEP 3131**).  For these characters, the classification\\nuses the version of the Unicode Character Database as included in the\\n``unicodedata`` module.\\n\\nIdentifiers are unlimited in length.  Case is significant.\\n\\n   identifier   ::= xid_start xid_continue*\\n   id_start     ::= <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property>\\n   id_continue  ::= <all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property>\\n   xid_start    ::= <all characters in id_start whose NFKC normalization is in \"id_start xid_continue*\">\\n   xid_continue ::= <all characters in id_continue whose NFKC normalization is in \"id_continue*\">\\n\\nThe Unicode category codes mentioned above stand for:\\n\\n* *Lu* - uppercase letters\\n\\n* *Ll* - lowercase letters\\n\\n* *Lt* - titlecase letters\\n\\n* *Lm* - modifier letters\\n\\n* *Lo* - other letters\\n\\n* *Nl* - letter numbers\\n\\n* *Mn* - nonspacing marks\\n\\n* *Mc* - spacing combining marks\\n\\n* *Nd* - decimal numbers\\n\\n* *Pc* - connector punctuations\\n\\n* *Other_ID_Start* - explicit list of characters in PropList.txt to\\n  support backwards compatibility\\n\\n* *Other_ID_Continue* - likewise\\n\\nAll identifiers are converted into the normal form NFKC while parsing;\\ncomparison of identifiers is based on NFKC.\\n\\nA non-normative HTML file listing all valid identifier characters for\\nUnicode 4.1 can be found at http://www.dcl.hpi.uni-\\npotsdam.de/home/loewis/table-3131.html.\\n\\n\\nKeywords\\n========\\n\\nThe following identifiers are used as reserved words, or *keywords* of\\nthe language, and cannot be used as ordinary identifiers.  They must\\nbe spelled exactly as written here:\\n\\n   False      class      finally    is         return\\n   None       continue   for        lambda     try\\n   True       def        from       nonlocal   while\\n   and        del        global     not        with\\n   as         elif       if         or         yield\\n   assert     else       import     pass\\n   break      except     in         raise\\n\\n\\nReserved classes of identifiers\\n===============================\\n\\nCertain classes of identifiers (besides keywords) have special\\nmeanings.  These classes are identified by the patterns of leading and\\ntrailing underscore characters:\\n\\n``_*``\\n   Not imported by ``from module import *``.  The special identifier\\n   ``_`` is used in the interactive interpreter to store the result of\\n   the last evaluation; it is stored in the ``builtins`` module.  When\\n   not in interactive mode, ``_`` has no special meaning and is not\\n   defined. See section *The import statement*.\\n\\n   Note: The name ``_`` is often used in conjunction with\\n     internationalization; refer to the documentation for the\\n     ``gettext`` module for more information on this convention.\\n\\n``__*__``\\n   System-defined names. These names are defined by the interpreter\\n   and its implementation (including the standard library).  Current\\n   system names are discussed in the *Special method names* section\\n   and elsewhere.  More will likely be defined in future versions of\\n   Python.  *Any* use of ``__*__`` names, in any context, that does\\n   not follow explicitly documented use, is subject to breakage\\n   without warning.\\n\\n``__*``\\n   Class-private names.  Names in this category, when used within the\\n   context of a class definition, are re-written to use a mangled form\\n   to help avoid name clashes between \"private\" attributes of base and\\n   derived classes. See section *Identifiers (Names)*.\\n',\n'if': '\\nThe ``if`` statement\\n********************\\n\\nThe ``if`` statement is used for conditional execution:\\n\\n   if_stmt ::= \"if\" expression \":\" suite\\n               ( \"elif\" expression \":\" suite )*\\n               [\"else\" \":\" suite]\\n\\nIt selects exactly one of the suites by evaluating the expressions one\\nby one until one is found to be true (see section *Boolean operations*\\nfor the definition of true and false); then that suite is executed\\n(and no other part of the ``if`` statement is executed or evaluated).\\nIf all expressions are false, the suite of the ``else`` clause, if\\npresent, is executed.\\n',\n'imaginary': '\\nImaginary literals\\n******************\\n\\nImaginary literals are described by the following lexical definitions:\\n\\n   imagnumber ::= (floatnumber | intpart) (\"j\" | \"J\")\\n\\nAn imaginary literal yields a complex number with a real part of 0.0.\\nComplex numbers are represented as a pair of floating point numbers\\nand have the same restrictions on their range.  To create a complex\\nnumber with a nonzero real part, add a floating point number to it,\\ne.g., ``(3+4j)``.  Some examples of imaginary literals:\\n\\n   3.14j   10.j    10j     .001j   1e100j  3.14e-10j\\n',\n'import': '\\nThe ``import`` statement\\n************************\\n\\n   import_stmt     ::= \"import\" module [\"as\" name] ( \",\" module [\"as\" name] )*\\n                   | \"from\" relative_module \"import\" identifier [\"as\" name]\\n                   ( \",\" identifier [\"as\" name] )*\\n                   | \"from\" relative_module \"import\" \"(\" identifier [\"as\" name]\\n                   ( \",\" identifier [\"as\" name] )* [\",\"] \")\"\\n                   | \"from\" module \"import\" \"*\"\\n   module          ::= (identifier \".\")* identifier\\n   relative_module ::= \".\"* module | \".\"+\\n   name            ::= identifier\\n\\nThe basic import statement (no ``from`` clause) is executed in two\\nsteps:\\n\\n1. find a module, loading and initializing it if necessary\\n\\n2. define a name or names in the local namespace for the scope where\\n   the ``import`` statement occurs.\\n\\nWhen the statement contains multiple clauses (separated by commas) the\\ntwo steps are carried out separately for each clause, just as though\\nthe clauses had been separated out into individiual import statements.\\n\\nThe details of the first step, finding and loading modules is\\ndescribed in greater detail in the section on the *import system*,\\nwhich also describes the various types of packages and modules that\\ncan be imported, as well as all the hooks that can be used to\\ncustomize the import system. Note that failures in this step may\\nindicate either that the module could not be located, *or* that an\\nerror occurred while initializing the module, which includes execution\\nof the module\\'s code.\\n\\nIf the requested module is retrieved successfully, it will be made\\navailable in the local namespace in one of three ways:\\n\\n* If the module name is followed by ``as``, then the name following\\n  ``as`` is bound directly to the imported module.\\n\\n* If no other name is specified, and the module being imported is a\\n  top level module, the module\\'s name is bound in the local namespace\\n  as a reference to the imported module\\n\\n* If the module being imported is *not* a top level module, then the\\n  name of the top level package that contains the module is bound in\\n  the local namespace as a reference to the top level package. The\\n  imported module must be accessed using its full qualified name\\n  rather than directly\\n\\nThe ``from`` form uses a slightly more complex process:\\n\\n1. find the module specified in the ``from`` clause loading and\\n   initializing it if necessary;\\n\\n2. for each of the identifiers specified in the ``import`` clauses:\\n\\n   1. check if the imported module has an attribute by that name\\n\\n   2. if not, attempt to import a submodule with that name and then\\n      check the imported module again for that attribute\\n\\n   3. if the attribute is not found, ``ImportError`` is raised.\\n\\n   4. otherwise, a reference to that value is bound in the local\\n      namespace, using the name in the ``as`` clause if it is present,\\n      otherwise using the attribute name\\n\\nExamples:\\n\\n   import foo                 # foo imported and bound locally\\n   import foo.bar.baz         # foo.bar.baz imported, foo bound locally\\n   import foo.bar.baz as fbb  # foo.bar.baz imported and bound as fbb\\n   from foo.bar import baz    # foo.bar.baz imported and bound as baz\\n   from foo import attr       # foo imported and foo.attr bound as attr\\n\\nIf the list of identifiers is replaced by a star (``\\'*\\'``), all public\\nnames defined in the module are bound in the local namespace for the\\nscope where the ``import`` statement occurs.\\n\\nThe *public names* defined by a module are determined by checking the\\nmodule\\'s namespace for a variable named ``__all__``; if defined, it\\nmust be a sequence of strings which are names defined or imported by\\nthat module.  The names given in ``__all__`` are all considered public\\nand are required to exist.  If ``__all__`` is not defined, the set of\\npublic names includes all names found in the module\\'s namespace which\\ndo not begin with an underscore character (``\\'_\\'``).  ``__all__``\\nshould contain the entire public API. It is intended to avoid\\naccidentally exporting items that are not part of the API (such as\\nlibrary modules which were imported and used within the module).\\n\\nThe ``from`` form with ``*`` may only occur in a module scope.\\nAttempting to use it in class or function definitions will raise a\\n``SyntaxError``.\\n\\nThe *public names* defined by a module are determined by checking the\\nmodule\\'s namespace for a variable named ``__all__``; if defined, it\\nmust be a sequence of strings which are names defined or imported by\\nthat module.  The names given in ``__all__`` are all considered public\\nand are required to exist.  If ``__all__`` is not defined, the set of\\npublic names includes all names found in the module\\'s namespace which\\ndo not begin with an underscore character (``\\'_\\'``).  ``__all__``\\nshould contain the entire public API. It is intended to avoid\\naccidentally exporting items that are not part of the API (such as\\nlibrary modules which were imported and used within the module).\\n\\nThe ``from`` form with ``*`` may only occur in a module scope.  The\\nwild card form of import --- ``import *`` --- is only allowed at the\\nmodule level. Attempting to use it in class or function definitions\\nwill raise a ``SyntaxError``.\\n\\nWhen specifying what module to import you do not have to specify the\\nabsolute name of the module. When a module or package is contained\\nwithin another package it is possible to make a relative import within\\nthe same top package without having to mention the package name. By\\nusing leading dots in the specified module or package after ``from``\\nyou can specify how high to traverse up the current package hierarchy\\nwithout specifying exact names. One leading dot means the current\\npackage where the module making the import exists. Two dots means up\\none package level. Three dots is up two levels, etc. So if you execute\\n``from . import mod`` from a module in the ``pkg`` package then you\\nwill end up importing ``pkg.mod``. If you execute ``from ..subpkg2\\nimport mod`` from within ``pkg.subpkg1`` you will import\\n``pkg.subpkg2.mod``. The specification for relative imports is\\ncontained within **PEP 328**.\\n\\n``importlib.import_module()`` is provided to support applications that\\ndetermine which modules need to be loaded dynamically.\\n\\n\\nFuture statements\\n=================\\n\\nA *future statement* is a directive to the compiler that a particular\\nmodule should be compiled using syntax or semantics that will be\\navailable in a specified future release of Python.  The future\\nstatement is intended to ease migration to future versions of Python\\nthat introduce incompatible changes to the language.  It allows use of\\nthe new features on a per-module basis before the release in which the\\nfeature becomes standard.\\n\\n   future_statement ::= \"from\" \"__future__\" \"import\" feature [\"as\" name]\\n                        (\",\" feature [\"as\" name])*\\n                        | \"from\" \"__future__\" \"import\" \"(\" feature [\"as\" name]\\n                        (\",\" feature [\"as\" name])* [\",\"] \")\"\\n   feature          ::= identifier\\n   name             ::= identifier\\n\\nA future statement must appear near the top of the module.  The only\\nlines that can appear before a future statement are:\\n\\n* the module docstring (if any),\\n\\n* comments,\\n\\n* blank lines, and\\n\\n* other future statements.\\n\\nThe features recognized by Python 3.0 are ``absolute_import``,\\n``division``, ``generators``, ``unicode_literals``,\\n``print_function``, ``nested_scopes`` and ``with_statement``.  They\\nare all redundant because they are always enabled, and only kept for\\nbackwards compatibility.\\n\\nA future statement is recognized and treated specially at compile\\ntime: Changes to the semantics of core constructs are often\\nimplemented by generating different code.  It may even be the case\\nthat a new feature introduces new incompatible syntax (such as a new\\nreserved word), in which case the compiler may need to parse the\\nmodule differently.  Such decisions cannot be pushed off until\\nruntime.\\n\\nFor any given release, the compiler knows which feature names have\\nbeen defined, and raises a compile-time error if a future statement\\ncontains a feature not known to it.\\n\\nThe direct runtime semantics are the same as for any import statement:\\nthere is a standard module ``__future__``, described later, and it\\nwill be imported in the usual way at the time the future statement is\\nexecuted.\\n\\nThe interesting runtime semantics depend on the specific feature\\nenabled by the future statement.\\n\\nNote that there is nothing special about the statement:\\n\\n   import __future__ [as name]\\n\\nThat is not a future statement; it\\'s an ordinary import statement with\\nno special semantics or syntax restrictions.\\n\\nCode compiled by calls to the built-in functions ``exec()`` and\\n``compile()`` that occur in a module ``M`` containing a future\\nstatement will, by default, use the new syntax or semantics associated\\nwith the future statement.  This can be controlled by optional\\narguments to ``compile()`` --- see the documentation of that function\\nfor details.\\n\\nA future statement typed at an interactive interpreter prompt will\\ntake effect for the rest of the interpreter session.  If an\\ninterpreter is started with the *-i* option, is passed a script name\\nto execute, and the script includes a future statement, it will be in\\neffect in the interactive session started after the script is\\nexecuted.\\n\\nSee also:\\n\\n   **PEP 236** - Back to the __future__\\n      The original proposal for the __future__ mechanism.\\n',\n'in': '\\nComparisons\\n***********\\n\\nUnlike C, all comparison operations in Python have the same priority,\\nwhich is lower than that of any arithmetic, shifting or bitwise\\noperation.  Also unlike C, expressions like ``a < b < c`` have the\\ninterpretation that is conventional in mathematics:\\n\\n   comparison    ::= or_expr ( comp_operator or_expr )*\\n   comp_operator ::= \"<\" | \">\" | \"==\" | \">=\" | \"<=\" | \"!=\"\\n                     | \"is\" [\"not\"] | [\"not\"] \"in\"\\n\\nComparisons yield boolean values: ``True`` or ``False``.\\n\\nComparisons can be chained arbitrarily, e.g., ``x < y <= z`` is\\nequivalent to ``x < y and y <= z``, except that ``y`` is evaluated\\nonly once (but in both cases ``z`` is not evaluated at all when ``x <\\ny`` is found to be false).\\n\\nFormally, if *a*, *b*, *c*, ..., *y*, *z* are expressions and *op1*,\\n*op2*, ..., *opN* are comparison operators, then ``a op1 b op2 c ... y\\nopN z`` is equivalent to ``a op1 b and b op2 c and ... y opN z``,\\nexcept that each expression is evaluated at most once.\\n\\nNote that ``a op1 b op2 c`` doesn\\'t imply any kind of comparison\\nbetween *a* and *c*, so that, e.g., ``x < y > z`` is perfectly legal\\n(though perhaps not pretty).\\n\\nThe operators ``<``, ``>``, ``==``, ``>=``, ``<=``, and ``!=`` compare\\nthe values of two objects.  The objects need not have the same type.\\nIf both are numbers, they are converted to a common type.  Otherwise,\\nthe ``==`` and ``!=`` operators *always* consider objects of different\\ntypes to be unequal, while the ``<``, ``>``, ``>=`` and ``<=``\\noperators raise a ``TypeError`` when comparing objects of different\\ntypes that do not implement these operators for the given pair of\\ntypes.  You can control comparison behavior of objects of non-built-in\\ntypes by defining rich comparison methods like ``__gt__()``, described\\nin section *Basic customization*.\\n\\nComparison of objects of the same type depends on the type:\\n\\n* Numbers are compared arithmetically.\\n\\n* The values ``float(\\'NaN\\')`` and ``Decimal(\\'NaN\\')`` are special. The\\n  are identical to themselves, ``x is x`` but are not equal to\\n  themselves, ``x != x``.  Additionally, comparing any value to a\\n  not-a-number value will return ``False``.  For example, both ``3 <\\n  float(\\'NaN\\')`` and ``float(\\'NaN\\') < 3`` will return ``False``.\\n\\n* Bytes objects are compared lexicographically using the numeric\\n  values of their elements.\\n\\n* Strings are compared lexicographically using the numeric equivalents\\n  (the result of the built-in function ``ord()``) of their characters.\\n  [3] String and bytes object can\\'t be compared!\\n\\n* Tuples and lists are compared lexicographically using comparison of\\n  corresponding elements.  This means that to compare equal, each\\n  element must compare equal and the two sequences must be of the same\\n  type and have the same length.\\n\\n  If not equal, the sequences are ordered the same as their first\\n  differing elements.  For example, ``[1,2,x] <= [1,2,y]`` has the\\n  same value as ``x <= y``.  If the corresponding element does not\\n  exist, the shorter sequence is ordered first (for example, ``[1,2] <\\n  [1,2,3]``).\\n\\n* Mappings (dictionaries) compare equal if and only if they have the\\n  same ``(key, value)`` pairs. Order comparisons ``(\\'<\\', \\'<=\\', \\'>=\\',\\n  \\'>\\')`` raise ``TypeError``.\\n\\n* Sets and frozensets define comparison operators to mean subset and\\n  superset tests.  Those relations do not define total orderings (the\\n  two sets ``{1,2}`` and {2,3} are not equal, nor subsets of one\\n  another, nor supersets of one another).  Accordingly, sets are not\\n  appropriate arguments for functions which depend on total ordering.\\n  For example, ``min()``, ``max()``, and ``sorted()`` produce\\n  undefined results given a list of sets as inputs.\\n\\n* Most other objects of built-in types compare unequal unless they are\\n  the same object; the choice whether one object is considered smaller\\n  or larger than another one is made arbitrarily but consistently\\n  within one execution of a program.\\n\\nComparison of objects of the differing types depends on whether either\\nof the types provide explicit support for the comparison.  Most\\nnumeric types can be compared with one another.  When cross-type\\ncomparison is not supported, the comparison method returns\\n``NotImplemented``.\\n\\nThe operators ``in`` and ``not in`` test for membership.  ``x in s``\\nevaluates to true if *x* is a member of *s*, and false otherwise.  ``x\\nnot in s`` returns the negation of ``x in s``.  All built-in sequences\\nand set types support this as well as dictionary, for which ``in``\\ntests whether a the dictionary has a given key. For container types\\nsuch as list, tuple, set, frozenset, dict, or collections.deque, the\\nexpression ``x in y`` is equivalent to ``any(x is e or x == e for e in\\ny)``.\\n\\nFor the string and bytes types, ``x in y`` is true if and only if *x*\\nis a substring of *y*.  An equivalent test is ``y.find(x) != -1``.\\nEmpty strings are always considered to be a substring of any other\\nstring, so ``\"\" in \"abc\"`` will return ``True``.\\n\\nFor user-defined classes which define the ``__contains__()`` method,\\n``x in y`` is true if and only if ``y.__contains__(x)`` is true.\\n\\nFor user-defined classes which do not define ``__contains__()`` but do\\ndefine ``__iter__()``, ``x in y`` is true if some value ``z`` with ``x\\n== z`` is produced while iterating over ``y``.  If an exception is\\nraised during the iteration, it is as if ``in`` raised that exception.\\n\\nLastly, the old-style iteration protocol is tried: if a class defines\\n``__getitem__()``, ``x in y`` is true if and only if there is a non-\\nnegative integer index *i* such that ``x == y[i]``, and all lower\\ninteger indices do not raise ``IndexError`` exception.  (If any other\\nexception is raised, it is as if ``in`` raised that exception).\\n\\nThe operator ``not in`` is defined to have the inverse true value of\\n``in``.\\n\\nThe operators ``is`` and ``is not`` test for object identity: ``x is\\ny`` is true if and only if *x* and *y* are the same object.  ``x is\\nnot y`` yields the inverse truth value. [4]\\n',\n'integers': '\\nInteger literals\\n****************\\n\\nInteger literals are described by the following lexical definitions:\\n\\n   integer        ::= decimalinteger | octinteger | hexinteger | bininteger\\n   decimalinteger ::= nonzerodigit digit* | \"0\"+\\n   nonzerodigit   ::= \"1\"...\"9\"\\n   digit          ::= \"0\"...\"9\"\\n   octinteger     ::= \"0\" (\"o\" | \"O\") octdigit+\\n   hexinteger     ::= \"0\" (\"x\" | \"X\") hexdigit+\\n   bininteger     ::= \"0\" (\"b\" | \"B\") bindigit+\\n   octdigit       ::= \"0\"...\"7\"\\n   hexdigit       ::= digit | \"a\"...\"f\" | \"A\"...\"F\"\\n   bindigit       ::= \"0\" | \"1\"\\n\\nThere is no limit for the length of integer literals apart from what\\ncan be stored in available memory.\\n\\nNote that leading zeros in a non-zero decimal number are not allowed.\\nThis is for disambiguation with C-style octal literals, which Python\\nused before version 3.0.\\n\\nSome examples of integer literals:\\n\\n   7     2147483647                        0o177    0b100110111\\n   3     79228162514264337593543950336     0o377    0x100000000\\n         79228162514264337593543950336              0xdeadbeef\\n',\n'lambda': '\\nLambdas\\n*******\\n\\n   lambda_form        ::= \"lambda\" [parameter_list]: expression\\n   lambda_form_nocond ::= \"lambda\" [parameter_list]: expression_nocond\\n\\nLambda forms (lambda expressions) have the same syntactic position as\\nexpressions.  They are a shorthand to create anonymous functions; the\\nexpression ``lambda arguments: expression`` yields a function object.\\nThe unnamed object behaves like a function object defined with\\n\\n   def <lambda>(arguments):\\n       return expression\\n\\nSee section *Function definitions* for the syntax of parameter lists.\\nNote that functions created with lambda forms cannot contain\\nstatements or annotations.\\n',\n'lists': '\\nList displays\\n*************\\n\\nA list display is a possibly empty series of expressions enclosed in\\nsquare brackets:\\n\\n   list_display ::= \"[\" [expression_list | comprehension] \"]\"\\n\\nA list display yields a new list object, the contents being specified\\nby either a list of expressions or a comprehension.  When a comma-\\nseparated list of expressions is supplied, its elements are evaluated\\nfrom left to right and placed into the list object in that order.\\nWhen a comprehension is supplied, the list is constructed from the\\nelements resulting from the comprehension.\\n',\n'naming': \"\\nNaming and binding\\n******************\\n\\n*Names* refer to objects.  Names are introduced by name binding\\noperations. Each occurrence of a name in the program text refers to\\nthe *binding* of that name established in the innermost function block\\ncontaining the use.\\n\\nA *block* is a piece of Python program text that is executed as a\\nunit. The following are blocks: a module, a function body, and a class\\ndefinition. Each command typed interactively is a block.  A script\\nfile (a file given as standard input to the interpreter or specified\\non the interpreter command line the first argument) is a code block.\\nA script command (a command specified on the interpreter command line\\nwith the '**-c**' option) is a code block.  The string argument passed\\nto the built-in functions ``eval()`` and ``exec()`` is a code block.\\n\\nA code block is executed in an *execution frame*.  A frame contains\\nsome administrative information (used for debugging) and determines\\nwhere and how execution continues after the code block's execution has\\ncompleted.\\n\\nA *scope* defines the visibility of a name within a block.  If a local\\nvariable is defined in a block, its scope includes that block.  If the\\ndefinition occurs in a function block, the scope extends to any blocks\\ncontained within the defining one, unless a contained block introduces\\na different binding for the name.  The scope of names defined in a\\nclass block is limited to the class block; it does not extend to the\\ncode blocks of methods -- this includes comprehensions and generator\\nexpressions since they are implemented using a function scope.  This\\nmeans that the following will fail:\\n\\n   class A:\\n       a = 42\\n       b = list(a + i for i in range(10))\\n\\nWhen a name is used in a code block, it is resolved using the nearest\\nenclosing scope.  The set of all such scopes visible to a code block\\nis called the block's *environment*.\\n\\nIf a name is bound in a block, it is a local variable of that block,\\nunless declared as ``nonlocal``.  If a name is bound at the module\\nlevel, it is a global variable.  (The variables of the module code\\nblock are local and global.)  If a variable is used in a code block\\nbut not defined there, it is a *free variable*.\\n\\nWhen a name is not found at all, a ``NameError`` exception is raised.\\nIf the name refers to a local variable that has not been bound, a\\n``UnboundLocalError`` exception is raised.  ``UnboundLocalError`` is a\\nsubclass of ``NameError``.\\n\\nThe following constructs bind names: formal parameters to functions,\\n``import`` statements, class and function definitions (these bind the\\nclass or function name in the defining block), and targets that are\\nidentifiers if occurring in an assignment, ``for`` loop header, or\\nafter ``as`` in a ``with`` statement or ``except`` clause. The\\n``import`` statement of the form ``from ... import *`` binds all names\\ndefined in the imported module, except those beginning with an\\nunderscore.  This form may only be used at the module level.\\n\\nA target occurring in a ``del`` statement is also considered bound for\\nthis purpose (though the actual semantics are to unbind the name).\\n\\nEach assignment or import statement occurs within a block defined by a\\nclass or function definition or at the module level (the top-level\\ncode block).\\n\\nIf a name binding operation occurs anywhere within a code block, all\\nuses of the name within the block are treated as references to the\\ncurrent block.  This can lead to errors when a name is used within a\\nblock before it is bound.  This rule is subtle.  Python lacks\\ndeclarations and allows name binding operations to occur anywhere\\nwithin a code block.  The local variables of a code block can be\\ndetermined by scanning the entire text of the block for name binding\\noperations.\\n\\nIf the ``global`` statement occurs within a block, all uses of the\\nname specified in the statement refer to the binding of that name in\\nthe top-level namespace.  Names are resolved in the top-level\\nnamespace by searching the global namespace, i.e. the namespace of the\\nmodule containing the code block, and the builtins namespace, the\\nnamespace of the module ``builtins``.  The global namespace is\\nsearched first.  If the name is not found there, the builtins\\nnamespace is searched.  The global statement must precede all uses of\\nthe name.\\n\\nThe builtins namespace associated with the execution of a code block\\nis actually found by looking up the name ``__builtins__`` in its\\nglobal namespace; this should be a dictionary or a module (in the\\nlatter case the module's dictionary is used).  By default, when in the\\n``__main__`` module, ``__builtins__`` is the built-in module\\n``builtins``; when in any other module, ``__builtins__`` is an alias\\nfor the dictionary of the ``builtins`` module itself.\\n``__builtins__`` can be set to a user-created dictionary to create a\\nweak form of restricted execution.\\n\\n**CPython implementation detail:** Users should not touch\\n``__builtins__``; it is strictly an implementation detail.  Users\\nwanting to override values in the builtins namespace should ``import``\\nthe ``builtins`` module and modify its attributes appropriately.\\n\\nThe namespace for a module is automatically created the first time a\\nmodule is imported.  The main module for a script is always called\\n``__main__``.\\n\\nThe ``global`` statement has the same scope as a name binding\\noperation in the same block.  If the nearest enclosing scope for a\\nfree variable contains a global statement, the free variable is\\ntreated as a global.\\n\\nA class definition is an executable statement that may use and define\\nnames. These references follow the normal rules for name resolution.\\nThe namespace of the class definition becomes the attribute dictionary\\nof the class.  Names defined at the class scope are not visible in\\nmethods.\\n\\n\\nInteraction with dynamic features\\n=================================\\n\\nThere are several cases where Python statements are illegal when used\\nin conjunction with nested scopes that contain free variables.\\n\\nIf a variable is referenced in an enclosing scope, it is illegal to\\ndelete the name.  An error will be reported at compile time.\\n\\nIf the wild card form of import --- ``import *`` --- is used in a\\nfunction and the function contains or is a nested block with free\\nvariables, the compiler will raise a ``SyntaxError``.\\n\\nThe ``eval()`` and ``exec()`` functions do not have access to the full\\nenvironment for resolving names.  Names may be resolved in the local\\nand global namespaces of the caller.  Free variables are not resolved\\nin the nearest enclosing namespace, but in the global namespace.  [1]\\nThe ``exec()`` and ``eval()`` functions have optional arguments to\\noverride the global and local namespace.  If only one namespace is\\nspecified, it is used for both.\\n\",\n'nonlocal': '\\nThe ``nonlocal`` statement\\n**************************\\n\\n   nonlocal_stmt ::= \"nonlocal\" identifier (\",\" identifier)*\\n\\nThe ``nonlocal`` statement causes the listed identifiers to refer to\\npreviously bound variables in the nearest enclosing scope.  This is\\nimportant because the default behavior for binding is to search the\\nlocal namespace first.  The statement allows encapsulated code to\\nrebind variables outside of the local scope besides the global\\n(module) scope.\\n\\nNames listed in a ``nonlocal`` statement, unlike to those listed in a\\n``global`` statement, must refer to pre-existing bindings in an\\nenclosing scope (the scope in which a new binding should be created\\ncannot be determined unambiguously).\\n\\nNames listed in a ``nonlocal`` statement must not collide with pre-\\nexisting bindings in the local scope.\\n\\nSee also:\\n\\n   **PEP 3104** - Access to Names in Outer Scopes\\n      The specification for the ``nonlocal`` statement.\\n',\n'numbers': \"\\nNumeric literals\\n****************\\n\\nThere are three types of numeric literals: integers, floating point\\nnumbers, and imaginary numbers.  There are no complex literals\\n(complex numbers can be formed by adding a real number and an\\nimaginary number).\\n\\nNote that numeric literals do not include a sign; a phrase like ``-1``\\nis actually an expression composed of the unary operator '``-``' and\\nthe literal ``1``.\\n\",\n'numeric-types': \"\\nEmulating numeric types\\n***********************\\n\\nThe following methods can be defined to emulate numeric objects.\\nMethods corresponding to operations that are not supported by the\\nparticular kind of number implemented (e.g., bitwise operations for\\nnon-integral numbers) should be left undefined.\\n\\nobject.__add__(self, other)\\nobject.__sub__(self, other)\\nobject.__mul__(self, other)\\nobject.__truediv__(self, other)\\nobject.__floordiv__(self, other)\\nobject.__mod__(self, other)\\nobject.__divmod__(self, other)\\nobject.__pow__(self, other[, modulo])\\nobject.__lshift__(self, other)\\nobject.__rshift__(self, other)\\nobject.__and__(self, other)\\nobject.__xor__(self, other)\\nobject.__or__(self, other)\\n\\n   These methods are called to implement the binary arithmetic\\n   operations (``+``, ``-``, ``*``, ``/``, ``//``, ``%``,\\n   ``divmod()``, ``pow()``, ``**``, ``<<``, ``>>``, ``&``, ``^``,\\n   ``|``).  For instance, to evaluate the expression ``x + y``, where\\n   *x* is an instance of a class that has an ``__add__()`` method,\\n   ``x.__add__(y)`` is called.  The ``__divmod__()`` method should be\\n   the equivalent to using ``__floordiv__()`` and ``__mod__()``; it\\n   should not be related to ``__truediv__()``.  Note that\\n   ``__pow__()`` should be defined to accept an optional third\\n   argument if the ternary version of the built-in ``pow()`` function\\n   is to be supported.\\n\\n   If one of those methods does not support the operation with the\\n   supplied arguments, it should return ``NotImplemented``.\\n\\nobject.__radd__(self, other)\\nobject.__rsub__(self, other)\\nobject.__rmul__(self, other)\\nobject.__rtruediv__(self, other)\\nobject.__rfloordiv__(self, other)\\nobject.__rmod__(self, other)\\nobject.__rdivmod__(self, other)\\nobject.__rpow__(self, other)\\nobject.__rlshift__(self, other)\\nobject.__rrshift__(self, other)\\nobject.__rand__(self, other)\\nobject.__rxor__(self, other)\\nobject.__ror__(self, other)\\n\\n   These methods are called to implement the binary arithmetic\\n   operations (``+``, ``-``, ``*``, ``/``, ``//``, ``%``,\\n   ``divmod()``, ``pow()``, ``**``, ``<<``, ``>>``, ``&``, ``^``,\\n   ``|``) with reflected (swapped) operands. These functions are only\\n   called if the left operand does not support the corresponding\\n   operation and the operands are of different types. [2]  For\\n   instance, to evaluate the expression ``x - y``, where *y* is an\\n   instance of a class that has an ``__rsub__()`` method,\\n   ``y.__rsub__(x)`` is called if ``x.__sub__(y)`` returns\\n   *NotImplemented*.\\n\\n   Note that ternary ``pow()`` will not try calling ``__rpow__()``\\n   (the coercion rules would become too complicated).\\n\\n   Note: If the right operand's type is a subclass of the left operand's\\n     type and that subclass provides the reflected method for the\\n     operation, this method will be called before the left operand's\\n     non-reflected method.  This behavior allows subclasses to\\n     override their ancestors' operations.\\n\\nobject.__iadd__(self, other)\\nobject.__isub__(self, other)\\nobject.__imul__(self, other)\\nobject.__itruediv__(self, other)\\nobject.__ifloordiv__(self, other)\\nobject.__imod__(self, other)\\nobject.__ipow__(self, other[, modulo])\\nobject.__ilshift__(self, other)\\nobject.__irshift__(self, other)\\nobject.__iand__(self, other)\\nobject.__ixor__(self, other)\\nobject.__ior__(self, other)\\n\\n   These methods are called to implement the augmented arithmetic\\n   assignments (``+=``, ``-=``, ``*=``, ``/=``, ``//=``, ``%=``,\\n   ``**=``, ``<<=``, ``>>=``, ``&=``, ``^=``, ``|=``).  These methods\\n   should attempt to do the operation in-place (modifying *self*) and\\n   return the result (which could be, but does not have to be,\\n   *self*).  If a specific method is not defined, the augmented\\n   assignment falls back to the normal methods.  For instance, to\\n   execute the statement ``x += y``, where *x* is an instance of a\\n   class that has an ``__iadd__()`` method, ``x.__iadd__(y)`` is\\n   called.  If *x* is an instance of a class that does not define a\\n   ``__iadd__()`` method, ``x.__add__(y)`` and ``y.__radd__(x)`` are\\n   considered, as with the evaluation of ``x + y``.\\n\\nobject.__neg__(self)\\nobject.__pos__(self)\\nobject.__abs__(self)\\nobject.__invert__(self)\\n\\n   Called to implement the unary arithmetic operations (``-``, ``+``,\\n   ``abs()`` and ``~``).\\n\\nobject.__complex__(self)\\nobject.__int__(self)\\nobject.__float__(self)\\nobject.__round__(self[, n])\\n\\n   Called to implement the built-in functions ``complex()``,\\n   ``int()``, ``float()`` and ``round()``.  Should return a value of\\n   the appropriate type.\\n\\nobject.__index__(self)\\n\\n   Called to implement ``operator.index()``.  Also called whenever\\n   Python needs an integer object (such as in slicing, or in the\\n   built-in ``bin()``, ``hex()`` and ``oct()`` functions). Must return\\n   an integer.\\n\",\n'objects': '\\nObjects, values and types\\n*************************\\n\\n*Objects* are Python\\'s abstraction for data.  All data in a Python\\nprogram is represented by objects or by relations between objects. (In\\na sense, and in conformance to Von Neumann\\'s model of a \"stored\\nprogram computer,\" code is also represented by objects.)\\n\\nEvery object has an identity, a type and a value.  An object\\'s\\n*identity* never changes once it has been created; you may think of it\\nas the object\\'s address in memory.  The \\'``is``\\' operator compares the\\nidentity of two objects; the ``id()`` function returns an integer\\nrepresenting its identity.\\n\\n**CPython implementation detail:** For CPython, ``id(x)`` is the\\nmemory address where ``x`` is stored.\\n\\nAn object\\'s type determines the operations that the object supports\\n(e.g., \"does it have a length?\") and also defines the possible values\\nfor objects of that type.  The ``type()`` function returns an object\\'s\\ntype (which is an object itself).  Like its identity, an object\\'s\\n*type* is also unchangeable. [1]\\n\\nThe *value* of some objects can change.  Objects whose value can\\nchange are said to be *mutable*; objects whose value is unchangeable\\nonce they are created are called *immutable*. (The value of an\\nimmutable container object that contains a reference to a mutable\\nobject can change when the latter\\'s value is changed; however the\\ncontainer is still considered immutable, because the collection of\\nobjects it contains cannot be changed.  So, immutability is not\\nstrictly the same as having an unchangeable value, it is more subtle.)\\nAn object\\'s mutability is determined by its type; for instance,\\nnumbers, strings and tuples are immutable, while dictionaries and\\nlists are mutable.\\n\\nObjects are never explicitly destroyed; however, when they become\\nunreachable they may be garbage-collected.  An implementation is\\nallowed to postpone garbage collection or omit it altogether --- it is\\na matter of implementation quality how garbage collection is\\nimplemented, as long as no objects are collected that are still\\nreachable.\\n\\n**CPython implementation detail:** CPython currently uses a reference-\\ncounting scheme with (optional) delayed detection of cyclically linked\\ngarbage, which collects most objects as soon as they become\\nunreachable, but is not guaranteed to collect garbage containing\\ncircular references.  See the documentation of the ``gc`` module for\\ninformation on controlling the collection of cyclic garbage. Other\\nimplementations act differently and CPython may change. Do not depend\\non immediate finalization of objects when they become unreachable (ex:\\nalways close files).\\n\\nNote that the use of the implementation\\'s tracing or debugging\\nfacilities may keep objects alive that would normally be collectable.\\nAlso note that catching an exception with a \\'``try``...``except``\\'\\nstatement may keep objects alive.\\n\\nSome objects contain references to \"external\" resources such as open\\nfiles or windows.  It is understood that these resources are freed\\nwhen the object is garbage-collected, but since garbage collection is\\nnot guaranteed to happen, such objects also provide an explicit way to\\nrelease the external resource, usually a ``close()`` method. Programs\\nare strongly recommended to explicitly close such objects.  The\\n\\'``try``...``finally``\\' statement and the \\'``with``\\' statement provide\\nconvenient ways to do this.\\n\\nSome objects contain references to other objects; these are called\\n*containers*. Examples of containers are tuples, lists and\\ndictionaries.  The references are part of a container\\'s value.  In\\nmost cases, when we talk about the value of a container, we imply the\\nvalues, not the identities of the contained objects; however, when we\\ntalk about the mutability of a container, only the identities of the\\nimmediately contained objects are implied.  So, if an immutable\\ncontainer (like a tuple) contains a reference to a mutable object, its\\nvalue changes if that mutable object is changed.\\n\\nTypes affect almost all aspects of object behavior.  Even the\\nimportance of object identity is affected in some sense: for immutable\\ntypes, operations that compute new values may actually return a\\nreference to any existing object with the same type and value, while\\nfor mutable objects this is not allowed.  E.g., after ``a = 1; b =\\n1``, ``a`` and ``b`` may or may not refer to the same object with the\\nvalue one, depending on the implementation, but after ``c = []; d =\\n[]``, ``c`` and ``d`` are guaranteed to refer to two different,\\nunique, newly created empty lists. (Note that ``c = d = []`` assigns\\nthe same object to both ``c`` and ``d``.)\\n',\n'operator-summary': '\\nOperator precedence\\n*******************\\n\\nThe following table summarizes the operator precedences in Python,\\nfrom lowest precedence (least binding) to highest precedence (most\\nbinding).  Operators in the same box have the same precedence.  Unless\\nthe syntax is explicitly given, operators are binary.  Operators in\\nthe same box group left to right (except for comparisons, including\\ntests, which all have the same precedence and chain from left to right\\n--- see section *Comparisons* --- and exponentiation, which groups\\nfrom right to left).\\n\\n+-------------------------------------------------+---------------------------------------+\\n| Operator                                        | Description                           |\\n+=================================================+=======================================+\\n| ``lambda``                                      | Lambda expression                     |\\n+-------------------------------------------------+---------------------------------------+\\n| ``if`` -- ``else``                              | Conditional expression                |\\n+-------------------------------------------------+---------------------------------------+\\n| ``or``                                          | Boolean OR                            |\\n+-------------------------------------------------+---------------------------------------+\\n| ``and``                                         | Boolean AND                           |\\n+-------------------------------------------------+---------------------------------------+\\n| ``not`` ``x``                                   | Boolean NOT                           |\\n+-------------------------------------------------+---------------------------------------+\\n| ``in``, ``not in``, ``is``, ``is not``, ``<``,  | Comparisons, including membership     |\\n| ``<=``, ``>``, ``>=``, ``!=``, ``==``           | tests and identity tests,             |\\n+-------------------------------------------------+---------------------------------------+\\n| ``|``                                           | Bitwise OR                            |\\n+-------------------------------------------------+---------------------------------------+\\n| ``^``                                           | Bitwise XOR                           |\\n+-------------------------------------------------+---------------------------------------+\\n| ``&``                                           | Bitwise AND                           |\\n+-------------------------------------------------+---------------------------------------+\\n| ``<<``, ``>>``                                  | Shifts                                |\\n+-------------------------------------------------+---------------------------------------+\\n| ``+``, ``-``                                    | Addition and subtraction              |\\n+-------------------------------------------------+---------------------------------------+\\n| ``*``, ``/``, ``//``, ``%``                     | Multiplication, division, remainder   |\\n|                                                 | [5]                                   |\\n+-------------------------------------------------+---------------------------------------+\\n| ``+x``, ``-x``, ``~x``                          | Positive, negative, bitwise NOT       |\\n+-------------------------------------------------+---------------------------------------+\\n| ``**``                                          | Exponentiation [6]                    |\\n+-------------------------------------------------+---------------------------------------+\\n| ``x[index]``, ``x[index:index]``,               | Subscription, slicing, call,          |\\n| ``x(arguments...)``, ``x.attribute``            | attribute reference                   |\\n+-------------------------------------------------+---------------------------------------+\\n| ``(expressions...)``, ``[expressions...]``,     | Binding or tuple display, list        |\\n| ``{key: value...}``, ``{expressions...}``       | display, dictionary display, set      |\\n|                                                 | display                               |\\n+-------------------------------------------------+---------------------------------------+\\n\\n-[ Footnotes ]-\\n\\n[1] While ``abs(x%y) < abs(y)`` is true mathematically, for floats it\\n    may not be true numerically due to roundoff.  For example, and\\n    assuming a platform on which a Python float is an IEEE 754 double-\\n    precision number, in order that ``-1e-100 % 1e100`` have the same\\n    sign as ``1e100``, the computed result is ``-1e-100 + 1e100``,\\n    which is numerically exactly equal to ``1e100``.  The function\\n    ``math.fmod()`` returns a result whose sign matches the sign of\\n    the first argument instead, and so returns ``-1e-100`` in this\\n    case. Which approach is more appropriate depends on the\\n    application.\\n\\n[2] If x is very close to an exact integer multiple of y, it\\'s\\n    possible for ``x//y`` to be one larger than ``(x-x%y)//y`` due to\\n    rounding.  In such cases, Python returns the latter result, in\\n    order to preserve that ``divmod(x,y)[0] * y + x % y`` be very\\n    close to ``x``.\\n\\n[3] While comparisons between strings make sense at the byte level,\\n    they may be counter-intuitive to users.  For example, the strings\\n    ``\"\\\\u00C7\"`` and ``\"\\\\u0327\\\\u0043\"`` compare differently, even\\n    though they both represent the same unicode character (LATIN\\n    CAPITAL LETTER C WITH CEDILLA).  To compare strings in a human\\n    recognizable way, compare using ``unicodedata.normalize()``.\\n\\n[4] Due to automatic garbage-collection, free lists, and the dynamic\\n    nature of descriptors, you may notice seemingly unusual behaviour\\n    in certain uses of the ``is`` operator, like those involving\\n    comparisons between instance methods, or constants.  Check their\\n    documentation for more info.\\n\\n[5] The ``%`` operator is also used for string formatting; the same\\n    precedence applies.\\n\\n[6] The power operator ``**`` binds less tightly than an arithmetic or\\n    bitwise unary operator on its right, that is, ``2**-1`` is\\n    ``0.5``.\\n',\n'pass': '\\nThe ``pass`` statement\\n**********************\\n\\n   pass_stmt ::= \"pass\"\\n\\n``pass`` is a null operation --- when it is executed, nothing happens.\\nIt is useful as a placeholder when a statement is required\\nsyntactically, but no code needs to be executed, for example:\\n\\n   def f(arg): pass    # a function that does nothing (yet)\\n\\n   class C: pass       # a class with no methods (yet)\\n',\n'power': '\\nThe power operator\\n******************\\n\\nThe power operator binds more tightly than unary operators on its\\nleft; it binds less tightly than unary operators on its right.  The\\nsyntax is:\\n\\n   power ::= primary [\"**\" u_expr]\\n\\nThus, in an unparenthesized sequence of power and unary operators, the\\noperators are evaluated from right to left (this does not constrain\\nthe evaluation order for the operands): ``-1**2`` results in ``-1``.\\n\\nThe power operator has the same semantics as the built-in ``pow()``\\nfunction, when called with two arguments: it yields its left argument\\nraised to the power of its right argument.  The numeric arguments are\\nfirst converted to a common type, and the result is of that type.\\n\\nFor int operands, the result has the same type as the operands unless\\nthe second argument is negative; in that case, all arguments are\\nconverted to float and a float result is delivered. For example,\\n``10**2`` returns ``100``, but ``10**-2`` returns ``0.01``.\\n\\nRaising ``0.0`` to a negative power results in a\\n``ZeroDivisionError``. Raising a negative number to a fractional power\\nresults in a ``complex`` number. (In earlier versions it raised a\\n``ValueError``.)\\n',\n'raise': '\\nThe ``raise`` statement\\n***********************\\n\\n   raise_stmt ::= \"raise\" [expression [\"from\" expression]]\\n\\nIf no expressions are present, ``raise`` re-raises the last exception\\nthat was active in the current scope.  If no exception is active in\\nthe current scope, a ``RuntimeError`` exception is raised indicating\\nthat this is an error.\\n\\nOtherwise, ``raise`` evaluates the first expression as the exception\\nobject.  It must be either a subclass or an instance of\\n``BaseException``. If it is a class, the exception instance will be\\nobtained when needed by instantiating the class with no arguments.\\n\\nThe *type* of the exception is the exception instance\\'s class, the\\n*value* is the instance itself.\\n\\nA traceback object is normally created automatically when an exception\\nis raised and attached to it as the ``__traceback__`` attribute, which\\nis writable. You can create an exception and set your own traceback in\\none step using the ``with_traceback()`` exception method (which\\nreturns the same exception instance, with its traceback set to its\\nargument), like so:\\n\\n   raise Exception(\"foo occurred\").with_traceback(tracebackobj)\\n\\nThe ``from`` clause is used for exception chaining: if given, the\\nsecond *expression* must be another exception class or instance, which\\nwill then be attached to the raised exception as the ``__cause__``\\nattribute (which is writable).  If the raised exception is not\\nhandled, both exceptions will be printed:\\n\\n   >>> try:\\n   ...     print(1 / 0)\\n   ... except Exception as exc:\\n   ...     raise RuntimeError(\"Something bad happened\") from exc\\n   ...\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 2, in <module>\\n   ZeroDivisionError: int division or modulo by zero\\n\\n   The above exception was the direct cause of the following exception:\\n\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 4, in <module>\\n   RuntimeError: Something bad happened\\n\\nA similar mechanism works implicitly if an exception is raised inside\\nan exception handler: the previous exception is then attached as the\\nnew exception\\'s ``__context__`` attribute:\\n\\n   >>> try:\\n   ...     print(1 / 0)\\n   ... except:\\n   ...     raise RuntimeError(\"Something bad happened\")\\n   ...\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 2, in <module>\\n   ZeroDivisionError: int division or modulo by zero\\n\\n   During handling of the above exception, another exception occurred:\\n\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 4, in <module>\\n   RuntimeError: Something bad happened\\n\\nAdditional information on exceptions can be found in section\\n*Exceptions*, and information about handling exceptions is in section\\n*The try statement*.\\n',\n'return': '\\nThe ``return`` statement\\n************************\\n\\n   return_stmt ::= \"return\" [expression_list]\\n\\n``return`` may only occur syntactically nested in a function\\ndefinition, not within a nested class definition.\\n\\nIf an expression list is present, it is evaluated, else ``None`` is\\nsubstituted.\\n\\n``return`` leaves the current function call with the expression list\\n(or ``None``) as return value.\\n\\nWhen ``return`` passes control out of a ``try`` statement with a\\n``finally`` clause, that ``finally`` clause is executed before really\\nleaving the function.\\n\\nIn a generator function, the ``return`` statement indicates that the\\ngenerator is done and will cause ``StopIteration`` to be raised. The\\nreturned value (if any) is used as an argument to construct\\n``StopIteration`` and becomes the ``StopIteration.value`` attribute.\\n',\n'sequence-types': \"\\nEmulating container types\\n*************************\\n\\nThe following methods can be defined to implement container objects.\\nContainers usually are sequences (such as lists or tuples) or mappings\\n(like dictionaries), but can represent other containers as well.  The\\nfirst set of methods is used either to emulate a sequence or to\\nemulate a mapping; the difference is that for a sequence, the\\nallowable keys should be the integers *k* for which ``0 <= k < N``\\nwhere *N* is the length of the sequence, or slice objects, which\\ndefine a range of items.  It is also recommended that mappings provide\\nthe methods ``keys()``, ``values()``, ``items()``, ``get()``,\\n``clear()``, ``setdefault()``, ``pop()``, ``popitem()``, ``copy()``,\\nand ``update()`` behaving similar to those for Python's standard\\ndictionary objects.  The ``collections`` module provides a\\n``MutableMapping`` abstract base class to help create those methods\\nfrom a base set of ``__getitem__()``, ``__setitem__()``,\\n``__delitem__()``, and ``keys()``. Mutable sequences should provide\\nmethods ``append()``, ``count()``, ``index()``, ``extend()``,\\n``insert()``, ``pop()``, ``remove()``, ``reverse()`` and ``sort()``,\\nlike Python standard list objects.  Finally, sequence types should\\nimplement addition (meaning concatenation) and multiplication (meaning\\nrepetition) by defining the methods ``__add__()``, ``__radd__()``,\\n``__iadd__()``, ``__mul__()``, ``__rmul__()`` and ``__imul__()``\\ndescribed below; they should not define other numerical operators.  It\\nis recommended that both mappings and sequences implement the\\n``__contains__()`` method to allow efficient use of the ``in``\\noperator; for mappings, ``in`` should search the mapping's keys; for\\nsequences, it should search through the values.  It is further\\nrecommended that both mappings and sequences implement the\\n``__iter__()`` method to allow efficient iteration through the\\ncontainer; for mappings, ``__iter__()`` should be the same as\\n``keys()``; for sequences, it should iterate through the values.\\n\\nobject.__len__(self)\\n\\n   Called to implement the built-in function ``len()``.  Should return\\n   the length of the object, an integer ``>=`` 0.  Also, an object\\n   that doesn't define a ``__bool__()`` method and whose ``__len__()``\\n   method returns zero is considered to be false in a Boolean context.\\n\\nNote: Slicing is done exclusively with the following three methods.  A\\n  call like\\n\\n     a[1:2] = b\\n\\n  is translated to\\n\\n     a[slice(1, 2, None)] = b\\n\\n  and so forth.  Missing slice items are always filled in with\\n  ``None``.\\n\\nobject.__getitem__(self, key)\\n\\n   Called to implement evaluation of ``self[key]``. For sequence\\n   types, the accepted keys should be integers and slice objects.\\n   Note that the special interpretation of negative indexes (if the\\n   class wishes to emulate a sequence type) is up to the\\n   ``__getitem__()`` method. If *key* is of an inappropriate type,\\n   ``TypeError`` may be raised; if of a value outside the set of\\n   indexes for the sequence (after any special interpretation of\\n   negative values), ``IndexError`` should be raised. For mapping\\n   types, if *key* is missing (not in the container), ``KeyError``\\n   should be raised.\\n\\n   Note: ``for`` loops expect that an ``IndexError`` will be raised for\\n     illegal indexes to allow proper detection of the end of the\\n     sequence.\\n\\nobject.__setitem__(self, key, value)\\n\\n   Called to implement assignment to ``self[key]``.  Same note as for\\n   ``__getitem__()``.  This should only be implemented for mappings if\\n   the objects support changes to the values for keys, or if new keys\\n   can be added, or for sequences if elements can be replaced.  The\\n   same exceptions should be raised for improper *key* values as for\\n   the ``__getitem__()`` method.\\n\\nobject.__delitem__(self, key)\\n\\n   Called to implement deletion of ``self[key]``.  Same note as for\\n   ``__getitem__()``.  This should only be implemented for mappings if\\n   the objects support removal of keys, or for sequences if elements\\n   can be removed from the sequence.  The same exceptions should be\\n   raised for improper *key* values as for the ``__getitem__()``\\n   method.\\n\\nobject.__iter__(self)\\n\\n   This method is called when an iterator is required for a container.\\n   This method should return a new iterator object that can iterate\\n   over all the objects in the container.  For mappings, it should\\n   iterate over the keys of the container, and should also be made\\n   available as the method ``keys()``.\\n\\n   Iterator objects also need to implement this method; they are\\n   required to return themselves.  For more information on iterator\\n   objects, see *Iterator Types*.\\n\\nobject.__reversed__(self)\\n\\n   Called (if present) by the ``reversed()`` built-in to implement\\n   reverse iteration.  It should return a new iterator object that\\n   iterates over all the objects in the container in reverse order.\\n\\n   If the ``__reversed__()`` method is not provided, the\\n   ``reversed()`` built-in will fall back to using the sequence\\n   protocol (``__len__()`` and ``__getitem__()``).  Objects that\\n   support the sequence protocol should only provide\\n   ``__reversed__()`` if they can provide an implementation that is\\n   more efficient than the one provided by ``reversed()``.\\n\\nThe membership test operators (``in`` and ``not in``) are normally\\nimplemented as an iteration through a sequence.  However, container\\nobjects can supply the following special method with a more efficient\\nimplementation, which also does not require the object be a sequence.\\n\\nobject.__contains__(self, item)\\n\\n   Called to implement membership test operators.  Should return true\\n   if *item* is in *self*, false otherwise.  For mapping objects, this\\n   should consider the keys of the mapping rather than the values or\\n   the key-item pairs.\\n\\n   For objects that don't define ``__contains__()``, the membership\\n   test first tries iteration via ``__iter__()``, then the old\\n   sequence iteration protocol via ``__getitem__()``, see *this\\n   section in the language reference*.\\n\",\n'shifting': '\\nShifting operations\\n*******************\\n\\nThe shifting operations have lower priority than the arithmetic\\noperations:\\n\\n   shift_expr ::= a_expr | shift_expr ( \"<<\" | \">>\" ) a_expr\\n\\nThese operators accept integers as arguments.  They shift the first\\nargument to the left or right by the number of bits given by the\\nsecond argument.\\n\\nA right shift by *n* bits is defined as division by ``pow(2,n)``.  A\\nleft shift by *n* bits is defined as multiplication with ``pow(2,n)``.\\n\\nNote: In the current implementation, the right-hand operand is required to\\n  be at most ``sys.maxsize``.  If the right-hand operand is larger\\n  than ``sys.maxsize`` an ``OverflowError`` exception is raised.\\n',\n'slicings': '\\nSlicings\\n********\\n\\nA slicing selects a range of items in a sequence object (e.g., a\\nstring, tuple or list).  Slicings may be used as expressions or as\\ntargets in assignment or ``del`` statements.  The syntax for a\\nslicing:\\n\\n   slicing      ::= primary \"[\" slice_list \"]\"\\n   slice_list   ::= slice_item (\",\" slice_item)* [\",\"]\\n   slice_item   ::= expression | proper_slice\\n   proper_slice ::= [lower_bound] \":\" [upper_bound] [ \":\" [stride] ]\\n   lower_bound  ::= expression\\n   upper_bound  ::= expression\\n   stride       ::= expression\\n\\nThere is ambiguity in the formal syntax here: anything that looks like\\nan expression list also looks like a slice list, so any subscription\\ncan be interpreted as a slicing.  Rather than further complicating the\\nsyntax, this is disambiguated by defining that in this case the\\ninterpretation as a subscription takes priority over the\\ninterpretation as a slicing (this is the case if the slice list\\ncontains no proper slice).\\n\\nThe semantics for a slicing are as follows.  The primary must evaluate\\nto a mapping object, and it is indexed (using the same\\n``__getitem__()`` method as normal subscription) with a key that is\\nconstructed from the slice list, as follows.  If the slice list\\ncontains at least one comma, the key is a tuple containing the\\nconversion of the slice items; otherwise, the conversion of the lone\\nslice item is the key.  The conversion of a slice item that is an\\nexpression is that expression.  The conversion of a proper slice is a\\nslice object (see section *The standard type hierarchy*) whose\\n``start``, ``stop`` and ``step`` attributes are the values of the\\nexpressions given as lower bound, upper bound and stride,\\nrespectively, substituting ``None`` for missing expressions.\\n',\n'specialattrs': '\\nSpecial Attributes\\n******************\\n\\nThe implementation adds a few special read-only attributes to several\\nobject types, where they are relevant.  Some of these are not reported\\nby the ``dir()`` built-in function.\\n\\nobject.__dict__\\n\\n   A dictionary or other mapping object used to store an object\\'s\\n   (writable) attributes.\\n\\ninstance.__class__\\n\\n   The class to which a class instance belongs.\\n\\nclass.__bases__\\n\\n   The tuple of base classes of a class object.\\n\\nclass.__name__\\n\\n   The name of the class or type.\\n\\nclass.__qualname__\\n\\n   The *qualified name* of the class or type.\\n\\n   New in version 3.3.\\n\\nclass.__mro__\\n\\n   This attribute is a tuple of classes that are considered when\\n   looking for base classes during method resolution.\\n\\nclass.mro()\\n\\n   This method can be overridden by a metaclass to customize the\\n   method resolution order for its instances.  It is called at class\\n   instantiation, and its result is stored in ``__mro__``.\\n\\nclass.__subclasses__()\\n\\n   Each class keeps a list of weak references to its immediate\\n   subclasses.  This method returns a list of all those references\\n   still alive. Example:\\n\\n      >>> int.__subclasses__()\\n      [<class \\'bool\\'>]\\n\\n-[ Footnotes ]-\\n\\n[1] Additional information on these special methods may be found in\\n    the Python Reference Manual (*Basic customization*).\\n\\n[2] As a consequence, the list ``[1, 2]`` is considered equal to\\n    ``[1.0, 2.0]``, and similarly for tuples.\\n\\n[3] They must have since the parser can\\'t tell the type of the\\n    operands.\\n\\n[4] Cased characters are those with general category property being\\n    one of \"Lu\" (Letter, uppercase), \"Ll\" (Letter, lowercase), or \"Lt\"\\n    (Letter, titlecase).\\n\\n[5] To format only a tuple you should therefore provide a singleton\\n    tuple whose only element is the tuple to be formatted.\\n',\n'specialnames': '\\nSpecial method names\\n********************\\n\\nA class can implement certain operations that are invoked by special\\nsyntax (such as arithmetic operations or subscripting and slicing) by\\ndefining methods with special names. This is Python\\'s approach to\\n*operator overloading*, allowing classes to define their own behavior\\nwith respect to language operators.  For instance, if a class defines\\na method named ``__getitem__()``, and ``x`` is an instance of this\\nclass, then ``x[i]`` is roughly equivalent to ``type(x).__getitem__(x,\\ni)``.  Except where mentioned, attempts to execute an operation raise\\nan exception when no appropriate method is defined (typically\\n``AttributeError`` or ``TypeError``).\\n\\nWhen implementing a class that emulates any built-in type, it is\\nimportant that the emulation only be implemented to the degree that it\\nmakes sense for the object being modelled.  For example, some\\nsequences may work well with retrieval of individual elements, but\\nextracting a slice may not make sense.  (One example of this is the\\n``NodeList`` interface in the W3C\\'s Document Object Model.)\\n\\n\\nBasic customization\\n===================\\n\\nobject.__new__(cls[, ...])\\n\\n   Called to create a new instance of class *cls*.  ``__new__()`` is a\\n   static method (special-cased so you need not declare it as such)\\n   that takes the class of which an instance was requested as its\\n   first argument.  The remaining arguments are those passed to the\\n   object constructor expression (the call to the class).  The return\\n   value of ``__new__()`` should be the new object instance (usually\\n   an instance of *cls*).\\n\\n   Typical implementations create a new instance of the class by\\n   invoking the superclass\\'s ``__new__()`` method using\\n   ``super(currentclass, cls).__new__(cls[, ...])`` with appropriate\\n   arguments and then modifying the newly-created instance as\\n   necessary before returning it.\\n\\n   If ``__new__()`` returns an instance of *cls*, then the new\\n   instance\\'s ``__init__()`` method will be invoked like\\n   ``__init__(self[, ...])``, where *self* is the new instance and the\\n   remaining arguments are the same as were passed to ``__new__()``.\\n\\n   If ``__new__()`` does not return an instance of *cls*, then the new\\n   instance\\'s ``__init__()`` method will not be invoked.\\n\\n   ``__new__()`` is intended mainly to allow subclasses of immutable\\n   types (like int, str, or tuple) to customize instance creation.  It\\n   is also commonly overridden in custom metaclasses in order to\\n   customize class creation.\\n\\nobject.__init__(self[, ...])\\n\\n   Called when the instance is created.  The arguments are those\\n   passed to the class constructor expression.  If a base class has an\\n   ``__init__()`` method, the derived class\\'s ``__init__()`` method,\\n   if any, must explicitly call it to ensure proper initialization of\\n   the base class part of the instance; for example:\\n   ``BaseClass.__init__(self, [args...])``.  As a special constraint\\n   on constructors, no value may be returned; doing so will cause a\\n   ``TypeError`` to be raised at runtime.\\n\\nobject.__del__(self)\\n\\n   Called when the instance is about to be destroyed.  This is also\\n   called a destructor.  If a base class has a ``__del__()`` method,\\n   the derived class\\'s ``__del__()`` method, if any, must explicitly\\n   call it to ensure proper deletion of the base class part of the\\n   instance.  Note that it is possible (though not recommended!) for\\n   the ``__del__()`` method to postpone destruction of the instance by\\n   creating a new reference to it.  It may then be called at a later\\n   time when this new reference is deleted.  It is not guaranteed that\\n   ``__del__()`` methods are called for objects that still exist when\\n   the interpreter exits.\\n\\n   Note: ``del x`` doesn\\'t directly call ``x.__del__()`` --- the former\\n     decrements the reference count for ``x`` by one, and the latter\\n     is only called when ``x``\\'s reference count reaches zero.  Some\\n     common situations that may prevent the reference count of an\\n     object from going to zero include: circular references between\\n     objects (e.g., a doubly-linked list or a tree data structure with\\n     parent and child pointers); a reference to the object on the\\n     stack frame of a function that caught an exception (the traceback\\n     stored in ``sys.exc_info()[2]`` keeps the stack frame alive); or\\n     a reference to the object on the stack frame that raised an\\n     unhandled exception in interactive mode (the traceback stored in\\n     ``sys.last_traceback`` keeps the stack frame alive).  The first\\n     situation can only be remedied by explicitly breaking the cycles;\\n     the latter two situations can be resolved by storing ``None`` in\\n     ``sys.last_traceback``. Circular references which are garbage are\\n     detected when the option cycle detector is enabled (it\\'s on by\\n     default), but can only be cleaned up if there are no Python-\\n     level ``__del__()`` methods involved. Refer to the documentation\\n     for the ``gc`` module for more information about how\\n     ``__del__()`` methods are handled by the cycle detector,\\n     particularly the description of the ``garbage`` value.\\n\\n   Warning: Due to the precarious circumstances under which ``__del__()``\\n     methods are invoked, exceptions that occur during their execution\\n     are ignored, and a warning is printed to ``sys.stderr`` instead.\\n     Also, when ``__del__()`` is invoked in response to a module being\\n     deleted (e.g., when execution of the program is done), other\\n     globals referenced by the ``__del__()`` method may already have\\n     been deleted or in the process of being torn down (e.g. the\\n     import machinery shutting down).  For this reason, ``__del__()``\\n     methods should do the absolute minimum needed to maintain\\n     external invariants.  Starting with version 1.5, Python\\n     guarantees that globals whose name begins with a single\\n     underscore are deleted from their module before other globals are\\n     deleted; if no other references to such globals exist, this may\\n     help in assuring that imported modules are still available at the\\n     time when the ``__del__()`` method is called.\\n\\nobject.__repr__(self)\\n\\n   Called by the ``repr()`` built-in function to compute the\\n   \"official\" string representation of an object.  If at all possible,\\n   this should look like a valid Python expression that could be used\\n   to recreate an object with the same value (given an appropriate\\n   environment).  If this is not possible, a string of the form\\n   ``<...some useful description...>`` should be returned. The return\\n   value must be a string object. If a class defines ``__repr__()``\\n   but not ``__str__()``, then ``__repr__()`` is also used when an\\n   \"informal\" string representation of instances of that class is\\n   required.\\n\\n   This is typically used for debugging, so it is important that the\\n   representation is information-rich and unambiguous.\\n\\nobject.__str__(self)\\n\\n   Called by ``str(object)`` and the built-in functions ``format()``\\n   and ``print()`` to compute the \"informal\" or nicely printable\\n   string representation of an object.  The return value must be a\\n   *string* object.\\n\\n   This method differs from ``object.__repr__()`` in that there is no\\n   expectation that ``__str__()`` return a valid Python expression: a\\n   more convenient or concise representation can be used.\\n\\n   The default implementation defined by the built-in type ``object``\\n   calls ``object.__repr__()``.\\n\\nobject.__bytes__(self)\\n\\n   Called by ``bytes()`` to compute a byte-string representation of an\\n   object. This should return a ``bytes`` object.\\n\\nobject.__format__(self, format_spec)\\n\\n   Called by the ``format()`` built-in function (and by extension, the\\n   ``str.format()`` method of class ``str``) to produce a \"formatted\"\\n   string representation of an object. The ``format_spec`` argument is\\n   a string that contains a description of the formatting options\\n   desired. The interpretation of the ``format_spec`` argument is up\\n   to the type implementing ``__format__()``, however most classes\\n   will either delegate formatting to one of the built-in types, or\\n   use a similar formatting option syntax.\\n\\n   See *Format Specification Mini-Language* for a description of the\\n   standard formatting syntax.\\n\\n   The return value must be a string object.\\n\\nobject.__lt__(self, other)\\nobject.__le__(self, other)\\nobject.__eq__(self, other)\\nobject.__ne__(self, other)\\nobject.__gt__(self, other)\\nobject.__ge__(self, other)\\n\\n   These are the so-called \"rich comparison\" methods. The\\n   correspondence between operator symbols and method names is as\\n   follows: ``x<y`` calls ``x.__lt__(y)``, ``x<=y`` calls\\n   ``x.__le__(y)``, ``x==y`` calls ``x.__eq__(y)``, ``x!=y`` calls\\n   ``x.__ne__(y)``, ``x>y`` calls ``x.__gt__(y)``, and ``x>=y`` calls\\n   ``x.__ge__(y)``.\\n\\n   A rich comparison method may return the singleton\\n   ``NotImplemented`` if it does not implement the operation for a\\n   given pair of arguments. By convention, ``False`` and ``True`` are\\n   returned for a successful comparison. However, these methods can\\n   return any value, so if the comparison operator is used in a\\n   Boolean context (e.g., in the condition of an ``if`` statement),\\n   Python will call ``bool()`` on the value to determine if the result\\n   is true or false.\\n\\n   There are no implied relationships among the comparison operators.\\n   The truth of ``x==y`` does not imply that ``x!=y`` is false.\\n   Accordingly, when defining ``__eq__()``, one should also define\\n   ``__ne__()`` so that the operators will behave as expected.  See\\n   the paragraph on ``__hash__()`` for some important notes on\\n   creating *hashable* objects which support custom comparison\\n   operations and are usable as dictionary keys.\\n\\n   There are no swapped-argument versions of these methods (to be used\\n   when the left argument does not support the operation but the right\\n   argument does); rather, ``__lt__()`` and ``__gt__()`` are each\\n   other\\'s reflection, ``__le__()`` and ``__ge__()`` are each other\\'s\\n   reflection, and ``__eq__()`` and ``__ne__()`` are their own\\n   reflection.\\n\\n   Arguments to rich comparison methods are never coerced.\\n\\n   To automatically generate ordering operations from a single root\\n   operation, see ``functools.total_ordering()``.\\n\\nobject.__hash__(self)\\n\\n   Called by built-in function ``hash()`` and for operations on\\n   members of hashed collections including ``set``, ``frozenset``, and\\n   ``dict``.  ``__hash__()`` should return an integer.  The only\\n   required property is that objects which compare equal have the same\\n   hash value; it is advised to somehow mix together (e.g. using\\n   exclusive or) the hash values for the components of the object that\\n   also play a part in comparison of objects.\\n\\n   If a class does not define an ``__eq__()`` method it should not\\n   define a ``__hash__()`` operation either; if it defines\\n   ``__eq__()`` but not ``__hash__()``, its instances will not be\\n   usable as items in hashable collections.  If a class defines\\n   mutable objects and implements an ``__eq__()`` method, it should\\n   not implement ``__hash__()``, since the implementation of hashable\\n   collections requires that a key\\'s hash value is immutable (if the\\n   object\\'s hash value changes, it will be in the wrong hash bucket).\\n\\n   User-defined classes have ``__eq__()`` and ``__hash__()`` methods\\n   by default; with them, all objects compare unequal (except with\\n   themselves) and ``x.__hash__()`` returns an appropriate value such\\n   that ``x == y`` implies both that ``x is y`` and ``hash(x) ==\\n   hash(y)``.\\n\\n   A class that overrides ``__eq__()`` and does not define\\n   ``__hash__()`` will have its ``__hash__()`` implicitly set to\\n   ``None``.  When the ``__hash__()`` method of a class is ``None``,\\n   instances of the class will raise an appropriate ``TypeError`` when\\n   a program attempts to retrieve their hash value, and will also be\\n   correctly identified as unhashable when checking ``isinstance(obj,\\n   collections.Hashable``).\\n\\n   If a class that overrides ``__eq__()`` needs to retain the\\n   implementation of ``__hash__()`` from a parent class, the\\n   interpreter must be told this explicitly by setting ``__hash__ =\\n   <ParentClass>.__hash__``.\\n\\n   If a class that does not override ``__eq__()`` wishes to suppress\\n   hash support, it should include ``__hash__ = None`` in the class\\n   definition. A class which defines its own ``__hash__()`` that\\n   explicitly raises a ``TypeError`` would be incorrectly identified\\n   as hashable by an ``isinstance(obj, collections.Hashable)`` call.\\n\\n   Note: By default, the ``__hash__()`` values of str, bytes and datetime\\n     objects are \"salted\" with an unpredictable random value.\\n     Although they remain constant within an individual Python\\n     process, they are not predictable between repeated invocations of\\n     Python.This is intended to provide protection against a denial-\\n     of-service caused by carefully-chosen inputs that exploit the\\n     worst case performance of a dict insertion, O(n^2) complexity.\\n     See http://www.ocert.org/advisories/ocert-2011-003.html for\\n     details.Changing hash values affects the iteration order of\\n     dicts, sets and other mappings.  Python has never made guarantees\\n     about this ordering (and it typically varies between 32-bit and\\n     64-bit builds).See also ``PYTHONHASHSEED``.\\n\\n   Changed in version 3.3: Hash randomization is enabled by default.\\n\\nobject.__bool__(self)\\n\\n   Called to implement truth value testing and the built-in operation\\n   ``bool()``; should return ``False`` or ``True``.  When this method\\n   is not defined, ``__len__()`` is called, if it is defined, and the\\n   object is considered true if its result is nonzero.  If a class\\n   defines neither ``__len__()`` nor ``__bool__()``, all its instances\\n   are considered true.\\n\\n\\nCustomizing attribute access\\n============================\\n\\nThe following methods can be defined to customize the meaning of\\nattribute access (use of, assignment to, or deletion of ``x.name``)\\nfor class instances.\\n\\nobject.__getattr__(self, name)\\n\\n   Called when an attribute lookup has not found the attribute in the\\n   usual places (i.e. it is not an instance attribute nor is it found\\n   in the class tree for ``self``).  ``name`` is the attribute name.\\n   This method should return the (computed) attribute value or raise\\n   an ``AttributeError`` exception.\\n\\n   Note that if the attribute is found through the normal mechanism,\\n   ``__getattr__()`` is not called.  (This is an intentional asymmetry\\n   between ``__getattr__()`` and ``__setattr__()``.) This is done both\\n   for efficiency reasons and because otherwise ``__getattr__()``\\n   would have no way to access other attributes of the instance.  Note\\n   that at least for instance variables, you can fake total control by\\n   not inserting any values in the instance attribute dictionary (but\\n   instead inserting them in another object).  See the\\n   ``__getattribute__()`` method below for a way to actually get total\\n   control over attribute access.\\n\\nobject.__getattribute__(self, name)\\n\\n   Called unconditionally to implement attribute accesses for\\n   instances of the class. If the class also defines\\n   ``__getattr__()``, the latter will not be called unless\\n   ``__getattribute__()`` either calls it explicitly or raises an\\n   ``AttributeError``. This method should return the (computed)\\n   attribute value or raise an ``AttributeError`` exception. In order\\n   to avoid infinite recursion in this method, its implementation\\n   should always call the base class method with the same name to\\n   access any attributes it needs, for example,\\n   ``object.__getattribute__(self, name)``.\\n\\n   Note: This method may still be bypassed when looking up special methods\\n     as the result of implicit invocation via language syntax or\\n     built-in functions. See *Special method lookup*.\\n\\nobject.__setattr__(self, name, value)\\n\\n   Called when an attribute assignment is attempted.  This is called\\n   instead of the normal mechanism (i.e. store the value in the\\n   instance dictionary). *name* is the attribute name, *value* is the\\n   value to be assigned to it.\\n\\n   If ``__setattr__()`` wants to assign to an instance attribute, it\\n   should call the base class method with the same name, for example,\\n   ``object.__setattr__(self, name, value)``.\\n\\nobject.__delattr__(self, name)\\n\\n   Like ``__setattr__()`` but for attribute deletion instead of\\n   assignment.  This should only be implemented if ``del obj.name`` is\\n   meaningful for the object.\\n\\nobject.__dir__(self)\\n\\n   Called when ``dir()`` is called on the object. A sequence must be\\n   returned. ``dir()`` converts the returned sequence to a list and\\n   sorts it.\\n\\n\\nImplementing Descriptors\\n------------------------\\n\\nThe following methods only apply when an instance of the class\\ncontaining the method (a so-called *descriptor* class) appears in an\\n*owner* class (the descriptor must be in either the owner\\'s class\\ndictionary or in the class dictionary for one of its parents).  In the\\nexamples below, \"the attribute\" refers to the attribute whose name is\\nthe key of the property in the owner class\\' ``__dict__``.\\n\\nobject.__get__(self, instance, owner)\\n\\n   Called to get the attribute of the owner class (class attribute\\n   access) or of an instance of that class (instance attribute\\n   access). *owner* is always the owner class, while *instance* is the\\n   instance that the attribute was accessed through, or ``None`` when\\n   the attribute is accessed through the *owner*.  This method should\\n   return the (computed) attribute value or raise an\\n   ``AttributeError`` exception.\\n\\nobject.__set__(self, instance, value)\\n\\n   Called to set the attribute on an instance *instance* of the owner\\n   class to a new value, *value*.\\n\\nobject.__delete__(self, instance)\\n\\n   Called to delete the attribute on an instance *instance* of the\\n   owner class.\\n\\n\\nInvoking Descriptors\\n--------------------\\n\\nIn general, a descriptor is an object attribute with \"binding\\nbehavior\", one whose attribute access has been overridden by methods\\nin the descriptor protocol:  ``__get__()``, ``__set__()``, and\\n``__delete__()``. If any of those methods are defined for an object,\\nit is said to be a descriptor.\\n\\nThe default behavior for attribute access is to get, set, or delete\\nthe attribute from an object\\'s dictionary. For instance, ``a.x`` has a\\nlookup chain starting with ``a.__dict__[\\'x\\']``, then\\n``type(a).__dict__[\\'x\\']``, and continuing through the base classes of\\n``type(a)`` excluding metaclasses.\\n\\nHowever, if the looked-up value is an object defining one of the\\ndescriptor methods, then Python may override the default behavior and\\ninvoke the descriptor method instead.  Where this occurs in the\\nprecedence chain depends on which descriptor methods were defined and\\nhow they were called.\\n\\nThe starting point for descriptor invocation is a binding, ``a.x``.\\nHow the arguments are assembled depends on ``a``:\\n\\nDirect Call\\n   The simplest and least common call is when user code directly\\n   invokes a descriptor method:    ``x.__get__(a)``.\\n\\nInstance Binding\\n   If binding to an object instance, ``a.x`` is transformed into the\\n   call: ``type(a).__dict__[\\'x\\'].__get__(a, type(a))``.\\n\\nClass Binding\\n   If binding to a class, ``A.x`` is transformed into the call:\\n   ``A.__dict__[\\'x\\'].__get__(None, A)``.\\n\\nSuper Binding\\n   If ``a`` is an instance of ``super``, then the binding ``super(B,\\n   obj).m()`` searches ``obj.__class__.__mro__`` for the base class\\n   ``A`` immediately preceding ``B`` and then invokes the descriptor\\n   with the call: ``A.__dict__[\\'m\\'].__get__(obj, obj.__class__)``.\\n\\nFor instance bindings, the precedence of descriptor invocation depends\\non the which descriptor methods are defined.  A descriptor can define\\nany combination of ``__get__()``, ``__set__()`` and ``__delete__()``.\\nIf it does not define ``__get__()``, then accessing the attribute will\\nreturn the descriptor object itself unless there is a value in the\\nobject\\'s instance dictionary.  If the descriptor defines ``__set__()``\\nand/or ``__delete__()``, it is a data descriptor; if it defines\\nneither, it is a non-data descriptor.  Normally, data descriptors\\ndefine both ``__get__()`` and ``__set__()``, while non-data\\ndescriptors have just the ``__get__()`` method.  Data descriptors with\\n``__set__()`` and ``__get__()`` defined always override a redefinition\\nin an instance dictionary.  In contrast, non-data descriptors can be\\noverridden by instances.\\n\\nPython methods (including ``staticmethod()`` and ``classmethod()``)\\nare implemented as non-data descriptors.  Accordingly, instances can\\nredefine and override methods.  This allows individual instances to\\nacquire behaviors that differ from other instances of the same class.\\n\\nThe ``property()`` function is implemented as a data descriptor.\\nAccordingly, instances cannot override the behavior of a property.\\n\\n\\n__slots__\\n---------\\n\\nBy default, instances of classes have a dictionary for attribute\\nstorage.  This wastes space for objects having very few instance\\nvariables.  The space consumption can become acute when creating large\\nnumbers of instances.\\n\\nThe default can be overridden by defining *__slots__* in a class\\ndefinition. The *__slots__* declaration takes a sequence of instance\\nvariables and reserves just enough space in each instance to hold a\\nvalue for each variable.  Space is saved because *__dict__* is not\\ncreated for each instance.\\n\\nobject.__slots__\\n\\n   This class variable can be assigned a string, iterable, or sequence\\n   of strings with variable names used by instances.  If defined in a\\n   class, *__slots__* reserves space for the declared variables and\\n   prevents the automatic creation of *__dict__* and *__weakref__* for\\n   each instance.\\n\\n\\nNotes on using *__slots__*\\n~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\n* When inheriting from a class without *__slots__*, the *__dict__*\\n  attribute of that class will always be accessible, so a *__slots__*\\n  definition in the subclass is meaningless.\\n\\n* Without a *__dict__* variable, instances cannot be assigned new\\n  variables not listed in the *__slots__* definition.  Attempts to\\n  assign to an unlisted variable name raises ``AttributeError``. If\\n  dynamic assignment of new variables is desired, then add\\n  ``\\'__dict__\\'`` to the sequence of strings in the *__slots__*\\n  declaration.\\n\\n* Without a *__weakref__* variable for each instance, classes defining\\n  *__slots__* do not support weak references to its instances. If weak\\n  reference support is needed, then add ``\\'__weakref__\\'`` to the\\n  sequence of strings in the *__slots__* declaration.\\n\\n* *__slots__* are implemented at the class level by creating\\n  descriptors (*Implementing Descriptors*) for each variable name.  As\\n  a result, class attributes cannot be used to set default values for\\n  instance variables defined by *__slots__*; otherwise, the class\\n  attribute would overwrite the descriptor assignment.\\n\\n* The action of a *__slots__* declaration is limited to the class\\n  where it is defined.  As a result, subclasses will have a *__dict__*\\n  unless they also define *__slots__* (which must only contain names\\n  of any *additional* slots).\\n\\n* If a class defines a slot also defined in a base class, the instance\\n  variable defined by the base class slot is inaccessible (except by\\n  retrieving its descriptor directly from the base class). This\\n  renders the meaning of the program undefined.  In the future, a\\n  check may be added to prevent this.\\n\\n* Nonempty *__slots__* does not work for classes derived from\\n  \"variable-length\" built-in types such as ``int``, ``str`` and\\n  ``tuple``.\\n\\n* Any non-string iterable may be assigned to *__slots__*. Mappings may\\n  also be used; however, in the future, special meaning may be\\n  assigned to the values corresponding to each key.\\n\\n* *__class__* assignment works only if both classes have the same\\n  *__slots__*.\\n\\n\\nCustomizing class creation\\n==========================\\n\\nBy default, classes are constructed using ``type()``. The class body\\nis executed in a new namespace and the class name is bound locally to\\nthe result of ``type(name, bases, namespace)``.\\n\\nThe class creation process can be customised by passing the\\n``metaclass`` keyword argument in the class definition line, or by\\ninheriting from an existing class that included such an argument. In\\nthe following example, both ``MyClass`` and ``MySubclass`` are\\ninstances of ``Meta``:\\n\\n   class Meta(type):\\n       pass\\n\\n   class MyClass(metaclass=Meta):\\n       pass\\n\\n   class MySubclass(MyClass):\\n       pass\\n\\nAny other keyword arguments that are specified in the class definition\\nare passed through to all metaclass operations described below.\\n\\nWhen a class definition is executed, the following steps occur:\\n\\n* the appropriate metaclass is determined\\n\\n* the class namespace is prepared\\n\\n* the class body is executed\\n\\n* the class object is created\\n\\n\\nDetermining the appropriate metaclass\\n-------------------------------------\\n\\nThe appropriate metaclass for a class definition is determined as\\nfollows:\\n\\n* if no bases and no explicit metaclass are given, then ``type()`` is\\n  used\\n\\n* if an explicit metaclass is given and it is *not* an instance of\\n  ``type()``, then it is used directly as the metaclass\\n\\n* if an instance of ``type()`` is given as the explicit metaclass, or\\n  bases are defined, then the most derived metaclass is used\\n\\nThe most derived metaclass is selected from the explicitly specified\\nmetaclass (if any) and the metaclasses (i.e. ``type(cls)``) of all\\nspecified base classes. The most derived metaclass is one which is a\\nsubtype of *all* of these candidate metaclasses. If none of the\\ncandidate metaclasses meets that criterion, then the class definition\\nwill fail with ``TypeError``.\\n\\n\\nPreparing the class namespace\\n-----------------------------\\n\\nOnce the appropriate metaclass has been identified, then the class\\nnamespace is prepared. If the metaclass has a ``__prepare__``\\nattribute, it is called as ``namespace = metaclass.__prepare__(name,\\nbases, **kwds)`` (where the additional keyword arguments, if any, come\\nfrom the class definition).\\n\\nIf the metaclass has no ``__prepare__`` attribute, then the class\\nnamespace is initialised as an empty ``dict()`` instance.\\n\\nSee also:\\n\\n   **PEP 3115** - Metaclasses in Python 3000\\n      Introduced the ``__prepare__`` namespace hook\\n\\n\\nExecuting the class body\\n------------------------\\n\\nThe class body is executed (approximately) as ``exec(body, globals(),\\nnamespace)``. The key difference from a normal call to ``exec()`` is\\nthat lexical scoping allows the class body (including any methods) to\\nreference names from the current and outer scopes when the class\\ndefinition occurs inside a function.\\n\\nHowever, even when the class definition occurs inside the function,\\nmethods defined inside the class still cannot see names defined at the\\nclass scope. Class variables must be accessed through the first\\nparameter of instance or class methods, and cannot be accessed at all\\nfrom static methods.\\n\\n\\nCreating the class object\\n-------------------------\\n\\nOnce the class namespace has been populated by executing the class\\nbody, the class object is created by calling ``metaclass(name, bases,\\nnamespace, **kwds)`` (the additional keywords passed here are the same\\nas those passed to ``__prepare__``).\\n\\nThis class object is the one that will be referenced by the zero-\\nargument form of ``super()``. ``__class__`` is an implicit closure\\nreference created by the compiler if any methods in a class body refer\\nto either ``__class__`` or ``super``. This allows the zero argument\\nform of ``super()`` to correctly identify the class being defined\\nbased on lexical scoping, while the class or instance that was used to\\nmake the current call is identified based on the first argument passed\\nto the method.\\n\\nAfter the class object is created, it is passed to the class\\ndecorators included in the class definition (if any) and the resulting\\nobject is bound in the local namespace as the defined class.\\n\\nSee also:\\n\\n   **PEP 3135** - New super\\n      Describes the implicit ``__class__`` closure reference\\n\\n\\nMetaclass example\\n-----------------\\n\\nThe potential uses for metaclasses are boundless. Some ideas that have\\nbeen explored include logging, interface checking, automatic\\ndelegation, automatic property creation, proxies, frameworks, and\\nautomatic resource locking/synchronization.\\n\\nHere is an example of a metaclass that uses an\\n``collections.OrderedDict`` to remember the order that class members\\nwere defined:\\n\\n   class OrderedClass(type):\\n\\n        @classmethod\\n        def __prepare__(metacls, name, bases, **kwds):\\n           return collections.OrderedDict()\\n\\n        def __new__(cls, name, bases, namespace, **kwds):\\n           result = type.__new__(cls, name, bases, dict(namespace))\\n           result.members = tuple(namespace)\\n           return result\\n\\n   class A(metaclass=OrderedClass):\\n       def one(self): pass\\n       def two(self): pass\\n       def three(self): pass\\n       def four(self): pass\\n\\n   >>> A.members\\n   (\\'__module__\\', \\'one\\', \\'two\\', \\'three\\', \\'four\\')\\n\\nWhen the class definition for *A* gets executed, the process begins\\nwith calling the metaclass\\'s ``__prepare__()`` method which returns an\\nempty ``collections.OrderedDict``.  That mapping records the methods\\nand attributes of *A* as they are defined within the body of the class\\nstatement. Once those definitions are executed, the ordered dictionary\\nis fully populated and the metaclass\\'s ``__new__()`` method gets\\ninvoked.  That method builds the new type and it saves the ordered\\ndictionary keys in an attribute called ``members``.\\n\\n\\nCustomizing instance and subclass checks\\n========================================\\n\\nThe following methods are used to override the default behavior of the\\n``isinstance()`` and ``issubclass()`` built-in functions.\\n\\nIn particular, the metaclass ``abc.ABCMeta`` implements these methods\\nin order to allow the addition of Abstract Base Classes (ABCs) as\\n\"virtual base classes\" to any class or type (including built-in\\ntypes), including other ABCs.\\n\\nclass.__instancecheck__(self, instance)\\n\\n   Return true if *instance* should be considered a (direct or\\n   indirect) instance of *class*. If defined, called to implement\\n   ``isinstance(instance, class)``.\\n\\nclass.__subclasscheck__(self, subclass)\\n\\n   Return true if *subclass* should be considered a (direct or\\n   indirect) subclass of *class*.  If defined, called to implement\\n   ``issubclass(subclass, class)``.\\n\\nNote that these methods are looked up on the type (metaclass) of a\\nclass.  They cannot be defined as class methods in the actual class.\\nThis is consistent with the lookup of special methods that are called\\non instances, only in this case the instance is itself a class.\\n\\nSee also:\\n\\n   **PEP 3119** - Introducing Abstract Base Classes\\n      Includes the specification for customizing ``isinstance()`` and\\n      ``issubclass()`` behavior through ``__instancecheck__()`` and\\n      ``__subclasscheck__()``, with motivation for this functionality\\n      in the context of adding Abstract Base Classes (see the ``abc``\\n      module) to the language.\\n\\n\\nEmulating callable objects\\n==========================\\n\\nobject.__call__(self[, args...])\\n\\n   Called when the instance is \"called\" as a function; if this method\\n   is defined, ``x(arg1, arg2, ...)`` is a shorthand for\\n   ``x.__call__(arg1, arg2, ...)``.\\n\\n\\nEmulating container types\\n=========================\\n\\nThe following methods can be defined to implement container objects.\\nContainers usually are sequences (such as lists or tuples) or mappings\\n(like dictionaries), but can represent other containers as well.  The\\nfirst set of methods is used either to emulate a sequence or to\\nemulate a mapping; the difference is that for a sequence, the\\nallowable keys should be the integers *k* for which ``0 <= k < N``\\nwhere *N* is the length of the sequence, or slice objects, which\\ndefine a range of items.  It is also recommended that mappings provide\\nthe methods ``keys()``, ``values()``, ``items()``, ``get()``,\\n``clear()``, ``setdefault()``, ``pop()``, ``popitem()``, ``copy()``,\\nand ``update()`` behaving similar to those for Python\\'s standard\\ndictionary objects.  The ``collections`` module provides a\\n``MutableMapping`` abstract base class to help create those methods\\nfrom a base set of ``__getitem__()``, ``__setitem__()``,\\n``__delitem__()``, and ``keys()``. Mutable sequences should provide\\nmethods ``append()``, ``count()``, ``index()``, ``extend()``,\\n``insert()``, ``pop()``, ``remove()``, ``reverse()`` and ``sort()``,\\nlike Python standard list objects.  Finally, sequence types should\\nimplement addition (meaning concatenation) and multiplication (meaning\\nrepetition) by defining the methods ``__add__()``, ``__radd__()``,\\n``__iadd__()``, ``__mul__()``, ``__rmul__()`` and ``__imul__()``\\ndescribed below; they should not define other numerical operators.  It\\nis recommended that both mappings and sequences implement the\\n``__contains__()`` method to allow efficient use of the ``in``\\noperator; for mappings, ``in`` should search the mapping\\'s keys; for\\nsequences, it should search through the values.  It is further\\nrecommended that both mappings and sequences implement the\\n``__iter__()`` method to allow efficient iteration through the\\ncontainer; for mappings, ``__iter__()`` should be the same as\\n``keys()``; for sequences, it should iterate through the values.\\n\\nobject.__len__(self)\\n\\n   Called to implement the built-in function ``len()``.  Should return\\n   the length of the object, an integer ``>=`` 0.  Also, an object\\n   that doesn\\'t define a ``__bool__()`` method and whose ``__len__()``\\n   method returns zero is considered to be false in a Boolean context.\\n\\nNote: Slicing is done exclusively with the following three methods.  A\\n  call like\\n\\n     a[1:2] = b\\n\\n  is translated to\\n\\n     a[slice(1, 2, None)] = b\\n\\n  and so forth.  Missing slice items are always filled in with\\n  ``None``.\\n\\nobject.__getitem__(self, key)\\n\\n   Called to implement evaluation of ``self[key]``. For sequence\\n   types, the accepted keys should be integers and slice objects.\\n   Note that the special interpretation of negative indexes (if the\\n   class wishes to emulate a sequence type) is up to the\\n   ``__getitem__()`` method. If *key* is of an inappropriate type,\\n   ``TypeError`` may be raised; if of a value outside the set of\\n   indexes for the sequence (after any special interpretation of\\n   negative values), ``IndexError`` should be raised. For mapping\\n   types, if *key* is missing (not in the container), ``KeyError``\\n   should be raised.\\n\\n   Note: ``for`` loops expect that an ``IndexError`` will be raised for\\n     illegal indexes to allow proper detection of the end of the\\n     sequence.\\n\\nobject.__setitem__(self, key, value)\\n\\n   Called to implement assignment to ``self[key]``.  Same note as for\\n   ``__getitem__()``.  This should only be implemented for mappings if\\n   the objects support changes to the values for keys, or if new keys\\n   can be added, or for sequences if elements can be replaced.  The\\n   same exceptions should be raised for improper *key* values as for\\n   the ``__getitem__()`` method.\\n\\nobject.__delitem__(self, key)\\n\\n   Called to implement deletion of ``self[key]``.  Same note as for\\n   ``__getitem__()``.  This should only be implemented for mappings if\\n   the objects support removal of keys, or for sequences if elements\\n   can be removed from the sequence.  The same exceptions should be\\n   raised for improper *key* values as for the ``__getitem__()``\\n   method.\\n\\nobject.__iter__(self)\\n\\n   This method is called when an iterator is required for a container.\\n   This method should return a new iterator object that can iterate\\n   over all the objects in the container.  For mappings, it should\\n   iterate over the keys of the container, and should also be made\\n   available as the method ``keys()``.\\n\\n   Iterator objects also need to implement this method; they are\\n   required to return themselves.  For more information on iterator\\n   objects, see *Iterator Types*.\\n\\nobject.__reversed__(self)\\n\\n   Called (if present) by the ``reversed()`` built-in to implement\\n   reverse iteration.  It should return a new iterator object that\\n   iterates over all the objects in the container in reverse order.\\n\\n   If the ``__reversed__()`` method is not provided, the\\n   ``reversed()`` built-in will fall back to using the sequence\\n   protocol (``__len__()`` and ``__getitem__()``).  Objects that\\n   support the sequence protocol should only provide\\n   ``__reversed__()`` if they can provide an implementation that is\\n   more efficient than the one provided by ``reversed()``.\\n\\nThe membership test operators (``in`` and ``not in``) are normally\\nimplemented as an iteration through a sequence.  However, container\\nobjects can supply the following special method with a more efficient\\nimplementation, which also does not require the object be a sequence.\\n\\nobject.__contains__(self, item)\\n\\n   Called to implement membership test operators.  Should return true\\n   if *item* is in *self*, false otherwise.  For mapping objects, this\\n   should consider the keys of the mapping rather than the values or\\n   the key-item pairs.\\n\\n   For objects that don\\'t define ``__contains__()``, the membership\\n   test first tries iteration via ``__iter__()``, then the old\\n   sequence iteration protocol via ``__getitem__()``, see *this\\n   section in the language reference*.\\n\\n\\nEmulating numeric types\\n=======================\\n\\nThe following methods can be defined to emulate numeric objects.\\nMethods corresponding to operations that are not supported by the\\nparticular kind of number implemented (e.g., bitwise operations for\\nnon-integral numbers) should be left undefined.\\n\\nobject.__add__(self, other)\\nobject.__sub__(self, other)\\nobject.__mul__(self, other)\\nobject.__truediv__(self, other)\\nobject.__floordiv__(self, other)\\nobject.__mod__(self, other)\\nobject.__divmod__(self, other)\\nobject.__pow__(self, other[, modulo])\\nobject.__lshift__(self, other)\\nobject.__rshift__(self, other)\\nobject.__and__(self, other)\\nobject.__xor__(self, other)\\nobject.__or__(self, other)\\n\\n   These methods are called to implement the binary arithmetic\\n   operations (``+``, ``-``, ``*``, ``/``, ``//``, ``%``,\\n   ``divmod()``, ``pow()``, ``**``, ``<<``, ``>>``, ``&``, ``^``,\\n   ``|``).  For instance, to evaluate the expression ``x + y``, where\\n   *x* is an instance of a class that has an ``__add__()`` method,\\n   ``x.__add__(y)`` is called.  The ``__divmod__()`` method should be\\n   the equivalent to using ``__floordiv__()`` and ``__mod__()``; it\\n   should not be related to ``__truediv__()``.  Note that\\n   ``__pow__()`` should be defined to accept an optional third\\n   argument if the ternary version of the built-in ``pow()`` function\\n   is to be supported.\\n\\n   If one of those methods does not support the operation with the\\n   supplied arguments, it should return ``NotImplemented``.\\n\\nobject.__radd__(self, other)\\nobject.__rsub__(self, other)\\nobject.__rmul__(self, other)\\nobject.__rtruediv__(self, other)\\nobject.__rfloordiv__(self, other)\\nobject.__rmod__(self, other)\\nobject.__rdivmod__(self, other)\\nobject.__rpow__(self, other)\\nobject.__rlshift__(self, other)\\nobject.__rrshift__(self, other)\\nobject.__rand__(self, other)\\nobject.__rxor__(self, other)\\nobject.__ror__(self, other)\\n\\n   These methods are called to implement the binary arithmetic\\n   operations (``+``, ``-``, ``*``, ``/``, ``//``, ``%``,\\n   ``divmod()``, ``pow()``, ``**``, ``<<``, ``>>``, ``&``, ``^``,\\n   ``|``) with reflected (swapped) operands. These functions are only\\n   called if the left operand does not support the corresponding\\n   operation and the operands are of different types. [2]  For\\n   instance, to evaluate the expression ``x - y``, where *y* is an\\n   instance of a class that has an ``__rsub__()`` method,\\n   ``y.__rsub__(x)`` is called if ``x.__sub__(y)`` returns\\n   *NotImplemented*.\\n\\n   Note that ternary ``pow()`` will not try calling ``__rpow__()``\\n   (the coercion rules would become too complicated).\\n\\n   Note: If the right operand\\'s type is a subclass of the left operand\\'s\\n     type and that subclass provides the reflected method for the\\n     operation, this method will be called before the left operand\\'s\\n     non-reflected method.  This behavior allows subclasses to\\n     override their ancestors\\' operations.\\n\\nobject.__iadd__(self, other)\\nobject.__isub__(self, other)\\nobject.__imul__(self, other)\\nobject.__itruediv__(self, other)\\nobject.__ifloordiv__(self, other)\\nobject.__imod__(self, other)\\nobject.__ipow__(self, other[, modulo])\\nobject.__ilshift__(self, other)\\nobject.__irshift__(self, other)\\nobject.__iand__(self, other)\\nobject.__ixor__(self, other)\\nobject.__ior__(self, other)\\n\\n   These methods are called to implement the augmented arithmetic\\n   assignments (``+=``, ``-=``, ``*=``, ``/=``, ``//=``, ``%=``,\\n   ``**=``, ``<<=``, ``>>=``, ``&=``, ``^=``, ``|=``).  These methods\\n   should attempt to do the operation in-place (modifying *self*) and\\n   return the result (which could be, but does not have to be,\\n   *self*).  If a specific method is not defined, the augmented\\n   assignment falls back to the normal methods.  For instance, to\\n   execute the statement ``x += y``, where *x* is an instance of a\\n   class that has an ``__iadd__()`` method, ``x.__iadd__(y)`` is\\n   called.  If *x* is an instance of a class that does not define a\\n   ``__iadd__()`` method, ``x.__add__(y)`` and ``y.__radd__(x)`` are\\n   considered, as with the evaluation of ``x + y``.\\n\\nobject.__neg__(self)\\nobject.__pos__(self)\\nobject.__abs__(self)\\nobject.__invert__(self)\\n\\n   Called to implement the unary arithmetic operations (``-``, ``+``,\\n   ``abs()`` and ``~``).\\n\\nobject.__complex__(self)\\nobject.__int__(self)\\nobject.__float__(self)\\nobject.__round__(self[, n])\\n\\n   Called to implement the built-in functions ``complex()``,\\n   ``int()``, ``float()`` and ``round()``.  Should return a value of\\n   the appropriate type.\\n\\nobject.__index__(self)\\n\\n   Called to implement ``operator.index()``.  Also called whenever\\n   Python needs an integer object (such as in slicing, or in the\\n   built-in ``bin()``, ``hex()`` and ``oct()`` functions). Must return\\n   an integer.\\n\\n\\nWith Statement Context Managers\\n===============================\\n\\nA *context manager* is an object that defines the runtime context to\\nbe established when executing a ``with`` statement. The context\\nmanager handles the entry into, and the exit from, the desired runtime\\ncontext for the execution of the block of code.  Context managers are\\nnormally invoked using the ``with`` statement (described in section\\n*The with statement*), but can also be used by directly invoking their\\nmethods.\\n\\nTypical uses of context managers include saving and restoring various\\nkinds of global state, locking and unlocking resources, closing opened\\nfiles, etc.\\n\\nFor more information on context managers, see *Context Manager Types*.\\n\\nobject.__enter__(self)\\n\\n   Enter the runtime context related to this object. The ``with``\\n   statement will bind this method\\'s return value to the target(s)\\n   specified in the ``as`` clause of the statement, if any.\\n\\nobject.__exit__(self, exc_type, exc_value, traceback)\\n\\n   Exit the runtime context related to this object. The parameters\\n   describe the exception that caused the context to be exited. If the\\n   context was exited without an exception, all three arguments will\\n   be ``None``.\\n\\n   If an exception is supplied, and the method wishes to suppress the\\n   exception (i.e., prevent it from being propagated), it should\\n   return a true value. Otherwise, the exception will be processed\\n   normally upon exit from this method.\\n\\n   Note that ``__exit__()`` methods should not reraise the passed-in\\n   exception; this is the caller\\'s responsibility.\\n\\nSee also:\\n\\n   **PEP 0343** - The \"with\" statement\\n      The specification, background, and examples for the Python\\n      ``with`` statement.\\n\\n\\nSpecial method lookup\\n=====================\\n\\nFor custom classes, implicit invocations of special methods are only\\nguaranteed to work correctly if defined on an object\\'s type, not in\\nthe object\\'s instance dictionary.  That behaviour is the reason why\\nthe following code raises an exception:\\n\\n   >>> class C:\\n   ...     pass\\n   ...\\n   >>> c = C()\\n   >>> c.__len__ = lambda: 5\\n   >>> len(c)\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 1, in <module>\\n   TypeError: object of type \\'C\\' has no len()\\n\\nThe rationale behind this behaviour lies with a number of special\\nmethods such as ``__hash__()`` and ``__repr__()`` that are implemented\\nby all objects, including type objects. If the implicit lookup of\\nthese methods used the conventional lookup process, they would fail\\nwhen invoked on the type object itself:\\n\\n   >>> 1 .__hash__() == hash(1)\\n   True\\n   >>> int.__hash__() == hash(int)\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 1, in <module>\\n   TypeError: descriptor \\'__hash__\\' of \\'int\\' object needs an argument\\n\\nIncorrectly attempting to invoke an unbound method of a class in this\\nway is sometimes referred to as \\'metaclass confusion\\', and is avoided\\nby bypassing the instance when looking up special methods:\\n\\n   >>> type(1).__hash__(1) == hash(1)\\n   True\\n   >>> type(int).__hash__(int) == hash(int)\\n   True\\n\\nIn addition to bypassing any instance attributes in the interest of\\ncorrectness, implicit special method lookup generally also bypasses\\nthe ``__getattribute__()`` method even of the object\\'s metaclass:\\n\\n   >>> class Meta(type):\\n   ...    def __getattribute__(*args):\\n   ...       print(\"Metaclass getattribute invoked\")\\n   ...       return type.__getattribute__(*args)\\n   ...\\n   >>> class C(object, metaclass=Meta):\\n   ...     def __len__(self):\\n   ...         return 10\\n   ...     def __getattribute__(*args):\\n   ...         print(\"Class getattribute invoked\")\\n   ...         return object.__getattribute__(*args)\\n   ...\\n   >>> c = C()\\n   >>> c.__len__()                 # Explicit lookup via instance\\n   Class getattribute invoked\\n   10\\n   >>> type(c).__len__(c)          # Explicit lookup via type\\n   Metaclass getattribute invoked\\n   10\\n   >>> len(c)                      # Implicit lookup\\n   10\\n\\nBypassing the ``__getattribute__()`` machinery in this fashion\\nprovides significant scope for speed optimisations within the\\ninterpreter, at the cost of some flexibility in the handling of\\nspecial methods (the special method *must* be set on the class object\\nitself in order to be consistently invoked by the interpreter).\\n\\n-[ Footnotes ]-\\n\\n[1] It *is* possible in some cases to change an object\\'s type, under\\n    certain controlled conditions. It generally isn\\'t a good idea\\n    though, since it can lead to some very strange behaviour if it is\\n    handled incorrectly.\\n\\n[2] For operands of the same type, it is assumed that if the non-\\n    reflected method (such as ``__add__()``) fails the operation is\\n    not supported, which is why the reflected method is not called.\\n',\n'string-methods': '\\nString Methods\\n**************\\n\\nStrings implement all of the *common* sequence operations, along with\\nthe additional methods described below.\\n\\nStrings also support two styles of string formatting, one providing a\\nlarge degree of flexibility and customization (see ``str.format()``,\\n*Format String Syntax* and *String Formatting*) and the other based on\\nC ``printf`` style formatting that handles a narrower range of types\\nand is slightly harder to use correctly, but is often faster for the\\ncases it can handle (*printf-style String Formatting*).\\n\\nThe *Text Processing Services* section of the standard library covers\\na number of other modules that provide various text related utilities\\n(including regular expression support in the ``re`` module).\\n\\nstr.capitalize()\\n\\n   Return a copy of the string with its first character capitalized\\n   and the rest lowercased.\\n\\nstr.casefold()\\n\\n   Return a casefolded copy of the string. Casefolded strings may be\\n   used for caseless matching.\\n\\n   Casefolding is similar to lowercasing but more aggressive because\\n   it is intended to remove all case distinctions in a string. For\\n   example, the German lowercase letter ``\\'\\xc3\\x9f\\'`` is equivalent to\\n   ``\"ss\"``. Since it is already lowercase, ``lower()`` would do\\n   nothing to ``\\'\\xc3\\x9f\\'``; ``casefold()`` converts it to ``\"ss\"``.\\n\\n   The casefolding algorithm is described in section 3.13 of the\\n   Unicode Standard.\\n\\n   New in version 3.3.\\n\\nstr.center(width[, fillchar])\\n\\n   Return centered in a string of length *width*. Padding is done\\n   using the specified *fillchar* (default is a space).\\n\\nstr.count(sub[, start[, end]])\\n\\n   Return the number of non-overlapping occurrences of substring *sub*\\n   in the range [*start*, *end*].  Optional arguments *start* and\\n   *end* are interpreted as in slice notation.\\n\\nstr.encode(encoding=\"utf-8\", errors=\"strict\")\\n\\n   Return an encoded version of the string as a bytes object. Default\\n   encoding is ``\\'utf-8\\'``. *errors* may be given to set a different\\n   error handling scheme. The default for *errors* is ``\\'strict\\'``,\\n   meaning that encoding errors raise a ``UnicodeError``. Other\\n   possible values are ``\\'ignore\\'``, ``\\'replace\\'``,\\n   ``\\'xmlcharrefreplace\\'``, ``\\'backslashreplace\\'`` and any other name\\n   registered via ``codecs.register_error()``, see section *Codec Base\\n   Classes*. For a list of possible encodings, see section *Standard\\n   Encodings*.\\n\\n   Changed in version 3.1: Support for keyword arguments added.\\n\\nstr.endswith(suffix[, start[, end]])\\n\\n   Return ``True`` if the string ends with the specified *suffix*,\\n   otherwise return ``False``.  *suffix* can also be a tuple of\\n   suffixes to look for.  With optional *start*, test beginning at\\n   that position.  With optional *end*, stop comparing at that\\n   position.\\n\\nstr.expandtabs([tabsize])\\n\\n   Return a copy of the string where all tab characters are replaced\\n   by zero or more spaces, depending on the current column and the\\n   given tab size.  The column number is reset to zero after each\\n   newline occurring in the string. If *tabsize* is not given, a tab\\n   size of ``8`` characters is assumed.  This doesn\\'t understand other\\n   non-printing characters or escape sequences.\\n\\nstr.find(sub[, start[, end]])\\n\\n   Return the lowest index in the string where substring *sub* is\\n   found, such that *sub* is contained in the slice ``s[start:end]``.\\n   Optional arguments *start* and *end* are interpreted as in slice\\n   notation.  Return ``-1`` if *sub* is not found.\\n\\n   Note: The ``find()`` method should be used only if you need to know the\\n     position of *sub*.  To check if *sub* is a substring or not, use\\n     the ``in`` operator:\\n\\n        >>> \\'Py\\' in \\'Python\\'\\n        True\\n\\nstr.format(*args, **kwargs)\\n\\n   Perform a string formatting operation.  The string on which this\\n   method is called can contain literal text or replacement fields\\n   delimited by braces ``{}``.  Each replacement field contains either\\n   the numeric index of a positional argument, or the name of a\\n   keyword argument.  Returns a copy of the string where each\\n   replacement field is replaced with the string value of the\\n   corresponding argument.\\n\\n   >>> \"The sum of 1 + 2 is {0}\".format(1+2)\\n   \\'The sum of 1 + 2 is 3\\'\\n\\n   See *Format String Syntax* for a description of the various\\n   formatting options that can be specified in format strings.\\n\\nstr.format_map(mapping)\\n\\n   Similar to ``str.format(**mapping)``, except that ``mapping`` is\\n   used directly and not copied to a ``dict`` .  This is useful if for\\n   example ``mapping`` is a dict subclass:\\n\\n   >>> class Default(dict):\\n   ...     def __missing__(self, key):\\n   ...         return key\\n   ...\\n   >>> \\'{name} was born in {country}\\'.format_map(Default(name=\\'Guido\\'))\\n   \\'Guido was born in country\\'\\n\\n   New in version 3.2.\\n\\nstr.index(sub[, start[, end]])\\n\\n   Like ``find()``, but raise ``ValueError`` when the substring is not\\n   found.\\n\\nstr.isalnum()\\n\\n   Return true if all characters in the string are alphanumeric and\\n   there is at least one character, false otherwise.  A character\\n   ``c`` is alphanumeric if one of the following returns ``True``:\\n   ``c.isalpha()``, ``c.isdecimal()``, ``c.isdigit()``, or\\n   ``c.isnumeric()``.\\n\\nstr.isalpha()\\n\\n   Return true if all characters in the string are alphabetic and\\n   there is at least one character, false otherwise.  Alphabetic\\n   characters are those characters defined in the Unicode character\\n   database as \"Letter\", i.e., those with general category property\\n   being one of \"Lm\", \"Lt\", \"Lu\", \"Ll\", or \"Lo\".  Note that this is\\n   different from the \"Alphabetic\" property defined in the Unicode\\n   Standard.\\n\\nstr.isdecimal()\\n\\n   Return true if all characters in the string are decimal characters\\n   and there is at least one character, false otherwise. Decimal\\n   characters are those from general category \"Nd\". This category\\n   includes digit characters, and all characters that can be used to\\n   form decimal-radix numbers, e.g. U+0660, ARABIC-INDIC DIGIT ZERO.\\n\\nstr.isdigit()\\n\\n   Return true if all characters in the string are digits and there is\\n   at least one character, false otherwise.  Digits include decimal\\n   characters and digits that need special handling, such as the\\n   compatibility superscript digits.  Formally, a digit is a character\\n   that has the property value Numeric_Type=Digit or\\n   Numeric_Type=Decimal.\\n\\nstr.isidentifier()\\n\\n   Return true if the string is a valid identifier according to the\\n   language definition, section *Identifiers and keywords*.\\n\\nstr.islower()\\n\\n   Return true if all cased characters [4] in the string are lowercase\\n   and there is at least one cased character, false otherwise.\\n\\nstr.isnumeric()\\n\\n   Return true if all characters in the string are numeric characters,\\n   and there is at least one character, false otherwise. Numeric\\n   characters include digit characters, and all characters that have\\n   the Unicode numeric value property, e.g. U+2155, VULGAR FRACTION\\n   ONE FIFTH.  Formally, numeric characters are those with the\\n   property value Numeric_Type=Digit, Numeric_Type=Decimal or\\n   Numeric_Type=Numeric.\\n\\nstr.isprintable()\\n\\n   Return true if all characters in the string are printable or the\\n   string is empty, false otherwise.  Nonprintable characters are\\n   those characters defined in the Unicode character database as\\n   \"Other\" or \"Separator\", excepting the ASCII space (0x20) which is\\n   considered printable.  (Note that printable characters in this\\n   context are those which should not be escaped when ``repr()`` is\\n   invoked on a string.  It has no bearing on the handling of strings\\n   written to ``sys.stdout`` or ``sys.stderr``.)\\n\\nstr.isspace()\\n\\n   Return true if there are only whitespace characters in the string\\n   and there is at least one character, false otherwise.  Whitespace\\n   characters  are those characters defined in the Unicode character\\n   database as \"Other\" or \"Separator\" and those with bidirectional\\n   property being one of \"WS\", \"B\", or \"S\".\\n\\nstr.istitle()\\n\\n   Return true if the string is a titlecased string and there is at\\n   least one character, for example uppercase characters may only\\n   follow uncased characters and lowercase characters only cased ones.\\n   Return false otherwise.\\n\\nstr.isupper()\\n\\n   Return true if all cased characters [4] in the string are uppercase\\n   and there is at least one cased character, false otherwise.\\n\\nstr.join(iterable)\\n\\n   Return a string which is the concatenation of the strings in the\\n   *iterable* *iterable*.  A ``TypeError`` will be raised if there are\\n   any non-string values in *iterable*, including ``bytes`` objects.\\n   The separator between elements is the string providing this method.\\n\\nstr.ljust(width[, fillchar])\\n\\n   Return the string left justified in a string of length *width*.\\n   Padding is done using the specified *fillchar* (default is a\\n   space).  The original string is returned if *width* is less than or\\n   equal to ``len(s)``.\\n\\nstr.lower()\\n\\n   Return a copy of the string with all the cased characters [4]\\n   converted to lowercase.\\n\\n   The lowercasing algorithm used is described in section 3.13 of the\\n   Unicode Standard.\\n\\nstr.lstrip([chars])\\n\\n   Return a copy of the string with leading characters removed.  The\\n   *chars* argument is a string specifying the set of characters to be\\n   removed.  If omitted or ``None``, the *chars* argument defaults to\\n   removing whitespace.  The *chars* argument is not a prefix; rather,\\n   all combinations of its values are stripped:\\n\\n   >>> \\'   spacious   \\'.lstrip()\\n   \\'spacious   \\'\\n   >>> \\'www.example.com\\'.lstrip(\\'cmowz.\\')\\n   \\'example.com\\'\\n\\nstatic str.maketrans(x[, y[, z]])\\n\\n   This static method returns a translation table usable for\\n   ``str.translate()``.\\n\\n   If there is only one argument, it must be a dictionary mapping\\n   Unicode ordinals (integers) or characters (strings of length 1) to\\n   Unicode ordinals, strings (of arbitrary lengths) or None.\\n   Character keys will then be converted to ordinals.\\n\\n   If there are two arguments, they must be strings of equal length,\\n   and in the resulting dictionary, each character in x will be mapped\\n   to the character at the same position in y.  If there is a third\\n   argument, it must be a string, whose characters will be mapped to\\n   None in the result.\\n\\nstr.partition(sep)\\n\\n   Split the string at the first occurrence of *sep*, and return a\\n   3-tuple containing the part before the separator, the separator\\n   itself, and the part after the separator.  If the separator is not\\n   found, return a 3-tuple containing the string itself, followed by\\n   two empty strings.\\n\\nstr.replace(old, new[, count])\\n\\n   Return a copy of the string with all occurrences of substring *old*\\n   replaced by *new*.  If the optional argument *count* is given, only\\n   the first *count* occurrences are replaced.\\n\\nstr.rfind(sub[, start[, end]])\\n\\n   Return the highest index in the string where substring *sub* is\\n   found, such that *sub* is contained within ``s[start:end]``.\\n   Optional arguments *start* and *end* are interpreted as in slice\\n   notation.  Return ``-1`` on failure.\\n\\nstr.rindex(sub[, start[, end]])\\n\\n   Like ``rfind()`` but raises ``ValueError`` when the substring *sub*\\n   is not found.\\n\\nstr.rjust(width[, fillchar])\\n\\n   Return the string right justified in a string of length *width*.\\n   Padding is done using the specified *fillchar* (default is a\\n   space). The original string is returned if *width* is less than or\\n   equal to ``len(s)``.\\n\\nstr.rpartition(sep)\\n\\n   Split the string at the last occurrence of *sep*, and return a\\n   3-tuple containing the part before the separator, the separator\\n   itself, and the part after the separator.  If the separator is not\\n   found, return a 3-tuple containing two empty strings, followed by\\n   the string itself.\\n\\nstr.rsplit(sep=None, maxsplit=-1)\\n\\n   Return a list of the words in the string, using *sep* as the\\n   delimiter string. If *maxsplit* is given, at most *maxsplit* splits\\n   are done, the *rightmost* ones.  If *sep* is not specified or\\n   ``None``, any whitespace string is a separator.  Except for\\n   splitting from the right, ``rsplit()`` behaves like ``split()``\\n   which is described in detail below.\\n\\nstr.rstrip([chars])\\n\\n   Return a copy of the string with trailing characters removed.  The\\n   *chars* argument is a string specifying the set of characters to be\\n   removed.  If omitted or ``None``, the *chars* argument defaults to\\n   removing whitespace.  The *chars* argument is not a suffix; rather,\\n   all combinations of its values are stripped:\\n\\n   >>> \\'   spacious   \\'.rstrip()\\n   \\'   spacious\\'\\n   >>> \\'mississippi\\'.rstrip(\\'ipz\\')\\n   \\'mississ\\'\\n\\nstr.split(sep=None, maxsplit=-1)\\n\\n   Return a list of the words in the string, using *sep* as the\\n   delimiter string.  If *maxsplit* is given, at most *maxsplit*\\n   splits are done (thus, the list will have at most ``maxsplit+1``\\n   elements).  If *maxsplit* is not specified or ``-1``, then there is\\n   no limit on the number of splits (all possible splits are made).\\n\\n   If *sep* is given, consecutive delimiters are not grouped together\\n   and are deemed to delimit empty strings (for example,\\n   ``\\'1,,2\\'.split(\\',\\')`` returns ``[\\'1\\', \\'\\', \\'2\\']``).  The *sep*\\n   argument may consist of multiple characters (for example,\\n   ``\\'1<>2<>3\\'.split(\\'<>\\')`` returns ``[\\'1\\', \\'2\\', \\'3\\']``). Splitting\\n   an empty string with a specified separator returns ``[\\'\\']``.\\n\\n   If *sep* is not specified or is ``None``, a different splitting\\n   algorithm is applied: runs of consecutive whitespace are regarded\\n   as a single separator, and the result will contain no empty strings\\n   at the start or end if the string has leading or trailing\\n   whitespace.  Consequently, splitting an empty string or a string\\n   consisting of just whitespace with a ``None`` separator returns\\n   ``[]``.\\n\\n   For example, ``\\' 1  2   3  \\'.split()`` returns ``[\\'1\\', \\'2\\', \\'3\\']``,\\n   and ``\\'  1  2   3  \\'.split(None, 1)`` returns ``[\\'1\\', \\'2   3  \\']``.\\n\\nstr.splitlines([keepends])\\n\\n   Return a list of the lines in the string, breaking at line\\n   boundaries. This method uses the *universal newlines* approach to\\n   splitting lines. Line breaks are not included in the resulting list\\n   unless *keepends* is given and true.\\n\\n   For example, ``\\'ab c\\\\n\\\\nde fg\\\\rkl\\\\r\\\\n\\'.splitlines()`` returns\\n   ``[\\'ab c\\', \\'\\', \\'de fg\\', \\'kl\\']``, while the same call with\\n   ``splitlines(True)`` returns ``[\\'ab c\\\\n\\', \\'\\\\n\\', \\'de fg\\\\r\\',\\n   \\'kl\\\\r\\\\n\\']``.\\n\\n   Unlike ``split()`` when a delimiter string *sep* is given, this\\n   method returns an empty list for the empty string, and a terminal\\n   line break does not result in an extra line.\\n\\nstr.startswith(prefix[, start[, end]])\\n\\n   Return ``True`` if string starts with the *prefix*, otherwise\\n   return ``False``. *prefix* can also be a tuple of prefixes to look\\n   for.  With optional *start*, test string beginning at that\\n   position.  With optional *end*, stop comparing string at that\\n   position.\\n\\nstr.strip([chars])\\n\\n   Return a copy of the string with the leading and trailing\\n   characters removed. The *chars* argument is a string specifying the\\n   set of characters to be removed. If omitted or ``None``, the\\n   *chars* argument defaults to removing whitespace. The *chars*\\n   argument is not a prefix or suffix; rather, all combinations of its\\n   values are stripped:\\n\\n   >>> \\'   spacious   \\'.strip()\\n   \\'spacious\\'\\n   >>> \\'www.example.com\\'.strip(\\'cmowz.\\')\\n   \\'example\\'\\n\\nstr.swapcase()\\n\\n   Return a copy of the string with uppercase characters converted to\\n   lowercase and vice versa. Note that it is not necessarily true that\\n   ``s.swapcase().swapcase() == s``.\\n\\nstr.title()\\n\\n   Return a titlecased version of the string where words start with an\\n   uppercase character and the remaining characters are lowercase.\\n\\n   The algorithm uses a simple language-independent definition of a\\n   word as groups of consecutive letters.  The definition works in\\n   many contexts but it means that apostrophes in contractions and\\n   possessives form word boundaries, which may not be the desired\\n   result:\\n\\n      >>> \"they\\'re bill\\'s friends from the UK\".title()\\n      \"They\\'Re Bill\\'S Friends From The Uk\"\\n\\n   A workaround for apostrophes can be constructed using regular\\n   expressions:\\n\\n      >>> import re\\n      >>> def titlecase(s):\\n      ...     return re.sub(r\"[A-Za-z]+(\\'[A-Za-z]+)?\",\\n      ...                   lambda mo: mo.group(0)[0].upper() +\\n      ...                              mo.group(0)[1:].lower(),\\n      ...                   s)\\n      ...\\n      >>> titlecase(\"they\\'re bill\\'s friends.\")\\n      \"They\\'re Bill\\'s Friends.\"\\n\\nstr.translate(map)\\n\\n   Return a copy of the *s* where all characters have been mapped\\n   through the *map* which must be a dictionary of Unicode ordinals\\n   (integers) to Unicode ordinals, strings or ``None``.  Unmapped\\n   characters are left untouched. Characters mapped to ``None`` are\\n   deleted.\\n\\n   You can use ``str.maketrans()`` to create a translation map from\\n   character-to-character mappings in different formats.\\n\\n   Note: An even more flexible approach is to create a custom character\\n     mapping codec using the ``codecs`` module (see\\n     ``encodings.cp1251`` for an example).\\n\\nstr.upper()\\n\\n   Return a copy of the string with all the cased characters [4]\\n   converted to uppercase.  Note that ``str.upper().isupper()`` might\\n   be ``False`` if ``s`` contains uncased characters or if the Unicode\\n   category of the resulting character(s) is not \"Lu\" (Letter,\\n   uppercase), but e.g. \"Lt\" (Letter, titlecase).\\n\\n   The uppercasing algorithm used is described in section 3.13 of the\\n   Unicode Standard.\\n\\nstr.zfill(width)\\n\\n   Return the numeric string left filled with zeros in a string of\\n   length *width*.  A sign prefix is handled correctly.  The original\\n   string is returned if *width* is less than or equal to ``len(s)``.\\n',\n'strings': '\\nString and Bytes literals\\n*************************\\n\\nString literals are described by the following lexical definitions:\\n\\n   stringliteral   ::= [stringprefix](shortstring | longstring)\\n   stringprefix    ::= \"r\" | \"u\" | \"R\" | \"U\"\\n   shortstring     ::= \"\\'\" shortstringitem* \"\\'\" | \\'\"\\' shortstringitem* \\'\"\\'\\n   longstring      ::= \"\\'\\'\\'\" longstringitem* \"\\'\\'\\'\" | \\'\"\"\"\\' longstringitem* \\'\"\"\"\\'\\n   shortstringitem ::= shortstringchar | stringescapeseq\\n   longstringitem  ::= longstringchar | stringescapeseq\\n   shortstringchar ::= <any source character except \"\\\\\" or newline or the quote>\\n   longstringchar  ::= <any source character except \"\\\\\">\\n   stringescapeseq ::= \"\\\\\" <any source character>\\n\\n   bytesliteral   ::= bytesprefix(shortbytes | longbytes)\\n   bytesprefix    ::= \"b\" | \"B\" | \"br\" | \"Br\" | \"bR\" | \"BR\" | \"rb\" | \"rB\" | \"Rb\" | \"RB\"\\n   shortbytes     ::= \"\\'\" shortbytesitem* \"\\'\" | \\'\"\\' shortbytesitem* \\'\"\\'\\n   longbytes      ::= \"\\'\\'\\'\" longbytesitem* \"\\'\\'\\'\" | \\'\"\"\"\\' longbytesitem* \\'\"\"\"\\'\\n   shortbytesitem ::= shortbyteschar | bytesescapeseq\\n   longbytesitem  ::= longbyteschar | bytesescapeseq\\n   shortbyteschar ::= <any ASCII character except \"\\\\\" or newline or the quote>\\n   longbyteschar  ::= <any ASCII character except \"\\\\\">\\n   bytesescapeseq ::= \"\\\\\" <any ASCII character>\\n\\nOne syntactic restriction not indicated by these productions is that\\nwhitespace is not allowed between the ``stringprefix`` or\\n``bytesprefix`` and the rest of the literal. The source character set\\nis defined by the encoding declaration; it is UTF-8 if no encoding\\ndeclaration is given in the source file; see section *Encoding\\ndeclarations*.\\n\\nIn plain English: Both types of literals can be enclosed in matching\\nsingle quotes (``\\'``) or double quotes (``\"``).  They can also be\\nenclosed in matching groups of three single or double quotes (these\\nare generally referred to as *triple-quoted strings*).  The backslash\\n(``\\\\``) character is used to escape characters that otherwise have a\\nspecial meaning, such as newline, backslash itself, or the quote\\ncharacter.\\n\\nBytes literals are always prefixed with ``\\'b\\'`` or ``\\'B\\'``; they\\nproduce an instance of the ``bytes`` type instead of the ``str`` type.\\nThey may only contain ASCII characters; bytes with a numeric value of\\n128 or greater must be expressed with escapes.\\n\\nAs of Python 3.3 it is possible again to prefix unicode strings with a\\n``u`` prefix to simplify maintenance of dual 2.x and 3.x codebases.\\n\\nBoth string and bytes literals may optionally be prefixed with a\\nletter ``\\'r\\'`` or ``\\'R\\'``; such strings are called *raw strings* and\\ntreat backslashes as literal characters.  As a result, in string\\nliterals, ``\\'\\\\U\\'`` and ``\\'\\\\u\\'`` escapes in raw strings are not treated\\nspecially. Given that Python 2.x\\'s raw unicode literals behave\\ndifferently than Python 3.x\\'s the ``\\'ur\\'`` syntax is not supported.\\n\\n   New in version 3.3: The ``\\'rb\\'`` prefix of raw bytes literals has\\n   been added as a synonym of ``\\'br\\'``.\\n\\n   New in version 3.3: Support for the unicode legacy literal\\n   (``u\\'value\\'``) was reintroduced to simplify the maintenance of dual\\n   Python 2.x and 3.x codebases. See **PEP 414** for more information.\\n\\nIn triple-quoted strings, unescaped newlines and quotes are allowed\\n(and are retained), except that three unescaped quotes in a row\\nterminate the string.  (A \"quote\" is the character used to open the\\nstring, i.e. either ``\\'`` or ``\"``.)\\n\\nUnless an ``\\'r\\'`` or ``\\'R\\'`` prefix is present, escape sequences in\\nstrings are interpreted according to rules similar to those used by\\nStandard C.  The recognized escape sequences are:\\n\\n+-------------------+-----------------------------------+---------+\\n| Escape Sequence   | Meaning                           | Notes   |\\n+===================+===================================+=========+\\n| ``\\\\newline``      | Backslash and newline ignored     |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\\\\\``            | Backslash (``\\\\``)                 |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\\\'``            | Single quote (``\\'``)              |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\\"``            | Double quote (``\"``)              |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\a``            | ASCII Bell (BEL)                  |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\b``            | ASCII Backspace (BS)              |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\f``            | ASCII Formfeed (FF)               |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\n``            | ASCII Linefeed (LF)               |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\r``            | ASCII Carriage Return (CR)        |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\t``            | ASCII Horizontal Tab (TAB)        |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\v``            | ASCII Vertical Tab (VT)           |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\ooo``          | Character with octal value *ooo*  | (1,3)   |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\xhh``          | Character with hex value *hh*     | (2,3)   |\\n+-------------------+-----------------------------------+---------+\\n\\nEscape sequences only recognized in string literals are:\\n\\n+-------------------+-----------------------------------+---------+\\n| Escape Sequence   | Meaning                           | Notes   |\\n+===================+===================================+=========+\\n| ``\\\\N{name}``      | Character named *name* in the     | (4)     |\\n|                   | Unicode database                  |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\uxxxx``        | Character with 16-bit hex value   | (5)     |\\n|                   | *xxxx*                            |         |\\n+-------------------+-----------------------------------+---------+\\n| ``\\\\Uxxxxxxxx``    | Character with 32-bit hex value   | (6)     |\\n|                   | *xxxxxxxx*                        |         |\\n+-------------------+-----------------------------------+---------+\\n\\nNotes:\\n\\n1. As in Standard C, up to three octal digits are accepted.\\n\\n2. Unlike in Standard C, exactly two hex digits are required.\\n\\n3. In a bytes literal, hexadecimal and octal escapes denote the byte\\n   with the given value. In a string literal, these escapes denote a\\n   Unicode character with the given value.\\n\\n4. Changed in version 3.3: Support for name aliases [1] has been\\n   added.\\n\\n5. Individual code units which form parts of a surrogate pair can be\\n   encoded using this escape sequence.  Exactly four hex digits are\\n   required.\\n\\n6. Any Unicode character can be encoded this way.  Exactly eight hex\\n   digits are required.\\n\\nUnlike Standard C, all unrecognized escape sequences are left in the\\nstring unchanged, i.e., *the backslash is left in the string*.  (This\\nbehavior is useful when debugging: if an escape sequence is mistyped,\\nthe resulting output is more easily recognized as broken.)  It is also\\nimportant to note that the escape sequences only recognized in string\\nliterals fall into the category of unrecognized escapes for bytes\\nliterals.\\n\\nEven in a raw string, string quotes can be escaped with a backslash,\\nbut the backslash remains in the string; for example, ``r\"\\\\\"\"`` is a\\nvalid string literal consisting of two characters: a backslash and a\\ndouble quote; ``r\"\\\\\"`` is not a valid string literal (even a raw\\nstring cannot end in an odd number of backslashes).  Specifically, *a\\nraw string cannot end in a single backslash* (since the backslash\\nwould escape the following quote character).  Note also that a single\\nbackslash followed by a newline is interpreted as those two characters\\nas part of the string, *not* as a line continuation.\\n',\n'subscriptions': '\\nSubscriptions\\n*************\\n\\nA subscription selects an item of a sequence (string, tuple or list)\\nor mapping (dictionary) object:\\n\\n   subscription ::= primary \"[\" expression_list \"]\"\\n\\nThe primary must evaluate to an object that supports subscription,\\ne.g. a list or dictionary.  User-defined objects can support\\nsubscription by defining a ``__getitem__()`` method.\\n\\nFor built-in objects, there are two types of objects that support\\nsubscription:\\n\\nIf the primary is a mapping, the expression list must evaluate to an\\nobject whose value is one of the keys of the mapping, and the\\nsubscription selects the value in the mapping that corresponds to that\\nkey.  (The expression list is a tuple except if it has exactly one\\nitem.)\\n\\nIf the primary is a sequence, the expression (list) must evaluate to\\nan integer or a slice (as discussed in the following section).\\n\\nThe formal syntax makes no special provision for negative indices in\\nsequences; however, built-in sequences all provide a ``__getitem__()``\\nmethod that interprets negative indices by adding the length of the\\nsequence to the index (so that ``x[-1]`` selects the last item of\\n``x``).  The resulting value must be a nonnegative integer less than\\nthe number of items in the sequence, and the subscription selects the\\nitem whose index is that value (counting from zero). Since the support\\nfor negative indices and slicing occurs in the object\\'s\\n``__getitem__()`` method, subclasses overriding this method will need\\nto explicitly add that support.\\n\\nA string\\'s items are characters.  A character is not a separate data\\ntype but a string of exactly one character.\\n',\n'truth': \"\\nTruth Value Testing\\n*******************\\n\\nAny object can be tested for truth value, for use in an ``if`` or\\n``while`` condition or as operand of the Boolean operations below. The\\nfollowing values are considered false:\\n\\n* ``None``\\n\\n* ``False``\\n\\n* zero of any numeric type, for example, ``0``, ``0.0``, ``0j``.\\n\\n* any empty sequence, for example, ``''``, ``()``, ``[]``.\\n\\n* any empty mapping, for example, ``{}``.\\n\\n* instances of user-defined classes, if the class defines a\\n  ``__bool__()`` or ``__len__()`` method, when that method returns the\\n  integer zero or ``bool`` value ``False``. [1]\\n\\nAll other values are considered true --- so objects of many types are\\nalways true.\\n\\nOperations and built-in functions that have a Boolean result always\\nreturn ``0`` or ``False`` for false and ``1`` or ``True`` for true,\\nunless otherwise stated. (Important exception: the Boolean operations\\n``or`` and ``and`` always return one of their operands.)\\n\",\n'try': '\\nThe ``try`` statement\\n*********************\\n\\nThe ``try`` statement specifies exception handlers and/or cleanup code\\nfor a group of statements:\\n\\n   try_stmt  ::= try1_stmt | try2_stmt\\n   try1_stmt ::= \"try\" \":\" suite\\n                 (\"except\" [expression [\"as\" target]] \":\" suite)+\\n                 [\"else\" \":\" suite]\\n                 [\"finally\" \":\" suite]\\n   try2_stmt ::= \"try\" \":\" suite\\n                 \"finally\" \":\" suite\\n\\nThe ``except`` clause(s) specify one or more exception handlers. When\\nno exception occurs in the ``try`` clause, no exception handler is\\nexecuted. When an exception occurs in the ``try`` suite, a search for\\nan exception handler is started.  This search inspects the except\\nclauses in turn until one is found that matches the exception.  An\\nexpression-less except clause, if present, must be last; it matches\\nany exception.  For an except clause with an expression, that\\nexpression is evaluated, and the clause matches the exception if the\\nresulting object is \"compatible\" with the exception.  An object is\\ncompatible with an exception if it is the class or a base class of the\\nexception object or a tuple containing an item compatible with the\\nexception.\\n\\nIf no except clause matches the exception, the search for an exception\\nhandler continues in the surrounding code and on the invocation stack.\\n[1]\\n\\nIf the evaluation of an expression in the header of an except clause\\nraises an exception, the original search for a handler is canceled and\\na search starts for the new exception in the surrounding code and on\\nthe call stack (it is treated as if the entire ``try`` statement\\nraised the exception).\\n\\nWhen a matching except clause is found, the exception is assigned to\\nthe target specified after the ``as`` keyword in that except clause,\\nif present, and the except clause\\'s suite is executed.  All except\\nclauses must have an executable block.  When the end of this block is\\nreached, execution continues normally after the entire try statement.\\n(This means that if two nested handlers exist for the same exception,\\nand the exception occurs in the try clause of the inner handler, the\\nouter handler will not handle the exception.)\\n\\nWhen an exception has been assigned using ``as target``, it is cleared\\nat the end of the except clause.  This is as if\\n\\n   except E as N:\\n       foo\\n\\nwas translated to\\n\\n   except E as N:\\n       try:\\n           foo\\n       finally:\\n           del N\\n\\nThis means the exception must be assigned to a different name to be\\nable to refer to it after the except clause.  Exceptions are cleared\\nbecause with the traceback attached to them, they form a reference\\ncycle with the stack frame, keeping all locals in that frame alive\\nuntil the next garbage collection occurs.\\n\\nBefore an except clause\\'s suite is executed, details about the\\nexception are stored in the ``sys`` module and can be access via\\n``sys.exc_info()``. ``sys.exc_info()`` returns a 3-tuple consisting of\\nthe exception class, the exception instance and a traceback object\\n(see section *The standard type hierarchy*) identifying the point in\\nthe program where the exception occurred.  ``sys.exc_info()`` values\\nare restored to their previous values (before the call) when returning\\nfrom a function that handled an exception.\\n\\nThe optional ``else`` clause is executed if and when control flows off\\nthe end of the ``try`` clause. [2] Exceptions in the ``else`` clause\\nare not handled by the preceding ``except`` clauses.\\n\\nIf ``finally`` is present, it specifies a \\'cleanup\\' handler.  The\\n``try`` clause is executed, including any ``except`` and ``else``\\nclauses.  If an exception occurs in any of the clauses and is not\\nhandled, the exception is temporarily saved. The ``finally`` clause is\\nexecuted.  If there is a saved exception it is re-raised at the end of\\nthe ``finally`` clause.  If the ``finally`` clause raises another\\nexception, the saved exception is set as the context of the new\\nexception. If the ``finally`` clause executes a ``return`` or\\n``break`` statement, the saved exception is discarded:\\n\\n   def f():\\n       try:\\n           1/0\\n       finally:\\n           return 42\\n\\n   >>> f()\\n   42\\n\\nThe exception information is not available to the program during\\nexecution of the ``finally`` clause.\\n\\nWhen a ``return``, ``break`` or ``continue`` statement is executed in\\nthe ``try`` suite of a ``try``...``finally`` statement, the\\n``finally`` clause is also executed \\'on the way out.\\' A ``continue``\\nstatement is illegal in the ``finally`` clause. (The reason is a\\nproblem with the current implementation --- this restriction may be\\nlifted in the future).\\n\\nAdditional information on exceptions can be found in section\\n*Exceptions*, and information on using the ``raise`` statement to\\ngenerate exceptions may be found in section *The raise statement*.\\n',\n'types': '\\nThe standard type hierarchy\\n***************************\\n\\nBelow is a list of the types that are built into Python.  Extension\\nmodules (written in C, Java, or other languages, depending on the\\nimplementation) can define additional types.  Future versions of\\nPython may add types to the type hierarchy (e.g., rational numbers,\\nefficiently stored arrays of integers, etc.), although such additions\\nwill often be provided via the standard library instead.\\n\\nSome of the type descriptions below contain a paragraph listing\\n\\'special attributes.\\'  These are attributes that provide access to the\\nimplementation and are not intended for general use.  Their definition\\nmay change in the future.\\n\\nNone\\n   This type has a single value.  There is a single object with this\\n   value. This object is accessed through the built-in name ``None``.\\n   It is used to signify the absence of a value in many situations,\\n   e.g., it is returned from functions that don\\'t explicitly return\\n   anything. Its truth value is false.\\n\\nNotImplemented\\n   This type has a single value.  There is a single object with this\\n   value. This object is accessed through the built-in name\\n   ``NotImplemented``. Numeric methods and rich comparison methods may\\n   return this value if they do not implement the operation for the\\n   operands provided.  (The interpreter will then try the reflected\\n   operation, or some other fallback, depending on the operator.)  Its\\n   truth value is true.\\n\\nEllipsis\\n   This type has a single value.  There is a single object with this\\n   value. This object is accessed through the literal ``...`` or the\\n   built-in name ``Ellipsis``.  Its truth value is true.\\n\\n``numbers.Number``\\n   These are created by numeric literals and returned as results by\\n   arithmetic operators and arithmetic built-in functions.  Numeric\\n   objects are immutable; once created their value never changes.\\n   Python numbers are of course strongly related to mathematical\\n   numbers, but subject to the limitations of numerical representation\\n   in computers.\\n\\n   Python distinguishes between integers, floating point numbers, and\\n   complex numbers:\\n\\n   ``numbers.Integral``\\n      These represent elements from the mathematical set of integers\\n      (positive and negative).\\n\\n      There are two types of integers:\\n\\n      Integers (``int``)\\n\\n         These represent numbers in an unlimited range, subject to\\n         available (virtual) memory only.  For the purpose of shift\\n         and mask operations, a binary representation is assumed, and\\n         negative numbers are represented in a variant of 2\\'s\\n         complement which gives the illusion of an infinite string of\\n         sign bits extending to the left.\\n\\n      Booleans (``bool``)\\n         These represent the truth values False and True.  The two\\n         objects representing the values False and True are the only\\n         Boolean objects. The Boolean type is a subtype of the integer\\n         type, and Boolean values behave like the values 0 and 1,\\n         respectively, in almost all contexts, the exception being\\n         that when converted to a string, the strings ``\"False\"`` or\\n         ``\"True\"`` are returned, respectively.\\n\\n      The rules for integer representation are intended to give the\\n      most meaningful interpretation of shift and mask operations\\n      involving negative integers.\\n\\n   ``numbers.Real`` (``float``)\\n      These represent machine-level double precision floating point\\n      numbers. You are at the mercy of the underlying machine\\n      architecture (and C or Java implementation) for the accepted\\n      range and handling of overflow. Python does not support single-\\n      precision floating point numbers; the savings in processor and\\n      memory usage that are usually the reason for using these is\\n      dwarfed by the overhead of using objects in Python, so there is\\n      no reason to complicate the language with two kinds of floating\\n      point numbers.\\n\\n   ``numbers.Complex`` (``complex``)\\n      These represent complex numbers as a pair of machine-level\\n      double precision floating point numbers.  The same caveats apply\\n      as for floating point numbers. The real and imaginary parts of a\\n      complex number ``z`` can be retrieved through the read-only\\n      attributes ``z.real`` and ``z.imag``.\\n\\nSequences\\n   These represent finite ordered sets indexed by non-negative\\n   numbers. The built-in function ``len()`` returns the number of\\n   items of a sequence. When the length of a sequence is *n*, the\\n   index set contains the numbers 0, 1, ..., *n*-1.  Item *i* of\\n   sequence *a* is selected by ``a[i]``.\\n\\n   Sequences also support slicing: ``a[i:j]`` selects all items with\\n   index *k* such that *i* ``<=`` *k* ``<`` *j*.  When used as an\\n   expression, a slice is a sequence of the same type.  This implies\\n   that the index set is renumbered so that it starts at 0.\\n\\n   Some sequences also support \"extended slicing\" with a third \"step\"\\n   parameter: ``a[i:j:k]`` selects all items of *a* with index *x*\\n   where ``x = i + n*k``, *n* ``>=`` ``0`` and *i* ``<=`` *x* ``<``\\n   *j*.\\n\\n   Sequences are distinguished according to their mutability:\\n\\n   Immutable sequences\\n      An object of an immutable sequence type cannot change once it is\\n      created.  (If the object contains references to other objects,\\n      these other objects may be mutable and may be changed; however,\\n      the collection of objects directly referenced by an immutable\\n      object cannot change.)\\n\\n      The following types are immutable sequences:\\n\\n      Strings\\n         A string is a sequence of values that represent Unicode\\n         codepoints. All the codepoints in range ``U+0000 - U+10FFFF``\\n         can be represented in a string.  Python doesn\\'t have a\\n         ``chr`` type, and every character in the string is\\n         represented as a string object with length ``1``.  The built-\\n         in function ``ord()`` converts a character to its codepoint\\n         (as an integer); ``chr()`` converts an integer in range ``0 -\\n         10FFFF`` to the corresponding character. ``str.encode()`` can\\n         be used to convert a ``str`` to ``bytes`` using the given\\n         encoding, and ``bytes.decode()`` can be used to achieve the\\n         opposite.\\n\\n      Tuples\\n         The items of a tuple are arbitrary Python objects. Tuples of\\n         two or more items are formed by comma-separated lists of\\n         expressions.  A tuple of one item (a \\'singleton\\') can be\\n         formed by affixing a comma to an expression (an expression by\\n         itself does not create a tuple, since parentheses must be\\n         usable for grouping of expressions).  An empty tuple can be\\n         formed by an empty pair of parentheses.\\n\\n      Bytes\\n         A bytes object is an immutable array.  The items are 8-bit\\n         bytes, represented by integers in the range 0 <= x < 256.\\n         Bytes literals (like ``b\\'abc\\'``) and the built-in function\\n         ``bytes()`` can be used to construct bytes objects.  Also,\\n         bytes objects can be decoded to strings via the ``decode()``\\n         method.\\n\\n   Mutable sequences\\n      Mutable sequences can be changed after they are created.  The\\n      subscription and slicing notations can be used as the target of\\n      assignment and ``del`` (delete) statements.\\n\\n      There are currently two intrinsic mutable sequence types:\\n\\n      Lists\\n         The items of a list are arbitrary Python objects.  Lists are\\n         formed by placing a comma-separated list of expressions in\\n         square brackets. (Note that there are no special cases needed\\n         to form lists of length 0 or 1.)\\n\\n      Byte Arrays\\n         A bytearray object is a mutable array. They are created by\\n         the built-in ``bytearray()`` constructor.  Aside from being\\n         mutable (and hence unhashable), byte arrays otherwise provide\\n         the same interface and functionality as immutable bytes\\n         objects.\\n\\n      The extension module ``array`` provides an additional example of\\n      a mutable sequence type, as does the ``collections`` module.\\n\\nSet types\\n   These represent unordered, finite sets of unique, immutable\\n   objects. As such, they cannot be indexed by any subscript. However,\\n   they can be iterated over, and the built-in function ``len()``\\n   returns the number of items in a set. Common uses for sets are fast\\n   membership testing, removing duplicates from a sequence, and\\n   computing mathematical operations such as intersection, union,\\n   difference, and symmetric difference.\\n\\n   For set elements, the same immutability rules apply as for\\n   dictionary keys. Note that numeric types obey the normal rules for\\n   numeric comparison: if two numbers compare equal (e.g., ``1`` and\\n   ``1.0``), only one of them can be contained in a set.\\n\\n   There are currently two intrinsic set types:\\n\\n   Sets\\n      These represent a mutable set. They are created by the built-in\\n      ``set()`` constructor and can be modified afterwards by several\\n      methods, such as ``add()``.\\n\\n   Frozen sets\\n      These represent an immutable set.  They are created by the\\n      built-in ``frozenset()`` constructor.  As a frozenset is\\n      immutable and *hashable*, it can be used again as an element of\\n      another set, or as a dictionary key.\\n\\nMappings\\n   These represent finite sets of objects indexed by arbitrary index\\n   sets. The subscript notation ``a[k]`` selects the item indexed by\\n   ``k`` from the mapping ``a``; this can be used in expressions and\\n   as the target of assignments or ``del`` statements. The built-in\\n   function ``len()`` returns the number of items in a mapping.\\n\\n   There is currently a single intrinsic mapping type:\\n\\n   Dictionaries\\n      These represent finite sets of objects indexed by nearly\\n      arbitrary values.  The only types of values not acceptable as\\n      keys are values containing lists or dictionaries or other\\n      mutable types that are compared by value rather than by object\\n      identity, the reason being that the efficient implementation of\\n      dictionaries requires a key\\'s hash value to remain constant.\\n      Numeric types used for keys obey the normal rules for numeric\\n      comparison: if two numbers compare equal (e.g., ``1`` and\\n      ``1.0``) then they can be used interchangeably to index the same\\n      dictionary entry.\\n\\n      Dictionaries are mutable; they can be created by the ``{...}``\\n      notation (see section *Dictionary displays*).\\n\\n      The extension modules ``dbm.ndbm`` and ``dbm.gnu`` provide\\n      additional examples of mapping types, as does the\\n      ``collections`` module.\\n\\nCallable types\\n   These are the types to which the function call operation (see\\n   section *Calls*) can be applied:\\n\\n   User-defined functions\\n      A user-defined function object is created by a function\\n      definition (see section *Function definitions*).  It should be\\n      called with an argument list containing the same number of items\\n      as the function\\'s formal parameter list.\\n\\n      Special attributes:\\n\\n      +---------------------------+---------------------------------+-------------+\\n      | Attribute                 | Meaning                         |             |\\n      +===========================+=================================+=============+\\n      | ``__doc__``               | The function\\'s documentation    | Writable    |\\n      |                           | string, or ``None`` if          |             |\\n      |                           | unavailable                     |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__name__``              | The function\\'s name             | Writable    |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__qualname__``          | The function\\'s *qualified name* | Writable    |\\n      |                           | New in version 3.3.             |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__module__``            | The name of the module the      | Writable    |\\n      |                           | function was defined in, or     |             |\\n      |                           | ``None`` if unavailable.        |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__defaults__``          | A tuple containing default      | Writable    |\\n      |                           | argument values for those       |             |\\n      |                           | arguments that have defaults,   |             |\\n      |                           | or ``None`` if no arguments     |             |\\n      |                           | have a default value            |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__code__``              | The code object representing    | Writable    |\\n      |                           | the compiled function body.     |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__globals__``           | A reference to the dictionary   | Read-only   |\\n      |                           | that holds the function\\'s       |             |\\n      |                           | global variables --- the global |             |\\n      |                           | namespace of the module in      |             |\\n      |                           | which the function was defined. |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__dict__``              | The namespace supporting        | Writable    |\\n      |                           | arbitrary function attributes.  |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__closure__``           | ``None`` or a tuple of cells    | Read-only   |\\n      |                           | that contain bindings for the   |             |\\n      |                           | function\\'s free variables.      |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__annotations__``       | A dict containing annotations   | Writable    |\\n      |                           | of parameters.  The keys of the |             |\\n      |                           | dict are the parameter names,   |             |\\n      |                           | or ``\\'return\\'`` for the return  |             |\\n      |                           | annotation, if provided.        |             |\\n      +---------------------------+---------------------------------+-------------+\\n      | ``__kwdefaults__``        | A dict containing defaults for  | Writable    |\\n      |                           | keyword-only parameters.        |             |\\n      +---------------------------+---------------------------------+-------------+\\n\\n      Most of the attributes labelled \"Writable\" check the type of the\\n      assigned value.\\n\\n      Function objects also support getting and setting arbitrary\\n      attributes, which can be used, for example, to attach metadata\\n      to functions.  Regular attribute dot-notation is used to get and\\n      set such attributes. *Note that the current implementation only\\n      supports function attributes on user-defined functions. Function\\n      attributes on built-in functions may be supported in the\\n      future.*\\n\\n      Additional information about a function\\'s definition can be\\n      retrieved from its code object; see the description of internal\\n      types below.\\n\\n   Instance methods\\n      An instance method object combines a class, a class instance and\\n      any callable object (normally a user-defined function).\\n\\n      Special read-only attributes: ``__self__`` is the class instance\\n      object, ``__func__`` is the function object; ``__doc__`` is the\\n      method\\'s documentation (same as ``__func__.__doc__``);\\n      ``__name__`` is the method name (same as ``__func__.__name__``);\\n      ``__module__`` is the name of the module the method was defined\\n      in, or ``None`` if unavailable.\\n\\n      Methods also support accessing (but not setting) the arbitrary\\n      function attributes on the underlying function object.\\n\\n      User-defined method objects may be created when getting an\\n      attribute of a class (perhaps via an instance of that class), if\\n      that attribute is a user-defined function object or a class\\n      method object.\\n\\n      When an instance method object is created by retrieving a user-\\n      defined function object from a class via one of its instances,\\n      its ``__self__`` attribute is the instance, and the method\\n      object is said to be bound.  The new method\\'s ``__func__``\\n      attribute is the original function object.\\n\\n      When a user-defined method object is created by retrieving\\n      another method object from a class or instance, the behaviour is\\n      the same as for a function object, except that the ``__func__``\\n      attribute of the new instance is not the original method object\\n      but its ``__func__`` attribute.\\n\\n      When an instance method object is created by retrieving a class\\n      method object from a class or instance, its ``__self__``\\n      attribute is the class itself, and its ``__func__`` attribute is\\n      the function object underlying the class method.\\n\\n      When an instance method object is called, the underlying\\n      function (``__func__``) is called, inserting the class instance\\n      (``__self__``) in front of the argument list.  For instance,\\n      when ``C`` is a class which contains a definition for a function\\n      ``f()``, and ``x`` is an instance of ``C``, calling ``x.f(1)``\\n      is equivalent to calling ``C.f(x, 1)``.\\n\\n      When an instance method object is derived from a class method\\n      object, the \"class instance\" stored in ``__self__`` will\\n      actually be the class itself, so that calling either ``x.f(1)``\\n      or ``C.f(1)`` is equivalent to calling ``f(C,1)`` where ``f`` is\\n      the underlying function.\\n\\n      Note that the transformation from function object to instance\\n      method object happens each time the attribute is retrieved from\\n      the instance.  In some cases, a fruitful optimization is to\\n      assign the attribute to a local variable and call that local\\n      variable. Also notice that this transformation only happens for\\n      user-defined functions; other callable objects (and all non-\\n      callable objects) are retrieved without transformation.  It is\\n      also important to note that user-defined functions which are\\n      attributes of a class instance are not converted to bound\\n      methods; this *only* happens when the function is an attribute\\n      of the class.\\n\\n   Generator functions\\n      A function or method which uses the ``yield`` statement (see\\n      section *The yield statement*) is called a *generator function*.\\n      Such a function, when called, always returns an iterator object\\n      which can be used to execute the body of the function:  calling\\n      the iterator\\'s ``iterator__next__()`` method will cause the\\n      function to execute until it provides a value using the\\n      ``yield`` statement.  When the function executes a ``return``\\n      statement or falls off the end, a ``StopIteration`` exception is\\n      raised and the iterator will have reached the end of the set of\\n      values to be returned.\\n\\n   Built-in functions\\n      A built-in function object is a wrapper around a C function.\\n      Examples of built-in functions are ``len()`` and ``math.sin()``\\n      (``math`` is a standard built-in module). The number and type of\\n      the arguments are determined by the C function. Special read-\\n      only attributes: ``__doc__`` is the function\\'s documentation\\n      string, or ``None`` if unavailable; ``__name__`` is the\\n      function\\'s name; ``__self__`` is set to ``None`` (but see the\\n      next item); ``__module__`` is the name of the module the\\n      function was defined in or ``None`` if unavailable.\\n\\n   Built-in methods\\n      This is really a different disguise of a built-in function, this\\n      time containing an object passed to the C function as an\\n      implicit extra argument.  An example of a built-in method is\\n      ``alist.append()``, assuming *alist* is a list object. In this\\n      case, the special read-only attribute ``__self__`` is set to the\\n      object denoted by *alist*.\\n\\n   Classes\\n      Classes are callable.  These objects normally act as factories\\n      for new instances of themselves, but variations are possible for\\n      class types that override ``__new__()``.  The arguments of the\\n      call are passed to ``__new__()`` and, in the typical case, to\\n      ``__init__()`` to initialize the new instance.\\n\\n   Class Instances\\n      Instances of arbitrary classes can be made callable by defining\\n      a ``__call__()`` method in their class.\\n\\nModules\\n   Modules are a basic organizational unit of Python code, and are\\n   created by the *import system* as invoked either by the ``import``\\n   statement (see ``import``), or by calling functions such as\\n   ``importlib.import_module()`` and built-in ``__import__()``.  A\\n   module object has a namespace implemented by a dictionary object\\n   (this is the dictionary referenced by the ``__globals__`` attribute\\n   of functions defined in the module).  Attribute references are\\n   translated to lookups in this dictionary, e.g., ``m.x`` is\\n   equivalent to ``m.__dict__[\"x\"]``. A module object does not contain\\n   the code object used to initialize the module (since it isn\\'t\\n   needed once the initialization is done).\\n\\n   Attribute assignment updates the module\\'s namespace dictionary,\\n   e.g., ``m.x = 1`` is equivalent to ``m.__dict__[\"x\"] = 1``.\\n\\n   Special read-only attribute: ``__dict__`` is the module\\'s namespace\\n   as a dictionary object.\\n\\n   **CPython implementation detail:** Because of the way CPython\\n   clears module dictionaries, the module dictionary will be cleared\\n   when the module falls out of scope even if the dictionary still has\\n   live references.  To avoid this, copy the dictionary or keep the\\n   module around while using its dictionary directly.\\n\\n   Predefined (writable) attributes: ``__name__`` is the module\\'s\\n   name; ``__doc__`` is the module\\'s documentation string, or ``None``\\n   if unavailable; ``__file__`` is the pathname of the file from which\\n   the module was loaded, if it was loaded from a file. The\\n   ``__file__`` attribute may be missing for certain types of modules,\\n   such as C modules that are statically linked into the interpreter;\\n   for extension modules loaded dynamically from a shared library, it\\n   is the pathname of the shared library file.\\n\\nCustom classes\\n   Custom class types are typically created by class definitions (see\\n   section *Class definitions*).  A class has a namespace implemented\\n   by a dictionary object. Class attribute references are translated\\n   to lookups in this dictionary, e.g., ``C.x`` is translated to\\n   ``C.__dict__[\"x\"]`` (although there are a number of hooks which\\n   allow for other means of locating attributes). When the attribute\\n   name is not found there, the attribute search continues in the base\\n   classes. This search of the base classes uses the C3 method\\n   resolution order which behaves correctly even in the presence of\\n   \\'diamond\\' inheritance structures where there are multiple\\n   inheritance paths leading back to a common ancestor. Additional\\n   details on the C3 MRO used by Python can be found in the\\n   documentation accompanying the 2.3 release at\\n   http://www.python.org/download/releases/2.3/mro/.\\n\\n   When a class attribute reference (for class ``C``, say) would yield\\n   a class method object, it is transformed into an instance method\\n   object whose ``__self__`` attributes is ``C``.  When it would yield\\n   a static method object, it is transformed into the object wrapped\\n   by the static method object. See section *Implementing Descriptors*\\n   for another way in which attributes retrieved from a class may\\n   differ from those actually contained in its ``__dict__``.\\n\\n   Class attribute assignments update the class\\'s dictionary, never\\n   the dictionary of a base class.\\n\\n   A class object can be called (see above) to yield a class instance\\n   (see below).\\n\\n   Special attributes: ``__name__`` is the class name; ``__module__``\\n   is the module name in which the class was defined; ``__dict__`` is\\n   the dictionary containing the class\\'s namespace; ``__bases__`` is a\\n   tuple (possibly empty or a singleton) containing the base classes,\\n   in the order of their occurrence in the base class list;\\n   ``__doc__`` is the class\\'s documentation string, or None if\\n   undefined.\\n\\nClass instances\\n   A class instance is created by calling a class object (see above).\\n   A class instance has a namespace implemented as a dictionary which\\n   is the first place in which attribute references are searched.\\n   When an attribute is not found there, and the instance\\'s class has\\n   an attribute by that name, the search continues with the class\\n   attributes.  If a class attribute is found that is a user-defined\\n   function object, it is transformed into an instance method object\\n   whose ``__self__`` attribute is the instance.  Static method and\\n   class method objects are also transformed; see above under\\n   \"Classes\".  See section *Implementing Descriptors* for another way\\n   in which attributes of a class retrieved via its instances may\\n   differ from the objects actually stored in the class\\'s\\n   ``__dict__``.  If no class attribute is found, and the object\\'s\\n   class has a ``__getattr__()`` method, that is called to satisfy the\\n   lookup.\\n\\n   Attribute assignments and deletions update the instance\\'s\\n   dictionary, never a class\\'s dictionary.  If the class has a\\n   ``__setattr__()`` or ``__delattr__()`` method, this is called\\n   instead of updating the instance dictionary directly.\\n\\n   Class instances can pretend to be numbers, sequences, or mappings\\n   if they have methods with certain special names.  See section\\n   *Special method names*.\\n\\n   Special attributes: ``__dict__`` is the attribute dictionary;\\n   ``__class__`` is the instance\\'s class.\\n\\nI/O objects (also known as file objects)\\n   A *file object* represents an open file.  Various shortcuts are\\n   available to create file objects: the ``open()`` built-in function,\\n   and also ``os.popen()``, ``os.fdopen()``, and the ``makefile()``\\n   method of socket objects (and perhaps by other functions or methods\\n   provided by extension modules).\\n\\n   The objects ``sys.stdin``, ``sys.stdout`` and ``sys.stderr`` are\\n   initialized to file objects corresponding to the interpreter\\'s\\n   standard input, output and error streams; they are all open in text\\n   mode and therefore follow the interface defined by the\\n   ``io.TextIOBase`` abstract class.\\n\\nInternal types\\n   A few types used internally by the interpreter are exposed to the\\n   user. Their definitions may change with future versions of the\\n   interpreter, but they are mentioned here for completeness.\\n\\n   Code objects\\n      Code objects represent *byte-compiled* executable Python code,\\n      or *bytecode*. The difference between a code object and a\\n      function object is that the function object contains an explicit\\n      reference to the function\\'s globals (the module in which it was\\n      defined), while a code object contains no context; also the\\n      default argument values are stored in the function object, not\\n      in the code object (because they represent values calculated at\\n      run-time).  Unlike function objects, code objects are immutable\\n      and contain no references (directly or indirectly) to mutable\\n      objects.\\n\\n      Special read-only attributes: ``co_name`` gives the function\\n      name; ``co_argcount`` is the number of positional arguments\\n      (including arguments with default values); ``co_nlocals`` is the\\n      number of local variables used by the function (including\\n      arguments); ``co_varnames`` is a tuple containing the names of\\n      the local variables (starting with the argument names);\\n      ``co_cellvars`` is a tuple containing the names of local\\n      variables that are referenced by nested functions;\\n      ``co_freevars`` is a tuple containing the names of free\\n      variables; ``co_code`` is a string representing the sequence of\\n      bytecode instructions; ``co_consts`` is a tuple containing the\\n      literals used by the bytecode; ``co_names`` is a tuple\\n      containing the names used by the bytecode; ``co_filename`` is\\n      the filename from which the code was compiled;\\n      ``co_firstlineno`` is the first line number of the function;\\n      ``co_lnotab`` is a string encoding the mapping from bytecode\\n      offsets to line numbers (for details see the source code of the\\n      interpreter); ``co_stacksize`` is the required stack size\\n      (including local variables); ``co_flags`` is an integer encoding\\n      a number of flags for the interpreter.\\n\\n      The following flag bits are defined for ``co_flags``: bit\\n      ``0x04`` is set if the function uses the ``*arguments`` syntax\\n      to accept an arbitrary number of positional arguments; bit\\n      ``0x08`` is set if the function uses the ``**keywords`` syntax\\n      to accept arbitrary keyword arguments; bit ``0x20`` is set if\\n      the function is a generator.\\n\\n      Future feature declarations (``from __future__ import\\n      division``) also use bits in ``co_flags`` to indicate whether a\\n      code object was compiled with a particular feature enabled: bit\\n      ``0x2000`` is set if the function was compiled with future\\n      division enabled; bits ``0x10`` and ``0x1000`` were used in\\n      earlier versions of Python.\\n\\n      Other bits in ``co_flags`` are reserved for internal use.\\n\\n      If a code object represents a function, the first item in\\n      ``co_consts`` is the documentation string of the function, or\\n      ``None`` if undefined.\\n\\n   Frame objects\\n      Frame objects represent execution frames.  They may occur in\\n      traceback objects (see below).\\n\\n      Special read-only attributes: ``f_back`` is to the previous\\n      stack frame (towards the caller), or ``None`` if this is the\\n      bottom stack frame; ``f_code`` is the code object being executed\\n      in this frame; ``f_locals`` is the dictionary used to look up\\n      local variables; ``f_globals`` is used for global variables;\\n      ``f_builtins`` is used for built-in (intrinsic) names;\\n      ``f_lasti`` gives the precise instruction (this is an index into\\n      the bytecode string of the code object).\\n\\n      Special writable attributes: ``f_trace``, if not ``None``, is a\\n      function called at the start of each source code line (this is\\n      used by the debugger); ``f_lineno`` is the current line number\\n      of the frame --- writing to this from within a trace function\\n      jumps to the given line (only for the bottom-most frame).  A\\n      debugger can implement a Jump command (aka Set Next Statement)\\n      by writing to f_lineno.\\n\\n   Traceback objects\\n      Traceback objects represent a stack trace of an exception.  A\\n      traceback object is created when an exception occurs.  When the\\n      search for an exception handler unwinds the execution stack, at\\n      each unwound level a traceback object is inserted in front of\\n      the current traceback.  When an exception handler is entered,\\n      the stack trace is made available to the program. (See section\\n      *The try statement*.) It is accessible as the third item of the\\n      tuple returned by ``sys.exc_info()``. When the program contains\\n      no suitable handler, the stack trace is written (nicely\\n      formatted) to the standard error stream; if the interpreter is\\n      interactive, it is also made available to the user as\\n      ``sys.last_traceback``.\\n\\n      Special read-only attributes: ``tb_next`` is the next level in\\n      the stack trace (towards the frame where the exception\\n      occurred), or ``None`` if there is no next level; ``tb_frame``\\n      points to the execution frame of the current level;\\n      ``tb_lineno`` gives the line number where the exception\\n      occurred; ``tb_lasti`` indicates the precise instruction.  The\\n      line number and last instruction in the traceback may differ\\n      from the line number of its frame object if the exception\\n      occurred in a ``try`` statement with no matching except clause\\n      or with a finally clause.\\n\\n   Slice objects\\n      Slice objects are used to represent slices for ``__getitem__()``\\n      methods.  They are also created by the built-in ``slice()``\\n      function.\\n\\n      Special read-only attributes: ``start`` is the lower bound;\\n      ``stop`` is the upper bound; ``step`` is the step value; each is\\n      ``None`` if omitted. These attributes can have any type.\\n\\n      Slice objects support one method:\\n\\n      slice.indices(self, length)\\n\\n         This method takes a single integer argument *length* and\\n         computes information about the slice that the slice object\\n         would describe if applied to a sequence of *length* items.\\n         It returns a tuple of three integers; respectively these are\\n         the *start* and *stop* indices and the *step* or stride\\n         length of the slice. Missing or out-of-bounds indices are\\n         handled in a manner consistent with regular slices.\\n\\n   Static method objects\\n      Static method objects provide a way of defeating the\\n      transformation of function objects to method objects described\\n      above. A static method object is a wrapper around any other\\n      object, usually a user-defined method object. When a static\\n      method object is retrieved from a class or a class instance, the\\n      object actually returned is the wrapped object, which is not\\n      subject to any further transformation. Static method objects are\\n      not themselves callable, although the objects they wrap usually\\n      are. Static method objects are created by the built-in\\n      ``staticmethod()`` constructor.\\n\\n   Class method objects\\n      A class method object, like a static method object, is a wrapper\\n      around another object that alters the way in which that object\\n      is retrieved from classes and class instances. The behaviour of\\n      class method objects upon such retrieval is described above,\\n      under \"User-defined methods\". Class method objects are created\\n      by the built-in ``classmethod()`` constructor.\\n',\n'typesfunctions': '\\nFunctions\\n*********\\n\\nFunction objects are created by function definitions.  The only\\noperation on a function object is to call it: ``func(argument-list)``.\\n\\nThere are really two flavors of function objects: built-in functions\\nand user-defined functions.  Both support the same operation (to call\\nthe function), but the implementation is different, hence the\\ndifferent object types.\\n\\nSee *Function definitions* for more information.\\n',\n'typesmapping': '\\nMapping Types --- ``dict``\\n**************************\\n\\nA *mapping* object maps *hashable* values to arbitrary objects.\\nMappings are mutable objects.  There is currently only one standard\\nmapping type, the *dictionary*.  (For other containers see the built-\\nin ``list``, ``set``, and ``tuple`` classes, and the ``collections``\\nmodule.)\\n\\nA dictionary\\'s keys are *almost* arbitrary values.  Values that are\\nnot *hashable*, that is, values containing lists, dictionaries or\\nother mutable types (that are compared by value rather than by object\\nidentity) may not be used as keys.  Numeric types used for keys obey\\nthe normal rules for numeric comparison: if two numbers compare equal\\n(such as ``1`` and ``1.0``) then they can be used interchangeably to\\nindex the same dictionary entry.  (Note however, that since computers\\nstore floating-point numbers as approximations it is usually unwise to\\nuse them as dictionary keys.)\\n\\nDictionaries can be created by placing a comma-separated list of\\n``key: value`` pairs within braces, for example: ``{\\'jack\\': 4098,\\n\\'sjoerd\\': 4127}`` or ``{4098: \\'jack\\', 4127: \\'sjoerd\\'}``, or by the\\n``dict`` constructor.\\n\\nclass class dict(**kwarg)\\nclass class dict(mapping, **kwarg)\\nclass class dict(iterable, **kwarg)\\n\\n   Return a new dictionary initialized from an optional positional\\n   argument and a possibly empty set of keyword arguments.\\n\\n   If no positional argument is given, an empty dictionary is created.\\n   If a positional argument is given and it is a mapping object, a\\n   dictionary is created with the same key-value pairs as the mapping\\n   object.  Otherwise, the positional argument must be an *iterator*\\n   object.  Each item in the iterable must itself be an iterator with\\n   exactly two objects.  The first object of each item becomes a key\\n   in the new dictionary, and the second object the corresponding\\n   value.  If a key occurs more than once, the last value for that key\\n   becomes the corresponding value in the new dictionary.\\n\\n   If keyword arguments are given, the keyword arguments and their\\n   values are added to the dictionary created from the positional\\n   argument.  If a key being added is already present, the value from\\n   the keyword argument replaces the value from the positional\\n   argument.\\n\\n   To illustrate, the following examples all return a dictionary equal\\n   to ``{\"one\": 1, \"two\": 2, \"three\": 3}``:\\n\\n      >>> a = dict(one=1, two=2, three=3)\\n      >>> b = {\\'one\\': 1, \\'two\\': 2, \\'three\\': 3}\\n      >>> c = dict(zip([\\'one\\', \\'two\\', \\'three\\'], [1, 2, 3]))\\n      >>> d = dict([(\\'two\\', 2), (\\'one\\', 1), (\\'three\\', 3)])\\n      >>> e = dict({\\'three\\': 3, \\'one\\': 1, \\'two\\': 2})\\n      >>> a == b == c == d == e\\n      True\\n\\n   Providing keyword arguments as in the first example only works for\\n   keys that are valid Python identifiers.  Otherwise, any valid keys\\n   can be used.\\n\\n   These are the operations that dictionaries support (and therefore,\\n   custom mapping types should support too):\\n\\n   len(d)\\n\\n      Return the number of items in the dictionary *d*.\\n\\n   d[key]\\n\\n      Return the item of *d* with key *key*.  Raises a ``KeyError`` if\\n      *key* is not in the map.\\n\\n      If a subclass of dict defines a method ``__missing__()``, if the\\n      key *key* is not present, the ``d[key]`` operation calls that\\n      method with the key *key* as argument.  The ``d[key]`` operation\\n      then returns or raises whatever is returned or raised by the\\n      ``__missing__(key)`` call if the key is not present. No other\\n      operations or methods invoke ``__missing__()``. If\\n      ``__missing__()`` is not defined, ``KeyError`` is raised.\\n      ``__missing__()`` must be a method; it cannot be an instance\\n      variable:\\n\\n         >>> class Counter(dict):\\n         ...     def __missing__(self, key):\\n         ...         return 0\\n         >>> c = Counter()\\n         >>> c[\\'red\\']\\n         0\\n         >>> c[\\'red\\'] += 1\\n         >>> c[\\'red\\']\\n         1\\n\\n      See ``collections.Counter`` for a complete implementation\\n      including other methods helpful for accumulating and managing\\n      tallies.\\n\\n   d[key] = value\\n\\n      Set ``d[key]`` to *value*.\\n\\n   del d[key]\\n\\n      Remove ``d[key]`` from *d*.  Raises a ``KeyError`` if *key* is\\n      not in the map.\\n\\n   key in d\\n\\n      Return ``True`` if *d* has a key *key*, else ``False``.\\n\\n   key not in d\\n\\n      Equivalent to ``not key in d``.\\n\\n   iter(d)\\n\\n      Return an iterator over the keys of the dictionary.  This is a\\n      shortcut for ``iter(d.keys())``.\\n\\n   clear()\\n\\n      Remove all items from the dictionary.\\n\\n   copy()\\n\\n      Return a shallow copy of the dictionary.\\n\\n   classmethod fromkeys(seq[, value])\\n\\n      Create a new dictionary with keys from *seq* and values set to\\n      *value*.\\n\\n      ``fromkeys()`` is a class method that returns a new dictionary.\\n      *value* defaults to ``None``.\\n\\n   get(key[, default])\\n\\n      Return the value for *key* if *key* is in the dictionary, else\\n      *default*. If *default* is not given, it defaults to ``None``,\\n      so that this method never raises a ``KeyError``.\\n\\n   items()\\n\\n      Return a new view of the dictionary\\'s items (``(key, value)``\\n      pairs). See the *documentation of view objects*.\\n\\n   keys()\\n\\n      Return a new view of the dictionary\\'s keys.  See the\\n      *documentation of view objects*.\\n\\n   pop(key[, default])\\n\\n      If *key* is in the dictionary, remove it and return its value,\\n      else return *default*.  If *default* is not given and *key* is\\n      not in the dictionary, a ``KeyError`` is raised.\\n\\n   popitem()\\n\\n      Remove and return an arbitrary ``(key, value)`` pair from the\\n      dictionary.\\n\\n      ``popitem()`` is useful to destructively iterate over a\\n      dictionary, as often used in set algorithms.  If the dictionary\\n      is empty, calling ``popitem()`` raises a ``KeyError``.\\n\\n   setdefault(key[, default])\\n\\n      If *key* is in the dictionary, return its value.  If not, insert\\n      *key* with a value of *default* and return *default*.  *default*\\n      defaults to ``None``.\\n\\n   update([other])\\n\\n      Update the dictionary with the key/value pairs from *other*,\\n      overwriting existing keys.  Return ``None``.\\n\\n      ``update()`` accepts either another dictionary object or an\\n      iterable of key/value pairs (as tuples or other iterables of\\n      length two).  If keyword arguments are specified, the dictionary\\n      is then updated with those key/value pairs: ``d.update(red=1,\\n      blue=2)``.\\n\\n   values()\\n\\n      Return a new view of the dictionary\\'s values.  See the\\n      *documentation of view objects*.\\n\\nSee also:\\n\\n   ``types.MappingProxyType`` can be used to create a read-only view\\n   of a ``dict``.\\n\\n\\nDictionary view objects\\n=======================\\n\\nThe objects returned by ``dict.keys()``, ``dict.values()`` and\\n``dict.items()`` are *view objects*.  They provide a dynamic view on\\nthe dictionary\\'s entries, which means that when the dictionary\\nchanges, the view reflects these changes.\\n\\nDictionary views can be iterated over to yield their respective data,\\nand support membership tests:\\n\\nlen(dictview)\\n\\n   Return the number of entries in the dictionary.\\n\\niter(dictview)\\n\\n   Return an iterator over the keys, values or items (represented as\\n   tuples of ``(key, value)``) in the dictionary.\\n\\n   Keys and values are iterated over in an arbitrary order which is\\n   non-random, varies across Python implementations, and depends on\\n   the dictionary\\'s history of insertions and deletions. If keys,\\n   values and items views are iterated over with no intervening\\n   modifications to the dictionary, the order of items will directly\\n   correspond.  This allows the creation of ``(value, key)`` pairs\\n   using ``zip()``: ``pairs = zip(d.values(), d.keys())``.  Another\\n   way to create the same list is ``pairs = [(v, k) for (k, v) in\\n   d.items()]``.\\n\\n   Iterating views while adding or deleting entries in the dictionary\\n   may raise a ``RuntimeError`` or fail to iterate over all entries.\\n\\nx in dictview\\n\\n   Return ``True`` if *x* is in the underlying dictionary\\'s keys,\\n   values or items (in the latter case, *x* should be a ``(key,\\n   value)`` tuple).\\n\\nKeys views are set-like since their entries are unique and hashable.\\nIf all values are hashable, so that ``(key, value)`` pairs are unique\\nand hashable, then the items view is also set-like.  (Values views are\\nnot treated as set-like since the entries are generally not unique.)\\nFor set-like views, all of the operations defined for the abstract\\nbase class ``collections.abc.Set`` are available (for example, ``==``,\\n``<``, or ``^``).\\n\\nAn example of dictionary view usage:\\n\\n   >>> dishes = {\\'eggs\\': 2, \\'sausage\\': 1, \\'bacon\\': 1, \\'spam\\': 500}\\n   >>> keys = dishes.keys()\\n   >>> values = dishes.values()\\n\\n   >>> # iteration\\n   >>> n = 0\\n   >>> for val in values:\\n   ...     n += val\\n   >>> print(n)\\n   504\\n\\n   >>> # keys and values are iterated over in the same order\\n   >>> list(keys)\\n   [\\'eggs\\', \\'bacon\\', \\'sausage\\', \\'spam\\']\\n   >>> list(values)\\n   [2, 1, 1, 500]\\n\\n   >>> # view objects are dynamic and reflect dict changes\\n   >>> del dishes[\\'eggs\\']\\n   >>> del dishes[\\'sausage\\']\\n   >>> list(keys)\\n   [\\'spam\\', \\'bacon\\']\\n\\n   >>> # set operations\\n   >>> keys & {\\'eggs\\', \\'bacon\\', \\'salad\\'}\\n   {\\'bacon\\'}\\n   >>> keys ^ {\\'sausage\\', \\'juice\\'}\\n   {\\'juice\\', \\'sausage\\', \\'bacon\\', \\'spam\\'}\\n',\n'typesmethods': '\\nMethods\\n*******\\n\\nMethods are functions that are called using the attribute notation.\\nThere are two flavors: built-in methods (such as ``append()`` on\\nlists) and class instance methods.  Built-in methods are described\\nwith the types that support them.\\n\\nIf you access a method (a function defined in a class namespace)\\nthrough an instance, you get a special object: a *bound method* (also\\ncalled *instance method*) object. When called, it will add the\\n``self`` argument to the argument list.  Bound methods have two\\nspecial read-only attributes: ``m.__self__`` is the object on which\\nthe method operates, and ``m.__func__`` is the function implementing\\nthe method.  Calling ``m(arg-1, arg-2, ..., arg-n)`` is completely\\nequivalent to calling ``m.__func__(m.__self__, arg-1, arg-2, ...,\\narg-n)``.\\n\\nLike function objects, bound method objects support getting arbitrary\\nattributes.  However, since method attributes are actually stored on\\nthe underlying function object (``meth.__func__``), setting method\\nattributes on bound methods is disallowed.  Attempting to set an\\nattribute on a method results in an ``AttributeError`` being raised.\\nIn order to set a method attribute, you need to explicitly set it on\\nthe underlying function object:\\n\\n   >>> class C:\\n   ...     def method(self):\\n   ...         pass\\n   ...\\n   >>> c = C()\\n   >>> c.method.whoami = \\'my name is method\\'  # can\\'t set on the method\\n   Traceback (most recent call last):\\n     File \"<stdin>\", line 1, in <module>\\n   AttributeError: \\'method\\' object has no attribute \\'whoami\\'\\n   >>> c.method.__func__.whoami = \\'my name is method\\'\\n   >>> c.method.whoami\\n   \\'my name is method\\'\\n\\nSee *The standard type hierarchy* for more information.\\n',\n'typesmodules': \"\\nModules\\n*******\\n\\nThe only special operation on a module is attribute access:\\n``m.name``, where *m* is a module and *name* accesses a name defined\\nin *m*'s symbol table. Module attributes can be assigned to.  (Note\\nthat the ``import`` statement is not, strictly speaking, an operation\\non a module object; ``import foo`` does not require a module object\\nnamed *foo* to exist, rather it requires an (external) *definition*\\nfor a module named *foo* somewhere.)\\n\\nA special attribute of every module is ``__dict__``. This is the\\ndictionary containing the module's symbol table. Modifying this\\ndictionary will actually change the module's symbol table, but direct\\nassignment to the ``__dict__`` attribute is not possible (you can\\nwrite ``m.__dict__['a'] = 1``, which defines ``m.a`` to be ``1``, but\\nyou can't write ``m.__dict__ = {}``).  Modifying ``__dict__`` directly\\nis not recommended.\\n\\nModules built into the interpreter are written like this: ``<module\\n'sys' (built-in)>``.  If loaded from a file, they are written as\\n``<module 'os' from '/usr/local/lib/pythonX.Y/os.pyc'>``.\\n\",\n'typesseq': '\\nSequence Types --- ``list``, ``tuple``, ``range``\\n*************************************************\\n\\nThere are three basic sequence types: lists, tuples, and range\\nobjects. Additional sequence types tailored for processing of *binary\\ndata* and *text strings* are described in dedicated sections.\\n\\n\\nCommon Sequence Operations\\n==========================\\n\\nThe operations in the following table are supported by most sequence\\ntypes, both mutable and immutable. The ``collections.abc.Sequence``\\nABC is provided to make it easier to correctly implement these\\noperations on custom sequence types.\\n\\nThis table lists the sequence operations sorted in ascending priority\\n(operations in the same box have the same priority).  In the table,\\n*s* and *t* are sequences of the same type, *n*, *i*, *j* and *k* are\\nintegers and *x* is an arbitrary object that meets any type and value\\nrestrictions imposed by *s*.\\n\\nThe ``in`` and ``not in`` operations have the same priorities as the\\ncomparison operations. The ``+`` (concatenation) and ``*``\\n(repetition) operations have the same priority as the corresponding\\nnumeric operations.\\n\\n+----------------------------+----------------------------------+------------+\\n| Operation                  | Result                           | Notes      |\\n+============================+==================================+============+\\n| ``x in s``                 | ``True`` if an item of *s* is    | (1)        |\\n|                            | equal to *x*, else ``False``     |            |\\n+----------------------------+----------------------------------+------------+\\n| ``x not in s``             | ``False`` if an item of *s* is   | (1)        |\\n|                            | equal to *x*, else ``True``      |            |\\n+----------------------------+----------------------------------+------------+\\n| ``s + t``                  | the concatenation of *s* and *t* | (6)(7)     |\\n+----------------------------+----------------------------------+------------+\\n| ``s * n`` or ``n * s``     | *n* shallow copies of *s*        | (2)(7)     |\\n|                            | concatenated                     |            |\\n+----------------------------+----------------------------------+------------+\\n| ``s[i]``                   | *i*th item of *s*, origin 0      | (3)        |\\n+----------------------------+----------------------------------+------------+\\n| ``s[i:j]``                 | slice of *s* from *i* to *j*     | (3)(4)     |\\n+----------------------------+----------------------------------+------------+\\n| ``s[i:j:k]``               | slice of *s* from *i* to *j*     | (3)(5)     |\\n|                            | with step *k*                    |            |\\n+----------------------------+----------------------------------+------------+\\n| ``len(s)``                 | length of *s*                    |            |\\n+----------------------------+----------------------------------+------------+\\n| ``min(s)``                 | smallest item of *s*             |            |\\n+----------------------------+----------------------------------+------------+\\n| ``max(s)``                 | largest item of *s*              |            |\\n+----------------------------+----------------------------------+------------+\\n| ``s.index(x[, i[, j]])``   | index of the first occurence of  | (8)        |\\n|                            | *x* in *s* (at or after index    |            |\\n|                            | *i* and before index *j*)        |            |\\n+----------------------------+----------------------------------+------------+\\n| ``s.count(x)``             | total number of occurences of    |            |\\n|                            | *x* in *s*                       |            |\\n+----------------------------+----------------------------------+------------+\\n\\nSequences of the same type also support comparisons.  In particular,\\ntuples and lists are compared lexicographically by comparing\\ncorresponding elements. This means that to compare equal, every\\nelement must compare equal and the two sequences must be of the same\\ntype and have the same length.  (For full details see *Comparisons* in\\nthe language reference.)\\n\\nNotes:\\n\\n1. While the ``in`` and ``not in`` operations are used only for simple\\n   containment testing in the general case, some specialised sequences\\n   (such as ``str``, ``bytes`` and ``bytearray``) also use them for\\n   subsequence testing:\\n\\n      >>> \"gg\" in \"eggs\"\\n      True\\n\\n2. Values of *n* less than ``0`` are treated as ``0`` (which yields an\\n   empty sequence of the same type as *s*).  Note also that the copies\\n   are shallow; nested structures are not copied.  This often haunts\\n   new Python programmers; consider:\\n\\n      >>> lists = [[]] * 3\\n      >>> lists\\n      [[], [], []]\\n      >>> lists[0].append(3)\\n      >>> lists\\n      [[3], [3], [3]]\\n\\n   What has happened is that ``[[]]`` is a one-element list containing\\n   an empty list, so all three elements of ``[[]] * 3`` are (pointers\\n   to) this single empty list.  Modifying any of the elements of\\n   ``lists`` modifies this single list. You can create a list of\\n   different lists this way:\\n\\n      >>> lists = [[] for i in range(3)]\\n      >>> lists[0].append(3)\\n      >>> lists[1].append(5)\\n      >>> lists[2].append(7)\\n      >>> lists\\n      [[3], [5], [7]]\\n\\n3. If *i* or *j* is negative, the index is relative to the end of the\\n   string: ``len(s) + i`` or ``len(s) + j`` is substituted.  But note\\n   that ``-0`` is still ``0``.\\n\\n4. The slice of *s* from *i* to *j* is defined as the sequence of\\n   items with index *k* such that ``i <= k < j``.  If *i* or *j* is\\n   greater than ``len(s)``, use ``len(s)``.  If *i* is omitted or\\n   ``None``, use ``0``.  If *j* is omitted or ``None``, use\\n   ``len(s)``.  If *i* is greater than or equal to *j*, the slice is\\n   empty.\\n\\n5. The slice of *s* from *i* to *j* with step *k* is defined as the\\n   sequence of items with index  ``x = i + n*k`` such that ``0 <= n <\\n   (j-i)/k``.  In other words, the indices are ``i``, ``i+k``,\\n   ``i+2*k``, ``i+3*k`` and so on, stopping when *j* is reached (but\\n   never including *j*).  If *i* or *j* is greater than ``len(s)``,\\n   use ``len(s)``.  If *i* or *j* are omitted or ``None``, they become\\n   \"end\" values (which end depends on the sign of *k*).  Note, *k*\\n   cannot be zero. If *k* is ``None``, it is treated like ``1``.\\n\\n6. Concatenating immutable sequences always results in a new object.\\n   This means that building up a sequence by repeated concatenation\\n   will have a quadratic runtime cost in the total sequence length.\\n   To get a linear runtime cost, you must switch to one of the\\n   alternatives below:\\n\\n   * if concatenating ``str`` objects, you can build a list and use\\n     ``str.join()`` at the end or else write to a ``io.StringIO``\\n     instance and retrieve its value when complete\\n\\n   * if concatenating ``bytes`` objects, you can similarly use\\n     ``bytes.join()`` or ``io.BytesIO``, or you can do in-place\\n     concatenation with a ``bytearray`` object.  ``bytearray`` objects\\n     are mutable and have an efficient overallocation mechanism\\n\\n   * if concatenating ``tuple`` objects, extend a ``list`` instead\\n\\n   * for other types, investigate the relevant class documentation\\n\\n7. Some sequence types (such as ``range``) only support item sequences\\n   that follow specific patterns, and hence don\\'t support sequence\\n   concatenation or repetition.\\n\\n8. ``index`` raises ``ValueError`` when *x* is not found in *s*. When\\n   supported, the additional arguments to the index method allow\\n   efficient searching of subsections of the sequence. Passing the\\n   extra arguments is roughly equivalent to using ``s[i:j].index(x)``,\\n   only without copying any data and with the returned index being\\n   relative to the start of the sequence rather than the start of the\\n   slice.\\n\\n\\nImmutable Sequence Types\\n========================\\n\\nThe only operation that immutable sequence types generally implement\\nthat is not also implemented by mutable sequence types is support for\\nthe ``hash()`` built-in.\\n\\nThis support allows immutable sequences, such as ``tuple`` instances,\\nto be used as ``dict`` keys and stored in ``set`` and ``frozenset``\\ninstances.\\n\\nAttempting to hash an immutable sequence that contains unhashable\\nvalues will result in ``TypeError``.\\n\\n\\nMutable Sequence Types\\n======================\\n\\nThe operations in the following table are defined on mutable sequence\\ntypes. The ``collections.abc.MutableSequence`` ABC is provided to make\\nit easier to correctly implement these operations on custom sequence\\ntypes.\\n\\nIn the table *s* is an instance of a mutable sequence type, *t* is any\\niterable object and *x* is an arbitrary object that meets any type and\\nvalue restrictions imposed by *s* (for example, ``bytearray`` only\\naccepts integers that meet the value restriction ``0 <= x <= 255``).\\n\\n+--------------------------------+----------------------------------+-----------------------+\\n| Operation                      | Result                           | Notes                 |\\n+================================+==================================+=======================+\\n| ``s[i] = x``                   | item *i* of *s* is replaced by   |                       |\\n|                                | *x*                              |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s[i:j] = t``                 | slice of *s* from *i* to *j* is  |                       |\\n|                                | replaced by the contents of the  |                       |\\n|                                | iterable *t*                     |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``del s[i:j]``                 | same as ``s[i:j] = []``          |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s[i:j:k] = t``               | the elements of ``s[i:j:k]`` are | (1)                   |\\n|                                | replaced by those of *t*         |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``del s[i:j:k]``               | removes the elements of          |                       |\\n|                                | ``s[i:j:k]`` from the list       |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.append(x)``                | appends *x* to the end of the    |                       |\\n|                                | sequence (same as                |                       |\\n|                                | ``s[len(s):len(s)] = [x]``)      |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.clear()``                  | removes all items from ``s``     | (5)                   |\\n|                                | (same as ``del s[:]``)           |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.copy()``                   | creates a shallow copy of ``s``  | (5)                   |\\n|                                | (same as ``s[:]``)               |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.extend(t)``                | extends *s* with the contents of |                       |\\n|                                | *t* (same as ``s[len(s):len(s)]  |                       |\\n|                                | = t``)                           |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.insert(i, x)``             | inserts *x* into *s* at the      |                       |\\n|                                | index given by *i* (same as      |                       |\\n|                                | ``s[i:i] = [x]``)                |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.pop([i])``                 | retrieves the item at *i* and    | (2)                   |\\n|                                | also removes it from *s*         |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.remove(x)``                | remove the first item from *s*   | (3)                   |\\n|                                | where ``s[i] == x``              |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.reverse()``                | reverses the items of *s* in     | (4)                   |\\n|                                | place                            |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n\\nNotes:\\n\\n1. *t* must have the same length as the slice it is replacing.\\n\\n2. The optional argument *i* defaults to ``-1``, so that by default\\n   the last item is removed and returned.\\n\\n3. ``remove`` raises ``ValueError`` when *x* is not found in *s*.\\n\\n4. The ``reverse()`` method modifies the sequence in place for economy\\n   of space when reversing a large sequence.  To remind users that it\\n   operates by side effect, it does not return the reversed sequence.\\n\\n5. ``clear()`` and ``copy()`` are included for consistency with the\\n   interfaces of mutable containers that don\\'t support slicing\\n   operations (such as ``dict`` and ``set``)\\n\\n   New in version 3.3: ``clear()`` and ``copy()`` methods.\\n\\n\\nLists\\n=====\\n\\nLists are mutable sequences, typically used to store collections of\\nhomogeneous items (where the precise degree of similarity will vary by\\napplication).\\n\\nclass class list([iterable])\\n\\n   Lists may be constructed in several ways:\\n\\n   * Using a pair of square brackets to denote the empty list: ``[]``\\n\\n   * Using square brackets, separating items with commas: ``[a]``,\\n     ``[a, b, c]``\\n\\n   * Using a list comprehension: ``[x for x in iterable]``\\n\\n   * Using the type constructor: ``list()`` or ``list(iterable)``\\n\\n   The constructor builds a list whose items are the same and in the\\n   same order as *iterable*\\'s items.  *iterable* may be either a\\n   sequence, a container that supports iteration, or an iterator\\n   object.  If *iterable* is already a list, a copy is made and\\n   returned, similar to ``iterable[:]``. For example, ``list(\\'abc\\')``\\n   returns ``[\\'a\\', \\'b\\', \\'c\\']`` and ``list( (1, 2, 3) )`` returns ``[1,\\n   2, 3]``. If no argument is given, the constructor creates a new\\n   empty list, ``[]``.\\n\\n   Many other operations also produce lists, including the\\n   ``sorted()`` built-in.\\n\\n   Lists implement all of the *common* and *mutable* sequence\\n   operations. Lists also provide the following additional method:\\n\\n   sort(*, key=None, reverse=None)\\n\\n      This method sorts the list in place, using only ``<``\\n      comparisons between items. Exceptions are not suppressed - if\\n      any comparison operations fail, the entire sort operation will\\n      fail (and the list will likely be left in a partially modified\\n      state).\\n\\n      *key* specifies a function of one argument that is used to\\n      extract a comparison key from each list element (for example,\\n      ``key=str.lower``). The key corresponding to each item in the\\n      list is calculated once and then used for the entire sorting\\n      process. The default value of ``None`` means that list items are\\n      sorted directly without calculating a separate key value.\\n\\n      The ``functools.cmp_to_key()`` utility is available to convert a\\n      2.x style *cmp* function to a *key* function.\\n\\n      *reverse* is a boolean value.  If set to ``True``, then the list\\n      elements are sorted as if each comparison were reversed.\\n\\n      This method modifies the sequence in place for economy of space\\n      when sorting a large sequence.  To remind users that it operates\\n      by side effect, it does not return the sorted sequence (use\\n      ``sorted()`` to explicitly request a new sorted list instance).\\n\\n      The ``sort()`` method is guaranteed to be stable.  A sort is\\n      stable if it guarantees not to change the relative order of\\n      elements that compare equal --- this is helpful for sorting in\\n      multiple passes (for example, sort by department, then by salary\\n      grade).\\n\\n      **CPython implementation detail:** While a list is being sorted,\\n      the effect of attempting to mutate, or even inspect, the list is\\n      undefined.  The C implementation of Python makes the list appear\\n      empty for the duration, and raises ``ValueError`` if it can\\n      detect that the list has been mutated during a sort.\\n\\n\\nTuples\\n======\\n\\nTuples are immutable sequences, typically used to store collections of\\nheterogeneous data (such as the 2-tuples produced by the\\n``enumerate()`` built-in). Tuples are also used for cases where an\\nimmutable sequence of homogeneous data is needed (such as allowing\\nstorage in a ``set`` or ``dict`` instance).\\n\\nclass class tuple([iterable])\\n\\n   Tuples may be constructed in a number of ways:\\n\\n   * Using a pair of parentheses to denote the empty tuple: ``()``\\n\\n   * Using a trailing comma for a singleton tuple: ``a,`` or ``(a,)``\\n\\n   * Separating items with commas: ``a, b, c`` or ``(a, b, c)``\\n\\n   * Using the ``tuple()`` built-in: ``tuple()`` or\\n     ``tuple(iterable)``\\n\\n   The constructor builds a tuple whose items are the same and in the\\n   same order as *iterable*\\'s items.  *iterable* may be either a\\n   sequence, a container that supports iteration, or an iterator\\n   object.  If *iterable* is already a tuple, it is returned\\n   unchanged. For example, ``tuple(\\'abc\\')`` returns ``(\\'a\\', \\'b\\',\\n   \\'c\\')`` and ``tuple( [1, 2, 3] )`` returns ``(1, 2, 3)``. If no\\n   argument is given, the constructor creates a new empty tuple,\\n   ``()``.\\n\\n   Note that it is actually the comma which makes a tuple, not the\\n   parentheses. The parentheses are optional, except in the empty\\n   tuple case, or when they are needed to avoid syntactic ambiguity.\\n   For example, ``f(a, b, c)`` is a function call with three\\n   arguments, while ``f((a, b, c))`` is a function call with a 3-tuple\\n   as the sole argument.\\n\\n   Tuples implement all of the *common* sequence operations.\\n\\nFor heterogeneous collections of data where access by name is clearer\\nthan access by index, ``collections.namedtuple()`` may be a more\\nappropriate choice than a simple tuple object.\\n\\n\\nRanges\\n======\\n\\nThe ``range`` type represents an immutable sequence of numbers and is\\ncommonly used for looping a specific number of times in ``for`` loops.\\n\\nclass class range(stop)\\nclass class range(start, stop[, step])\\n\\n   The arguments to the range constructor must be integers (either\\n   built-in ``int`` or any object that implements the ``__index__``\\n   special method).  If the *step* argument is omitted, it defaults to\\n   ``1``. If the *start* argument is omitted, it defaults to ``0``. If\\n   *step* is zero, ``ValueError`` is raised.\\n\\n   For a positive *step*, the contents of a range ``r`` are determined\\n   by the formula ``r[i] = start + step*i`` where ``i >= 0`` and\\n   ``r[i] < stop``.\\n\\n   For a negative *step*, the contents of the range are still\\n   determined by the formula ``r[i] = start + step*i``, but the\\n   constraints are ``i >= 0`` and ``r[i] > stop``.\\n\\n   A range object will be empty if ``r[0]`` does not meet the value\\n   constraint. Ranges do support negative indices, but these are\\n   interpreted as indexing from the end of the sequence determined by\\n   the positive indices.\\n\\n   Ranges containing absolute values larger than ``sys.maxsize`` are\\n   permitted but some features (such as ``len()``) may raise\\n   ``OverflowError``.\\n\\n   Range examples:\\n\\n      >>> list(range(10))\\n      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\\n      >>> list(range(1, 11))\\n      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\\n      >>> list(range(0, 30, 5))\\n      [0, 5, 10, 15, 20, 25]\\n      >>> list(range(0, 10, 3))\\n      [0, 3, 6, 9]\\n      >>> list(range(0, -10, -1))\\n      [0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\\n      >>> list(range(0))\\n      []\\n      >>> list(range(1, 0))\\n      []\\n\\n   Ranges implement all of the *common* sequence operations except\\n   concatenation and repetition (due to the fact that range objects\\n   can only represent sequences that follow a strict pattern and\\n   repetition and concatenation will usually violate that pattern).\\n\\nThe advantage of the ``range`` type over a regular ``list`` or\\n``tuple`` is that a ``range`` object will always take the same (small)\\namount of memory, no matter the size of the range it represents (as it\\nonly stores the ``start``, ``stop`` and ``step`` values, calculating\\nindividual items and subranges as needed).\\n\\nRange objects implement the ``collections.Sequence`` ABC, and provide\\nfeatures such as containment tests, element index lookup, slicing and\\nsupport for negative indices (see *Sequence Types --- list, tuple,\\nrange*):\\n\\n>>> r = range(0, 20, 2)\\n>>> r\\nrange(0, 20, 2)\\n>>> 11 in r\\nFalse\\n>>> 10 in r\\nTrue\\n>>> r.index(10)\\n5\\n>>> r[5]\\n10\\n>>> r[:5]\\nrange(0, 10, 2)\\n>>> r[-1]\\n18\\n\\nTesting range objects for equality with ``==`` and ``!=`` compares\\nthem as sequences.  That is, two range objects are considered equal if\\nthey represent the same sequence of values.  (Note that two range\\nobjects that compare equal might have different ``start``, ``stop``\\nand ``step`` attributes, for example ``range(0) == range(2, 1, 3)`` or\\n``range(0, 3, 2) == range(0, 4, 2)``.)\\n\\nChanged in version 3.2: Implement the Sequence ABC. Support slicing\\nand negative indices. Test ``int`` objects for membership in constant\\ntime instead of iterating through all items.\\n\\nChanged in version 3.3: Define \\'==\\' and \\'!=\\' to compare range objects\\nbased on the sequence of values they define (instead of comparing\\nbased on object identity).\\n\\nNew in version 3.3: The ``start``, ``stop`` and ``step`` attributes.\\n',\n'typesseq-mutable': \"\\nMutable Sequence Types\\n**********************\\n\\nThe operations in the following table are defined on mutable sequence\\ntypes. The ``collections.abc.MutableSequence`` ABC is provided to make\\nit easier to correctly implement these operations on custom sequence\\ntypes.\\n\\nIn the table *s* is an instance of a mutable sequence type, *t* is any\\niterable object and *x* is an arbitrary object that meets any type and\\nvalue restrictions imposed by *s* (for example, ``bytearray`` only\\naccepts integers that meet the value restriction ``0 <= x <= 255``).\\n\\n+--------------------------------+----------------------------------+-----------------------+\\n| Operation                      | Result                           | Notes                 |\\n+================================+==================================+=======================+\\n| ``s[i] = x``                   | item *i* of *s* is replaced by   |                       |\\n|                                | *x*                              |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s[i:j] = t``                 | slice of *s* from *i* to *j* is  |                       |\\n|                                | replaced by the contents of the  |                       |\\n|                                | iterable *t*                     |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``del s[i:j]``                 | same as ``s[i:j] = []``          |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s[i:j:k] = t``               | the elements of ``s[i:j:k]`` are | (1)                   |\\n|                                | replaced by those of *t*         |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``del s[i:j:k]``               | removes the elements of          |                       |\\n|                                | ``s[i:j:k]`` from the list       |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.append(x)``                | appends *x* to the end of the    |                       |\\n|                                | sequence (same as                |                       |\\n|                                | ``s[len(s):len(s)] = [x]``)      |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.clear()``                  | removes all items from ``s``     | (5)                   |\\n|                                | (same as ``del s[:]``)           |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.copy()``                   | creates a shallow copy of ``s``  | (5)                   |\\n|                                | (same as ``s[:]``)               |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.extend(t)``                | extends *s* with the contents of |                       |\\n|                                | *t* (same as ``s[len(s):len(s)]  |                       |\\n|                                | = t``)                           |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.insert(i, x)``             | inserts *x* into *s* at the      |                       |\\n|                                | index given by *i* (same as      |                       |\\n|                                | ``s[i:i] = [x]``)                |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.pop([i])``                 | retrieves the item at *i* and    | (2)                   |\\n|                                | also removes it from *s*         |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.remove(x)``                | remove the first item from *s*   | (3)                   |\\n|                                | where ``s[i] == x``              |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n| ``s.reverse()``                | reverses the items of *s* in     | (4)                   |\\n|                                | place                            |                       |\\n+--------------------------------+----------------------------------+-----------------------+\\n\\nNotes:\\n\\n1. *t* must have the same length as the slice it is replacing.\\n\\n2. The optional argument *i* defaults to ``-1``, so that by default\\n   the last item is removed and returned.\\n\\n3. ``remove`` raises ``ValueError`` when *x* is not found in *s*.\\n\\n4. The ``reverse()`` method modifies the sequence in place for economy\\n   of space when reversing a large sequence.  To remind users that it\\n   operates by side effect, it does not return the reversed sequence.\\n\\n5. ``clear()`` and ``copy()`` are included for consistency with the\\n   interfaces of mutable containers that don't support slicing\\n   operations (such as ``dict`` and ``set``)\\n\\n   New in version 3.3: ``clear()`` and ``copy()`` methods.\\n\",\n'unary': '\\nUnary arithmetic and bitwise operations\\n***************************************\\n\\nAll unary arithmetic and bitwise operations have the same priority:\\n\\n   u_expr ::= power | \"-\" u_expr | \"+\" u_expr | \"~\" u_expr\\n\\nThe unary ``-`` (minus) operator yields the negation of its numeric\\nargument.\\n\\nThe unary ``+`` (plus) operator yields its numeric argument unchanged.\\n\\nThe unary ``~`` (invert) operator yields the bitwise inversion of its\\ninteger argument.  The bitwise inversion of ``x`` is defined as\\n``-(x+1)``.  It only applies to integral numbers.\\n\\nIn all three cases, if the argument does not have the proper type, a\\n``TypeError`` exception is raised.\\n',\n'while': '\\nThe ``while`` statement\\n***********************\\n\\nThe ``while`` statement is used for repeated execution as long as an\\nexpression is true:\\n\\n   while_stmt ::= \"while\" expression \":\" suite\\n                  [\"else\" \":\" suite]\\n\\nThis repeatedly tests the expression and, if it is true, executes the\\nfirst suite; if the expression is false (which may be the first time\\nit is tested) the suite of the ``else`` clause, if present, is\\nexecuted and the loop terminates.\\n\\nA ``break`` statement executed in the first suite terminates the loop\\nwithout executing the ``else`` clause\\'s suite.  A ``continue``\\nstatement executed in the first suite skips the rest of the suite and\\ngoes back to testing the expression.\\n',\n'with': '\\nThe ``with`` statement\\n**********************\\n\\nThe ``with`` statement is used to wrap the execution of a block with\\nmethods defined by a context manager (see section *With Statement\\nContext Managers*). This allows common\\n``try``...``except``...``finally`` usage patterns to be encapsulated\\nfor convenient reuse.\\n\\n   with_stmt ::= \"with\" with_item (\",\" with_item)* \":\" suite\\n   with_item ::= expression [\"as\" target]\\n\\nThe execution of the ``with`` statement with one \"item\" proceeds as\\nfollows:\\n\\n1. The context expression (the expression given in the ``with_item``)\\n   is evaluated to obtain a context manager.\\n\\n2. The context manager\\'s ``__exit__()`` is loaded for later use.\\n\\n3. The context manager\\'s ``__enter__()`` method is invoked.\\n\\n4. If a target was included in the ``with`` statement, the return\\n   value from ``__enter__()`` is assigned to it.\\n\\n   Note: The ``with`` statement guarantees that if the ``__enter__()``\\n     method returns without an error, then ``__exit__()`` will always\\n     be called. Thus, if an error occurs during the assignment to the\\n     target list, it will be treated the same as an error occurring\\n     within the suite would be. See step 6 below.\\n\\n5. The suite is executed.\\n\\n6. The context manager\\'s ``__exit__()`` method is invoked.  If an\\n   exception caused the suite to be exited, its type, value, and\\n   traceback are passed as arguments to ``__exit__()``. Otherwise,\\n   three ``None`` arguments are supplied.\\n\\n   If the suite was exited due to an exception, and the return value\\n   from the ``__exit__()`` method was false, the exception is\\n   reraised.  If the return value was true, the exception is\\n   suppressed, and execution continues with the statement following\\n   the ``with`` statement.\\n\\n   If the suite was exited for any reason other than an exception, the\\n   return value from ``__exit__()`` is ignored, and execution proceeds\\n   at the normal location for the kind of exit that was taken.\\n\\nWith more than one item, the context managers are processed as if\\nmultiple ``with`` statements were nested:\\n\\n   with A() as a, B() as b:\\n       suite\\n\\nis equivalent to\\n\\n   with A() as a:\\n       with B() as b:\\n           suite\\n\\nChanged in version 3.1: Support for multiple context expressions.\\n\\nSee also:\\n\\n   **PEP 0343** - The \"with\" statement\\n      The specification, background, and examples for the Python\\n      ``with`` statement.\\n',\n'yield': '\\nThe ``yield`` statement\\n***********************\\n\\n   yield_stmt ::= yield_expression\\n\\nThe ``yield`` statement is only used when defining a generator\\nfunction, and is only used in the body of the generator function.\\nUsing a ``yield`` statement in a function definition is sufficient to\\ncause that definition to create a generator function instead of a\\nnormal function.\\n\\nWhen a generator function is called, it returns an iterator known as a\\ngenerator iterator, or more commonly, a generator.  The body of the\\ngenerator function is executed by calling the ``next()`` function on\\nthe generator repeatedly until it raises an exception.\\n\\nWhen a ``yield`` statement is executed, the state of the generator is\\nfrozen and the value of ``expression_list`` is returned to\\n``next()``\\'s caller.  By \"frozen\" we mean that all local state is\\nretained, including the current bindings of local variables, the\\ninstruction pointer, and the internal evaluation stack: enough\\ninformation is saved so that the next time ``next()`` is invoked, the\\nfunction can proceed exactly as if the ``yield`` statement were just\\nanother external call.\\n\\nThe ``yield`` statement is allowed in the ``try`` clause of a ``try``\\n...  ``finally`` construct.  If the generator is not resumed before it\\nis finalized (by reaching a zero reference count or by being garbage\\ncollected), the generator-iterator\\'s ``close()`` method will be\\ncalled, allowing any pending ``finally`` clauses to execute.\\n\\nWhen ``yield from <expr>`` is used, it treats the supplied expression\\nas a subiterator, producing values from it until the underlying\\niterator is exhausted.\\n\\n   Changed in version 3.3: Added ``yield from <expr>`` to delegate\\n   control flow to a subiterator\\n\\nFor full details of ``yield`` semantics, refer to the *Yield\\nexpressions* section.\\n\\nSee also:\\n\\n   **PEP 0255** - Simple Generators\\n      The proposal for adding generators and the ``yield`` statement\\n      to Python.\\n\\n   **PEP 0342** - Coroutines via Enhanced Generators\\n      The proposal to enhance the API and syntax of generators, making\\n      them usable as simple coroutines.\\n\\n   **PEP 0380** - Syntax for Delegating to a Subgenerator\\n      The proposal to introduce the ``yield_from`` syntax, making\\n      delegation to sub-generators easy.\\n'}\n"], "shutil": [".py", "\"\"\n\nimport os\nimport sys\nimport stat\nfrom os.path import abspath\nimport fnmatch\nimport collections\nimport errno\nimport tarfile\n\ntry:\n import bz2\n del bz2\n _BZ2_SUPPORTED = True\nexcept ImportError:\n _BZ2_SUPPORTED = False\n \ntry:\n from pwd import getpwnam\nexcept ImportError:\n getpwnam = None\n \ntry:\n from grp import getgrnam\nexcept ImportError:\n getgrnam = None\n \n__all__ = [\"copyfileobj\", \"copyfile\", \"copymode\", \"copystat\", \"copy\", \"copy2\",\n\"copytree\", \"move\", \"rmtree\", \"Error\", \"SpecialFileError\",\n\"ExecError\", \"make_archive\", \"get_archive_formats\",\n\"register_archive_format\", \"unregister_archive_format\",\n\"get_unpack_formats\", \"register_unpack_format\",\n\"unregister_unpack_format\", \"unpack_archive\",\n\"ignore_patterns\", \"chown\", \"which\"]\n\n\nclass Error(EnvironmentError):\n pass\n \nclass SpecialFileError(EnvironmentError):\n \"\"\n \nclass ExecError(EnvironmentError):\n \"\"\n \nclass ReadError(EnvironmentError):\n \"\"\n \nclass RegistryError(Exception):\n \"\"\n \n \ntry:\n WindowsError\nexcept NameError:\n WindowsError = None\n \ndef copyfileobj(fsrc, fdst, length=16*1024):\n \"\"\n while 1:\n  buf = fsrc.read(length)\n  if not buf:\n   break\n  fdst.write(buf)\n  \ndef _samefile(src, dst):\n\n if hasattr(os.path, 'samefile'):\n  try:\n   return os.path.samefile(src, dst)\n  except OSError:\n   return False\n   \n   \n return (os.path.normcase(os.path.abspath(src)) ==\n os.path.normcase(os.path.abspath(dst)))\n \ndef copyfile(src, dst, *, follow_symlinks=True):\n \"\"\n if _samefile(src, dst):\n  raise Error(\"`%s` and `%s` are the same file\" % (src, dst))\n  \n for fn in [src, dst]:\n  try:\n   st = os.stat(fn)\n  except OSError:\n  \n   pass\n  else:\n  \n   if stat.S_ISFIFO(st.st_mode):\n    raise SpecialFileError(\"`%s` is a named pipe\" % fn)\n    \n if not follow_symlinks and os.path.islink(src):\n  os.symlink(os.readlink(src), dst)\n else:\n  with open(src, 'rb') as fsrc:\n   with open(dst, 'wb') as fdst:\n    copyfileobj(fsrc, fdst)\n return dst\n \ndef copymode(src, dst, *, follow_symlinks=True):\n \"\"\n if not follow_symlinks and os.path.islink(src) and os.path.islink(dst):\n  if hasattr(os, 'lchmod'):\n   stat_func, chmod_func = os.lstat, os.lchmod\n  else:\n   return\n elif hasattr(os, 'chmod'):\n  stat_func, chmod_func = os.stat, os.chmod\n else:\n  return\n  \n st = stat_func(src)\n chmod_func(dst, stat.S_IMODE(st.st_mode))\n \nif hasattr(os, 'listxattr'):\n def _copyxattr(src, dst, *, follow_symlinks=True):\n  \"\"\n  \n  try:\n   names = os.listxattr(src, follow_symlinks=follow_symlinks)\n  except OSError as e:\n   if e.errno not in (errno.ENOTSUP, errno.ENODATA):\n    raise\n   return\n  for name in names:\n   try:\n    value = os.getxattr(src, name, follow_symlinks=follow_symlinks)\n    os.setxattr(dst, name, value, follow_symlinks=follow_symlinks)\n   except OSError as e:\n    if e.errno not in (errno.EPERM, errno.ENOTSUP, errno.ENODATA):\n     raise\nelse:\n def _copyxattr(*args, **kwargs):\n  pass\n  \ndef copystat(src, dst, *, follow_symlinks=True):\n \"\"\n def _nop(*args, ns=None, follow_symlinks=None):\n  pass\n  \n  \n follow = follow_symlinks or not (os.path.islink(src) and os.path.islink(dst))\n if follow:\n \n  def lookup(name):\n   return getattr(os, name, _nop)\n else:\n \n \n  def lookup(name):\n   fn = getattr(os, name, _nop)\n   if fn in os.supports_follow_symlinks:\n    return fn\n   return _nop\n   \n st = lookup(\"stat\")(src, follow_symlinks=follow)\n mode = stat.S_IMODE(st.st_mode)\n lookup(\"utime\")(dst, ns=(st.st_atime_ns, st.st_mtime_ns),\n follow_symlinks=follow)\n try:\n  lookup(\"chmod\")(dst, mode, follow_symlinks=follow)\n except NotImplementedError:\n \n \n \n \n \n \n \n \n \n \n  pass\n if hasattr(st, 'st_flags'):\n  try:\n   lookup(\"chflags\")(dst, st.st_flags, follow_symlinks=follow)\n  except OSError as why:\n   for err in 'EOPNOTSUPP', 'ENOTSUP':\n    if hasattr(errno, err) and why.errno == getattr(errno, err):\n     break\n   else:\n    raise\n _copyxattr(src, dst, follow_symlinks=follow)\n \ndef copy(src, dst, *, follow_symlinks=True):\n \"\"\n if os.path.isdir(dst):\n  dst = os.path.join(dst, os.path.basename(src))\n copyfile(src, dst, follow_symlinks=follow_symlinks)\n copymode(src, dst, follow_symlinks=follow_symlinks)\n return dst\n \ndef copy2(src, dst, *, follow_symlinks=True):\n \"\"\n if os.path.isdir(dst):\n  dst = os.path.join(dst, os.path.basename(src))\n copyfile(src, dst, follow_symlinks=follow_symlinks)\n copystat(src, dst, follow_symlinks=follow_symlinks)\n return dst\n \ndef ignore_patterns(*patterns):\n \"\"\n def _ignore_patterns(path, names):\n  ignored_names = []\n  for pattern in patterns:\n   ignored_names.extend(fnmatch.filter(names, pattern))\n  return set(ignored_names)\n return _ignore_patterns\n \ndef copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2,\nignore_dangling_symlinks=False):\n \"\"\n names = os.listdir(src)\n if ignore is not None:\n  ignored_names = ignore(src, names)\n else:\n  ignored_names = set()\n  \n os.makedirs(dst)\n errors = []\n for name in names:\n  if name in ignored_names:\n   continue\n  srcname = os.path.join(src, name)\n  dstname = os.path.join(dst, name)\n  try:\n   if os.path.islink(srcname):\n    linkto = os.readlink(srcname)\n    if symlinks:\n    \n    \n    \n     os.symlink(linkto, dstname)\n     copystat(srcname, dstname, follow_symlinks=not symlinks)\n    else:\n    \n     if not os.path.exists(linkto) and ignore_dangling_symlinks:\n      continue\n      \n     copy_function(srcname, dstname)\n   elif os.path.isdir(srcname):\n    copytree(srcname, dstname, symlinks, ignore, copy_function)\n   else:\n   \n    copy_function(srcname, dstname)\n    \n    \n  except Error as err:\n   errors.extend(err.args[0])\n  except EnvironmentError as why:\n   errors.append((srcname, dstname, str(why)))\n try:\n  copystat(src, dst)\n except OSError as why:\n  if WindowsError is not None and isinstance(why, WindowsError):\n  \n   pass\n  else:\n   errors.append((src, dst, str(why)))\n if errors:\n  raise Error(errors)\n return dst\n \n \ndef _rmtree_unsafe(path, onerror):\n try:\n  if os.path.islink(path):\n  \n   raise OSError(\"Cannot call rmtree on a symbolic link\")\n except OSError:\n  onerror(os.path.islink, path, sys.exc_info())\n  \n  return\n names = []\n try:\n  names = os.listdir(path)\n except os.error:\n  onerror(os.listdir, path, sys.exc_info())\n for name in names:\n  fullname = os.path.join(path, name)\n  try:\n   mode = os.lstat(fullname).st_mode\n  except os.error:\n   mode = 0\n  if stat.S_ISDIR(mode):\n   _rmtree_unsafe(fullname, onerror)\n  else:\n   try:\n    os.unlink(fullname)\n   except os.error:\n    onerror(os.unlink, fullname, sys.exc_info())\n try:\n  os.rmdir(path)\n except os.error:\n  onerror(os.rmdir, path, sys.exc_info())\n  \n  \ndef _rmtree_safe_fd(topfd, path, onerror):\n names = []\n try:\n  names = os.listdir(topfd)\n except OSError as err:\n  err.filename = path\n  onerror(os.listdir, path, sys.exc_info())\n for name in names:\n  fullname = os.path.join(path, name)\n  try:\n   orig_st = os.stat(name, dir_fd=topfd, follow_symlinks=False)\n   mode = orig_st.st_mode\n  except OSError:\n   mode = 0\n  if stat.S_ISDIR(mode):\n   try:\n    dirfd = os.open(name, os.O_RDONLY, dir_fd=topfd)\n   except OSError:\n    onerror(os.open, fullname, sys.exc_info())\n   else:\n    try:\n     if os.path.samestat(orig_st, os.fstat(dirfd)):\n      _rmtree_safe_fd(dirfd, fullname, onerror)\n      try:\n       os.rmdir(name, dir_fd=topfd)\n      except OSError:\n       onerror(os.rmdir, fullname, sys.exc_info())\n     else:\n      try:\n      \n      \n      \n       raise OSError(\"Cannot call rmtree on a symbolic \"\n       \"link\")\n      except OSError:\n       onerror(os.path.islink, fullname, sys.exc_info())\n    finally:\n     os.close(dirfd)\n  else:\n   try:\n    os.unlink(name, dir_fd=topfd)\n   except OSError:\n    onerror(os.unlink, fullname, sys.exc_info())\n    \n_use_fd_functions = ({os.open, os.stat, os.unlink, os.rmdir} <=\nos.supports_dir_fd and\nos.listdir in os.supports_fd and\nos.stat in os.supports_follow_symlinks)\n\ndef rmtree(path, ignore_errors=False, onerror=None):\n \"\"\n if ignore_errors:\n  def onerror(*args):\n   pass\n elif onerror is None:\n  def onerror(*args):\n   raise\n if _use_fd_functions:\n \n  if isinstance(path, bytes):\n   path = os.fsdecode(path)\n   \n   \n  try:\n   orig_st = os.lstat(path)\n  except Exception:\n   onerror(os.lstat, path, sys.exc_info())\n   return\n  try:\n   fd = os.open(path, os.O_RDONLY)\n  except Exception:\n   onerror(os.lstat, path, sys.exc_info())\n   return\n  try:\n   if os.path.samestat(orig_st, os.fstat(fd)):\n    _rmtree_safe_fd(fd, path, onerror)\n    try:\n     os.rmdir(path)\n    except os.error:\n     onerror(os.rmdir, path, sys.exc_info())\n   else:\n    try:\n    \n     raise OSError(\"Cannot call rmtree on a symbolic link\")\n    except OSError:\n     onerror(os.path.islink, path, sys.exc_info())\n  finally:\n   os.close(fd)\n else:\n  return _rmtree_unsafe(path, onerror)\n  \n  \n  \nrmtree.avoids_symlink_attacks = _use_fd_functions\n\ndef _basename(path):\n\n\n return os.path.basename(path.rstrip(os.path.sep))\n \ndef move(src, dst):\n \"\"\n real_dst = dst\n if os.path.isdir(dst):\n  if _samefile(src, dst):\n  \n  \n   os.rename(src, dst)\n   return\n   \n  real_dst = os.path.join(dst, _basename(src))\n  if os.path.exists(real_dst):\n   raise Error(\"Destination path '%s' already exists\" % real_dst)\n try:\n  os.rename(src, real_dst)\n except OSError:\n  if os.path.islink(src):\n   linkto = os.readlink(src)\n   os.symlink(linkto, real_dst)\n   os.unlink(src)\n  elif os.path.isdir(src):\n   if _destinsrc(src, dst):\n    raise Error(\"Cannot move a directory '%s' into itself '%s'.\" % (src, dst))\n   copytree(src, real_dst, symlinks=True)\n   rmtree(src)\n  else:\n   copy2(src, real_dst)\n   os.unlink(src)\n return real_dst\n \ndef _destinsrc(src, dst):\n src = abspath(src)\n dst = abspath(dst)\n if not src.endswith(os.path.sep):\n  src += os.path.sep\n if not dst.endswith(os.path.sep):\n  dst += os.path.sep\n return dst.startswith(src)\n \ndef _get_gid(name):\n \"\"\n if getgrnam is None or name is None:\n  return None\n try:\n  result = getgrnam(name)\n except KeyError:\n  result = None\n if result is not None:\n  return result[2]\n return None\n \ndef _get_uid(name):\n \"\"\n if getpwnam is None or name is None:\n  return None\n try:\n  result = getpwnam(name)\n except KeyError:\n  result = None\n if result is not None:\n  return result[2]\n return None\n \ndef _make_tarball(base_name, base_dir, compress=\"gzip\", verbose=0, dry_run=0,\nowner=None, group=None, logger=None):\n \"\"\n tar_compression = {'gzip': 'gz', None: ''}\n compress_ext = {'gzip': '.gz'}\n \n if _BZ2_SUPPORTED:\n  tar_compression['bzip2'] = 'bz2'\n  compress_ext['bzip2'] = '.bz2'\n  \n  \n if compress is not None and compress not in compress_ext:\n  raise ValueError(\"bad value for 'compress', or compression format not \"\n  \"supported : {0}\".format(compress))\n  \n archive_name = base_name + '.tar' + compress_ext.get(compress, '')\n archive_dir = os.path.dirname(archive_name)\n \n if not os.path.exists(archive_dir):\n  if logger is not None:\n   logger.info(\"creating %s\", archive_dir)\n  if not dry_run:\n   os.makedirs(archive_dir)\n   \n   \n if logger is not None:\n  logger.info('Creating tar archive')\n  \n uid = _get_uid(owner)\n gid = _get_gid(group)\n \n def _set_uid_gid(tarinfo):\n  if gid is not None:\n   tarinfo.gid = gid\n   tarinfo.gname = group\n  if uid is not None:\n   tarinfo.uid = uid\n   tarinfo.uname = owner\n  return tarinfo\n  \n if not dry_run:\n  tar = tarfile.open(archive_name, 'w|%s' % tar_compression[compress])\n  try:\n   tar.add(base_dir, filter=_set_uid_gid)\n  finally:\n   tar.close()\n   \n return archive_name\n \ndef _call_external_zip(base_dir, zip_filename, verbose=False, dry_run=False):\n\n if verbose:\n  zipoptions = \"-r\"\n else:\n  zipoptions = \"-rq\"\n from distutils.errors import DistutilsExecError\n from distutils.spawn import spawn\n try:\n  spawn([\"zip\", zipoptions, zip_filename, base_dir], dry_run=dry_run)\n except DistutilsExecError:\n \n \n  raise ExecError(\"unable to create zip file '%s': \"\n  \"could neither import the 'zipfile' module nor \"\n  \"find a standalone zip utility\") % zip_filename\n  \ndef _make_zipfile(base_name, base_dir, verbose=0, dry_run=0, logger=None):\n \"\"\n zip_filename = base_name + \".zip\"\n archive_dir = os.path.dirname(base_name)\n \n if not os.path.exists(archive_dir):\n  if logger is not None:\n   logger.info(\"creating %s\", archive_dir)\n  if not dry_run:\n   os.makedirs(archive_dir)\n   \n   \n   \n try:\n  import zipfile\n except ImportError:\n  zipfile = None\n  \n if zipfile is None:\n  _call_external_zip(base_dir, zip_filename, verbose, dry_run)\n else:\n  if logger is not None:\n   logger.info(\"creating '%s' and adding '%s' to it\",\n   zip_filename, base_dir)\n   \n  if not dry_run:\n   zip = zipfile.ZipFile(zip_filename, \"w\",\n   compression=zipfile.ZIP_DEFLATED)\n   \n   for dirpath, dirnames, filenames in os.walk(base_dir):\n    for name in filenames:\n     path = os.path.normpath(os.path.join(dirpath, name))\n     if os.path.isfile(path):\n      zip.write(path, path)\n      if logger is not None:\n       logger.info(\"adding '%s'\", path)\n   zip.close()\n   \n return zip_filename\n \n_ARCHIVE_FORMATS = {\n'gztar': (_make_tarball, [('compress', 'gzip')], \"gzip'ed tar-file\"),\n'tar': (_make_tarball, [('compress', None)], \"uncompressed tar file\"),\n'zip': (_make_zipfile, [], \"ZIP file\")\n}\n\nif _BZ2_SUPPORTED:\n _ARCHIVE_FORMATS['bztar'] = (_make_tarball, [('compress', 'bzip2')],\n \"bzip2'ed tar-file\")\n \ndef get_archive_formats():\n \"\"\n formats = [(name, registry[2]) for name, registry in\n _ARCHIVE_FORMATS.items()]\n formats.sort()\n return formats\n \ndef register_archive_format(name, function, extra_args=None, description=''):\n \"\"\n if extra_args is None:\n  extra_args = []\n if not callable(function):\n  raise TypeError('The %s object is not callable' % function)\n if not isinstance(extra_args, (tuple, list)):\n  raise TypeError('extra_args needs to be a sequence')\n for element in extra_args:\n  if not isinstance(element, (tuple, list)) or len(element) !=2:\n   raise TypeError('extra_args elements are : (arg_name, value)')\n   \n _ARCHIVE_FORMATS[name] = (function, extra_args, description)\n \ndef unregister_archive_format(name):\n del _ARCHIVE_FORMATS[name]\n \ndef make_archive(base_name, format, root_dir=None, base_dir=None, verbose=0,\ndry_run=0, owner=None, group=None, logger=None):\n \"\"\n save_cwd = os.getcwd()\n if root_dir is not None:\n  if logger is not None:\n   logger.debug(\"changing into '%s'\", root_dir)\n  base_name = os.path.abspath(base_name)\n  if not dry_run:\n   os.chdir(root_dir)\n   \n if base_dir is None:\n  base_dir = os.curdir\n  \n kwargs = {'dry_run': dry_run, 'logger': logger}\n \n try:\n  format_info = _ARCHIVE_FORMATS[format]\n except KeyError:\n  raise ValueError(\"unknown archive format '%s'\" % format)\n  \n func = format_info[0]\n for arg, val in format_info[1]:\n  kwargs[arg] = val\n  \n if format != 'zip':\n  kwargs['owner'] = owner\n  kwargs['group'] = group\n  \n try:\n  filename = func(base_name, base_dir, **kwargs)\n finally:\n  if root_dir is not None:\n   if logger is not None:\n    logger.debug(\"changing back to '%s'\", save_cwd)\n   os.chdir(save_cwd)\n   \n return filename\n \n \ndef get_unpack_formats():\n \"\"\n formats = [(name, info[0], info[3]) for name, info in\n _UNPACK_FORMATS.items()]\n formats.sort()\n return formats\n \ndef _check_unpack_options(extensions, function, extra_args):\n \"\"\n \n existing_extensions = {}\n for name, info in _UNPACK_FORMATS.items():\n  for ext in info[0]:\n   existing_extensions[ext] = name\n   \n for extension in extensions:\n  if extension in existing_extensions:\n   msg = '%s is already registered for \"%s\"'\n   raise RegistryError(msg % (extension,\n   existing_extensions[extension]))\n   \n if not callable(function):\n  raise TypeError('The registered function must be a callable')\n  \n  \ndef register_unpack_format(name, extensions, function, extra_args=None,\ndescription=''):\n \"\"\n if extra_args is None:\n  extra_args = []\n _check_unpack_options(extensions, function, extra_args)\n _UNPACK_FORMATS[name] = extensions, function, extra_args, description\n \ndef unregister_unpack_format(name):\n \"\"\n del _UNPACK_FORMATS[name]\n \ndef _ensure_directory(path):\n \"\"\n dirname = os.path.dirname(path)\n if not os.path.isdir(dirname):\n  os.makedirs(dirname)\n  \ndef _unpack_zipfile(filename, extract_dir):\n \"\"\n try:\n  import zipfile\n except ImportError:\n  raise ReadError('zlib not supported, cannot unpack this archive.')\n  \n if not zipfile.is_zipfile(filename):\n  raise ReadError(\"%s is not a zip file\" % filename)\n  \n zip = zipfile.ZipFile(filename)\n try:\n  for info in zip.infolist():\n   name = info.filename\n   \n   \n   if name.startswith('/') or '..' in name:\n    continue\n    \n   target = os.path.join(extract_dir, *name.split('/'))\n   if not target:\n    continue\n    \n   _ensure_directory(target)\n   if not name.endswith('/'):\n   \n    data = zip.read(info.filename)\n    f = open(target, 'wb')\n    try:\n     f.write(data)\n    finally:\n     f.close()\n     del data\n finally:\n  zip.close()\n  \ndef _unpack_tarfile(filename, extract_dir):\n \"\"\n try:\n  tarobj = tarfile.open(filename)\n except tarfile.TarError:\n  raise ReadError(\n  \"%s is not a compressed or uncompressed tar file\" % filename)\n try:\n  tarobj.extractall(extract_dir)\n finally:\n  tarobj.close()\n  \n_UNPACK_FORMATS = {\n'gztar': (['.tar.gz', '.tgz'], _unpack_tarfile, [], \"gzip'ed tar-file\"),\n'tar': (['.tar'], _unpack_tarfile, [], \"uncompressed tar file\"),\n'zip': (['.zip'], _unpack_zipfile, [], \"ZIP file\")\n}\n\nif _BZ2_SUPPORTED:\n _UNPACK_FORMATS['bztar'] = (['.bz2'], _unpack_tarfile, [],\n \"bzip2'ed tar-file\")\n \ndef _find_unpack_format(filename):\n for name, info in _UNPACK_FORMATS.items():\n  for extension in info[0]:\n   if filename.endswith(extension):\n    return name\n return None\n \ndef unpack_archive(filename, extract_dir=None, format=None):\n \"\"\n if extract_dir is None:\n  extract_dir = os.getcwd()\n  \n if format is not None:\n  try:\n   format_info = _UNPACK_FORMATS[format]\n  except KeyError:\n   raise ValueError(\"Unknown unpack format '{0}'\".format(format))\n   \n  func = format_info[1]\n  func(filename, extract_dir, **dict(format_info[2]))\n else:\n \n  format = _find_unpack_format(filename)\n  if format is None:\n   raise ReadError(\"Unknown archive format '{0}'\".format(filename))\n   \n  func = _UNPACK_FORMATS[format][1]\n  kwargs = dict(_UNPACK_FORMATS[format][2])\n  func(filename, extract_dir, **kwargs)\n  \n  \nif hasattr(os, 'statvfs'):\n\n __all__.append('disk_usage')\n _ntuple_diskusage = collections.namedtuple('usage', 'total used free')\n \n def disk_usage(path):\n  \"\"\n  st = os.statvfs(path)\n  free = st.f_bavail * st.f_frsize\n  total = st.f_blocks * st.f_frsize\n  used = (st.f_blocks - st.f_bfree) * st.f_frsize\n  return _ntuple_diskusage(total, used, free)\n  \nelif os.name == 'nt':\n\n import nt\n __all__.append('disk_usage')\n _ntuple_diskusage = collections.namedtuple('usage', 'total used free')\n \n def disk_usage(path):\n  \"\"\n  total, free = nt._getdiskusage(path)\n  used = total - free\n  return _ntuple_diskusage(total, used, free)\n  \n  \ndef chown(path, user=None, group=None):\n \"\"\n \n if user is None and group is None:\n  raise ValueError(\"user and/or group must be set\")\n  \n _user = user\n _group = group\n \n \n if user is None:\n  _user = -1\n  \n elif isinstance(user, str):\n  _user = _get_uid(user)\n  if _user is None:\n   raise LookupError(\"no such user: {!r}\".format(user))\n   \n if group is None:\n  _group = -1\n elif not isinstance(group, int):\n  _group = _get_gid(group)\n  if _group is None:\n   raise LookupError(\"no such group: {!r}\".format(group))\n   \n os.chown(path, _user, _group)\n \ndef get_terminal_size(fallback=(80, 24)):\n \"\"\n \n try:\n  columns = int(os.environ['COLUMNS'])\n except (KeyError, ValueError):\n  columns = 0\n  \n try:\n  lines = int(os.environ['LINES'])\n except (KeyError, ValueError):\n  lines = 0\n  \n  \n if columns <= 0 or lines <= 0:\n  try:\n   size = os.get_terminal_size(sys.__stdout__.fileno())\n  except (NameError, OSError):\n   size = os.terminal_size(fallback)\n  if columns <= 0:\n   columns = size.columns\n  if lines <= 0:\n   lines = size.lines\n   \n return os.terminal_size((columns, lines))\n \ndef which(cmd, mode=os.F_OK | os.X_OK, path=None):\n \"\"\n \n \n \n def _access_check(fn, mode):\n  return (os.path.exists(fn) and os.access(fn, mode)\n  and not os.path.isdir(fn))\n  \n  \n  \n  \n if os.path.dirname(cmd):\n  if _access_check(cmd, mode):\n   return cmd\n  return None\n  \n if path is None:\n  path = os.environ.get(\"PATH\", os.defpath)\n if not path:\n  return None\n path = path.split(os.pathsep)\n \n if sys.platform == \"win32\":\n \n  if not os.curdir in path:\n   path.insert(0, os.curdir)\n   \n   \n  pathext = os.environ.get(\"PATHEXT\", \"\").split(os.pathsep)\n  \n  \n  \n  \n  if any(cmd.lower().endswith(ext.lower()) for ext in pathext):\n   files = [cmd]\n  else:\n   files = [cmd + ext for ext in pathext]\n else:\n \n \n  files = [cmd]\n  \n seen = set()\n for dir in path:\n  normdir = os.path.normcase(dir)\n  if not normdir in seen:\n   seen.add(normdir)\n   for thefile in files:\n    name = os.path.join(dir, thefile)\n    if _access_check(name, mode):\n     return name\n return None\n"], "unittest.test.test_break": [".py", "import gc\nimport io\nimport os\nimport sys\nimport signal\nimport weakref\n\nimport unittest\n\n\n@unittest.skipUnless(hasattr(os, 'kill'), \"Test requires os.kill\")\n@unittest.skipIf(sys.platform ==\"win32\", \"Test cannot run on Windows\")\n@unittest.skipIf(sys.platform == 'freebsd6', \"Test kills regrtest on freebsd6 \"\n\"if threads have been used\")\nclass TestBreak(unittest.TestCase):\n\n def setUp(self):\n  self._default_handler = signal.getsignal(signal.SIGINT)\n  \n def tearDown(self):\n  signal.signal(signal.SIGINT, self._default_handler)\n  unittest.signals._results = weakref.WeakKeyDictionary()\n  unittest.signals._interrupt_handler = None\n  \n  \n def testInstallHandler(self):\n  default_handler = signal.getsignal(signal.SIGINT)\n  unittest.installHandler()\n  self.assertNotEqual(signal.getsignal(signal.SIGINT), default_handler)\n  \n  try:\n   pid = os.getpid()\n   os.kill(pid, signal.SIGINT)\n  except KeyboardInterrupt:\n   self.fail(\"KeyboardInterrupt not handled\")\n   \n  self.assertTrue(unittest.signals._interrupt_handler.called)\n  \n def testRegisterResult(self):\n  result = unittest.TestResult()\n  unittest.registerResult(result)\n  \n  for ref in unittest.signals._results:\n   if ref is result:\n    break\n   elif ref is not result:\n    self.fail(\"odd object in result set\")\n  else:\n   self.fail(\"result not found\")\n   \n   \n def testInterruptCaught(self):\n  default_handler = signal.getsignal(signal.SIGINT)\n  \n  result = unittest.TestResult()\n  unittest.installHandler()\n  unittest.registerResult(result)\n  \n  self.assertNotEqual(signal.getsignal(signal.SIGINT), default_handler)\n  \n  def test(result):\n   pid = os.getpid()\n   os.kill(pid, signal.SIGINT)\n   result.breakCaught = True\n   self.assertTrue(result.shouldStop)\n   \n  try:\n   test(result)\n  except KeyboardInterrupt:\n   self.fail(\"KeyboardInterrupt not handled\")\n  self.assertTrue(result.breakCaught)\n  \n  \n def testSecondInterrupt(self):\n  result = unittest.TestResult()\n  unittest.installHandler()\n  unittest.registerResult(result)\n  \n  def test(result):\n   pid = os.getpid()\n   os.kill(pid, signal.SIGINT)\n   result.breakCaught = True\n   self.assertTrue(result.shouldStop)\n   os.kill(pid, signal.SIGINT)\n   self.fail(\"Second KeyboardInterrupt not raised\")\n   \n  try:\n   test(result)\n  except KeyboardInterrupt:\n   pass\n  else:\n   self.fail(\"Second KeyboardInterrupt not raised\")\n  self.assertTrue(result.breakCaught)\n  \n  \n def testTwoResults(self):\n  unittest.installHandler()\n  \n  result = unittest.TestResult()\n  unittest.registerResult(result)\n  new_handler = signal.getsignal(signal.SIGINT)\n  \n  result2 = unittest.TestResult()\n  unittest.registerResult(result2)\n  self.assertEqual(signal.getsignal(signal.SIGINT), new_handler)\n  \n  result3 = unittest.TestResult()\n  \n  def test(result):\n   pid = os.getpid()\n   os.kill(pid, signal.SIGINT)\n   \n  try:\n   test(result)\n  except KeyboardInterrupt:\n   self.fail(\"KeyboardInterrupt not handled\")\n   \n  self.assertTrue(result.shouldStop)\n  self.assertTrue(result2.shouldStop)\n  self.assertFalse(result3.shouldStop)\n  \n  \n def testHandlerReplacedButCalled(self):\n \n \n \n  unittest.installHandler()\n  \n  handler = signal.getsignal(signal.SIGINT)\n  def new_handler(frame, signum):\n   handler(frame, signum)\n  signal.signal(signal.SIGINT, new_handler)\n  \n  try:\n   pid = os.getpid()\n   os.kill(pid, signal.SIGINT)\n  except KeyboardInterrupt:\n   pass\n  else:\n   self.fail(\"replaced but delegated handler doesn't raise interrupt\")\n   \n def testRunner(self):\n \n \n  runner = unittest.TextTestRunner(stream=io.StringIO())\n  \n  result = runner.run(unittest.TestSuite())\n  self.assertIn(result, unittest.signals._results)\n  \n def testWeakReferences(self):\n \n  result = unittest.TestResult()\n  unittest.registerResult(result)\n  \n  ref = weakref.ref(result)\n  del result\n  \n  \n  gc.collect();gc.collect()\n  self.assertIsNone(ref())\n  \n  \n def testRemoveResult(self):\n  result = unittest.TestResult()\n  unittest.registerResult(result)\n  \n  unittest.installHandler()\n  self.assertTrue(unittest.removeResult(result))\n  \n  \n  self.assertFalse(unittest.removeResult(unittest.TestResult()))\n  \n  try:\n   pid = os.getpid()\n   os.kill(pid, signal.SIGINT)\n  except KeyboardInterrupt:\n   pass\n   \n  self.assertFalse(result.shouldStop)\n  \n def testMainInstallsHandler(self):\n  failfast = object()\n  test = object()\n  verbosity = object()\n  result = object()\n  default_handler = signal.getsignal(signal.SIGINT)\n  \n  class FakeRunner(object):\n   initArgs = []\n   runArgs = []\n   def __init__(self, *args, **kwargs):\n    self.initArgs.append((args, kwargs))\n   def run(self, test):\n    self.runArgs.append(test)\n    return result\n    \n  class Program(unittest.TestProgram):\n   def __init__(self, catchbreak):\n    self.exit = False\n    self.verbosity = verbosity\n    self.failfast = failfast\n    self.catchbreak = catchbreak\n    self.testRunner = FakeRunner\n    self.test = test\n    self.result = None\n    \n  p = Program(False)\n  p.runTests()\n  \n  self.assertEqual(FakeRunner.initArgs, [((), {'buffer': None,\n  'verbosity': verbosity,\n  'failfast': failfast,\n  'warnings': None})])\n  self.assertEqual(FakeRunner.runArgs, [test])\n  self.assertEqual(p.result, result)\n  \n  self.assertEqual(signal.getsignal(signal.SIGINT), default_handler)\n  \n  FakeRunner.initArgs = []\n  FakeRunner.runArgs = []\n  p = Program(True)\n  p.runTests()\n  \n  self.assertEqual(FakeRunner.initArgs, [((), {'buffer': None,\n  'verbosity': verbosity,\n  'failfast': failfast,\n  'warnings': None})])\n  self.assertEqual(FakeRunner.runArgs, [test])\n  self.assertEqual(p.result, result)\n  \n  self.assertNotEqual(signal.getsignal(signal.SIGINT), default_handler)\n  \n def testRemoveHandler(self):\n  default_handler = signal.getsignal(signal.SIGINT)\n  unittest.installHandler()\n  unittest.removeHandler()\n  self.assertEqual(signal.getsignal(signal.SIGINT), default_handler)\n  \n  \n  unittest.removeHandler()\n  self.assertEqual(signal.getsignal(signal.SIGINT), default_handler)\n  \n def testRemoveHandlerAsDecorator(self):\n  default_handler = signal.getsignal(signal.SIGINT)\n  unittest.installHandler()\n  \n  @unittest.removeHandler\n  def test():\n   self.assertEqual(signal.getsignal(signal.SIGINT), default_handler)\n   \n  test()\n  self.assertNotEqual(signal.getsignal(signal.SIGINT), default_handler)\n"], "configparser": [".py", "\"\"\n\nfrom collections.abc import MutableMapping\nfrom collections import OrderedDict as _default_dict, ChainMap as _ChainMap\nimport functools\nimport io\nimport itertools\nimport re\nimport sys\nimport warnings\n\n__all__ = [\"NoSectionError\", \"DuplicateOptionError\", \"DuplicateSectionError\",\n\"NoOptionError\", \"InterpolationError\", \"InterpolationDepthError\",\n\"InterpolationSyntaxError\", \"ParsingError\",\n\"MissingSectionHeaderError\",\n\"ConfigParser\", \"SafeConfigParser\", \"RawConfigParser\",\n\"DEFAULTSECT\", \"MAX_INTERPOLATION_DEPTH\"]\n\nDEFAULTSECT = \"DEFAULT\"\n\nMAX_INTERPOLATION_DEPTH = 10\n\n\n\n\nclass Error(Exception):\n \"\"\n \n def _get_message(self):\n  \"\"\n  return self.__message\n  \n def _set_message(self, value):\n  \"\"\n  self.__message = value\n  \n  \n  \n  \n message = property(_get_message, _set_message)\n \n def __init__(self, msg=''):\n  self.message = msg\n  Exception.__init__(self, msg)\n  \n def __repr__(self):\n  return self.message\n  \n __str__ = __repr__\n \n \nclass NoSectionError(Error):\n \"\"\n \n def __init__(self, section):\n  Error.__init__(self, 'No section: %r' % (section,))\n  self.section = section\n  self.args = (section, )\n  \n  \nclass DuplicateSectionError(Error):\n \"\"\n \n def __init__(self, section, source=None, lineno=None):\n  msg = [repr(section), \" already exists\"]\n  if source is not None:\n   message = [\"While reading from \", source]\n   if lineno is not None:\n    message.append(\" [line {0:2d}]\".format(lineno))\n   message.append(\": section \")\n   message.extend(msg)\n   msg = message\n  else:\n   msg.insert(0, \"Section \")\n  Error.__init__(self, \"\".join(msg))\n  self.section = section\n  self.source = source\n  self.lineno = lineno\n  self.args = (section, source, lineno)\n  \n  \nclass DuplicateOptionError(Error):\n \"\"\n \n def __init__(self, section, option, source=None, lineno=None):\n  msg = [repr(option), \" in section \", repr(section),\n  \" already exists\"]\n  if source is not None:\n   message = [\"While reading from \", source]\n   if lineno is not None:\n    message.append(\" [line {0:2d}]\".format(lineno))\n   message.append(\": option \")\n   message.extend(msg)\n   msg = message\n  else:\n   msg.insert(0, \"Option \")\n  Error.__init__(self, \"\".join(msg))\n  self.section = section\n  self.option = option\n  self.source = source\n  self.lineno = lineno\n  self.args = (section, option, source, lineno)\n  \n  \nclass NoOptionError(Error):\n \"\"\n \n def __init__(self, option, section):\n  Error.__init__(self, \"No option %r in section: %r\" %\n  (option, section))\n  self.option = option\n  self.section = section\n  self.args = (option, section)\n  \n  \nclass InterpolationError(Error):\n \"\"\n \n def __init__(self, option, section, msg):\n  Error.__init__(self, msg)\n  self.option = option\n  self.section = section\n  self.args = (option, section, msg)\n  \n  \nclass InterpolationMissingOptionError(InterpolationError):\n \"\"\n \n def __init__(self, option, section, rawval, reference):\n  msg = (\"Bad value substitution:\\n\"\n  \"\\tsection: [%s]\\n\"\n  \"\\toption : %s\\n\"\n  \"\\tkey    : %s\\n\"\n  \"\\trawval : %s\\n\"\n  % (section, option, reference, rawval))\n  InterpolationError.__init__(self, option, section, msg)\n  self.reference = reference\n  self.args = (option, section, rawval, reference)\n  \n  \nclass InterpolationSyntaxError(InterpolationError):\n \"\"\n \n \nclass InterpolationDepthError(InterpolationError):\n \"\"\n \n def __init__(self, option, section, rawval):\n  msg = (\"Value interpolation too deeply recursive:\\n\"\n  \"\\tsection: [%s]\\n\"\n  \"\\toption : %s\\n\"\n  \"\\trawval : %s\\n\"\n  % (section, option, rawval))\n  InterpolationError.__init__(self, option, section, msg)\n  self.args = (option, section, rawval)\n  \n  \nclass ParsingError(Error):\n \"\"\n \n def __init__(self, source=None, filename=None):\n \n \n  if filename and source:\n   raise ValueError(\"Cannot specify both `filename' and `source'. \"\n   \"Use `source'.\")\n  elif not filename and not source:\n   raise ValueError(\"Required argument `source' not given.\")\n  elif filename:\n   source = filename\n  Error.__init__(self, 'Source contains parsing errors: %s' % source)\n  self.source = source\n  self.errors = []\n  self.args = (source, )\n  \n @property\n def filename(self):\n  \"\"\n  warnings.warn(\n  \"The 'filename' attribute will be removed in future versions.  \"\n  \"Use 'source' instead.\",\n  DeprecationWarning, stacklevel=2\n  )\n  return self.source\n  \n @filename.setter\n def filename(self, value):\n  \"\"\n  warnings.warn(\n  \"The 'filename' attribute will be removed in future versions.  \"\n  \"Use 'source' instead.\",\n  DeprecationWarning, stacklevel=2\n  )\n  self.source = value\n  \n def append(self, lineno, line):\n  self.errors.append((lineno, line))\n  self.message += '\\n\\t[line %2d]: %s' % (lineno, line)\n  \n  \nclass MissingSectionHeaderError(ParsingError):\n \"\"\n \n def __init__(self, filename, lineno, line):\n  Error.__init__(\n  self,\n  'File contains no section headers.\\nfile: %s, line: %d\\n%r' %\n  (filename, lineno, line))\n  self.source = filename\n  self.lineno = lineno\n  self.line = line\n  self.args = (filename, lineno, line)\n  \n  \n  \n  \n  \n_UNSET = object()\n\n\nclass Interpolation:\n \"\"\n \n def before_get(self, parser, section, option, value, defaults):\n  return value\n  \n def before_set(self, parser, section, option, value):\n  return value\n  \n def before_read(self, parser, section, option, value):\n  return value\n  \n def before_write(self, parser, section, option, value):\n  return value\n  \n  \nclass BasicInterpolation(Interpolation):\n \"\"\n \n _KEYCRE = re.compile(r\"%\\(([^)]+)\\)s\")\n \n def before_get(self, parser, section, option, value, defaults):\n  L = []\n  self._interpolate_some(parser, option, L, value, section, defaults, 1)\n  return ''.join(L)\n  \n def before_set(self, parser, section, option, value):\n  tmp_value = value.replace('%%', '') \n  tmp_value = self._KEYCRE.sub('', tmp_value) \n  if '%' in tmp_value:\n   raise ValueError(\"invalid interpolation syntax in %r at \"\n   \"position %d\" % (value, tmp_value.find('%')))\n  return value\n  \n def _interpolate_some(self, parser, option, accum, rest, section, map,\n depth):\n  if depth > MAX_INTERPOLATION_DEPTH:\n   raise InterpolationDepthError(option, section, rest)\n  while rest:\n   p = rest.find(\"%\")\n   if p < 0:\n    accum.append(rest)\n    return\n   if p > 0:\n    accum.append(rest[:p])\n    rest = rest[p:]\n    \n   c = rest[1:2]\n   if c == \"%\":\n    accum.append(\"%\")\n    rest = rest[2:]\n   elif c == \"(\":\n    m = self._KEYCRE.match(rest)\n    if m is None:\n     raise InterpolationSyntaxError(option, section,\n     \"bad interpolation variable reference %r\" % rest)\n    var = parser.optionxform(m.group(1))\n    rest = rest[m.end():]\n    try:\n     v = map[var]\n    except KeyError:\n     raise InterpolationMissingOptionError(\n     option, section, rest, var)\n    if \"%\" in v:\n     self._interpolate_some(parser, option, accum, v,\n     section, map, depth + 1)\n    else:\n     accum.append(v)\n   else:\n    raise InterpolationSyntaxError(\n    option, section,\n    \"'%%' must be followed by '%%' or '(', \"\n    \"found: %r\" % (rest,))\n    \n    \nclass ExtendedInterpolation(Interpolation):\n \"\"\n \n _KEYCRE = re.compile(r\"\\$\\{([^}]+)\\}\")\n \n def before_get(self, parser, section, option, value, defaults):\n  L = []\n  self._interpolate_some(parser, option, L, value, section, defaults, 1)\n  return ''.join(L)\n  \n def before_set(self, parser, section, option, value):\n  tmp_value = value.replace('$$', '') \n  tmp_value = self._KEYCRE.sub('', tmp_value) \n  if '$' in tmp_value:\n   raise ValueError(\"invalid interpolation syntax in %r at \"\n   \"position %d\" % (value, tmp_value.find('%')))\n  return value\n  \n def _interpolate_some(self, parser, option, accum, rest, section, map,\n depth):\n  if depth > MAX_INTERPOLATION_DEPTH:\n   raise InterpolationDepthError(option, section, rest)\n  while rest:\n   p = rest.find(\"$\")\n   if p < 0:\n    accum.append(rest)\n    return\n   if p > 0:\n    accum.append(rest[:p])\n    rest = rest[p:]\n    \n   c = rest[1:2]\n   if c == \"$\":\n    accum.append(\"$\")\n    rest = rest[2:]\n   elif c == \"{\":\n    m = self._KEYCRE.match(rest)\n    if m is None:\n     raise InterpolationSyntaxError(option, section,\n     \"bad interpolation variable reference %r\" % rest)\n    path = m.group(1).split(':')\n    rest = rest[m.end():]\n    sect = section\n    opt = option\n    try:\n     if len(path) == 1:\n      opt = parser.optionxform(path[0])\n      v = map[opt]\n     elif len(path) == 2:\n      sect = path[0]\n      opt = parser.optionxform(path[1])\n      v = parser.get(sect, opt, raw=True)\n     else:\n      raise InterpolationSyntaxError(\n      option, section,\n      \"More than one ':' found: %r\" % (rest,))\n    except (KeyError, NoSectionError, NoOptionError):\n     raise InterpolationMissingOptionError(\n     option, section, rest, \":\".join(path))\n    if \"$\" in v:\n     self._interpolate_some(parser, opt, accum, v, sect,\n     dict(parser.items(sect, raw=True)),\n     depth + 1)\n    else:\n     accum.append(v)\n   else:\n    raise InterpolationSyntaxError(\n    option, section,\n    \"'$' must be followed by '$' or '{', \"\n    \"found: %r\" % (rest,))\n    \n    \nclass LegacyInterpolation(Interpolation):\n \"\"\n \n _KEYCRE = re.compile(r\"%\\(([^)]*)\\)s|.\")\n \n def before_get(self, parser, section, option, value, vars):\n  rawval = value\n  depth = MAX_INTERPOLATION_DEPTH\n  while depth: \n   depth -= 1\n   if value and \"%(\" in value:\n    replace = functools.partial(self._interpolation_replace,\n    parser=parser)\n    value = self._KEYCRE.sub(replace, value)\n    try:\n     value = value % vars\n    except KeyError as e:\n     raise InterpolationMissingOptionError(\n     option, section, rawval, e.args[0])\n   else:\n    break\n  if value and \"%(\" in value:\n   raise InterpolationDepthError(option, section, rawval)\n  return value\n  \n def before_set(self, parser, section, option, value):\n  return value\n  \n @staticmethod\n def _interpolation_replace(match, parser):\n  s = match.group(1)\n  if s is None:\n   return match.group()\n  else:\n   return \"%%(%s)s\" % parser.optionxform(s)\n   \n   \nclass RawConfigParser(MutableMapping):\n \"\"\n \n \n _SECT_TMPL = r\"\"\"\n        \\[                                 # [\n        (?P<header>[^]]+)                  # very permissive!\n        \\]                                 # ]\n        \"\"\" \n _OPT_TMPL = r\"\"\"\n        (?P<option>.*?)                    # very permissive!\n        \\s*(?P<vi>{delim})\\s*              # any number of space/tab,\n                                           # followed by any of the\n                                           # allowed delimiters,\n                                           # followed by any space/tab\n        (?P<value>.*)$                     # everything up to eol\n        \"\"\" \n _OPT_NV_TMPL = r\"\"\"\n        (?P<option>.*?)                    # very permissive!\n        \\s*(?:                             # any number of space/tab,\n        (?P<vi>{delim})\\s*                 # optionally followed by\n                                           # any of the allowed\n                                           # delimiters, followed by any\n                                           # space/tab\n        (?P<value>.*))?$                   # everything up to eol\n        \"\"\" \n \n _DEFAULT_INTERPOLATION = Interpolation()\n \n SECTCRE = re.compile(_SECT_TMPL, re.VERBOSE)\n \n OPTCRE = re.compile(_OPT_TMPL.format(delim=\"=|:\"), re.VERBOSE)\n \n \n OPTCRE_NV = re.compile(_OPT_NV_TMPL.format(delim=\"=|:\"), re.VERBOSE)\n \n NONSPACECRE = re.compile(r\"\\S\")\n \n BOOLEAN_STATES = {'1': True, 'yes': True, 'true': True, 'on': True,\n '0': False, 'no': False, 'false': False, 'off': False}\n \n def __init__(self, defaults=None, dict_type=_default_dict,\n allow_no_value=False, *, delimiters=('=', ':'),\n comment_prefixes=('#', ';'), inline_comment_prefixes=None,\n strict=True, empty_lines_in_values=True,\n default_section=DEFAULTSECT,\n interpolation=_UNSET):\n \n  self._dict = dict_type\n  self._sections = self._dict()\n  self._defaults = self._dict()\n  self._proxies = self._dict()\n  self._proxies[default_section] = SectionProxy(self, default_section)\n  if defaults:\n   for key, value in defaults.items():\n    self._defaults[self.optionxform(key)] = value\n  self._delimiters = tuple(delimiters)\n  if delimiters == ('=', ':'):\n   self._optcre = self.OPTCRE_NV if allow_no_value else self.OPTCRE\n  else:\n   d = \"|\".join(re.escape(d) for d in delimiters)\n   if allow_no_value:\n    self._optcre = re.compile(self._OPT_NV_TMPL.format(delim=d),\n    re.VERBOSE)\n   else:\n    self._optcre = re.compile(self._OPT_TMPL.format(delim=d),\n    re.VERBOSE)\n  self._comment_prefixes = tuple(comment_prefixes or ())\n  self._inline_comment_prefixes = tuple(inline_comment_prefixes or ())\n  self._strict = strict\n  self._allow_no_value = allow_no_value\n  self._empty_lines_in_values = empty_lines_in_values\n  self.default_section=default_section\n  self._interpolation = interpolation\n  if self._interpolation is _UNSET:\n   self._interpolation = self._DEFAULT_INTERPOLATION\n  if self._interpolation is None:\n   self._interpolation = Interpolation()\n   \n def defaults(self):\n  return self._defaults\n  \n def sections(self):\n  \"\"\n  \n  return list(self._sections.keys())\n  \n def add_section(self, section):\n  \"\"\n  if section == self.default_section:\n   raise ValueError('Invalid section name: %r' % section)\n   \n  if section in self._sections:\n   raise DuplicateSectionError(section)\n  self._sections[section] = self._dict()\n  self._proxies[section] = SectionProxy(self, section)\n  \n def has_section(self, section):\n  \"\"\n  return section in self._sections\n  \n def options(self, section):\n  \"\"\n  try:\n   opts = self._sections[section].copy()\n  except KeyError:\n   raise NoSectionError(section)\n  opts.update(self._defaults)\n  return list(opts.keys())\n  \n def read(self, filenames, encoding=None):\n  \"\"\n  if isinstance(filenames, str):\n   filenames = [filenames]\n  read_ok = []\n  for filename in filenames:\n   try:\n    with open(filename, encoding=encoding) as fp:\n     self._read(fp, filename)\n   except IOError:\n    continue\n   read_ok.append(filename)\n  return read_ok\n  \n def read_file(self, f, source=None):\n  \"\"\n  if source is None:\n   try:\n    source = f.name\n   except AttributeError:\n    source = '<???>'\n  self._read(f, source)\n  \n def read_string(self, string, source='<string>'):\n  \"\"\n  sfile = io.StringIO(string)\n  self.read_file(sfile, source)\n  \n def read_dict(self, dictionary, source='<dict>'):\n  \"\"\n  elements_added = set()\n  for section, keys in dictionary.items():\n   section = str(section)\n   try:\n    self.add_section(section)\n   except (DuplicateSectionError, ValueError):\n    if self._strict and section in elements_added:\n     raise\n   elements_added.add(section)\n   for key, value in keys.items():\n    key = self.optionxform(str(key))\n    if value is not None:\n     value = str(value)\n    if self._strict and (section, key) in elements_added:\n     raise DuplicateOptionError(section, key, source)\n    elements_added.add((section, key))\n    self.set(section, key, value)\n    \n def readfp(self, fp, filename=None):\n  \"\"\n  warnings.warn(\n  \"This method will be removed in future versions.  \"\n  \"Use 'parser.read_file()' instead.\",\n  DeprecationWarning, stacklevel=2\n  )\n  self.read_file(fp, source=filename)\n  \n def get(self, section, option, *, raw=False, vars=None, fallback=_UNSET):\n  \"\"\n  try:\n   d = self._unify_values(section, vars)\n  except NoSectionError:\n   if fallback is _UNSET:\n    raise\n   else:\n    return fallback\n  option = self.optionxform(option)\n  try:\n   value = d[option]\n  except KeyError:\n   if fallback is _UNSET:\n    raise NoOptionError(option, section)\n   else:\n    return fallback\n    \n  if raw or value is None:\n   return value\n  else:\n   return self._interpolation.before_get(self, section, option, value,\n   d)\n   \n def _get(self, section, conv, option, **kwargs):\n  return conv(self.get(section, option, **kwargs))\n  \n def getint(self, section, option, *, raw=False, vars=None,\n fallback=_UNSET):\n  try:\n   return self._get(section, int, option, raw=raw, vars=vars)\n  except (NoSectionError, NoOptionError):\n   if fallback is _UNSET:\n    raise\n   else:\n    return fallback\n    \n def getfloat(self, section, option, *, raw=False, vars=None,\n fallback=_UNSET):\n  try:\n   return self._get(section, float, option, raw=raw, vars=vars)\n  except (NoSectionError, NoOptionError):\n   if fallback is _UNSET:\n    raise\n   else:\n    return fallback\n    \n def getboolean(self, section, option, *, raw=False, vars=None,\n fallback=_UNSET):\n  try:\n   return self._get(section, self._convert_to_boolean, option,\n   raw=raw, vars=vars)\n  except (NoSectionError, NoOptionError):\n   if fallback is _UNSET:\n    raise\n   else:\n    return fallback\n    \n def items(self, section=_UNSET, raw=False, vars=None):\n  \"\"\n  if section is _UNSET:\n   return super().items()\n  d = self._defaults.copy()\n  try:\n   d.update(self._sections[section])\n  except KeyError:\n   if section != self.default_section:\n    raise NoSectionError(section)\n    \n  if vars:\n   for key, value in vars.items():\n    d[self.optionxform(key)] = value\n  value_getter = lambda option: self._interpolation.before_get(self,\n  section, option, d[option], d)\n  if raw:\n   value_getter = lambda option: d[option]\n  return [(option, value_getter(option)) for option in d.keys()]\n  \n def popitem(self):\n  \"\"\n  for key in self.sections():\n   value = self[key]\n   del self[key]\n   return key, value\n  raise KeyError\n  \n def optionxform(self, optionstr):\n  return optionstr.lower()\n  \n def has_option(self, section, option):\n  \"\"\n  if not section or section == self.default_section:\n   option = self.optionxform(option)\n   return option in self._defaults\n  elif section not in self._sections:\n   return False\n  else:\n   option = self.optionxform(option)\n   return (option in self._sections[section]\n   or option in self._defaults)\n   \n def set(self, section, option, value=None):\n  \"\"\n  if value:\n   value = self._interpolation.before_set(self, section, option,\n   value)\n  if not section or section == self.default_section:\n   sectdict = self._defaults\n  else:\n   try:\n    sectdict = self._sections[section]\n   except KeyError:\n    raise NoSectionError(section)\n  sectdict[self.optionxform(option)] = value\n  \n def write(self, fp, space_around_delimiters=True):\n  \"\"\n  if space_around_delimiters:\n   d = \" {} \".format(self._delimiters[0])\n  else:\n   d = self._delimiters[0]\n  if self._defaults:\n   self._write_section(fp, self.default_section,\n   self._defaults.items(), d)\n  for section in self._sections:\n   self._write_section(fp, section,\n   self._sections[section].items(), d)\n   \n def _write_section(self, fp, section_name, section_items, delimiter):\n  \"\"\n  fp.write(\"[{}]\\n\".format(section_name))\n  for key, value in section_items:\n   value = self._interpolation.before_write(self, section_name, key,\n   value)\n   if value is not None or not self._allow_no_value:\n    value = delimiter + str(value).replace('\\n', '\\n\\t')\n   else:\n    value = \"\"\n   fp.write(\"{}{}\\n\".format(key, value))\n  fp.write(\"\\n\")\n  \n def remove_option(self, section, option):\n  \"\"\n  if not section or section == self.default_section:\n   sectdict = self._defaults\n  else:\n   try:\n    sectdict = self._sections[section]\n   except KeyError:\n    raise NoSectionError(section)\n  option = self.optionxform(option)\n  existed = option in sectdict\n  if existed:\n   del sectdict[option]\n  return existed\n  \n def remove_section(self, section):\n  \"\"\n  existed = section in self._sections\n  if existed:\n   del self._sections[section]\n   del self._proxies[section]\n  return existed\n  \n def __getitem__(self, key):\n  if key != self.default_section and not self.has_section(key):\n   raise KeyError(key)\n  return self._proxies[key]\n  \n def __setitem__(self, key, value):\n \n \n \n \n \n  if key == self.default_section:\n   self._defaults.clear()\n  elif key in self._sections:\n   self._sections[key].clear()\n  self.read_dict({key: value})\n  \n def __delitem__(self, key):\n  if key == self.default_section:\n   raise ValueError(\"Cannot remove the default section.\")\n  if not self.has_section(key):\n   raise KeyError(key)\n  self.remove_section(key)\n  \n def __contains__(self, key):\n  return key == self.default_section or self.has_section(key)\n  \n def __len__(self):\n  return len(self._sections) + 1 \n  \n def __iter__(self):\n \n  return itertools.chain((self.default_section,), self._sections.keys())\n  \n def _read(self, fp, fpname):\n  \"\"\n  elements_added = set()\n  cursect = None \n  sectname = None\n  optname = None\n  lineno = 0\n  indent_level = 0\n  e = None \n  for lineno, line in enumerate(fp, start=1):\n   comment_start = sys.maxsize\n   \n   inline_prefixes = {p: -1 for p in self._inline_comment_prefixes}\n   while comment_start == sys.maxsize and inline_prefixes:\n    next_prefixes = {}\n    for prefix, index in inline_prefixes.items():\n     index = line.find(prefix, index+1)\n     if index == -1:\n      continue\n     next_prefixes[prefix] = index\n     if index == 0 or (index > 0 and line[index-1].isspace()):\n      comment_start = min(comment_start, index)\n    inline_prefixes = next_prefixes\n    \n   for prefix in self._comment_prefixes:\n    if line.strip().startswith(prefix):\n     comment_start = 0\n     break\n   if comment_start == sys.maxsize:\n    comment_start = None\n   value = line[:comment_start].strip()\n   if not value:\n    if self._empty_lines_in_values:\n    \n    \n     if (comment_start is None and\n     cursect is not None and\n     optname and\n     cursect[optname] is not None):\n      cursect[optname].append('') \n    else:\n    \n     indent_level = sys.maxsize\n    continue\n    \n   first_nonspace = self.NONSPACECRE.search(line)\n   cur_indent_level = first_nonspace.start() if first_nonspace else 0\n   if (cursect is not None and optname and\n   cur_indent_level > indent_level):\n    cursect[optname].append(value)\n    \n   else:\n    indent_level = cur_indent_level\n    \n    mo = self.SECTCRE.match(value)\n    if mo:\n     sectname = mo.group('header')\n     if sectname in self._sections:\n      if self._strict and sectname in elements_added:\n       raise DuplicateSectionError(sectname, fpname,\n       lineno)\n      cursect = self._sections[sectname]\n      elements_added.add(sectname)\n     elif sectname == self.default_section:\n      cursect = self._defaults\n     else:\n      cursect = self._dict()\n      self._sections[sectname] = cursect\n      self._proxies[sectname] = SectionProxy(self, sectname)\n      elements_added.add(sectname)\n      \n     optname = None\n     \n    elif cursect is None:\n     raise MissingSectionHeaderError(fpname, lineno, line)\n     \n    else:\n     mo = self._optcre.match(value)\n     if mo:\n      optname, vi, optval = mo.group('option', 'vi', 'value')\n      if not optname:\n       e = self._handle_error(e, fpname, lineno, line)\n      optname = self.optionxform(optname.rstrip())\n      if (self._strict and\n      (sectname, optname) in elements_added):\n       raise DuplicateOptionError(sectname, optname,\n       fpname, lineno)\n      elements_added.add((sectname, optname))\n      \n      \n      if optval is not None:\n       optval = optval.strip()\n       cursect[optname] = [optval]\n      else:\n      \n       cursect[optname] = None\n     else:\n     \n     \n     \n     \n      e = self._handle_error(e, fpname, lineno, line)\n      \n  if e:\n   raise e\n  self._join_multiline_values()\n  \n def _join_multiline_values(self):\n  defaults = self.default_section, self._defaults\n  all_sections = itertools.chain((defaults,),\n  self._sections.items())\n  for section, options in all_sections:\n   for name, val in options.items():\n    if isinstance(val, list):\n     val = '\\n'.join(val).rstrip()\n    options[name] = self._interpolation.before_read(self,\n    section,\n    name, val)\n    \n def _handle_error(self, exc, fpname, lineno, line):\n  if not exc:\n   exc = ParsingError(fpname)\n  exc.append(lineno, repr(line))\n  return exc\n  \n def _unify_values(self, section, vars):\n  \"\"\n  sectiondict = {}\n  try:\n   sectiondict = self._sections[section]\n  except KeyError:\n   if section != self.default_section:\n    raise NoSectionError(section)\n    \n  vardict = {}\n  if vars:\n   for key, value in vars.items():\n    if value is not None:\n     value = str(value)\n    vardict[self.optionxform(key)] = value\n  return _ChainMap(vardict, sectiondict, self._defaults)\n  \n def _convert_to_boolean(self, value):\n  \"\"\n  if value.lower() not in self.BOOLEAN_STATES:\n   raise ValueError('Not a boolean: %s' % value)\n  return self.BOOLEAN_STATES[value.lower()]\n  \n def _validate_value_types(self, *, section=\"\", option=\"\", value=\"\"):\n  \"\"\n  if not isinstance(section, str):\n   raise TypeError(\"section names must be strings\")\n  if not isinstance(option, str):\n   raise TypeError(\"option keys must be strings\")\n  if not self._allow_no_value or value:\n   if not isinstance(value, str):\n    raise TypeError(\"option values must be strings\")\n    \n    \nclass ConfigParser(RawConfigParser):\n \"\"\n \n _DEFAULT_INTERPOLATION = BasicInterpolation()\n \n def set(self, section, option, value=None):\n  \"\"\n  self._validate_value_types(option=option, value=value)\n  super().set(section, option, value)\n  \n def add_section(self, section):\n  \"\"\n  self._validate_value_types(section=section)\n  super().add_section(section)\n  \n  \nclass SafeConfigParser(ConfigParser):\n \"\"\n \n def __init__(self, *args, **kwargs):\n  super().__init__(*args, **kwargs)\n  warnings.warn(\n  \"The SafeConfigParser class has been renamed to ConfigParser \"\n  \"in Python 3.2. This alias will be removed in future versions.\"\n  \" Use ConfigParser directly instead.\",\n  DeprecationWarning, stacklevel=2\n  )\n  \n  \nclass SectionProxy(MutableMapping):\n \"\"\n \n def __init__(self, parser, name):\n  \"\"\n  self._parser = parser\n  self._name = name\n  \n def __repr__(self):\n  return '<Section: {}>'.format(self._name)\n  \n def __getitem__(self, key):\n  if not self._parser.has_option(self._name, key):\n   raise KeyError(key)\n  return self._parser.get(self._name, key)\n  \n def __setitem__(self, key, value):\n  self._parser._validate_value_types(option=key, value=value)\n  return self._parser.set(self._name, key, value)\n  \n def __delitem__(self, key):\n  if not (self._parser.has_option(self._name, key) and\n  self._parser.remove_option(self._name, key)):\n   raise KeyError(key)\n   \n def __contains__(self, key):\n  return self._parser.has_option(self._name, key)\n  \n def __len__(self):\n  return len(self._options())\n  \n def __iter__(self):\n  return self._options().__iter__()\n  \n def _options(self):\n  if self._name != self._parser.default_section:\n   return self._parser.options(self._name)\n  else:\n   return self._parser.defaults()\n   \n def get(self, option, fallback=None, *, raw=False, vars=None):\n  return self._parser.get(self._name, option, raw=raw, vars=vars,\n  fallback=fallback)\n  \n def getint(self, option, fallback=None, *, raw=False, vars=None):\n  return self._parser.getint(self._name, option, raw=raw, vars=vars,\n  fallback=fallback)\n  \n def getfloat(self, option, fallback=None, *, raw=False, vars=None):\n  return self._parser.getfloat(self._name, option, raw=raw, vars=vars,\n  fallback=fallback)\n  \n def getboolean(self, option, fallback=None, *, raw=False, vars=None):\n  return self._parser.getboolean(self._name, option, raw=raw, vars=vars,\n  fallback=fallback)\n  \n @property\n def parser(self):\n \n  return self._parser\n  \n @property\n def name(self):\n \n  return self._name\n"], "weakref": [".py", "\"\"\n\n\n\n\n\nfrom _weakref import (\ngetweakrefcount,\ngetweakrefs,\nref,\nproxy,\nCallableProxyType,\nProxyType,\nReferenceType)\n\nfrom _weakrefset import WeakSet, _IterationGuard\n\nimport collections \n\nProxyTypes = (ProxyType, CallableProxyType)\n\n__all__ = [\"ref\", \"proxy\", \"getweakrefcount\", \"getweakrefs\",\n\"WeakKeyDictionary\", \"ReferenceType\", \"ProxyType\",\n\"CallableProxyType\", \"ProxyTypes\", \"WeakValueDictionary\",\n\"WeakSet\"]\n\n\nclass WeakValueDictionary(collections.MutableMapping):\n \"\"\n \n \n \n \n \n \n def __init__(self, *args, **kw):\n  def remove(wr, selfref=ref(self)):\n   self = selfref()\n   if self is not None:\n    if self._iterating:\n     self._pending_removals.append(wr.key)\n    else:\n     del self.data[wr.key]\n  self._remove = remove\n  \n  self._pending_removals = []\n  self._iterating = set()\n  self.data = d = {}\n  self.update(*args, **kw)\n  \n def _commit_removals(self):\n  l = self._pending_removals\n  d = self.data\n  \n  \n  while l:\n   del d[l.pop()]\n   \n def __getitem__(self, key):\n  o = self.data[key]()\n  if o is None:\n   raise KeyError(key)\n  else:\n   return o\n   \n def __delitem__(self, key):\n  if self._pending_removals:\n   self._commit_removals()\n  del self.data[key]\n  \n def __len__(self):\n  return len(self.data) - len(self._pending_removals)\n  \n def __contains__(self, key):\n  try:\n   o = self.data[key]()\n  except KeyError:\n   return False\n  return o is not None\n  \n def __repr__(self):\n  return \"<WeakValueDictionary at %s>\" % id(self)\n  \n def __setitem__(self, key, value):\n  if self._pending_removals:\n   self._commit_removals()\n  self.data[key] = KeyedRef(value, self._remove, key)\n  \n def copy(self):\n  new = WeakValueDictionary()\n  for key, wr in self.data.items():\n   o = wr()\n   if o is not None:\n    new[key] = o\n  return new\n  \n __copy__ = copy\n \n def __deepcopy__(self, memo):\n  from copy import deepcopy\n  new = self.__class__()\n  for key, wr in self.data.items():\n   o = wr()\n   if o is not None:\n    new[deepcopy(key, memo)] = o\n  return new\n  \n def get(self, key, default=None):\n  try:\n   wr = self.data[key]\n  except KeyError:\n   return default\n  else:\n   o = wr()\n   if o is None:\n   \n    return default\n   else:\n    return o\n    \n def items(self):\n  with _IterationGuard(self):\n   for k, wr in self.data.items():\n    v = wr()\n    if v is not None:\n     yield k, v\n     \n def keys(self):\n  with _IterationGuard(self):\n   for k, wr in self.data.items():\n    if wr() is not None:\n     yield k\n     \n __iter__ = keys\n \n def itervaluerefs(self):\n  \"\"\n  with _IterationGuard(self):\n   for wr in self.data.values():\n    yield wr\n    \n def values(self):\n  with _IterationGuard(self):\n   for wr in self.data.values():\n    obj = wr()\n    if obj is not None:\n     yield obj\n     \n def popitem(self):\n  if self._pending_removals:\n   self._commit_removals()\n  while True:\n   key, wr = self.data.popitem()\n   o = wr()\n   if o is not None:\n    return key, o\n    \n def pop(self, key, *args):\n  if self._pending_removals:\n   self._commit_removals()\n  try:\n   o = self.data.pop(key)()\n  except KeyError:\n   if args:\n    return args[0]\n   raise\n  if o is None:\n   raise KeyError(key)\n  else:\n   return o\n   \n def setdefault(self, key, default=None):\n  try:\n   wr = self.data[key]\n  except KeyError:\n   if self._pending_removals:\n    self._commit_removals()\n   self.data[key] = KeyedRef(default, self._remove, key)\n   return default\n  else:\n   return wr()\n   \n def update(self, dict=None, **kwargs):\n  if self._pending_removals:\n   self._commit_removals()\n  d = self.data\n  if dict is not None:\n   if not hasattr(dict, \"items\"):\n    dict = type({})(dict)\n   for key, o in dict.items():\n    d[key] = KeyedRef(o, self._remove, key)\n  if len(kwargs):\n   self.update(kwargs)\n   \n def valuerefs(self):\n  \"\"\n  return list(self.data.values())\n  \n  \nclass KeyedRef(ref):\n \"\"\n \n __slots__ = \"key\",\n \n def __new__(type, ob, callback, key):\n  self = ref.__new__(type, ob, callback)\n  self.key = key\n  return self\n  \n def __init__(self, ob, callback, key):\n  super().__init__(ob, callback)\n  \n  \nclass WeakKeyDictionary(collections.MutableMapping):\n \"\"\n \n def __init__(self, dict=None):\n  self.data = {}\n  def remove(k, selfref=ref(self)):\n   self = selfref()\n   if self is not None:\n    if self._iterating:\n     self._pending_removals.append(k)\n    else:\n     del self.data[k]\n  self._remove = remove\n  \n  self._pending_removals = []\n  self._iterating = set()\n  if dict is not None:\n   self.update(dict)\n   \n def _commit_removals(self):\n \n \n \n \n  l = self._pending_removals\n  d = self.data\n  while l:\n   try:\n    del d[l.pop()]\n   except KeyError:\n    pass\n    \n def __delitem__(self, key):\n  del self.data[ref(key)]\n  \n def __getitem__(self, key):\n  return self.data[ref(key)]\n  \n def __len__(self):\n  return len(self.data) - len(self._pending_removals)\n  \n def __repr__(self):\n  return \"<WeakKeyDictionary at %s>\" % id(self)\n  \n def __setitem__(self, key, value):\n  self.data[ref(key, self._remove)] = value\n  \n def copy(self):\n  new = WeakKeyDictionary()\n  for key, value in self.data.items():\n   o = key()\n   if o is not None:\n    new[o] = value\n  return new\n  \n __copy__ = copy\n \n def __deepcopy__(self, memo):\n  from copy import deepcopy\n  new = self.__class__()\n  for key, value in self.data.items():\n   o = key()\n   if o is not None:\n    new[o] = deepcopy(value, memo)\n  return new\n  \n def get(self, key, default=None):\n  return self.data.get(ref(key),default)\n  \n def __contains__(self, key):\n  try:\n   wr = ref(key)\n  except TypeError:\n   return False\n  return wr in self.data\n  \n def items(self):\n  with _IterationGuard(self):\n   for wr, value in self.data.items():\n    key = wr()\n    if key is not None:\n     yield key, value\n     \n def keys(self):\n  with _IterationGuard(self):\n   for wr in self.data:\n    obj = wr()\n    if obj is not None:\n     yield obj\n     \n __iter__ = keys\n \n def values(self):\n  with _IterationGuard(self):\n   for wr, value in self.data.items():\n    if wr() is not None:\n     yield value\n     \n def keyrefs(self):\n  \"\"\n  return list(self.data)\n  \n def popitem(self):\n  while True:\n   key, value = self.data.popitem()\n   o = key()\n   if o is not None:\n    return o, value\n    \n def pop(self, key, *args):\n  return self.data.pop(ref(key), *args)\n  \n def setdefault(self, key, default=None):\n  return self.data.setdefault(ref(key, self._remove),default)\n  \n def update(self, dict=None, **kwargs):\n  d = self.data\n  if dict is not None:\n   if not hasattr(dict, \"items\"):\n    dict = type({})(dict)\n   for key, value in dict.items():\n    d[ref(key, self._remove)] = value\n  if len(kwargs):\n   self.update(kwargs)\n"], "unittest.result": [".py", "\"\"\n\nimport io\nimport sys\nimport traceback\n\nfrom . import util\nfrom functools import wraps\n\n__unittest = True\n\ndef failfast(method):\n @wraps(method)\n def inner(self, *args, **kw):\n  if getattr(self, 'failfast', False):\n   self.stop()\n  return method(self, *args, **kw)\n return inner\n \nSTDOUT_LINE = '\\nStdout:\\n%s'\nSTDERR_LINE = '\\nStderr:\\n%s'\n\n\nclass TestResult(object):\n \"\"\n _previousTestClass = None\n _testRunEntered = False\n _moduleSetUpFailed = False\n def __init__(self, stream=None, descriptions=None, verbosity=None):\n  self.failfast = False\n  self.failures = []\n  self.errors = []\n  self.testsRun = 0\n  self.skipped = []\n  self.expectedFailures = []\n  self.unexpectedSuccesses = []\n  self.shouldStop = False\n  self.buffer = False\n  self._stdout_buffer = None\n  self._stderr_buffer = None\n  self._original_stdout = sys.stdout\n  self._original_stderr = sys.stderr\n  self._mirrorOutput = False\n  \n def printErrors(self):\n  \"\"\n  \n  pass\n  \n def startTest(self, test):\n  \"\"\n  self.testsRun += 1\n  self._mirrorOutput = False\n  self._setupStdout()\n  \n def _setupStdout(self):\n  if self.buffer:\n   if self._stderr_buffer is None:\n    self._stderr_buffer = io.StringIO()\n    self._stdout_buffer = io.StringIO()\n   sys.stdout = self._stdout_buffer\n   sys.stderr = self._stderr_buffer\n   \n def startTestRun(self):\n  \"\"\n  \n def stopTest(self, test):\n  \"\"\n  self._restoreStdout()\n  self._mirrorOutput = False\n  \n def _restoreStdout(self):\n  if self.buffer:\n   if self._mirrorOutput:\n    output = sys.stdout.getvalue()\n    error = sys.stderr.getvalue()\n    if output:\n     if not output.endswith('\\n'):\n      output += '\\n'\n     self._original_stdout.write(STDOUT_LINE % output)\n    if error:\n     if not error.endswith('\\n'):\n      error += '\\n'\n     self._original_stderr.write(STDERR_LINE % error)\n     \n   sys.stdout = self._original_stdout\n   sys.stderr = self._original_stderr\n   self._stdout_buffer.seek(0)\n   self._stdout_buffer.truncate()\n   self._stderr_buffer.seek(0)\n   self._stderr_buffer.truncate()\n   \n def stopTestRun(self):\n  \"\"\n  \n @failfast\n def addError(self, test, err):\n  \"\"\n  self.errors.append((test, self._exc_info_to_string(err, test)))\n  self._mirrorOutput = True\n  \n @failfast\n def addFailure(self, test, err):\n  \"\"\n  self.failures.append((test, self._exc_info_to_string(err, test)))\n  self._mirrorOutput = True\n  \n def addSuccess(self, test):\n  \"\"\n  pass\n  \n def addSkip(self, test, reason):\n  \"\"\n  self.skipped.append((test, reason))\n  \n def addExpectedFailure(self, test, err):\n  \"\"\n  self.expectedFailures.append(\n  (test, self._exc_info_to_string(err, test)))\n  \n @failfast\n def addUnexpectedSuccess(self, test):\n  \"\"\n  self.unexpectedSuccesses.append(test)\n  \n def wasSuccessful(self):\n  \"\"\n  return len(self.failures) == len(self.errors) == 0\n  \n def stop(self):\n  \"\"\n  self.shouldStop = True\n  \n def _exc_info_to_string(self, err, test):\n  \"\"\n  exctype, value, tb = err\n  \n  while tb and self._is_relevant_tb_level(tb):\n   tb = tb.tb_next\n   \n  if exctype is test.failureException:\n  \n   length = self._count_relevant_tb_levels(tb)\n   msgLines = traceback.format_exception(exctype, value, tb, length)\n  else:\n   msgLines = traceback.format_exception(exctype, value, tb)\n   \n  if self.buffer:\n   output = sys.stdout.getvalue()\n   error = sys.stderr.getvalue()\n   if output:\n    if not output.endswith('\\n'):\n     output += '\\n'\n    msgLines.append(STDOUT_LINE % output)\n   if error:\n    if not error.endswith('\\n'):\n     error += '\\n'\n    msgLines.append(STDERR_LINE % error)\n  return ''.join(msgLines)\n  \n  \n def _is_relevant_tb_level(self, tb):\n \n \n  return True \n  \n def _count_relevant_tb_levels(self, tb):\n  length = 0\n  while tb and not self._is_relevant_tb_level(tb):\n   length += 1\n   tb = tb.tb_next\n  return length\n  \n def __repr__(self):\n  return (\"<%s run=%i errors=%i failures=%i>\" %\n  (util.strclass(self.__class__), self.testsRun, len(self.errors),\n  len(self.failures)))\n"], "xml.etree.ElementPath": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport re\n\nxpath_tokenizer_re = re.compile(\n\"(\"\n\"'[^']*'|\\\"[^\\\"]*\\\"|\"\n\"::|\"\n\"//?|\"\n\"\\.\\.|\"\n\"\\(\\)|\"\n\"[/.*:\\[\\]\\(\\)@=])|\"\n\"((?:\\{[^}]+\\})?[^/\\[\\]\\(\\)@=\\s]+)|\"\n\"\\s+\"\n)\n\ndef xpath_tokenizer(pattern, namespaces=None):\n for token in xpath_tokenizer_re.findall(pattern):\n  tag = token[1]\n  if tag and tag[0] != \"{\" and \":\" in tag:\n   try:\n    prefix, uri = tag.split(\":\", 1)\n    if not namespaces:\n     raise KeyError\n    yield token[0], \"{%s}%s\" % (namespaces[prefix], uri)\n   except KeyError:\n    raise SyntaxError(\"prefix %r not found in prefix map\" % prefix)\n  else:\n   yield token\n   \ndef get_parent_map(context):\n parent_map = context.parent_map\n if parent_map is None:\n  context.parent_map = parent_map = {}\n  for p in context.root.iter():\n   for e in p:\n    parent_map[e] = p\n return parent_map\n \ndef prepare_child(next, token):\n tag = token[1]\n def select(context, result):\n  for elem in result:\n   for e in elem:\n    if e.tag == tag:\n     yield e\n return select\n \ndef prepare_star(next, token):\n def select(context, result):\n  for elem in result:\n   for e in elem:\n    yield e\n return select\n \ndef prepare_self(next, token):\n def select(context, result):\n  for elem in result:\n   yield elem\n return select\n \ndef prepare_descendant(next, token):\n token = next()\n if token[0] == \"*\":\n  tag = \"*\"\n elif not token[0]:\n  tag = token[1]\n else:\n  raise SyntaxError(\"invalid descendant\")\n def select(context, result):\n  for elem in result:\n   for e in elem.iter(tag):\n    if e is not elem:\n     yield e\n return select\n \ndef prepare_parent(next, token):\n def select(context, result):\n \n  parent_map = get_parent_map(context)\n  result_map = {}\n  for elem in result:\n   if elem in parent_map:\n    parent = parent_map[elem]\n    if parent not in result_map:\n     result_map[parent] = None\n     yield parent\n return select\n \ndef prepare_predicate(next, token):\n\n\n\n signature = []\n predicate = []\n while 1:\n  token = next()\n  if token[0] == \"]\":\n   break\n  if token[0] and token[0][:1] in \"'\\\"\":\n   token = \"'\", token[0][1:-1]\n  signature.append(token[0] or \"-\")\n  predicate.append(token[1])\n signature = \"\".join(signature)\n \n if signature == \"@-\":\n \n  key = predicate[1]\n  def select(context, result):\n   for elem in result:\n    if elem.get(key) is not None:\n     yield elem\n  return select\n if signature == \"@-='\":\n \n  key = predicate[1]\n  value = predicate[-1]\n  def select(context, result):\n   for elem in result:\n    if elem.get(key) == value:\n     yield elem\n  return select\n if signature == \"-\" and not re.match(\"\\d+$\", predicate[0]):\n \n  tag = predicate[0]\n  def select(context, result):\n   for elem in result:\n    if elem.find(tag) is not None:\n     yield elem\n  return select\n if signature == \"-='\" and not re.match(\"\\d+$\", predicate[0]):\n \n  tag = predicate[0]\n  value = predicate[-1]\n  def select(context, result):\n   for elem in result:\n    for e in elem.findall(tag):\n     if \"\".join(e.itertext()) == value:\n      yield elem\n      break\n  return select\n if signature == \"-\" or signature == \"-()\" or signature == \"-()-\":\n \n  if signature == \"-\":\n   index = int(predicate[0]) - 1\n  else:\n   if predicate[0] != \"last\":\n    raise SyntaxError(\"unsupported function\")\n   if signature == \"-()-\":\n    try:\n     index = int(predicate[2]) - 1\n    except ValueError:\n     raise SyntaxError(\"unsupported expression\")\n   else:\n    index = -1\n  def select(context, result):\n   parent_map = get_parent_map(context)\n   for elem in result:\n    try:\n     parent = parent_map[elem]\n     \n     elems = list(parent.findall(elem.tag))\n     if elems[index] is elem:\n      yield elem\n    except (IndexError, KeyError):\n     pass\n  return select\n raise SyntaxError(\"invalid predicate\")\n \nops = {\n\"\": prepare_child,\n\"*\": prepare_star,\n\".\": prepare_self,\n\"..\": prepare_parent,\n\"//\": prepare_descendant,\n\"[\": prepare_predicate,\n}\n\n_cache = {}\n\nclass _SelectorContext:\n parent_map = None\n def __init__(self, root):\n  self.root = root\n  \n  \n  \n  \n  \n  \ndef iterfind(elem, path, namespaces=None):\n\n if path[-1:] == \"/\":\n  path = path + \"*\" \n try:\n  selector = _cache[path]\n except KeyError:\n  if len(_cache) > 100:\n   _cache.clear()\n  if path[:1] == \"/\":\n   raise SyntaxError(\"cannot use absolute path on element\")\n  next = iter(xpath_tokenizer(path, namespaces)).__next__\n  token = next()\n  selector = []\n  while 1:\n   try:\n    selector.append(ops[token[0]](next, token))\n   except StopIteration:\n    raise SyntaxError(\"invalid path\")\n   try:\n    token = next()\n    if token[0] == \"/\":\n     token = next()\n   except StopIteration:\n    break\n  _cache[path] = selector\n  \n result = [elem]\n context = _SelectorContext(elem)\n for select in selector:\n  result = select(context, result)\n return result\n \n \n \n \ndef find(elem, path, namespaces=None):\n try:\n  return next(iterfind(elem, path, namespaces))\n except StopIteration:\n  return None\n  \n  \n  \n  \ndef findall(elem, path, namespaces=None):\n return list(iterfind(elem, path, namespaces))\n \n \n \n \ndef findtext(elem, path, default=None, namespaces=None):\n try:\n  elem = next(iterfind(elem, path, namespaces))\n  return elem.text or \"\"\n except StopIteration:\n  return default\n"], "_weakrefset": [".py", "\n\n\n\nfrom _weakref import ref\n\n__all__ = ['WeakSet']\n\n\nclass _IterationGuard:\n\n\n\n\n\n def __init__(self, weakcontainer):\n \n  self.weakcontainer = ref(weakcontainer)\n  \n def __enter__(self):\n  w = self.weakcontainer()\n  if w is not None:\n   w._iterating.add(self)\n  return self\n  \n def __exit__(self, e, t, b):\n  w = self.weakcontainer()\n  if w is not None:\n   s = w._iterating\n   s.remove(self)\n   if not s:\n    w._commit_removals()\n    \n    \nclass WeakSet:\n def __init__(self, data=None):\n  self.data = set()\n  def _remove(item, selfref=ref(self)):\n   self = selfref()\n   if self is not None:\n    if self._iterating:\n     self._pending_removals.append(item)\n    else:\n     self.data.discard(item)\n  self._remove = _remove\n  \n  self._pending_removals = []\n  self._iterating = set()\n  if data is not None:\n   self.update(data)\n   \n def _commit_removals(self):\n  l = self._pending_removals\n  discard = self.data.discard\n  while l:\n   discard(l.pop())\n   \n def __iter__(self):\n  with _IterationGuard(self):\n   for itemref in self.data:\n    item = itemref()\n    if item is not None:\n     yield item\n     \n def __len__(self):\n  return len(self.data) - len(self._pending_removals)\n  \n def __contains__(self, item):\n  try:\n   wr = ref(item)\n  except TypeError:\n   return False\n  return wr in self.data\n  \n def __reduce__(self):\n  return (self.__class__, (list(self),),\n  getattr(self, '__dict__', None))\n  \n def add(self, item):\n  if self._pending_removals:\n   self._commit_removals()\n  self.data.add(ref(item, self._remove))\n  \n def clear(self):\n  if self._pending_removals:\n   self._commit_removals()\n  self.data.clear()\n  \n def copy(self):\n  return self.__class__(self)\n  \n def pop(self):\n  if self._pending_removals:\n   self._commit_removals()\n  while True:\n   try:\n    itemref = self.data.pop()\n   except KeyError:\n    raise KeyError('pop from empty WeakSet')\n   item = itemref()\n   if item is not None:\n    return item\n    \n def remove(self, item):\n  if self._pending_removals:\n   self._commit_removals()\n  self.data.remove(ref(item))\n  \n def discard(self, item):\n  if self._pending_removals:\n   self._commit_removals()\n  self.data.discard(ref(item))\n  \n def update(self, other):\n  if self._pending_removals:\n   self._commit_removals()\n  for element in other:\n   self.add(element)\n   \n def __ior__(self, other):\n  self.update(other)\n  return self\n  \n def difference(self, other):\n  newset = self.copy()\n  newset.difference_update(other)\n  return newset\n __sub__ = difference\n \n def difference_update(self, other):\n  self.__isub__(other)\n def __isub__(self, other):\n  if self._pending_removals:\n   self._commit_removals()\n  if self is other:\n   self.data.clear()\n  else:\n   self.data.difference_update(ref(item) for item in other)\n  return self\n  \n def intersection(self, other):\n  return self.__class__(item for item in other if item in self)\n __and__ = intersection\n \n def intersection_update(self, other):\n  self.__iand__(other)\n def __iand__(self, other):\n  if self._pending_removals:\n   self._commit_removals()\n  self.data.intersection_update(ref(item) for item in other)\n  return self\n  \n def issubset(self, other):\n  return self.data.issubset(ref(item) for item in other)\n __le__ = issubset\n \n def __lt__(self, other):\n  return self.data < set(ref(item) for item in other)\n  \n def issuperset(self, other):\n  return self.data.issuperset(ref(item) for item in other)\n __ge__ = issuperset\n \n def __gt__(self, other):\n  return self.data > set(ref(item) for item in other)\n  \n def __eq__(self, other):\n  if not isinstance(other, self.__class__):\n   return NotImplemented\n  return self.data == set(ref(item) for item in other)\n  \n def symmetric_difference(self, other):\n  newset = self.copy()\n  newset.symmetric_difference_update(other)\n  return newset\n __xor__ = symmetric_difference\n \n def symmetric_difference_update(self, other):\n  self.__ixor__(other)\n def __ixor__(self, other):\n  if self._pending_removals:\n   self._commit_removals()\n  if self is other:\n   self.data.clear()\n  else:\n   self.data.symmetric_difference_update(ref(item, self._remove) for item in other)\n  return self\n  \n def union(self, other):\n  return self.__class__(e for s in (self, other) for e in s)\n __or__ = union\n \n def isdisjoint(self, other):\n  return len(self.intersection(other)) == 0\n"], "_timer": [".js", "var $module = (function($B){\n\n    var _b_=$B.builtins\n    \n    function wrap(func){\n        // Transforms a function f into another function that prints a\n        // traceback in case of exception\n        return function(){\n            try{return func.apply(null,arguments)}\n            catch(err){\n                var exc = $B.exception(err)\n                var w = _b_.getattr($B.stderr,'write')\n                w(exc.info)\n                w('\\n'+exc.__name__)\n                if(exc.message){w(': '+exc.message)}\n                w('\\n')\n            }\n        }\n    }\n    \n    return {\n\n        __name__ : 'timer',\n    \n        clear_interval : function(int_id){window.clearInterval(int_id)},\n        \n        clear_timeout : function(timeout_id){window.clearTimeout(timeout_id)},\n    \n        set_interval : function(func,interval){\n            return _b_.int(window.setInterval(wrap(func),interval))\n        },\n        set_timeout : function(func,interval){\n            return _b_.int(window.setTimeout(wrap(func),interval))\n        },\n        request_animation_frame: function(func){\n            return _b_.int(window.requestAnimationFrame(func))\n        },\n        cancel_animation_frame: function(int_id){\n            window.cancelAnimationFrame(int_id)\n        }\n    }\n\n})(__BRYTHON__)\n"], "importlib._bootstrap": [".py", "\"\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n_CASE_INSENSITIVE_PLATFORMS = 'win', 'cygwin', 'darwin'\n\n\ndef _make_relax_case():\n if sys.platform.startswith(_CASE_INSENSITIVE_PLATFORMS):\n  def _relax_case():\n   \"\"\n   return b'PYTHONCASEOK' in _os.environ\n else:\n  def _relax_case():\n   \"\"\n   return False\n return _relax_case\n \n \n \ndef _w_long(x):\n \"\"\n x = int(x)\n int_bytes = []\n int_bytes.append(x & 0xFF)\n int_bytes.append((x >> 8) & 0xFF)\n int_bytes.append((x >> 16) & 0xFF)\n int_bytes.append((x >> 24) & 0xFF)\n return bytearray(int_bytes)\n \n \n \ndef _r_long(int_bytes):\n \"\"\n x = int_bytes[0]\n x |= int_bytes[1] << 8\n x |= int_bytes[2] << 16\n x |= int_bytes[3] << 24\n return x\n \n \ndef _path_join(*path_parts):\n \"\"\n new_parts = []\n for part in path_parts:\n  if not part:\n   continue\n  new_parts.append(part)\n  if part[-1] not in path_separators:\n   new_parts.append(path_sep)\n return ''.join(new_parts[:-1]) \n \n \ndef _path_split(path):\n \"\"\n for x in reversed(path):\n  if x in path_separators:\n   sep = x\n   break\n else:\n  sep = path_sep\n front, _, tail = path.rpartition(sep)\n return front, tail\n \n \ndef _path_is_mode_type(path, mode):\n \"\"\n try:\n  stat_info = _os.stat(path)\n except OSError:\n  return False\n return (stat_info.st_mode & 0o170000) == mode\n \n \n \ndef _path_isfile(path):\n \"\"\n return _path_is_mode_type(path, 0o100000)\n \n \n \ndef _path_isdir(path):\n \"\"\n if not path:\n  path = _os.getcwd()\n return _path_is_mode_type(path, 0o040000)\n \n \ndef _write_atomic(path, data, mode=0o666):\n \"\"\n \n path_tmp = '{}.{}'.format(path, id(path))\n fd = _os.open(path_tmp,\n _os.O_EXCL | _os.O_CREAT | _os.O_WRONLY, mode & 0o666)\n try:\n \n \n  with _io.FileIO(fd, 'wb') as file:\n   file.write(data)\n  _os.replace(path_tmp, path)\n except OSError:\n  try:\n   _os.unlink(path_tmp)\n  except OSError:\n   pass\n  raise\n  \n  \ndef _wrap(new, old):\n \"\"\n for replace in ['__module__', '__name__', '__qualname__', '__doc__']:\n  if hasattr(old, replace):\n   setattr(new, replace, getattr(old, replace))\n new.__dict__.update(old.__dict__)\n \n \n_code_type = type(_wrap.__code__)\n\n\ndef new_module(name):\n \"\"\n return type(_io)(name)\n \n \n \n \n \n_module_locks = {}\n\n_blocking_on = {}\n\n\nclass _DeadlockError(RuntimeError):\n pass\n \n \nclass _ModuleLock:\n \"\"\n \n def __init__(self, name):\n  self.lock = _thread.allocate_lock()\n  self.wakeup = _thread.allocate_lock()\n  self.name = name\n  self.owner = None\n  self.count = 0\n  self.waiters = 0\n  \n def has_deadlock(self):\n \n  me = _thread.get_ident()\n  tid = self.owner\n  while True:\n   lock = _blocking_on.get(tid)\n   if lock is None:\n    return False\n   tid = lock.owner\n   if tid == me:\n    return True\n    \n def acquire(self):\n  \"\"\n  tid = _thread.get_ident()\n  _blocking_on[tid] = self\n  try:\n   while True:\n    with self.lock:\n     if self.count == 0 or self.owner == tid:\n      self.owner = tid\n      self.count += 1\n      return True\n     if self.has_deadlock():\n      raise _DeadlockError(\"deadlock detected by %r\" % self)\n     if self.wakeup.acquire(False):\n      self.waiters += 1\n      \n    self.wakeup.acquire()\n    self.wakeup.release()\n  finally:\n   del _blocking_on[tid]\n   \n def release(self):\n  tid = _thread.get_ident()\n  with self.lock:\n   if self.owner != tid:\n    raise RuntimeError(\"cannot release un-acquired lock\")\n   assert self.count > 0\n   self.count -= 1\n   if self.count == 0:\n    self.owner = None\n    if self.waiters:\n     self.waiters -= 1\n     self.wakeup.release()\n     \n def __repr__(self):\n  return \"_ModuleLock(%r) at %d\" % (self.name, id(self))\n  \n  \nclass _DummyModuleLock:\n \"\"\n \n def __init__(self, name):\n  self.name = name\n  self.count = 0\n  \n def acquire(self):\n  self.count += 1\n  return True\n  \n def release(self):\n  if self.count == 0:\n   raise RuntimeError(\"cannot release un-acquired lock\")\n  self.count -= 1\n  \n def __repr__(self):\n  return \"_DummyModuleLock(%r) at %d\" % (self.name, id(self))\n  \n  \n  \n  \ndef _get_module_lock(name):\n \"\"\n lock = None\n try:\n  lock = _module_locks[name]()\n except KeyError:\n  pass\n if lock is None:\n  if _thread is None:\n   lock = _DummyModuleLock(name)\n  else:\n   lock = _ModuleLock(name)\n  def cb(_):\n   del _module_locks[name]\n  _module_locks[name] = _weakref.ref(lock, cb)\n return lock\n \ndef _lock_unlock_module(name):\n \"\"\n lock = _get_module_lock(name)\n _imp.release_lock()\n try:\n  lock.acquire()\n except _DeadlockError:\n \n \n  pass\n else:\n  lock.release()\n  \n  \n  \ndef _call_with_frames_removed(f, *args, **kwds):\n \"\"\n return f(*args, **kwds)\n \n \n \n \n\"\"\n_RAW_MAGIC_NUMBER = 3230 | ord('\\r') << 16 | ord('\\n') << 24\n_MAGIC_BYTES = bytes(_RAW_MAGIC_NUMBER >> n & 0xff for n in range(0, 25, 8))\n\n_PYCACHE = '__pycache__'\n\nSOURCE_SUFFIXES = ['.py'] \n\nDEBUG_BYTECODE_SUFFIXES = ['.pyc']\nOPTIMIZED_BYTECODE_SUFFIXES = ['.pyo']\n\ndef cache_from_source(path, debug_override=None):\n \"\"\n debug = not sys.flags.optimize if debug_override is None else debug_override\n if debug:\n  suffixes = DEBUG_BYTECODE_SUFFIXES\n else:\n  suffixes = OPTIMIZED_BYTECODE_SUFFIXES\n head, tail = _path_split(path)\n base_filename, sep, _ = tail.partition('.')\n tag = sys.implementation.cache_tag\n if tag is None:\n  raise NotImplementedError('sys.implementation.cache_tag is None')\n filename = ''.join([base_filename, sep, tag, suffixes[0]])\n return _path_join(head, _PYCACHE, filename)\n \n \ndef source_from_cache(path):\n \"\"\n if sys.implementation.cache_tag is None:\n  raise NotImplementedError('sys.implementation.cache_tag is None')\n head, pycache_filename = _path_split(path)\n head, pycache = _path_split(head)\n if pycache != _PYCACHE:\n  raise ValueError('{} not bottom-level directory in '\n  '{!r}'.format(_PYCACHE, path))\n if pycache_filename.count('.') != 2:\n  raise ValueError('expected only 2 dots in '\n  '{!r}'.format(pycache_filename))\n base_filename = pycache_filename.partition('.')[0]\n return _path_join(head, base_filename + SOURCE_SUFFIXES[0])\n \n \ndef _get_sourcefile(bytecode_path):\n \"\"\n if len(bytecode_path) == 0:\n  return None\n rest, _, extension = bytecode_path.rpartition('.')\n if not rest or extension.lower()[-3:-1] != 'py':\n  return bytecode_path\n try:\n  source_path = source_from_cache(bytecode_path)\n except (NotImplementedError, ValueError):\n  source_path = bytecode_path[:-1]\n return source_path if _path_isfile(source_path) else bytecode_path\n \n \ndef _verbose_message(message, *args, verbosity=1):\n \"\"\n if sys.flags.verbose >= verbosity:\n  if not message.startswith(('#', 'import ')):\n   message = '# ' + message\n  print(message.format(*args), file=sys.stderr)\n  \n  \ndef set_package(fxn):\n \"\"\n def set_package_wrapper(*args, **kwargs):\n  module = fxn(*args, **kwargs)\n  if getattr(module, '__package__', None) is None:\n   module.__package__ = module.__name__\n   if not hasattr(module, '__path__'):\n    module.__package__ = module.__package__.rpartition('.')[0]\n  return module\n _wrap(set_package_wrapper, fxn)\n return set_package_wrapper\n \n \ndef set_loader(fxn):\n \"\"\n def set_loader_wrapper(self, *args, **kwargs):\n  module = fxn(self, *args, **kwargs)\n  if not hasattr(module, '__loader__'):\n   module.__loader__ = self\n  return module\n _wrap(set_loader_wrapper, fxn)\n return set_loader_wrapper\n \n \ndef module_for_loader(fxn):\n \"\"\n def module_for_loader_wrapper(self, fullname, *args, **kwargs):\n  module = sys.modules.get(fullname)\n  is_reload = module is not None\n  if not is_reload:\n  \n  \n  \n   module = new_module(fullname)\n   \n   \n   module.__initializing__ = True\n   sys.modules[fullname] = module\n   module.__loader__ = self\n   try:\n    is_package = self.is_package(fullname)\n   except (ImportError, AttributeError):\n    pass\n   else:\n    if is_package:\n     module.__package__ = fullname\n    else:\n     module.__package__ = fullname.rpartition('.')[0]\n  else:\n   module.__initializing__ = True\n  try:\n  \n   return fxn(self, module, *args, **kwargs)\n  except:\n   if not is_reload:\n    del sys.modules[fullname]\n   raise\n  finally:\n   module.__initializing__ = False\n _wrap(module_for_loader_wrapper, fxn)\n return module_for_loader_wrapper\n \n \ndef _check_name(method):\n \"\"\n def _check_name_wrapper(self, name=None, *args, **kwargs):\n  if name is None:\n   name = self.name\n  elif self.name != name:\n   raise ImportError(\"loader cannot handle %s\" % name, name=name)\n  return method(self, name, *args, **kwargs)\n _wrap(_check_name_wrapper, method)\n return _check_name_wrapper\n \n \ndef _requires_builtin(fxn):\n \"\"\n def _requires_builtin_wrapper(self, fullname):\n  if fullname not in sys.builtin_module_names:\n   raise ImportError(\"{} is not a built-in module\".format(fullname),\n   name=fullname)\n  return fxn(self, fullname)\n _wrap(_requires_builtin_wrapper, fxn)\n return _requires_builtin_wrapper\n \n \ndef _requires_frozen(fxn):\n \"\"\n def _requires_frozen_wrapper(self, fullname):\n  if not _imp.is_frozen(fullname):\n   raise ImportError(\"{} is not a frozen module\".format(fullname),\n   name=fullname)\n  return fxn(self, fullname)\n _wrap(_requires_frozen_wrapper, fxn)\n return _requires_frozen_wrapper\n \n \ndef _find_module_shim(self, fullname):\n \"\"\n \n \n \n loader, portions = self.find_loader(fullname)\n if loader is None and len(portions):\n  msg = \"Not importing directory {}: missing __init__\"\n  _warnings.warn(msg.format(portions[0]), ImportWarning)\n return loader\n \n \n \n \n \n \nclass BuiltinImporter:\n\n \"\"\n \n @classmethod\n def module_repr(cls, module):\n  return \"<module '{}' (built-in)>\".format(module.__name__)\n  \n @classmethod\n def find_module(cls, fullname, path=None):\n  \"\"\n  if path is not None:\n   return None\n  return cls if _imp.is_builtin(fullname) else None\n  \n @classmethod\n @set_package\n @set_loader\n @_requires_builtin\n def load_module(cls, fullname):\n  \"\"\n  is_reload = fullname in sys.modules\n  try:\n   return _call_with_frames_removed(_imp.init_builtin, fullname)\n  except:\n   if not is_reload and fullname in sys.modules:\n    del sys.modules[fullname]\n   raise\n   \n @classmethod\n @_requires_builtin\n def get_code(cls, fullname):\n  \"\"\n  return None\n  \n @classmethod\n @_requires_builtin\n def get_source(cls, fullname):\n  \"\"\n  return None\n  \n @classmethod\n @_requires_builtin\n def is_package(cls, fullname):\n  \"\"\n  return False\n  \n  \nclass FrozenImporter:\n\n \"\"\n \n @classmethod\n def module_repr(cls, m):\n  return \"<module '{}' (frozen)>\".format(m.__name__)\n  \n @classmethod\n def find_module(cls, fullname, path=None):\n  \"\"\n  return cls if _imp.is_frozen(fullname) else None\n  \n @classmethod\n @set_package\n @set_loader\n @_requires_frozen\n def load_module(cls, fullname):\n  \"\"\n  is_reload = fullname in sys.modules\n  try:\n   m = _call_with_frames_removed(_imp.init_frozen, fullname)\n   \n   del m.__file__\n   return m\n  except:\n   if not is_reload and fullname in sys.modules:\n    del sys.modules[fullname]\n   raise\n   \n @classmethod\n @_requires_frozen\n def get_code(cls, fullname):\n  \"\"\n  return _imp.get_frozen_object(fullname)\n  \n @classmethod\n @_requires_frozen\n def get_source(cls, fullname):\n  \"\"\n  return None\n  \n @classmethod\n @_requires_frozen\n def is_package(cls, fullname):\n  \"\"\n  return _imp.is_frozen_package(fullname)\n  \n  \nclass WindowsRegistryFinder:\n\n \"\"\n \n REGISTRY_KEY = (\n \"Software\\\\Python\\\\PythonCore\\\\{sys_version}\"\n \"\\\\Modules\\\\{fullname}\")\n REGISTRY_KEY_DEBUG = (\n \"Software\\\\Python\\\\PythonCore\\\\{sys_version}\"\n \"\\\\Modules\\\\{fullname}\\\\Debug\")\n DEBUG_BUILD = False \n \n @classmethod\n def _open_registry(cls, key):\n  try:\n   return _winreg.OpenKey(_winreg.HKEY_CURRENT_USER, key)\n  except WindowsError:\n   return _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE, key)\n   \n @classmethod\n def _search_registry(cls, fullname):\n  if cls.DEBUG_BUILD:\n   registry_key = cls.REGISTRY_KEY_DEBUG\n  else:\n   registry_key = cls.REGISTRY_KEY\n  key = registry_key.format(fullname=fullname,\n  sys_version=sys.version[:3])\n  try:\n   with cls._open_registry(key) as hkey:\n    filepath = _winreg.QueryValue(hkey, \"\")\n  except WindowsError:\n   return None\n  return filepath\n  \n @classmethod\n def find_module(cls, fullname, path=None):\n  \"\"\n  filepath = cls._search_registry(fullname)\n  if filepath is None:\n   return None\n  try:\n   _os.stat(filepath)\n  except OSError:\n   return None\n  for loader, suffixes in _get_supported_file_loaders():\n   if filepath.endswith(tuple(suffixes)):\n    return loader(fullname, filepath)\n    \n    \nclass _LoaderBasics:\n\n \"\"\n \n def is_package(self, fullname):\n  \"\"\n  filename = _path_split(self.get_filename(fullname))[1]\n  filename_base = filename.rsplit('.', 1)[0]\n  tail_name = fullname.rpartition('.')[2]\n  return filename_base == '__init__' and tail_name != '__init__'\n  \n def _bytes_from_bytecode(self, fullname, data, bytecode_path, source_stats):\n  \"\"\n  magic = data[:4]\n  raw_timestamp = data[4:8]\n  raw_size = data[8:12]\n  if magic != _MAGIC_BYTES:\n   msg = 'bad magic number in {!r}: {!r}'.format(fullname, magic)\n   _verbose_message(msg)\n   raise ImportError(msg, name=fullname, path=bytecode_path)\n  elif len(raw_timestamp) != 4:\n   message = 'bad timestamp in {}'.format(fullname)\n   _verbose_message(message)\n   raise EOFError(message)\n  elif len(raw_size) != 4:\n   message = 'bad size in {}'.format(fullname)\n   _verbose_message(message)\n   raise EOFError(message)\n  if source_stats is not None:\n   try:\n    source_mtime = int(source_stats['mtime'])\n   except KeyError:\n    pass\n   else:\n    if _r_long(raw_timestamp) != source_mtime:\n     message = 'bytecode is stale for {}'.format(fullname)\n     _verbose_message(message)\n     raise ImportError(message, name=fullname,\n     path=bytecode_path)\n   try:\n    source_size = source_stats['size'] & 0xFFFFFFFF\n   except KeyError:\n    pass\n   else:\n    if _r_long(raw_size) != source_size:\n     raise ImportError(\n     \"bytecode is stale for {}\".format(fullname),\n     name=fullname, path=bytecode_path)\n     \n     \n  return data[12:]\n  \n @module_for_loader\n def _load_module(self, module, *, sourceless=False):\n  \"\"\n  name = module.__name__\n  code_object = self.get_code(name)\n  module.__file__ = self.get_filename(name)\n  if not sourceless:\n   try:\n    module.__cached__ = cache_from_source(module.__file__)\n   except NotImplementedError:\n    module.__cached__ = module.__file__\n  else:\n   module.__cached__ = module.__file__\n  module.__package__ = name\n  if self.is_package(name):\n   module.__path__ = [_path_split(module.__file__)[0]]\n  else:\n   module.__package__ = module.__package__.rpartition('.')[0]\n  module.__loader__ = self\n  _call_with_frames_removed(exec, code_object, module.__dict__)\n  return module\n  \n  \nclass SourceLoader(_LoaderBasics):\n\n def path_mtime(self, path):\n  \"\"\n  raise NotImplementedError\n  \n def path_stats(self, path):\n  \"\"\n  return {'mtime': self.path_mtime(path)}\n  \n def _cache_bytecode(self, source_path, cache_path, data):\n  \"\"\n  \n  return self.set_data(cache_path, data)\n  \n def set_data(self, path, data):\n  \"\"\n  raise NotImplementedError\n  \n  \n def get_source(self, fullname):\n  \"\"\n  import tokenize\n  path = self.get_filename(fullname)\n  try:\n   source_bytes = self.get_data(path)\n  except IOError as exc:\n   raise ImportError(\"source not available through get_data()\",\n   name=fullname) from exc\n  readsource = _io.BytesIO(source_bytes).readline\n  try:\n   encoding = tokenize.detect_encoding(readsource)\n  except SyntaxError as exc:\n   raise ImportError(\"Failed to detect encoding\",\n   name=fullname) from exc\n  newline_decoder = _io.IncrementalNewlineDecoder(None, True)\n  try:\n   return newline_decoder.decode(source_bytes.decode(encoding[0]))\n  except UnicodeDecodeError as exc:\n   raise ImportError(\"Failed to decode source file\",\n   name=fullname) from exc\n   \n def get_code(self, fullname):\n  \"\"\n  source_path = self.get_filename(fullname)\n  source_mtime = None\n  try:\n   bytecode_path = cache_from_source(source_path)\n  except NotImplementedError:\n   bytecode_path = None\n  else:\n   try:\n    st = self.path_stats(source_path)\n   except NotImplementedError:\n    pass\n   else:\n    source_mtime = int(st['mtime'])\n    try:\n     data = self.get_data(bytecode_path)\n    except IOError:\n     pass\n    else:\n     try:\n      bytes_data = self._bytes_from_bytecode(fullname, data,\n      bytecode_path,\n      st)\n     except (ImportError, EOFError):\n      pass\n     else:\n      _verbose_message('{} matches {}', bytecode_path,\n      source_path)\n      found = marshal.loads(bytes_data)\n      if isinstance(found, _code_type):\n       _imp._fix_co_filename(found, source_path)\n       _verbose_message('code object from {}',\n       bytecode_path)\n       return found\n      else:\n       msg = \"Non-code object in {}\"\n       raise ImportError(msg.format(bytecode_path),\n       name=fullname, path=bytecode_path)\n  source_bytes = self.get_data(source_path)\n  code_object = _call_with_frames_removed(compile,\n  source_bytes, source_path, 'exec',\n  dont_inherit=True)\n  _verbose_message('code object from {}', source_path)\n  if (not sys.dont_write_bytecode and bytecode_path is not None and\n  source_mtime is not None):\n   data = bytearray(_MAGIC_BYTES)\n   data.extend(_w_long(source_mtime))\n   data.extend(_w_long(len(source_bytes)))\n   data.extend(marshal.dumps(code_object))\n   try:\n    self._cache_bytecode(source_path, bytecode_path, data)\n    _verbose_message('wrote {!r}', bytecode_path)\n   except NotImplementedError:\n    pass\n  return code_object\n  \n def load_module(self, fullname):\n  \"\"\n  return self._load_module(fullname)\n  \n  \nclass FileLoader:\n\n \"\"\n \n def __init__(self, fullname, path):\n  \"\"\n  self.name = fullname\n  self.path = path\n  \n @_check_name\n def load_module(self, fullname):\n  \"\"\n  \n  \n  return super(FileLoader, self).load_module(fullname)\n  \n @_check_name\n def get_filename(self, fullname):\n  \"\"\n  return self.path\n  \n def get_data(self, path):\n  \"\"\n  with _io.FileIO(path, 'r') as file:\n   return file.read()\n   \n   \nclass SourceFileLoader(FileLoader, SourceLoader):\n\n \"\"\n \n def path_stats(self, path):\n  \"\"\n  st = _os.stat(path)\n  return {'mtime': st.st_mtime, 'size': st.st_size}\n  \n def _cache_bytecode(self, source_path, bytecode_path, data):\n \n  try:\n   mode = _os.stat(source_path).st_mode\n  except OSError:\n   mode = 0o666\n   \n   \n  mode |= 0o200\n  return self.set_data(bytecode_path, data, _mode=mode)\n  \n def set_data(self, path, data, *, _mode=0o666):\n  \"\"\n  parent, filename = _path_split(path)\n  path_parts = []\n  \n  while parent and not _path_isdir(parent):\n   parent, part = _path_split(parent)\n   path_parts.append(part)\n   \n  for part in reversed(path_parts):\n   parent = _path_join(parent, part)\n   try:\n    _os.mkdir(parent)\n   except FileExistsError:\n   \n    continue\n   except OSError as exc:\n   \n   \n    _verbose_message('could not create {!r}: {!r}', parent, exc)\n    return\n  try:\n   _write_atomic(path, data, _mode)\n   _verbose_message('created {!r}', path)\n  except OSError as exc:\n  \n   _verbose_message('could not create {!r}: {!r}', path, exc)\n   \n   \nclass SourcelessFileLoader(FileLoader, _LoaderBasics):\n\n \"\"\n \n def load_module(self, fullname):\n  return self._load_module(fullname, sourceless=True)\n  \n def get_code(self, fullname):\n  path = self.get_filename(fullname)\n  data = self.get_data(path)\n  bytes_data = self._bytes_from_bytecode(fullname, data, path, None)\n  found = marshal.loads(bytes_data)\n  if isinstance(found, _code_type):\n   _verbose_message('code object from {!r}', path)\n   return found\n  else:\n   raise ImportError(\"Non-code object in {}\".format(path),\n   name=fullname, path=path)\n   \n def get_source(self, fullname):\n  \"\"\n  return None\n  \n  \n  \nEXTENSION_SUFFIXES = []\n\n\nclass ExtensionFileLoader:\n\n \"\"\n \n def __init__(self, name, path):\n  self.name = name\n  self.path = path\n  \n @_check_name\n @set_package\n @set_loader\n def load_module(self, fullname):\n  \"\"\n  is_reload = fullname in sys.modules\n  try:\n   module = _call_with_frames_removed(_imp.load_dynamic,\n   fullname, self.path)\n   _verbose_message('extension module loaded from {!r}', self.path)\n   if self.is_package(fullname) and not hasattr(module, '__path__'):\n    module.__path__ = [_path_split(self.path)[0]]\n   return module\n  except:\n   if not is_reload and fullname in sys.modules:\n    del sys.modules[fullname]\n   raise\n   \n def is_package(self, fullname):\n  \"\"\n  file_name = _path_split(self.path)[1]\n  return any(file_name == '__init__' + suffix\n  for suffix in EXTENSION_SUFFIXES)\n  \n def get_code(self, fullname):\n  \"\"\n  return None\n  \n def get_source(self, fullname):\n  \"\"\n  return None\n  \n  \nclass _NamespacePath:\n \"\"\n \n def __init__(self, name, path, path_finder):\n  self._name = name\n  self._path = path\n  self._last_parent_path = tuple(self._get_parent_path())\n  self._path_finder = path_finder\n  \n def _find_parent_path_names(self):\n  \"\"\n  parent, dot, me = self._name.rpartition('.')\n  if dot == '':\n  \n   return 'sys', 'path'\n   \n   \n  return parent, '__path__'\n  \n def _get_parent_path(self):\n  parent_module_name, path_attr_name = self._find_parent_path_names()\n  return getattr(sys.modules[parent_module_name], path_attr_name)\n  \n def _recalculate(self):\n \n  parent_path = tuple(self._get_parent_path()) \n  if parent_path != self._last_parent_path:\n   loader, new_path = self._path_finder(self._name, parent_path)\n   \n   \n   if loader is None:\n    self._path = new_path\n   self._last_parent_path = parent_path \n  return self._path\n  \n def __iter__(self):\n  return iter(self._recalculate())\n  \n def __len__(self):\n  return len(self._recalculate())\n  \n def __repr__(self):\n  return \"_NamespacePath({!r})\".format(self._path)\n  \n def __contains__(self, item):\n  return item in self._recalculate()\n  \n def append(self, item):\n  self._path.append(item)\n  \n  \nclass NamespaceLoader:\n def __init__(self, name, path, path_finder):\n  self._path = _NamespacePath(name, path, path_finder)\n  \n @classmethod\n def module_repr(cls, module):\n  return \"<module '{}' (namespace)>\".format(module.__name__)\n  \n @module_for_loader\n def load_module(self, module):\n  \"\"\n  _verbose_message('namespace module loaded with path {!r}', self._path)\n  module.__path__ = self._path\n  return module\n  \n  \n  \n  \nclass PathFinder:\n\n \"\"\n \n @classmethod\n def invalidate_caches(cls):\n  \"\"\n  for finder in sys.path_importer_cache.values():\n   if hasattr(finder, 'invalidate_caches'):\n    finder.invalidate_caches()\n    \n @classmethod\n def _path_hooks(cls, path):\n  \"\"\n  if not sys.path_hooks:\n   _warnings.warn('sys.path_hooks is empty', ImportWarning)\n  for hook in sys.path_hooks:\n   try:\n    return hook(path)\n   except ImportError:\n    continue\n  else:\n   return None\n   \n @classmethod\n def _path_importer_cache(cls, path):\n  \"\"\n  if path == '':\n   path = '.'\n  try:\n   finder = sys.path_importer_cache[path]\n  except KeyError:\n   finder = cls._path_hooks(path)\n   sys.path_importer_cache[path] = finder\n  return finder\n  \n @classmethod\n def _get_loader(cls, fullname, path):\n  \"\"\n  \n  \n  namespace_path = []\n  for entry in path:\n   if not isinstance(entry, (str, bytes)):\n    continue\n   finder = cls._path_importer_cache(entry)\n   if finder is not None:\n    if hasattr(finder, 'find_loader'):\n     loader, portions = finder.find_loader(fullname)\n    else:\n     loader = finder.find_module(fullname)\n     portions = []\n    if loader is not None:\n    \n     return loader, namespace_path\n     \n     \n     \n     \n    namespace_path.extend(portions)\n  else:\n   return None, namespace_path\n   \n @classmethod\n def find_module(cls, fullname, path=None):\n  \"\"\n  if path is None:\n   path = sys.path\n  loader, namespace_path = cls._get_loader(fullname, path)\n  if loader is not None:\n   return loader\n  else:\n   if namespace_path:\n   \n   \n    return NamespaceLoader(fullname, namespace_path, cls._get_loader)\n   else:\n    return None\n    \n    \nclass FileFinder:\n\n \"\"\n \n def __init__(self, path, *loader_details):\n  \"\"\n  loaders = []\n  for loader, suffixes in loader_details:\n   loaders.extend((suffix, loader) for suffix in suffixes)\n  self._loaders = loaders\n  \n  self.path = path or '.'\n  self._path_mtime = -1\n  self._path_cache = set()\n  self._relaxed_path_cache = set()\n  \n def invalidate_caches(self):\n  \"\"\n  self._path_mtime = -1\n  \n find_module = _find_module_shim\n \n def find_loader(self, fullname):\n  \"\"\n  is_namespace = False\n  tail_module = fullname.rpartition('.')[2]\n  try:\n   mtime = _os.stat(self.path).st_mtime\n  except OSError:\n   mtime = -1\n  if mtime != self._path_mtime:\n   self._fill_cache()\n   self._path_mtime = mtime\n   \n  if _relax_case():\n   cache = self._relaxed_path_cache\n   cache_module = tail_module.lower()\n  else:\n   cache = self._path_cache\n   cache_module = tail_module\n   \n  if cache_module in cache:\n   base_path = _path_join(self.path, tail_module)\n   if _path_isdir(base_path):\n    for suffix, loader in self._loaders:\n     init_filename = '__init__' + suffix\n     full_path = _path_join(base_path, init_filename)\n     if _path_isfile(full_path):\n      return (loader(fullname, full_path), [base_path])\n    else:\n    \n    \n     is_namespace = True\n     \n  for suffix, loader in self._loaders:\n   full_path = _path_join(self.path, tail_module + suffix)\n   _verbose_message('trying {}'.format(full_path), verbosity=2)\n   if cache_module + suffix in cache:\n    if _path_isfile(full_path):\n     return (loader(fullname, full_path), [])\n  if is_namespace:\n   _verbose_message('possible namespace for {}'.format(base_path))\n   return (None, [base_path])\n  return (None, [])\n  \n def _fill_cache(self):\n  \"\"\n  path = self.path\n  try:\n   contents = _os.listdir(path)\n  except (FileNotFoundError, PermissionError, NotADirectoryError):\n  \n  \n   contents = []\n   \n   \n  if not sys.platform.startswith('win'):\n   self._path_cache = set(contents)\n  else:\n  \n  \n  \n  \n  \n   lower_suffix_contents = set()\n   for item in contents:\n    name, dot, suffix = item.partition('.')\n    if dot:\n     new_name = '{}.{}'.format(name, suffix.lower())\n    else:\n     new_name = name\n    lower_suffix_contents.add(new_name)\n   self._path_cache = lower_suffix_contents\n  if sys.platform.startswith(_CASE_INSENSITIVE_PLATFORMS):\n   self._relaxed_path_cache = set(fn.lower() for fn in contents)\n   \n @classmethod\n def path_hook(cls, *loader_details):\n  \"\"\n  def path_hook_for_FileFinder(path):\n   \"\"\n   if not _path_isdir(path):\n    raise ImportError(\"only directories are supported\", path=path)\n   return cls(path, *loader_details)\n   \n  return path_hook_for_FileFinder\n  \n def __repr__(self):\n  return \"FileFinder(%r)\" % (self.path,)\n  \n  \n  \n  \nclass _ImportLockContext:\n\n \"\"\n \n def __enter__(self):\n  \"\"\n  _imp.acquire_lock()\n  \n def __exit__(self, exc_type, exc_value, exc_traceback):\n  \"\"\n  _imp.release_lock()\n  \n  \ndef _resolve_name(name, package, level):\n \"\"\n bits = package.rsplit('.', level - 1)\n if len(bits) < level:\n  raise ValueError('attempted relative import beyond top-level package')\n base = bits[0]\n return '{}.{}'.format(base, name) if name else base\n \n \ndef _find_module(name, path):\n \"\"\n if not sys.meta_path:\n  _warnings.warn('sys.meta_path is empty', ImportWarning)\n for finder in sys.meta_path:\n  with _ImportLockContext():\n   loader = finder.find_module(name, path)\n  if loader is not None:\n  \n   if name not in sys.modules:\n    return loader\n   else:\n    return sys.modules[name].__loader__\n else:\n  return None\n  \n  \ndef _sanity_check(name, package, level):\n \"\"\n if not isinstance(name, str):\n  raise TypeError(\"module name must be str, not {}\".format(type(name)))\n if level < 0:\n  raise ValueError('level must be >= 0')\n if package:\n  if not isinstance(package, str):\n   raise TypeError(\"__package__ not set to a string\")\n  elif package not in sys.modules:\n   msg = (\"Parent module {!r} not loaded, cannot perform relative \"\n   \"import\")\n   raise SystemError(msg.format(package))\n if not name and level == 0:\n  raise ValueError(\"Empty module name\")\n  \n  \n_ERR_MSG = 'No module named {!r}'\n\ndef _find_and_load_unlocked(name, import_):\n path = None\n parent = name.rpartition('.')[0]\n if parent:\n  if parent not in sys.modules:\n   _call_with_frames_removed(import_, parent)\n   \n  if name in sys.modules:\n   return sys.modules[name]\n   \n  parent_module = sys.modules[parent]\n  try:\n   path = parent_module.__path__\n  except AttributeError:\n   msg = (_ERR_MSG + '; {} is not a package').format(name, parent)\n   raise ImportError(msg, name=name)\n loader = _find_module(name, path)\n if loader is None:\n  exc = ImportError(_ERR_MSG.format(name), name=name)\n  \n  \n  exc._not_found = True\n  raise exc\n elif name not in sys.modules:\n \n  loader.load_module(name)\n  _verbose_message('import {!r} # {!r}', name, loader)\n  \n module = sys.modules[name]\n if parent:\n \n  parent_module = sys.modules[parent]\n  setattr(parent_module, name.rpartition('.')[2], module)\n  \n if getattr(module, '__package__', None) is None:\n  try:\n   module.__package__ = module.__name__\n   if not hasattr(module, '__path__'):\n    module.__package__ = module.__package__.rpartition('.')[0]\n  except AttributeError:\n   pass\n   \n if not hasattr(module, '__loader__'):\n  try:\n   module.__loader__ = loader\n  except AttributeError:\n   pass\n return module\n \n \ndef _find_and_load(name, import_):\n \"\"\n try:\n  lock = _get_module_lock(name)\n finally:\n  _imp.release_lock()\n lock.acquire()\n try:\n  return _find_and_load_unlocked(name, import_)\n finally:\n  lock.release()\n  \n  \ndef _gcd_import(name, package=None, level=0):\n \"\"\n _sanity_check(name, package, level)\n if level > 0:\n  name = _resolve_name(name, package, level)\n _imp.acquire_lock()\n if name not in sys.modules:\n  return _find_and_load(name, _gcd_import)\n module = sys.modules[name]\n if module is None:\n  _imp.release_lock()\n  message = (\"import of {} halted; \"\n  \"None in sys.modules\".format(name))\n  raise ImportError(message, name=name)\n _lock_unlock_module(name)\n return module\n \ndef _handle_fromlist(module, fromlist, import_):\n \"\"\n \n \n if hasattr(module, '__path__'):\n  if '*' in fromlist:\n   fromlist = list(fromlist)\n   fromlist.remove('*')\n   if hasattr(module, '__all__'):\n    fromlist.extend(module.__all__)\n  for x in fromlist:\n   if not hasattr(module, x):\n    from_name = '{}.{}'.format(module.__name__, x)\n    try:\n     _call_with_frames_removed(import_, from_name)\n    except ImportError as exc:\n    \n    \n    \n    \n    \n     if getattr(exc, '_not_found', False):\n      if exc.name == from_name:\n       continue\n     raise\n return module\n \n \ndef _calc___package__(globals):\n \"\"\n package = globals.get('__package__')\n if package is None:\n  package = globals['__name__']\n  if '__path__' not in globals:\n   package = package.rpartition('.')[0]\n return package\n \n \ndef _get_supported_file_loaders():\n \"\"\n extensions = ExtensionFileLoader, _imp.extension_suffixes()\n source = SourceFileLoader, SOURCE_SUFFIXES\n bytecode = SourcelessFileLoader, BYTECODE_SUFFIXES\n return [extensions, source, bytecode]\n \n \ndef __import__(name, globals=None, locals=None, fromlist=(), level=0):\n \"\"\n if level == 0:\n  module = _gcd_import(name)\n else:\n  globals_ = globals if globals is not None else {}\n  package = _calc___package__(globals_)\n  module = _gcd_import(name, package, level)\n if not fromlist:\n \n \n  if level == 0:\n   return _gcd_import(name.partition('.')[0])\n  elif not name:\n   return module\n  else:\n  \n  \n   cut_off = len(name) - len(name.partition('.')[0])\n   \n   \n   return sys.modules[module.__name__[:len(module.__name__)-cut_off]]\n else:\n  return _handle_fromlist(module, fromlist, _gcd_import)\n  \n  \n  \ndef _setup(sys_module, _imp_module):\n \"\"\n \n global _imp, sys, BYTECODE_SUFFIXES\n _imp = _imp_module\n sys = sys_module\n \n if sys.flags.optimize:\n  BYTECODE_SUFFIXES = OPTIMIZED_BYTECODE_SUFFIXES\n else:\n  BYTECODE_SUFFIXES = DEBUG_BYTECODE_SUFFIXES\n  \n module_type = type(sys)\n for name, module in sys.modules.items():\n  if isinstance(module, module_type):\n   if not hasattr(module, '__loader__'):\n    if name in sys.builtin_module_names:\n     module.__loader__ = BuiltinImporter\n     \n     \n     \n     \n self_module = sys.modules[__name__]\n for builtin_name in ('_io', '_warnings', 'builtins', 'marshal'):\n  if builtin_name not in sys.modules:\n   builtin_module = BuiltinImporter.load_module(builtin_name)\n  else:\n   builtin_module = sys.modules[builtin_name]\n  setattr(self_module, builtin_name, builtin_module)\n  \n os_details = ('posix', ['/']), ('nt', ['\\\\', '/']), ('os2', ['\\\\', '/'])\n for builtin_os, path_separators in os_details:\n \n  assert all(len(sep) == 1 for sep in path_separators)\n  path_sep = path_separators[0]\n  if builtin_os in sys.modules:\n   os_module = sys.modules[builtin_os]\n   break\n  else:\n   try:\n    os_module = BuiltinImporter.load_module(builtin_os)\n    \n    if builtin_os == 'os2' and 'EMX GCC' in sys.version:\n     path_sep = path_separators[1]\n    break\n   except ImportError:\n    continue\n else:\n  raise ImportError('importlib requires posix or nt')\n  \n try:\n  thread_module = BuiltinImporter.load_module('_thread')\n except ImportError:\n \n  thread_module = None\n weakref_module = BuiltinImporter.load_module('_weakref')\n \n if builtin_os == 'nt':\n  winreg_module = BuiltinImporter.load_module('winreg')\n  setattr(self_module, '_winreg', winreg_module)\n  \n setattr(self_module, '_os', os_module)\n setattr(self_module, '_thread', thread_module)\n setattr(self_module, '_weakref', weakref_module)\n setattr(self_module, 'path_sep', path_sep)\n setattr(self_module, 'path_separators', set(path_separators))\n \n setattr(self_module, '_relax_case', _make_relax_case())\n EXTENSION_SUFFIXES.extend(_imp.extension_suffixes())\n if builtin_os == 'nt':\n  SOURCE_SUFFIXES.append('.pyw')\n  if '_d.pyd' in EXTENSION_SUFFIXES:\n   WindowsRegistryFinder.DEBUG_BUILD = True\n   \ndef _install(sys_module, _imp_module):\n \"\"\n _setup(sys_module, _imp_module)\n supported_loaders = _get_supported_file_loaders()\n sys.path_hooks.extend([FileFinder.path_hook(*supported_loaders)])\n sys.meta_path.append(BuiltinImporter)\n sys.meta_path.append(FrozenImporter)\n if _os.__name__ == 'nt':\n  sys.meta_path.append(WindowsRegistryFinder)\n sys.meta_path.append(PathFinder)\n"], "_abcoll": [".py", "\n\n\n\"\"\n\nfrom abc import ABCMeta, abstractmethod\nimport sys\n\n__all__ = [\"Hashable\", \"Iterable\", \"Iterator\",\n\"Sized\", \"Container\", \"Callable\",\n\"Set\", \"MutableSet\",\n\"Mapping\", \"MutableMapping\",\n\"MappingView\", \"KeysView\", \"ItemsView\", \"ValuesView\",\n\"Sequence\", \"MutableSequence\",\n\"ByteString\",\n]\n\n\"\"\n\ndef abstractmethod(self):\n return self\n \n \n \n \n \nclass Iterable:\n\n @abstractmethod\n def __iter__(self):\n  while False:\n   yield None\n   \n @classmethod\n def __subclasshook__(cls, C):\n  if cls is Iterable:\n   if any(\"__iter__\" in B.__dict__ for B in C.__mro__):\n    return True\n  return NotImplemented\n  \n  \n  \nclass Sized:\n\n @abstractmethod\n def __len__(self):\n  return 0\n  \n @classmethod\n def __subclasshook__(cls, C):\n  if cls is Sized:\n   if any(\"__len__\" in B.__dict__ for B in C.__mro__):\n    return True\n  return NotImplemented\n  \n  \n  \nclass Container:\n\n @abstractmethod\n def __contains__(self, x):\n  return False\n  \n @classmethod\n def __subclasshook__(cls, C):\n  if cls is Container:\n   if any(\"__contains__\" in B.__dict__ for B in C.__mro__):\n    return True\n  return NotImplemented\n  \n  \n  \n  \nclass Mapping(Sized, Iterable, Container):\n\n @abstractmethod\n def __getitem__(self, key):\n  raise KeyError\n  \n def get(self, key, default=None):\n  try:\n   return self[key]\n  except KeyError:\n   return default\n   \n def __contains__(self, key):\n  try:\n   self[key]\n  except KeyError:\n   return False\n  else:\n   return True\n   \n def keys(self):\n  return KeysView(self)\n  \n def items(self):\n  return ItemsView(self)\n  \n def values(self):\n  return ValuesView(self)\n  \n def __eq__(self, other):\n  if not isinstance(other, Mapping):\n   return NotImplemented\n  return dict(self.items()) == dict(other.items())\n  \n def __ne__(self, other):\n  return not (self == other)\n  \n  \nclass MutableMapping(Mapping):\n\n @abstractmethod\n def __setitem__(self, key, value):\n  raise KeyError\n  \n @abstractmethod\n def __delitem__(self, key):\n  raise KeyError\n  \n __marker = object()\n \n def pop(self, key, default=__marker):\n  try:\n   value = self[key]\n  except KeyError:\n   if default is self.__marker:\n    raise\n   return default\n  else:\n   del self[key]\n   return value\n   \n def popitem(self):\n  try:\n   key = next(iter(self))\n  except StopIteration:\n   raise KeyError\n  value = self[key]\n  del self[key]\n  return key, value\n  \n def clear(self):\n  try:\n   while True:\n    self.popitem()\n  except KeyError:\n   pass\n   \n def update(*args, **kwds):\n  if len(args) > 2:\n   raise TypeError(\"update() takes at most 2 positional \"\n   \"arguments ({} given)\".format(len(args)))\n  elif not args:\n   raise TypeError(\"update() takes at least 1 argument (0 given)\")\n  self = args[0]\n  other = args[1] if len(args) >= 2 else ()\n  \n  if isinstance(other, Mapping):\n   for key in other:\n    self[key] = other[key]\n  elif hasattr(other, \"keys\"):\n   for key in other.keys():\n    self[key] = other[key]\n  else:\n   for key, value in other:\n    self[key] = value\n  for key, value in kwds.items():\n   self[key] = value\n   \n def setdefault(self, key, default=None):\n  try:\n   return self[key]\n  except KeyError:\n   self[key] = default\n  return default\n  \n  \n"], "xml.dom.minicompat": [".py", "\"\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n__all__ = [\"NodeList\", \"EmptyNodeList\", \"StringTypes\", \"defproperty\"]\n\nimport xml.dom\n\nStringTypes = (str,)\n\n\nclass NodeList(list):\n __slots__ = ()\n \n def item(self, index):\n  if 0 <= index < len(self):\n   return self[index]\n   \n def _get_length(self):\n  return len(self)\n  \n def _set_length(self, value):\n  raise xml.dom.NoModificationAllowedErr(\n  \"attempt to modify read-only attribute 'length'\")\n  \n length = property(_get_length, _set_length,\n doc=\"The number of nodes in the NodeList.\")\n \n def __getstate__(self):\n  return list(self)\n  \n def __setstate__(self, state):\n  self[:] = state\n  \n  \nclass EmptyNodeList(tuple):\n __slots__ = ()\n \n def __add__(self, other):\n  NL = NodeList()\n  NL.extend(other)\n  return NL\n  \n def __radd__(self, other):\n  NL = NodeList()\n  NL.extend(other)\n  return NL\n  \n def item(self, index):\n  return None\n  \n def _get_length(self):\n  return 0\n  \n def _set_length(self, value):\n  raise xml.dom.NoModificationAllowedErr(\n  \"attempt to modify read-only attribute 'length'\")\n  \n length = property(_get_length, _set_length,\n doc=\"The number of nodes in the NodeList.\")\n \n \ndef defproperty(klass, name, doc):\n get = getattr(klass, (\"_get_\" + name))\n def set(self, value, name=name):\n  raise xml.dom.NoModificationAllowedErr(\n  \"attempt to modify read-only attribute \" + repr(name))\n assert not hasattr(klass, \"_set_\" + name), \"expected not to find _set_\" + name\n prop = property(get, set, doc=doc)\n setattr(klass, name, prop)\n"], "test": [".py", "\n", 1], "getopt": [".py", "\"\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n__all__ = [\"GetoptError\",\"error\",\"getopt\",\"gnu_getopt\"]\n\nimport os\ntry:\n from gettext import gettext as _\nexcept ImportError:\n\n def _(s): return s\n \nclass GetoptError(Exception):\n opt = ''\n msg = ''\n def __init__(self, msg, opt=''):\n  self.msg = msg\n  self.opt = opt\n  Exception.__init__(self, msg, opt)\n  \n def __str__(self):\n  return self.msg\n  \nerror = GetoptError \n\ndef getopt(args, shortopts, longopts = []):\n \"\"\n \n opts = []\n if type(longopts) == type(\"\"):\n  longopts = [longopts]\n else:\n  longopts = list(longopts)\n while args and args[0].startswith('-') and args[0] != '-':\n  if args[0] == '--':\n   args = args[1:]\n   break\n  if args[0].startswith('--'):\n   opts, args = do_longs(opts, args[0][2:], longopts, args[1:])\n  else:\n   opts, args = do_shorts(opts, args[0][1:], shortopts, args[1:])\n   \n return opts, args\n \ndef gnu_getopt(args, shortopts, longopts = []):\n \"\"\n \n opts = []\n prog_args = []\n if isinstance(longopts, str):\n  longopts = [longopts]\n else:\n  longopts = list(longopts)\n  \n  \n if shortopts.startswith('+'):\n  shortopts = shortopts[1:]\n  all_options_first = True\n elif os.environ.get(\"POSIXLY_CORRECT\"):\n  all_options_first = True\n else:\n  all_options_first = False\n  \n while args:\n  if args[0] == '--':\n   prog_args += args[1:]\n   break\n   \n  if args[0][:2] == '--':\n   opts, args = do_longs(opts, args[0][2:], longopts, args[1:])\n  elif args[0][:1] == '-' and args[0] != '-':\n   opts, args = do_shorts(opts, args[0][1:], shortopts, args[1:])\n  else:\n   if all_options_first:\n    prog_args += args\n    break\n   else:\n    prog_args.append(args[0])\n    args = args[1:]\n    \n return opts, prog_args\n \ndef do_longs(opts, opt, longopts, args):\n try:\n  i = opt.index('=')\n except ValueError:\n  optarg = None\n else:\n  opt, optarg = opt[:i], opt[i+1:]\n  \n has_arg, opt = long_has_args(opt, longopts)\n if has_arg:\n  if optarg is None:\n   if not args:\n    raise GetoptError(_('option --%s requires argument') % opt, opt)\n   optarg, args = args[0], args[1:]\n elif optarg is not None:\n  raise GetoptError(_('option --%s must not have an argument') % opt, opt)\n opts.append(('--' + opt, optarg or ''))\n return opts, args\n \n \n \n \ndef long_has_args(opt, longopts):\n possibilities = [o for o in longopts if o.startswith(opt)]\n if not possibilities:\n  raise GetoptError(_('option --%s not recognized') % opt, opt)\n  \n if opt in possibilities:\n  return False, opt\n elif opt + '=' in possibilities:\n  return True, opt\n  \n if len(possibilities) > 1:\n \n \n  raise GetoptError(_('option --%s not a unique prefix') % opt, opt)\n assert len(possibilities) == 1\n unique_match = possibilities[0]\n has_arg = unique_match.endswith('=')\n if has_arg:\n  unique_match = unique_match[:-1]\n return has_arg, unique_match\n \ndef do_shorts(opts, optstring, shortopts, args):\n while optstring != '':\n  opt, optstring = optstring[0], optstring[1:]\n  if short_has_arg(opt, shortopts):\n   if optstring == '':\n    if not args:\n     raise GetoptError(_('option -%s requires argument') % opt,\n     opt)\n    optstring, args = args[0], args[1:]\n   optarg, optstring = optstring, ''\n  else:\n   optarg = ''\n  opts.append(('-' + opt, optarg))\n return opts, args\n \ndef short_has_arg(opt, shortopts):\n for i in range(len(shortopts)):\n  if opt == shortopts[i] != ':':\n   return shortopts.startswith(':', i+1)\n raise GetoptError(_('option -%s not recognized') % opt, opt)\n \nif __name__ == '__main__':\n import sys\n print(getopt(sys.argv[1:], \"a:b\", [\"alpha=\", \"beta\"]))\n"], "csv": [".py", "\n\"\"\n\nimport re\nfrom _csv import Error, __version__, writer, reader, register_dialect, unregister_dialect, get_dialect, list_dialects, field_size_limit, QUOTE_MINIMAL, QUOTE_ALL, QUOTE_NONNUMERIC, QUOTE_NONE, __doc__\nfrom _csv import Dialect as _Dialect\n\nfrom io import StringIO\n\n__all__ = [ \"QUOTE_MINIMAL\", \"QUOTE_ALL\", \"QUOTE_NONNUMERIC\", \"QUOTE_NONE\",\n\"Error\", \"Dialect\", \"__doc__\", \"excel\", \"excel_tab\",\n\"field_size_limit\", \"reader\", \"writer\",\n\"register_dialect\", \"get_dialect\", \"list_dialects\", \"Sniffer\",\n\"unregister_dialect\", \"__version__\", \"DictReader\", \"DictWriter\" ]\n\nclass Dialect:\n \"\"\n _name = \"\"\n _valid = False\n \n delimiter = None\n quotechar = None\n escapechar = None\n doublequote = None\n skipinitialspace = None\n lineterminator = None\n quoting = None\n \n def __init__(self):\n  if self.__class__ != Dialect:\n   self._valid = True\n  self._validate()\n  \n def _validate(self):\n  try:\n   _Dialect(self)\n  except TypeError as e:\n  \n   raise Error(str(e))\n   \nclass excel(Dialect):\n \"\"\n delimiter = ','\n quotechar = '\"'\n doublequote = True\n skipinitialspace = False\n lineterminator = '\\r\\n'\n quoting = QUOTE_MINIMAL\nregister_dialect(\"excel\", excel)\n\nclass excel_tab(excel):\n \"\"\n delimiter = '\\t'\nregister_dialect(\"excel-tab\", excel_tab)\n\nclass unix_dialect(Dialect):\n \"\"\n delimiter = ','\n quotechar = '\"'\n doublequote = True\n skipinitialspace = False\n lineterminator = '\\n'\n quoting = QUOTE_ALL\nregister_dialect(\"unix\", unix_dialect)\n\n\nclass DictReader:\n def __init__(self, f, fieldnames=None, restkey=None, restval=None,\n dialect=\"excel\", *args, **kwds):\n  self._fieldnames = fieldnames \n  self.restkey = restkey \n  self.restval = restval \n  self.reader = reader(f, dialect, *args, **kwds)\n  self.dialect = dialect\n  self.line_num = 0\n  \n def __iter__(self):\n  return self\n  \n @property\n def fieldnames(self):\n  if self._fieldnames is None:\n   try:\n    self._fieldnames = next(self.reader)\n   except StopIteration:\n    pass\n  self.line_num = self.reader.line_num\n  return self._fieldnames\n  \n @fieldnames.setter\n def fieldnames(self, value):\n  self._fieldnames = value\n  \n def __next__(self):\n  if self.line_num == 0:\n  \n   self.fieldnames\n  row = next(self.reader)\n  self.line_num = self.reader.line_num\n  \n  \n  \n  \n  while row == []:\n   row = next(self.reader)\n  d = dict(zip(self.fieldnames, row))\n  lf = len(self.fieldnames)\n  lr = len(row)\n  if lf < lr:\n   d[self.restkey] = row[lf:]\n  elif lf > lr:\n   for key in self.fieldnames[lr:]:\n    d[key] = self.restval\n  return d\n  \n  \nclass DictWriter:\n def __init__(self, f, fieldnames, restval=\"\", extrasaction=\"raise\",\n dialect=\"excel\", *args, **kwds):\n  self.fieldnames = fieldnames \n  self.restval = restval \n  if extrasaction.lower() not in (\"raise\", \"ignore\"):\n   raise ValueError(\"extrasaction (%s) must be 'raise' or 'ignore'\"\n   % extrasaction)\n  self.extrasaction = extrasaction\n  self.writer = writer(f, dialect, *args, **kwds)\n  \n def writeheader(self):\n  header = dict(zip(self.fieldnames, self.fieldnames))\n  self.writerow(header)\n  \n def _dict_to_list(self, rowdict):\n  if self.extrasaction == \"raise\":\n   wrong_fields = [k for k in rowdict if k not in self.fieldnames]\n   if wrong_fields:\n    raise ValueError(\"dict contains fields not in fieldnames: \"\n    + \", \".join(wrong_fields))\n  return [rowdict.get(key, self.restval) for key in self.fieldnames]\n  \n def writerow(self, rowdict):\n  return self.writer.writerow(self._dict_to_list(rowdict))\n  \n def writerows(self, rowdicts):\n  rows = []\n  for rowdict in rowdicts:\n   rows.append(self._dict_to_list(rowdict))\n  return self.writer.writerows(rows)\n  \n  \ntry:\n complex\nexcept NameError:\n complex = float\n \nclass Sniffer:\n \"\"\n def __init__(self):\n \n  self.preferred = [',', '\\t', ';', ' ', ':']\n  \n  \n def sniff(self, sample, delimiters=None):\n  \"\"\n  \n  quotechar, doublequote, delimiter, skipinitialspace = self._guess_quote_and_delimiter(sample, delimiters)\n  if not delimiter:\n   delimiter, skipinitialspace = self._guess_delimiter(sample,\n   delimiters)\n   \n  if not delimiter:\n   raise Error(\"Could not determine delimiter\")\n   \n  class dialect(Dialect):\n   _name = \"sniffed\"\n   lineterminator = '\\r\\n'\n   quoting = QUOTE_MINIMAL\n   \n   \n  dialect.doublequote = doublequote\n  dialect.delimiter = delimiter\n  \n  dialect.quotechar = quotechar or '\"'\n  dialect.skipinitialspace = skipinitialspace\n  \n  return dialect\n  \n  \n def _guess_quote_and_delimiter(self, data, delimiters):\n  \"\"\n  \n  matches = []\n  for restr in ('(?P<delim>[^\\w\\n\"\\'])(?P<space> ?)(?P<quote>[\"\\']).*?(?P=quote)(?P=delim)', \n  '(?:^|\\n)(?P<quote>[\"\\']).*?(?P=quote)(?P<delim>[^\\w\\n\"\\'])(?P<space> ?)', \n  '(?P<delim>>[^\\w\\n\"\\'])(?P<space> ?)(?P<quote>[\"\\']).*?(?P=quote)(?:$|\\n)', \n  '(?:^|\\n)(?P<quote>[\"\\']).*?(?P=quote)(?:$|\\n)'): \n   regexp = re.compile(restr, re.DOTALL | re.MULTILINE)\n   matches = regexp.findall(data)\n   if matches:\n    break\n    \n  if not matches:\n  \n   return ('', False, None, 0)\n  quotes = {}\n  delims = {}\n  spaces = 0\n  for m in matches:\n   n = regexp.groupindex['quote'] - 1\n   key = m[n]\n   if key:\n    quotes[key] = quotes.get(key, 0) + 1\n   try:\n    n = regexp.groupindex['delim'] - 1\n    key = m[n]\n   except KeyError:\n    continue\n   if key and (delimiters is None or key in delimiters):\n    delims[key] = delims.get(key, 0) + 1\n   try:\n    n = regexp.groupindex['space'] - 1\n   except KeyError:\n    continue\n   if m[n]:\n    spaces += 1\n    \n  quotechar = max(quotes, key=quotes.get)\n  \n  if delims:\n   delim = max(delims, key=delims.get)\n   skipinitialspace = delims[delim] == spaces\n   if delim == '\\n': \n    delim = ''\n  else:\n  \n   delim = ''\n   skipinitialspace = 0\n   \n   \n   \n  dq_regexp = re.compile(\n  r\"((%(delim)s)|^)\\W*%(quote)s[^%(delim)s\\n]*%(quote)s[^%(delim)s\\n]*%(quote)s\\W*((%(delim)s)|$)\" % {'delim':re.escape(delim), 'quote':quotechar}, re.MULTILINE)\n  \n  \n  \n  if dq_regexp.search(data):\n   doublequote = True\n  else:\n   doublequote = False\n   \n  return (quotechar, doublequote, delim, skipinitialspace)\n  \n  \n def _guess_delimiter(self, data, delimiters):\n  \"\"\n  \n  data = list(filter(None, data.split('\\n')))\n  \n  ascii = [chr(c) for c in range(127)] \n  \n  \n  chunkLength = min(10, len(data))\n  iteration = 0\n  charFrequency = {}\n  modes = {}\n  delims = {}\n  start, end = 0, min(chunkLength, len(data))\n  while start < len(data):\n   iteration += 1\n   for line in data[start:end]:\n    for char in ascii:\n     metaFrequency = charFrequency.get(char, {})\n     \n     freq = line.count(char)\n     \n     metaFrequency[freq] = metaFrequency.get(freq, 0) + 1\n     charFrequency[char] = metaFrequency\n     \n   for char in charFrequency.keys():\n    items = list(charFrequency[char].items())\n    if len(items) == 1 and items[0][0] == 0:\n     continue\n     \n    if len(items) > 1:\n     modes[char] = max(items, key=lambda x: x[1])\n     \n     \n     items.remove(modes[char])\n     modes[char] = (modes[char][0], modes[char][1]\n     - sum(item[1] for item in items))\n    else:\n     modes[char] = items[0]\n     \n     \n   modeList = modes.items()\n   total = float(chunkLength * iteration)\n   \n   consistency = 1.0\n   \n   threshold = 0.9\n   while len(delims) == 0 and consistency >= threshold:\n    for k, v in modeList:\n     if v[0] > 0 and v[1] > 0:\n      if ((v[1]/total) >= consistency and\n      (delimiters is None or k in delimiters)):\n       delims[k] = v\n    consistency -= 0.01\n    \n   if len(delims) == 1:\n    delim = list(delims.keys())[0]\n    skipinitialspace = (data[0].count(delim) ==\n    data[0].count(\"%c \" % delim))\n    return (delim, skipinitialspace)\n    \n    \n   start = end\n   end += chunkLength\n   \n  if not delims:\n   return ('', 0)\n   \n   \n  if len(delims) > 1:\n   for d in self.preferred:\n    if d in delims.keys():\n     skipinitialspace = (data[0].count(d) ==\n     data[0].count(\"%c \" % d))\n     return (d, skipinitialspace)\n     \n     \n     \n  items = [(v,k) for (k,v) in delims.items()]\n  items.sort()\n  delim = items[-1][1]\n  \n  skipinitialspace = (data[0].count(delim) ==\n  data[0].count(\"%c \" % delim))\n  return (delim, skipinitialspace)\n  \n  \n def has_header(self, sample):\n \n \n \n \n \n \n \n \n \n  rdr = reader(StringIO(sample), self.sniff(sample))\n  \n  header = next(rdr) \n  \n  columns = len(header)\n  columnTypes = {}\n  for i in range(columns): columnTypes[i] = None\n  \n  checked = 0\n  for row in rdr:\n  \n   if checked > 20:\n    break\n   checked += 1\n   \n   if len(row) != columns:\n    continue \n    \n   for col in list(columnTypes.keys()):\n   \n    for thisType in [int, float, complex]:\n     try:\n      thisType(row[col])\n      break\n     except (ValueError, OverflowError):\n      pass\n    else:\n    \n     thisType = len(row[col])\n     \n    if thisType != columnTypes[col]:\n     if columnTypes[col] is None: \n      columnTypes[col] = thisType\n     else:\n     \n     \n      del columnTypes[col]\n      \n      \n      \n  hasHeader = 0\n  for col, colType in columnTypes.items():\n   if type(colType) == type(0): \n    if len(header[col]) != colType:\n     hasHeader += 1\n    else:\n     hasHeader -= 1\n   else: \n    try:\n     colType(header[col])\n    except (ValueError, TypeError):\n     hasHeader += 1\n    else:\n     hasHeader -= 1\n     \n  return hasHeader > 0\n"], "crypto_js.rollups.sha3": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(v,p){var d={},u=d.lib={},r=function(){},f=u.Base={extend:function(a){r.prototype=this;var b=new r;a&&b.mixIn(a);b.hasOwnProperty(\"init\")||(b.init=function(){b.$super.init.apply(this,arguments)});b.init.prototype=b;b.$super=this;return b},create:function(){var a=this.extend();a.init.apply(a,arguments);return a},init:function(){},mixIn:function(a){for(var b in a)a.hasOwnProperty(b)&&(this[b]=a[b]);a.hasOwnProperty(\"toString\")&&(this.toString=a.toString)},clone:function(){return this.init.prototype.extend(this)}},\ns=u.WordArray=f.extend({init:function(a,b){a=this.words=a||[];this.sigBytes=b!=p?b:4*a.length},toString:function(a){return(a||y).stringify(this)},concat:function(a){var b=this.words,c=a.words,j=this.sigBytes;a=a.sigBytes;this.clamp();if(j%4)for(var n=0;n<a;n++)b[j+n>>>2]|=(c[n>>>2]>>>24-8*(n%4)&255)<<24-8*((j+n)%4);else if(65535<c.length)for(n=0;n<a;n+=4)b[j+n>>>2]=c[n>>>2];else b.push.apply(b,c);this.sigBytes+=a;return this},clamp:function(){var a=this.words,b=this.sigBytes;a[b>>>2]&=4294967295<<\n32-8*(b%4);a.length=v.ceil(b/4)},clone:function(){var a=f.clone.call(this);a.words=this.words.slice(0);return a},random:function(a){for(var b=[],c=0;c<a;c+=4)b.push(4294967296*v.random()|0);return new s.init(b,a)}}),x=d.enc={},y=x.Hex={stringify:function(a){var b=a.words;a=a.sigBytes;for(var c=[],j=0;j<a;j++){var n=b[j>>>2]>>>24-8*(j%4)&255;c.push((n>>>4).toString(16));c.push((n&15).toString(16))}return c.join(\"\")},parse:function(a){for(var b=a.length,c=[],j=0;j<b;j+=2)c[j>>>3]|=parseInt(a.substr(j,\n2),16)<<24-4*(j%8);return new s.init(c,b/2)}},e=x.Latin1={stringify:function(a){var b=a.words;a=a.sigBytes;for(var c=[],j=0;j<a;j++)c.push(String.fromCharCode(b[j>>>2]>>>24-8*(j%4)&255));return c.join(\"\")},parse:function(a){for(var b=a.length,c=[],j=0;j<b;j++)c[j>>>2]|=(a.charCodeAt(j)&255)<<24-8*(j%4);return new s.init(c,b)}},q=x.Utf8={stringify:function(a){try{return decodeURIComponent(escape(e.stringify(a)))}catch(b){throw Error(\"Malformed UTF-8 data\");}},parse:function(a){return e.parse(unescape(encodeURIComponent(a)))}},\nt=u.BufferedBlockAlgorithm=f.extend({reset:function(){this._data=new s.init;this._nDataBytes=0},_append:function(a){\"string\"==typeof a&&(a=q.parse(a));this._data.concat(a);this._nDataBytes+=a.sigBytes},_process:function(a){var b=this._data,c=b.words,j=b.sigBytes,n=this.blockSize,e=j/(4*n),e=a?v.ceil(e):v.max((e|0)-this._minBufferSize,0);a=e*n;j=v.min(4*a,j);if(a){for(var f=0;f<a;f+=n)this._doProcessBlock(c,f);f=c.splice(0,a);b.sigBytes-=j}return new s.init(f,j)},clone:function(){var a=f.clone.call(this);\na._data=this._data.clone();return a},_minBufferSize:0});u.Hasher=t.extend({cfg:f.extend(),init:function(a){this.cfg=this.cfg.extend(a);this.reset()},reset:function(){t.reset.call(this);this._doReset()},update:function(a){this._append(a);this._process();return this},finalize:function(a){a&&this._append(a);return this._doFinalize()},blockSize:16,_createHelper:function(a){return function(b,c){return(new a.init(c)).finalize(b)}},_createHmacHelper:function(a){return function(b,c){return(new w.HMAC.init(a,\nc)).finalize(b)}}});var w=d.algo={};return d}(Math);\n(function(v){var p=CryptoJS,d=p.lib,u=d.Base,r=d.WordArray,p=p.x64={};p.Word=u.extend({init:function(f,s){this.high=f;this.low=s}});p.WordArray=u.extend({init:function(f,s){f=this.words=f||[];this.sigBytes=s!=v?s:8*f.length},toX32:function(){for(var f=this.words,s=f.length,d=[],p=0;p<s;p++){var e=f[p];d.push(e.high);d.push(e.low)}return r.create(d,this.sigBytes)},clone:function(){for(var f=u.clone.call(this),d=f.words=this.words.slice(0),p=d.length,r=0;r<p;r++)d[r]=d[r].clone();return f}})})();\n(function(v){for(var p=CryptoJS,d=p.lib,u=d.WordArray,r=d.Hasher,f=p.x64.Word,d=p.algo,s=[],x=[],y=[],e=1,q=0,t=0;24>t;t++){s[e+5*q]=(t+1)*(t+2)/2%64;var w=(2*e+3*q)%5,e=q%5,q=w}for(e=0;5>e;e++)for(q=0;5>q;q++)x[e+5*q]=q+5*((2*e+3*q)%5);e=1;for(q=0;24>q;q++){for(var a=w=t=0;7>a;a++){if(e&1){var b=(1<<a)-1;32>b?w^=1<<b:t^=1<<b-32}e=e&128?e<<1^113:e<<1}y[q]=f.create(t,w)}for(var c=[],e=0;25>e;e++)c[e]=f.create();d=d.SHA3=r.extend({cfg:r.cfg.extend({outputLength:512}),_doReset:function(){for(var a=this._state=\n[],b=0;25>b;b++)a[b]=new f.init;this.blockSize=(1600-2*this.cfg.outputLength)/32},_doProcessBlock:function(a,b){for(var e=this._state,f=this.blockSize/2,h=0;h<f;h++){var l=a[b+2*h],m=a[b+2*h+1],l=(l<<8|l>>>24)&16711935|(l<<24|l>>>8)&4278255360,m=(m<<8|m>>>24)&16711935|(m<<24|m>>>8)&4278255360,g=e[h];g.high^=m;g.low^=l}for(f=0;24>f;f++){for(h=0;5>h;h++){for(var d=l=0,k=0;5>k;k++)g=e[h+5*k],l^=g.high,d^=g.low;g=c[h];g.high=l;g.low=d}for(h=0;5>h;h++){g=c[(h+4)%5];l=c[(h+1)%5];m=l.high;k=l.low;l=g.high^\n(m<<1|k>>>31);d=g.low^(k<<1|m>>>31);for(k=0;5>k;k++)g=e[h+5*k],g.high^=l,g.low^=d}for(m=1;25>m;m++)g=e[m],h=g.high,g=g.low,k=s[m],32>k?(l=h<<k|g>>>32-k,d=g<<k|h>>>32-k):(l=g<<k-32|h>>>64-k,d=h<<k-32|g>>>64-k),g=c[x[m]],g.high=l,g.low=d;g=c[0];h=e[0];g.high=h.high;g.low=h.low;for(h=0;5>h;h++)for(k=0;5>k;k++)m=h+5*k,g=e[m],l=c[m],m=c[(h+1)%5+5*k],d=c[(h+2)%5+5*k],g.high=l.high^~m.high&d.high,g.low=l.low^~m.low&d.low;g=e[0];h=y[f];g.high^=h.high;g.low^=h.low}},_doFinalize:function(){var a=this._data,\nb=a.words,c=8*a.sigBytes,e=32*this.blockSize;b[c>>>5]|=1<<24-c%32;b[(v.ceil((c+1)/e)*e>>>5)-1]|=128;a.sigBytes=4*b.length;this._process();for(var a=this._state,b=this.cfg.outputLength/8,c=b/8,e=[],h=0;h<c;h++){var d=a[h],f=d.high,d=d.low,f=(f<<8|f>>>24)&16711935|(f<<24|f>>>8)&4278255360,d=(d<<8|d>>>24)&16711935|(d<<24|d>>>8)&4278255360;e.push(d);e.push(f)}return new u.init(e,b)},clone:function(){for(var a=r.clone.call(this),b=a._state=this._state.slice(0),c=0;25>c;c++)b[c]=b[c].clone();return a}});\np.SHA3=r._createHelper(d);p.HmacSHA3=r._createHmacHelper(d)})(Math);\n"], "crypto_js.rollups.sha1": [".js", "/*\nCryptoJS v3.1.2\ncode.google.com/p/crypto-js\n(c) 2009-2013 by Jeff Mott. All rights reserved.\ncode.google.com/p/crypto-js/wiki/License\n*/\nvar CryptoJS=CryptoJS||function(e,m){var p={},j=p.lib={},l=function(){},f=j.Base={extend:function(a){l.prototype=this;var c=new l;a&&c.mixIn(a);c.hasOwnProperty(\"init\")||(c.init=function(){c.$super.init.apply(this,arguments)});c.init.prototype=c;c.$super=this;return c},create:function(){var a=this.extend();a.init.apply(a,arguments);return a},init:function(){},mixIn:function(a){for(var c in a)a.hasOwnProperty(c)&&(this[c]=a[c]);a.hasOwnProperty(\"toString\")&&(this.toString=a.toString)},clone:function(){return this.init.prototype.extend(this)}},\nn=j.WordArray=f.extend({init:function(a,c){a=this.words=a||[];this.sigBytes=c!=m?c:4*a.length},toString:function(a){return(a||h).stringify(this)},concat:function(a){var c=this.words,q=a.words,d=this.sigBytes;a=a.sigBytes;this.clamp();if(d%4)for(var b=0;b<a;b++)c[d+b>>>2]|=(q[b>>>2]>>>24-8*(b%4)&255)<<24-8*((d+b)%4);else if(65535<q.length)for(b=0;b<a;b+=4)c[d+b>>>2]=q[b>>>2];else c.push.apply(c,q);this.sigBytes+=a;return this},clamp:function(){var a=this.words,c=this.sigBytes;a[c>>>2]&=4294967295<<\n32-8*(c%4);a.length=e.ceil(c/4)},clone:function(){var a=f.clone.call(this);a.words=this.words.slice(0);return a},random:function(a){for(var c=[],b=0;b<a;b+=4)c.push(4294967296*e.random()|0);return new n.init(c,a)}}),b=p.enc={},h=b.Hex={stringify:function(a){var c=a.words;a=a.sigBytes;for(var b=[],d=0;d<a;d++){var f=c[d>>>2]>>>24-8*(d%4)&255;b.push((f>>>4).toString(16));b.push((f&15).toString(16))}return b.join(\"\")},parse:function(a){for(var c=a.length,b=[],d=0;d<c;d+=2)b[d>>>3]|=parseInt(a.substr(d,\n2),16)<<24-4*(d%8);return new n.init(b,c/2)}},g=b.Latin1={stringify:function(a){var c=a.words;a=a.sigBytes;for(var b=[],d=0;d<a;d++)b.push(String.fromCharCode(c[d>>>2]>>>24-8*(d%4)&255));return b.join(\"\")},parse:function(a){for(var c=a.length,b=[],d=0;d<c;d++)b[d>>>2]|=(a.charCodeAt(d)&255)<<24-8*(d%4);return new n.init(b,c)}},r=b.Utf8={stringify:function(a){try{return decodeURIComponent(escape(g.stringify(a)))}catch(c){throw Error(\"Malformed UTF-8 data\");}},parse:function(a){return g.parse(unescape(encodeURIComponent(a)))}},\nk=j.BufferedBlockAlgorithm=f.extend({reset:function(){this._data=new n.init;this._nDataBytes=0},_append:function(a){\"string\"==typeof a&&(a=r.parse(a));this._data.concat(a);this._nDataBytes+=a.sigBytes},_process:function(a){var c=this._data,b=c.words,d=c.sigBytes,f=this.blockSize,h=d/(4*f),h=a?e.ceil(h):e.max((h|0)-this._minBufferSize,0);a=h*f;d=e.min(4*a,d);if(a){for(var g=0;g<a;g+=f)this._doProcessBlock(b,g);g=b.splice(0,a);c.sigBytes-=d}return new n.init(g,d)},clone:function(){var a=f.clone.call(this);\na._data=this._data.clone();return a},_minBufferSize:0});j.Hasher=k.extend({cfg:f.extend(),init:function(a){this.cfg=this.cfg.extend(a);this.reset()},reset:function(){k.reset.call(this);this._doReset()},update:function(a){this._append(a);this._process();return this},finalize:function(a){a&&this._append(a);return this._doFinalize()},blockSize:16,_createHelper:function(a){return function(c,b){return(new a.init(b)).finalize(c)}},_createHmacHelper:function(a){return function(b,f){return(new s.HMAC.init(a,\nf)).finalize(b)}}});var s=p.algo={};return p}(Math);\n(function(){var e=CryptoJS,m=e.lib,p=m.WordArray,j=m.Hasher,l=[],m=e.algo.SHA1=j.extend({_doReset:function(){this._hash=new p.init([1732584193,4023233417,2562383102,271733878,3285377520])},_doProcessBlock:function(f,n){for(var b=this._hash.words,h=b[0],g=b[1],e=b[2],k=b[3],j=b[4],a=0;80>a;a++){if(16>a)l[a]=f[n+a]|0;else{var c=l[a-3]^l[a-8]^l[a-14]^l[a-16];l[a]=c<<1|c>>>31}c=(h<<5|h>>>27)+j+l[a];c=20>a?c+((g&e|~g&k)+1518500249):40>a?c+((g^e^k)+1859775393):60>a?c+((g&e|g&k|e&k)-1894007588):c+((g^e^\nk)-899497514);j=k;k=e;e=g<<30|g>>>2;g=h;h=c}b[0]=b[0]+h|0;b[1]=b[1]+g|0;b[2]=b[2]+e|0;b[3]=b[3]+k|0;b[4]=b[4]+j|0},_doFinalize:function(){var f=this._data,e=f.words,b=8*this._nDataBytes,h=8*f.sigBytes;e[h>>>5]|=128<<24-h%32;e[(h+64>>>9<<4)+14]=Math.floor(b/4294967296);e[(h+64>>>9<<4)+15]=b;f.sigBytes=4*e.length;this._process();return this._hash},clone:function(){var e=j.clone.call(this);e._hash=this._hash.clone();return e}});e.SHA1=j._createHelper(m);e.HmacSHA1=j._createHmacHelper(m)})();\n"], "genericpath": [".py", "\"\"\nimport os\nimport stat\n\n__all__ = ['commonprefix', 'exists', 'getatime', 'getctime', 'getmtime',\n'getsize', 'isdir', 'isfile']\n\n\n\n\ndef exists(path):\n \"\"\n try:\n  os.stat(path)\n except os.error:\n  return False\n return True\n \n \n \n \ndef isfile(path):\n \"\"\n try:\n  st = os.stat(path)\n except os.error:\n  return False\n return stat.S_ISREG(st.st_mode)\n \n \n \n \n \ndef isdir(s):\n \"\"\n try:\n  st = os.stat(s)\n except os.error:\n  return False\n return stat.S_ISDIR(st.st_mode)\n \n \ndef getsize(filename):\n \"\"\n return os.stat(filename).st_size\n \n \ndef getmtime(filename):\n \"\"\n return os.stat(filename).st_mtime\n \n \ndef getatime(filename):\n \"\"\n return os.stat(filename).st_atime\n \n \ndef getctime(filename):\n \"\"\n return os.stat(filename).st_ctime\n \n \n \ndef commonprefix(m):\n \"\"\n if not m: return ''\n s1 = min(m)\n s2 = max(m)\n for i, c in enumerate(s1):\n  if c != s2[i]:\n   return s1[:i]\n return s1\n \n \n \n \n \n \n \n \ndef _splitext(p, sep, altsep, extsep):\n \"\"\n \n \n sepIndex = p.rfind(sep)\n if altsep:\n  altsepIndex = p.rfind(altsep)\n  sepIndex = max(sepIndex, altsepIndex)\n  \n dotIndex = p.rfind(extsep)\n if dotIndex > sepIndex:\n \n  filenameIndex = sepIndex + 1\n  while filenameIndex < dotIndex:\n   if p[filenameIndex:filenameIndex+1] != extsep:\n    return p[:dotIndex], p[dotIndex:]\n   filenameIndex += 1\n   \n return p, p[:0]\n"], "stat": [".py", "\"\"\n\n\n\nST_MODE = 0\nST_INO = 1\nST_DEV = 2\nST_NLINK = 3\nST_UID = 4\nST_GID = 5\nST_SIZE = 6\nST_ATIME = 7\nST_MTIME = 8\nST_CTIME = 9\n\n\n\ndef S_IMODE(mode):\n \"\"\n return mode & 0o7777\n \ndef S_IFMT(mode):\n \"\"\n return mode & 0o170000\n \n \n \n \nS_IFDIR = 0o040000 \nS_IFCHR = 0o020000 \nS_IFBLK = 0o060000 \nS_IFREG = 0o100000 \nS_IFIFO = 0o010000 \nS_IFLNK = 0o120000 \nS_IFSOCK = 0o140000 \n\n\n\ndef S_ISDIR(mode):\n \"\"\n return S_IFMT(mode) == S_IFDIR\n \ndef S_ISCHR(mode):\n \"\"\n return S_IFMT(mode) == S_IFCHR\n \ndef S_ISBLK(mode):\n \"\"\n return S_IFMT(mode) == S_IFBLK\n \ndef S_ISREG(mode):\n \"\"\n return S_IFMT(mode) == S_IFREG\n \ndef S_ISFIFO(mode):\n \"\"\n return S_IFMT(mode) == S_IFIFO\n \ndef S_ISLNK(mode):\n \"\"\n return S_IFMT(mode) == S_IFLNK\n \ndef S_ISSOCK(mode):\n \"\"\n return S_IFMT(mode) == S_IFSOCK\n \n \n \nS_ISUID = 0o4000 \nS_ISGID = 0o2000 \nS_ENFMT = S_ISGID \nS_ISVTX = 0o1000 \nS_IREAD = 0o0400 \nS_IWRITE = 0o0200 \nS_IEXEC = 0o0100 \nS_IRWXU = 0o0700 \nS_IRUSR = 0o0400 \nS_IWUSR = 0o0200 \nS_IXUSR = 0o0100 \nS_IRWXG = 0o0070 \nS_IRGRP = 0o0040 \nS_IWGRP = 0o0020 \nS_IXGRP = 0o0010 \nS_IRWXO = 0o0007 \nS_IROTH = 0o0004 \nS_IWOTH = 0o0002 \nS_IXOTH = 0o0001 \n\n\n\nUF_NODUMP = 0x00000001 \nUF_IMMUTABLE = 0x00000002 \nUF_APPEND = 0x00000004 \nUF_OPAQUE = 0x00000008 \nUF_NOUNLINK = 0x00000010 \nUF_COMPRESSED = 0x00000020 \nUF_HIDDEN = 0x00008000 \nSF_ARCHIVED = 0x00010000 \nSF_IMMUTABLE = 0x00020000 \nSF_APPEND = 0x00040000 \nSF_NOUNLINK = 0x00100000 \nSF_SNAPSHOT = 0x00200000 \n\n\n_filemode_table = (\n((S_IFLNK, \"l\"),\n(S_IFREG, \"-\"),\n(S_IFBLK, \"b\"),\n(S_IFDIR, \"d\"),\n(S_IFCHR, \"c\"),\n(S_IFIFO, \"p\")),\n\n((S_IRUSR, \"r\"),),\n((S_IWUSR, \"w\"),),\n((S_IXUSR|S_ISUID, \"s\"),\n(S_ISUID, \"S\"),\n(S_IXUSR, \"x\")),\n\n((S_IRGRP, \"r\"),),\n((S_IWGRP, \"w\"),),\n((S_IXGRP|S_ISGID, \"s\"),\n(S_ISGID, \"S\"),\n(S_IXGRP, \"x\")),\n\n((S_IROTH, \"r\"),),\n((S_IWOTH, \"w\"),),\n((S_IXOTH|S_ISVTX, \"t\"),\n(S_ISVTX, \"T\"),\n(S_IXOTH, \"x\"))\n)\n\ndef filemode(mode):\n \"\"\n perm = []\n for table in _filemode_table:\n  for bit, char in table:\n   if mode & bit == bit:\n    perm.append(char)\n    break\n  else:\n   perm.append(\"-\")\n return \"\".join(perm)\n"], "http": [".py", "\n", 1], "xml.sax.saxutils": [".py", "\"\"\n\nimport os, urllib.parse, urllib.request\nimport io\nfrom . import handler\nfrom . import xmlreader\n\ndef __dict_replace(s, d):\n \"\"\n for key, value in d.items():\n  s = s.replace(key, value)\n return s\n \ndef escape(data, entities={}):\n \"\"\n \n \n data = data.replace(\"&\", \"&amp;\")\n data = data.replace(\">\", \"&gt;\")\n data = data.replace(\"<\", \"&lt;\")\n if entities:\n  data = __dict_replace(data, entities)\n return data\n \ndef unescape(data, entities={}):\n \"\"\n data = data.replace(\"&lt;\", \"<\")\n data = data.replace(\"&gt;\", \">\")\n if entities:\n  data = __dict_replace(data, entities)\n  \n return data.replace(\"&amp;\", \"&\")\n \ndef quoteattr(data, entities={}):\n \"\"\n entities = entities.copy()\n entities.update({'\\n': '&#10;', '\\r': '&#13;', '\\t':'&#9;'})\n data = escape(data, entities)\n if '\"' in data:\n  if \"'\" in data:\n   data = '\"%s\"' % data.replace('\"', \"&quot;\")\n  else:\n   data = \"'%s'\" % data\n else:\n  data = '\"%s\"' % data\n return data\n \n \ndef _gettextwriter(out, encoding):\n if out is None:\n  import sys\n  return sys.stdout\n  \n if isinstance(out, io.TextIOBase):\n \n  return out\n  \n  \n if isinstance(out, io.RawIOBase):\n \n \n  class _wrapper:\n   __class__ = out.__class__\n   def __getattr__(self, name):\n    return getattr(out, name)\n  buffer = _wrapper()\n  buffer.close = lambda: None\n else:\n \n \n  buffer = io.BufferedIOBase()\n  buffer.writable = lambda: True\n  buffer.write = out.write\n  try:\n  \n  \n   buffer.seekable = out.seekable\n   buffer.tell = out.tell\n  except AttributeError:\n   pass\n return io.TextIOWrapper(buffer, encoding=encoding,\n errors='xmlcharrefreplace',\n newline='\\n',\n write_through=True)\n \nclass XMLGenerator(handler.ContentHandler):\n\n def __init__(self, out=None, encoding=\"iso-8859-1\", short_empty_elements=False):\n  handler.ContentHandler.__init__(self)\n  out = _gettextwriter(out, encoding)\n  self._write = out.write\n  self._flush = out.flush\n  self._ns_contexts = [{}] \n  self._current_context = self._ns_contexts[-1]\n  self._undeclared_ns_maps = []\n  self._encoding = encoding\n  self._short_empty_elements = short_empty_elements\n  self._pending_start_element = False\n  \n def _qname(self, name):\n  \"\"\n  if name[0]:\n  \n  \n  \n  \n   if 'http://www.w3.org/XML/1998/namespace' == name[0]:\n    return 'xml:' + name[1]\n    \n   prefix = self._current_context[name[0]]\n   if prefix:\n   \n    return prefix + \":\" + name[1]\n    \n  return name[1]\n  \n def _finish_pending_start_element(self,endElement=False):\n  if self._pending_start_element:\n   self._write('>')\n   self._pending_start_element = False\n   \n   \n   \n def startDocument(self):\n  self._write('<?xml version=\"1.0\" encoding=\"%s\"?>\\n' %\n  self._encoding)\n  \n def endDocument(self):\n  self._flush()\n  \n def startPrefixMapping(self, prefix, uri):\n  self._ns_contexts.append(self._current_context.copy())\n  self._current_context[uri] = prefix\n  self._undeclared_ns_maps.append((prefix, uri))\n  \n def endPrefixMapping(self, prefix):\n  self._current_context = self._ns_contexts[-1]\n  del self._ns_contexts[-1]\n  \n def startElement(self, name, attrs):\n  self._finish_pending_start_element()\n  self._write('<' + name)\n  for (name, value) in attrs.items():\n   self._write(' %s=%s' % (name, quoteattr(value)))\n  if self._short_empty_elements:\n   self._pending_start_element = True\n  else:\n   self._write(\">\")\n   \n def endElement(self, name):\n  if self._pending_start_element:\n   self._write('/>')\n   self._pending_start_element = False\n  else:\n   self._write('</%s>' % name)\n   \n def startElementNS(self, name, qname, attrs):\n  self._finish_pending_start_element()\n  self._write('<' + self._qname(name))\n  \n  for prefix, uri in self._undeclared_ns_maps:\n   if prefix:\n    self._write(' xmlns:%s=\"%s\"' % (prefix, uri))\n   else:\n    self._write(' xmlns=\"%s\"' % uri)\n  self._undeclared_ns_maps = []\n  \n  for (name, value) in attrs.items():\n   self._write(' %s=%s' % (self._qname(name), quoteattr(value)))\n  if self._short_empty_elements:\n   self._pending_start_element = True\n  else:\n   self._write(\">\")\n   \n def endElementNS(self, name, qname):\n  if self._pending_start_element:\n   self._write('/>')\n   self._pending_start_element = False\n  else:\n   self._write('</%s>' % self._qname(name))\n   \n def characters(self, content):\n  if content:\n   self._finish_pending_start_element()\n   self._write(escape(content))\n   \n def ignorableWhitespace(self, content):\n  if content:\n   self._finish_pending_start_element()\n   self._write(content)\n   \n def processingInstruction(self, target, data):\n  self._finish_pending_start_element()\n  self._write('<?%s %s?>' % (target, data))\n  \n  \nclass XMLFilterBase(xmlreader.XMLReader):\n \"\"\n \n def __init__(self, parent = None):\n  xmlreader.XMLReader.__init__(self)\n  self._parent = parent\n  \n  \n  \n def error(self, exception):\n  self._err_handler.error(exception)\n  \n def fatalError(self, exception):\n  self._err_handler.fatalError(exception)\n  \n def warning(self, exception):\n  self._err_handler.warning(exception)\n  \n  \n  \n def setDocumentLocator(self, locator):\n  self._cont_handler.setDocumentLocator(locator)\n  \n def startDocument(self):\n  self._cont_handler.startDocument()\n  \n def endDocument(self):\n  self._cont_handler.endDocument()\n  \n def startPrefixMapping(self, prefix, uri):\n  self._cont_handler.startPrefixMapping(prefix, uri)\n  \n def endPrefixMapping(self, prefix):\n  self._cont_handler.endPrefixMapping(prefix)\n  \n def startElement(self, name, attrs):\n  self._cont_handler.startElement(name, attrs)\n  \n def endElement(self, name):\n  self._cont_handler.endElement(name)\n  \n def startElementNS(self, name, qname, attrs):\n  self._cont_handler.startElementNS(name, qname, attrs)\n  \n def endElementNS(self, name, qname):\n  self._cont_handler.endElementNS(name, qname)\n  \n def characters(self, content):\n  self._cont_handler.characters(content)\n  \n def ignorableWhitespace(self, chars):\n  self._cont_handler.ignorableWhitespace(chars)\n  \n def processingInstruction(self, target, data):\n  self._cont_handler.processingInstruction(target, data)\n  \n def skippedEntity(self, name):\n  self._cont_handler.skippedEntity(name)\n  \n  \n  \n def notationDecl(self, name, publicId, systemId):\n  self._dtd_handler.notationDecl(name, publicId, systemId)\n  \n def unparsedEntityDecl(self, name, publicId, systemId, ndata):\n  self._dtd_handler.unparsedEntityDecl(name, publicId, systemId, ndata)\n  \n  \n  \n def resolveEntity(self, publicId, systemId):\n  return self._ent_handler.resolveEntity(publicId, systemId)\n  \n  \n  \n def parse(self, source):\n  self._parent.setContentHandler(self)\n  self._parent.setErrorHandler(self)\n  self._parent.setEntityResolver(self)\n  self._parent.setDTDHandler(self)\n  self._parent.parse(source)\n  \n def setLocale(self, locale):\n  self._parent.setLocale(locale)\n  \n def getFeature(self, name):\n  return self._parent.getFeature(name)\n  \n def setFeature(self, name, state):\n  self._parent.setFeature(name, state)\n  \n def getProperty(self, name):\n  return self._parent.getProperty(name)\n  \n def setProperty(self, name, value):\n  self._parent.setProperty(name, value)\n  \n  \n  \n def getParent(self):\n  return self._parent\n  \n def setParent(self, parent):\n  self._parent = parent\n  \n  \n  \ndef prepare_input_source(source, base=\"\"):\n \"\"\n \n if isinstance(source, str):\n  source = xmlreader.InputSource(source)\n elif hasattr(source, \"read\"):\n  f = source\n  source = xmlreader.InputSource()\n  source.setByteStream(f)\n  if hasattr(f, \"name\"):\n   source.setSystemId(f.name)\n   \n if source.getByteStream() is None:\n  sysid = source.getSystemId()\n  basehead = os.path.dirname(os.path.normpath(base))\n  sysidfilename = os.path.join(basehead, sysid)\n  if os.path.isfile(sysidfilename):\n   source.setSystemId(sysidfilename)\n   f = open(sysidfilename, \"rb\")\n  else:\n   source.setSystemId(urllib.parse.urljoin(base, sysid))\n   f = urllib.request.urlopen(source.getSystemId())\n   \n  source.setByteStream(f)\n  \n return source\n"], "warnings": [".py", "\"\"\n\n\n\n\nimport linecache\nimport sys\n\n__all__ = [\"warn\", \"showwarning\", \"formatwarning\", \"filterwarnings\",\n\"resetwarnings\", \"catch_warnings\"]\n\n\ndef showwarning(message, category, filename, lineno, file=None, line=None):\n \"\"\n if file is None:\n  file = sys.stderr\n try:\n  file.write(formatwarning(message, category, filename, lineno, line))\n except IOError:\n  pass \n  \ndef formatwarning(message, category, filename, lineno, line=None):\n \"\"\n s = \"%s:%s: %s: %s\\n\" % (filename, lineno, category.__name__, message)\n line = linecache.getline(filename, lineno) if line is None else line\n if line:\n  line = line.strip()\n  s += \"  %s\\n\" % line\n return s\n \ndef filterwarnings(action, message=\"\", category=Warning, module=\"\", lineno=0,\nappend=False):\n \"\"\n import re\n assert action in (\"error\", \"ignore\", \"always\", \"default\", \"module\",\n \"once\"), \"invalid action: %r\" % (action,)\n assert isinstance(message, str), \"message must be a string\"\n assert isinstance(category, type), \"category must be a class\"\n assert issubclass(category, Warning), \"category must be a Warning subclass\"\n assert isinstance(module, str), \"module must be a string\"\n assert isinstance(lineno, int) and lineno >= 0, \"lineno must be an int >= 0\"\n item = (action, re.compile(message, re.I), category,\n re.compile(module), lineno)\n if append:\n  filters.append(item)\n else:\n  filters.insert(0, item)\n  \ndef simplefilter(action, category=Warning, lineno=0, append=False):\n \"\"\n assert action in (\"error\", \"ignore\", \"always\", \"default\", \"module\",\n \"once\"), \"invalid action: %r\" % (action,)\n assert isinstance(lineno, int) and lineno >= 0, \"lineno must be an int >= 0\"\n item = (action, None, category, None, lineno)\n if append:\n  filters.append(item)\n else:\n  filters.insert(0, item)\n  \ndef resetwarnings():\n \"\"\n filters[:] = []\n \nclass _OptionError(Exception):\n \"\"\n pass\n \n \ndef _processoptions(args):\n for arg in args:\n  try:\n   _setoption(arg)\n  except _OptionError as msg:\n   print(\"Invalid -W option ignored:\", msg, file=sys.stderr)\n   \n   \ndef _setoption(arg):\n import re\n parts = arg.split(':')\n if len(parts) > 5:\n  raise _OptionError(\"too many fields (max 5): %r\" % (arg,))\n while len(parts) < 5:\n  parts.append('')\n action, message, category, module, lineno = [s.strip()\n for s in parts]\n action = _getaction(action)\n message = re.escape(message)\n category = _getcategory(category)\n module = re.escape(module)\n if module:\n  module = module + '$'\n if lineno:\n  try:\n   lineno = int(lineno)\n   if lineno < 0:\n    raise ValueError\n  except (ValueError, OverflowError):\n   raise _OptionError(\"invalid lineno %r\" % (lineno,))\n else:\n  lineno = 0\n filterwarnings(action, message, category, module, lineno)\n \n \ndef _getaction(action):\n if not action:\n  return \"default\"\n if action == \"all\": return \"always\" \n for a in ('default', 'always', 'ignore', 'module', 'once', 'error'):\n  if a.startswith(action):\n   return a\n raise _OptionError(\"invalid action: %r\" % (action,))\n \n \ndef _getcategory(category):\n import re\n if not category:\n  return Warning\n if re.match(\"^[a-zA-Z0-9_]+$\", category):\n  try:\n   cat = eval(category)\n  except NameError:\n   raise _OptionError(\"unknown warning category: %r\" % (category,))\n else:\n  i = category.rfind(\".\")\n  module = category[:i]\n  klass = category[i+1:]\n  try:\n   m = __import__(module, None, None, [klass])\n  except ImportError:\n   raise _OptionError(\"invalid module name: %r\" % (module,))\n  try:\n   cat = getattr(m, klass)\n  except AttributeError:\n   raise _OptionError(\"unknown warning category: %r\" % (category,))\n if not issubclass(cat, Warning):\n  raise _OptionError(\"invalid warning category: %r\" % (category,))\n return cat\n \n \n \ndef warn(message, category=None, stacklevel=1):\n \"\"\n \n if isinstance(message, Warning):\n  category = message.__class__\n  \n if category is None:\n  category = UserWarning\n assert issubclass(category, Warning)\n \n try:\n  caller = sys._getframe(stacklevel)\n except ValueError:\n  globals = sys.__dict__\n  lineno = 1\n else:\n  globals = caller.f_globals\n  lineno = caller.f_lineno\n if '__name__' in globals:\n  module = globals['__name__']\n else:\n  module = \"<string>\"\n filename = globals.get('__file__')\n if filename:\n  fnl = filename.lower()\n  if fnl.endswith((\".pyc\", \".pyo\")):\n   filename = filename[:-1]\n else:\n  if module == \"__main__\":\n   try:\n    filename = sys.argv[0]\n   except AttributeError:\n   \n    filename = '__main__'\n  if not filename:\n   filename = module\n registry = globals.setdefault(\"__warningregistry__\", {})\n warn_explicit(message, category, filename, lineno, module, registry,\n globals)\n \ndef warn_explicit(message, category, filename, lineno,\nmodule=None, registry=None, module_globals=None):\n lineno = int(lineno)\n if module is None:\n  module = filename or \"<unknown>\"\n  if module[-3:].lower() == \".py\":\n   module = module[:-3] \n if registry is None:\n  registry = {}\n if isinstance(message, Warning):\n  text = str(message)\n  category = message.__class__\n else:\n  text = message\n  message = category(message)\n key = (text, category, lineno)\n \n if registry.get(key):\n  return\n  \n for item in filters:\n  action, msg, cat, mod, ln = item\n  if ((msg is None or msg.match(text)) and\n  issubclass(category, cat) and\n  (mod is None or mod.match(module)) and\n  (ln == 0 or lineno == ln)):\n   break\n else:\n  action = defaultaction\n  \n if action == \"ignore\":\n  registry[key] = 1\n  return\n  \n  \n  \n linecache.getlines(filename, module_globals)\n \n if action == \"error\":\n  raise message\n  \n if action == \"once\":\n  registry[key] = 1\n  oncekey = (text, category)\n  if onceregistry.get(oncekey):\n   return\n  onceregistry[oncekey] = 1\n elif action == \"always\":\n  pass\n elif action == \"module\":\n  registry[key] = 1\n  altkey = (text, category, 0)\n  if registry.get(altkey):\n   return\n  registry[altkey] = 1\n elif action == \"default\":\n  registry[key] = 1\n else:\n \n  raise RuntimeError(\n  \"Unrecognized action (%r) in warnings.filters:\\n %s\" %\n  (action, item))\n if not callable(showwarning):\n  raise TypeError(\"warnings.showwarning() must be set to a \"\n  \"function or method\")\n  \n showwarning(message, category, filename, lineno)\n \n \nclass WarningMessage(object):\n\n \"\"\n \n _WARNING_DETAILS = (\"message\", \"category\", \"filename\", \"lineno\", \"file\",\n \"line\")\n \n def __init__(self, message, category, filename, lineno, file=None,\n line=None):\n  local_values = locals()\n  for attr in self._WARNING_DETAILS:\n   setattr(self, attr, local_values[attr])\n  self._category_name = category.__name__ if category else None\n  \n def __str__(self):\n  return (\"{message : %r, category : %r, filename : %r, lineno : %s, \"\n  \"line : %r}\" % (self.message, self._category_name,\n  self.filename, self.lineno, self.line))\n  \n  \nclass catch_warnings(object):\n\n \"\"\n \n def __init__(self, *, record=False, module=None):\n  \"\"\n  self._record = record\n  self._module = sys.modules['warnings'] if module is None else module\n  self._entered = False\n  \n def __repr__(self):\n  args = []\n  if self._record:\n   args.append(\"record=True\")\n  if self._module is not sys.modules['warnings']:\n   args.append(\"module=%r\" % self._module)\n  name = type(self).__name__\n  return \"%s(%s)\" % (name, \", \".join(args))\n  \n def __enter__(self):\n  if self._entered:\n   raise RuntimeError(\"Cannot enter %r twice\" % self)\n  self._entered = True\n  self._filters = self._module.filters\n  self._module.filters = self._filters[:]\n  self._showwarning = self._module.showwarning\n  if self._record:\n   log = []\n   def showwarning(*args, **kwargs):\n    log.append(WarningMessage(*args, **kwargs))\n   self._module.showwarning = showwarning\n   return log\n  else:\n   return None\n   \n def __exit__(self, *exc_info):\n  if not self._entered:\n   raise RuntimeError(\"Cannot exit %r without entering first\" % self)\n  self._module.filters = self._filters\n  self._module.showwarning = self._showwarning\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n_warnings_defaults = False\ntry:\n from _warnings import (filters, _defaultaction, _onceregistry,\n warn, warn_explicit)\n defaultaction = _defaultaction\n onceregistry = _onceregistry\n _warnings_defaults = True\nexcept ImportError:\n filters = []\n defaultaction = \"default\"\n onceregistry = {}\n \n \n \n_processoptions(sys.warnoptions)\nif not _warnings_defaults:\n silence = [ImportWarning, PendingDeprecationWarning]\n silence.append(DeprecationWarning)\n for cls in silence:\n  simplefilter(\"ignore\", category=cls)\n bytes_warning = sys.flags.bytes_warning\n if bytes_warning > 1:\n  bytes_action = \"error\"\n elif bytes_warning:\n  bytes_action = \"default\"\n else:\n  bytes_action = \"ignore\"\n simplefilter(bytes_action, category=BytesWarning, append=1)\n \n if hasattr(sys, 'gettotalrefcount'):\n  resource_action = \"always\"\n else:\n  resource_action = \"ignore\"\n simplefilter(resource_action, category=ResourceWarning, append=1)\n \ndel _warnings_defaults\n"], "html.entities": [".py", "\"\"\n\n\nname2codepoint = {\n'AElig': 0x00c6, \n'Aacute': 0x00c1, \n'Acirc': 0x00c2, \n'Agrave': 0x00c0, \n'Alpha': 0x0391, \n'Aring': 0x00c5, \n'Atilde': 0x00c3, \n'Auml': 0x00c4, \n'Beta': 0x0392, \n'Ccedil': 0x00c7, \n'Chi': 0x03a7, \n'Dagger': 0x2021, \n'Delta': 0x0394, \n'ETH': 0x00d0, \n'Eacute': 0x00c9, \n'Ecirc': 0x00ca, \n'Egrave': 0x00c8, \n'Epsilon': 0x0395, \n'Eta': 0x0397, \n'Euml': 0x00cb, \n'Gamma': 0x0393, \n'Iacute': 0x00cd, \n'Icirc': 0x00ce, \n'Igrave': 0x00cc, \n'Iota': 0x0399, \n'Iuml': 0x00cf, \n'Kappa': 0x039a, \n'Lambda': 0x039b, \n'Mu': 0x039c, \n'Ntilde': 0x00d1, \n'Nu': 0x039d, \n'OElig': 0x0152, \n'Oacute': 0x00d3, \n'Ocirc': 0x00d4, \n'Ograve': 0x00d2, \n'Omega': 0x03a9, \n'Omicron': 0x039f, \n'Oslash': 0x00d8, \n'Otilde': 0x00d5, \n'Ouml': 0x00d6, \n'Phi': 0x03a6, \n'Pi': 0x03a0, \n'Prime': 0x2033, \n'Psi': 0x03a8, \n'Rho': 0x03a1, \n'Scaron': 0x0160, \n'Sigma': 0x03a3, \n'THORN': 0x00de, \n'Tau': 0x03a4, \n'Theta': 0x0398, \n'Uacute': 0x00da, \n'Ucirc': 0x00db, \n'Ugrave': 0x00d9, \n'Upsilon': 0x03a5, \n'Uuml': 0x00dc, \n'Xi': 0x039e, \n'Yacute': 0x00dd, \n'Yuml': 0x0178, \n'Zeta': 0x0396, \n'aacute': 0x00e1, \n'acirc': 0x00e2, \n'acute': 0x00b4, \n'aelig': 0x00e6, \n'agrave': 0x00e0, \n'alefsym': 0x2135, \n'alpha': 0x03b1, \n'amp': 0x0026, \n'and': 0x2227, \n'ang': 0x2220, \n'aring': 0x00e5, \n'asymp': 0x2248, \n'atilde': 0x00e3, \n'auml': 0x00e4, \n'bdquo': 0x201e, \n'beta': 0x03b2, \n'brvbar': 0x00a6, \n'bull': 0x2022, \n'cap': 0x2229, \n'ccedil': 0x00e7, \n'cedil': 0x00b8, \n'cent': 0x00a2, \n'chi': 0x03c7, \n'circ': 0x02c6, \n'clubs': 0x2663, \n'cong': 0x2245, \n'copy': 0x00a9, \n'crarr': 0x21b5, \n'cup': 0x222a, \n'curren': 0x00a4, \n'dArr': 0x21d3, \n'dagger': 0x2020, \n'darr': 0x2193, \n'deg': 0x00b0, \n'delta': 0x03b4, \n'diams': 0x2666, \n'divide': 0x00f7, \n'eacute': 0x00e9, \n'ecirc': 0x00ea, \n'egrave': 0x00e8, \n'empty': 0x2205, \n'emsp': 0x2003, \n'ensp': 0x2002, \n'epsilon': 0x03b5, \n'equiv': 0x2261, \n'eta': 0x03b7, \n'eth': 0x00f0, \n'euml': 0x00eb, \n'euro': 0x20ac, \n'exist': 0x2203, \n'fnof': 0x0192, \n'forall': 0x2200, \n'frac12': 0x00bd, \n'frac14': 0x00bc, \n'frac34': 0x00be, \n'frasl': 0x2044, \n'gamma': 0x03b3, \n'ge': 0x2265, \n'gt': 0x003e, \n'hArr': 0x21d4, \n'harr': 0x2194, \n'hearts': 0x2665, \n'hellip': 0x2026, \n'iacute': 0x00ed, \n'icirc': 0x00ee, \n'iexcl': 0x00a1, \n'igrave': 0x00ec, \n'image': 0x2111, \n'infin': 0x221e, \n'int': 0x222b, \n'iota': 0x03b9, \n'iquest': 0x00bf, \n'isin': 0x2208, \n'iuml': 0x00ef, \n'kappa': 0x03ba, \n'lArr': 0x21d0, \n'lambda': 0x03bb, \n'lang': 0x2329, \n'laquo': 0x00ab, \n'larr': 0x2190, \n'lceil': 0x2308, \n'ldquo': 0x201c, \n'le': 0x2264, \n'lfloor': 0x230a, \n'lowast': 0x2217, \n'loz': 0x25ca, \n'lrm': 0x200e, \n'lsaquo': 0x2039, \n'lsquo': 0x2018, \n'lt': 0x003c, \n'macr': 0x00af, \n'mdash': 0x2014, \n'micro': 0x00b5, \n'middot': 0x00b7, \n'minus': 0x2212, \n'mu': 0x03bc, \n'nabla': 0x2207, \n'nbsp': 0x00a0, \n'ndash': 0x2013, \n'ne': 0x2260, \n'ni': 0x220b, \n'not': 0x00ac, \n'notin': 0x2209, \n'nsub': 0x2284, \n'ntilde': 0x00f1, \n'nu': 0x03bd, \n'oacute': 0x00f3, \n'ocirc': 0x00f4, \n'oelig': 0x0153, \n'ograve': 0x00f2, \n'oline': 0x203e, \n'omega': 0x03c9, \n'omicron': 0x03bf, \n'oplus': 0x2295, \n'or': 0x2228, \n'ordf': 0x00aa, \n'ordm': 0x00ba, \n'oslash': 0x00f8, \n'otilde': 0x00f5, \n'otimes': 0x2297, \n'ouml': 0x00f6, \n'para': 0x00b6, \n'part': 0x2202, \n'permil': 0x2030, \n'perp': 0x22a5, \n'phi': 0x03c6, \n'pi': 0x03c0, \n'piv': 0x03d6, \n'plusmn': 0x00b1, \n'pound': 0x00a3, \n'prime': 0x2032, \n'prod': 0x220f, \n'prop': 0x221d, \n'psi': 0x03c8, \n'quot': 0x0022, \n'rArr': 0x21d2, \n'radic': 0x221a, \n'rang': 0x232a, \n'raquo': 0x00bb, \n'rarr': 0x2192, \n'rceil': 0x2309, \n'rdquo': 0x201d, \n'real': 0x211c, \n'reg': 0x00ae, \n'rfloor': 0x230b, \n'rho': 0x03c1, \n'rlm': 0x200f, \n'rsaquo': 0x203a, \n'rsquo': 0x2019, \n'sbquo': 0x201a, \n'scaron': 0x0161, \n'sdot': 0x22c5, \n'sect': 0x00a7, \n'shy': 0x00ad, \n'sigma': 0x03c3, \n'sigmaf': 0x03c2, \n'sim': 0x223c, \n'spades': 0x2660, \n'sub': 0x2282, \n'sube': 0x2286, \n'sum': 0x2211, \n'sup': 0x2283, \n'sup1': 0x00b9, \n'sup2': 0x00b2, \n'sup3': 0x00b3, \n'supe': 0x2287, \n'szlig': 0x00df, \n'tau': 0x03c4, \n'there4': 0x2234, \n'theta': 0x03b8, \n'thetasym': 0x03d1, \n'thinsp': 0x2009, \n'thorn': 0x00fe, \n'tilde': 0x02dc, \n'times': 0x00d7, \n'trade': 0x2122, \n'uArr': 0x21d1, \n'uacute': 0x00fa, \n'uarr': 0x2191, \n'ucirc': 0x00fb, \n'ugrave': 0x00f9, \n'uml': 0x00a8, \n'upsih': 0x03d2, \n'upsilon': 0x03c5, \n'uuml': 0x00fc, \n'weierp': 0x2118, \n'xi': 0x03be, \n'yacute': 0x00fd, \n'yen': 0x00a5, \n'yuml': 0x00ff, \n'zeta': 0x03b6, \n'zwj': 0x200d, \n'zwnj': 0x200c, \n}\n\n\n\nhtml5 = {\n'Aacute': '\\xc1',\n'aacute': '\\xe1',\n'Aacute;': '\\xc1',\n'aacute;': '\\xe1',\n'Abreve;': '\\u0102',\n'abreve;': '\\u0103',\n'ac;': '\\u223e',\n'acd;': '\\u223f',\n'acE;': '\\u223e\\u0333',\n'Acirc': '\\xc2',\n'acirc': '\\xe2',\n'Acirc;': '\\xc2',\n'acirc;': '\\xe2',\n'acute': '\\xb4',\n'acute;': '\\xb4',\n'Acy;': '\\u0410',\n'acy;': '\\u0430',\n'AElig': '\\xc6',\n'aelig': '\\xe6',\n'AElig;': '\\xc6',\n'aelig;': '\\xe6',\n'af;': '\\u2061',\n'Afr;': '\\U0001d504',\n'afr;': '\\U0001d51e',\n'Agrave': '\\xc0',\n'agrave': '\\xe0',\n'Agrave;': '\\xc0',\n'agrave;': '\\xe0',\n'alefsym;': '\\u2135',\n'aleph;': '\\u2135',\n'Alpha;': '\\u0391',\n'alpha;': '\\u03b1',\n'Amacr;': '\\u0100',\n'amacr;': '\\u0101',\n'amalg;': '\\u2a3f',\n'AMP': '&',\n'amp': '&',\n'AMP;': '&',\n'amp;': '&',\n'And;': '\\u2a53',\n'and;': '\\u2227',\n'andand;': '\\u2a55',\n'andd;': '\\u2a5c',\n'andslope;': '\\u2a58',\n'andv;': '\\u2a5a',\n'ang;': '\\u2220',\n'ange;': '\\u29a4',\n'angle;': '\\u2220',\n'angmsd;': '\\u2221',\n'angmsdaa;': '\\u29a8',\n'angmsdab;': '\\u29a9',\n'angmsdac;': '\\u29aa',\n'angmsdad;': '\\u29ab',\n'angmsdae;': '\\u29ac',\n'angmsdaf;': '\\u29ad',\n'angmsdag;': '\\u29ae',\n'angmsdah;': '\\u29af',\n'angrt;': '\\u221f',\n'angrtvb;': '\\u22be',\n'angrtvbd;': '\\u299d',\n'angsph;': '\\u2222',\n'angst;': '\\xc5',\n'angzarr;': '\\u237c',\n'Aogon;': '\\u0104',\n'aogon;': '\\u0105',\n'Aopf;': '\\U0001d538',\n'aopf;': '\\U0001d552',\n'ap;': '\\u2248',\n'apacir;': '\\u2a6f',\n'apE;': '\\u2a70',\n'ape;': '\\u224a',\n'apid;': '\\u224b',\n'apos;': \"'\",\n'ApplyFunction;': '\\u2061',\n'approx;': '\\u2248',\n'approxeq;': '\\u224a',\n'Aring': '\\xc5',\n'aring': '\\xe5',\n'Aring;': '\\xc5',\n'aring;': '\\xe5',\n'Ascr;': '\\U0001d49c',\n'ascr;': '\\U0001d4b6',\n'Assign;': '\\u2254',\n'ast;': '*',\n'asymp;': '\\u2248',\n'asympeq;': '\\u224d',\n'Atilde': '\\xc3',\n'atilde': '\\xe3',\n'Atilde;': '\\xc3',\n'atilde;': '\\xe3',\n'Auml': '\\xc4',\n'auml': '\\xe4',\n'Auml;': '\\xc4',\n'auml;': '\\xe4',\n'awconint;': '\\u2233',\n'awint;': '\\u2a11',\n'backcong;': '\\u224c',\n'backepsilon;': '\\u03f6',\n'backprime;': '\\u2035',\n'backsim;': '\\u223d',\n'backsimeq;': '\\u22cd',\n'Backslash;': '\\u2216',\n'Barv;': '\\u2ae7',\n'barvee;': '\\u22bd',\n'Barwed;': '\\u2306',\n'barwed;': '\\u2305',\n'barwedge;': '\\u2305',\n'bbrk;': '\\u23b5',\n'bbrktbrk;': '\\u23b6',\n'bcong;': '\\u224c',\n'Bcy;': '\\u0411',\n'bcy;': '\\u0431',\n'bdquo;': '\\u201e',\n'becaus;': '\\u2235',\n'Because;': '\\u2235',\n'because;': '\\u2235',\n'bemptyv;': '\\u29b0',\n'bepsi;': '\\u03f6',\n'bernou;': '\\u212c',\n'Bernoullis;': '\\u212c',\n'Beta;': '\\u0392',\n'beta;': '\\u03b2',\n'beth;': '\\u2136',\n'between;': '\\u226c',\n'Bfr;': '\\U0001d505',\n'bfr;': '\\U0001d51f',\n'bigcap;': '\\u22c2',\n'bigcirc;': '\\u25ef',\n'bigcup;': '\\u22c3',\n'bigodot;': '\\u2a00',\n'bigoplus;': '\\u2a01',\n'bigotimes;': '\\u2a02',\n'bigsqcup;': '\\u2a06',\n'bigstar;': '\\u2605',\n'bigtriangledown;': '\\u25bd',\n'bigtriangleup;': '\\u25b3',\n'biguplus;': '\\u2a04',\n'bigvee;': '\\u22c1',\n'bigwedge;': '\\u22c0',\n'bkarow;': '\\u290d',\n'blacklozenge;': '\\u29eb',\n'blacksquare;': '\\u25aa',\n'blacktriangle;': '\\u25b4',\n'blacktriangledown;': '\\u25be',\n'blacktriangleleft;': '\\u25c2',\n'blacktriangleright;': '\\u25b8',\n'blank;': '\\u2423',\n'blk12;': '\\u2592',\n'blk14;': '\\u2591',\n'blk34;': '\\u2593',\n'block;': '\\u2588',\n'bne;': '=\\u20e5',\n'bnequiv;': '\\u2261\\u20e5',\n'bNot;': '\\u2aed',\n'bnot;': '\\u2310',\n'Bopf;': '\\U0001d539',\n'bopf;': '\\U0001d553',\n'bot;': '\\u22a5',\n'bottom;': '\\u22a5',\n'bowtie;': '\\u22c8',\n'boxbox;': '\\u29c9',\n'boxDL;': '\\u2557',\n'boxDl;': '\\u2556',\n'boxdL;': '\\u2555',\n'boxdl;': '\\u2510',\n'boxDR;': '\\u2554',\n'boxDr;': '\\u2553',\n'boxdR;': '\\u2552',\n'boxdr;': '\\u250c',\n'boxH;': '\\u2550',\n'boxh;': '\\u2500',\n'boxHD;': '\\u2566',\n'boxHd;': '\\u2564',\n'boxhD;': '\\u2565',\n'boxhd;': '\\u252c',\n'boxHU;': '\\u2569',\n'boxHu;': '\\u2567',\n'boxhU;': '\\u2568',\n'boxhu;': '\\u2534',\n'boxminus;': '\\u229f',\n'boxplus;': '\\u229e',\n'boxtimes;': '\\u22a0',\n'boxUL;': '\\u255d',\n'boxUl;': '\\u255c',\n'boxuL;': '\\u255b',\n'boxul;': '\\u2518',\n'boxUR;': '\\u255a',\n'boxUr;': '\\u2559',\n'boxuR;': '\\u2558',\n'boxur;': '\\u2514',\n'boxV;': '\\u2551',\n'boxv;': '\\u2502',\n'boxVH;': '\\u256c',\n'boxVh;': '\\u256b',\n'boxvH;': '\\u256a',\n'boxvh;': '\\u253c',\n'boxVL;': '\\u2563',\n'boxVl;': '\\u2562',\n'boxvL;': '\\u2561',\n'boxvl;': '\\u2524',\n'boxVR;': '\\u2560',\n'boxVr;': '\\u255f',\n'boxvR;': '\\u255e',\n'boxvr;': '\\u251c',\n'bprime;': '\\u2035',\n'Breve;': '\\u02d8',\n'breve;': '\\u02d8',\n'brvbar': '\\xa6',\n'brvbar;': '\\xa6',\n'Bscr;': '\\u212c',\n'bscr;': '\\U0001d4b7',\n'bsemi;': '\\u204f',\n'bsim;': '\\u223d',\n'bsime;': '\\u22cd',\n'bsol;': '\\\\',\n'bsolb;': '\\u29c5',\n'bsolhsub;': '\\u27c8',\n'bull;': '\\u2022',\n'bullet;': '\\u2022',\n'bump;': '\\u224e',\n'bumpE;': '\\u2aae',\n'bumpe;': '\\u224f',\n'Bumpeq;': '\\u224e',\n'bumpeq;': '\\u224f',\n'Cacute;': '\\u0106',\n'cacute;': '\\u0107',\n'Cap;': '\\u22d2',\n'cap;': '\\u2229',\n'capand;': '\\u2a44',\n'capbrcup;': '\\u2a49',\n'capcap;': '\\u2a4b',\n'capcup;': '\\u2a47',\n'capdot;': '\\u2a40',\n'CapitalDifferentialD;': '\\u2145',\n'caps;': '\\u2229\\ufe00',\n'caret;': '\\u2041',\n'caron;': '\\u02c7',\n'Cayleys;': '\\u212d',\n'ccaps;': '\\u2a4d',\n'Ccaron;': '\\u010c',\n'ccaron;': '\\u010d',\n'Ccedil': '\\xc7',\n'ccedil': '\\xe7',\n'Ccedil;': '\\xc7',\n'ccedil;': '\\xe7',\n'Ccirc;': '\\u0108',\n'ccirc;': '\\u0109',\n'Cconint;': '\\u2230',\n'ccups;': '\\u2a4c',\n'ccupssm;': '\\u2a50',\n'Cdot;': '\\u010a',\n'cdot;': '\\u010b',\n'cedil': '\\xb8',\n'cedil;': '\\xb8',\n'Cedilla;': '\\xb8',\n'cemptyv;': '\\u29b2',\n'cent': '\\xa2',\n'cent;': '\\xa2',\n'CenterDot;': '\\xb7',\n'centerdot;': '\\xb7',\n'Cfr;': '\\u212d',\n'cfr;': '\\U0001d520',\n'CHcy;': '\\u0427',\n'chcy;': '\\u0447',\n'check;': '\\u2713',\n'checkmark;': '\\u2713',\n'Chi;': '\\u03a7',\n'chi;': '\\u03c7',\n'cir;': '\\u25cb',\n'circ;': '\\u02c6',\n'circeq;': '\\u2257',\n'circlearrowleft;': '\\u21ba',\n'circlearrowright;': '\\u21bb',\n'circledast;': '\\u229b',\n'circledcirc;': '\\u229a',\n'circleddash;': '\\u229d',\n'CircleDot;': '\\u2299',\n'circledR;': '\\xae',\n'circledS;': '\\u24c8',\n'CircleMinus;': '\\u2296',\n'CirclePlus;': '\\u2295',\n'CircleTimes;': '\\u2297',\n'cirE;': '\\u29c3',\n'cire;': '\\u2257',\n'cirfnint;': '\\u2a10',\n'cirmid;': '\\u2aef',\n'cirscir;': '\\u29c2',\n'ClockwiseContourIntegral;': '\\u2232',\n'CloseCurlyDoubleQuote;': '\\u201d',\n'CloseCurlyQuote;': '\\u2019',\n'clubs;': '\\u2663',\n'clubsuit;': '\\u2663',\n'Colon;': '\\u2237',\n'colon;': ':',\n'Colone;': '\\u2a74',\n'colone;': '\\u2254',\n'coloneq;': '\\u2254',\n'comma;': ',',\n'commat;': '@',\n'comp;': '\\u2201',\n'compfn;': '\\u2218',\n'complement;': '\\u2201',\n'complexes;': '\\u2102',\n'cong;': '\\u2245',\n'congdot;': '\\u2a6d',\n'Congruent;': '\\u2261',\n'Conint;': '\\u222f',\n'conint;': '\\u222e',\n'ContourIntegral;': '\\u222e',\n'Copf;': '\\u2102',\n'copf;': '\\U0001d554',\n'coprod;': '\\u2210',\n'Coproduct;': '\\u2210',\n'COPY': '\\xa9',\n'copy': '\\xa9',\n'COPY;': '\\xa9',\n'copy;': '\\xa9',\n'copysr;': '\\u2117',\n'CounterClockwiseContourIntegral;': '\\u2233',\n'crarr;': '\\u21b5',\n'Cross;': '\\u2a2f',\n'cross;': '\\u2717',\n'Cscr;': '\\U0001d49e',\n'cscr;': '\\U0001d4b8',\n'csub;': '\\u2acf',\n'csube;': '\\u2ad1',\n'csup;': '\\u2ad0',\n'csupe;': '\\u2ad2',\n'ctdot;': '\\u22ef',\n'cudarrl;': '\\u2938',\n'cudarrr;': '\\u2935',\n'cuepr;': '\\u22de',\n'cuesc;': '\\u22df',\n'cularr;': '\\u21b6',\n'cularrp;': '\\u293d',\n'Cup;': '\\u22d3',\n'cup;': '\\u222a',\n'cupbrcap;': '\\u2a48',\n'CupCap;': '\\u224d',\n'cupcap;': '\\u2a46',\n'cupcup;': '\\u2a4a',\n'cupdot;': '\\u228d',\n'cupor;': '\\u2a45',\n'cups;': '\\u222a\\ufe00',\n'curarr;': '\\u21b7',\n'curarrm;': '\\u293c',\n'curlyeqprec;': '\\u22de',\n'curlyeqsucc;': '\\u22df',\n'curlyvee;': '\\u22ce',\n'curlywedge;': '\\u22cf',\n'curren': '\\xa4',\n'curren;': '\\xa4',\n'curvearrowleft;': '\\u21b6',\n'curvearrowright;': '\\u21b7',\n'cuvee;': '\\u22ce',\n'cuwed;': '\\u22cf',\n'cwconint;': '\\u2232',\n'cwint;': '\\u2231',\n'cylcty;': '\\u232d',\n'Dagger;': '\\u2021',\n'dagger;': '\\u2020',\n'daleth;': '\\u2138',\n'Darr;': '\\u21a1',\n'dArr;': '\\u21d3',\n'darr;': '\\u2193',\n'dash;': '\\u2010',\n'Dashv;': '\\u2ae4',\n'dashv;': '\\u22a3',\n'dbkarow;': '\\u290f',\n'dblac;': '\\u02dd',\n'Dcaron;': '\\u010e',\n'dcaron;': '\\u010f',\n'Dcy;': '\\u0414',\n'dcy;': '\\u0434',\n'DD;': '\\u2145',\n'dd;': '\\u2146',\n'ddagger;': '\\u2021',\n'ddarr;': '\\u21ca',\n'DDotrahd;': '\\u2911',\n'ddotseq;': '\\u2a77',\n'deg': '\\xb0',\n'deg;': '\\xb0',\n'Del;': '\\u2207',\n'Delta;': '\\u0394',\n'delta;': '\\u03b4',\n'demptyv;': '\\u29b1',\n'dfisht;': '\\u297f',\n'Dfr;': '\\U0001d507',\n'dfr;': '\\U0001d521',\n'dHar;': '\\u2965',\n'dharl;': '\\u21c3',\n'dharr;': '\\u21c2',\n'DiacriticalAcute;': '\\xb4',\n'DiacriticalDot;': '\\u02d9',\n'DiacriticalDoubleAcute;': '\\u02dd',\n'DiacriticalGrave;': '`',\n'DiacriticalTilde;': '\\u02dc',\n'diam;': '\\u22c4',\n'Diamond;': '\\u22c4',\n'diamond;': '\\u22c4',\n'diamondsuit;': '\\u2666',\n'diams;': '\\u2666',\n'die;': '\\xa8',\n'DifferentialD;': '\\u2146',\n'digamma;': '\\u03dd',\n'disin;': '\\u22f2',\n'div;': '\\xf7',\n'divide': '\\xf7',\n'divide;': '\\xf7',\n'divideontimes;': '\\u22c7',\n'divonx;': '\\u22c7',\n'DJcy;': '\\u0402',\n'djcy;': '\\u0452',\n'dlcorn;': '\\u231e',\n'dlcrop;': '\\u230d',\n'dollar;': '$',\n'Dopf;': '\\U0001d53b',\n'dopf;': '\\U0001d555',\n'Dot;': '\\xa8',\n'dot;': '\\u02d9',\n'DotDot;': '\\u20dc',\n'doteq;': '\\u2250',\n'doteqdot;': '\\u2251',\n'DotEqual;': '\\u2250',\n'dotminus;': '\\u2238',\n'dotplus;': '\\u2214',\n'dotsquare;': '\\u22a1',\n'doublebarwedge;': '\\u2306',\n'DoubleContourIntegral;': '\\u222f',\n'DoubleDot;': '\\xa8',\n'DoubleDownArrow;': '\\u21d3',\n'DoubleLeftArrow;': '\\u21d0',\n'DoubleLeftRightArrow;': '\\u21d4',\n'DoubleLeftTee;': '\\u2ae4',\n'DoubleLongLeftArrow;': '\\u27f8',\n'DoubleLongLeftRightArrow;': '\\u27fa',\n'DoubleLongRightArrow;': '\\u27f9',\n'DoubleRightArrow;': '\\u21d2',\n'DoubleRightTee;': '\\u22a8',\n'DoubleUpArrow;': '\\u21d1',\n'DoubleUpDownArrow;': '\\u21d5',\n'DoubleVerticalBar;': '\\u2225',\n'DownArrow;': '\\u2193',\n'Downarrow;': '\\u21d3',\n'downarrow;': '\\u2193',\n'DownArrowBar;': '\\u2913',\n'DownArrowUpArrow;': '\\u21f5',\n'DownBreve;': '\\u0311',\n'downdownarrows;': '\\u21ca',\n'downharpoonleft;': '\\u21c3',\n'downharpoonright;': '\\u21c2',\n'DownLeftRightVector;': '\\u2950',\n'DownLeftTeeVector;': '\\u295e',\n'DownLeftVector;': '\\u21bd',\n'DownLeftVectorBar;': '\\u2956',\n'DownRightTeeVector;': '\\u295f',\n'DownRightVector;': '\\u21c1',\n'DownRightVectorBar;': '\\u2957',\n'DownTee;': '\\u22a4',\n'DownTeeArrow;': '\\u21a7',\n'drbkarow;': '\\u2910',\n'drcorn;': '\\u231f',\n'drcrop;': '\\u230c',\n'Dscr;': '\\U0001d49f',\n'dscr;': '\\U0001d4b9',\n'DScy;': '\\u0405',\n'dscy;': '\\u0455',\n'dsol;': '\\u29f6',\n'Dstrok;': '\\u0110',\n'dstrok;': '\\u0111',\n'dtdot;': '\\u22f1',\n'dtri;': '\\u25bf',\n'dtrif;': '\\u25be',\n'duarr;': '\\u21f5',\n'duhar;': '\\u296f',\n'dwangle;': '\\u29a6',\n'DZcy;': '\\u040f',\n'dzcy;': '\\u045f',\n'dzigrarr;': '\\u27ff',\n'Eacute': '\\xc9',\n'eacute': '\\xe9',\n'Eacute;': '\\xc9',\n'eacute;': '\\xe9',\n'easter;': '\\u2a6e',\n'Ecaron;': '\\u011a',\n'ecaron;': '\\u011b',\n'ecir;': '\\u2256',\n'Ecirc': '\\xca',\n'ecirc': '\\xea',\n'Ecirc;': '\\xca',\n'ecirc;': '\\xea',\n'ecolon;': '\\u2255',\n'Ecy;': '\\u042d',\n'ecy;': '\\u044d',\n'eDDot;': '\\u2a77',\n'Edot;': '\\u0116',\n'eDot;': '\\u2251',\n'edot;': '\\u0117',\n'ee;': '\\u2147',\n'efDot;': '\\u2252',\n'Efr;': '\\U0001d508',\n'efr;': '\\U0001d522',\n'eg;': '\\u2a9a',\n'Egrave': '\\xc8',\n'egrave': '\\xe8',\n'Egrave;': '\\xc8',\n'egrave;': '\\xe8',\n'egs;': '\\u2a96',\n'egsdot;': '\\u2a98',\n'el;': '\\u2a99',\n'Element;': '\\u2208',\n'elinters;': '\\u23e7',\n'ell;': '\\u2113',\n'els;': '\\u2a95',\n'elsdot;': '\\u2a97',\n'Emacr;': '\\u0112',\n'emacr;': '\\u0113',\n'empty;': '\\u2205',\n'emptyset;': '\\u2205',\n'EmptySmallSquare;': '\\u25fb',\n'emptyv;': '\\u2205',\n'EmptyVerySmallSquare;': '\\u25ab',\n'emsp13;': '\\u2004',\n'emsp14;': '\\u2005',\n'emsp;': '\\u2003',\n'ENG;': '\\u014a',\n'eng;': '\\u014b',\n'ensp;': '\\u2002',\n'Eogon;': '\\u0118',\n'eogon;': '\\u0119',\n'Eopf;': '\\U0001d53c',\n'eopf;': '\\U0001d556',\n'epar;': '\\u22d5',\n'eparsl;': '\\u29e3',\n'eplus;': '\\u2a71',\n'epsi;': '\\u03b5',\n'Epsilon;': '\\u0395',\n'epsilon;': '\\u03b5',\n'epsiv;': '\\u03f5',\n'eqcirc;': '\\u2256',\n'eqcolon;': '\\u2255',\n'eqsim;': '\\u2242',\n'eqslantgtr;': '\\u2a96',\n'eqslantless;': '\\u2a95',\n'Equal;': '\\u2a75',\n'equals;': '=',\n'EqualTilde;': '\\u2242',\n'equest;': '\\u225f',\n'Equilibrium;': '\\u21cc',\n'equiv;': '\\u2261',\n'equivDD;': '\\u2a78',\n'eqvparsl;': '\\u29e5',\n'erarr;': '\\u2971',\n'erDot;': '\\u2253',\n'Escr;': '\\u2130',\n'escr;': '\\u212f',\n'esdot;': '\\u2250',\n'Esim;': '\\u2a73',\n'esim;': '\\u2242',\n'Eta;': '\\u0397',\n'eta;': '\\u03b7',\n'ETH': '\\xd0',\n'eth': '\\xf0',\n'ETH;': '\\xd0',\n'eth;': '\\xf0',\n'Euml': '\\xcb',\n'euml': '\\xeb',\n'Euml;': '\\xcb',\n'euml;': '\\xeb',\n'euro;': '\\u20ac',\n'excl;': '!',\n'exist;': '\\u2203',\n'Exists;': '\\u2203',\n'expectation;': '\\u2130',\n'ExponentialE;': '\\u2147',\n'exponentiale;': '\\u2147',\n'fallingdotseq;': '\\u2252',\n'Fcy;': '\\u0424',\n'fcy;': '\\u0444',\n'female;': '\\u2640',\n'ffilig;': '\\ufb03',\n'fflig;': '\\ufb00',\n'ffllig;': '\\ufb04',\n'Ffr;': '\\U0001d509',\n'ffr;': '\\U0001d523',\n'filig;': '\\ufb01',\n'FilledSmallSquare;': '\\u25fc',\n'FilledVerySmallSquare;': '\\u25aa',\n'fjlig;': 'fj',\n'flat;': '\\u266d',\n'fllig;': '\\ufb02',\n'fltns;': '\\u25b1',\n'fnof;': '\\u0192',\n'Fopf;': '\\U0001d53d',\n'fopf;': '\\U0001d557',\n'ForAll;': '\\u2200',\n'forall;': '\\u2200',\n'fork;': '\\u22d4',\n'forkv;': '\\u2ad9',\n'Fouriertrf;': '\\u2131',\n'fpartint;': '\\u2a0d',\n'frac12': '\\xbd',\n'frac12;': '\\xbd',\n'frac13;': '\\u2153',\n'frac14': '\\xbc',\n'frac14;': '\\xbc',\n'frac15;': '\\u2155',\n'frac16;': '\\u2159',\n'frac18;': '\\u215b',\n'frac23;': '\\u2154',\n'frac25;': '\\u2156',\n'frac34': '\\xbe',\n'frac34;': '\\xbe',\n'frac35;': '\\u2157',\n'frac38;': '\\u215c',\n'frac45;': '\\u2158',\n'frac56;': '\\u215a',\n'frac58;': '\\u215d',\n'frac78;': '\\u215e',\n'frasl;': '\\u2044',\n'frown;': '\\u2322',\n'Fscr;': '\\u2131',\n'fscr;': '\\U0001d4bb',\n'gacute;': '\\u01f5',\n'Gamma;': '\\u0393',\n'gamma;': '\\u03b3',\n'Gammad;': '\\u03dc',\n'gammad;': '\\u03dd',\n'gap;': '\\u2a86',\n'Gbreve;': '\\u011e',\n'gbreve;': '\\u011f',\n'Gcedil;': '\\u0122',\n'Gcirc;': '\\u011c',\n'gcirc;': '\\u011d',\n'Gcy;': '\\u0413',\n'gcy;': '\\u0433',\n'Gdot;': '\\u0120',\n'gdot;': '\\u0121',\n'gE;': '\\u2267',\n'ge;': '\\u2265',\n'gEl;': '\\u2a8c',\n'gel;': '\\u22db',\n'geq;': '\\u2265',\n'geqq;': '\\u2267',\n'geqslant;': '\\u2a7e',\n'ges;': '\\u2a7e',\n'gescc;': '\\u2aa9',\n'gesdot;': '\\u2a80',\n'gesdoto;': '\\u2a82',\n'gesdotol;': '\\u2a84',\n'gesl;': '\\u22db\\ufe00',\n'gesles;': '\\u2a94',\n'Gfr;': '\\U0001d50a',\n'gfr;': '\\U0001d524',\n'Gg;': '\\u22d9',\n'gg;': '\\u226b',\n'ggg;': '\\u22d9',\n'gimel;': '\\u2137',\n'GJcy;': '\\u0403',\n'gjcy;': '\\u0453',\n'gl;': '\\u2277',\n'gla;': '\\u2aa5',\n'glE;': '\\u2a92',\n'glj;': '\\u2aa4',\n'gnap;': '\\u2a8a',\n'gnapprox;': '\\u2a8a',\n'gnE;': '\\u2269',\n'gne;': '\\u2a88',\n'gneq;': '\\u2a88',\n'gneqq;': '\\u2269',\n'gnsim;': '\\u22e7',\n'Gopf;': '\\U0001d53e',\n'gopf;': '\\U0001d558',\n'grave;': '`',\n'GreaterEqual;': '\\u2265',\n'GreaterEqualLess;': '\\u22db',\n'GreaterFullEqual;': '\\u2267',\n'GreaterGreater;': '\\u2aa2',\n'GreaterLess;': '\\u2277',\n'GreaterSlantEqual;': '\\u2a7e',\n'GreaterTilde;': '\\u2273',\n'Gscr;': '\\U0001d4a2',\n'gscr;': '\\u210a',\n'gsim;': '\\u2273',\n'gsime;': '\\u2a8e',\n'gsiml;': '\\u2a90',\n'GT': '>',\n'gt': '>',\n'GT;': '>',\n'Gt;': '\\u226b',\n'gt;': '>',\n'gtcc;': '\\u2aa7',\n'gtcir;': '\\u2a7a',\n'gtdot;': '\\u22d7',\n'gtlPar;': '\\u2995',\n'gtquest;': '\\u2a7c',\n'gtrapprox;': '\\u2a86',\n'gtrarr;': '\\u2978',\n'gtrdot;': '\\u22d7',\n'gtreqless;': '\\u22db',\n'gtreqqless;': '\\u2a8c',\n'gtrless;': '\\u2277',\n'gtrsim;': '\\u2273',\n'gvertneqq;': '\\u2269\\ufe00',\n'gvnE;': '\\u2269\\ufe00',\n'Hacek;': '\\u02c7',\n'hairsp;': '\\u200a',\n'half;': '\\xbd',\n'hamilt;': '\\u210b',\n'HARDcy;': '\\u042a',\n'hardcy;': '\\u044a',\n'hArr;': '\\u21d4',\n'harr;': '\\u2194',\n'harrcir;': '\\u2948',\n'harrw;': '\\u21ad',\n'Hat;': '^',\n'hbar;': '\\u210f',\n'Hcirc;': '\\u0124',\n'hcirc;': '\\u0125',\n'hearts;': '\\u2665',\n'heartsuit;': '\\u2665',\n'hellip;': '\\u2026',\n'hercon;': '\\u22b9',\n'Hfr;': '\\u210c',\n'hfr;': '\\U0001d525',\n'HilbertSpace;': '\\u210b',\n'hksearow;': '\\u2925',\n'hkswarow;': '\\u2926',\n'hoarr;': '\\u21ff',\n'homtht;': '\\u223b',\n'hookleftarrow;': '\\u21a9',\n'hookrightarrow;': '\\u21aa',\n'Hopf;': '\\u210d',\n'hopf;': '\\U0001d559',\n'horbar;': '\\u2015',\n'HorizontalLine;': '\\u2500',\n'Hscr;': '\\u210b',\n'hscr;': '\\U0001d4bd',\n'hslash;': '\\u210f',\n'Hstrok;': '\\u0126',\n'hstrok;': '\\u0127',\n'HumpDownHump;': '\\u224e',\n'HumpEqual;': '\\u224f',\n'hybull;': '\\u2043',\n'hyphen;': '\\u2010',\n'Iacute': '\\xcd',\n'iacute': '\\xed',\n'Iacute;': '\\xcd',\n'iacute;': '\\xed',\n'ic;': '\\u2063',\n'Icirc': '\\xce',\n'icirc': '\\xee',\n'Icirc;': '\\xce',\n'icirc;': '\\xee',\n'Icy;': '\\u0418',\n'icy;': '\\u0438',\n'Idot;': '\\u0130',\n'IEcy;': '\\u0415',\n'iecy;': '\\u0435',\n'iexcl': '\\xa1',\n'iexcl;': '\\xa1',\n'iff;': '\\u21d4',\n'Ifr;': '\\u2111',\n'ifr;': '\\U0001d526',\n'Igrave': '\\xcc',\n'igrave': '\\xec',\n'Igrave;': '\\xcc',\n'igrave;': '\\xec',\n'ii;': '\\u2148',\n'iiiint;': '\\u2a0c',\n'iiint;': '\\u222d',\n'iinfin;': '\\u29dc',\n'iiota;': '\\u2129',\n'IJlig;': '\\u0132',\n'ijlig;': '\\u0133',\n'Im;': '\\u2111',\n'Imacr;': '\\u012a',\n'imacr;': '\\u012b',\n'image;': '\\u2111',\n'ImaginaryI;': '\\u2148',\n'imagline;': '\\u2110',\n'imagpart;': '\\u2111',\n'imath;': '\\u0131',\n'imof;': '\\u22b7',\n'imped;': '\\u01b5',\n'Implies;': '\\u21d2',\n'in;': '\\u2208',\n'incare;': '\\u2105',\n'infin;': '\\u221e',\n'infintie;': '\\u29dd',\n'inodot;': '\\u0131',\n'Int;': '\\u222c',\n'int;': '\\u222b',\n'intcal;': '\\u22ba',\n'integers;': '\\u2124',\n'Integral;': '\\u222b',\n'intercal;': '\\u22ba',\n'Intersection;': '\\u22c2',\n'intlarhk;': '\\u2a17',\n'intprod;': '\\u2a3c',\n'InvisibleComma;': '\\u2063',\n'InvisibleTimes;': '\\u2062',\n'IOcy;': '\\u0401',\n'iocy;': '\\u0451',\n'Iogon;': '\\u012e',\n'iogon;': '\\u012f',\n'Iopf;': '\\U0001d540',\n'iopf;': '\\U0001d55a',\n'Iota;': '\\u0399',\n'iota;': '\\u03b9',\n'iprod;': '\\u2a3c',\n'iquest': '\\xbf',\n'iquest;': '\\xbf',\n'Iscr;': '\\u2110',\n'iscr;': '\\U0001d4be',\n'isin;': '\\u2208',\n'isindot;': '\\u22f5',\n'isinE;': '\\u22f9',\n'isins;': '\\u22f4',\n'isinsv;': '\\u22f3',\n'isinv;': '\\u2208',\n'it;': '\\u2062',\n'Itilde;': '\\u0128',\n'itilde;': '\\u0129',\n'Iukcy;': '\\u0406',\n'iukcy;': '\\u0456',\n'Iuml': '\\xcf',\n'iuml': '\\xef',\n'Iuml;': '\\xcf',\n'iuml;': '\\xef',\n'Jcirc;': '\\u0134',\n'jcirc;': '\\u0135',\n'Jcy;': '\\u0419',\n'jcy;': '\\u0439',\n'Jfr;': '\\U0001d50d',\n'jfr;': '\\U0001d527',\n'jmath;': '\\u0237',\n'Jopf;': '\\U0001d541',\n'jopf;': '\\U0001d55b',\n'Jscr;': '\\U0001d4a5',\n'jscr;': '\\U0001d4bf',\n'Jsercy;': '\\u0408',\n'jsercy;': '\\u0458',\n'Jukcy;': '\\u0404',\n'jukcy;': '\\u0454',\n'Kappa;': '\\u039a',\n'kappa;': '\\u03ba',\n'kappav;': '\\u03f0',\n'Kcedil;': '\\u0136',\n'kcedil;': '\\u0137',\n'Kcy;': '\\u041a',\n'kcy;': '\\u043a',\n'Kfr;': '\\U0001d50e',\n'kfr;': '\\U0001d528',\n'kgreen;': '\\u0138',\n'KHcy;': '\\u0425',\n'khcy;': '\\u0445',\n'KJcy;': '\\u040c',\n'kjcy;': '\\u045c',\n'Kopf;': '\\U0001d542',\n'kopf;': '\\U0001d55c',\n'Kscr;': '\\U0001d4a6',\n'kscr;': '\\U0001d4c0',\n'lAarr;': '\\u21da',\n'Lacute;': '\\u0139',\n'lacute;': '\\u013a',\n'laemptyv;': '\\u29b4',\n'lagran;': '\\u2112',\n'Lambda;': '\\u039b',\n'lambda;': '\\u03bb',\n'Lang;': '\\u27ea',\n'lang;': '\\u27e8',\n'langd;': '\\u2991',\n'langle;': '\\u27e8',\n'lap;': '\\u2a85',\n'Laplacetrf;': '\\u2112',\n'laquo': '\\xab',\n'laquo;': '\\xab',\n'Larr;': '\\u219e',\n'lArr;': '\\u21d0',\n'larr;': '\\u2190',\n'larrb;': '\\u21e4',\n'larrbfs;': '\\u291f',\n'larrfs;': '\\u291d',\n'larrhk;': '\\u21a9',\n'larrlp;': '\\u21ab',\n'larrpl;': '\\u2939',\n'larrsim;': '\\u2973',\n'larrtl;': '\\u21a2',\n'lat;': '\\u2aab',\n'lAtail;': '\\u291b',\n'latail;': '\\u2919',\n'late;': '\\u2aad',\n'lates;': '\\u2aad\\ufe00',\n'lBarr;': '\\u290e',\n'lbarr;': '\\u290c',\n'lbbrk;': '\\u2772',\n'lbrace;': '{',\n'lbrack;': '[',\n'lbrke;': '\\u298b',\n'lbrksld;': '\\u298f',\n'lbrkslu;': '\\u298d',\n'Lcaron;': '\\u013d',\n'lcaron;': '\\u013e',\n'Lcedil;': '\\u013b',\n'lcedil;': '\\u013c',\n'lceil;': '\\u2308',\n'lcub;': '{',\n'Lcy;': '\\u041b',\n'lcy;': '\\u043b',\n'ldca;': '\\u2936',\n'ldquo;': '\\u201c',\n'ldquor;': '\\u201e',\n'ldrdhar;': '\\u2967',\n'ldrushar;': '\\u294b',\n'ldsh;': '\\u21b2',\n'lE;': '\\u2266',\n'le;': '\\u2264',\n'LeftAngleBracket;': '\\u27e8',\n'LeftArrow;': '\\u2190',\n'Leftarrow;': '\\u21d0',\n'leftarrow;': '\\u2190',\n'LeftArrowBar;': '\\u21e4',\n'LeftArrowRightArrow;': '\\u21c6',\n'leftarrowtail;': '\\u21a2',\n'LeftCeiling;': '\\u2308',\n'LeftDoubleBracket;': '\\u27e6',\n'LeftDownTeeVector;': '\\u2961',\n'LeftDownVector;': '\\u21c3',\n'LeftDownVectorBar;': '\\u2959',\n'LeftFloor;': '\\u230a',\n'leftharpoondown;': '\\u21bd',\n'leftharpoonup;': '\\u21bc',\n'leftleftarrows;': '\\u21c7',\n'LeftRightArrow;': '\\u2194',\n'Leftrightarrow;': '\\u21d4',\n'leftrightarrow;': '\\u2194',\n'leftrightarrows;': '\\u21c6',\n'leftrightharpoons;': '\\u21cb',\n'leftrightsquigarrow;': '\\u21ad',\n'LeftRightVector;': '\\u294e',\n'LeftTee;': '\\u22a3',\n'LeftTeeArrow;': '\\u21a4',\n'LeftTeeVector;': '\\u295a',\n'leftthreetimes;': '\\u22cb',\n'LeftTriangle;': '\\u22b2',\n'LeftTriangleBar;': '\\u29cf',\n'LeftTriangleEqual;': '\\u22b4',\n'LeftUpDownVector;': '\\u2951',\n'LeftUpTeeVector;': '\\u2960',\n'LeftUpVector;': '\\u21bf',\n'LeftUpVectorBar;': '\\u2958',\n'LeftVector;': '\\u21bc',\n'LeftVectorBar;': '\\u2952',\n'lEg;': '\\u2a8b',\n'leg;': '\\u22da',\n'leq;': '\\u2264',\n'leqq;': '\\u2266',\n'leqslant;': '\\u2a7d',\n'les;': '\\u2a7d',\n'lescc;': '\\u2aa8',\n'lesdot;': '\\u2a7f',\n'lesdoto;': '\\u2a81',\n'lesdotor;': '\\u2a83',\n'lesg;': '\\u22da\\ufe00',\n'lesges;': '\\u2a93',\n'lessapprox;': '\\u2a85',\n'lessdot;': '\\u22d6',\n'lesseqgtr;': '\\u22da',\n'lesseqqgtr;': '\\u2a8b',\n'LessEqualGreater;': '\\u22da',\n'LessFullEqual;': '\\u2266',\n'LessGreater;': '\\u2276',\n'lessgtr;': '\\u2276',\n'LessLess;': '\\u2aa1',\n'lesssim;': '\\u2272',\n'LessSlantEqual;': '\\u2a7d',\n'LessTilde;': '\\u2272',\n'lfisht;': '\\u297c',\n'lfloor;': '\\u230a',\n'Lfr;': '\\U0001d50f',\n'lfr;': '\\U0001d529',\n'lg;': '\\u2276',\n'lgE;': '\\u2a91',\n'lHar;': '\\u2962',\n'lhard;': '\\u21bd',\n'lharu;': '\\u21bc',\n'lharul;': '\\u296a',\n'lhblk;': '\\u2584',\n'LJcy;': '\\u0409',\n'ljcy;': '\\u0459',\n'Ll;': '\\u22d8',\n'll;': '\\u226a',\n'llarr;': '\\u21c7',\n'llcorner;': '\\u231e',\n'Lleftarrow;': '\\u21da',\n'llhard;': '\\u296b',\n'lltri;': '\\u25fa',\n'Lmidot;': '\\u013f',\n'lmidot;': '\\u0140',\n'lmoust;': '\\u23b0',\n'lmoustache;': '\\u23b0',\n'lnap;': '\\u2a89',\n'lnapprox;': '\\u2a89',\n'lnE;': '\\u2268',\n'lne;': '\\u2a87',\n'lneq;': '\\u2a87',\n'lneqq;': '\\u2268',\n'lnsim;': '\\u22e6',\n'loang;': '\\u27ec',\n'loarr;': '\\u21fd',\n'lobrk;': '\\u27e6',\n'LongLeftArrow;': '\\u27f5',\n'Longleftarrow;': '\\u27f8',\n'longleftarrow;': '\\u27f5',\n'LongLeftRightArrow;': '\\u27f7',\n'Longleftrightarrow;': '\\u27fa',\n'longleftrightarrow;': '\\u27f7',\n'longmapsto;': '\\u27fc',\n'LongRightArrow;': '\\u27f6',\n'Longrightarrow;': '\\u27f9',\n'longrightarrow;': '\\u27f6',\n'looparrowleft;': '\\u21ab',\n'looparrowright;': '\\u21ac',\n'lopar;': '\\u2985',\n'Lopf;': '\\U0001d543',\n'lopf;': '\\U0001d55d',\n'loplus;': '\\u2a2d',\n'lotimes;': '\\u2a34',\n'lowast;': '\\u2217',\n'lowbar;': '_',\n'LowerLeftArrow;': '\\u2199',\n'LowerRightArrow;': '\\u2198',\n'loz;': '\\u25ca',\n'lozenge;': '\\u25ca',\n'lozf;': '\\u29eb',\n'lpar;': '(',\n'lparlt;': '\\u2993',\n'lrarr;': '\\u21c6',\n'lrcorner;': '\\u231f',\n'lrhar;': '\\u21cb',\n'lrhard;': '\\u296d',\n'lrm;': '\\u200e',\n'lrtri;': '\\u22bf',\n'lsaquo;': '\\u2039',\n'Lscr;': '\\u2112',\n'lscr;': '\\U0001d4c1',\n'Lsh;': '\\u21b0',\n'lsh;': '\\u21b0',\n'lsim;': '\\u2272',\n'lsime;': '\\u2a8d',\n'lsimg;': '\\u2a8f',\n'lsqb;': '[',\n'lsquo;': '\\u2018',\n'lsquor;': '\\u201a',\n'Lstrok;': '\\u0141',\n'lstrok;': '\\u0142',\n'LT': '<',\n'lt': '<',\n'LT;': '<',\n'Lt;': '\\u226a',\n'lt;': '<',\n'ltcc;': '\\u2aa6',\n'ltcir;': '\\u2a79',\n'ltdot;': '\\u22d6',\n'lthree;': '\\u22cb',\n'ltimes;': '\\u22c9',\n'ltlarr;': '\\u2976',\n'ltquest;': '\\u2a7b',\n'ltri;': '\\u25c3',\n'ltrie;': '\\u22b4',\n'ltrif;': '\\u25c2',\n'ltrPar;': '\\u2996',\n'lurdshar;': '\\u294a',\n'luruhar;': '\\u2966',\n'lvertneqq;': '\\u2268\\ufe00',\n'lvnE;': '\\u2268\\ufe00',\n'macr': '\\xaf',\n'macr;': '\\xaf',\n'male;': '\\u2642',\n'malt;': '\\u2720',\n'maltese;': '\\u2720',\n'Map;': '\\u2905',\n'map;': '\\u21a6',\n'mapsto;': '\\u21a6',\n'mapstodown;': '\\u21a7',\n'mapstoleft;': '\\u21a4',\n'mapstoup;': '\\u21a5',\n'marker;': '\\u25ae',\n'mcomma;': '\\u2a29',\n'Mcy;': '\\u041c',\n'mcy;': '\\u043c',\n'mdash;': '\\u2014',\n'mDDot;': '\\u223a',\n'measuredangle;': '\\u2221',\n'MediumSpace;': '\\u205f',\n'Mellintrf;': '\\u2133',\n'Mfr;': '\\U0001d510',\n'mfr;': '\\U0001d52a',\n'mho;': '\\u2127',\n'micro': '\\xb5',\n'micro;': '\\xb5',\n'mid;': '\\u2223',\n'midast;': '*',\n'midcir;': '\\u2af0',\n'middot': '\\xb7',\n'middot;': '\\xb7',\n'minus;': '\\u2212',\n'minusb;': '\\u229f',\n'minusd;': '\\u2238',\n'minusdu;': '\\u2a2a',\n'MinusPlus;': '\\u2213',\n'mlcp;': '\\u2adb',\n'mldr;': '\\u2026',\n'mnplus;': '\\u2213',\n'models;': '\\u22a7',\n'Mopf;': '\\U0001d544',\n'mopf;': '\\U0001d55e',\n'mp;': '\\u2213',\n'Mscr;': '\\u2133',\n'mscr;': '\\U0001d4c2',\n'mstpos;': '\\u223e',\n'Mu;': '\\u039c',\n'mu;': '\\u03bc',\n'multimap;': '\\u22b8',\n'mumap;': '\\u22b8',\n'nabla;': '\\u2207',\n'Nacute;': '\\u0143',\n'nacute;': '\\u0144',\n'nang;': '\\u2220\\u20d2',\n'nap;': '\\u2249',\n'napE;': '\\u2a70\\u0338',\n'napid;': '\\u224b\\u0338',\n'napos;': '\\u0149',\n'napprox;': '\\u2249',\n'natur;': '\\u266e',\n'natural;': '\\u266e',\n'naturals;': '\\u2115',\n'nbsp': '\\xa0',\n'nbsp;': '\\xa0',\n'nbump;': '\\u224e\\u0338',\n'nbumpe;': '\\u224f\\u0338',\n'ncap;': '\\u2a43',\n'Ncaron;': '\\u0147',\n'ncaron;': '\\u0148',\n'Ncedil;': '\\u0145',\n'ncedil;': '\\u0146',\n'ncong;': '\\u2247',\n'ncongdot;': '\\u2a6d\\u0338',\n'ncup;': '\\u2a42',\n'Ncy;': '\\u041d',\n'ncy;': '\\u043d',\n'ndash;': '\\u2013',\n'ne;': '\\u2260',\n'nearhk;': '\\u2924',\n'neArr;': '\\u21d7',\n'nearr;': '\\u2197',\n'nearrow;': '\\u2197',\n'nedot;': '\\u2250\\u0338',\n'NegativeMediumSpace;': '\\u200b',\n'NegativeThickSpace;': '\\u200b',\n'NegativeThinSpace;': '\\u200b',\n'NegativeVeryThinSpace;': '\\u200b',\n'nequiv;': '\\u2262',\n'nesear;': '\\u2928',\n'nesim;': '\\u2242\\u0338',\n'NestedGreaterGreater;': '\\u226b',\n'NestedLessLess;': '\\u226a',\n'NewLine;': '\\n',\n'nexist;': '\\u2204',\n'nexists;': '\\u2204',\n'Nfr;': '\\U0001d511',\n'nfr;': '\\U0001d52b',\n'ngE;': '\\u2267\\u0338',\n'nge;': '\\u2271',\n'ngeq;': '\\u2271',\n'ngeqq;': '\\u2267\\u0338',\n'ngeqslant;': '\\u2a7e\\u0338',\n'nges;': '\\u2a7e\\u0338',\n'nGg;': '\\u22d9\\u0338',\n'ngsim;': '\\u2275',\n'nGt;': '\\u226b\\u20d2',\n'ngt;': '\\u226f',\n'ngtr;': '\\u226f',\n'nGtv;': '\\u226b\\u0338',\n'nhArr;': '\\u21ce',\n'nharr;': '\\u21ae',\n'nhpar;': '\\u2af2',\n'ni;': '\\u220b',\n'nis;': '\\u22fc',\n'nisd;': '\\u22fa',\n'niv;': '\\u220b',\n'NJcy;': '\\u040a',\n'njcy;': '\\u045a',\n'nlArr;': '\\u21cd',\n'nlarr;': '\\u219a',\n'nldr;': '\\u2025',\n'nlE;': '\\u2266\\u0338',\n'nle;': '\\u2270',\n'nLeftarrow;': '\\u21cd',\n'nleftarrow;': '\\u219a',\n'nLeftrightarrow;': '\\u21ce',\n'nleftrightarrow;': '\\u21ae',\n'nleq;': '\\u2270',\n'nleqq;': '\\u2266\\u0338',\n'nleqslant;': '\\u2a7d\\u0338',\n'nles;': '\\u2a7d\\u0338',\n'nless;': '\\u226e',\n'nLl;': '\\u22d8\\u0338',\n'nlsim;': '\\u2274',\n'nLt;': '\\u226a\\u20d2',\n'nlt;': '\\u226e',\n'nltri;': '\\u22ea',\n'nltrie;': '\\u22ec',\n'nLtv;': '\\u226a\\u0338',\n'nmid;': '\\u2224',\n'NoBreak;': '\\u2060',\n'NonBreakingSpace;': '\\xa0',\n'Nopf;': '\\u2115',\n'nopf;': '\\U0001d55f',\n'not': '\\xac',\n'Not;': '\\u2aec',\n'not;': '\\xac',\n'NotCongruent;': '\\u2262',\n'NotCupCap;': '\\u226d',\n'NotDoubleVerticalBar;': '\\u2226',\n'NotElement;': '\\u2209',\n'NotEqual;': '\\u2260',\n'NotEqualTilde;': '\\u2242\\u0338',\n'NotExists;': '\\u2204',\n'NotGreater;': '\\u226f',\n'NotGreaterEqual;': '\\u2271',\n'NotGreaterFullEqual;': '\\u2267\\u0338',\n'NotGreaterGreater;': '\\u226b\\u0338',\n'NotGreaterLess;': '\\u2279',\n'NotGreaterSlantEqual;': '\\u2a7e\\u0338',\n'NotGreaterTilde;': '\\u2275',\n'NotHumpDownHump;': '\\u224e\\u0338',\n'NotHumpEqual;': '\\u224f\\u0338',\n'notin;': '\\u2209',\n'notindot;': '\\u22f5\\u0338',\n'notinE;': '\\u22f9\\u0338',\n'notinva;': '\\u2209',\n'notinvb;': '\\u22f7',\n'notinvc;': '\\u22f6',\n'NotLeftTriangle;': '\\u22ea',\n'NotLeftTriangleBar;': '\\u29cf\\u0338',\n'NotLeftTriangleEqual;': '\\u22ec',\n'NotLess;': '\\u226e',\n'NotLessEqual;': '\\u2270',\n'NotLessGreater;': '\\u2278',\n'NotLessLess;': '\\u226a\\u0338',\n'NotLessSlantEqual;': '\\u2a7d\\u0338',\n'NotLessTilde;': '\\u2274',\n'NotNestedGreaterGreater;': '\\u2aa2\\u0338',\n'NotNestedLessLess;': '\\u2aa1\\u0338',\n'notni;': '\\u220c',\n'notniva;': '\\u220c',\n'notnivb;': '\\u22fe',\n'notnivc;': '\\u22fd',\n'NotPrecedes;': '\\u2280',\n'NotPrecedesEqual;': '\\u2aaf\\u0338',\n'NotPrecedesSlantEqual;': '\\u22e0',\n'NotReverseElement;': '\\u220c',\n'NotRightTriangle;': '\\u22eb',\n'NotRightTriangleBar;': '\\u29d0\\u0338',\n'NotRightTriangleEqual;': '\\u22ed',\n'NotSquareSubset;': '\\u228f\\u0338',\n'NotSquareSubsetEqual;': '\\u22e2',\n'NotSquareSuperset;': '\\u2290\\u0338',\n'NotSquareSupersetEqual;': '\\u22e3',\n'NotSubset;': '\\u2282\\u20d2',\n'NotSubsetEqual;': '\\u2288',\n'NotSucceeds;': '\\u2281',\n'NotSucceedsEqual;': '\\u2ab0\\u0338',\n'NotSucceedsSlantEqual;': '\\u22e1',\n'NotSucceedsTilde;': '\\u227f\\u0338',\n'NotSuperset;': '\\u2283\\u20d2',\n'NotSupersetEqual;': '\\u2289',\n'NotTilde;': '\\u2241',\n'NotTildeEqual;': '\\u2244',\n'NotTildeFullEqual;': '\\u2247',\n'NotTildeTilde;': '\\u2249',\n'NotVerticalBar;': '\\u2224',\n'npar;': '\\u2226',\n'nparallel;': '\\u2226',\n'nparsl;': '\\u2afd\\u20e5',\n'npart;': '\\u2202\\u0338',\n'npolint;': '\\u2a14',\n'npr;': '\\u2280',\n'nprcue;': '\\u22e0',\n'npre;': '\\u2aaf\\u0338',\n'nprec;': '\\u2280',\n'npreceq;': '\\u2aaf\\u0338',\n'nrArr;': '\\u21cf',\n'nrarr;': '\\u219b',\n'nrarrc;': '\\u2933\\u0338',\n'nrarrw;': '\\u219d\\u0338',\n'nRightarrow;': '\\u21cf',\n'nrightarrow;': '\\u219b',\n'nrtri;': '\\u22eb',\n'nrtrie;': '\\u22ed',\n'nsc;': '\\u2281',\n'nsccue;': '\\u22e1',\n'nsce;': '\\u2ab0\\u0338',\n'Nscr;': '\\U0001d4a9',\n'nscr;': '\\U0001d4c3',\n'nshortmid;': '\\u2224',\n'nshortparallel;': '\\u2226',\n'nsim;': '\\u2241',\n'nsime;': '\\u2244',\n'nsimeq;': '\\u2244',\n'nsmid;': '\\u2224',\n'nspar;': '\\u2226',\n'nsqsube;': '\\u22e2',\n'nsqsupe;': '\\u22e3',\n'nsub;': '\\u2284',\n'nsubE;': '\\u2ac5\\u0338',\n'nsube;': '\\u2288',\n'nsubset;': '\\u2282\\u20d2',\n'nsubseteq;': '\\u2288',\n'nsubseteqq;': '\\u2ac5\\u0338',\n'nsucc;': '\\u2281',\n'nsucceq;': '\\u2ab0\\u0338',\n'nsup;': '\\u2285',\n'nsupE;': '\\u2ac6\\u0338',\n'nsupe;': '\\u2289',\n'nsupset;': '\\u2283\\u20d2',\n'nsupseteq;': '\\u2289',\n'nsupseteqq;': '\\u2ac6\\u0338',\n'ntgl;': '\\u2279',\n'Ntilde': '\\xd1',\n'ntilde': '\\xf1',\n'Ntilde;': '\\xd1',\n'ntilde;': '\\xf1',\n'ntlg;': '\\u2278',\n'ntriangleleft;': '\\u22ea',\n'ntrianglelefteq;': '\\u22ec',\n'ntriangleright;': '\\u22eb',\n'ntrianglerighteq;': '\\u22ed',\n'Nu;': '\\u039d',\n'nu;': '\\u03bd',\n'num;': '#',\n'numero;': '\\u2116',\n'numsp;': '\\u2007',\n'nvap;': '\\u224d\\u20d2',\n'nVDash;': '\\u22af',\n'nVdash;': '\\u22ae',\n'nvDash;': '\\u22ad',\n'nvdash;': '\\u22ac',\n'nvge;': '\\u2265\\u20d2',\n'nvgt;': '>\\u20d2',\n'nvHarr;': '\\u2904',\n'nvinfin;': '\\u29de',\n'nvlArr;': '\\u2902',\n'nvle;': '\\u2264\\u20d2',\n'nvlt;': '<\\u20d2',\n'nvltrie;': '\\u22b4\\u20d2',\n'nvrArr;': '\\u2903',\n'nvrtrie;': '\\u22b5\\u20d2',\n'nvsim;': '\\u223c\\u20d2',\n'nwarhk;': '\\u2923',\n'nwArr;': '\\u21d6',\n'nwarr;': '\\u2196',\n'nwarrow;': '\\u2196',\n'nwnear;': '\\u2927',\n'Oacute': '\\xd3',\n'oacute': '\\xf3',\n'Oacute;': '\\xd3',\n'oacute;': '\\xf3',\n'oast;': '\\u229b',\n'ocir;': '\\u229a',\n'Ocirc': '\\xd4',\n'ocirc': '\\xf4',\n'Ocirc;': '\\xd4',\n'ocirc;': '\\xf4',\n'Ocy;': '\\u041e',\n'ocy;': '\\u043e',\n'odash;': '\\u229d',\n'Odblac;': '\\u0150',\n'odblac;': '\\u0151',\n'odiv;': '\\u2a38',\n'odot;': '\\u2299',\n'odsold;': '\\u29bc',\n'OElig;': '\\u0152',\n'oelig;': '\\u0153',\n'ofcir;': '\\u29bf',\n'Ofr;': '\\U0001d512',\n'ofr;': '\\U0001d52c',\n'ogon;': '\\u02db',\n'Ograve': '\\xd2',\n'ograve': '\\xf2',\n'Ograve;': '\\xd2',\n'ograve;': '\\xf2',\n'ogt;': '\\u29c1',\n'ohbar;': '\\u29b5',\n'ohm;': '\\u03a9',\n'oint;': '\\u222e',\n'olarr;': '\\u21ba',\n'olcir;': '\\u29be',\n'olcross;': '\\u29bb',\n'oline;': '\\u203e',\n'olt;': '\\u29c0',\n'Omacr;': '\\u014c',\n'omacr;': '\\u014d',\n'Omega;': '\\u03a9',\n'omega;': '\\u03c9',\n'Omicron;': '\\u039f',\n'omicron;': '\\u03bf',\n'omid;': '\\u29b6',\n'ominus;': '\\u2296',\n'Oopf;': '\\U0001d546',\n'oopf;': '\\U0001d560',\n'opar;': '\\u29b7',\n'OpenCurlyDoubleQuote;': '\\u201c',\n'OpenCurlyQuote;': '\\u2018',\n'operp;': '\\u29b9',\n'oplus;': '\\u2295',\n'Or;': '\\u2a54',\n'or;': '\\u2228',\n'orarr;': '\\u21bb',\n'ord;': '\\u2a5d',\n'order;': '\\u2134',\n'orderof;': '\\u2134',\n'ordf': '\\xaa',\n'ordf;': '\\xaa',\n'ordm': '\\xba',\n'ordm;': '\\xba',\n'origof;': '\\u22b6',\n'oror;': '\\u2a56',\n'orslope;': '\\u2a57',\n'orv;': '\\u2a5b',\n'oS;': '\\u24c8',\n'Oscr;': '\\U0001d4aa',\n'oscr;': '\\u2134',\n'Oslash': '\\xd8',\n'oslash': '\\xf8',\n'Oslash;': '\\xd8',\n'oslash;': '\\xf8',\n'osol;': '\\u2298',\n'Otilde': '\\xd5',\n'otilde': '\\xf5',\n'Otilde;': '\\xd5',\n'otilde;': '\\xf5',\n'Otimes;': '\\u2a37',\n'otimes;': '\\u2297',\n'otimesas;': '\\u2a36',\n'Ouml': '\\xd6',\n'ouml': '\\xf6',\n'Ouml;': '\\xd6',\n'ouml;': '\\xf6',\n'ovbar;': '\\u233d',\n'OverBar;': '\\u203e',\n'OverBrace;': '\\u23de',\n'OverBracket;': '\\u23b4',\n'OverParenthesis;': '\\u23dc',\n'par;': '\\u2225',\n'para': '\\xb6',\n'para;': '\\xb6',\n'parallel;': '\\u2225',\n'parsim;': '\\u2af3',\n'parsl;': '\\u2afd',\n'part;': '\\u2202',\n'PartialD;': '\\u2202',\n'Pcy;': '\\u041f',\n'pcy;': '\\u043f',\n'percnt;': '%',\n'period;': '.',\n'permil;': '\\u2030',\n'perp;': '\\u22a5',\n'pertenk;': '\\u2031',\n'Pfr;': '\\U0001d513',\n'pfr;': '\\U0001d52d',\n'Phi;': '\\u03a6',\n'phi;': '\\u03c6',\n'phiv;': '\\u03d5',\n'phmmat;': '\\u2133',\n'phone;': '\\u260e',\n'Pi;': '\\u03a0',\n'pi;': '\\u03c0',\n'pitchfork;': '\\u22d4',\n'piv;': '\\u03d6',\n'planck;': '\\u210f',\n'planckh;': '\\u210e',\n'plankv;': '\\u210f',\n'plus;': '+',\n'plusacir;': '\\u2a23',\n'plusb;': '\\u229e',\n'pluscir;': '\\u2a22',\n'plusdo;': '\\u2214',\n'plusdu;': '\\u2a25',\n'pluse;': '\\u2a72',\n'PlusMinus;': '\\xb1',\n'plusmn': '\\xb1',\n'plusmn;': '\\xb1',\n'plussim;': '\\u2a26',\n'plustwo;': '\\u2a27',\n'pm;': '\\xb1',\n'Poincareplane;': '\\u210c',\n'pointint;': '\\u2a15',\n'Popf;': '\\u2119',\n'popf;': '\\U0001d561',\n'pound': '\\xa3',\n'pound;': '\\xa3',\n'Pr;': '\\u2abb',\n'pr;': '\\u227a',\n'prap;': '\\u2ab7',\n'prcue;': '\\u227c',\n'prE;': '\\u2ab3',\n'pre;': '\\u2aaf',\n'prec;': '\\u227a',\n'precapprox;': '\\u2ab7',\n'preccurlyeq;': '\\u227c',\n'Precedes;': '\\u227a',\n'PrecedesEqual;': '\\u2aaf',\n'PrecedesSlantEqual;': '\\u227c',\n'PrecedesTilde;': '\\u227e',\n'preceq;': '\\u2aaf',\n'precnapprox;': '\\u2ab9',\n'precneqq;': '\\u2ab5',\n'precnsim;': '\\u22e8',\n'precsim;': '\\u227e',\n'Prime;': '\\u2033',\n'prime;': '\\u2032',\n'primes;': '\\u2119',\n'prnap;': '\\u2ab9',\n'prnE;': '\\u2ab5',\n'prnsim;': '\\u22e8',\n'prod;': '\\u220f',\n'Product;': '\\u220f',\n'profalar;': '\\u232e',\n'profline;': '\\u2312',\n'profsurf;': '\\u2313',\n'prop;': '\\u221d',\n'Proportion;': '\\u2237',\n'Proportional;': '\\u221d',\n'propto;': '\\u221d',\n'prsim;': '\\u227e',\n'prurel;': '\\u22b0',\n'Pscr;': '\\U0001d4ab',\n'pscr;': '\\U0001d4c5',\n'Psi;': '\\u03a8',\n'psi;': '\\u03c8',\n'puncsp;': '\\u2008',\n'Qfr;': '\\U0001d514',\n'qfr;': '\\U0001d52e',\n'qint;': '\\u2a0c',\n'Qopf;': '\\u211a',\n'qopf;': '\\U0001d562',\n'qprime;': '\\u2057',\n'Qscr;': '\\U0001d4ac',\n'qscr;': '\\U0001d4c6',\n'quaternions;': '\\u210d',\n'quatint;': '\\u2a16',\n'quest;': '?',\n'questeq;': '\\u225f',\n'QUOT': '\"',\n'quot': '\"',\n'QUOT;': '\"',\n'quot;': '\"',\n'rAarr;': '\\u21db',\n'race;': '\\u223d\\u0331',\n'Racute;': '\\u0154',\n'racute;': '\\u0155',\n'radic;': '\\u221a',\n'raemptyv;': '\\u29b3',\n'Rang;': '\\u27eb',\n'rang;': '\\u27e9',\n'rangd;': '\\u2992',\n'range;': '\\u29a5',\n'rangle;': '\\u27e9',\n'raquo': '\\xbb',\n'raquo;': '\\xbb',\n'Rarr;': '\\u21a0',\n'rArr;': '\\u21d2',\n'rarr;': '\\u2192',\n'rarrap;': '\\u2975',\n'rarrb;': '\\u21e5',\n'rarrbfs;': '\\u2920',\n'rarrc;': '\\u2933',\n'rarrfs;': '\\u291e',\n'rarrhk;': '\\u21aa',\n'rarrlp;': '\\u21ac',\n'rarrpl;': '\\u2945',\n'rarrsim;': '\\u2974',\n'Rarrtl;': '\\u2916',\n'rarrtl;': '\\u21a3',\n'rarrw;': '\\u219d',\n'rAtail;': '\\u291c',\n'ratail;': '\\u291a',\n'ratio;': '\\u2236',\n'rationals;': '\\u211a',\n'RBarr;': '\\u2910',\n'rBarr;': '\\u290f',\n'rbarr;': '\\u290d',\n'rbbrk;': '\\u2773',\n'rbrace;': '}',\n'rbrack;': ']',\n'rbrke;': '\\u298c',\n'rbrksld;': '\\u298e',\n'rbrkslu;': '\\u2990',\n'Rcaron;': '\\u0158',\n'rcaron;': '\\u0159',\n'Rcedil;': '\\u0156',\n'rcedil;': '\\u0157',\n'rceil;': '\\u2309',\n'rcub;': '}',\n'Rcy;': '\\u0420',\n'rcy;': '\\u0440',\n'rdca;': '\\u2937',\n'rdldhar;': '\\u2969',\n'rdquo;': '\\u201d',\n'rdquor;': '\\u201d',\n'rdsh;': '\\u21b3',\n'Re;': '\\u211c',\n'real;': '\\u211c',\n'realine;': '\\u211b',\n'realpart;': '\\u211c',\n'reals;': '\\u211d',\n'rect;': '\\u25ad',\n'REG': '\\xae',\n'reg': '\\xae',\n'REG;': '\\xae',\n'reg;': '\\xae',\n'ReverseElement;': '\\u220b',\n'ReverseEquilibrium;': '\\u21cb',\n'ReverseUpEquilibrium;': '\\u296f',\n'rfisht;': '\\u297d',\n'rfloor;': '\\u230b',\n'Rfr;': '\\u211c',\n'rfr;': '\\U0001d52f',\n'rHar;': '\\u2964',\n'rhard;': '\\u21c1',\n'rharu;': '\\u21c0',\n'rharul;': '\\u296c',\n'Rho;': '\\u03a1',\n'rho;': '\\u03c1',\n'rhov;': '\\u03f1',\n'RightAngleBracket;': '\\u27e9',\n'RightArrow;': '\\u2192',\n'Rightarrow;': '\\u21d2',\n'rightarrow;': '\\u2192',\n'RightArrowBar;': '\\u21e5',\n'RightArrowLeftArrow;': '\\u21c4',\n'rightarrowtail;': '\\u21a3',\n'RightCeiling;': '\\u2309',\n'RightDoubleBracket;': '\\u27e7',\n'RightDownTeeVector;': '\\u295d',\n'RightDownVector;': '\\u21c2',\n'RightDownVectorBar;': '\\u2955',\n'RightFloor;': '\\u230b',\n'rightharpoondown;': '\\u21c1',\n'rightharpoonup;': '\\u21c0',\n'rightleftarrows;': '\\u21c4',\n'rightleftharpoons;': '\\u21cc',\n'rightrightarrows;': '\\u21c9',\n'rightsquigarrow;': '\\u219d',\n'RightTee;': '\\u22a2',\n'RightTeeArrow;': '\\u21a6',\n'RightTeeVector;': '\\u295b',\n'rightthreetimes;': '\\u22cc',\n'RightTriangle;': '\\u22b3',\n'RightTriangleBar;': '\\u29d0',\n'RightTriangleEqual;': '\\u22b5',\n'RightUpDownVector;': '\\u294f',\n'RightUpTeeVector;': '\\u295c',\n'RightUpVector;': '\\u21be',\n'RightUpVectorBar;': '\\u2954',\n'RightVector;': '\\u21c0',\n'RightVectorBar;': '\\u2953',\n'ring;': '\\u02da',\n'risingdotseq;': '\\u2253',\n'rlarr;': '\\u21c4',\n'rlhar;': '\\u21cc',\n'rlm;': '\\u200f',\n'rmoust;': '\\u23b1',\n'rmoustache;': '\\u23b1',\n'rnmid;': '\\u2aee',\n'roang;': '\\u27ed',\n'roarr;': '\\u21fe',\n'robrk;': '\\u27e7',\n'ropar;': '\\u2986',\n'Ropf;': '\\u211d',\n'ropf;': '\\U0001d563',\n'roplus;': '\\u2a2e',\n'rotimes;': '\\u2a35',\n'RoundImplies;': '\\u2970',\n'rpar;': ')',\n'rpargt;': '\\u2994',\n'rppolint;': '\\u2a12',\n'rrarr;': '\\u21c9',\n'Rrightarrow;': '\\u21db',\n'rsaquo;': '\\u203a',\n'Rscr;': '\\u211b',\n'rscr;': '\\U0001d4c7',\n'Rsh;': '\\u21b1',\n'rsh;': '\\u21b1',\n'rsqb;': ']',\n'rsquo;': '\\u2019',\n'rsquor;': '\\u2019',\n'rthree;': '\\u22cc',\n'rtimes;': '\\u22ca',\n'rtri;': '\\u25b9',\n'rtrie;': '\\u22b5',\n'rtrif;': '\\u25b8',\n'rtriltri;': '\\u29ce',\n'RuleDelayed;': '\\u29f4',\n'ruluhar;': '\\u2968',\n'rx;': '\\u211e',\n'Sacute;': '\\u015a',\n'sacute;': '\\u015b',\n'sbquo;': '\\u201a',\n'Sc;': '\\u2abc',\n'sc;': '\\u227b',\n'scap;': '\\u2ab8',\n'Scaron;': '\\u0160',\n'scaron;': '\\u0161',\n'sccue;': '\\u227d',\n'scE;': '\\u2ab4',\n'sce;': '\\u2ab0',\n'Scedil;': '\\u015e',\n'scedil;': '\\u015f',\n'Scirc;': '\\u015c',\n'scirc;': '\\u015d',\n'scnap;': '\\u2aba',\n'scnE;': '\\u2ab6',\n'scnsim;': '\\u22e9',\n'scpolint;': '\\u2a13',\n'scsim;': '\\u227f',\n'Scy;': '\\u0421',\n'scy;': '\\u0441',\n'sdot;': '\\u22c5',\n'sdotb;': '\\u22a1',\n'sdote;': '\\u2a66',\n'searhk;': '\\u2925',\n'seArr;': '\\u21d8',\n'searr;': '\\u2198',\n'searrow;': '\\u2198',\n'sect': '\\xa7',\n'sect;': '\\xa7',\n'semi;': ';',\n'seswar;': '\\u2929',\n'setminus;': '\\u2216',\n'setmn;': '\\u2216',\n'sext;': '\\u2736',\n'Sfr;': '\\U0001d516',\n'sfr;': '\\U0001d530',\n'sfrown;': '\\u2322',\n'sharp;': '\\u266f',\n'SHCHcy;': '\\u0429',\n'shchcy;': '\\u0449',\n'SHcy;': '\\u0428',\n'shcy;': '\\u0448',\n'ShortDownArrow;': '\\u2193',\n'ShortLeftArrow;': '\\u2190',\n'shortmid;': '\\u2223',\n'shortparallel;': '\\u2225',\n'ShortRightArrow;': '\\u2192',\n'ShortUpArrow;': '\\u2191',\n'shy': '\\xad',\n'shy;': '\\xad',\n'Sigma;': '\\u03a3',\n'sigma;': '\\u03c3',\n'sigmaf;': '\\u03c2',\n'sigmav;': '\\u03c2',\n'sim;': '\\u223c',\n'simdot;': '\\u2a6a',\n'sime;': '\\u2243',\n'simeq;': '\\u2243',\n'simg;': '\\u2a9e',\n'simgE;': '\\u2aa0',\n'siml;': '\\u2a9d',\n'simlE;': '\\u2a9f',\n'simne;': '\\u2246',\n'simplus;': '\\u2a24',\n'simrarr;': '\\u2972',\n'slarr;': '\\u2190',\n'SmallCircle;': '\\u2218',\n'smallsetminus;': '\\u2216',\n'smashp;': '\\u2a33',\n'smeparsl;': '\\u29e4',\n'smid;': '\\u2223',\n'smile;': '\\u2323',\n'smt;': '\\u2aaa',\n'smte;': '\\u2aac',\n'smtes;': '\\u2aac\\ufe00',\n'SOFTcy;': '\\u042c',\n'softcy;': '\\u044c',\n'sol;': '/',\n'solb;': '\\u29c4',\n'solbar;': '\\u233f',\n'Sopf;': '\\U0001d54a',\n'sopf;': '\\U0001d564',\n'spades;': '\\u2660',\n'spadesuit;': '\\u2660',\n'spar;': '\\u2225',\n'sqcap;': '\\u2293',\n'sqcaps;': '\\u2293\\ufe00',\n'sqcup;': '\\u2294',\n'sqcups;': '\\u2294\\ufe00',\n'Sqrt;': '\\u221a',\n'sqsub;': '\\u228f',\n'sqsube;': '\\u2291',\n'sqsubset;': '\\u228f',\n'sqsubseteq;': '\\u2291',\n'sqsup;': '\\u2290',\n'sqsupe;': '\\u2292',\n'sqsupset;': '\\u2290',\n'sqsupseteq;': '\\u2292',\n'squ;': '\\u25a1',\n'Square;': '\\u25a1',\n'square;': '\\u25a1',\n'SquareIntersection;': '\\u2293',\n'SquareSubset;': '\\u228f',\n'SquareSubsetEqual;': '\\u2291',\n'SquareSuperset;': '\\u2290',\n'SquareSupersetEqual;': '\\u2292',\n'SquareUnion;': '\\u2294',\n'squarf;': '\\u25aa',\n'squf;': '\\u25aa',\n'srarr;': '\\u2192',\n'Sscr;': '\\U0001d4ae',\n'sscr;': '\\U0001d4c8',\n'ssetmn;': '\\u2216',\n'ssmile;': '\\u2323',\n'sstarf;': '\\u22c6',\n'Star;': '\\u22c6',\n'star;': '\\u2606',\n'starf;': '\\u2605',\n'straightepsilon;': '\\u03f5',\n'straightphi;': '\\u03d5',\n'strns;': '\\xaf',\n'Sub;': '\\u22d0',\n'sub;': '\\u2282',\n'subdot;': '\\u2abd',\n'subE;': '\\u2ac5',\n'sube;': '\\u2286',\n'subedot;': '\\u2ac3',\n'submult;': '\\u2ac1',\n'subnE;': '\\u2acb',\n'subne;': '\\u228a',\n'subplus;': '\\u2abf',\n'subrarr;': '\\u2979',\n'Subset;': '\\u22d0',\n'subset;': '\\u2282',\n'subseteq;': '\\u2286',\n'subseteqq;': '\\u2ac5',\n'SubsetEqual;': '\\u2286',\n'subsetneq;': '\\u228a',\n'subsetneqq;': '\\u2acb',\n'subsim;': '\\u2ac7',\n'subsub;': '\\u2ad5',\n'subsup;': '\\u2ad3',\n'succ;': '\\u227b',\n'succapprox;': '\\u2ab8',\n'succcurlyeq;': '\\u227d',\n'Succeeds;': '\\u227b',\n'SucceedsEqual;': '\\u2ab0',\n'SucceedsSlantEqual;': '\\u227d',\n'SucceedsTilde;': '\\u227f',\n'succeq;': '\\u2ab0',\n'succnapprox;': '\\u2aba',\n'succneqq;': '\\u2ab6',\n'succnsim;': '\\u22e9',\n'succsim;': '\\u227f',\n'SuchThat;': '\\u220b',\n'Sum;': '\\u2211',\n'sum;': '\\u2211',\n'sung;': '\\u266a',\n'sup1': '\\xb9',\n'sup1;': '\\xb9',\n'sup2': '\\xb2',\n'sup2;': '\\xb2',\n'sup3': '\\xb3',\n'sup3;': '\\xb3',\n'Sup;': '\\u22d1',\n'sup;': '\\u2283',\n'supdot;': '\\u2abe',\n'supdsub;': '\\u2ad8',\n'supE;': '\\u2ac6',\n'supe;': '\\u2287',\n'supedot;': '\\u2ac4',\n'Superset;': '\\u2283',\n'SupersetEqual;': '\\u2287',\n'suphsol;': '\\u27c9',\n'suphsub;': '\\u2ad7',\n'suplarr;': '\\u297b',\n'supmult;': '\\u2ac2',\n'supnE;': '\\u2acc',\n'supne;': '\\u228b',\n'supplus;': '\\u2ac0',\n'Supset;': '\\u22d1',\n'supset;': '\\u2283',\n'supseteq;': '\\u2287',\n'supseteqq;': '\\u2ac6',\n'supsetneq;': '\\u228b',\n'supsetneqq;': '\\u2acc',\n'supsim;': '\\u2ac8',\n'supsub;': '\\u2ad4',\n'supsup;': '\\u2ad6',\n'swarhk;': '\\u2926',\n'swArr;': '\\u21d9',\n'swarr;': '\\u2199',\n'swarrow;': '\\u2199',\n'swnwar;': '\\u292a',\n'szlig': '\\xdf',\n'szlig;': '\\xdf',\n'Tab;': '\\t',\n'target;': '\\u2316',\n'Tau;': '\\u03a4',\n'tau;': '\\u03c4',\n'tbrk;': '\\u23b4',\n'Tcaron;': '\\u0164',\n'tcaron;': '\\u0165',\n'Tcedil;': '\\u0162',\n'tcedil;': '\\u0163',\n'Tcy;': '\\u0422',\n'tcy;': '\\u0442',\n'tdot;': '\\u20db',\n'telrec;': '\\u2315',\n'Tfr;': '\\U0001d517',\n'tfr;': '\\U0001d531',\n'there4;': '\\u2234',\n'Therefore;': '\\u2234',\n'therefore;': '\\u2234',\n'Theta;': '\\u0398',\n'theta;': '\\u03b8',\n'thetasym;': '\\u03d1',\n'thetav;': '\\u03d1',\n'thickapprox;': '\\u2248',\n'thicksim;': '\\u223c',\n'ThickSpace;': '\\u205f\\u200a',\n'thinsp;': '\\u2009',\n'ThinSpace;': '\\u2009',\n'thkap;': '\\u2248',\n'thksim;': '\\u223c',\n'THORN': '\\xde',\n'thorn': '\\xfe',\n'THORN;': '\\xde',\n'thorn;': '\\xfe',\n'Tilde;': '\\u223c',\n'tilde;': '\\u02dc',\n'TildeEqual;': '\\u2243',\n'TildeFullEqual;': '\\u2245',\n'TildeTilde;': '\\u2248',\n'times': '\\xd7',\n'times;': '\\xd7',\n'timesb;': '\\u22a0',\n'timesbar;': '\\u2a31',\n'timesd;': '\\u2a30',\n'tint;': '\\u222d',\n'toea;': '\\u2928',\n'top;': '\\u22a4',\n'topbot;': '\\u2336',\n'topcir;': '\\u2af1',\n'Topf;': '\\U0001d54b',\n'topf;': '\\U0001d565',\n'topfork;': '\\u2ada',\n'tosa;': '\\u2929',\n'tprime;': '\\u2034',\n'TRADE;': '\\u2122',\n'trade;': '\\u2122',\n'triangle;': '\\u25b5',\n'triangledown;': '\\u25bf',\n'triangleleft;': '\\u25c3',\n'trianglelefteq;': '\\u22b4',\n'triangleq;': '\\u225c',\n'triangleright;': '\\u25b9',\n'trianglerighteq;': '\\u22b5',\n'tridot;': '\\u25ec',\n'trie;': '\\u225c',\n'triminus;': '\\u2a3a',\n'TripleDot;': '\\u20db',\n'triplus;': '\\u2a39',\n'trisb;': '\\u29cd',\n'tritime;': '\\u2a3b',\n'trpezium;': '\\u23e2',\n'Tscr;': '\\U0001d4af',\n'tscr;': '\\U0001d4c9',\n'TScy;': '\\u0426',\n'tscy;': '\\u0446',\n'TSHcy;': '\\u040b',\n'tshcy;': '\\u045b',\n'Tstrok;': '\\u0166',\n'tstrok;': '\\u0167',\n'twixt;': '\\u226c',\n'twoheadleftarrow;': '\\u219e',\n'twoheadrightarrow;': '\\u21a0',\n'Uacute': '\\xda',\n'uacute': '\\xfa',\n'Uacute;': '\\xda',\n'uacute;': '\\xfa',\n'Uarr;': '\\u219f',\n'uArr;': '\\u21d1',\n'uarr;': '\\u2191',\n'Uarrocir;': '\\u2949',\n'Ubrcy;': '\\u040e',\n'ubrcy;': '\\u045e',\n'Ubreve;': '\\u016c',\n'ubreve;': '\\u016d',\n'Ucirc': '\\xdb',\n'ucirc': '\\xfb',\n'Ucirc;': '\\xdb',\n'ucirc;': '\\xfb',\n'Ucy;': '\\u0423',\n'ucy;': '\\u0443',\n'udarr;': '\\u21c5',\n'Udblac;': '\\u0170',\n'udblac;': '\\u0171',\n'udhar;': '\\u296e',\n'ufisht;': '\\u297e',\n'Ufr;': '\\U0001d518',\n'ufr;': '\\U0001d532',\n'Ugrave': '\\xd9',\n'ugrave': '\\xf9',\n'Ugrave;': '\\xd9',\n'ugrave;': '\\xf9',\n'uHar;': '\\u2963',\n'uharl;': '\\u21bf',\n'uharr;': '\\u21be',\n'uhblk;': '\\u2580',\n'ulcorn;': '\\u231c',\n'ulcorner;': '\\u231c',\n'ulcrop;': '\\u230f',\n'ultri;': '\\u25f8',\n'Umacr;': '\\u016a',\n'umacr;': '\\u016b',\n'uml': '\\xa8',\n'uml;': '\\xa8',\n'UnderBar;': '_',\n'UnderBrace;': '\\u23df',\n'UnderBracket;': '\\u23b5',\n'UnderParenthesis;': '\\u23dd',\n'Union;': '\\u22c3',\n'UnionPlus;': '\\u228e',\n'Uogon;': '\\u0172',\n'uogon;': '\\u0173',\n'Uopf;': '\\U0001d54c',\n'uopf;': '\\U0001d566',\n'UpArrow;': '\\u2191',\n'Uparrow;': '\\u21d1',\n'uparrow;': '\\u2191',\n'UpArrowBar;': '\\u2912',\n'UpArrowDownArrow;': '\\u21c5',\n'UpDownArrow;': '\\u2195',\n'Updownarrow;': '\\u21d5',\n'updownarrow;': '\\u2195',\n'UpEquilibrium;': '\\u296e',\n'upharpoonleft;': '\\u21bf',\n'upharpoonright;': '\\u21be',\n'uplus;': '\\u228e',\n'UpperLeftArrow;': '\\u2196',\n'UpperRightArrow;': '\\u2197',\n'Upsi;': '\\u03d2',\n'upsi;': '\\u03c5',\n'upsih;': '\\u03d2',\n'Upsilon;': '\\u03a5',\n'upsilon;': '\\u03c5',\n'UpTee;': '\\u22a5',\n'UpTeeArrow;': '\\u21a5',\n'upuparrows;': '\\u21c8',\n'urcorn;': '\\u231d',\n'urcorner;': '\\u231d',\n'urcrop;': '\\u230e',\n'Uring;': '\\u016e',\n'uring;': '\\u016f',\n'urtri;': '\\u25f9',\n'Uscr;': '\\U0001d4b0',\n'uscr;': '\\U0001d4ca',\n'utdot;': '\\u22f0',\n'Utilde;': '\\u0168',\n'utilde;': '\\u0169',\n'utri;': '\\u25b5',\n'utrif;': '\\u25b4',\n'uuarr;': '\\u21c8',\n'Uuml': '\\xdc',\n'uuml': '\\xfc',\n'Uuml;': '\\xdc',\n'uuml;': '\\xfc',\n'uwangle;': '\\u29a7',\n'vangrt;': '\\u299c',\n'varepsilon;': '\\u03f5',\n'varkappa;': '\\u03f0',\n'varnothing;': '\\u2205',\n'varphi;': '\\u03d5',\n'varpi;': '\\u03d6',\n'varpropto;': '\\u221d',\n'vArr;': '\\u21d5',\n'varr;': '\\u2195',\n'varrho;': '\\u03f1',\n'varsigma;': '\\u03c2',\n'varsubsetneq;': '\\u228a\\ufe00',\n'varsubsetneqq;': '\\u2acb\\ufe00',\n'varsupsetneq;': '\\u228b\\ufe00',\n'varsupsetneqq;': '\\u2acc\\ufe00',\n'vartheta;': '\\u03d1',\n'vartriangleleft;': '\\u22b2',\n'vartriangleright;': '\\u22b3',\n'Vbar;': '\\u2aeb',\n'vBar;': '\\u2ae8',\n'vBarv;': '\\u2ae9',\n'Vcy;': '\\u0412',\n'vcy;': '\\u0432',\n'VDash;': '\\u22ab',\n'Vdash;': '\\u22a9',\n'vDash;': '\\u22a8',\n'vdash;': '\\u22a2',\n'Vdashl;': '\\u2ae6',\n'Vee;': '\\u22c1',\n'vee;': '\\u2228',\n'veebar;': '\\u22bb',\n'veeeq;': '\\u225a',\n'vellip;': '\\u22ee',\n'Verbar;': '\\u2016',\n'verbar;': '|',\n'Vert;': '\\u2016',\n'vert;': '|',\n'VerticalBar;': '\\u2223',\n'VerticalLine;': '|',\n'VerticalSeparator;': '\\u2758',\n'VerticalTilde;': '\\u2240',\n'VeryThinSpace;': '\\u200a',\n'Vfr;': '\\U0001d519',\n'vfr;': '\\U0001d533',\n'vltri;': '\\u22b2',\n'vnsub;': '\\u2282\\u20d2',\n'vnsup;': '\\u2283\\u20d2',\n'Vopf;': '\\U0001d54d',\n'vopf;': '\\U0001d567',\n'vprop;': '\\u221d',\n'vrtri;': '\\u22b3',\n'Vscr;': '\\U0001d4b1',\n'vscr;': '\\U0001d4cb',\n'vsubnE;': '\\u2acb\\ufe00',\n'vsubne;': '\\u228a\\ufe00',\n'vsupnE;': '\\u2acc\\ufe00',\n'vsupne;': '\\u228b\\ufe00',\n'Vvdash;': '\\u22aa',\n'vzigzag;': '\\u299a',\n'Wcirc;': '\\u0174',\n'wcirc;': '\\u0175',\n'wedbar;': '\\u2a5f',\n'Wedge;': '\\u22c0',\n'wedge;': '\\u2227',\n'wedgeq;': '\\u2259',\n'weierp;': '\\u2118',\n'Wfr;': '\\U0001d51a',\n'wfr;': '\\U0001d534',\n'Wopf;': '\\U0001d54e',\n'wopf;': '\\U0001d568',\n'wp;': '\\u2118',\n'wr;': '\\u2240',\n'wreath;': '\\u2240',\n'Wscr;': '\\U0001d4b2',\n'wscr;': '\\U0001d4cc',\n'xcap;': '\\u22c2',\n'xcirc;': '\\u25ef',\n'xcup;': '\\u22c3',\n'xdtri;': '\\u25bd',\n'Xfr;': '\\U0001d51b',\n'xfr;': '\\U0001d535',\n'xhArr;': '\\u27fa',\n'xharr;': '\\u27f7',\n'Xi;': '\\u039e',\n'xi;': '\\u03be',\n'xlArr;': '\\u27f8',\n'xlarr;': '\\u27f5',\n'xmap;': '\\u27fc',\n'xnis;': '\\u22fb',\n'xodot;': '\\u2a00',\n'Xopf;': '\\U0001d54f',\n'xopf;': '\\U0001d569',\n'xoplus;': '\\u2a01',\n'xotime;': '\\u2a02',\n'xrArr;': '\\u27f9',\n'xrarr;': '\\u27f6',\n'Xscr;': '\\U0001d4b3',\n'xscr;': '\\U0001d4cd',\n'xsqcup;': '\\u2a06',\n'xuplus;': '\\u2a04',\n'xutri;': '\\u25b3',\n'xvee;': '\\u22c1',\n'xwedge;': '\\u22c0',\n'Yacute': '\\xdd',\n'yacute': '\\xfd',\n'Yacute;': '\\xdd',\n'yacute;': '\\xfd',\n'YAcy;': '\\u042f',\n'yacy;': '\\u044f',\n'Ycirc;': '\\u0176',\n'ycirc;': '\\u0177',\n'Ycy;': '\\u042b',\n'ycy;': '\\u044b',\n'yen': '\\xa5',\n'yen;': '\\xa5',\n'Yfr;': '\\U0001d51c',\n'yfr;': '\\U0001d536',\n'YIcy;': '\\u0407',\n'yicy;': '\\u0457',\n'Yopf;': '\\U0001d550',\n'yopf;': '\\U0001d56a',\n'Yscr;': '\\U0001d4b4',\n'yscr;': '\\U0001d4ce',\n'YUcy;': '\\u042e',\n'yucy;': '\\u044e',\n'yuml': '\\xff',\n'Yuml;': '\\u0178',\n'yuml;': '\\xff',\n'Zacute;': '\\u0179',\n'zacute;': '\\u017a',\n'Zcaron;': '\\u017d',\n'zcaron;': '\\u017e',\n'Zcy;': '\\u0417',\n'zcy;': '\\u0437',\n'Zdot;': '\\u017b',\n'zdot;': '\\u017c',\n'zeetrf;': '\\u2128',\n'ZeroWidthSpace;': '\\u200b',\n'Zeta;': '\\u0396',\n'zeta;': '\\u03b6',\n'Zfr;': '\\u2128',\n'zfr;': '\\U0001d537',\n'ZHcy;': '\\u0416',\n'zhcy;': '\\u0436',\n'zigrarr;': '\\u21dd',\n'Zopf;': '\\u2124',\n'zopf;': '\\U0001d56b',\n'Zscr;': '\\U0001d4b5',\n'zscr;': '\\U0001d4cf',\n'zwj;': '\\u200d',\n'zwnj;': '\\u200c',\n}\n\n\ncodepoint2name = {}\n\n\n\nentitydefs = {}\n\nfor (name, codepoint) in name2codepoint.items():\n codepoint2name[codepoint] = name\n entitydefs[name] = chr(codepoint)\n \ndel name, codepoint\n"], "unittest.test.test_loader": [".py", "import sys\nimport types\n\n\nimport unittest\n\n\nclass Test_TestLoader(unittest.TestCase):\n\n\n\n\n\n\n def test_loadTestsFromTestCase(self):\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foo_bar(self): pass\n   \n  tests = unittest.TestSuite([Foo('test_1'), Foo('test_2')])\n  \n  loader = unittest.TestLoader()\n  self.assertEqual(loader.loadTestsFromTestCase(Foo), tests)\n  \n  \n  \n  \n  \n def test_loadTestsFromTestCase__no_matches(self):\n  class Foo(unittest.TestCase):\n   def foo_bar(self): pass\n   \n  empty_suite = unittest.TestSuite()\n  \n  loader = unittest.TestLoader()\n  self.assertEqual(loader.loadTestsFromTestCase(Foo), empty_suite)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_loadTestsFromTestCase__TestSuite_subclass(self):\n  class NotATestCase(unittest.TestSuite):\n   pass\n   \n  loader = unittest.TestLoader()\n  try:\n   loader.loadTestsFromTestCase(NotATestCase)\n  except TypeError:\n   pass\n  else:\n   self.fail('Should raise TypeError')\n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromTestCase__default_method_name(self):\n  class Foo(unittest.TestCase):\n   def runTest(self):\n    pass\n    \n  loader = unittest.TestLoader()\n  \n  self.assertFalse('runTest'.startswith(loader.testMethodPrefix))\n  \n  suite = loader.loadTestsFromTestCase(Foo)\n  self.assertIsInstance(suite, loader.suiteClass)\n  self.assertEqual(list(suite), [Foo('runTest')])\n  \n  \n  \n  \n  \n  \n  \n  \n def test_loadTestsFromModule__TestCase_subclass(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testcase_1 = MyTestCase\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromModule(m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  expected = [loader.suiteClass([MyTestCase('test')])]\n  self.assertEqual(list(suite), expected)\n  \n  \n  \n  \n def test_loadTestsFromModule__no_TestCase_instances(self):\n  m = types.ModuleType('m')\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromModule(m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  self.assertEqual(list(suite), [])\n  \n  \n  \n  \n def test_loadTestsFromModule__no_TestCase_tests(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   pass\n  m.testcase_1 = MyTestCase\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromModule(m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  self.assertEqual(list(suite), [loader.suiteClass()])\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_loadTestsFromModule__not_a_module(self):\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n    \n  class NotAModule(object):\n   test_2 = MyTestCase\n   \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromModule(NotAModule)\n  \n  reference = [unittest.TestSuite([MyTestCase('test')])]\n  self.assertEqual(list(suite), reference)\n  \n  \n  \n  \n def test_loadTestsFromModule__load_tests(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testcase_1 = MyTestCase\n  \n  load_tests_args = []\n  def load_tests(loader, tests, pattern):\n   self.assertIsInstance(tests, unittest.TestSuite)\n   load_tests_args.extend((loader, tests, pattern))\n   return tests\n  m.load_tests = load_tests\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromModule(m)\n  self.assertIsInstance(suite, unittest.TestSuite)\n  self.assertEqual(load_tests_args, [loader, suite, None])\n  \n  load_tests_args = []\n  suite = loader.loadTestsFromModule(m, use_load_tests=False)\n  self.assertEqual(load_tests_args, [])\n  \n def test_loadTestsFromModule__faulty_load_tests(self):\n  m = types.ModuleType('m')\n  \n  def load_tests(loader, tests, pattern):\n   raise TypeError('some failure')\n  m.load_tests = load_tests\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromModule(m)\n  self.assertIsInstance(suite, unittest.TestSuite)\n  self.assertEqual(suite.countTestCases(), 1)\n  test = list(suite)[0]\n  \n  self.assertRaisesRegex(TypeError, \"some failure\", test.m)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_loadTestsFromName__empty_name(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromName('')\n  except ValueError as e:\n   self.assertEqual(str(e), \"Empty module name\")\n  else:\n   self.fail(\"TestLoader.loadTestsFromName failed to raise ValueError\")\n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromName__malformed_name(self):\n  loader = unittest.TestLoader()\n  \n  \n  try:\n   loader.loadTestsFromName('abc () //')\n  except ValueError:\n   pass\n  except ImportError:\n   pass\n  else:\n   self.fail(\"TestLoader.loadTestsFromName failed to raise ValueError\")\n   \n   \n   \n   \n   \n def test_loadTestsFromName__unknown_module_name(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromName('sdasfasfasdf')\n  except ImportError as e:\n   self.assertEqual(str(e), \"No module named 'sdasfasfasdf'\")\n  else:\n   self.fail(\"TestLoader.loadTestsFromName failed to raise ImportError\")\n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromName__unknown_attr_name(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromName('unittest.sdasfasfasdf')\n  except AttributeError as e:\n   self.assertEqual(str(e), \"'module' object has no attribute 'sdasfasfasdf'\")\n  else:\n   self.fail(\"TestLoader.loadTestsFromName failed to raise AttributeError\")\n   \n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromName__relative_unknown_name(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromName('sdasfasfasdf', unittest)\n  except AttributeError as e:\n   self.assertEqual(str(e), \"'module' object has no attribute 'sdasfasfasdf'\")\n  else:\n   self.fail(\"TestLoader.loadTestsFromName failed to raise AttributeError\")\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromName__relative_empty_name(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromName('', unittest)\n  except AttributeError as e:\n   pass\n  else:\n   self.fail(\"Failed to raise AttributeError\")\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromName__relative_malformed_name(self):\n  loader = unittest.TestLoader()\n  \n  \n  try:\n   loader.loadTestsFromName('abc () //', unittest)\n  except ValueError:\n   pass\n  except AttributeError:\n   pass\n  else:\n   self.fail(\"TestLoader.loadTestsFromName failed to raise ValueError\")\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromName__relative_not_a_module(self):\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n    \n  class NotAModule(object):\n   test_2 = MyTestCase\n   \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromName('test_2', NotAModule)\n  \n  reference = [MyTestCase('test')]\n  self.assertEqual(list(suite), reference)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_loadTestsFromName__relative_bad_object(self):\n  m = types.ModuleType('m')\n  m.testcase_1 = object()\n  \n  loader = unittest.TestLoader()\n  try:\n   loader.loadTestsFromName('testcase_1', m)\n  except TypeError:\n   pass\n  else:\n   self.fail(\"Should have raised TypeError\")\n   \n   \n   \n def test_loadTestsFromName__relative_TestCase_subclass(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testcase_1 = MyTestCase\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromName('testcase_1', m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  self.assertEqual(list(suite), [MyTestCase('test')])\n  \n  \n  \n  \n  \n def test_loadTestsFromName__relative_TestSuite(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testsuite = unittest.TestSuite([MyTestCase('test')])\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromName('testsuite', m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  self.assertEqual(list(suite), [MyTestCase('test')])\n  \n  \n  \n def test_loadTestsFromName__relative_testmethod(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testcase_1 = MyTestCase\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromName('testcase_1.test', m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  self.assertEqual(list(suite), [MyTestCase('test')])\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_loadTestsFromName__relative_invalid_testmethod(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testcase_1 = MyTestCase\n  \n  loader = unittest.TestLoader()\n  try:\n   loader.loadTestsFromName('testcase_1.testfoo', m)\n  except AttributeError as e:\n   self.assertEqual(str(e), \"type object 'MyTestCase' has no attribute 'testfoo'\")\n  else:\n   self.fail(\"Failed to raise AttributeError\")\n   \n   \n   \n def test_loadTestsFromName__callable__TestSuite(self):\n  m = types.ModuleType('m')\n  testcase_1 = unittest.FunctionTestCase(lambda: None)\n  testcase_2 = unittest.FunctionTestCase(lambda: None)\n  def return_TestSuite():\n   return unittest.TestSuite([testcase_1, testcase_2])\n  m.return_TestSuite = return_TestSuite\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromName('return_TestSuite', m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  self.assertEqual(list(suite), [testcase_1, testcase_2])\n  \n  \n  \n def test_loadTestsFromName__callable__TestCase_instance(self):\n  m = types.ModuleType('m')\n  testcase_1 = unittest.FunctionTestCase(lambda: None)\n  def return_TestCase():\n   return testcase_1\n  m.return_TestCase = return_TestCase\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromName('return_TestCase', m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  self.assertEqual(list(suite), [testcase_1])\n  \n  \n  \n  \n  \n  \n def test_loadTestsFromName__callable__TestCase_instance_ProperSuiteClass(self):\n  class SubTestSuite(unittest.TestSuite):\n   pass\n  m = types.ModuleType('m')\n  testcase_1 = unittest.FunctionTestCase(lambda: None)\n  def return_TestCase():\n   return testcase_1\n  m.return_TestCase = return_TestCase\n  \n  loader = unittest.TestLoader()\n  loader.suiteClass = SubTestSuite\n  suite = loader.loadTestsFromName('return_TestCase', m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  self.assertEqual(list(suite), [testcase_1])\n  \n  \n  \n  \n  \n  \n def test_loadTestsFromName__relative_testmethod_ProperSuiteClass(self):\n  class SubTestSuite(unittest.TestSuite):\n   pass\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testcase_1 = MyTestCase\n  \n  loader = unittest.TestLoader()\n  loader.suiteClass=SubTestSuite\n  suite = loader.loadTestsFromName('testcase_1.test', m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  self.assertEqual(list(suite), [MyTestCase('test')])\n  \n  \n  \n  \n  \n def test_loadTestsFromName__callable__wrong_type(self):\n  m = types.ModuleType('m')\n  def return_wrong():\n   return 6\n  m.return_wrong = return_wrong\n  \n  loader = unittest.TestLoader()\n  try:\n   suite = loader.loadTestsFromName('return_wrong', m)\n  except TypeError:\n   pass\n  else:\n   self.fail(\"TestLoader.loadTestsFromName failed to raise TypeError\")\n   \n   \n   \n def test_loadTestsFromName__module_not_loaded(self):\n \n \n \n  module_name = 'unittest.test.dummy'\n  sys.modules.pop(module_name, None)\n  \n  loader = unittest.TestLoader()\n  try:\n   suite = loader.loadTestsFromName(module_name)\n   \n   self.assertIsInstance(suite, loader.suiteClass)\n   self.assertEqual(list(suite), [])\n   \n   \n   self.assertIn(module_name, sys.modules)\n  finally:\n   if module_name in sys.modules:\n    del sys.modules[module_name]\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n def test_loadTestsFromNames__empty_name_list(self):\n  loader = unittest.TestLoader()\n  \n  suite = loader.loadTestsFromNames([])\n  self.assertIsInstance(suite, loader.suiteClass)\n  self.assertEqual(list(suite), [])\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_loadTestsFromNames__relative_empty_name_list(self):\n  loader = unittest.TestLoader()\n  \n  suite = loader.loadTestsFromNames([], unittest)\n  self.assertIsInstance(suite, loader.suiteClass)\n  self.assertEqual(list(suite), [])\n  \n  \n  \n  \n  \n  \n  \n def test_loadTestsFromNames__empty_name(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromNames([''])\n  except ValueError as e:\n   self.assertEqual(str(e), \"Empty module name\")\n  else:\n   self.fail(\"TestLoader.loadTestsFromNames failed to raise ValueError\")\n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromNames__malformed_name(self):\n  loader = unittest.TestLoader()\n  \n  \n  try:\n   loader.loadTestsFromNames(['abc () //'])\n  except ValueError:\n   pass\n  except ImportError:\n   pass\n  else:\n   self.fail(\"TestLoader.loadTestsFromNames failed to raise ValueError\")\n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromNames__unknown_module_name(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromNames(['sdasfasfasdf'])\n  except ImportError as e:\n   self.assertEqual(str(e), \"No module named 'sdasfasfasdf'\")\n  else:\n   self.fail(\"TestLoader.loadTestsFromNames failed to raise ImportError\")\n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromNames__unknown_attr_name(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromNames(['unittest.sdasfasfasdf', 'unittest'])\n  except AttributeError as e:\n   self.assertEqual(str(e), \"'module' object has no attribute 'sdasfasfasdf'\")\n  else:\n   self.fail(\"TestLoader.loadTestsFromNames failed to raise AttributeError\")\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromNames__unknown_name_relative_1(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromNames(['sdasfasfasdf'], unittest)\n  except AttributeError as e:\n   self.assertEqual(str(e), \"'module' object has no attribute 'sdasfasfasdf'\")\n  else:\n   self.fail(\"TestLoader.loadTestsFromName failed to raise AttributeError\")\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromNames__unknown_name_relative_2(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromNames(['TestCase', 'sdasfasfasdf'], unittest)\n  except AttributeError as e:\n   self.assertEqual(str(e), \"'module' object has no attribute 'sdasfasfasdf'\")\n  else:\n   self.fail(\"TestLoader.loadTestsFromName failed to raise AttributeError\")\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromNames__relative_empty_name(self):\n  loader = unittest.TestLoader()\n  \n  try:\n   loader.loadTestsFromNames([''], unittest)\n  except AttributeError:\n   pass\n  else:\n   self.fail(\"Failed to raise ValueError\")\n   \n   \n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromNames__relative_malformed_name(self):\n  loader = unittest.TestLoader()\n  \n  \n  try:\n   loader.loadTestsFromNames(['abc () //'], unittest)\n  except AttributeError:\n   pass\n  except ValueError:\n   pass\n  else:\n   self.fail(\"TestLoader.loadTestsFromNames failed to raise ValueError\")\n   \n   \n   \n   \n   \n   \n   \n   \n def test_loadTestsFromNames__relative_not_a_module(self):\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n    \n  class NotAModule(object):\n   test_2 = MyTestCase\n   \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromNames(['test_2'], NotAModule)\n  \n  reference = [unittest.TestSuite([MyTestCase('test')])]\n  self.assertEqual(list(suite), reference)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_loadTestsFromNames__relative_bad_object(self):\n  m = types.ModuleType('m')\n  m.testcase_1 = object()\n  \n  loader = unittest.TestLoader()\n  try:\n   loader.loadTestsFromNames(['testcase_1'], m)\n  except TypeError:\n   pass\n  else:\n   self.fail(\"Should have raised TypeError\")\n   \n   \n   \n def test_loadTestsFromNames__relative_TestCase_subclass(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testcase_1 = MyTestCase\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromNames(['testcase_1'], m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  expected = loader.suiteClass([MyTestCase('test')])\n  self.assertEqual(list(suite), [expected])\n  \n  \n  \n def test_loadTestsFromNames__relative_TestSuite(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testsuite = unittest.TestSuite([MyTestCase('test')])\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromNames(['testsuite'], m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  self.assertEqual(list(suite), [m.testsuite])\n  \n  \n  \n def test_loadTestsFromNames__relative_testmethod(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testcase_1 = MyTestCase\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromNames(['testcase_1.test'], m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  ref_suite = unittest.TestSuite([MyTestCase('test')])\n  self.assertEqual(list(suite), [ref_suite])\n  \n  \n  \n  \n  \n  \n def test_loadTestsFromNames__relative_invalid_testmethod(self):\n  m = types.ModuleType('m')\n  class MyTestCase(unittest.TestCase):\n   def test(self):\n    pass\n  m.testcase_1 = MyTestCase\n  \n  loader = unittest.TestLoader()\n  try:\n   loader.loadTestsFromNames(['testcase_1.testfoo'], m)\n  except AttributeError as e:\n   self.assertEqual(str(e), \"type object 'MyTestCase' has no attribute 'testfoo'\")\n  else:\n   self.fail(\"Failed to raise AttributeError\")\n   \n   \n   \n def test_loadTestsFromNames__callable__TestSuite(self):\n  m = types.ModuleType('m')\n  testcase_1 = unittest.FunctionTestCase(lambda: None)\n  testcase_2 = unittest.FunctionTestCase(lambda: None)\n  def return_TestSuite():\n   return unittest.TestSuite([testcase_1, testcase_2])\n  m.return_TestSuite = return_TestSuite\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromNames(['return_TestSuite'], m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  expected = unittest.TestSuite([testcase_1, testcase_2])\n  self.assertEqual(list(suite), [expected])\n  \n  \n  \n def test_loadTestsFromNames__callable__TestCase_instance(self):\n  m = types.ModuleType('m')\n  testcase_1 = unittest.FunctionTestCase(lambda: None)\n  def return_TestCase():\n   return testcase_1\n  m.return_TestCase = return_TestCase\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromNames(['return_TestCase'], m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  ref_suite = unittest.TestSuite([testcase_1])\n  self.assertEqual(list(suite), [ref_suite])\n  \n  \n  \n  \n  \n def test_loadTestsFromNames__callable__call_staticmethod(self):\n  m = types.ModuleType('m')\n  class Test1(unittest.TestCase):\n   def test(self):\n    pass\n    \n  testcase_1 = Test1('test')\n  class Foo(unittest.TestCase):\n   @staticmethod\n   def foo():\n    return testcase_1\n  m.Foo = Foo\n  \n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromNames(['Foo.foo'], m)\n  self.assertIsInstance(suite, loader.suiteClass)\n  \n  ref_suite = unittest.TestSuite([testcase_1])\n  self.assertEqual(list(suite), [ref_suite])\n  \n  \n  \n  \n  \n def test_loadTestsFromNames__callable__wrong_type(self):\n  m = types.ModuleType('m')\n  def return_wrong():\n   return 6\n  m.return_wrong = return_wrong\n  \n  loader = unittest.TestLoader()\n  try:\n   suite = loader.loadTestsFromNames(['return_wrong'], m)\n  except TypeError:\n   pass\n  else:\n   self.fail(\"TestLoader.loadTestsFromNames failed to raise TypeError\")\n   \n   \n   \n def test_loadTestsFromNames__module_not_loaded(self):\n \n \n \n  module_name = 'unittest.test.dummy'\n  sys.modules.pop(module_name, None)\n  \n  loader = unittest.TestLoader()\n  try:\n   suite = loader.loadTestsFromNames([module_name])\n   \n   self.assertIsInstance(suite, loader.suiteClass)\n   self.assertEqual(list(suite), [unittest.TestSuite()])\n   \n   \n   self.assertIn(module_name, sys.modules)\n  finally:\n   if module_name in sys.modules:\n    del sys.modules[module_name]\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n def test_getTestCaseNames(self):\n  class Test(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foobar(self): pass\n   \n  loader = unittest.TestLoader()\n  \n  self.assertEqual(loader.getTestCaseNames(Test), ['test_1', 'test_2'])\n  \n  \n  \n  \n def test_getTestCaseNames__no_tests(self):\n  class Test(unittest.TestCase):\n   def foobar(self): pass\n   \n  loader = unittest.TestLoader()\n  \n  self.assertEqual(loader.getTestCaseNames(Test), [])\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_getTestCaseNames__not_a_TestCase(self):\n  class BadCase(int):\n   def test_foo(self):\n    pass\n    \n  loader = unittest.TestLoader()\n  names = loader.getTestCaseNames(BadCase)\n  \n  self.assertEqual(names, ['test_foo'])\n  \n  \n  \n  \n  \n  \n  \n def test_getTestCaseNames__inheritance(self):\n  class TestP(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foobar(self): pass\n   \n  class TestC(TestP):\n   def test_1(self): pass\n   def test_3(self): pass\n   \n  loader = unittest.TestLoader()\n  \n  names = ['test_1', 'test_2', 'test_3']\n  self.assertEqual(loader.getTestCaseNames(TestC), names)\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_testMethodPrefix__loadTestsFromTestCase(self):\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foo_bar(self): pass\n   \n  tests_1 = unittest.TestSuite([Foo('foo_bar')])\n  tests_2 = unittest.TestSuite([Foo('test_1'), Foo('test_2')])\n  \n  loader = unittest.TestLoader()\n  loader.testMethodPrefix = 'foo'\n  self.assertEqual(loader.loadTestsFromTestCase(Foo), tests_1)\n  \n  loader.testMethodPrefix = 'test'\n  self.assertEqual(loader.loadTestsFromTestCase(Foo), tests_2)\n  \n  \n  \n  \n  \n  \n def test_testMethodPrefix__loadTestsFromModule(self):\n  m = types.ModuleType('m')\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foo_bar(self): pass\n  m.Foo = Foo\n  \n  tests_1 = [unittest.TestSuite([Foo('foo_bar')])]\n  tests_2 = [unittest.TestSuite([Foo('test_1'), Foo('test_2')])]\n  \n  loader = unittest.TestLoader()\n  loader.testMethodPrefix = 'foo'\n  self.assertEqual(list(loader.loadTestsFromModule(m)), tests_1)\n  \n  loader.testMethodPrefix = 'test'\n  self.assertEqual(list(loader.loadTestsFromModule(m)), tests_2)\n  \n  \n  \n  \n  \n  \n def test_testMethodPrefix__loadTestsFromName(self):\n  m = types.ModuleType('m')\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foo_bar(self): pass\n  m.Foo = Foo\n  \n  tests_1 = unittest.TestSuite([Foo('foo_bar')])\n  tests_2 = unittest.TestSuite([Foo('test_1'), Foo('test_2')])\n  \n  loader = unittest.TestLoader()\n  loader.testMethodPrefix = 'foo'\n  self.assertEqual(loader.loadTestsFromName('Foo', m), tests_1)\n  \n  loader.testMethodPrefix = 'test'\n  self.assertEqual(loader.loadTestsFromName('Foo', m), tests_2)\n  \n  \n  \n  \n  \n  \n def test_testMethodPrefix__loadTestsFromNames(self):\n  m = types.ModuleType('m')\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foo_bar(self): pass\n  m.Foo = Foo\n  \n  tests_1 = unittest.TestSuite([unittest.TestSuite([Foo('foo_bar')])])\n  tests_2 = unittest.TestSuite([Foo('test_1'), Foo('test_2')])\n  tests_2 = unittest.TestSuite([tests_2])\n  \n  loader = unittest.TestLoader()\n  loader.testMethodPrefix = 'foo'\n  self.assertEqual(loader.loadTestsFromNames(['Foo'], m), tests_1)\n  \n  loader.testMethodPrefix = 'test'\n  self.assertEqual(loader.loadTestsFromNames(['Foo'], m), tests_2)\n  \n  \n def test_testMethodPrefix__default_value(self):\n  loader = unittest.TestLoader()\n  self.assertEqual(loader.testMethodPrefix, 'test')\n  \n  \n  \n  \n  \n  \n  \n  \n  \n def test_sortTestMethodsUsing__loadTestsFromTestCase(self):\n  def reversed_cmp(x, y):\n   return -((x > y) - (x < y))\n   \n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   \n  loader = unittest.TestLoader()\n  loader.sortTestMethodsUsing = reversed_cmp\n  \n  tests = loader.suiteClass([Foo('test_2'), Foo('test_1')])\n  self.assertEqual(loader.loadTestsFromTestCase(Foo), tests)\n  \n  \n  \n def test_sortTestMethodsUsing__loadTestsFromModule(self):\n  def reversed_cmp(x, y):\n   return -((x > y) - (x < y))\n   \n  m = types.ModuleType('m')\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n  m.Foo = Foo\n  \n  loader = unittest.TestLoader()\n  loader.sortTestMethodsUsing = reversed_cmp\n  \n  tests = [loader.suiteClass([Foo('test_2'), Foo('test_1')])]\n  self.assertEqual(list(loader.loadTestsFromModule(m)), tests)\n  \n  \n  \n def test_sortTestMethodsUsing__loadTestsFromName(self):\n  def reversed_cmp(x, y):\n   return -((x > y) - (x < y))\n   \n  m = types.ModuleType('m')\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n  m.Foo = Foo\n  \n  loader = unittest.TestLoader()\n  loader.sortTestMethodsUsing = reversed_cmp\n  \n  tests = loader.suiteClass([Foo('test_2'), Foo('test_1')])\n  self.assertEqual(loader.loadTestsFromName('Foo', m), tests)\n  \n  \n  \n def test_sortTestMethodsUsing__loadTestsFromNames(self):\n  def reversed_cmp(x, y):\n   return -((x > y) - (x < y))\n   \n  m = types.ModuleType('m')\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n  m.Foo = Foo\n  \n  loader = unittest.TestLoader()\n  loader.sortTestMethodsUsing = reversed_cmp\n  \n  tests = [loader.suiteClass([Foo('test_2'), Foo('test_1')])]\n  self.assertEqual(list(loader.loadTestsFromNames(['Foo'], m)), tests)\n  \n  \n  \n  \n  \n def test_sortTestMethodsUsing__getTestCaseNames(self):\n  def reversed_cmp(x, y):\n   return -((x > y) - (x < y))\n   \n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   \n  loader = unittest.TestLoader()\n  loader.sortTestMethodsUsing = reversed_cmp\n  \n  test_names = ['test_2', 'test_1']\n  self.assertEqual(loader.getTestCaseNames(Foo), test_names)\n  \n  \n  \n  \n def test_sortTestMethodsUsing__default_value(self):\n  loader = unittest.TestLoader()\n  \n  class Foo(unittest.TestCase):\n   def test_2(self): pass\n   def test_3(self): pass\n   def test_1(self): pass\n   \n  test_names = ['test_2', 'test_3', 'test_1']\n  self.assertEqual(loader.getTestCaseNames(Foo), sorted(test_names))\n  \n  \n  \n  \n  \n  \n def test_sortTestMethodsUsing__None(self):\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   \n  loader = unittest.TestLoader()\n  loader.sortTestMethodsUsing = None\n  \n  test_names = ['test_2', 'test_1']\n  self.assertEqual(set(loader.getTestCaseNames(Foo)), set(test_names))\n  \n  \n  \n  \n  \n  \n  \n  \n def test_suiteClass__loadTestsFromTestCase(self):\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foo_bar(self): pass\n   \n  tests = [Foo('test_1'), Foo('test_2')]\n  \n  loader = unittest.TestLoader()\n  loader.suiteClass = list\n  self.assertEqual(loader.loadTestsFromTestCase(Foo), tests)\n  \n  \n  \n def test_suiteClass__loadTestsFromModule(self):\n  m = types.ModuleType('m')\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foo_bar(self): pass\n  m.Foo = Foo\n  \n  tests = [[Foo('test_1'), Foo('test_2')]]\n  \n  loader = unittest.TestLoader()\n  loader.suiteClass = list\n  self.assertEqual(loader.loadTestsFromModule(m), tests)\n  \n  \n  \n def test_suiteClass__loadTestsFromName(self):\n  m = types.ModuleType('m')\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foo_bar(self): pass\n  m.Foo = Foo\n  \n  tests = [Foo('test_1'), Foo('test_2')]\n  \n  loader = unittest.TestLoader()\n  loader.suiteClass = list\n  self.assertEqual(loader.loadTestsFromName('Foo', m), tests)\n  \n  \n  \n def test_suiteClass__loadTestsFromNames(self):\n  m = types.ModuleType('m')\n  class Foo(unittest.TestCase):\n   def test_1(self): pass\n   def test_2(self): pass\n   def foo_bar(self): pass\n  m.Foo = Foo\n  \n  tests = [[Foo('test_1'), Foo('test_2')]]\n  \n  loader = unittest.TestLoader()\n  loader.suiteClass = list\n  self.assertEqual(loader.loadTestsFromNames(['Foo'], m), tests)\n  \n  \n def test_suiteClass__default_value(self):\n  loader = unittest.TestLoader()\n  self.assertTrue(loader.suiteClass is unittest.TestSuite)\n"], "unittest.test.test_runner": [".py", "import io\nimport os\nimport sys\nimport pickle\nimport subprocess\n\nimport unittest\n\nfrom .support import LoggingResult, ResultWithNoStartTestRunStopTestRun\n\n\nclass TestCleanUp(unittest.TestCase):\n\n def testCleanUp(self):\n  class TestableTest(unittest.TestCase):\n   def testNothing(self):\n    pass\n    \n  test = TestableTest('testNothing')\n  self.assertEqual(test._cleanups, [])\n  \n  cleanups = []\n  \n  def cleanup1(*args, **kwargs):\n   cleanups.append((1, args, kwargs))\n   \n  def cleanup2(*args, **kwargs):\n   cleanups.append((2, args, kwargs))\n   \n  test.addCleanup(cleanup1, 1, 2, 3, four='hello', five='goodbye')\n  test.addCleanup(cleanup2)\n  \n  self.assertEqual(test._cleanups,\n  [(cleanup1, (1, 2, 3), dict(four='hello', five='goodbye')),\n  (cleanup2, (), {})])\n  \n  self.assertTrue(test.doCleanups())\n  self.assertEqual(cleanups, [(2, (), {}), (1, (1, 2, 3), dict(four='hello', five='goodbye'))])\n  \n def testCleanUpWithErrors(self):\n  class TestableTest(unittest.TestCase):\n   def testNothing(self):\n    pass\n    \n  class MockOutcome(object):\n   success = True\n   errors = []\n   \n  test = TestableTest('testNothing')\n  test._outcomeForDoCleanups = MockOutcome\n  \n  exc1 = Exception('foo')\n  exc2 = Exception('bar')\n  def cleanup1():\n   raise exc1\n   \n  def cleanup2():\n   raise exc2\n   \n  test.addCleanup(cleanup1)\n  test.addCleanup(cleanup2)\n  \n  self.assertFalse(test.doCleanups())\n  self.assertFalse(MockOutcome.success)\n  \n  (Type1, instance1, _), (Type2, instance2, _) = reversed(MockOutcome.errors)\n  self.assertEqual((Type1, instance1), (Exception, exc1))\n  self.assertEqual((Type2, instance2), (Exception, exc2))\n  \n def testCleanupInRun(self):\n  blowUp = False\n  ordering = []\n  \n  class TestableTest(unittest.TestCase):\n   def setUp(self):\n    ordering.append('setUp')\n    if blowUp:\n     raise Exception('foo')\n     \n   def testNothing(self):\n    ordering.append('test')\n    \n   def tearDown(self):\n    ordering.append('tearDown')\n    \n  test = TestableTest('testNothing')\n  \n  def cleanup1():\n   ordering.append('cleanup1')\n  def cleanup2():\n   ordering.append('cleanup2')\n  test.addCleanup(cleanup1)\n  test.addCleanup(cleanup2)\n  \n  def success(some_test):\n   self.assertEqual(some_test, test)\n   ordering.append('success')\n   \n  result = unittest.TestResult()\n  result.addSuccess = success\n  \n  test.run(result)\n  self.assertEqual(ordering, ['setUp', 'test', 'tearDown',\n  'cleanup2', 'cleanup1', 'success'])\n  \n  blowUp = True\n  ordering = []\n  test = TestableTest('testNothing')\n  test.addCleanup(cleanup1)\n  test.run(result)\n  self.assertEqual(ordering, ['setUp', 'cleanup1'])\n  \n def testTestCaseDebugExecutesCleanups(self):\n  ordering = []\n  \n  class TestableTest(unittest.TestCase):\n   def setUp(self):\n    ordering.append('setUp')\n    self.addCleanup(cleanup1)\n    \n   def testNothing(self):\n    ordering.append('test')\n    \n   def tearDown(self):\n    ordering.append('tearDown')\n    \n  test = TestableTest('testNothing')\n  \n  def cleanup1():\n   ordering.append('cleanup1')\n   test.addCleanup(cleanup2)\n  def cleanup2():\n   ordering.append('cleanup2')\n   \n  test.debug()\n  self.assertEqual(ordering, ['setUp', 'test', 'tearDown', 'cleanup1', 'cleanup2'])\n  \n  \nclass Test_TextTestRunner(unittest.TestCase):\n \"\"\n \n def test_init(self):\n  runner = unittest.TextTestRunner()\n  self.assertFalse(runner.failfast)\n  self.assertFalse(runner.buffer)\n  self.assertEqual(runner.verbosity, 1)\n  self.assertEqual(runner.warnings, None)\n  self.assertTrue(runner.descriptions)\n  self.assertEqual(runner.resultclass, unittest.TextTestResult)\n  \n  \n def testBufferAndFailfast(self):\n  class Test(unittest.TestCase):\n   def testFoo(self):\n    pass\n  result = unittest.TestResult()\n  runner = unittest.TextTestRunner(stream=io.StringIO(), failfast=True,\n  buffer=True)\n  \n  runner._makeResult = lambda: result\n  runner.run(Test('testFoo'))\n  \n  self.assertTrue(result.failfast)\n  self.assertTrue(result.buffer)\n  \n def testRunnerRegistersResult(self):\n  class Test(unittest.TestCase):\n   def testFoo(self):\n    pass\n  originalRegisterResult = unittest.runner.registerResult\n  def cleanup():\n   unittest.runner.registerResult = originalRegisterResult\n  self.addCleanup(cleanup)\n  \n  result = unittest.TestResult()\n  runner = unittest.TextTestRunner(stream=io.StringIO())\n  \n  runner._makeResult = lambda: result\n  \n  self.wasRegistered = 0\n  def fakeRegisterResult(thisResult):\n   self.wasRegistered += 1\n   self.assertEqual(thisResult, result)\n  unittest.runner.registerResult = fakeRegisterResult\n  \n  runner.run(unittest.TestSuite())\n  self.assertEqual(self.wasRegistered, 1)\n  \n def test_works_with_result_without_startTestRun_stopTestRun(self):\n  class OldTextResult(ResultWithNoStartTestRunStopTestRun):\n   separator2 = ''\n   def printErrors(self):\n    pass\n    \n  class Runner(unittest.TextTestRunner):\n   def __init__(self):\n    super(Runner, self).__init__(io.StringIO())\n    \n   def _makeResult(self):\n    return OldTextResult()\n    \n  runner = Runner()\n  runner.run(unittest.TestSuite())\n  \n def test_startTestRun_stopTestRun_called(self):\n  class LoggingTextResult(LoggingResult):\n   separator2 = ''\n   def printErrors(self):\n    pass\n    \n  class LoggingRunner(unittest.TextTestRunner):\n   def __init__(self, events):\n    super(LoggingRunner, self).__init__(io.StringIO())\n    self._events = events\n    \n   def _makeResult(self):\n    return LoggingTextResult(self._events)\n    \n  events = []\n  runner = LoggingRunner(events)\n  runner.run(unittest.TestSuite())\n  expected = ['startTestRun', 'stopTestRun']\n  self.assertEqual(events, expected)\n  \n def test_pickle_unpickle(self):\n \n \n  stream = io.StringIO(\"foo\")\n  runner = unittest.TextTestRunner(stream)\n  for protocol in range(2, pickle.HIGHEST_PROTOCOL + 1):\n   s = pickle.dumps(runner, protocol)\n   obj = pickle.loads(s)\n   \n   self.assertEqual(obj.stream.getvalue(), stream.getvalue())\n   \n def test_resultclass(self):\n  def MockResultClass(*args):\n   return args\n  STREAM = object()\n  DESCRIPTIONS = object()\n  VERBOSITY = object()\n  runner = unittest.TextTestRunner(STREAM, DESCRIPTIONS, VERBOSITY,\n  resultclass=MockResultClass)\n  self.assertEqual(runner.resultclass, MockResultClass)\n  \n  expectedresult = (runner.stream, DESCRIPTIONS, VERBOSITY)\n  self.assertEqual(runner._makeResult(), expectedresult)\n  \n def test_warnings(self):\n  \"\"\n  \n  \n  def get_parse_out_err(p):\n   return [b.splitlines() for b in p.communicate()]\n  opts = dict(stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n  cwd=os.path.dirname(__file__))\n  ae_msg = b'Please use assertEqual instead.'\n  at_msg = b'Please use assertTrue instead.'\n  \n  \n  p = subprocess.Popen([sys.executable, '_test_warnings.py'], **opts)\n  out, err = get_parse_out_err(p)\n  self.assertIn(b'OK', err)\n  \n  self.assertEqual(len(out), 12)\n  \n  for msg in [b'dw', b'iw', b'uw']:\n   self.assertEqual(out.count(msg), 3)\n  for msg in [ae_msg, at_msg, b'rw']:\n   self.assertEqual(out.count(msg), 1)\n   \n  args_list = (\n  \n  [sys.executable, '_test_warnings.py', 'ignore'],\n  \n  [sys.executable, '-Wa', '_test_warnings.py', 'ignore'],\n  \n  [sys.executable, '-Wi', '_test_warnings.py']\n  )\n  \n  for args in args_list:\n   p = subprocess.Popen(args, **opts)\n   out, err = get_parse_out_err(p)\n   self.assertIn(b'OK', err)\n   self.assertEqual(len(out), 0)\n   \n   \n   \n   \n  p = subprocess.Popen([sys.executable, '_test_warnings.py', 'always'],\n  **opts)\n  out, err = get_parse_out_err(p)\n  self.assertIn(b'OK', err)\n  self.assertEqual(len(out), 14)\n  for msg in [b'dw', b'iw', b'uw', b'rw']:\n   self.assertEqual(out.count(msg), 3)\n  for msg in [ae_msg, at_msg]:\n   self.assertEqual(out.count(msg), 1)\n   \n def testStdErrLookedUpAtInstantiationTime(self):\n \n  old_stderr = sys.stderr\n  f = io.StringIO()\n  sys.stderr = f\n  try:\n   runner = unittest.TextTestRunner()\n   self.assertTrue(runner.stream.stream is f)\n  finally:\n   sys.stderr = old_stderr\n   \n def testSpecifiedStreamUsed(self):\n \n  f = io.StringIO()\n  runner = unittest.TextTestRunner(f)\n  self.assertTrue(runner.stream.stream is f)\n"], "urllib.request": [".py", "from browser import ajax\n\nclass FileIO:\n def __init__(self, data):\n  self._data=data\n  \n def read(self):\n  return self._data\n  \ndef urlopen(url, data=None, timeout=None):\n global result\n result=None\n \n def on_complete(req):\n  global result\n  result=req\n  \n _ajax=ajax.ajax()\n _ajax.bind('complete', on_complete)\n if timeout is not None:\n  _ajax.set_timeout(timeout)\n  \n _ajax.open('GET', url, False)\n if data is None:\n  _ajax.send()\n else:\n  _ajax.send(data)\n  \n if isinstance(result.text, str):\n  return FileIO(result.text), url, result.headers\n  \n return FileIO(result.text()), url, result.headers\n"], "encodings.utf_8": [".py", "\"\"\nimport codecs\n\n\n\nencode = codecs.utf_8_encode\n\ndef decode(input, errors='strict'):\n return codecs.utf_8_decode(input, errors, True)\n \nclass IncrementalEncoder(codecs.IncrementalEncoder):\n def encode(self, input, final=False):\n  return codecs.utf_8_encode(input, self.errors)[0]\n  \nclass IncrementalDecoder(codecs.BufferedIncrementalDecoder):\n _buffer_decode = codecs.utf_8_decode\n \nclass StreamWriter(codecs.StreamWriter):\n encode = codecs.utf_8_encode\n \nclass StreamReader(codecs.StreamReader):\n decode = codecs.utf_8_decode\n \n \n \ndef getregentry():\n return codecs.CodecInfo(\n name='utf-8',\n encode=encode,\n decode=decode,\n incrementalencoder=IncrementalEncoder,\n incrementaldecoder=IncrementalDecoder,\n streamreader=StreamReader,\n streamwriter=StreamWriter,\n )\n"], "sys": [".py", "\nfrom _sys import *\nfrom javascript import JSObject\n\nhas_local_storage=__BRYTHON__.has_local_storage\nhas_json=__BRYTHON__.has_json\n\nargv = ['__main__']\n\nbase_exec_prefix = __BRYTHON__.brython_path\n\nbase_prefix = __BRYTHON__.brython_path\n\nbuiltin_module_names=__BRYTHON__.builtin_module_names\n\nbyteorder='little'\n\ndef exc_info():\n exc = __BRYTHON__.exception_stack[-1]\n return (exc.__class__,exc,exc.traceback)\n \nexec_prefix = __BRYTHON__.brython_path\n\nexecutable = __BRYTHON__.brython_path+'/brython.js'\n\ndef exit(i=None):\n raise SystemExit('')\n \nclass flag_class:\n def __init__(self):\n  self.debug=0\n  self.inspect=0\n  self.interactive=0\n  self.optimize=0\n  self.dont_write_bytecode=0\n  self.no_user_site=0\n  self.no_site=0\n  self.ignore_environment=0\n  self.verbose=0\n  self.bytes_warning=0\n  self.quiet=0\n  self.hash_randomization=1\n  \nflags=flag_class()\n\ndef getfilesystemencoding(*args,**kw):\n \"\"\n return 'utf-8'\n \nmaxsize=2147483647\n\nmaxunicode=1114111\n\npath = __BRYTHON__.path\n\npath_hooks = list(JSObject(__BRYTHON__.path_hooks))\n\nplatform=\"brython\"\n\nprefix = __BRYTHON__.brython_path\n\nversion = '.'.join(str(x) for x in __BRYTHON__.version_info[:3])\n\nversion += \" (default, Feb 29 2013, 00:00:00) \\n[Javascript 1.5]\"\nhexversion = 0x03000000 \n\nclass __version_info(object):\n def __init__(self, version_info):\n  self.version_info = version_info\n  self.major = version_info[0]\n  self.minor = version_info[1]\n  self.micro = version_info[2]\n  self.releaselevel = version_info[3]\n  self.serial = version_info[4]\n  \n def __getitem__(self, index):\n  if isinstance(self.version_info[index], list):\n   return tuple(self.version_info[index])\n  return self.version_info[index]\n  \n def hexversion(self):\n  try:\n   return '0%d0%d0%d' % (self.major, self.minor, self.micro)\n  finally: \n   return '0%d0000' % (self.major)\n   \n def __str__(self):\n  _s=\"sys.version(major=%d, minor=%d, micro=%d, releaselevel='%s', serial=%d)\"\n  return _s % (self.major, self.minor, self.micro, \n  self.releaselevel, self.serial)\n  \n  \n  \nversion_info=__version_info(__BRYTHON__.version_info)\n\nclass _implementation:\n def __init__(self):\n  self.name='brython'\n  self.version = __version_info(__BRYTHON__.implementation)\n  self.hexversion = self.version.hexversion()\n  self.cache_tag=None\n  \n def __repr__(self):\n  return \"namespace(name='%s' version=%s hexversion='%s')\" % (self.name, self.version, self.hexversion)\n  \n def __str__(self):\n  return \"namespace(name='%s' version=%s hexversion='%s')\" % (self.name, self.version, self.hexversion)\n  \nimplementation=_implementation()\n\nclass _hash_info:\n def __init__(self):\n  self.width=32, \n  self.modulus=2147483647\n  self.inf=314159 \n  self.nan=0\n  self.imag=1000003\n  self.algorithm='siphash24' \n  self.hash_bits=64 \n  self.seed_bits=128 \n  cutoff=0\n  \n def __repr(self):\n \n  return \"sys.hash_info(width=32, modulus=2147483647, inf=314159, nan=0, imag=1000003, algorithm='siphash24', hash_bits=64, seed_bits=128, cutoff=0)\"\n  \nhash_info=_hash_info()\n\nwarnoptions=[]\n\ndef getfilesystemencoding():\n return 'utf-8'\n \n \ndel JSObject\ndel _implementation\n"], "browser.svg": [".py", "from _svg import *"], "markdown2": [".py", "import browser.html\nimport re\n\nclass URL:\n def __init__(self,src):\n  elts = src.split(maxsplit=1)\n  self.href = elts[0]\n  self.alt = ''\n  if len(elts)==2:\n   alt = elts[1]\n   if alt[0]=='\"' and alt[-1]=='\"':self.alt=alt[1:-1]\n   elif alt[0]==\"'\" and alt[-1]==\"'\":self.alt=alt[1:-1]\n   elif alt[0]==\"(\" and alt[-1]==\")\":self.alt=alt[1:-1]\n   \nclass CodeBlock:\n def __init__(self,line):\n  self.lines = [line]\n  \n def to_html(self):\n  if self.lines[0].startswith(\"`\"):\n   self.lines.pop(0)\n  res = escape('\\n'.join(self.lines))\n  res = unmark(res)\n  res = '<pre class=\"marked\">%s</pre>\\n' %res\n  return res,[]\n  \nclass Marked:\n def __init__(self, line=''):\n  self.line = line\n  self.children = []\n  \n def to_html(self):\n  return apply_markdown(self.line)\n  \n  \nrefs = {}\nref_pattern = r\"^\\[(.*)\\]:\\s+(.*)\"\n\ndef mark(src):\n\n global refs\n refs = {}\n \n \n \n \n \n \n \n \n src = src.replace('\\r\\n','\\n')\n \n \n src = re.sub(r'(.*?)\\n=+\\n', '\\n# \\\\1\\n', src)\n src = re.sub(r'(.*?)\\n-+\\n', '\\n## \\\\1\\n', src) \n \n lines = src.split('\\n')\n \n i = bq = 0\n ul = ol = 0\n \n while i<len(lines):\n \n \n  if lines[i].startswith('>'):\n   nb = 1\n   while nb<len(lines[i]) and lines[i][nb]=='>':\n    nb += 1\n   lines[i] = lines[i][nb:]\n   if nb>bq:\n    lines.insert(i,'<blockquote>'*(nb-bq))\n    i += 1\n    bq = nb\n   elif nb<bq:\n    lines.insert(i,'</blockquote>'*(bq-nb))\n    i += 1\n    bq = nb\n  elif bq>0:\n   lines.insert(i,'</blockquote>'*bq)\n   i += 1\n   bq = 0\n   \n   \n  if lines[i].strip() and lines[i].lstrip()[0] in '-+*' and (i==0 or ul or not lines[i-1].strip()):\n   print('is ul',lines[i])\n   \n   nb = 1+len(lines[i])-len(lines[i].lstrip())\n   lines[i] = '<li>'+lines[i][1+nb:]\n   if nb>ul:\n    lines.insert(i,'<ul>'*(nb-ul))\n    i += 1\n   elif nb<ul:\n    lines.insert(i,'</ul>'*(ul-nb))\n    i += 1\n   ul = nb\n  elif ul:\n   lines.insert(i,'</ul>'*ul)\n   i += 1\n   ul = 0\n   \n   \n  mo = re.search(r'^(\\d+\\.)',lines[i])\n  if mo:\n   if not ol:\n    lines.insert(i,'<ol>')\n    i += 1\n   lines[i] = '<li>'+lines[i][len(mo.groups()[0]):]\n   ol = 1\n  elif ol:\n   lines.insert(i,'</ol>')\n   i += 1\n   ol = 0\n  i += 1\n  \n sections = []\n scripts = []\n section = Marked()\n \n i = 0\n while i<len(lines):\n  line = lines[i]\n  if line.strip() and line.startswith('    '):\n   if isinstance(section,Marked) and section.line:\n    sections.append(section)\n   section = CodeBlock(line[4:])\n   j = i+1\n   while j<len(lines) and lines[j].strip() and lines[j].startswith('    '):\n    section.lines.append(lines[j][4:])\n    j += 1\n   sections.append(section)\n   section = Marked()\n   i = j \n   continue\n  elif line.lower().startswith('<script'):\n   if isinstance(section,Marked) and section.line:\n    sections.append(section)\n    section = Marked()\n   j = i+1\n   while j<len(lines):\n    if lines[j].lower().startswith('</script>'):\n     scripts.append('\\n'.join(lines[i+1:j]))\n     for k in range(i,j+1):\n      lines[k] = ''\n     break\n    j += 1\n   i = j\n   continue\n  else:\n   mo = re.search(ref_pattern,line)\n   if mo is not None:\n    if isinstance(section,Marked) and section.line:\n     sections.append(section)\n     section = Marked()\n    key = mo.groups()[0]\n    value = URL(mo.groups()[1])\n    refs[key.lower()] = value\n   else:\n    if line.strip():\n     if section.line:\n      section.line += ' '\n     section.line += line\n    else:\n     sections.append(section)\n     section = Marked()\n   i += 1\n   \n res = ''\n for section in sections:\n  mk,_scripts = section.to_html()\n  res += '<p>'+mk+'\\n'\n  scripts += _scripts\n return res,scripts\n \ndef escape(czone):\n czone = czone.replace('&','&amp;')\n czone = czone.replace('<','&lt;')\n czone = czone.replace('>','&gt;')\n return czone\n \ndef s_escape(mo):\n\n czone = mo.string[mo.start():mo.end()]\n return escape(czone)\n \ndef unmark(code_zone):\n\n code_zone = code_zone.replace('_','&#95;')\n return code_zone\n \ndef s_unmark(mo):\n\n code_zone = mo.string[mo.start():mo.end()]\n code_zone = code_zone.replace('_','&#95;')\n return code_zone\n \ndef apply_markdown(src):\n\n scripts = []\n \n \n src = re.sub(r'\\\\\\`','&#96;',src)\n \n \n code_pattern = r'\\`(\\S.*?\\S)\\`'\n src = re.sub(code_pattern,s_escape,src)\n \n src = re.sub(code_pattern,s_unmark,src)\n \n \n link_pattern1 = r'\\[(.+?)\\]\\s?\\((.+?)\\)'\n def repl(mo):\n  g1,g2 = mo.groups()\n  g2 = re.sub('_','&#95;',g2)\n  return '<a href=\"%s\">%s</a>' %(g2,g1)\n src = re.sub(link_pattern1,repl,src)\n \n \n link_pattern2 = r'\\[(.+?)\\]\\s?\\[(.*?)\\]'\n while True:\n  mo = re.search(link_pattern2,src)\n  if mo is None:break\n  text,key = mo.groups()\n  print(text,key)\n  if not key:key=text \n  if key.lower() not in refs:\n   raise KeyError('unknow reference %s' %key)\n  url = refs[key.lower()]\n  repl = '<a href=\"'+url.href+'\"'\n  if url.alt:\n   repl += ' title=\"'+url.alt+'\"'\n  repl += '>%s</a>' %text\n  src = re.sub(link_pattern2,repl,src,count=1)\n  \n  \n  \n  \n src = re.sub(r'\\\\\\*','&#42;',src)\n \n src = re.sub(r'\\\\\\_','&#95;',src)\n \n src = re.sub(r' _ ',' &#95; ',src)\n src = re.sub(r' \\* ',' &#42; ',src)\n \n strong_patterns = [('STRONG',r'\\*\\*(.*?)\\*\\*'),('B',r'__(.*?)__')]\n for tag,strong_pattern in strong_patterns:\n  src = re.sub(strong_pattern,r'<%s>\\1</%s>' %(tag,tag),src)\n  \n em_patterns = [('EM',r'\\*(.*?)\\*'),('I',r'\\_(.*?)\\_')]\n for tag,em_pattern in em_patterns:\n  src = re.sub(em_pattern,r'<%s>\\1</%s>' %(tag,tag),src)\n  \n  \n  \n src = re.sub(r'\\\\\\`','&#96;',src)\n \n code_pattern = r'\\`(.*?)\\`'\n src = re.sub(code_pattern,r'<code>\\1</code>',src)\n \n \n lines = src.split('\\n')\n \n atx_header_pattern = '^(#+)(.*)(#*)'\n for i,line in enumerate(lines):\n  print('line [%s]' %line, line.startswith('#'))\n  mo = re.search(atx_header_pattern,line)\n  if not mo:continue\n  print('pattern matches')\n  level = len(mo.groups()[0])\n  lines[i] = re.sub(atx_header_pattern,\n  '<H%s>%s</H%s>\\n' %(level,mo.groups()[1],level),\n  line,count=1)\n  \n src = '\\n'.join(lines) \n src = re.sub('\\n\\n+','\\n<p>',src)+'\\n'\n \n return src,scripts\n"], "types": [".py", "\"\"\nimport sys\n\n\n\n\n\n\ndef _f(): pass\nFunctionType = type(_f)\nLambdaType = type(lambda: None) \nCodeType = type(_f.__code__)\nMappingProxyType = type(type.__dict__)\nSimpleNamespace = type(sys.implementation)\n\ndef _g():\n yield 1\nGeneratorType = type(_g())\n\nclass _C:\n def _m(self): pass\nMethodType = type(_C()._m)\n\nBuiltinFunctionType = type(len)\nBuiltinMethodType = type([].append) \n\nModuleType = type(sys)\n\ntry:\n raise TypeError\nexcept TypeError:\n tb = sys.exc_info()[2]\n TracebackType = type(tb)\n FrameType = type(tb.tb_frame)\n tb = None; del tb\n \n \nGetSetDescriptorType = type(FunctionType.__code__)\nMemberDescriptorType = type(FunctionType.__globals__)\n\ndel sys, _f, _g, _C, \n\n\n\ndef new_class(name, bases=(), kwds=None, exec_body=None):\n \"\"\n meta, ns, kwds = prepare_class(name, bases, kwds)\n if exec_body is not None:\n  exec_body(ns)\n return meta(name, bases, ns, **kwds)\n \ndef prepare_class(name, bases=(), kwds=None):\n \"\"\n if kwds is None:\n  kwds = {}\n else:\n  kwds = dict(kwds) \n if 'metaclass' in kwds:\n  meta = kwds.pop('metaclass')\n else:\n  if bases:\n   meta = type(bases[0])\n  else:\n   meta = type\n if isinstance(meta, type):\n \n \n  meta = _calculate_meta(meta, bases)\n if hasattr(meta, '__prepare__'):\n  ns = meta.__prepare__(name, bases, **kwds)\n else:\n  ns = {}\n return meta, ns, kwds\n \ndef _calculate_meta(meta, bases):\n \"\"\n winner = meta\n for base in bases:\n  base_meta = type(base)\n  if issubclass(winner, base_meta):\n   continue\n  if issubclass(base_meta, winner):\n   winner = base_meta\n   continue\n   \n  raise TypeError(\"metaclass conflict: \"\n  \"the metaclass of a derived class \"\n  \"must be a (non-strict) subclass \"\n  \"of the metaclasses of all its bases\")\n return winner\n"], "xml.sax.expatreader": [".py", "\"\"\n\nversion = \"0.20\"\n\nfrom xml.sax._exceptions import *\nfrom xml.sax.handler import feature_validation, feature_namespaces\nfrom xml.sax.handler import feature_namespace_prefixes\nfrom xml.sax.handler import feature_external_ges, feature_external_pes\nfrom xml.sax.handler import feature_string_interning\nfrom xml.sax.handler import property_xml_string, property_interning_dict\n\n\nimport sys\nif sys.platform[:4] == \"java\":\n raise SAXReaderNotAvailable(\"expat not available in Java\", None)\ndel sys\n\ntry:\n from xml.parsers import expat\nexcept ImportError:\n raise SAXReaderNotAvailable(\"expat not supported\", None)\nelse:\n if not hasattr(expat, \"ParserCreate\"):\n  raise SAXReaderNotAvailable(\"expat not supported\", None)\nfrom xml.sax import xmlreader, saxutils, handler\n\nAttributesImpl = xmlreader.AttributesImpl\nAttributesNSImpl = xmlreader.AttributesNSImpl\n\n\n\n\ntry:\n import _weakref\nexcept ImportError:\n def _mkproxy(o):\n  return o\nelse:\n import weakref\n _mkproxy = weakref.proxy\n del weakref, _weakref\n \n \n \nclass ExpatLocator(xmlreader.Locator):\n \"\"\n def __init__(self, parser):\n  self._ref = _mkproxy(parser)\n  \n def getColumnNumber(self):\n  parser = self._ref\n  if parser._parser is None:\n   return None\n  return parser._parser.ErrorColumnNumber\n  \n def getLineNumber(self):\n  parser = self._ref\n  if parser._parser is None:\n   return 1\n  return parser._parser.ErrorLineNumber\n  \n def getPublicId(self):\n  parser = self._ref\n  if parser is None:\n   return None\n  return parser._source.getPublicId()\n  \n def getSystemId(self):\n  parser = self._ref\n  if parser is None:\n   return None\n  return parser._source.getSystemId()\n  \n  \n  \n  \nclass ExpatParser(xmlreader.IncrementalParser, xmlreader.Locator):\n \"\"\n \n def __init__(self, namespaceHandling=0, bufsize=2**16-20):\n  xmlreader.IncrementalParser.__init__(self, bufsize)\n  self._source = xmlreader.InputSource()\n  self._parser = None\n  self._namespaces = namespaceHandling\n  self._lex_handler_prop = None\n  self._parsing = 0\n  self._entity_stack = []\n  self._external_ges = 1\n  self._interning = None\n  \n  \n  \n def parse(self, source):\n  \"\"\n  source = saxutils.prepare_input_source(source)\n  \n  self._source = source\n  self.reset()\n  self._cont_handler.setDocumentLocator(ExpatLocator(self))\n  xmlreader.IncrementalParser.parse(self, source)\n  \n def prepareParser(self, source):\n  if source.getSystemId() is not None:\n   self._parser.SetBase(source.getSystemId())\n   \n   \n   \n def setContentHandler(self, handler):\n  xmlreader.IncrementalParser.setContentHandler(self, handler)\n  if self._parsing:\n   self._reset_cont_handler()\n   \n def getFeature(self, name):\n  if name == feature_namespaces:\n   return self._namespaces\n  elif name == feature_string_interning:\n   return self._interning is not None\n  elif name in (feature_validation, feature_external_pes,\n  feature_namespace_prefixes):\n   return 0\n  elif name == feature_external_ges:\n   return self._external_ges\n  raise SAXNotRecognizedException(\"Feature '%s' not recognized\" % name)\n  \n def setFeature(self, name, state):\n  if self._parsing:\n   raise SAXNotSupportedException(\"Cannot set features while parsing\")\n   \n  if name == feature_namespaces:\n   self._namespaces = state\n  elif name == feature_external_ges:\n   self._external_ges = state\n  elif name == feature_string_interning:\n   if state:\n    if self._interning is None:\n     self._interning = {}\n   else:\n    self._interning = None\n  elif name == feature_validation:\n   if state:\n    raise SAXNotSupportedException(\n    \"expat does not support validation\")\n  elif name == feature_external_pes:\n   if state:\n    raise SAXNotSupportedException(\n    \"expat does not read external parameter entities\")\n  elif name == feature_namespace_prefixes:\n   if state:\n    raise SAXNotSupportedException(\n    \"expat does not report namespace prefixes\")\n  else:\n   raise SAXNotRecognizedException(\n   \"Feature '%s' not recognized\" % name)\n   \n def getProperty(self, name):\n  if name == handler.property_lexical_handler:\n   return self._lex_handler_prop\n  elif name == property_interning_dict:\n   return self._interning\n  elif name == property_xml_string:\n   if self._parser:\n    if hasattr(self._parser, \"GetInputContext\"):\n     return self._parser.GetInputContext()\n    else:\n     raise SAXNotRecognizedException(\n     \"This version of expat does not support getting\"\n     \" the XML string\")\n   else:\n    raise SAXNotSupportedException(\n    \"XML string cannot be returned when not parsing\")\n  raise SAXNotRecognizedException(\"Property '%s' not recognized\" % name)\n  \n def setProperty(self, name, value):\n  if name == handler.property_lexical_handler:\n   self._lex_handler_prop = value\n   if self._parsing:\n    self._reset_lex_handler_prop()\n  elif name == property_interning_dict:\n   self._interning = value\n  elif name == property_xml_string:\n   raise SAXNotSupportedException(\"Property '%s' cannot be set\" %\n   name)\n  else:\n   raise SAXNotRecognizedException(\"Property '%s' not recognized\" %\n   name)\n   \n   \n   \n def feed(self, data, isFinal = 0):\n  if not self._parsing:\n   self.reset()\n   self._parsing = 1\n   self._cont_handler.startDocument()\n   \n  try:\n  \n  \n  \n  \n   self._parser.Parse(data, isFinal)\n  except expat.error as e:\n   exc = SAXParseException(expat.ErrorString(e.code), e, self)\n   \n   self._err_handler.fatalError(exc)\n   \n def close(self):\n  if self._entity_stack:\n  \n   return\n  self.feed(\"\", isFinal = 1)\n  self._cont_handler.endDocument()\n  self._parsing = 0\n  \n  self._parser = None\n  bs = self._source.getByteStream()\n  if bs is not None:\n   bs.close()\n   \n def _reset_cont_handler(self):\n  self._parser.ProcessingInstructionHandler = self._cont_handler.processingInstruction\n  self._parser.CharacterDataHandler = self._cont_handler.characters\n  \n def _reset_lex_handler_prop(self):\n  lex = self._lex_handler_prop\n  parser = self._parser\n  if lex is None:\n   parser.CommentHandler = None\n   parser.StartCdataSectionHandler = None\n   parser.EndCdataSectionHandler = None\n   parser.StartDoctypeDeclHandler = None\n   parser.EndDoctypeDeclHandler = None\n  else:\n   parser.CommentHandler = lex.comment\n   parser.StartCdataSectionHandler = lex.startCDATA\n   parser.EndCdataSectionHandler = lex.endCDATA\n   parser.StartDoctypeDeclHandler = self.start_doctype_decl\n   parser.EndDoctypeDeclHandler = lex.endDTD\n   \n def reset(self):\n  if self._namespaces:\n   self._parser = expat.ParserCreate(self._source.getEncoding(), \" \",\n   intern=self._interning)\n   self._parser.namespace_prefixes = 1\n   self._parser.StartElementHandler = self.start_element_ns\n   self._parser.EndElementHandler = self.end_element_ns\n  else:\n   self._parser = expat.ParserCreate(self._source.getEncoding(),\n   intern = self._interning)\n   self._parser.StartElementHandler = self.start_element\n   self._parser.EndElementHandler = self.end_element\n   \n  self._reset_cont_handler()\n  self._parser.UnparsedEntityDeclHandler = self.unparsed_entity_decl\n  self._parser.NotationDeclHandler = self.notation_decl\n  self._parser.StartNamespaceDeclHandler = self.start_namespace_decl\n  self._parser.EndNamespaceDeclHandler = self.end_namespace_decl\n  \n  self._decl_handler_prop = None\n  if self._lex_handler_prop:\n   self._reset_lex_handler_prop()\n   \n   \n   \n  self._parser.ExternalEntityRefHandler = self.external_entity_ref\n  try:\n   self._parser.SkippedEntityHandler = self.skipped_entity_handler\n  except AttributeError:\n  \n   pass\n  self._parser.SetParamEntityParsing(\n  expat.XML_PARAM_ENTITY_PARSING_UNLESS_STANDALONE)\n  \n  self._parsing = 0\n  self._entity_stack = []\n  \n  \n  \n def getColumnNumber(self):\n  if self._parser is None:\n   return None\n  return self._parser.ErrorColumnNumber\n  \n def getLineNumber(self):\n  if self._parser is None:\n   return 1\n  return self._parser.ErrorLineNumber\n  \n def getPublicId(self):\n  return self._source.getPublicId()\n  \n def getSystemId(self):\n  return self._source.getSystemId()\n  \n  \n def start_element(self, name, attrs):\n  self._cont_handler.startElement(name, AttributesImpl(attrs))\n  \n def end_element(self, name):\n  self._cont_handler.endElement(name)\n  \n def start_element_ns(self, name, attrs):\n  pair = name.split()\n  if len(pair) == 1:\n  \n   pair = (None, name)\n  elif len(pair) == 3:\n   pair = pair[0], pair[1]\n  else:\n  \n   pair = tuple(pair)\n   \n  newattrs = {}\n  qnames = {}\n  for (aname, value) in attrs.items():\n   parts = aname.split()\n   length = len(parts)\n   if length == 1:\n   \n    qname = aname\n    apair = (None, aname)\n   elif length == 3:\n    qname = \"%s:%s\" % (parts[2], parts[1])\n    apair = parts[0], parts[1]\n   else:\n   \n    qname = parts[1]\n    apair = tuple(parts)\n    \n   newattrs[apair] = value\n   qnames[apair] = qname\n   \n  self._cont_handler.startElementNS(pair, None,\n  AttributesNSImpl(newattrs, qnames))\n  \n def end_element_ns(self, name):\n  pair = name.split()\n  if len(pair) == 1:\n   pair = (None, name)\n  elif len(pair) == 3:\n   pair = pair[0], pair[1]\n  else:\n   pair = tuple(pair)\n   \n  self._cont_handler.endElementNS(pair, None)\n  \n  \n def processing_instruction(self, target, data):\n  self._cont_handler.processingInstruction(target, data)\n  \n  \n def character_data(self, data):\n  self._cont_handler.characters(data)\n  \n def start_namespace_decl(self, prefix, uri):\n  self._cont_handler.startPrefixMapping(prefix, uri)\n  \n def end_namespace_decl(self, prefix):\n  self._cont_handler.endPrefixMapping(prefix)\n  \n def start_doctype_decl(self, name, sysid, pubid, has_internal_subset):\n  self._lex_handler_prop.startDTD(name, pubid, sysid)\n  \n def unparsed_entity_decl(self, name, base, sysid, pubid, notation_name):\n  self._dtd_handler.unparsedEntityDecl(name, pubid, sysid, notation_name)\n  \n def notation_decl(self, name, base, sysid, pubid):\n  self._dtd_handler.notationDecl(name, pubid, sysid)\n  \n def external_entity_ref(self, context, base, sysid, pubid):\n  if not self._external_ges:\n   return 1\n   \n  source = self._ent_handler.resolveEntity(pubid, sysid)\n  source = saxutils.prepare_input_source(source,\n  self._source.getSystemId() or\n  \"\")\n  \n  self._entity_stack.append((self._parser, self._source))\n  self._parser = self._parser.ExternalEntityParserCreate(context)\n  self._source = source\n  \n  try:\n   xmlreader.IncrementalParser.parse(self, source)\n  except:\n   return 0 \n   \n  (self._parser, self._source) = self._entity_stack[-1]\n  del self._entity_stack[-1]\n  return 1\n  \n def skipped_entity_handler(self, name, is_pe):\n  if is_pe:\n  \n   name = '%'+name\n  self._cont_handler.skippedEntity(name)\n  \n  \n  \ndef create_parser(*args, **kwargs):\n return ExpatParser(*args, **kwargs)\n \n \n \nif __name__ == \"__main__\":\n import xml.sax.saxutils\n p = create_parser()\n p.setContentHandler(xml.sax.saxutils.XMLGenerator())\n p.setErrorHandler(xml.sax.ErrorHandler())\n p.parse(\"http://www.ibiblio.org/xml/examples/shakespeare/hamlet.xml\")\n"], "unittest.test.test_case": [".py", "import difflib\nimport pprint\nimport pickle\nimport re\nimport sys\nimport warnings\nimport weakref\nimport inspect\n\nfrom copy import deepcopy\nfrom test import support\n\nimport unittest\n\nfrom .support import (\nTestEquality, TestHashing, LoggingResult,\nResultWithNoStartTestRunStopTestRun\n)\n\n\nclass Test(object):\n \"\"\n \n class Foo(unittest.TestCase):\n  def runTest(self): pass\n  def test1(self): pass\n  \n class Bar(Foo):\n  def test2(self): pass\n  \n class LoggingTestCase(unittest.TestCase):\n  \"\"\n  \n  def __init__(self, events):\n   super(Test.LoggingTestCase, self).__init__('test')\n   self.events = events\n   \n  def setUp(self):\n   self.events.append('setUp')\n   \n  def test(self):\n   self.events.append('test')\n   \n  def tearDown(self):\n   self.events.append('tearDown')\n   \n   \nclass Test_TestCase(unittest.TestCase, TestEquality, TestHashing):\n\n\n\n\n\n eq_pairs = [(Test.Foo('test1'), Test.Foo('test1'))]\n \n \n ne_pairs = [(Test.Foo('test1'), Test.Foo('runTest')),\n (Test.Foo('test1'), Test.Bar('test1')),\n (Test.Foo('test1'), Test.Bar('test2'))]\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n def test_init__no_test_name(self):\n  class Test(unittest.TestCase):\n   def runTest(self): raise MyException()\n   def test(self): pass\n   \n  self.assertEqual(Test().id()[-13:], '.Test.runTest')\n  \n  \n  \n  test = unittest.TestCase()\n  test.assertEqual(3, 3)\n  with test.assertRaises(test.failureException):\n   test.assertEqual(3, 2)\n   \n  with self.assertRaises(AttributeError):\n   test.run()\n   \n   \n   \n   \n   \n def test_init__test_name__valid(self):\n  class Test(unittest.TestCase):\n   def runTest(self): raise MyException()\n   def test(self): pass\n   \n  self.assertEqual(Test('test').id()[-10:], '.Test.test')\n  \n  \n  \n  \n  \n def test_init__test_name__invalid(self):\n  class Test(unittest.TestCase):\n   def runTest(self): raise MyException()\n   def test(self): pass\n   \n  try:\n   Test('testfoo')\n  except ValueError:\n   pass\n  else:\n   self.fail(\"Failed to raise ValueError\")\n   \n   \n   \n def test_countTestCases(self):\n  class Foo(unittest.TestCase):\n   def test(self): pass\n   \n  self.assertEqual(Foo('test').countTestCases(), 1)\n  \n  \n  \n  \n  \n def test_defaultTestResult(self):\n  class Foo(unittest.TestCase):\n   def runTest(self):\n    pass\n    \n  result = Foo().defaultTestResult()\n  self.assertEqual(type(result), unittest.TestResult)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_run_call_order__error_in_setUp(self):\n  events = []\n  result = LoggingResult(events)\n  \n  class Foo(Test.LoggingTestCase):\n   def setUp(self):\n    super(Foo, self).setUp()\n    raise RuntimeError('raised by Foo.setUp')\n    \n  Foo(events).run(result)\n  expected = ['startTest', 'setUp', 'addError', 'stopTest']\n  self.assertEqual(events, expected)\n  \n  \n def test_run_call_order__error_in_setUp_default_result(self):\n  events = []\n  \n  class Foo(Test.LoggingTestCase):\n   def defaultTestResult(self):\n    return LoggingResult(self.events)\n    \n   def setUp(self):\n    super(Foo, self).setUp()\n    raise RuntimeError('raised by Foo.setUp')\n    \n  Foo(events).run()\n  expected = ['startTestRun', 'startTest', 'setUp', 'addError',\n  'stopTest', 'stopTestRun']\n  self.assertEqual(events, expected)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_run_call_order__error_in_test(self):\n  events = []\n  result = LoggingResult(events)\n  \n  class Foo(Test.LoggingTestCase):\n   def test(self):\n    super(Foo, self).test()\n    raise RuntimeError('raised by Foo.test')\n    \n  expected = ['startTest', 'setUp', 'test', 'tearDown',\n  'addError', 'stopTest']\n  Foo(events).run(result)\n  self.assertEqual(events, expected)\n  \n  \n  \n def test_run_call_order__error_in_test_default_result(self):\n  events = []\n  \n  class Foo(Test.LoggingTestCase):\n   def defaultTestResult(self):\n    return LoggingResult(self.events)\n    \n   def test(self):\n    super(Foo, self).test()\n    raise RuntimeError('raised by Foo.test')\n    \n  expected = ['startTestRun', 'startTest', 'setUp', 'test',\n  'tearDown', 'addError', 'stopTest', 'stopTestRun']\n  Foo(events).run()\n  self.assertEqual(events, expected)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_run_call_order__failure_in_test(self):\n  events = []\n  result = LoggingResult(events)\n  \n  class Foo(Test.LoggingTestCase):\n   def test(self):\n    super(Foo, self).test()\n    self.fail('raised by Foo.test')\n    \n  expected = ['startTest', 'setUp', 'test', 'tearDown',\n  'addFailure', 'stopTest']\n  Foo(events).run(result)\n  self.assertEqual(events, expected)\n  \n  \n def test_run_call_order__failure_in_test_default_result(self):\n \n  class Foo(Test.LoggingTestCase):\n   def defaultTestResult(self):\n    return LoggingResult(self.events)\n   def test(self):\n    super(Foo, self).test()\n    self.fail('raised by Foo.test')\n    \n  expected = ['startTestRun', 'startTest', 'setUp', 'test',\n  'tearDown', 'addFailure', 'stopTest', 'stopTestRun']\n  events = []\n  Foo(events).run()\n  self.assertEqual(events, expected)\n  \n  \n  \n  \n  \n  \n  \n  \n def test_run_call_order__error_in_tearDown(self):\n  events = []\n  result = LoggingResult(events)\n  \n  class Foo(Test.LoggingTestCase):\n   def tearDown(self):\n    super(Foo, self).tearDown()\n    raise RuntimeError('raised by Foo.tearDown')\n    \n  Foo(events).run(result)\n  expected = ['startTest', 'setUp', 'test', 'tearDown', 'addError',\n  'stopTest']\n  self.assertEqual(events, expected)\n  \n  \n def test_run_call_order__error_in_tearDown_default_result(self):\n \n  class Foo(Test.LoggingTestCase):\n   def defaultTestResult(self):\n    return LoggingResult(self.events)\n   def tearDown(self):\n    super(Foo, self).tearDown()\n    raise RuntimeError('raised by Foo.tearDown')\n    \n  events = []\n  Foo(events).run()\n  expected = ['startTestRun', 'startTest', 'setUp', 'test', 'tearDown',\n  'addError', 'stopTest', 'stopTestRun']\n  self.assertEqual(events, expected)\n  \n  \n  \n def test_run_call_order_default_result(self):\n \n  class Foo(unittest.TestCase):\n   def defaultTestResult(self):\n    return ResultWithNoStartTestRunStopTestRun()\n   def test(self):\n    pass\n    \n  Foo('test').run()\n  \n  \n  \n  \n  \n  \n def test_failureException__default(self):\n  class Foo(unittest.TestCase):\n   def test(self):\n    pass\n    \n  self.assertTrue(Foo('test').failureException is AssertionError)\n  \n  \n  \n  \n  \n  \n  \n def test_failureException__subclassing__explicit_raise(self):\n  events = []\n  result = LoggingResult(events)\n  \n  class Foo(unittest.TestCase):\n   def test(self):\n    raise RuntimeError()\n    \n   failureException = RuntimeError\n   \n  self.assertTrue(Foo('test').failureException is RuntimeError)\n  \n  \n  Foo('test').run(result)\n  expected = ['startTest', 'addFailure', 'stopTest']\n  self.assertEqual(events, expected)\n  \n  \n  \n  \n  \n  \n  \n def test_failureException__subclassing__implicit_raise(self):\n  events = []\n  result = LoggingResult(events)\n  \n  class Foo(unittest.TestCase):\n   def test(self):\n    self.fail(\"foo\")\n    \n   failureException = RuntimeError\n   \n  self.assertTrue(Foo('test').failureException is RuntimeError)\n  \n  \n  Foo('test').run(result)\n  expected = ['startTest', 'addFailure', 'stopTest']\n  self.assertEqual(events, expected)\n  \n  \n def test_setUp(self):\n  class Foo(unittest.TestCase):\n   def runTest(self):\n    pass\n    \n    \n  Foo().setUp()\n  \n  \n def test_tearDown(self):\n  class Foo(unittest.TestCase):\n   def runTest(self):\n    pass\n    \n    \n  Foo().tearDown()\n  \n  \n  \n  \n  \n  \n  \n def test_id(self):\n  class Foo(unittest.TestCase):\n   def runTest(self):\n    pass\n    \n  self.assertIsInstance(Foo().id(), str)\n  \n  \n  \n  \n  \n  \n def test_run__uses_defaultTestResult(self):\n  events = []\n  defaultResult = LoggingResult(events)\n  \n  class Foo(unittest.TestCase):\n   def test(self):\n    events.append('test')\n    \n   def defaultTestResult(self):\n    return defaultResult\n    \n    \n  result = Foo('test').run()\n  \n  self.assertIs(result, defaultResult)\n  expected = ['startTestRun', 'startTest', 'test', 'addSuccess',\n  'stopTest', 'stopTestRun']\n  self.assertEqual(events, expected)\n  \n  \n  \n def test_run__returns_given_result(self):\n \n  class Foo(unittest.TestCase):\n   def test(self):\n    pass\n    \n  result = unittest.TestResult()\n  \n  retval = Foo('test').run(result)\n  self.assertIs(retval, result)\n  \n  \n  \n  \n def test_call__invoking_an_instance_delegates_to_run(self):\n  resultIn = unittest.TestResult()\n  resultOut = unittest.TestResult()\n  \n  class Foo(unittest.TestCase):\n   def test(self):\n    pass\n    \n   def run(self, result):\n    self.assertIs(result, resultIn)\n    return resultOut\n    \n  retval = Foo('test')(resultIn)\n  \n  self.assertIs(retval, resultOut)\n  \n  \n def testShortDescriptionWithoutDocstring(self):\n  self.assertIsNone(self.shortDescription())\n  \n @unittest.skipIf(sys.flags.optimize >= 2,\n \"Docstrings are omitted with -O2 and above\")\n def testShortDescriptionWithOneLineDocstring(self):\n  \"\"\n  self.assertEqual(\n  self.shortDescription(),\n  'Tests shortDescription() for a method with a docstring.')\n  \n @unittest.skipIf(sys.flags.optimize >= 2,\n \"Docstrings are omitted with -O2 and above\")\n def testShortDescriptionWithMultiLineDocstring(self):\n  \"\"\n  self.assertEqual(\n  self.shortDescription(),\n  'Tests shortDescription() for a method with a longer '\n  'docstring.')\n  \n def testAddTypeEqualityFunc(self):\n  class SadSnake(object):\n   \"\"\n  s1, s2 = SadSnake(), SadSnake()\n  self.assertFalse(s1 == s2)\n  def AllSnakesCreatedEqual(a, b, msg=None):\n   return type(a) == type(b) == SadSnake\n  self.addTypeEqualityFunc(SadSnake, AllSnakesCreatedEqual)\n  self.assertEqual(s1, s2)\n  \n  \n  \n  \n def testAssertIs(self):\n  thing = object()\n  self.assertIs(thing, thing)\n  self.assertRaises(self.failureException, self.assertIs, thing, object())\n  \n def testAssertIsNot(self):\n  thing = object()\n  self.assertIsNot(thing, object())\n  self.assertRaises(self.failureException, self.assertIsNot, thing, thing)\n  \n def testAssertIsInstance(self):\n  thing = []\n  self.assertIsInstance(thing, list)\n  self.assertRaises(self.failureException, self.assertIsInstance,\n  thing, dict)\n  \n def testAssertNotIsInstance(self):\n  thing = []\n  self.assertNotIsInstance(thing, dict)\n  self.assertRaises(self.failureException, self.assertNotIsInstance,\n  thing, list)\n  \n def testAssertIn(self):\n  animals = {'monkey': 'banana', 'cow': 'grass', 'seal': 'fish'}\n  \n  self.assertIn('a', 'abc')\n  self.assertIn(2, [1, 2, 3])\n  self.assertIn('monkey', animals)\n  \n  self.assertNotIn('d', 'abc')\n  self.assertNotIn(0, [1, 2, 3])\n  self.assertNotIn('otter', animals)\n  \n  self.assertRaises(self.failureException, self.assertIn, 'x', 'abc')\n  self.assertRaises(self.failureException, self.assertIn, 4, [1, 2, 3])\n  self.assertRaises(self.failureException, self.assertIn, 'elephant',\n  animals)\n  \n  self.assertRaises(self.failureException, self.assertNotIn, 'c', 'abc')\n  self.assertRaises(self.failureException, self.assertNotIn, 1, [1, 2, 3])\n  self.assertRaises(self.failureException, self.assertNotIn, 'cow',\n  animals)\n  \n def testAssertDictContainsSubset(self):\n  with warnings.catch_warnings():\n   warnings.simplefilter(\"ignore\", DeprecationWarning)\n   \n   self.assertDictContainsSubset({}, {})\n   self.assertDictContainsSubset({}, {'a': 1})\n   self.assertDictContainsSubset({'a': 1}, {'a': 1})\n   self.assertDictContainsSubset({'a': 1}, {'a': 1, 'b': 2})\n   self.assertDictContainsSubset({'a': 1, 'b': 2}, {'a': 1, 'b': 2})\n   \n   with self.assertRaises(self.failureException):\n    self.assertDictContainsSubset({1: \"one\"}, {})\n    \n   with self.assertRaises(self.failureException):\n    self.assertDictContainsSubset({'a': 2}, {'a': 1})\n    \n   with self.assertRaises(self.failureException):\n    self.assertDictContainsSubset({'c': 1}, {'a': 1})\n    \n   with self.assertRaises(self.failureException):\n    self.assertDictContainsSubset({'a': 1, 'c': 1}, {'a': 1})\n    \n   with self.assertRaises(self.failureException):\n    self.assertDictContainsSubset({'a': 1, 'c': 1}, {'a': 1})\n    \n   one = ''.join(chr(i) for i in range(255))\n   \n   with self.assertRaises(self.failureException):\n    self.assertDictContainsSubset({'foo': one}, {'foo': '\\uFFFD'})\n    \n def testAssertEqual(self):\n  equal_pairs = [\n  ((), ()),\n  ({}, {}),\n  ([], []),\n  (set(), set()),\n  (frozenset(), frozenset())]\n  for a, b in equal_pairs:\n  \n  \n   try:\n    self.assertEqual(a, b)\n   except self.failureException:\n    self.fail('assertEqual(%r, %r) failed' % (a, b))\n   try:\n    self.assertEqual(a, b, msg='foo')\n   except self.failureException:\n    self.fail('assertEqual(%r, %r) with msg= failed' % (a, b))\n   try:\n    self.assertEqual(a, b, 'foo')\n   except self.failureException:\n    self.fail('assertEqual(%r, %r) with third parameter failed' %\n    (a, b))\n    \n  unequal_pairs = [\n  ((), []),\n  ({}, set()),\n  (set([4,1]), frozenset([4,2])),\n  (frozenset([4,5]), set([2,3])),\n  (set([3,4]), set([5,4]))]\n  for a, b in unequal_pairs:\n   self.assertRaises(self.failureException, self.assertEqual, a, b)\n   self.assertRaises(self.failureException, self.assertEqual, a, b,\n   'foo')\n   self.assertRaises(self.failureException, self.assertEqual, a, b,\n   msg='foo')\n   \n def testEquality(self):\n  self.assertListEqual([], [])\n  self.assertTupleEqual((), ())\n  self.assertSequenceEqual([], ())\n  \n  a = [0, 'a', []]\n  b = []\n  self.assertRaises(unittest.TestCase.failureException,\n  self.assertListEqual, a, b)\n  self.assertRaises(unittest.TestCase.failureException,\n  self.assertListEqual, tuple(a), tuple(b))\n  self.assertRaises(unittest.TestCase.failureException,\n  self.assertSequenceEqual, a, tuple(b))\n  \n  b.extend(a)\n  self.assertListEqual(a, b)\n  self.assertTupleEqual(tuple(a), tuple(b))\n  self.assertSequenceEqual(a, tuple(b))\n  self.assertSequenceEqual(tuple(a), b)\n  \n  self.assertRaises(self.failureException, self.assertListEqual,\n  a, tuple(b))\n  self.assertRaises(self.failureException, self.assertTupleEqual,\n  tuple(a), b)\n  self.assertRaises(self.failureException, self.assertListEqual, None, b)\n  self.assertRaises(self.failureException, self.assertTupleEqual, None,\n  tuple(b))\n  self.assertRaises(self.failureException, self.assertSequenceEqual,\n  None, tuple(b))\n  self.assertRaises(self.failureException, self.assertListEqual, 1, 1)\n  self.assertRaises(self.failureException, self.assertTupleEqual, 1, 1)\n  self.assertRaises(self.failureException, self.assertSequenceEqual,\n  1, 1)\n  \n  self.assertDictEqual({}, {})\n  \n  c = { 'x': 1 }\n  d = {}\n  self.assertRaises(unittest.TestCase.failureException,\n  self.assertDictEqual, c, d)\n  \n  d.update(c)\n  self.assertDictEqual(c, d)\n  \n  d['x'] = 0\n  self.assertRaises(unittest.TestCase.failureException,\n  self.assertDictEqual, c, d, 'These are unequal')\n  \n  self.assertRaises(self.failureException, self.assertDictEqual, None, d)\n  self.assertRaises(self.failureException, self.assertDictEqual, [], d)\n  self.assertRaises(self.failureException, self.assertDictEqual, 1, 1)\n  \n def testAssertSequenceEqualMaxDiff(self):\n  self.assertEqual(self.maxDiff, 80*8)\n  seq1 = 'a' + 'x' * 80**2\n  seq2 = 'b' + 'x' * 80**2\n  diff = '\\n'.join(difflib.ndiff(pprint.pformat(seq1).splitlines(),\n  pprint.pformat(seq2).splitlines()))\n  \n  omitted = unittest.case.DIFF_OMITTED % (len(diff) + 1,)\n  \n  self.maxDiff = len(diff)//2\n  try:\n  \n   self.assertSequenceEqual(seq1, seq2)\n  except self.failureException as e:\n   msg = e.args[0]\n  else:\n   self.fail('assertSequenceEqual did not fail.')\n  self.assertTrue(len(msg) < len(diff))\n  self.assertIn(omitted, msg)\n  \n  self.maxDiff = len(diff) * 2\n  try:\n   self.assertSequenceEqual(seq1, seq2)\n  except self.failureException as e:\n   msg = e.args[0]\n  else:\n   self.fail('assertSequenceEqual did not fail.')\n  self.assertTrue(len(msg) > len(diff))\n  self.assertNotIn(omitted, msg)\n  \n  self.maxDiff = None\n  try:\n   self.assertSequenceEqual(seq1, seq2)\n  except self.failureException as e:\n   msg = e.args[0]\n  else:\n   self.fail('assertSequenceEqual did not fail.')\n  self.assertTrue(len(msg) > len(diff))\n  self.assertNotIn(omitted, msg)\n  \n def testTruncateMessage(self):\n  self.maxDiff = 1\n  message = self._truncateMessage('foo', 'bar')\n  omitted = unittest.case.DIFF_OMITTED % len('bar')\n  self.assertEqual(message, 'foo' + omitted)\n  \n  self.maxDiff = None\n  message = self._truncateMessage('foo', 'bar')\n  self.assertEqual(message, 'foobar')\n  \n  self.maxDiff = 4\n  message = self._truncateMessage('foo', 'bar')\n  self.assertEqual(message, 'foobar')\n  \n def testAssertDictEqualTruncates(self):\n  test = unittest.TestCase('assertEqual')\n  def truncate(msg, diff):\n   return 'foo'\n  test._truncateMessage = truncate\n  try:\n   test.assertDictEqual({}, {1: 0})\n  except self.failureException as e:\n   self.assertEqual(str(e), 'foo')\n  else:\n   self.fail('assertDictEqual did not fail')\n   \n def testAssertMultiLineEqualTruncates(self):\n  test = unittest.TestCase('assertEqual')\n  def truncate(msg, diff):\n   return 'foo'\n  test._truncateMessage = truncate\n  try:\n   test.assertMultiLineEqual('foo', 'bar')\n  except self.failureException as e:\n   self.assertEqual(str(e), 'foo')\n  else:\n   self.fail('assertMultiLineEqual did not fail')\n   \n def testAssertEqual_diffThreshold(self):\n \n  self.assertEqual(self._diffThreshold, 2**16)\n  \n  self.maxDiff = None\n  \n  \n  old_threshold = self._diffThreshold\n  self._diffThreshold = 2**8\n  self.addCleanup(lambda: setattr(self, '_diffThreshold', old_threshold))\n  \n  \n  s = 'x' * (2**7)\n  with self.assertRaises(self.failureException) as cm:\n   self.assertEqual(s + 'a', s + 'b')\n  self.assertIn('^', str(cm.exception))\n  self.assertEqual(s + 'a', s + 'a')\n  \n  \n  s = 'x' * (2**9)\n  \n  \n  \n  def explodingTruncation(message, diff):\n   raise SystemError('this should not be raised')\n  old_truncate = self._truncateMessage\n  self._truncateMessage = explodingTruncation\n  self.addCleanup(lambda: setattr(self, '_truncateMessage', old_truncate))\n  \n  s1, s2 = s + 'a', s + 'b'\n  with self.assertRaises(self.failureException) as cm:\n   self.assertEqual(s1, s2)\n  self.assertNotIn('^', str(cm.exception))\n  self.assertEqual(str(cm.exception), '%r != %r' % (s1, s2))\n  self.assertEqual(s + 'a', s + 'a')\n  \n def testAssertCountEqual(self):\n  a = object()\n  self.assertCountEqual([1, 2, 3], [3, 2, 1])\n  self.assertCountEqual(['foo', 'bar', 'baz'], ['bar', 'baz', 'foo'])\n  self.assertCountEqual([a, a, 2, 2, 3], (a, 2, 3, a, 2))\n  self.assertCountEqual([1, \"2\", \"a\", \"a\"], [\"a\", \"2\", True, \"a\"])\n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [1, 2] + [3] * 100, [1] * 100 + [2, 3])\n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [1, \"2\", \"a\", \"a\"], [\"a\", \"2\", True, 1])\n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [10], [10, 11])\n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [10, 11], [10])\n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [10, 11, 10], [10, 11])\n  \n  \n  self.assertCountEqual([[1, 2], [3, 4], 0], [False, [3, 4], [1, 2]])\n  \n  self.assertCountEqual(iter([1, 2, [], 3, 4]),\n  iter([1, 2, [], 3, 4]))\n  \n  \n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [], [divmod, 'x', 1, 5j, 2j, frozenset()])\n  \n  self.assertCountEqual([{'a': 1}, {'b': 2}], [{'b': 2}, {'a': 1}])\n  \n  self.assertCountEqual([1, 'x', divmod, []], [divmod, [], 'x', 1])\n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [], [divmod, [], 'x', 1, 5j, 2j, set()])\n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [[1]], [[2]])\n  \n  \n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [1, 1, 2], [2, 1])\n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [1, 1, \"2\", \"a\", \"a\"], [\"2\", \"2\", True, \"a\"])\n  self.assertRaises(self.failureException, self.assertCountEqual,\n  [1, {'b': 2}, None, True], [{'b': 2}, True, None])\n  \n  \n  \n  a = [{2,4}, {1,2}]\n  b = a[::-1]\n  self.assertCountEqual(a, b)\n  \n  \n  \n  diffs = set(unittest.util._count_diff_all_purpose('aaabccd', 'abbbcce'))\n  expected = {(3,1,'a'), (1,3,'b'), (1,0,'d'), (0,1,'e')}\n  self.assertEqual(diffs, expected)\n  \n  diffs = unittest.util._count_diff_all_purpose([[]], [])\n  self.assertEqual(diffs, [(1, 0, [])])\n  \n  diffs = set(unittest.util._count_diff_hashable('aaabccd', 'abbbcce'))\n  expected = {(3,1,'a'), (1,3,'b'), (1,0,'d'), (0,1,'e')}\n  self.assertEqual(diffs, expected)\n  \n def testAssertSetEqual(self):\n  set1 = set()\n  set2 = set()\n  self.assertSetEqual(set1, set2)\n  \n  self.assertRaises(self.failureException, self.assertSetEqual, None, set2)\n  self.assertRaises(self.failureException, self.assertSetEqual, [], set2)\n  self.assertRaises(self.failureException, self.assertSetEqual, set1, None)\n  self.assertRaises(self.failureException, self.assertSetEqual, set1, [])\n  \n  set1 = set(['a'])\n  set2 = set()\n  self.assertRaises(self.failureException, self.assertSetEqual, set1, set2)\n  \n  set1 = set(['a'])\n  set2 = set(['a'])\n  self.assertSetEqual(set1, set2)\n  \n  set1 = set(['a'])\n  set2 = set(['a', 'b'])\n  self.assertRaises(self.failureException, self.assertSetEqual, set1, set2)\n  \n  set1 = set(['a'])\n  set2 = frozenset(['a', 'b'])\n  self.assertRaises(self.failureException, self.assertSetEqual, set1, set2)\n  \n  set1 = set(['a', 'b'])\n  set2 = frozenset(['a', 'b'])\n  self.assertSetEqual(set1, set2)\n  \n  set1 = set()\n  set2 = \"foo\"\n  self.assertRaises(self.failureException, self.assertSetEqual, set1, set2)\n  self.assertRaises(self.failureException, self.assertSetEqual, set2, set1)\n  \n  \n  set1 = set([(0, 1), (2, 3)])\n  set2 = set([(4, 5)])\n  self.assertRaises(self.failureException, self.assertSetEqual, set1, set2)\n  \n def testInequality(self):\n \n  self.assertGreater(2, 1)\n  self.assertGreaterEqual(2, 1)\n  self.assertGreaterEqual(1, 1)\n  self.assertLess(1, 2)\n  self.assertLessEqual(1, 2)\n  self.assertLessEqual(1, 1)\n  self.assertRaises(self.failureException, self.assertGreater, 1, 2)\n  self.assertRaises(self.failureException, self.assertGreater, 1, 1)\n  self.assertRaises(self.failureException, self.assertGreaterEqual, 1, 2)\n  self.assertRaises(self.failureException, self.assertLess, 2, 1)\n  self.assertRaises(self.failureException, self.assertLess, 1, 1)\n  self.assertRaises(self.failureException, self.assertLessEqual, 2, 1)\n  \n  \n  self.assertGreater(1.1, 1.0)\n  self.assertGreaterEqual(1.1, 1.0)\n  self.assertGreaterEqual(1.0, 1.0)\n  self.assertLess(1.0, 1.1)\n  self.assertLessEqual(1.0, 1.1)\n  self.assertLessEqual(1.0, 1.0)\n  self.assertRaises(self.failureException, self.assertGreater, 1.0, 1.1)\n  self.assertRaises(self.failureException, self.assertGreater, 1.0, 1.0)\n  self.assertRaises(self.failureException, self.assertGreaterEqual, 1.0, 1.1)\n  self.assertRaises(self.failureException, self.assertLess, 1.1, 1.0)\n  self.assertRaises(self.failureException, self.assertLess, 1.0, 1.0)\n  self.assertRaises(self.failureException, self.assertLessEqual, 1.1, 1.0)\n  \n  \n  self.assertGreater('bug', 'ant')\n  self.assertGreaterEqual('bug', 'ant')\n  self.assertGreaterEqual('ant', 'ant')\n  self.assertLess('ant', 'bug')\n  self.assertLessEqual('ant', 'bug')\n  self.assertLessEqual('ant', 'ant')\n  self.assertRaises(self.failureException, self.assertGreater, 'ant', 'bug')\n  self.assertRaises(self.failureException, self.assertGreater, 'ant', 'ant')\n  self.assertRaises(self.failureException, self.assertGreaterEqual, 'ant', 'bug')\n  self.assertRaises(self.failureException, self.assertLess, 'bug', 'ant')\n  self.assertRaises(self.failureException, self.assertLess, 'ant', 'ant')\n  self.assertRaises(self.failureException, self.assertLessEqual, 'bug', 'ant')\n  \n  \n  self.assertGreater(b'bug', b'ant')\n  self.assertGreaterEqual(b'bug', b'ant')\n  self.assertGreaterEqual(b'ant', b'ant')\n  self.assertLess(b'ant', b'bug')\n  self.assertLessEqual(b'ant', b'bug')\n  self.assertLessEqual(b'ant', b'ant')\n  self.assertRaises(self.failureException, self.assertGreater, b'ant', b'bug')\n  self.assertRaises(self.failureException, self.assertGreater, b'ant', b'ant')\n  self.assertRaises(self.failureException, self.assertGreaterEqual, b'ant',\n  b'bug')\n  self.assertRaises(self.failureException, self.assertLess, b'bug', b'ant')\n  self.assertRaises(self.failureException, self.assertLess, b'ant', b'ant')\n  self.assertRaises(self.failureException, self.assertLessEqual, b'bug', b'ant')\n  \n def testAssertMultiLineEqual(self):\n  sample_text = \"\"\"\\\nhttp://www.python.org/doc/2.3/lib/module-unittest.html\ntest case\n    A test case is the smallest unit of testing. [...]\n\"\"\"  \n  revised_sample_text = \"\"\"\\\nhttp://www.python.org/doc/2.4.1/lib/module-unittest.html\ntest case\n    A test case is the smallest unit of testing. [...] You may provide your\n    own implementation that does not subclass from TestCase, of course.\n\"\"\"  \n  sample_text_error = \"\"\"\\\n- http://www.python.org/doc/2.3/lib/module-unittest.html\n?                             ^\n+ http://www.python.org/doc/2.4.1/lib/module-unittest.html\n?                             ^^^\n  test case\n-     A test case is the smallest unit of testing. [...]\n+     A test case is the smallest unit of testing. [...] You may provide your\n?                                                       +++++++++++++++++++++\n+     own implementation that does not subclass from TestCase, of course.\n\"\"\"  \n  self.maxDiff = None\n  try:\n   self.assertMultiLineEqual(sample_text, revised_sample_text)\n  except self.failureException as e:\n  \n   error = str(e).split('\\n', 1)[1]\n   \n   \n   \n   self.assertTrue(sample_text_error == error)\n   \n def testAsertEqualSingleLine(self):\n  sample_text = \"laden swallows fly slowly\"\n  revised_sample_text = \"unladen swallows fly quickly\"\n  sample_text_error = \"\"\"\\\n- laden swallows fly slowly\n?                    ^^^^\n+ unladen swallows fly quickly\n? ++                   ^^^^^\n\"\"\"  \n  try:\n   self.assertEqual(sample_text, revised_sample_text)\n  except self.failureException as e:\n   error = str(e).split('\\n', 1)[1]\n   self.assertTrue(sample_text_error == error)\n   \n def testAssertIsNone(self):\n  self.assertIsNone(None)\n  self.assertRaises(self.failureException, self.assertIsNone, False)\n  self.assertIsNotNone('DjZoPloGears on Rails')\n  self.assertRaises(self.failureException, self.assertIsNotNone, None)\n  \n def testAssertRegex(self):\n  self.assertRegex('asdfabasdf', r'ab+')\n  self.assertRaises(self.failureException, self.assertRegex,\n  'saaas', r'aaaa')\n  \n def testAssertRaisesRegex(self):\n  class ExceptionMock(Exception):\n   pass\n   \n  def Stub():\n   raise ExceptionMock('We expect')\n   \n  self.assertRaisesRegex(ExceptionMock, re.compile('expect$'), Stub)\n  self.assertRaisesRegex(ExceptionMock, 'expect$', Stub)\n  \n def testAssertNotRaisesRegex(self):\n  self.assertRaisesRegex(\n  self.failureException, '^Exception not raised by <lambda>$',\n  self.assertRaisesRegex, Exception, re.compile('x'),\n  lambda: None)\n  self.assertRaisesRegex(\n  self.failureException, '^Exception not raised by <lambda>$',\n  self.assertRaisesRegex, Exception, 'x',\n  lambda: None)\n  \n def testAssertRaisesRegexMismatch(self):\n  def Stub():\n   raise Exception('Unexpected')\n   \n  self.assertRaisesRegex(\n  self.failureException,\n  r'\"\\^Expected\\$\" does not match \"Unexpected\"',\n  self.assertRaisesRegex, Exception, '^Expected$',\n  Stub)\n  self.assertRaisesRegex(\n  self.failureException,\n  r'\"\\^Expected\\$\" does not match \"Unexpected\"',\n  self.assertRaisesRegex, Exception,\n  re.compile('^Expected$'), Stub)\n  \n def testAssertRaisesExcValue(self):\n  class ExceptionMock(Exception):\n   pass\n   \n  def Stub(foo):\n   raise ExceptionMock(foo)\n  v = \"particular value\"\n  \n  ctx = self.assertRaises(ExceptionMock)\n  with ctx:\n   Stub(v)\n  e = ctx.exception\n  self.assertIsInstance(e, ExceptionMock)\n  self.assertEqual(e.args[0], v)\n  \n def testAssertWarnsCallable(self):\n  def _runtime_warn():\n   warnings.warn(\"foo\", RuntimeWarning)\n   \n  self.assertWarns(RuntimeWarning, _runtime_warn)\n  self.assertWarns(RuntimeWarning, _runtime_warn)\n  \n  self.assertWarns((DeprecationWarning, RuntimeWarning), _runtime_warn)\n  \n  self.assertWarns(RuntimeWarning,\n  warnings.warn, \"foo\", category=RuntimeWarning)\n  \n  with self.assertRaises(self.failureException):\n   self.assertWarns(RuntimeWarning, lambda: 0)\n   \n  with warnings.catch_warnings():\n  \n   warnings.simplefilter(\"default\", RuntimeWarning)\n   with self.assertRaises(self.failureException):\n    self.assertWarns(DeprecationWarning, _runtime_warn)\n    \n  with warnings.catch_warnings():\n   warnings.simplefilter(\"error\", RuntimeWarning)\n   with self.assertRaises(RuntimeWarning):\n    self.assertWarns(DeprecationWarning, _runtime_warn)\n    \n def testAssertWarnsContext(self):\n \n \n  def _runtime_warn():\n   warnings.warn(\"foo\", RuntimeWarning)\n  _runtime_warn_lineno = inspect.getsourcelines(_runtime_warn)[1]\n  with self.assertWarns(RuntimeWarning) as cm:\n   _runtime_warn()\n   \n  with self.assertWarns((DeprecationWarning, RuntimeWarning)) as cm:\n   _runtime_warn()\n   \n  self.assertIsInstance(cm.warning, RuntimeWarning)\n  self.assertEqual(cm.warning.args[0], \"foo\")\n  self.assertIn(\"test_case.py\", cm.filename)\n  self.assertEqual(cm.lineno, _runtime_warn_lineno + 1)\n  \n  with self.assertWarns(RuntimeWarning):\n   _runtime_warn()\n   _runtime_warn()\n  with self.assertWarns(RuntimeWarning):\n   warnings.warn(\"foo\", category=RuntimeWarning)\n   \n  with self.assertRaises(self.failureException):\n   with self.assertWarns(RuntimeWarning):\n    pass\n    \n  with warnings.catch_warnings():\n  \n   warnings.simplefilter(\"default\", RuntimeWarning)\n   with self.assertRaises(self.failureException):\n    with self.assertWarns(DeprecationWarning):\n     _runtime_warn()\n     \n  with warnings.catch_warnings():\n   warnings.simplefilter(\"error\", RuntimeWarning)\n   with self.assertRaises(RuntimeWarning):\n    with self.assertWarns(DeprecationWarning):\n     _runtime_warn()\n     \n def testAssertWarnsRegexCallable(self):\n  def _runtime_warn(msg):\n   warnings.warn(msg, RuntimeWarning)\n  self.assertWarnsRegex(RuntimeWarning, \"o+\",\n  _runtime_warn, \"foox\")\n  \n  with self.assertRaises(self.failureException):\n   self.assertWarnsRegex(RuntimeWarning, \"o+\",\n   lambda: 0)\n   \n  with warnings.catch_warnings():\n  \n   warnings.simplefilter(\"default\", RuntimeWarning)\n   with self.assertRaises(self.failureException):\n    self.assertWarnsRegex(DeprecationWarning, \"o+\",\n    _runtime_warn, \"foox\")\n    \n  with self.assertRaises(self.failureException):\n   self.assertWarnsRegex(RuntimeWarning, \"o+\",\n   _runtime_warn, \"barz\")\n   \n   \n   \n   \n  with warnings.catch_warnings():\n   warnings.simplefilter(\"error\", RuntimeWarning)\n   with self.assertRaises((RuntimeWarning, self.failureException)):\n    self.assertWarnsRegex(RuntimeWarning, \"o+\",\n    _runtime_warn, \"barz\")\n    \n def testAssertWarnsRegexContext(self):\n \n  def _runtime_warn(msg):\n   warnings.warn(msg, RuntimeWarning)\n  _runtime_warn_lineno = inspect.getsourcelines(_runtime_warn)[1]\n  with self.assertWarnsRegex(RuntimeWarning, \"o+\") as cm:\n   _runtime_warn(\"foox\")\n  self.assertIsInstance(cm.warning, RuntimeWarning)\n  self.assertEqual(cm.warning.args[0], \"foox\")\n  self.assertIn(\"test_case.py\", cm.filename)\n  self.assertEqual(cm.lineno, _runtime_warn_lineno + 1)\n  \n  with self.assertRaises(self.failureException):\n   with self.assertWarnsRegex(RuntimeWarning, \"o+\"):\n    pass\n    \n  with warnings.catch_warnings():\n  \n   warnings.simplefilter(\"default\", RuntimeWarning)\n   with self.assertRaises(self.failureException):\n    with self.assertWarnsRegex(DeprecationWarning, \"o+\"):\n     _runtime_warn(\"foox\")\n     \n  with self.assertRaises(self.failureException):\n   with self.assertWarnsRegex(RuntimeWarning, \"o+\"):\n    _runtime_warn(\"barz\")\n    \n    \n    \n    \n  with warnings.catch_warnings():\n   warnings.simplefilter(\"error\", RuntimeWarning)\n   with self.assertRaises((RuntimeWarning, self.failureException)):\n    with self.assertWarnsRegex(RuntimeWarning, \"o+\"):\n     _runtime_warn(\"barz\")\n     \n def testDeprecatedMethodNames(self):\n  \"\"\n  old = (\n  (self.failIfEqual, (3, 5)),\n  (self.assertNotEquals, (3, 5)),\n  (self.failUnlessEqual, (3, 3)),\n  (self.assertEquals, (3, 3)),\n  (self.failUnlessAlmostEqual, (2.0, 2.0)),\n  (self.assertAlmostEquals, (2.0, 2.0)),\n  (self.failIfAlmostEqual, (3.0, 5.0)),\n  (self.assertNotAlmostEquals, (3.0, 5.0)),\n  (self.failUnless, (True,)),\n  (self.assert_, (True,)),\n  (self.failUnlessRaises, (TypeError, lambda _: 3.14 + 'spam')),\n  (self.failIf, (False,)),\n  (self.assertDictContainsSubset, (dict(a=1, b=2), dict(a=1, b=2, c=3))),\n  (self.assertRaisesRegexp, (KeyError, 'foo', lambda: {}['foo'])),\n  (self.assertRegexpMatches, ('bar', 'bar')),\n  )\n  for meth, args in old:\n   with self.assertWarns(DeprecationWarning):\n    meth(*args)\n    \n    \n    \n def _testDeprecatedFailMethods(self):\n  \"\"\n  if sys.version_info[:2] < (3, 3):\n   return\n  deprecated_names = [\n  'failIfEqual', 'failUnlessEqual', 'failUnlessAlmostEqual',\n  'failIfAlmostEqual', 'failUnless', 'failUnlessRaises', 'failIf',\n  'assertDictContainsSubset',\n  ]\n  for deprecated_name in deprecated_names:\n   with self.assertRaises(AttributeError):\n    getattr(self, deprecated_name) \n    \n def testDeepcopy(self):\n \n  class TestableTest(unittest.TestCase):\n   def testNothing(self):\n    pass\n    \n  test = TestableTest('testNothing')\n  \n  \n  deepcopy(test)\n  \n def testPickle(self):\n \n \n \n \n  test = unittest.TestCase('run')\n  for protocol in range(pickle.HIGHEST_PROTOCOL + 1):\n  \n  \n   pickled_test = pickle.dumps(test, protocol=protocol)\n   unpickled_test = pickle.loads(pickled_test)\n   self.assertEqual(test, unpickled_test)\n   \n   \n   \n   unpickled_test.assertEqual(set(), set())\n   \n def testKeyboardInterrupt(self):\n  def _raise(self=None):\n   raise KeyboardInterrupt\n  def nothing(self):\n   pass\n   \n  class Test1(unittest.TestCase):\n   test_something = _raise\n   \n  class Test2(unittest.TestCase):\n   setUp = _raise\n   test_something = nothing\n   \n  class Test3(unittest.TestCase):\n   test_something = nothing\n   tearDown = _raise\n   \n  class Test4(unittest.TestCase):\n   def test_something(self):\n    self.addCleanup(_raise)\n    \n  for klass in (Test1, Test2, Test3, Test4):\n   with self.assertRaises(KeyboardInterrupt):\n    klass('test_something').run()\n    \n def testSkippingEverywhere(self):\n  def _skip(self=None):\n   raise unittest.SkipTest('some reason')\n  def nothing(self):\n   pass\n   \n  class Test1(unittest.TestCase):\n   test_something = _skip\n   \n  class Test2(unittest.TestCase):\n   setUp = _skip\n   test_something = nothing\n   \n  class Test3(unittest.TestCase):\n   test_something = nothing\n   tearDown = _skip\n   \n  class Test4(unittest.TestCase):\n   def test_something(self):\n    self.addCleanup(_skip)\n    \n  for klass in (Test1, Test2, Test3, Test4):\n   result = unittest.TestResult()\n   klass('test_something').run(result)\n   self.assertEqual(len(result.skipped), 1)\n   self.assertEqual(result.testsRun, 1)\n   \n def testSystemExit(self):\n  def _raise(self=None):\n   raise SystemExit\n  def nothing(self):\n   pass\n   \n  class Test1(unittest.TestCase):\n   test_something = _raise\n   \n  class Test2(unittest.TestCase):\n   setUp = _raise\n   test_something = nothing\n   \n  class Test3(unittest.TestCase):\n   test_something = nothing\n   tearDown = _raise\n   \n  class Test4(unittest.TestCase):\n   def test_something(self):\n    self.addCleanup(_raise)\n    \n  for klass in (Test1, Test2, Test3, Test4):\n   result = unittest.TestResult()\n   klass('test_something').run(result)\n   self.assertEqual(len(result.errors), 1)\n   self.assertEqual(result.testsRun, 1)\n   \n @support.cpython_only\n def testNoCycles(self):\n  case = unittest.TestCase()\n  wr = weakref.ref(case)\n  with support.disable_gc():\n   del case\n   self.assertFalse(wr())\n"], "unittest.util": [".py", "\"\"\n\nfrom collections import namedtuple, OrderedDict\n\n__unittest = True\n\n_MAX_LENGTH = 80\ndef safe_repr(obj, short=False):\n try:\n  result = repr(obj)\n except Exception:\n  result = object.__repr__(obj)\n if not short or len(result) < _MAX_LENGTH:\n  return result\n return result[:_MAX_LENGTH] + ' [truncated]...'\n \ndef strclass(cls):\n return \"%s.%s\" % (cls.__module__, cls.__name__)\n \ndef sorted_list_difference(expected, actual):\n \"\"\n i = j = 0\n missing = []\n unexpected = []\n while True:\n  try:\n   e = expected[i]\n   a = actual[j]\n   if e < a:\n    missing.append(e)\n    i += 1\n    while expected[i] == e:\n     i += 1\n   elif e > a:\n    unexpected.append(a)\n    j += 1\n    while actual[j] == a:\n     j += 1\n   else:\n    i += 1\n    try:\n     while expected[i] == e:\n      i += 1\n    finally:\n     j += 1\n     while actual[j] == a:\n      j += 1\n  except IndexError:\n   missing.extend(expected[i:])\n   unexpected.extend(actual[j:])\n   break\n return missing, unexpected\n \n \ndef unorderable_list_difference(expected, actual):\n \"\"\n missing = []\n while expected:\n  item = expected.pop()\n  try:\n   actual.remove(item)\n  except ValueError:\n   missing.append(item)\n   \n   \n return missing, actual\n \ndef three_way_cmp(x, y):\n \"\"\n return (x > y) - (x < y)\n \n_Mismatch = namedtuple('Mismatch', 'actual expected value')\n\ndef _count_diff_all_purpose(actual, expected):\n \"\"\n \n s, t = list(actual), list(expected)\n m, n = len(s), len(t)\n NULL = object()\n result = []\n for i, elem in enumerate(s):\n  if elem is NULL:\n   continue\n  cnt_s = cnt_t = 0\n  for j in range(i, m):\n   if s[j] == elem:\n    cnt_s += 1\n    s[j] = NULL\n  for j, other_elem in enumerate(t):\n   if other_elem == elem:\n    cnt_t += 1\n    t[j] = NULL\n  if cnt_s != cnt_t:\n   diff = _Mismatch(cnt_s, cnt_t, elem)\n   result.append(diff)\n   \n for i, elem in enumerate(t):\n  if elem is NULL:\n   continue\n  cnt_t = 0\n  for j in range(i, n):\n   if t[j] == elem:\n    cnt_t += 1\n    t[j] = NULL\n  diff = _Mismatch(0, cnt_t, elem)\n  result.append(diff)\n return result\n \ndef _ordered_count(iterable):\n \"\"\n c = OrderedDict()\n for elem in iterable:\n  c[elem] = c.get(elem, 0) + 1\n return c\n \ndef _count_diff_hashable(actual, expected):\n \"\"\n \n s, t = _ordered_count(actual), _ordered_count(expected)\n result = []\n for elem, cnt_s in s.items():\n  cnt_t = t.get(elem, 0)\n  if cnt_s != cnt_t:\n   diff = _Mismatch(cnt_s, cnt_t, elem)\n   result.append(diff)\n for elem, cnt_t in t.items():\n  if elem not in s:\n   diff = _Mismatch(0, cnt_t, elem)\n   result.append(diff)\n return result\n"], "_weakref": [".py", "class ProxyType:\n\n def __init__(self,obj):\n  self.obj = obj\n  \nCallableProxyType = ProxyType\nProxyTypes = [ProxyType,CallableProxyType]\n\nclass ReferenceType:\n\n def __init__(self,obj,callback):\n  self.obj = obj\n  self.callback = callback\n  \nclass ref:\n\n def __init__(self,obj,callback=None):\n  self.obj = ReferenceType(obj,callback)\n  self.callback=callback\n  \ndef getweakrefcount(obj):\n return 1\n \ndef getweakrefs(obj):\n return obj\n \n \ndef proxy(obj,callback):\n return ProxyType(obj)\n \n"], "difflib": [".py", "\n\n\"\"\n\n__all__ = ['get_close_matches', 'ndiff', 'restore', 'SequenceMatcher',\n'Differ','IS_CHARACTER_JUNK', 'IS_LINE_JUNK', 'context_diff',\n'unified_diff', 'HtmlDiff', 'Match']\n\nimport warnings\nimport heapq\nfrom collections import namedtuple as _namedtuple\n\nMatch = _namedtuple('Match', 'a b size')\n\ndef _calculate_ratio(matches, length):\n if length:\n  return 2.0 * matches / length\n return 1.0\n \nclass SequenceMatcher:\n\n \"\"\n \n def __init__(self, isjunk=None, a='', b='', autojunk=True):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  self.isjunk = isjunk\n  self.a = self.b = None\n  self.autojunk = autojunk\n  self.set_seqs(a, b)\n  \n def set_seqs(self, a, b):\n  \"\"\n  \n  self.set_seq1(a)\n  self.set_seq2(b)\n  \n def set_seq1(self, a):\n  \"\"\n  \n  if a is self.a:\n   return\n  self.a = a\n  self.matching_blocks = self.opcodes = None\n  \n def set_seq2(self, b):\n  \"\"\n  \n  if b is self.b:\n   return\n  self.b = b\n  self.matching_blocks = self.opcodes = None\n  self.fullbcount = None\n  self.__chain_b()\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n def __chain_b(self):\n \n \n \n \n \n \n \n \n \n \n  b = self.b\n  self.b2j = b2j = {}\n  \n  for i, elt in enumerate(b):\n   indices = b2j.setdefault(elt, [])\n   indices.append(i)\n   \n   \n  self.bjunk = junk = set()\n  isjunk = self.isjunk\n  if isjunk:\n   for elt in b2j.keys():\n    if isjunk(elt):\n     junk.add(elt)\n   for elt in junk: \n    del b2j[elt]\n    \n    \n  self.bpopular = popular = set()\n  n = len(b)\n  if self.autojunk and n >= 200:\n   ntest = n // 100 + 1\n   for elt, idxs in b2j.items():\n    if len(idxs) > ntest:\n     popular.add(elt)\n   for elt in popular: \n    del b2j[elt]\n    \n def isbjunk(self, item):\n  \"\"\n  warnings.warn(\"'SequenceMatcher().isbjunk(item)' is deprecated;\\n\"\n  \"use 'item in SMinstance.bjunk' instead.\",\n  DeprecationWarning, 2)\n  return item in self.bjunk\n  \n def isbpopular(self, item):\n  \"\"\n  warnings.warn(\"'SequenceMatcher().isbpopular(item)' is deprecated;\\n\"\n  \"use 'item in SMinstance.bpopular' instead.\",\n  DeprecationWarning, 2)\n  return item in self.bpopular\n  \n def find_longest_match(self, alo, ahi, blo, bhi):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  a, b, b2j, isbjunk = self.a, self.b, self.b2j, self.bjunk.__contains__\n  besti, bestj, bestsize = alo, blo, 0\n  \n  \n  \n  j2len = {}\n  nothing = []\n  for i in range(alo, ahi):\n  \n  \n   j2lenget = j2len.get\n   newj2len = {}\n   for j in b2j.get(a[i], nothing):\n   \n    if j < blo:\n     continue\n    if j >= bhi:\n     break\n    k = newj2len[j] = j2lenget(j-1, 0) + 1\n    if k > bestsize:\n     besti, bestj, bestsize = i-k+1, j-k+1, k\n   j2len = newj2len\n   \n   \n   \n   \n   \n  while besti > alo and bestj > blo and not isbjunk(b[bestj-1]) and a[besti-1] == b[bestj-1]:\n   besti, bestj, bestsize = besti-1, bestj-1, bestsize+1\n  while besti+bestsize < ahi and bestj+bestsize < bhi and not isbjunk(b[bestj+bestsize]) and a[besti+bestsize] == b[bestj+bestsize]:\n   bestsize += 1\n   \n   \n   \n   \n   \n   \n   \n   \n  while besti > alo and bestj > blo and isbjunk(b[bestj-1]) and a[besti-1] == b[bestj-1]:\n   besti, bestj, bestsize = besti-1, bestj-1, bestsize+1\n  while besti+bestsize < ahi and bestj+bestsize < bhi and isbjunk(b[bestj+bestsize]) and a[besti+bestsize] == b[bestj+bestsize]:\n   bestsize = bestsize + 1\n   \n  return Match(besti, bestj, bestsize)\n  \n def get_matching_blocks(self):\n  \"\"\n  \n  if self.matching_blocks is not None:\n   return self.matching_blocks\n  la, lb = len(self.a), len(self.b)\n  \n  \n  \n  \n  \n  \n  \n  queue = [(0, la, 0, lb)]\n  matching_blocks = []\n  while queue:\n   alo, ahi, blo, bhi = queue.pop()\n   i, j, k = x = self.find_longest_match(alo, ahi, blo, bhi)\n   \n   \n   \n   if k: \n    matching_blocks.append(x)\n    if alo < i and blo < j:\n     queue.append((alo, i, blo, j))\n    if i+k < ahi and j+k < bhi:\n     queue.append((i+k, ahi, j+k, bhi))\n  matching_blocks.sort()\n  \n  \n  \n  \n  i1 = j1 = k1 = 0\n  non_adjacent = []\n  for i2, j2, k2 in matching_blocks:\n  \n   if i1 + k1 == i2 and j1 + k1 == j2:\n   \n   \n   \n    k1 += k2\n   else:\n   \n   \n   \n    if k1:\n     non_adjacent.append((i1, j1, k1))\n    i1, j1, k1 = i2, j2, k2\n  if k1:\n   non_adjacent.append((i1, j1, k1))\n   \n  non_adjacent.append( (la, lb, 0) )\n  self.matching_blocks = non_adjacent\n  return map(Match._make, self.matching_blocks)\n  \n def get_opcodes(self):\n  \"\"\n  \n  if self.opcodes is not None:\n   return self.opcodes\n  i = j = 0\n  self.opcodes = answer = []\n  for ai, bj, size in self.get_matching_blocks():\n  \n  \n  \n  \n  \n   tag = ''\n   if i < ai and j < bj:\n    tag = 'replace'\n   elif i < ai:\n    tag = 'delete'\n   elif j < bj:\n    tag = 'insert'\n   if tag:\n    answer.append( (tag, i, ai, j, bj) )\n   i, j = ai+size, bj+size\n   \n   \n   if size:\n    answer.append( ('equal', ai, i, bj, j) )\n  return answer\n  \n def get_grouped_opcodes(self, n=3):\n  \"\"\n  \n  codes = self.get_opcodes()\n  if not codes:\n   codes = [(\"equal\", 0, 1, 0, 1)]\n   \n  if codes[0][0] == 'equal':\n   tag, i1, i2, j1, j2 = codes[0]\n   codes[0] = tag, max(i1, i2-n), i2, max(j1, j2-n), j2\n  if codes[-1][0] == 'equal':\n   tag, i1, i2, j1, j2 = codes[-1]\n   codes[-1] = tag, i1, min(i2, i1+n), j1, min(j2, j1+n)\n   \n  nn = n + n\n  group = []\n  for tag, i1, i2, j1, j2 in codes:\n  \n  \n   if tag == 'equal' and i2-i1 > nn:\n    group.append((tag, i1, min(i2, i1+n), j1, min(j2, j1+n)))\n    yield group\n    group = []\n    i1, j1 = max(i1, i2-n), max(j1, j2-n)\n   group.append((tag, i1, i2, j1 ,j2))\n  if group and not (len(group)==1 and group[0][0] == 'equal'):\n   yield group\n   \n def ratio(self):\n  \"\"\n  \n  matches = sum(triple[-1] for triple in self.get_matching_blocks())\n  return _calculate_ratio(matches, len(self.a) + len(self.b))\n  \n def quick_ratio(self):\n  \"\"\n  \n  \n  \n  \n  if self.fullbcount is None:\n   self.fullbcount = fullbcount = {}\n   for elt in self.b:\n    fullbcount[elt] = fullbcount.get(elt, 0) + 1\n  fullbcount = self.fullbcount\n  \n  \n  avail = {}\n  availhas, matches = avail.__contains__, 0\n  for elt in self.a:\n   if availhas(elt):\n    numb = avail[elt]\n   else:\n    numb = fullbcount.get(elt, 0)\n   avail[elt] = numb - 1\n   if numb > 0:\n    matches = matches + 1\n  return _calculate_ratio(matches, len(self.a) + len(self.b))\n  \n def real_quick_ratio(self):\n  \"\"\n  \n  la, lb = len(self.a), len(self.b)\n  \n  \n  return _calculate_ratio(min(la, lb), la + lb)\n  \ndef get_close_matches(word, possibilities, n=3, cutoff=0.6):\n \"\"\n \n if not n > 0:\n  raise ValueError(\"n must be > 0: %r\" % (n,))\n if not 0.0 <= cutoff <= 1.0:\n  raise ValueError(\"cutoff must be in [0.0, 1.0]: %r\" % (cutoff,))\n result = []\n s = SequenceMatcher()\n s.set_seq2(word)\n for x in possibilities:\n  s.set_seq1(x)\n  if s.real_quick_ratio() >= cutoff and s.quick_ratio() >= cutoff and s.ratio() >= cutoff:\n   result.append((s.ratio(), x))\n   \n   \n result = heapq.nlargest(n, result)\n \n return [x for score, x in result]\n \ndef _count_leading(line, ch):\n \"\"\n \n i, n = 0, len(line)\n while i < n and line[i] == ch:\n  i += 1\n return i\n \nclass Differ:\n \"\"\n \n def __init__(self, linejunk=None, charjunk=None):\n  \"\"\n  \n  self.linejunk = linejunk\n  self.charjunk = charjunk\n  \n def compare(self, a, b):\n  \"\"\n  \n  cruncher = SequenceMatcher(self.linejunk, a, b)\n  for tag, alo, ahi, blo, bhi in cruncher.get_opcodes():\n   if tag == 'replace':\n    g = self._fancy_replace(a, alo, ahi, b, blo, bhi)\n   elif tag == 'delete':\n    g = self._dump('-', a, alo, ahi)\n   elif tag == 'insert':\n    g = self._dump('+', b, blo, bhi)\n   elif tag == 'equal':\n    g = self._dump(' ', a, alo, ahi)\n   else:\n    raise ValueError('unknown tag %r' % (tag,))\n    \n   for line in g:\n    yield line\n    \n def _dump(self, tag, x, lo, hi):\n  \"\"\n  for i in range(lo, hi):\n   yield '%s %s' % (tag, x[i])\n   \n def _plain_replace(self, a, alo, ahi, b, blo, bhi):\n  assert alo < ahi and blo < bhi\n  \n  \n  if bhi - blo < ahi - alo:\n   first = self._dump('+', b, blo, bhi)\n   second = self._dump('-', a, alo, ahi)\n  else:\n   first = self._dump('-', a, alo, ahi)\n   second = self._dump('+', b, blo, bhi)\n   \n  for g in first, second:\n   for line in g:\n    yield line\n    \n def _fancy_replace(self, a, alo, ahi, b, blo, bhi):\n  \"\"\n  \n  \n  \n  best_ratio, cutoff = 0.74, 0.75\n  cruncher = SequenceMatcher(self.charjunk)\n  eqi, eqj = None, None \n  \n  \n  \n  \n  for j in range(blo, bhi):\n   bj = b[j]\n   cruncher.set_seq2(bj)\n   for i in range(alo, ahi):\n    ai = a[i]\n    if ai == bj:\n     if eqi is None:\n      eqi, eqj = i, j\n     continue\n    cruncher.set_seq1(ai)\n    \n    \n    \n    \n    \n    \n    if cruncher.real_quick_ratio() > best_ratio and cruncher.quick_ratio() > best_ratio and cruncher.ratio() > best_ratio:\n     best_ratio, best_i, best_j = cruncher.ratio(), i, j\n  if best_ratio < cutoff:\n  \n   if eqi is None:\n   \n    for line in self._plain_replace(a, alo, ahi, b, blo, bhi):\n     yield line\n    return\n    \n   best_i, best_j, best_ratio = eqi, eqj, 1.0\n  else:\n  \n   eqi = None\n   \n   \n   \n   \n   \n  for line in self._fancy_helper(a, alo, best_i, b, blo, best_j):\n   yield line\n   \n   \n  aelt, belt = a[best_i], b[best_j]\n  if eqi is None:\n  \n   atags = btags = \"\"\n   cruncher.set_seqs(aelt, belt)\n   for tag, ai1, ai2, bj1, bj2 in cruncher.get_opcodes():\n    la, lb = ai2 - ai1, bj2 - bj1\n    if tag == 'replace':\n     atags += '^' * la\n     btags += '^' * lb\n    elif tag == 'delete':\n     atags += '-' * la\n    elif tag == 'insert':\n     btags += '+' * lb\n    elif tag == 'equal':\n     atags += ' ' * la\n     btags += ' ' * lb\n    else:\n     raise ValueError('unknown tag %r' % (tag,))\n   for line in self._qformat(aelt, belt, atags, btags):\n    yield line\n  else:\n  \n   yield '  ' + aelt\n   \n   \n  for line in self._fancy_helper(a, best_i+1, ahi, b, best_j+1, bhi):\n   yield line\n   \n def _fancy_helper(self, a, alo, ahi, b, blo, bhi):\n  g = []\n  if alo < ahi:\n   if blo < bhi:\n    g = self._fancy_replace(a, alo, ahi, b, blo, bhi)\n   else:\n    g = self._dump('-', a, alo, ahi)\n  elif blo < bhi:\n   g = self._dump('+', b, blo, bhi)\n   \n  for line in g:\n   yield line\n   \n def _qformat(self, aline, bline, atags, btags):\n  \"\"\n  \n  \n  common = min(_count_leading(aline, \"\\t\"),\n  _count_leading(bline, \"\\t\"))\n  common = min(common, _count_leading(atags[:common], \" \"))\n  common = min(common, _count_leading(btags[:common], \" \"))\n  atags = atags[common:].rstrip()\n  btags = btags[common:].rstrip()\n  \n  yield \"- \" + aline\n  if atags:\n   yield \"? %s%s\\n\" % (\"\\t\" * common, atags)\n   \n  yield \"+ \" + bline\n  if btags:\n   yield \"? %s%s\\n\" % (\"\\t\" * common, btags)\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \nimport re\n\ndef IS_LINE_JUNK(line, pat=re.compile(r\"\\s*#?\\s*$\").match):\n \"\"\n \n return pat(line) is not None\n \ndef IS_CHARACTER_JUNK(ch, ws=\" \\t\"):\n \"\"\n \n return ch in ws\n \n \n \n \n \n \ndef _format_range_unified(start, stop):\n \"\"\n \n beginning = start + 1 \n length = stop - start\n if length == 1:\n  return '{}'.format(beginning)\n if not length:\n  beginning -= 1 \n return '{},{}'.format(beginning, length)\n \ndef unified_diff(a, b, fromfile='', tofile='', fromfiledate='',\ntofiledate='', n=3, lineterm='\\n'):\n \"\"\n \n started = False\n for group in SequenceMatcher(None,a,b).get_grouped_opcodes(n):\n  if not started:\n   started = True\n   fromdate = '\\t{}'.format(fromfiledate) if fromfiledate else ''\n   todate = '\\t{}'.format(tofiledate) if tofiledate else ''\n   yield '--- {}{}{}'.format(fromfile, fromdate, lineterm)\n   yield '+++ {}{}{}'.format(tofile, todate, lineterm)\n   \n  first, last = group[0], group[-1]\n  file1_range = _format_range_unified(first[1], last[2])\n  file2_range = _format_range_unified(first[3], last[4])\n  yield '@@ -{} +{} @@{}'.format(file1_range, file2_range, lineterm)\n  \n  for tag, i1, i2, j1, j2 in group:\n   if tag == 'equal':\n    for line in a[i1:i2]:\n     yield ' ' + line\n    continue\n   if tag in {'replace', 'delete'}:\n    for line in a[i1:i2]:\n     yield '-' + line\n   if tag in {'replace', 'insert'}:\n    for line in b[j1:j2]:\n     yield '+' + line\n     \n     \n     \n     \n     \n     \ndef _format_range_context(start, stop):\n \"\"\n \n beginning = start + 1 \n length = stop - start\n if not length:\n  beginning -= 1 \n if length <= 1:\n  return '{}'.format(beginning)\n return '{},{}'.format(beginning, beginning + length - 1)\n \n \ndef context_diff(a, b, fromfile='', tofile='',\nfromfiledate='', tofiledate='', n=3, lineterm='\\n'):\n \"\"\n \n prefix = dict(insert='+ ', delete='- ', replace='! ', equal='  ')\n started = False\n for group in SequenceMatcher(None,a,b).get_grouped_opcodes(n):\n  if not started:\n   started = True\n   fromdate = '\\t{}'.format(fromfiledate) if fromfiledate else ''\n   todate = '\\t{}'.format(tofiledate) if tofiledate else ''\n   yield '*** {}{}{}'.format(fromfile, fromdate, lineterm)\n   yield '--- {}{}{}'.format(tofile, todate, lineterm)\n   \n  first, last = group[0], group[-1]\n  yield '***************' + lineterm\n  \n  file1_range = _format_range_context(first[1], last[2])\n  yield '*** {} ****{}'.format(file1_range, lineterm)\n  \n  if any(tag in {'replace', 'delete'} for tag, _, _, _, _ in group):\n   for tag, i1, i2, _, _ in group:\n    if tag != 'insert':\n     for line in a[i1:i2]:\n      yield prefix[tag] + line\n      \n  file2_range = _format_range_context(first[3], last[4])\n  yield '--- {} ----{}'.format(file2_range, lineterm)\n  \n  if any(tag in {'replace', 'insert'} for tag, _, _, _, _ in group):\n   for tag, _, _, j1, j2 in group:\n    if tag != 'delete':\n     for line in b[j1:j2]:\n      yield prefix[tag] + line\n      \ndef ndiff(a, b, linejunk=None, charjunk=IS_CHARACTER_JUNK):\n \"\"\n return Differ(linejunk, charjunk).compare(a, b)\n \ndef _mdiff(fromlines, tolines, context=None, linejunk=None,\ncharjunk=IS_CHARACTER_JUNK):\n \"\"\n import re\n \n \n change_re = re.compile('(\\++|\\-+|\\^+)')\n \n \n diff_lines_iterator = ndiff(fromlines,tolines,linejunk,charjunk)\n \n def _make_line(lines, format_key, side, num_lines=[0,0]):\n  \"\"\n  num_lines[side] += 1\n  \n  \n  if format_key is None:\n   return (num_lines[side],lines.pop(0)[2:])\n   \n  if format_key == '?':\n   text, markers = lines.pop(0), lines.pop(0)\n   \n   sub_info = []\n   def record_sub_info(match_object,sub_info=sub_info):\n    sub_info.append([match_object.group(1)[0],match_object.span()])\n    return match_object.group(1)\n   change_re.sub(record_sub_info,markers)\n   \n   \n   for key,(begin,end) in sub_info[::-1]:\n    text = text[0:begin]+'\\0'+key+text[begin:end]+'\\1'+text[end:]\n   text = text[2:]\n   \n  else:\n   text = lines.pop(0)[2:]\n   \n   \n   if not text:\n    text = ' '\n    \n   text = '\\0' + format_key + text + '\\1'\n   \n   \n   \n  return (num_lines[side],text)\n  \n def _line_iterator():\n  \"\"\n  lines = []\n  num_blanks_pending, num_blanks_to_yield = 0, 0\n  while True:\n  \n  \n  \n   while len(lines) < 4:\n    try:\n     lines.append(next(diff_lines_iterator))\n    except StopIteration:\n     lines.append('X')\n   s = ''.join([line[0] for line in lines])\n   if s.startswith('X'):\n   \n   \n   \n    num_blanks_to_yield = num_blanks_pending\n   elif s.startswith('-?+?'):\n   \n    yield _make_line(lines,'?',0), _make_line(lines,'?',1), True\n    continue\n   elif s.startswith('--++'):\n   \n   \n    num_blanks_pending -= 1\n    yield _make_line(lines,'-',0), None, True\n    continue\n   elif s.startswith(('--?+', '--+', '- ')):\n   \n   \n    from_line,to_line = _make_line(lines,'-',0), None\n    num_blanks_to_yield,num_blanks_pending = num_blanks_pending-1,0\n   elif s.startswith('-+?'):\n   \n    yield _make_line(lines,None,0), _make_line(lines,'?',1), True\n    continue\n   elif s.startswith('-?+'):\n   \n    yield _make_line(lines,'?',0), _make_line(lines,None,1), True\n    continue\n   elif s.startswith('-'):\n   \n    num_blanks_pending -= 1\n    yield _make_line(lines,'-',0), None, True\n    continue\n   elif s.startswith('+--'):\n   \n   \n    num_blanks_pending += 1\n    yield None, _make_line(lines,'+',1), True\n    continue\n   elif s.startswith(('+ ', '+-')):\n   \n    from_line, to_line = None, _make_line(lines,'+',1)\n    num_blanks_to_yield,num_blanks_pending = num_blanks_pending+1,0\n   elif s.startswith('+'):\n   \n    num_blanks_pending += 1\n    yield None, _make_line(lines,'+',1), True\n    continue\n   elif s.startswith(' '):\n   \n    yield _make_line(lines[:],None,0),_make_line(lines,None,1),False\n    continue\n    \n    \n   while(num_blanks_to_yield < 0):\n    num_blanks_to_yield += 1\n    yield None,('','\\n'),True\n   while(num_blanks_to_yield > 0):\n    num_blanks_to_yield -= 1\n    yield ('','\\n'),None,True\n   if s.startswith('X'):\n    raise StopIteration\n   else:\n    yield from_line,to_line,True\n    \n def _line_pair_iterator():\n  \"\"\n  line_iterator = _line_iterator()\n  fromlines,tolines=[],[]\n  while True:\n  \n   while (len(fromlines)==0 or len(tolines)==0):\n    from_line, to_line, found_diff = next(line_iterator)\n    if from_line is not None:\n     fromlines.append((from_line,found_diff))\n    if to_line is not None:\n     tolines.append((to_line,found_diff))\n     \n   from_line, fromDiff = fromlines.pop(0)\n   to_line, to_diff = tolines.pop(0)\n   yield (from_line,to_line,fromDiff or to_diff)\n   \n   \n   \n line_pair_iterator = _line_pair_iterator()\n if context is None:\n  while True:\n   yield next(line_pair_iterator)\n   \n   \n else:\n  context += 1\n  lines_to_write = 0\n  while True:\n  \n  \n  \n   index, contextLines = 0, [None]*(context)\n   found_diff = False\n   while(found_diff is False):\n    from_line, to_line, found_diff = next(line_pair_iterator)\n    i = index % context\n    contextLines[i] = (from_line, to_line, found_diff)\n    index += 1\n    \n    \n   if index > context:\n    yield None, None, None\n    lines_to_write = context\n   else:\n    lines_to_write = index\n    index = 0\n   while(lines_to_write):\n    i = index % context\n    index += 1\n    yield contextLines[i]\n    lines_to_write -= 1\n    \n   lines_to_write = context-1\n   while(lines_to_write):\n    from_line, to_line, found_diff = next(line_pair_iterator)\n    \n    if found_diff:\n     lines_to_write = context-1\n    else:\n     lines_to_write -= 1\n    yield from_line, to_line, found_diff\n    \n    \n_file_template = \"\"\"\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n          \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n\n<html>\n\n<head>\n    <meta http-equiv=\"Content-Type\"\n          content=\"text/html; charset=ISO-8859-1\" />\n    <title></title>\n    <style type=\"text/css\">%(styles)s\n    </style>\n</head>\n\n<body>\n    %(table)s%(legend)s\n</body>\n\n</html>\"\"\"\n\n_styles = \"\"\"\n        table.diff {font-family:Courier; border:medium;}\n        .diff_header {background-color:#e0e0e0}\n        td.diff_header {text-align:right}\n        .diff_next {background-color:#c0c0c0}\n        .diff_add {background-color:#aaffaa}\n        .diff_chg {background-color:#ffff77}\n        .diff_sub {background-color:#ffaaaa}\"\"\"\n\n_table_template = \"\"\"\n    <table class=\"diff\" id=\"difflib_chg_%(prefix)s_top\"\n           cellspacing=\"0\" cellpadding=\"0\" rules=\"groups\" >\n        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n        %(header_row)s\n        <tbody>\n%(data_rows)s        </tbody>\n    </table>\"\"\"\n\n_legend = \"\"\"\n    <table class=\"diff\" summary=\"Legends\">\n        <tr> <th colspan=\"2\"> Legends </th> </tr>\n        <tr> <td> <table border=\"\" summary=\"Colors\">\n                      <tr><th> Colors </th> </tr>\n                      <tr><td class=\"diff_add\">&nbsp;Added&nbsp;</td></tr>\n                      <tr><td class=\"diff_chg\">Changed</td> </tr>\n                      <tr><td class=\"diff_sub\">Deleted</td> </tr>\n                  </table></td>\n             <td> <table border=\"\" summary=\"Links\">\n                      <tr><th colspan=\"2\"> Links </th> </tr>\n                      <tr><td>(f)irst change</td> </tr>\n                      <tr><td>(n)ext change</td> </tr>\n                      <tr><td>(t)op</td> </tr>\n                  </table></td> </tr>\n    </table>\"\"\"\n\nclass HtmlDiff(object):\n \"\"\n \n _file_template = _file_template\n _styles = _styles\n _table_template = _table_template\n _legend = _legend\n _default_prefix = 0\n \n def __init__(self,tabsize=8,wrapcolumn=None,linejunk=None,\n charjunk=IS_CHARACTER_JUNK):\n  \"\"\n  self._tabsize = tabsize\n  self._wrapcolumn = wrapcolumn\n  self._linejunk = linejunk\n  self._charjunk = charjunk\n  \n def make_file(self,fromlines,tolines,fromdesc='',todesc='',context=False,\n numlines=5):\n  \"\"\n  \n  return self._file_template % dict(\n  styles = self._styles,\n  legend = self._legend,\n  table = self.make_table(fromlines,tolines,fromdesc,todesc,\n  context=context,numlines=numlines))\n  \n def _tab_newline_replace(self,fromlines,tolines):\n  \"\"\n  def expand_tabs(line):\n  \n   line = line.replace(' ','\\0')\n   \n   line = line.expandtabs(self._tabsize)\n   \n   \n   line = line.replace(' ','\\t')\n   return line.replace('\\0',' ').rstrip('\\n')\n  fromlines = [expand_tabs(line) for line in fromlines]\n  tolines = [expand_tabs(line) for line in tolines]\n  return fromlines,tolines\n  \n def _split_line(self,data_list,line_num,text):\n  \"\"\n  \n  if not line_num:\n   data_list.append((line_num,text))\n   return\n   \n   \n  size = len(text)\n  max = self._wrapcolumn\n  if (size <= max) or ((size -(text.count('\\0')*3)) <= max):\n   data_list.append((line_num,text))\n   return\n   \n   \n   \n  i = 0\n  n = 0\n  mark = ''\n  while n < max and i < size:\n   if text[i] == '\\0':\n    i += 1\n    mark = text[i]\n    i += 1\n   elif text[i] == '\\1':\n    i += 1\n    mark = ''\n   else:\n    i += 1\n    n += 1\n    \n    \n  line1 = text[:i]\n  line2 = text[i:]\n  \n  \n  \n  \n  if mark:\n   line1 = line1 + '\\1'\n   line2 = '\\0' + mark + line2\n   \n   \n  data_list.append((line_num,line1))\n  \n  \n  self._split_line(data_list,'>',line2)\n  \n def _line_wrapper(self,diffs):\n  \"\"\n  \n  \n  for fromdata,todata,flag in diffs:\n  \n   if flag is None:\n    yield fromdata,todata,flag\n    continue\n   (fromline,fromtext),(toline,totext) = fromdata,todata\n   \n   \n   fromlist,tolist = [],[]\n   self._split_line(fromlist,fromline,fromtext)\n   self._split_line(tolist,toline,totext)\n   \n   \n   while fromlist or tolist:\n    if fromlist:\n     fromdata = fromlist.pop(0)\n    else:\n     fromdata = ('',' ')\n    if tolist:\n     todata = tolist.pop(0)\n    else:\n     todata = ('',' ')\n    yield fromdata,todata,flag\n    \n def _collect_lines(self,diffs):\n  \"\"\n  \n  fromlist,tolist,flaglist = [],[],[]\n  \n  for fromdata,todata,flag in diffs:\n   try:\n   \n    fromlist.append(self._format_line(0,flag,*fromdata))\n    tolist.append(self._format_line(1,flag,*todata))\n   except TypeError:\n   \n    fromlist.append(None)\n    tolist.append(None)\n   flaglist.append(flag)\n  return fromlist,tolist,flaglist\n  \n def _format_line(self,side,flag,linenum,text):\n  \"\"\n  try:\n   linenum = '%d' % linenum\n   id = ' id=\"%s%s\"' % (self._prefix[side],linenum)\n  except TypeError:\n  \n   id = ''\n   \n  text=text.replace(\"&\",\"&amp;\").replace(\">\",\"&gt;\").replace(\"<\",\"&lt;\")\n  \n  \n  text = text.replace(' ','&nbsp;').rstrip()\n  \n  return '<td class=\"diff_header\"%s>%s</td><td nowrap=\"nowrap\">%s</td>' % (id,linenum,text)\n  \n def _make_prefix(self):\n  \"\"\n  \n  \n  \n  fromprefix = \"from%d_\" % HtmlDiff._default_prefix\n  toprefix = \"to%d_\" % HtmlDiff._default_prefix\n  HtmlDiff._default_prefix += 1\n  \n  self._prefix = [fromprefix,toprefix]\n  \n def _convert_flags(self,fromlist,tolist,flaglist,context,numlines):\n  \"\"\n  \n  \n  toprefix = self._prefix[1]\n  \n  \n  next_id = ['']*len(flaglist)\n  next_href = ['']*len(flaglist)\n  num_chg, in_change = 0, False\n  last = 0\n  for i,flag in enumerate(flaglist):\n   if flag:\n    if not in_change:\n     in_change = True\n     last = i\n     \n     \n     \n     i = max([0,i-numlines])\n     next_id[i] = ' id=\"difflib_chg_%s_%d\"' % (toprefix,num_chg)\n     \n     \n     num_chg += 1\n     next_href[last] = '<a href=\"#difflib_chg_%s_%d\">n</a>' % (\n     toprefix,num_chg)\n   else:\n    in_change = False\n    \n  if not flaglist:\n   flaglist = [False]\n   next_id = ['']\n   next_href = ['']\n   last = 0\n   if context:\n    fromlist = ['<td></td><td>&nbsp;No Differences Found&nbsp;</td>']\n    tolist = fromlist\n   else:\n    fromlist = tolist = ['<td></td><td>&nbsp;Empty File&nbsp;</td>']\n    \n  if not flaglist[0]:\n   next_href[0] = '<a href=\"#difflib_chg_%s_0\">f</a>' % toprefix\n   \n  next_href[last] = '<a href=\"#difflib_chg_%s_top\">t</a>' % (toprefix)\n  \n  return fromlist,tolist,flaglist,next_href,next_id\n  \n def make_table(self,fromlines,tolines,fromdesc='',todesc='',context=False,\n numlines=5):\n  \"\"\n  \n  \n  \n  self._make_prefix()\n  \n  \n  \n  fromlines,tolines = self._tab_newline_replace(fromlines,tolines)\n  \n  \n  if context:\n   context_lines = numlines\n  else:\n   context_lines = None\n  diffs = _mdiff(fromlines,tolines,context_lines,linejunk=self._linejunk,\n  charjunk=self._charjunk)\n  \n  \n  if self._wrapcolumn:\n   diffs = self._line_wrapper(diffs)\n   \n   \n  fromlist,tolist,flaglist = self._collect_lines(diffs)\n  \n  \n  fromlist,tolist,flaglist,next_href,next_id = self._convert_flags(\n  fromlist,tolist,flaglist,context,numlines)\n  \n  s = []\n  fmt = '            <tr><td class=\"diff_next\"%s>%s</td>%s' + '<td class=\"diff_next\">%s</td>%s</tr>\\n'\n  for i in range(len(flaglist)):\n   if flaglist[i] is None:\n   \n   \n    if i > 0:\n     s.append('        </tbody>        \\n        <tbody>\\n')\n   else:\n    s.append( fmt % (next_id[i],next_href[i],fromlist[i],\n    next_href[i],tolist[i]))\n  if fromdesc or todesc:\n   header_row = '<thead><tr>%s%s%s%s</tr></thead>' % (\n   '<th class=\"diff_next\"><br /></th>',\n   '<th colspan=\"2\" class=\"diff_header\">%s</th>' % fromdesc,\n   '<th class=\"diff_next\"><br /></th>',\n   '<th colspan=\"2\" class=\"diff_header\">%s</th>' % todesc)\n  else:\n   header_row = ''\n   \n  table = self._table_template % dict(\n  data_rows=''.join(s),\n  header_row=header_row,\n  prefix=self._prefix[1])\n  \n  return table.replace('\\0+','<span class=\"diff_add\">'). replace('\\0-','<span class=\"diff_sub\">'). replace('\\0^','<span class=\"diff_chg\">'). replace('\\1','</span>'). replace('\\t','&nbsp;')\n  \ndel re\n\ndef restore(delta, which):\n \"\"\n try:\n  tag = {1: \"- \", 2: \"+ \"}[int(which)]\n except KeyError:\n  raise ValueError('unknown delta choice (must be 1 or 2): %r'\n  % which)\n prefixes = (\"  \", tag)\n for line in delta:\n  if line[:2] in prefixes:\n   yield line[2:]\n   \ndef _test():\n import doctest, difflib\n return doctest.testmod(difflib)\n \nif __name__ == \"__main__\":\n _test()\n"], "_io": [".py", "\"\"\n\nimport os\nimport abc\nimport codecs\nimport errno\n\ntry:\n from _thread import allocate_lock as Lock\nexcept ImportError:\n from _dummy_thread import allocate_lock as Lock\n \nimport io\n\n\nSEEK_SET=0\nSEEK_CUR=1\nSEEK_END=2\n\nvalid_seek_flags = {0, 1, 2} \nif hasattr(os, 'SEEK_HOLE') :\n valid_seek_flags.add(os.SEEK_HOLE)\n valid_seek_flags.add(os.SEEK_DATA)\n \n \nDEFAULT_BUFFER_SIZE = 8 * 1024 \n\n\n\n\n\n\nBlockingIOError = BlockingIOError\n\n\ndef __open(file, mode=\"r\", buffering=-1, encoding=None, errors=None,\nnewline=None, closefd=True, opener=None):\n\n \"\"\n if not isinstance(file, (str, bytes, int)):\n  raise TypeError(\"invalid file: %r\" % file)\n if not isinstance(mode, str):\n  raise TypeError(\"invalid mode: %r\" % mode)\n if not isinstance(buffering, int):\n  raise TypeError(\"invalid buffering: %r\" % buffering)\n if encoding is not None and not isinstance(encoding, str):\n  raise TypeError(\"invalid encoding: %r\" % encoding)\n if errors is not None and not isinstance(errors, str):\n  raise TypeError(\"invalid errors: %r\" % errors)\n modes = set(mode)\n if modes - set(\"axrwb+tU\") or len(mode) > len(modes):\n  raise ValueError(\"invalid mode: %r\" % mode)\n creating = \"x\" in modes\n reading = \"r\" in modes\n writing = \"w\" in modes\n appending = \"a\" in modes\n updating = \"+\" in modes\n text = \"t\" in modes\n binary = \"b\" in modes\n if \"U\" in modes:\n  if creating or writing or appending:\n   raise ValueError(\"can't use U and writing mode at once\")\n  reading = True\n if text and binary:\n  raise ValueError(\"can't have text and binary mode at once\")\n if creating + reading + writing + appending > 1:\n  raise ValueError(\"can't have read/write/append mode at once\")\n if not (creating or reading or writing or appending):\n  raise ValueError(\"must have exactly one of read/write/append mode\")\n if binary and encoding is not None:\n  raise ValueError(\"binary mode doesn't take an encoding argument\")\n if binary and errors is not None:\n  raise ValueError(\"binary mode doesn't take an errors argument\")\n if binary and newline is not None:\n  raise ValueError(\"binary mode doesn't take a newline argument\")\n raw = FileIO(file,\n (creating and \"x\" or \"\") +\n (reading and \"r\" or \"\") +\n (writing and \"w\" or \"\") +\n (appending and \"a\" or \"\") +\n (updating and \"+\" or \"\"),\n closefd, opener=opener)\n line_buffering = False\n if buffering == 1 or buffering < 0 and raw.isatty():\n  buffering = -1\n  line_buffering = True\n if buffering < 0:\n  buffering = DEFAULT_BUFFER_SIZE\n  try:\n   bs = os.fstat(raw.fileno()).st_blksize\n  except (os.error, AttributeError):\n   pass\n  else:\n   if bs > 1:\n    buffering = bs\n if buffering < 0:\n  raise ValueError(\"invalid buffering size\")\n if buffering == 0:\n  if binary:\n   return raw\n  raise ValueError(\"can't have unbuffered text I/O\")\n if updating:\n  buffer = BufferedRandom(raw, buffering)\n elif creating or writing or appending:\n  buffer = BufferedWriter(raw, buffering)\n elif reading:\n  buffer = BufferedReader(raw, buffering)\n else:\n  raise ValueError(\"unknown mode: %r\" % mode)\n if binary:\n  return buffer\n text = TextIOWrapper(buffer, encoding, errors, newline, line_buffering)\n text.mode = mode\n return text\n \n \nclass DocDescriptor:\n \"\"\n def __get__(self, obj, typ):\n  return (\n  \"open(file, mode='r', buffering=-1, encoding=None, \"\n  \"errors=None, newline=None, closefd=True)\\n\\n\" +\n  open.__doc__)\n  \nclass OpenWrapper:\n \"\"\n __doc__ = DocDescriptor()\n \n def __new__(cls, *args, **kwargs):\n  return open(*args, **kwargs)\n  \n  \n  \n  \ntry:\n UnsupportedOperation = io.UnsupportedOperation\nexcept AttributeError:\n class UnsupportedOperation(ValueError, IOError):\n  pass\n  \n  \nclass IOBase(metaclass=abc.ABCMeta):\n\n \"\"\n \n \n \n def _unsupported(self, name):\n  \"\"\n  raise UnsupportedOperation(\"%s.%s() not supported\" %\n  (self.__class__.__name__, name))\n  \n  \n  \n def seek(self, pos, whence=0):\n  \"\"\n  self._unsupported(\"seek\")\n  \n def tell(self):\n  \"\"\n  return self.seek(0, 1)\n  \n def truncate(self, pos=None):\n  \"\"\n  self._unsupported(\"truncate\")\n  \n  \n  \n def flush(self):\n  \"\"\n  self._checkClosed()\n  \n  \n __closed = False\n \n def close(self):\n  \"\"\n  if not self.__closed:\n   try:\n    self.flush()\n   finally:\n    self.__closed = True\n    \n def __del__(self):\n  \"\"\n  \n  \n  \n  \n  \n  try:\n   self.close()\n  except:\n   pass\n   \n   \n   \n def seekable(self):\n  \"\"\n  return False\n  \n def _checkSeekable(self, msg=None):\n  \"\"\n  if not self.seekable():\n   raise UnsupportedOperation(\"File or stream is not seekable.\"\n   if msg is None else msg)\n   \n def readable(self):\n  \"\"\n  return False\n  \n def _checkReadable(self, msg=None):\n  \"\"\n  if not self.readable():\n   raise UnsupportedOperation(\"File or stream is not readable.\"\n   if msg is None else msg)\n   \n def writable(self):\n  \"\"\n  return False\n  \n def _checkWritable(self, msg=None):\n  \"\"\n  if not self.writable():\n   raise UnsupportedOperation(\"File or stream is not writable.\"\n   if msg is None else msg)\n   \n @property\n def closed(self):\n  \"\"\n  return self.__closed\n  \n def _checkClosed(self, msg=None):\n  \"\"\n  if self.closed:\n   raise ValueError(\"I/O operation on closed file.\"\n   if msg is None else msg)\n   \n   \n   \n def __enter__(self): \n  \"\"\n  self._checkClosed()\n  return self\n  \n def __exit__(self, *args):\n  \"\"\n  self.close()\n  \n  \n  \n  \n  \n def fileno(self):\n  \"\"\n  self._unsupported(\"fileno\")\n  \n def isatty(self):\n  \"\"\n  self._checkClosed()\n  return False\n  \n  \n  \n def readline(self, limit=-1):\n  \"\"\n  \n  if hasattr(self, \"peek\"):\n   def nreadahead():\n    readahead = self.peek(1)\n    if not readahead:\n     return 1\n    n = (readahead.find(b\"\\n\") + 1) or len(readahead)\n    if limit >= 0:\n     n = min(n, limit)\n    return n\n  else:\n   def nreadahead():\n    return 1\n  if limit is None:\n   limit = -1\n  elif not isinstance(limit, int):\n   raise TypeError(\"limit must be an integer\")\n  res = bytearray()\n  while limit < 0 or len(res) < limit:\n   b = self.read(nreadahead())\n   if not b:\n    break\n   res += b\n   if res.endswith(b\"\\n\"):\n    break\n  return bytes(res)\n  \n def __iter__(self):\n  self._checkClosed()\n  return self\n  \n def __next__(self):\n  line = self.readline()\n  if not line:\n   raise StopIteration\n  return line\n  \n def readlines(self, hint=None):\n  \"\"\n  if hint is None or hint <= 0:\n   return list(self)\n  n = 0\n  lines = []\n  for line in self:\n   lines.append(line)\n   n += len(line)\n   if n >= hint:\n    break\n  return lines\n  \n def writelines(self, lines):\n  self._checkClosed()\n  for line in lines:\n   self.write(line)\n   \n   \n   \n   \n   \nclass RawIOBase(IOBase):\n\n \"\"\n \n \n \n \n \n \n \n \n \n \n \n def read(self, n=-1):\n  \"\"\n  if n is None:\n   n = -1\n  if n < 0:\n   return self.readall()\n  b = bytearray(n.__index__())\n  n = self.readinto(b)\n  if n is None:\n   return None\n  del b[n:]\n  return bytes(b)\n  \n def readall(self):\n  \"\"\n  res = bytearray()\n  while True:\n   data = self.read(DEFAULT_BUFFER_SIZE)\n   if not data:\n    break\n   res += data\n  if res:\n   return bytes(res)\n  else:\n  \n   return data\n   \n def readinto(self, b):\n  \"\"\n  self._unsupported(\"readinto\")\n  \n def write(self, b):\n  \"\"\n  self._unsupported(\"write\")\n  \n  \n  \n  \n  \n  \n  \nclass BufferedIOBase(IOBase):\n\n \"\"\n \n def read(self, n=None):\n  \"\"\n  self._unsupported(\"read\")\n  \n def read1(self, n=None):\n  \"\"\n  self._unsupported(\"read1\")\n  \n def readinto(self, b):\n  \"\"\n  \n  data = self.read(len(b))\n  n = len(data)\n  try:\n   b[:n] = data\n  except TypeError as err:\n   import array\n   if not isinstance(b, array.array):\n    raise err\n   b[:n] = array.array('b', data)\n  return n\n  \n def write(self, b):\n  \"\"\n  self._unsupported(\"write\")\n  \n def detach(self):\n  \"\"\n  self._unsupported(\"detach\")\n  \n  \n  \n  \n  \nclass _BufferedIOMixin(BufferedIOBase):\n\n \"\"\n \n def __init__(self, raw):\n  self._raw = raw\n  \n  \n  \n def seek(self, pos, whence=0):\n  new_position = self.raw.seek(pos, whence)\n  if new_position < 0:\n   raise IOError(\"seek() returned an invalid position\")\n  return new_position\n  \n def tell(self):\n  pos = self.raw.tell()\n  if pos < 0:\n   raise IOError(\"tell() returned an invalid position\")\n  return pos\n  \n def truncate(self, pos=None):\n \n \n \n  self.flush()\n  \n  if pos is None:\n   pos = self.tell()\n   \n   \n  return self.raw.truncate(pos)\n  \n  \n  \n def flush(self):\n  if self.closed:\n   raise ValueError(\"flush of closed file\")\n  self.raw.flush()\n  \n def close(self):\n  if self.raw is not None and not self.closed:\n   try:\n   \n    self.flush()\n   finally:\n    self.raw.close()\n    \n def detach(self):\n  if self.raw is None:\n   raise ValueError(\"raw stream already detached\")\n  self.flush()\n  raw = self._raw\n  self._raw = None\n  return raw\n  \n  \n  \n def seekable(self):\n  return self.raw.seekable()\n  \n def readable(self):\n  return self.raw.readable()\n  \n def writable(self):\n  return self.raw.writable()\n  \n @property\n def raw(self):\n  return self._raw\n  \n @property\n def closed(self):\n  return self.raw.closed\n  \n @property\n def name(self):\n  return self.raw.name\n  \n @property\n def mode(self):\n  return self.raw.mode\n  \n def __getstate__(self):\n  raise TypeError(\"can not serialize a '{0}' object\"\n  .format(self.__class__.__name__))\n  \n def __repr__(self):\n  clsname = self.__class__.__name__\n  try:\n   name = self.name\n  except AttributeError:\n   return \"<_io.{0}>\".format(clsname)\n  else:\n   return \"<_io.{0} name={1!r}>\".format(clsname, name)\n   \n   \n   \n def fileno(self):\n  return self.raw.fileno()\n  \n def isatty(self):\n  return self.raw.isatty()\n  \n  \nclass BytesIO(BufferedIOBase):\n\n \"\"\n \n def __init__(self, initial_bytes=None):\n  buf = bytearray()\n  if initial_bytes is not None:\n   buf += initial_bytes\n  self._buffer = buf\n  self._pos = 0\n  \n def __getstate__(self):\n  if self.closed:\n   raise ValueError(\"__getstate__ on closed file\")\n  return self.__dict__.copy()\n  \n def getvalue(self):\n  \"\"\n  if self.closed:\n   raise ValueError(\"getvalue on closed file\")\n  return bytes(self._buffer)\n  \n def getbuffer(self):\n  \"\"\n  return memoryview(self._buffer)\n  \n def read(self, n=None):\n  if self.closed:\n   raise ValueError(\"read from closed file\")\n  if n is None:\n   n = -1\n  if n < 0:\n   n = len(self._buffer)\n  if len(self._buffer) <= self._pos:\n   return b\"\"\n  newpos = min(len(self._buffer), self._pos + n)\n  b = self._buffer[self._pos : newpos]\n  self._pos = newpos\n  return bytes(b)\n  \n def read1(self, n):\n  \"\"\n  return self.read(n)\n  \n def write(self, b):\n  if self.closed:\n   raise ValueError(\"write to closed file\")\n  if isinstance(b, str):\n   raise TypeError(\"can't write str to binary stream\")\n  n = len(b)\n  if n == 0:\n   return 0\n  pos = self._pos\n  if pos > len(self._buffer):\n  \n  \n   padding = b'\\x00' * (pos - len(self._buffer))\n   self._buffer += padding\n  self._buffer[pos:pos + n] = b\n  self._pos += n\n  return n\n  \n def seek(self, pos, whence=0):\n  if self.closed:\n   raise ValueError(\"seek on closed file\")\n  try:\n   pos.__index__\n  except AttributeError as err:\n   raise TypeError(\"an integer is required\") from err\n  if whence == 0:\n   if pos < 0:\n    raise ValueError(\"negative seek position %r\" % (pos,))\n   self._pos = pos\n  elif whence == 1:\n   self._pos = max(0, self._pos + pos)\n  elif whence == 2:\n   self._pos = max(0, len(self._buffer) + pos)\n  else:\n   raise ValueError(\"unsupported whence value\")\n  return self._pos\n  \n def tell(self):\n  if self.closed:\n   raise ValueError(\"tell on closed file\")\n  return self._pos\n  \n def truncate(self, pos=None):\n  if self.closed:\n   raise ValueError(\"truncate on closed file\")\n  if pos is None:\n   pos = self._pos\n  else:\n   try:\n    pos.__index__\n   except AttributeError as err:\n    raise TypeError(\"an integer is required\") from err\n   if pos < 0:\n    raise ValueError(\"negative truncate position %r\" % (pos,))\n  del self._buffer[pos:]\n  return pos\n  \n def readable(self):\n  if self.closed:\n   raise ValueError(\"I/O operation on closed file.\")\n  return True\n  \n def writable(self):\n  if self.closed:\n   raise ValueError(\"I/O operation on closed file.\")\n  return True\n  \n def seekable(self):\n  if self.closed:\n   raise ValueError(\"I/O operation on closed file.\")\n  return True\n  \n  \nclass BufferedReader(_BufferedIOMixin):\n\n \"\"\n \n def __init__(self, raw, buffer_size=DEFAULT_BUFFER_SIZE):\n  \"\"\n  if not raw.readable():\n   raise IOError('\"raw\" argument must be readable.')\n   \n  _BufferedIOMixin.__init__(self, raw)\n  if buffer_size <= 0:\n   raise ValueError(\"invalid buffer size\")\n  self.buffer_size = buffer_size\n  self._reset_read_buf()\n  self._read_lock = Lock()\n  \n def _reset_read_buf(self):\n  self._read_buf = b\"\"\n  self._read_pos = 0\n  \n def read(self, n=None):\n  \"\"\n  if n is not None and n < -1:\n   raise ValueError(\"invalid number of bytes to read\")\n  with self._read_lock:\n   return self._read_unlocked(n)\n   \n def _read_unlocked(self, n=None):\n  nodata_val = b\"\"\n  empty_values = (b\"\", None)\n  buf = self._read_buf\n  pos = self._read_pos\n  \n  \n  if n is None or n == -1:\n   self._reset_read_buf()\n   if hasattr(self.raw, 'readall'):\n    chunk = self.raw.readall()\n    if chunk is None:\n     return buf[pos:] or None\n    else:\n     return buf[pos:] + chunk\n   chunks = [buf[pos:]] \n   current_size = 0\n   while True:\n   \n    try:\n     chunk = self.raw.read()\n    except InterruptedError:\n     continue\n    if chunk in empty_values:\n     nodata_val = chunk\n     break\n    current_size += len(chunk)\n    chunks.append(chunk)\n   return b\"\".join(chunks) or nodata_val\n   \n   \n  avail = len(buf) - pos \n  if n <= avail:\n  \n   self._read_pos += n\n   return buf[pos:pos+n]\n   \n   \n  chunks = [buf[pos:]]\n  wanted = max(self.buffer_size, n)\n  while avail < n:\n   try:\n    chunk = self.raw.read(wanted)\n   except InterruptedError:\n    continue\n   if chunk in empty_values:\n    nodata_val = chunk\n    break\n   avail += len(chunk)\n   chunks.append(chunk)\n   \n   \n  n = min(n, avail)\n  out = b\"\".join(chunks)\n  self._read_buf = out[n:] \n  self._read_pos = 0\n  return out[:n] if out else nodata_val\n  \n def peek(self, n=0):\n  \"\"\n  with self._read_lock:\n   return self._peek_unlocked(n)\n   \n def _peek_unlocked(self, n=0):\n  want = min(n, self.buffer_size)\n  have = len(self._read_buf) - self._read_pos\n  if have < want or have <= 0:\n   to_read = self.buffer_size - have\n   while True:\n    try:\n     current = self.raw.read(to_read)\n    except InterruptedError:\n     continue\n    break\n   if current:\n    self._read_buf = self._read_buf[self._read_pos:] + current\n    self._read_pos = 0\n  return self._read_buf[self._read_pos:]\n  \n def read1(self, n):\n  \"\"\n  \n  \n  if n < 0:\n   raise ValueError(\"number of bytes to read must be positive\")\n  if n == 0:\n   return b\"\"\n  with self._read_lock:\n   self._peek_unlocked(1)\n   return self._read_unlocked(\n   min(n, len(self._read_buf) - self._read_pos))\n   \n def tell(self):\n  return _BufferedIOMixin.tell(self) - len(self._read_buf) + self._read_pos\n  \n def seek(self, pos, whence=0):\n  if whence not in valid_seek_flags:\n   raise ValueError(\"invalid whence value\")\n  with self._read_lock:\n   if whence == 1:\n    pos -= len(self._read_buf) - self._read_pos\n   pos = _BufferedIOMixin.seek(self, pos, whence)\n   self._reset_read_buf()\n   return pos\n   \nclass BufferedWriter(_BufferedIOMixin):\n\n \"\"\n \n def __init__(self, raw, buffer_size=DEFAULT_BUFFER_SIZE):\n  if not raw.writable():\n   raise IOError('\"raw\" argument must be writable.')\n   \n  _BufferedIOMixin.__init__(self, raw)\n  if buffer_size <= 0:\n   raise ValueError(\"invalid buffer size\")\n  self.buffer_size = buffer_size\n  self._write_buf = bytearray()\n  self._write_lock = Lock()\n  \n def write(self, b):\n  if self.closed:\n   raise ValueError(\"write to closed file\")\n  if isinstance(b, str):\n   raise TypeError(\"can't write str to binary stream\")\n  with self._write_lock:\n  \n  \n   if len(self._write_buf) > self.buffer_size:\n   \n   \n    self._flush_unlocked()\n   before = len(self._write_buf)\n   self._write_buf.extend(b)\n   written = len(self._write_buf) - before\n   if len(self._write_buf) > self.buffer_size:\n    try:\n     self._flush_unlocked()\n    except BlockingIOError as e:\n     if len(self._write_buf) > self.buffer_size:\n     \n     \n      overage = len(self._write_buf) - self.buffer_size\n      written -= overage\n      self._write_buf = self._write_buf[:self.buffer_size]\n      raise BlockingIOError(e.errno, e.strerror, written)\n   return written\n   \n def truncate(self, pos=None):\n  with self._write_lock:\n   self._flush_unlocked()\n   if pos is None:\n    pos = self.raw.tell()\n   return self.raw.truncate(pos)\n   \n def flush(self):\n  with self._write_lock:\n   self._flush_unlocked()\n   \n def _flush_unlocked(self):\n  if self.closed:\n   raise ValueError(\"flush of closed file\")\n  while self._write_buf:\n   try:\n    n = self.raw.write(self._write_buf)\n   except InterruptedError:\n    continue\n   except BlockingIOError:\n    raise RuntimeError(\"self.raw should implement RawIOBase: it \"\n    \"should not raise BlockingIOError\")\n   if n is None:\n    raise BlockingIOError(\n    errno.EAGAIN,\n    \"write could not complete without blocking\", 0)\n   if n > len(self._write_buf) or n < 0:\n    raise IOError(\"write() returned incorrect number of bytes\")\n   del self._write_buf[:n]\n   \n def tell(self):\n  return _BufferedIOMixin.tell(self) + len(self._write_buf)\n  \n def seek(self, pos, whence=0):\n  if whence not in valid_seek_flags:\n   raise ValueError(\"invalid whence value\")\n  with self._write_lock:\n   self._flush_unlocked()\n   return _BufferedIOMixin.seek(self, pos, whence)\n   \n   \nclass BufferedRWPair(BufferedIOBase):\n\n \"\"\n \n \n \n \n def __init__(self, reader, writer, buffer_size=DEFAULT_BUFFER_SIZE):\n  \"\"\n  if not reader.readable():\n   raise IOError('\"reader\" argument must be readable.')\n   \n  if not writer.writable():\n   raise IOError('\"writer\" argument must be writable.')\n   \n  self.reader = BufferedReader(reader, buffer_size)\n  self.writer = BufferedWriter(writer, buffer_size)\n  \n def read(self, n=None):\n  if n is None:\n   n = -1\n  return self.reader.read(n)\n  \n def readinto(self, b):\n  return self.reader.readinto(b)\n  \n def write(self, b):\n  return self.writer.write(b)\n  \n def peek(self, n=0):\n  return self.reader.peek(n)\n  \n def read1(self, n):\n  return self.reader.read1(n)\n  \n def readable(self):\n  return self.reader.readable()\n  \n def writable(self):\n  return self.writer.writable()\n  \n def flush(self):\n  return self.writer.flush()\n  \n def close(self):\n  self.writer.close()\n  self.reader.close()\n  \n def isatty(self):\n  return self.reader.isatty() or self.writer.isatty()\n  \n @property\n def closed(self):\n  return self.writer.closed\n  \n  \nclass BufferedRandom(BufferedWriter, BufferedReader):\n\n \"\"\n \n def __init__(self, raw, buffer_size=DEFAULT_BUFFER_SIZE):\n  raw._checkSeekable()\n  BufferedReader.__init__(self, raw, buffer_size)\n  BufferedWriter.__init__(self, raw, buffer_size)\n  \n def seek(self, pos, whence=0):\n  if whence not in valid_seek_flags:\n   raise ValueError(\"invalid whence value\")\n  self.flush()\n  if self._read_buf:\n  \n   with self._read_lock:\n    self.raw.seek(self._read_pos - len(self._read_buf), 1)\n    \n    \n  pos = self.raw.seek(pos, whence)\n  with self._read_lock:\n   self._reset_read_buf()\n  if pos < 0:\n   raise IOError(\"seek() returned invalid position\")\n  return pos\n  \n def tell(self):\n  if self._write_buf:\n   return BufferedWriter.tell(self)\n  else:\n   return BufferedReader.tell(self)\n   \n def truncate(self, pos=None):\n  if pos is None:\n   pos = self.tell()\n   \n  return BufferedWriter.truncate(self, pos)\n  \n def read(self, n=None):\n  if n is None:\n   n = -1\n  self.flush()\n  return BufferedReader.read(self, n)\n  \n def readinto(self, b):\n  self.flush()\n  return BufferedReader.readinto(self, b)\n  \n def peek(self, n=0):\n  self.flush()\n  return BufferedReader.peek(self, n)\n  \n def read1(self, n):\n  self.flush()\n  return BufferedReader.read1(self, n)\n  \n def write(self, b):\n  if self._read_buf:\n  \n   with self._read_lock:\n    self.raw.seek(self._read_pos - len(self._read_buf), 1)\n    self._reset_read_buf()\n  return BufferedWriter.write(self, b)\n  \n  \nclass TextIOBase(IOBase):\n\n \"\"\n \n def read(self, n=-1):\n  \"\"\n  self._unsupported(\"read\")\n  \n def write(self, s):\n  \"\"\n  self._unsupported(\"write\")\n  \n def truncate(self, pos=None):\n  \"\"\n  self._unsupported(\"truncate\")\n  \n def readline(self):\n  \"\"\n  self._unsupported(\"readline\")\n  \n def detach(self):\n  \"\"\n  self._unsupported(\"detach\")\n  \n @property\n def encoding(self):\n  \"\"\n  return None\n  \n @property\n def newlines(self):\n  \"\"\n  return None\n  \n @property\n def errors(self):\n  \"\"\n  return None\n  \n  \n  \n  \n  \nclass IncrementalNewlineDecoder(codecs.IncrementalDecoder):\n \"\"\n def __init__(self, decoder, translate, errors='strict'):\n  codecs.IncrementalDecoder.__init__(self, errors=errors)\n  self.translate = translate\n  self.decoder = decoder\n  self.seennl = 0\n  self.pendingcr = False\n  \n def decode(self, input, final=False):\n \n  if self.decoder is None:\n   output = input\n  else:\n   output = self.decoder.decode(input, final=final)\n  if self.pendingcr and (output or final):\n   output = \"\\r\" + output\n   self.pendingcr = False\n   \n   \n   \n  if output.endswith(\"\\r\") and not final:\n   output = output[:-1]\n   self.pendingcr = True\n   \n   \n  crlf = output.count('\\r\\n')\n  cr = output.count('\\r') - crlf\n  lf = output.count('\\n') - crlf\n  self.seennl |= (lf and self._LF) | (cr and self._CR) | (crlf and self._CRLF)\n  \n  if self.translate:\n   if crlf:\n    output = output.replace(\"\\r\\n\", \"\\n\")\n   if cr:\n    output = output.replace(\"\\r\", \"\\n\")\n    \n  return output\n  \n def getstate(self):\n  if self.decoder is None:\n   buf = b\"\"\n   flag = 0\n  else:\n   buf, flag = self.decoder.getstate()\n  flag <<= 1\n  if self.pendingcr:\n   flag |= 1\n  return buf, flag\n  \n def setstate(self, state):\n  buf, flag = state\n  self.pendingcr = bool(flag & 1)\n  if self.decoder is not None:\n   self.decoder.setstate((buf, flag >> 1))\n   \n def reset(self):\n  self.seennl = 0\n  self.pendingcr = False\n  if self.decoder is not None:\n   self.decoder.reset()\n   \n _LF = 1\n _CR = 2\n _CRLF = 4\n \n @property\n def newlines(self):\n  return (None,\n  \"\\n\",\n  \"\\r\",\n  (\"\\r\", \"\\n\"),\n  \"\\r\\n\",\n  (\"\\n\", \"\\r\\n\"),\n  (\"\\r\", \"\\r\\n\"),\n  (\"\\r\", \"\\n\", \"\\r\\n\")\n  )[self.seennl]\n  \n  \nclass TextIOWrapper(TextIOBase):\n\n \"\"\n \n _CHUNK_SIZE = 2048\n \n \n \n \n def __init__(self, buffer, encoding=None, errors=None, newline=None,\n line_buffering=False, write_through=False):\n  if newline is not None and not isinstance(newline, str):\n   raise TypeError(\"illegal newline type: %r\" % (type(newline),))\n  if newline not in (None, \"\", \"\\n\", \"\\r\", \"\\r\\n\"):\n   raise ValueError(\"illegal newline value: %r\" % (newline,))\n  if encoding is None:\n   try:\n    encoding = os.device_encoding(buffer.fileno())\n   except (AttributeError, UnsupportedOperation):\n    pass\n   if encoding is None:\n    try:\n     import locale\n    except ImportError:\n    \n     encoding = \"ascii\"\n    else:\n     encoding = locale.getpreferredencoding(False)\n     \n  if not isinstance(encoding, str):\n   raise ValueError(\"invalid encoding: %r\" % encoding)\n   \n  if errors is None:\n   errors = \"strict\"\n  else:\n   if not isinstance(errors, str):\n    raise ValueError(\"invalid errors: %r\" % errors)\n    \n  self._buffer = buffer\n  self._line_buffering = line_buffering\n  self._encoding = encoding\n  self._errors = errors\n  self._readuniversal = not newline\n  self._readtranslate = newline is None\n  self._readnl = newline\n  self._writetranslate = newline != ''\n  self._writenl = newline or os.linesep\n  self._encoder = None\n  self._decoder = None\n  self._decoded_chars = '' \n  self._decoded_chars_used = 0 \n  self._snapshot = None \n  self._seekable = self._telling = self.buffer.seekable()\n  self._has_read1 = hasattr(self.buffer, 'read1')\n  self._b2cratio = 0.0\n  \n  if self._seekable and self.writable():\n   position = self.buffer.tell()\n   if position != 0:\n    try:\n     self._get_encoder().setstate(0)\n    except LookupError:\n    \n     pass\n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n def __repr__(self):\n  result = \"<_io.TextIOWrapper\"\n  try:\n   name = self.name\n  except AttributeError:\n   pass\n  else:\n   result += \" name={0!r}\".format(name)\n  try:\n   mode = self.mode\n  except AttributeError:\n   pass\n  else:\n   result += \" mode={0!r}\".format(mode)\n  return result + \" encoding={0!r}>\".format(self.encoding)\n  \n @property\n def encoding(self):\n  return self._encoding\n  \n @property\n def errors(self):\n  return self._errors\n  \n @property\n def line_buffering(self):\n  return self._line_buffering\n  \n @property\n def buffer(self):\n  return self._buffer\n  \n def seekable(self):\n  if self.closed:\n   raise ValueError(\"I/O operation on closed file.\")\n  return self._seekable\n  \n def readable(self):\n  return self.buffer.readable()\n  \n def writable(self):\n  return self.buffer.writable()\n  \n def flush(self):\n  self.buffer.flush()\n  self._telling = self._seekable\n  \n def close(self):\n  if self.buffer is not None and not self.closed:\n   try:\n    self.flush()\n   finally:\n    self.buffer.close()\n    \n @property\n def closed(self):\n  return self.buffer.closed\n  \n @property\n def name(self):\n  return self.buffer.name\n  \n def fileno(self):\n  return self.buffer.fileno()\n  \n def isatty(self):\n  return self.buffer.isatty()\n  \n def write(self, s):\n  \"\"\n  if self.closed:\n   raise ValueError(\"write to closed file\")\n  if not isinstance(s, str):\n   raise TypeError(\"can't write %s to text stream\" %\n   s.__class__.__name__)\n  length = len(s)\n  haslf = (self._writetranslate or self._line_buffering) and \"\\n\" in s\n  if haslf and self._writetranslate and self._writenl != \"\\n\":\n   s = s.replace(\"\\n\", self._writenl)\n  encoder = self._encoder or self._get_encoder()\n  \n  b = encoder.encode(s)\n  self.buffer.write(b)\n  if self._line_buffering and (haslf or \"\\r\" in s):\n   self.flush()\n  self._snapshot = None\n  if self._decoder:\n   self._decoder.reset()\n  return length\n  \n def _get_encoder(self):\n  make_encoder = codecs.getincrementalencoder(self._encoding)\n  self._encoder = make_encoder(self._errors)\n  return self._encoder\n  \n def _get_decoder(self):\n  make_decoder = codecs.getincrementaldecoder(self._encoding)\n  decoder = make_decoder(self._errors)\n  if self._readuniversal:\n   decoder = IncrementalNewlineDecoder(decoder, self._readtranslate)\n  self._decoder = decoder\n  return decoder\n  \n  \n  \n  \n def _set_decoded_chars(self, chars):\n  \"\"\n  self._decoded_chars = chars\n  self._decoded_chars_used = 0\n  \n def _get_decoded_chars(self, n=None):\n  \"\"\n  offset = self._decoded_chars_used\n  if n is None:\n   chars = self._decoded_chars[offset:]\n  else:\n   chars = self._decoded_chars[offset:offset + n]\n  self._decoded_chars_used += len(chars)\n  return chars\n  \n def _rewind_decoded_chars(self, n):\n  \"\"\n  if self._decoded_chars_used < n:\n   raise AssertionError(\"rewind decoded_chars out of bounds\")\n  self._decoded_chars_used -= n\n  \n def _read_chunk(self):\n  \"\"\n  \n  \n  \n  \n  \n  \n  \n  if self._decoder is None:\n   raise ValueError(\"no decoder\")\n   \n  if self._telling:\n  \n  \n  \n   dec_buffer, dec_flags = self._decoder.getstate()\n   \n   \n   \n   \n  if self._has_read1:\n   input_chunk = self.buffer.read1(self._CHUNK_SIZE)\n  else:\n   input_chunk = self.buffer.read(self._CHUNK_SIZE)\n  eof = not input_chunk\n  decoded_chars = self._decoder.decode(input_chunk, eof)\n  self._set_decoded_chars(decoded_chars)\n  if decoded_chars:\n   self._b2cratio = len(input_chunk) / len(self._decoded_chars)\n  else:\n   self._b2cratio = 0.0\n   \n  if self._telling:\n  \n  \n   self._snapshot = (dec_flags, dec_buffer + input_chunk)\n   \n  return not eof\n  \n def _pack_cookie(self, position, dec_flags=0,\n bytes_to_feed=0, need_eof=0, chars_to_skip=0):\n \n \n \n \n \n  return (position | (dec_flags<<64) | (bytes_to_feed<<128) |\n  (chars_to_skip<<192) | bool(need_eof)<<256)\n  \n def _unpack_cookie(self, bigint):\n  rest, position = divmod(bigint, 1<<64)\n  rest, dec_flags = divmod(rest, 1<<64)\n  rest, bytes_to_feed = divmod(rest, 1<<64)\n  need_eof, chars_to_skip = divmod(rest, 1<<64)\n  return position, dec_flags, bytes_to_feed, need_eof, chars_to_skip\n  \n def tell(self):\n  if not self._seekable:\n   raise UnsupportedOperation(\"underlying stream is not seekable\")\n  if not self._telling:\n   raise IOError(\"telling position disabled by next() call\")\n  self.flush()\n  position = self.buffer.tell()\n  decoder = self._decoder\n  if decoder is None or self._snapshot is None:\n   if self._decoded_chars:\n   \n    raise AssertionError(\"pending decoded text\")\n   return position\n   \n   \n  dec_flags, next_input = self._snapshot\n  position -= len(next_input)\n  \n  \n  chars_to_skip = self._decoded_chars_used\n  if chars_to_skip == 0:\n  \n   return self._pack_cookie(position, dec_flags)\n   \n   \n   \n  saved_state = decoder.getstate()\n  try:\n  \n  \n  \n  \n  \n  \n  \n   skip_bytes = int(self._b2cratio * chars_to_skip)\n   skip_back = 1\n   assert skip_bytes <= len(next_input)\n   while skip_bytes > 0:\n    decoder.setstate((b'', dec_flags))\n    \n    n = len(decoder.decode(next_input[:skip_bytes]))\n    if n <= chars_to_skip:\n     b, d = decoder.getstate()\n     if not b:\n     \n      dec_flags = d\n      chars_to_skip -= n\n      break\n      \n     skip_bytes -= len(b)\n     skip_back = 1\n    else:\n    \n     skip_bytes -= skip_back\n     skip_back = skip_back * 2\n   else:\n    skip_bytes = 0\n    decoder.setstate((b'', dec_flags))\n    \n    \n   start_pos = position + skip_bytes\n   start_flags = dec_flags\n   if chars_to_skip == 0:\n   \n    return self._pack_cookie(start_pos, start_flags)\n    \n    \n    \n    \n    \n   bytes_fed = 0\n   need_eof = 0\n   \n   chars_decoded = 0\n   for i in range(skip_bytes, len(next_input)):\n    bytes_fed += 1\n    chars_decoded += len(decoder.decode(next_input[i:i+1]))\n    dec_buffer, dec_flags = decoder.getstate()\n    if not dec_buffer and chars_decoded <= chars_to_skip:\n    \n     start_pos += bytes_fed\n     chars_to_skip -= chars_decoded\n     start_flags, bytes_fed, chars_decoded = dec_flags, 0, 0\n    if chars_decoded >= chars_to_skip:\n     break\n   else:\n   \n    chars_decoded += len(decoder.decode(b'', final=True))\n    need_eof = 1\n    if chars_decoded < chars_to_skip:\n     raise IOError(\"can't reconstruct logical file position\")\n     \n     \n   return self._pack_cookie(\n   start_pos, start_flags, bytes_fed, need_eof, chars_to_skip)\n  finally:\n   decoder.setstate(saved_state)\n   \n def truncate(self, pos=None):\n  self.flush()\n  if pos is None:\n   pos = self.tell()\n  return self.buffer.truncate(pos)\n  \n def detach(self):\n  if self.buffer is None:\n   raise ValueError(\"buffer is already detached\")\n  self.flush()\n  buffer = self._buffer\n  self._buffer = None\n  return buffer\n  \n def seek(self, cookie, whence=0):\n  if self.closed:\n   raise ValueError(\"tell on closed file\")\n  if not self._seekable:\n   raise UnsupportedOperation(\"underlying stream is not seekable\")\n  if whence == 1: \n   if cookie != 0:\n    raise UnsupportedOperation(\"can't do nonzero cur-relative seeks\")\n    \n    \n   whence = 0\n   cookie = self.tell()\n  if whence == 2: \n   if cookie != 0:\n    raise UnsupportedOperation(\"can't do nonzero end-relative seeks\")\n   self.flush()\n   position = self.buffer.seek(0, 2)\n   self._set_decoded_chars('')\n   self._snapshot = None\n   if self._decoder:\n    self._decoder.reset()\n   return position\n  if whence != 0:\n   raise ValueError(\"unsupported whence (%r)\" % (whence,))\n  if cookie < 0:\n   raise ValueError(\"negative seek position %r\" % (cookie,))\n  self.flush()\n  \n  \n  \n  start_pos, dec_flags, bytes_to_feed, need_eof, chars_to_skip = self._unpack_cookie(cookie)\n  \n  \n  self.buffer.seek(start_pos)\n  self._set_decoded_chars('')\n  self._snapshot = None\n  \n  \n  if cookie == 0 and self._decoder:\n   self._decoder.reset()\n  elif self._decoder or dec_flags or chars_to_skip:\n   self._decoder = self._decoder or self._get_decoder()\n   self._decoder.setstate((b'', dec_flags))\n   self._snapshot = (dec_flags, b'')\n   \n  if chars_to_skip:\n  \n   input_chunk = self.buffer.read(bytes_to_feed)\n   self._set_decoded_chars(\n   self._decoder.decode(input_chunk, need_eof))\n   self._snapshot = (dec_flags, input_chunk)\n   \n   \n   if len(self._decoded_chars) < chars_to_skip:\n    raise IOError(\"can't restore logical file position\")\n   self._decoded_chars_used = chars_to_skip\n   \n   \n  try:\n   encoder = self._encoder or self._get_encoder()\n  except LookupError:\n  \n   pass\n  else:\n   if cookie != 0:\n    encoder.setstate(0)\n   else:\n    encoder.reset()\n  return cookie\n  \n def read(self, n=None):\n  self._checkReadable()\n  if n is None:\n   n = -1\n  decoder = self._decoder or self._get_decoder()\n  try:\n   n.__index__\n  except AttributeError as err:\n   raise TypeError(\"an integer is required\") from err\n  if n < 0:\n  \n   result = (self._get_decoded_chars() +\n   decoder.decode(self.buffer.read(), final=True))\n   self._set_decoded_chars('')\n   self._snapshot = None\n   return result\n  else:\n  \n   eof = False\n   result = self._get_decoded_chars(n)\n   while len(result) < n and not eof:\n    eof = not self._read_chunk()\n    result += self._get_decoded_chars(n - len(result))\n   return result\n   \n def __next__(self):\n  self._telling = False\n  line = self.readline()\n  if not line:\n   self._snapshot = None\n   self._telling = self._seekable\n   raise StopIteration\n  return line\n  \n def readline(self, limit=None):\n  if self.closed:\n   raise ValueError(\"read from closed file\")\n  if limit is None:\n   limit = -1\n  elif not isinstance(limit, int):\n   raise TypeError(\"limit must be an integer\")\n   \n   \n  line = self._get_decoded_chars()\n  \n  start = 0\n  \n  if not self._decoder:\n   self._get_decoder()\n   \n  pos = endpos = None\n  while True:\n   if self._readtranslate:\n   \n    pos = line.find('\\n', start)\n    if pos >= 0:\n     endpos = pos + 1\n     break\n    else:\n     start = len(line)\n     \n   elif self._readuniversal:\n   \n   \n   \n   \n    nlpos = line.find(\"\\n\", start)\n    crpos = line.find(\"\\r\", start)\n    if crpos == -1:\n     if nlpos == -1:\n     \n      start = len(line)\n     else:\n     \n      endpos = nlpos + 1\n      break\n    elif nlpos == -1:\n    \n     endpos = crpos + 1\n     break\n    elif nlpos < crpos:\n    \n     endpos = nlpos + 1\n     break\n    elif nlpos == crpos + 1:\n    \n     endpos = crpos + 2\n     break\n    else:\n    \n     endpos = crpos + 1\n     break\n   else:\n   \n    pos = line.find(self._readnl)\n    if pos >= 0:\n     endpos = pos + len(self._readnl)\n     break\n     \n   if limit >= 0 and len(line) >= limit:\n    endpos = limit \n    break\n    \n    \n   while self._read_chunk():\n    if self._decoded_chars:\n     break\n   if self._decoded_chars:\n    line += self._get_decoded_chars()\n   else:\n   \n    self._set_decoded_chars('')\n    self._snapshot = None\n    return line\n    \n  if limit >= 0 and endpos > limit:\n   endpos = limit \n   \n   \n  self._rewind_decoded_chars(len(line) - endpos)\n  return line[:endpos]\n  \n @property\n def newlines(self):\n  return self._decoder.newlines if self._decoder else None\n  \n  \nclass StringIO(TextIOWrapper):\n \"\"\n \n def __init__(self, initial_value=\"\", newline=\"\\n\"):\n  super(StringIO, self).__init__(BytesIO(),\n  encoding=\"utf-8\",\n  errors=\"strict\",\n  newline=newline)\n  \n  \n  if newline is None:\n   self._writetranslate = False\n  if initial_value is not None:\n   if not isinstance(initial_value, str):\n    raise TypeError(\"initial_value must be str or None, not {0}\"\n    .format(type(initial_value).__name__))\n    initial_value = str(initial_value)\n   self.write(initial_value)\n   self.seek(0)\n   \n def getvalue(self):\n  self.flush()\n  return self.buffer.getvalue().decode(self._encoding, self._errors)\n  \n def __repr__(self):\n \n \n  return object.__repr__(self)\n  \n @property\n def errors(self):\n  return None\n  \n @property\n def encoding(self):\n  return None\n  \n def detach(self):\n \n  self._unsupported(\"detach\")\n"], "linecache": [".py", "\"\"\n\nimport sys\nimport os\nimport tokenize\n\n__all__ = [\"getline\", \"clearcache\", \"checkcache\"]\n\ndef getline(filename, lineno, module_globals=None):\n lines = getlines(filename, module_globals)\n if 1 <= lineno <= len(lines):\n  return lines[lineno-1]\n else:\n  return ''\n  \n  \n  \n  \ncache = {} \n\n\ndef clearcache():\n \"\"\n \n global cache\n cache = {}\n \n \ndef getlines(filename, module_globals=None):\n \"\"\n \n if filename in cache:\n  return cache[filename][2]\n else:\n  return updatecache(filename, module_globals)\n  \n  \ndef checkcache(filename=None):\n \"\"\n \n if filename is None:\n  filenames = list(cache.keys())\n else:\n  if filename in cache:\n   filenames = [filename]\n  else:\n   return\n   \n for filename in filenames:\n  size, mtime, lines, fullname = cache[filename]\n  if mtime is None:\n   continue \n  try:\n   stat = os.stat(fullname)\n  except os.error:\n   del cache[filename]\n   continue\n  if size != stat.st_size or mtime != stat.st_mtime:\n   del cache[filename]\n   \n   \ndef updatecache(filename, module_globals=None):\n \"\"\n \n if filename in cache:\n  del cache[filename]\n if not filename or (filename.startswith('<') and filename.endswith('>')):\n  return []\n  \n fullname = filename\n try:\n  stat = os.stat(fullname)\n except OSError:\n  basename = filename\n  \n  \n  if module_globals and '__loader__' in module_globals:\n   name = module_globals.get('__name__')\n   loader = module_globals['__loader__']\n   get_source = getattr(loader, 'get_source', None)\n   \n   if name and get_source:\n    try:\n     data = get_source(name)\n    except (ImportError, IOError):\n     pass\n    else:\n     if data is None:\n     \n     \n      return []\n     cache[filename] = (\n     len(data), None,\n     [line+'\\n' for line in data.splitlines()], fullname\n     )\n     return cache[filename][2]\n     \n     \n     \n  if os.path.isabs(filename):\n   return []\n   \n  for dirname in sys.path:\n   try:\n    fullname = os.path.join(dirname, basename)\n   except (TypeError, AttributeError):\n   \n    continue\n   try:\n    stat = os.stat(fullname)\n    break\n   except os.error:\n    pass\n  else:\n   return []\n try:\n  with tokenize.open(fullname) as fp:\n   lines = fp.readlines()\n except IOError:\n  return []\n if lines and not lines[-1].endswith('\\n'):\n  lines[-1] += '\\n'\n size, mtime = stat.st_size, stat.st_mtime\n cache[filename] = size, mtime, lines, fullname\n return lines\n"], "_strptime": [".py", "\"\"\nimport time\nimport locale\nimport calendar\nfrom pyre import compile as re_compile\nfrom pyre import IGNORECASE\nfrom pyre import escape as re_escape\nfrom datetime import (date as datetime_date,\ntimedelta as datetime_timedelta,\ntimezone as datetime_timezone)\ntry:\n from _thread import allocate_lock as _thread_allocate_lock\nexcept ImportError:\n from _dummy_thread import allocate_lock as _thread_allocate_lock\n \n__all__ = []\n\ndef _getlang():\n\n return locale.getlocale(locale.LC_TIME)\n \nclass LocaleTime(object):\n \"\"\n \n def __init__(self):\n  \"\"\n  self.lang = _getlang()\n  self.__calc_weekday()\n  self.__calc_month()\n  self.__calc_am_pm()\n  self.__calc_timezone()\n  self.__calc_date_time()\n  if _getlang() != self.lang:\n   raise ValueError(\"locale changed during initialization\")\n   \n def __pad(self, seq, front):\n \n  seq = list(seq)\n  if front:\n   seq.insert(0, '')\n  else:\n   seq.append('')\n  return seq\n  \n def __calc_weekday(self):\n \n \n  a_weekday = [calendar.day_abbr[i].lower() for i in range(7)]\n  f_weekday = [calendar.day_name[i].lower() for i in range(7)]\n  self.a_weekday = a_weekday\n  self.f_weekday = f_weekday\n  \n def __calc_month(self):\n \n  a_month = [calendar.month_abbr[i].lower() for i in range(13)]\n  f_month = [calendar.month_name[i].lower() for i in range(13)]\n  self.a_month = a_month\n  self.f_month = f_month\n  \n def __calc_am_pm(self):\n \n \n \n \n \n  am_pm = []\n  for hour in (1, 22):\n   time_tuple = time.struct_time((1999,3,17,hour,44,55,2,76,0))\n   am_pm.append(time.strftime(\"%p\", time_tuple).lower())\n  self.am_pm = am_pm\n  \n def __calc_date_time(self):\n \n \n \n \n \n \n \n  time_tuple = time.struct_time((1999,3,17,22,44,55,2,76,0))\n  date_time = [None, None, None]\n  date_time[0] = time.strftime(\"%c\", time_tuple).lower()\n  date_time[1] = time.strftime(\"%x\", time_tuple).lower()\n  date_time[2] = time.strftime(\"%X\", time_tuple).lower()\n  replacement_pairs = [('%', '%%'), (self.f_weekday[2], '%A'),\n  (self.f_month[3], '%B'), (self.a_weekday[2], '%a'),\n  (self.a_month[3], '%b'), (self.am_pm[1], '%p'),\n  ('1999', '%Y'), ('99', '%y'), ('22', '%H'),\n  ('44', '%M'), ('55', '%S'), ('76', '%j'),\n  ('17', '%d'), ('03', '%m'), ('3', '%m'),\n  \n  ('2', '%w'), ('10', '%I')]\n  replacement_pairs.extend([(tz, \"%Z\") for tz_values in self.timezone\n  for tz in tz_values])\n  for offset,directive in ((0,'%c'), (1,'%x'), (2,'%X')):\n   current_format = date_time[offset]\n   for old, new in replacement_pairs:\n   \n   \n   \n   \n    if old:\n     current_format = current_format.replace(old, new)\n     \n     \n     \n   time_tuple = time.struct_time((1999,1,3,1,1,1,6,3,0))\n   if '00' in time.strftime(directive, time_tuple):\n    U_W = '%W'\n   else:\n    U_W = '%U'\n   date_time[offset] = current_format.replace('11', U_W)\n  self.LC_date_time = date_time[0]\n  self.LC_date = date_time[1]\n  self.LC_time = date_time[2]\n  \n def __calc_timezone(self):\n \n \n \n  try:\n   time.tzset()\n  except AttributeError:\n   pass\n  no_saving = frozenset([\"utc\", \"gmt\", time.tzname[0].lower()])\n  if time.daylight:\n   has_saving = frozenset([time.tzname[1].lower()])\n  else:\n   has_saving = frozenset()\n  self.timezone = (no_saving, has_saving)\n  \n  \nclass TimeRE(dict):\n \"\"\n \n def __init__(self, locale_time=None):\n  \"\"\n  if locale_time:\n   self.locale_time = locale_time\n  else:\n   self.locale_time = LocaleTime()\n  base = super()\n  base.__init__({\n  \n  'd': r\"(?P<d>3[0-1]|[1-2]\\d|0[1-9]|[1-9]| [1-9])\",\n  'f': r\"(?P<f>[0-9]{1,6})\",\n  'H': r\"(?P<H>2[0-3]|[0-1]\\d|\\d)\",\n  'I': r\"(?P<I>1[0-2]|0[1-9]|[1-9])\",\n  'j': r\"(?P<j>36[0-6]|3[0-5]\\d|[1-2]\\d\\d|0[1-9]\\d|00[1-9]|[1-9]\\d|0[1-9]|[1-9])\",\n  'm': r\"(?P<m>1[0-2]|0[1-9]|[1-9])\",\n  'M': r\"(?P<M>[0-5]\\d|\\d)\",\n  'S': r\"(?P<S>6[0-1]|[0-5]\\d|\\d)\",\n  'U': r\"(?P<U>5[0-3]|[0-4]\\d|\\d)\",\n  'w': r\"(?P<w>[0-6])\",\n  \n  'y': r\"(?P<y>\\d\\d)\",\n  \n  \n  'Y': r\"(?P<Y>\\d\\d\\d\\d)\",\n  'z': r\"(?P<z>[+-]\\d\\d[0-5]\\d)\",\n  'A': self.__seqToRE(self.locale_time.f_weekday, 'A'),\n  'a': self.__seqToRE(self.locale_time.a_weekday, 'a'),\n  'B': self.__seqToRE(self.locale_time.f_month[1:], 'B'),\n  'b': self.__seqToRE(self.locale_time.a_month[1:], 'b'),\n  'p': self.__seqToRE(self.locale_time.am_pm, 'p'),\n  'Z': self.__seqToRE((tz for tz_names in self.locale_time.timezone\n  for tz in tz_names),\n  'Z'),\n  '%': '%'})\n  base.__setitem__('W', base.__getitem__('U').replace('U', 'W'))\n  base.__setitem__('c', self.pattern(self.locale_time.LC_date_time))\n  base.__setitem__('x', self.pattern(self.locale_time.LC_date))\n  base.__setitem__('X', self.pattern(self.locale_time.LC_time))\n  \n def __seqToRE(self, to_convert, directive):\n  \"\"\n  to_convert = sorted(to_convert, key=len, reverse=True)\n  for value in to_convert:\n   if value != '':\n    break\n  else:\n   return ''\n  regex = '|'.join(re_escape(stuff) for stuff in to_convert)\n  regex = '(?P<%s>%s' % (directive, regex)\n  return '%s)' % regex\n  \n def pattern(self, format):\n  \"\"\n  processed_format = ''\n  \n  \n  \n  regex_chars = re_compile(r\"([\\\\.^$*+?\\(\\){}\\[\\]|])\")\n  format = regex_chars.sub(r\"\\\\\\1\", format)\n  whitespace_replacement = re_compile('\\s+')\n  format = whitespace_replacement.sub('\\s+', format)\n  while '%' in format:\n   directive_index = format.index('%')+1\n   processed_format = \"%s%s%s\" % (processed_format,\n   format[:directive_index-1],\n   self[format[directive_index]])\n   format = format[directive_index+1:]\n  return \"%s%s\" % (processed_format, format)\n  \n def compile(self, format):\n  \"\"\n  return re_compile(self.pattern(format), IGNORECASE)\n  \n_cache_lock = _thread_allocate_lock()\n\n\n_TimeRE_cache = TimeRE()\n_CACHE_MAX_SIZE = 5 \n_regex_cache = {}\n\ndef _calc_julian_from_U_or_W(year, week_of_year, day_of_week, week_starts_Mon):\n \"\"\n first_weekday = datetime_date(year, 1, 1).weekday()\n \n \n \n if not week_starts_Mon:\n  first_weekday = (first_weekday + 1) % 7\n  day_of_week = (day_of_week + 1) % 7\n  \n  \n week_0_length = (7 - first_weekday) % 7\n if week_of_year == 0:\n  return 1 + day_of_week - first_weekday\n else:\n  days_to_week = week_0_length + (7 * (week_of_year - 1))\n  return 1 + days_to_week + day_of_week\n  \n  \ndef _strptime(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n \"\"\n \n for index, arg in enumerate([data_string, format]):\n  if not isinstance(arg, str):\n   msg = \"strptime() argument {} must be str, not {}\"\n   raise TypeError(msg.format(index, type(arg)))\n   \n global _TimeRE_cache, _regex_cache\n with _cache_lock:\n \n  if _getlang() != _TimeRE_cache.locale_time.lang:\n   _TimeRE_cache = TimeRE()\n   _regex_cache.clear()\n  if len(_regex_cache) > _CACHE_MAX_SIZE:\n   _regex_cache.clear()\n  locale_time = _TimeRE_cache.locale_time\n  format_regex = _regex_cache.get(format)\n  if not format_regex:\n   try:\n    format_regex = _TimeRE_cache.compile(format)\n    \n    \n   except KeyError as err:\n    bad_directive = err.args[0]\n    if bad_directive == \"\\\\\":\n     bad_directive = \"%\"\n    del err\n    raise ValueError(\"'%s' is a bad directive in format '%s'\" %\n    (bad_directive, format)) from None\n    \n   except IndexError:\n    raise ValueError(\"stray %% in format '%s'\" % format) from None\n   _regex_cache[format] = format_regex\n found = format_regex.match(data_string)\n if not found:\n  raise ValueError(\"time data %r does not match format %r\" %\n  (data_string, format))\n if len(data_string) != found.end():\n  raise ValueError(\"unconverted data remains: %s\" %\n  data_string[found.end():])\n  \n year = None\n month = day = 1\n hour = minute = second = fraction = 0\n tz = -1\n tzoffset = None\n \n \n week_of_year = -1\n week_of_year_start = -1\n \n \n weekday = julian = -1\n found_dict = found.groupdict()\n for group_key in found_dict.keys():\n \n \n \n \n \n  if group_key == 'y':\n   year = int(found_dict['y'])\n   \n   \n   \n   if year <= 68:\n    year += 2000\n   else:\n    year += 1900\n  elif group_key == 'Y':\n   year = int(found_dict['Y'])\n  elif group_key == 'm':\n   month = int(found_dict['m'])\n  elif group_key == 'B':\n   month = locale_time.f_month.index(found_dict['B'].lower())\n  elif group_key == 'b':\n   month = locale_time.a_month.index(found_dict['b'].lower())\n  elif group_key == 'd':\n   day = int(found_dict['d'])\n  elif group_key == 'H':\n   hour = int(found_dict['H'])\n  elif group_key == 'I':\n   hour = int(found_dict['I'])\n   ampm = found_dict.get('p', '').lower()\n   \n   if ampm in ('', locale_time.am_pm[0]):\n   \n   \n   \n    if hour == 12:\n     hour = 0\n   elif ampm == locale_time.am_pm[1]:\n   \n   \n   \n    if hour != 12:\n     hour += 12\n  elif group_key == 'M':\n   minute = int(found_dict['M'])\n  elif group_key == 'S':\n   second = int(found_dict['S'])\n  elif group_key == 'f':\n   s = found_dict['f']\n   \n   s += \"0\" * (6 - len(s))\n   fraction = int(s)\n  elif group_key == 'A':\n   weekday = locale_time.f_weekday.index(found_dict['A'].lower())\n  elif group_key == 'a':\n   weekday = locale_time.a_weekday.index(found_dict['a'].lower())\n  elif group_key == 'w':\n   weekday = int(found_dict['w'])\n   if weekday == 0:\n    weekday = 6\n   else:\n    weekday -= 1\n  elif group_key == 'j':\n   julian = int(found_dict['j'])\n  elif group_key in ('U', 'W'):\n   week_of_year = int(found_dict[group_key])\n   if group_key == 'U':\n   \n    week_of_year_start = 6\n   else:\n   \n    week_of_year_start = 0\n  elif group_key == 'z':\n   z = found_dict['z']\n   tzoffset = int(z[1:3]) * 60 + int(z[3:5])\n   if z.startswith(\"-\"):\n    tzoffset = -tzoffset\n  elif group_key == 'Z':\n  \n  \n   found_zone = found_dict['Z'].lower()\n   for value, tz_values in enumerate(locale_time.timezone):\n    if found_zone in tz_values:\n    \n    \n    \n     if (time.tzname[0] == time.tzname[1] and\n     time.daylight and found_zone not in (\"utc\", \"gmt\")):\n      break\n     else:\n      tz = value\n      break\n leap_year_fix = False\n if year is None and month == 2 and day == 29:\n  year = 1904 \n  leap_year_fix = True\n elif year is None:\n  year = 1900\n  \n  \n if julian == -1 and week_of_year != -1 and weekday != -1:\n  week_starts_Mon = True if week_of_year_start == 0 else False\n  julian = _calc_julian_from_U_or_W(year, week_of_year, weekday,\n  week_starts_Mon)\n  \n  \n  \n if julian == -1:\n \n  julian = datetime_date(year, month, day).toordinal() - datetime_date(year, 1, 1).toordinal() + 1\n else: \n \n  datetime_result = datetime_date.fromordinal((julian - 1) + datetime_date(year, 1, 1).toordinal())\n  year = datetime_result.year\n  month = datetime_result.month\n  day = datetime_result.day\n if weekday == -1:\n  weekday = datetime_date(year, month, day).weekday()\n  \n tzname = found_dict.get(\"Z\")\n if tzoffset is not None:\n  gmtoff = tzoffset * 60\n else:\n  gmtoff = None\n  \n if leap_year_fix:\n \n \n \n  year = 1900\n  \n return (year, month, day,\n hour, minute, second,\n weekday, julian, tz, tzname, gmtoff), fraction\n \ndef _strptime_time(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n \"\"\n tt = _strptime(data_string, format)[0]\n return time.struct_time(tt[:time._STRUCT_TM_ITEMS])\n \ndef _strptime_datetime(cls, data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n \"\"\n tt, fraction = _strptime(data_string, format)\n tzname, gmtoff = tt[-2:]\n args = tt[:6] + (fraction,)\n if gmtoff is not None:\n  tzdelta = datetime_timedelta(seconds=gmtoff)\n  if tzname:\n   tz = datetime_timezone(tzdelta, tzname)\n  else:\n   tz = datetime_timezone(tzdelta)\n  args += (tz,)\n  \n return cls(*args)\n"], "unittest.test.test_assertions": [".py", "import datetime\nimport warnings\nimport unittest\nfrom itertools import product\n\n\nclass Test_Assertions(unittest.TestCase):\n def test_AlmostEqual(self):\n  self.assertAlmostEqual(1.00000001, 1.0)\n  self.assertNotAlmostEqual(1.0000001, 1.0)\n  self.assertRaises(self.failureException,\n  self.assertAlmostEqual, 1.0000001, 1.0)\n  self.assertRaises(self.failureException,\n  self.assertNotAlmostEqual, 1.00000001, 1.0)\n  \n  self.assertAlmostEqual(1.1, 1.0, places=0)\n  self.assertRaises(self.failureException,\n  self.assertAlmostEqual, 1.1, 1.0, places=1)\n  \n  self.assertAlmostEqual(0, .1+.1j, places=0)\n  self.assertNotAlmostEqual(0, .1+.1j, places=1)\n  self.assertRaises(self.failureException,\n  self.assertAlmostEqual, 0, .1+.1j, places=1)\n  self.assertRaises(self.failureException,\n  self.assertNotAlmostEqual, 0, .1+.1j, places=0)\n  \n  self.assertAlmostEqual(float('inf'), float('inf'))\n  self.assertRaises(self.failureException, self.assertNotAlmostEqual,\n  float('inf'), float('inf'))\n  \n def test_AmostEqualWithDelta(self):\n  self.assertAlmostEqual(1.1, 1.0, delta=0.5)\n  self.assertAlmostEqual(1.0, 1.1, delta=0.5)\n  self.assertNotAlmostEqual(1.1, 1.0, delta=0.05)\n  self.assertNotAlmostEqual(1.0, 1.1, delta=0.05)\n  \n  self.assertRaises(self.failureException, self.assertAlmostEqual,\n  1.1, 1.0, delta=0.05)\n  self.assertRaises(self.failureException, self.assertNotAlmostEqual,\n  1.1, 1.0, delta=0.5)\n  \n  self.assertRaises(TypeError, self.assertAlmostEqual,\n  1.1, 1.0, places=2, delta=2)\n  self.assertRaises(TypeError, self.assertNotAlmostEqual,\n  1.1, 1.0, places=2, delta=2)\n  \n  first = datetime.datetime.now()\n  second = first + datetime.timedelta(seconds=10)\n  self.assertAlmostEqual(first, second,\n  delta=datetime.timedelta(seconds=20))\n  self.assertNotAlmostEqual(first, second,\n  delta=datetime.timedelta(seconds=5))\n  \n def test_assertRaises(self):\n  def _raise(e):\n   raise e\n  self.assertRaises(KeyError, _raise, KeyError)\n  self.assertRaises(KeyError, _raise, KeyError(\"key\"))\n  try:\n   self.assertRaises(KeyError, lambda: None)\n  except self.failureException as e:\n   self.assertIn(\"KeyError not raised\", str(e))\n  else:\n   self.fail(\"assertRaises() didn't fail\")\n  try:\n   self.assertRaises(KeyError, _raise, ValueError)\n  except ValueError:\n   pass\n  else:\n   self.fail(\"assertRaises() didn't let exception pass through\")\n  with self.assertRaises(KeyError) as cm:\n   try:\n    raise KeyError\n   except Exception as e:\n    exc = e\n    raise\n  self.assertIs(cm.exception, exc)\n  \n  with self.assertRaises(KeyError):\n   raise KeyError(\"key\")\n  try:\n   with self.assertRaises(KeyError):\n    pass\n  except self.failureException as e:\n   self.assertIn(\"KeyError not raised\", str(e))\n  else:\n   self.fail(\"assertRaises() didn't fail\")\n  try:\n   with self.assertRaises(KeyError):\n    raise ValueError\n  except ValueError:\n   pass\n  else:\n   self.fail(\"assertRaises() didn't let exception pass through\")\n   \n def testAssertNotRegex(self):\n  self.assertNotRegex('Ala ma kota', r'r+')\n  try:\n   self.assertNotRegex('Ala ma kota', r'k.t', 'Message')\n  except self.failureException as e:\n   self.assertIn(\"'kot'\", e.args[0])\n   self.assertIn('Message', e.args[0])\n  else:\n   self.fail('assertNotRegex should have failed.')\n   \n   \nclass TestLongMessage(unittest.TestCase):\n \"\"\n \n def setUp(self):\n  class TestableTestFalse(unittest.TestCase):\n   longMessage = False\n   failureException = self.failureException\n   \n   def testTest(self):\n    pass\n    \n  class TestableTestTrue(unittest.TestCase):\n   longMessage = True\n   failureException = self.failureException\n   \n   def testTest(self):\n    pass\n    \n  self.testableTrue = TestableTestTrue('testTest')\n  self.testableFalse = TestableTestFalse('testTest')\n  \n def testDefault(self):\n  self.assertTrue(unittest.TestCase.longMessage)\n  \n def test_formatMsg(self):\n  self.assertEqual(self.testableFalse._formatMessage(None, \"foo\"), \"foo\")\n  self.assertEqual(self.testableFalse._formatMessage(\"foo\", \"bar\"), \"foo\")\n  \n  self.assertEqual(self.testableTrue._formatMessage(None, \"foo\"), \"foo\")\n  self.assertEqual(self.testableTrue._formatMessage(\"foo\", \"bar\"), \"bar : foo\")\n  \n  \n  self.testableTrue._formatMessage(object(), 'foo')\n  \n def test_formatMessage_unicode_error(self):\n  one = ''.join(chr(i) for i in range(255))\n  \n  self.testableTrue._formatMessage(one, '\\uFFFD')\n  \n def assertMessages(self, methodName, args, errors):\n  \"\"\n  def getMethod(i):\n   useTestableFalse = i < 2\n   if useTestableFalse:\n    test = self.testableFalse\n   else:\n    test = self.testableTrue\n   return getattr(test, methodName)\n   \n  for i, expected_regex in enumerate(errors):\n   testMethod = getMethod(i)\n   kwargs = {}\n   withMsg = i % 2\n   if withMsg:\n    kwargs = {\"msg\": \"oops\"}\n    \n   with self.assertRaisesRegex(self.failureException,\n   expected_regex=expected_regex):\n    testMethod(*args, **kwargs)\n    \n def testAssertTrue(self):\n  self.assertMessages('assertTrue', (False,),\n  [\"^False is not true$\", \"^oops$\", \"^False is not true$\",\n  \"^False is not true : oops$\"])\n  \n def testAssertFalse(self):\n  self.assertMessages('assertFalse', (True,),\n  [\"^True is not false$\", \"^oops$\", \"^True is not false$\",\n  \"^True is not false : oops$\"])\n  \n def testNotEqual(self):\n  self.assertMessages('assertNotEqual', (1, 1),\n  [\"^1 == 1$\", \"^oops$\", \"^1 == 1$\",\n  \"^1 == 1 : oops$\"])\n  \n def testAlmostEqual(self):\n  self.assertMessages('assertAlmostEqual', (1, 2),\n  [\"^1 != 2 within 7 places$\", \"^oops$\",\n  \"^1 != 2 within 7 places$\", \"^1 != 2 within 7 places : oops$\"])\n  \n def testNotAlmostEqual(self):\n  self.assertMessages('assertNotAlmostEqual', (1, 1),\n  [\"^1 == 1 within 7 places$\", \"^oops$\",\n  \"^1 == 1 within 7 places$\", \"^1 == 1 within 7 places : oops$\"])\n  \n def test_baseAssertEqual(self):\n  self.assertMessages('_baseAssertEqual', (1, 2),\n  [\"^1 != 2$\", \"^oops$\", \"^1 != 2$\", \"^1 != 2 : oops$\"])\n  \n def testAssertSequenceEqual(self):\n \n \n  self.assertMessages('assertSequenceEqual', ([], [None]),\n  [\"\\+ \\[None\\]$\", \"^oops$\", r\"\\+ \\[None\\]$\",\n  r\"\\+ \\[None\\] : oops$\"])\n  \n def testAssertSetEqual(self):\n  self.assertMessages('assertSetEqual', (set(), set([None])),\n  [\"None$\", \"^oops$\", \"None$\",\n  \"None : oops$\"])\n  \n def testAssertIn(self):\n  self.assertMessages('assertIn', (None, []),\n  ['^None not found in \\[\\]$', \"^oops$\",\n  '^None not found in \\[\\]$',\n  '^None not found in \\[\\] : oops$'])\n  \n def testAssertNotIn(self):\n  self.assertMessages('assertNotIn', (None, [None]),\n  ['^None unexpectedly found in \\[None\\]$', \"^oops$\",\n  '^None unexpectedly found in \\[None\\]$',\n  '^None unexpectedly found in \\[None\\] : oops$'])\n  \n def testAssertDictEqual(self):\n  self.assertMessages('assertDictEqual', ({}, {'key': 'value'}),\n  [r\"\\+ \\{'key': 'value'\\}$\", \"^oops$\",\n  \"\\+ \\{'key': 'value'\\}$\",\n  \"\\+ \\{'key': 'value'\\} : oops$\"])\n  \n def testAssertDictContainsSubset(self):\n  with warnings.catch_warnings():\n   warnings.simplefilter(\"ignore\", DeprecationWarning)\n   \n   self.assertMessages('assertDictContainsSubset', ({'key': 'value'}, {}),\n   [\"^Missing: 'key'$\", \"^oops$\",\n   \"^Missing: 'key'$\",\n   \"^Missing: 'key' : oops$\"])\n   \n def testAssertMultiLineEqual(self):\n  self.assertMessages('assertMultiLineEqual', (\"\", \"foo\"),\n  [r\"\\+ foo$\", \"^oops$\",\n  r\"\\+ foo$\",\n  r\"\\+ foo : oops$\"])\n  \n def testAssertLess(self):\n  self.assertMessages('assertLess', (2, 1),\n  [\"^2 not less than 1$\", \"^oops$\",\n  \"^2 not less than 1$\", \"^2 not less than 1 : oops$\"])\n  \n def testAssertLessEqual(self):\n  self.assertMessages('assertLessEqual', (2, 1),\n  [\"^2 not less than or equal to 1$\", \"^oops$\",\n  \"^2 not less than or equal to 1$\",\n  \"^2 not less than or equal to 1 : oops$\"])\n  \n def testAssertGreater(self):\n  self.assertMessages('assertGreater', (1, 2),\n  [\"^1 not greater than 2$\", \"^oops$\",\n  \"^1 not greater than 2$\",\n  \"^1 not greater than 2 : oops$\"])\n  \n def testAssertGreaterEqual(self):\n  self.assertMessages('assertGreaterEqual', (1, 2),\n  [\"^1 not greater than or equal to 2$\", \"^oops$\",\n  \"^1 not greater than or equal to 2$\",\n  \"^1 not greater than or equal to 2 : oops$\"])\n  \n def testAssertIsNone(self):\n  self.assertMessages('assertIsNone', ('not None',),\n  [\"^'not None' is not None$\", \"^oops$\",\n  \"^'not None' is not None$\",\n  \"^'not None' is not None : oops$\"])\n  \n def testAssertIsNotNone(self):\n  self.assertMessages('assertIsNotNone', (None,),\n  [\"^unexpectedly None$\", \"^oops$\",\n  \"^unexpectedly None$\",\n  \"^unexpectedly None : oops$\"])\n  \n def testAssertIs(self):\n  self.assertMessages('assertIs', (None, 'foo'),\n  [\"^None is not 'foo'$\", \"^oops$\",\n  \"^None is not 'foo'$\",\n  \"^None is not 'foo' : oops$\"])\n  \n def testAssertIsNot(self):\n  self.assertMessages('assertIsNot', (None, None),\n  [\"^unexpectedly identical: None$\", \"^oops$\",\n  \"^unexpectedly identical: None$\",\n  \"^unexpectedly identical: None : oops$\"])\n  \n  \n def assertMessagesCM(self, methodName, args, func, errors):\n  \"\"\n  p = product((self.testableFalse, self.testableTrue),\n  ({}, {\"msg\": \"oops\"}))\n  for (cls, kwargs), err in zip(p, errors):\n   method = getattr(cls, methodName)\n   with self.assertRaisesRegex(cls.failureException, err):\n    with method(*args, **kwargs) as cm:\n     func()\n     \n def testAssertRaises(self):\n  self.assertMessagesCM('assertRaises', (TypeError,), lambda: None,\n  ['^TypeError not raised$', '^oops$',\n  '^TypeError not raised$',\n  '^TypeError not raised : oops$'])\n  \n def testAssertRaisesRegex(self):\n \n  self.assertMessagesCM('assertRaisesRegex', (TypeError, 'unused regex'),\n  lambda: None,\n  ['^TypeError not raised$', '^oops$',\n  '^TypeError not raised$',\n  '^TypeError not raised : oops$'])\n  \n  def raise_wrong_message():\n   raise TypeError('foo')\n  self.assertMessagesCM('assertRaisesRegex', (TypeError, 'regex'),\n  raise_wrong_message,\n  ['^\"regex\" does not match \"foo\"$', '^oops$',\n  '^\"regex\" does not match \"foo\"$',\n  '^\"regex\" does not match \"foo\" : oops$'])\n  \n def testAssertWarns(self):\n  self.assertMessagesCM('assertWarns', (UserWarning,), lambda: None,\n  ['^UserWarning not triggered$', '^oops$',\n  '^UserWarning not triggered$',\n  '^UserWarning not triggered : oops$'])\n  \n def testAssertWarnsRegex(self):\n \n  self.assertMessagesCM('assertWarnsRegex', (UserWarning, 'unused regex'),\n  lambda: None,\n  ['^UserWarning not triggered$', '^oops$',\n  '^UserWarning not triggered$',\n  '^UserWarning not triggered : oops$'])\n  \n  def raise_wrong_message():\n   warnings.warn('foo')\n  self.assertMessagesCM('assertWarnsRegex', (UserWarning, 'regex'),\n  raise_wrong_message,\n  ['^\"regex\" does not match \"foo\"$', '^oops$',\n  '^\"regex\" does not match \"foo\"$',\n  '^\"regex\" does not match \"foo\" : oops$'])\n"], "unittest.test.testmock.testmagicmethods": [".py", "import unittest\nimport inspect\nimport sys\nfrom unittest.mock import Mock, MagicMock, _magics\n\n\n\nclass TestMockingMagicMethods(unittest.TestCase):\n\n def test_deleting_magic_methods(self):\n  mock = Mock()\n  self.assertFalse(hasattr(mock, '__getitem__'))\n  \n  mock.__getitem__ = Mock()\n  self.assertTrue(hasattr(mock, '__getitem__'))\n  \n  del mock.__getitem__\n  self.assertFalse(hasattr(mock, '__getitem__'))\n  \n  \n def test_magicmock_del(self):\n  mock = MagicMock()\n  \n  del mock.__getitem__\n  self.assertRaises(TypeError, lambda: mock['foo'])\n  \n  mock = MagicMock()\n  \n  mock['foo']\n  del mock.__getitem__\n  self.assertRaises(TypeError, lambda: mock['foo'])\n  \n  \n def test_magic_method_wrapping(self):\n  mock = Mock()\n  def f(self, name):\n   return self, 'fish'\n   \n  mock.__getitem__ = f\n  self.assertFalse(mock.__getitem__ is f)\n  self.assertEqual(mock['foo'], (mock, 'fish'))\n  self.assertEqual(mock.__getitem__('foo'), (mock, 'fish'))\n  \n  mock.__getitem__ = mock\n  self.assertTrue(mock.__getitem__ is mock)\n  \n  \n def test_magic_methods_isolated_between_mocks(self):\n  mock1 = Mock()\n  mock2 = Mock()\n  \n  mock1.__iter__ = Mock(return_value=iter([]))\n  self.assertEqual(list(mock1), [])\n  self.assertRaises(TypeError, lambda: list(mock2))\n  \n  \n def test_repr(self):\n  mock = Mock()\n  self.assertEqual(repr(mock), \"<Mock id='%s'>\" % id(mock))\n  mock.__repr__ = lambda s: 'foo'\n  self.assertEqual(repr(mock), 'foo')\n  \n  \n def test_str(self):\n  mock = Mock()\n  self.assertEqual(str(mock), object.__str__(mock))\n  mock.__str__ = lambda s: 'foo'\n  self.assertEqual(str(mock), 'foo')\n  \n  \n def test_dict_methods(self):\n  mock = Mock()\n  \n  self.assertRaises(TypeError, lambda: mock['foo'])\n  def _del():\n   del mock['foo']\n  def _set():\n   mock['foo'] = 3\n  self.assertRaises(TypeError, _del)\n  self.assertRaises(TypeError, _set)\n  \n  _dict = {}\n  def getitem(s, name):\n   return _dict[name]\n  def setitem(s, name, value):\n   _dict[name] = value\n  def delitem(s, name):\n   del _dict[name]\n   \n  mock.__setitem__ = setitem\n  mock.__getitem__ = getitem\n  mock.__delitem__ = delitem\n  \n  self.assertRaises(KeyError, lambda: mock['foo'])\n  mock['foo'] = 'bar'\n  self.assertEqual(_dict, {'foo': 'bar'})\n  self.assertEqual(mock['foo'], 'bar')\n  del mock['foo']\n  self.assertEqual(_dict, {})\n  \n  \n def test_numeric(self):\n  original = mock = Mock()\n  mock.value = 0\n  \n  self.assertRaises(TypeError, lambda: mock + 3)\n  \n  def add(self, other):\n   mock.value += other\n   return self\n  mock.__add__ = add\n  self.assertEqual(mock + 3, mock)\n  self.assertEqual(mock.value, 3)\n  \n  del mock.__add__\n  def iadd(mock):\n   mock += 3\n  self.assertRaises(TypeError, iadd, mock)\n  mock.__iadd__ = add\n  mock += 6\n  self.assertEqual(mock, original)\n  self.assertEqual(mock.value, 9)\n  \n  self.assertRaises(TypeError, lambda: 3 + mock)\n  mock.__radd__ = add\n  self.assertEqual(7 + mock, mock)\n  self.assertEqual(mock.value, 16)\n  \n  \n def test_hash(self):\n  mock = Mock()\n  \n  self.assertEqual(hash(mock), Mock.__hash__(mock))\n  \n  def _hash(s):\n   return 3\n  mock.__hash__ = _hash\n  self.assertEqual(hash(mock), 3)\n  \n  \n def test_nonzero(self):\n  m = Mock()\n  self.assertTrue(bool(m))\n  \n  m.__bool__ = lambda s: False\n  self.assertFalse(bool(m))\n  \n  \n def test_comparison(self):\n  mock = Mock()\n  def comp(s, o):\n   return True\n  mock.__lt__ = mock.__gt__ = mock.__le__ = mock.__ge__ = comp\n  self. assertTrue(mock < 3)\n  self. assertTrue(mock > 3)\n  self. assertTrue(mock <= 3)\n  self. assertTrue(mock >= 3)\n  \n  self.assertRaises(TypeError, lambda: MagicMock() < object())\n  self.assertRaises(TypeError, lambda: object() < MagicMock())\n  self.assertRaises(TypeError, lambda: MagicMock() < MagicMock())\n  self.assertRaises(TypeError, lambda: MagicMock() > object())\n  self.assertRaises(TypeError, lambda: object() > MagicMock())\n  self.assertRaises(TypeError, lambda: MagicMock() > MagicMock())\n  self.assertRaises(TypeError, lambda: MagicMock() <= object())\n  self.assertRaises(TypeError, lambda: object() <= MagicMock())\n  self.assertRaises(TypeError, lambda: MagicMock() <= MagicMock())\n  self.assertRaises(TypeError, lambda: MagicMock() >= object())\n  self.assertRaises(TypeError, lambda: object() >= MagicMock())\n  self.assertRaises(TypeError, lambda: MagicMock() >= MagicMock())\n  \n  \n def test_equality(self):\n  for mock in Mock(), MagicMock():\n   self.assertEqual(mock == mock, True)\n   self.assertIsInstance(mock == mock, bool)\n   self.assertEqual(mock != mock, False)\n   self.assertIsInstance(mock != mock, bool)\n   self.assertEqual(mock == object(), False)\n   self.assertEqual(mock != object(), True)\n   \n   def eq(self, other):\n    return other == 3\n   mock.__eq__ = eq\n   self.assertTrue(mock == 3)\n   self.assertFalse(mock == 4)\n   \n   def ne(self, other):\n    return other == 3\n   mock.__ne__ = ne\n   self.assertTrue(mock != 3)\n   self.assertFalse(mock != 4)\n   \n  mock = MagicMock()\n  mock.__eq__.return_value = True\n  self.assertIsInstance(mock == 3, bool)\n  self.assertEqual(mock == 3, True)\n  \n  mock.__ne__.return_value = False\n  self.assertIsInstance(mock != 3, bool)\n  self.assertEqual(mock != 3, False)\n  \n  \n def test_len_contains_iter(self):\n  mock = Mock()\n  \n  self.assertRaises(TypeError, len, mock)\n  self.assertRaises(TypeError, iter, mock)\n  self.assertRaises(TypeError, lambda: 'foo' in mock)\n  \n  mock.__len__ = lambda s: 6\n  self.assertEqual(len(mock), 6)\n  \n  mock.__contains__ = lambda s, o: o == 3\n  self.assertTrue(3 in mock)\n  self.assertFalse(6 in mock)\n  \n  mock.__iter__ = lambda s: iter('foobarbaz')\n  self.assertEqual(list(mock), list('foobarbaz'))\n  \n  \n def test_magicmock(self):\n  mock = MagicMock()\n  \n  mock.__iter__.return_value = iter([1, 2, 3])\n  self.assertEqual(list(mock), [1, 2, 3])\n  \n  getattr(mock, '__bool__').return_value = False\n  self.assertFalse(hasattr(mock, '__nonzero__'))\n  self.assertFalse(bool(mock))\n  \n  for entry in _magics:\n   self.assertTrue(hasattr(mock, entry))\n  self.assertFalse(hasattr(mock, '__imaginery__'))\n  \n  \n def test_magic_mock_equality(self):\n  mock = MagicMock()\n  self.assertIsInstance(mock == object(), bool)\n  self.assertIsInstance(mock != object(), bool)\n  \n  self.assertEqual(mock == object(), False)\n  self.assertEqual(mock != object(), True)\n  self.assertEqual(mock == mock, True)\n  self.assertEqual(mock != mock, False)\n  \n  \n def test_magicmock_defaults(self):\n  mock = MagicMock()\n  self.assertEqual(int(mock), 1)\n  self.assertEqual(complex(mock), 1j)\n  self.assertEqual(float(mock), 1.0)\n  self.assertNotIn(object(), mock)\n  self.assertEqual(len(mock), 0)\n  self.assertEqual(list(mock), [])\n  self.assertEqual(hash(mock), object.__hash__(mock))\n  self.assertEqual(str(mock), object.__str__(mock))\n  self.assertTrue(bool(mock))\n  \n  \n  \n  self.assertEqual(oct(mock), '0o1')\n  self.assertEqual(hex(mock), '0x1')\n  \n  \n  \n def test_magic_methods_and_spec(self):\n  class Iterable(object):\n   def __iter__(self):\n    pass\n    \n  mock = Mock(spec=Iterable)\n  self.assertRaises(AttributeError, lambda: mock.__iter__)\n  \n  mock.__iter__ = Mock(return_value=iter([]))\n  self.assertEqual(list(mock), [])\n  \n  class NonIterable(object):\n   pass\n  mock = Mock(spec=NonIterable)\n  self.assertRaises(AttributeError, lambda: mock.__iter__)\n  \n  def set_int():\n   mock.__int__ = Mock(return_value=iter([]))\n  self.assertRaises(AttributeError, set_int)\n  \n  mock = MagicMock(spec=Iterable)\n  self.assertEqual(list(mock), [])\n  self.assertRaises(AttributeError, set_int)\n  \n  \n def test_magic_methods_and_spec_set(self):\n  class Iterable(object):\n   def __iter__(self):\n    pass\n    \n  mock = Mock(spec_set=Iterable)\n  self.assertRaises(AttributeError, lambda: mock.__iter__)\n  \n  mock.__iter__ = Mock(return_value=iter([]))\n  self.assertEqual(list(mock), [])\n  \n  class NonIterable(object):\n   pass\n  mock = Mock(spec_set=NonIterable)\n  self.assertRaises(AttributeError, lambda: mock.__iter__)\n  \n  def set_int():\n   mock.__int__ = Mock(return_value=iter([]))\n  self.assertRaises(AttributeError, set_int)\n  \n  mock = MagicMock(spec_set=Iterable)\n  self.assertEqual(list(mock), [])\n  self.assertRaises(AttributeError, set_int)\n  \n  \n def test_setting_unsupported_magic_method(self):\n  mock = MagicMock()\n  def set_setattr():\n   mock.__setattr__ = lambda self, name: None\n  self.assertRaisesRegex(AttributeError,\n  \"Attempting to set unsupported magic method '__setattr__'.\",\n  set_setattr\n  )\n  \n  \n def test_attributes_and_return_value(self):\n  mock = MagicMock()\n  attr = mock.foo\n  def _get_type(obj):\n  \n  \n   return type(obj).__mro__[1]\n  self.assertEqual(_get_type(attr), MagicMock)\n  \n  returned = mock()\n  self.assertEqual(_get_type(returned), MagicMock)\n  \n  \n def test_magic_methods_are_magic_mocks(self):\n  mock = MagicMock()\n  self.assertIsInstance(mock.__getitem__, MagicMock)\n  \n  mock[1][2].__getitem__.return_value = 3\n  self.assertEqual(mock[1][2][3], 3)\n  \n  \n def test_magic_method_reset_mock(self):\n  mock = MagicMock()\n  str(mock)\n  self.assertTrue(mock.__str__.called)\n  mock.reset_mock()\n  self.assertFalse(mock.__str__.called)\n  \n  \n def test_dir(self):\n \n  for mock in Mock(), MagicMock():\n   def _dir(self):\n    return ['foo']\n   mock.__dir__ = _dir\n   self.assertEqual(dir(mock), ['foo'])\n   \n   \n @unittest.skipIf('PyPy' in sys.version, \"This fails differently on pypy\")\n def test_bound_methods(self):\n  m = Mock()\n  \n  \n  \n  \n  \n  m.__iter__ = [3].__iter__\n  self.assertRaises(TypeError, iter, m)\n  \n  \n def test_magic_method_type(self):\n  class Foo(MagicMock):\n   pass\n   \n  foo = Foo()\n  self.assertIsInstance(foo.__int__, Foo)\n  \n  \n def test_descriptor_from_class(self):\n  m = MagicMock()\n  type(m).__str__.return_value = 'foo'\n  self.assertEqual(str(m), 'foo')\n  \n  \n def test_iterable_as_iter_return_value(self):\n  m = MagicMock()\n  m.__iter__.return_value = [1, 2, 3]\n  self.assertEqual(list(m), [1, 2, 3])\n  self.assertEqual(list(m), [1, 2, 3])\n  \n  m.__iter__.return_value = iter([4, 5, 6])\n  self.assertEqual(list(m), [4, 5, 6])\n  self.assertEqual(list(m), [])\n  \n  \nif __name__ == '__main__':\n unittest.main()\n"], "_browser": [".js", "var $module=(function($B) {\n  return {\n    alert:function(message){window.alert($B.builtins.str(message))},\n    confirm: function(message){return $B.JSObject(window.confirm(message))},\n    console:{log:function(data){window.console.log(data)}},\n    $$document:$B.$DOMNode(document),\n    doc: $B.$DOMNode(document),   //want to use document instead of doc\n    DOMEvent:$B.DOMEvent,\n    DOMNode:$B.DOMNode,\n    mouseCoords: function(ev){return $B.JSObject($mouseCoords(ev))},\n    prompt: function(message, default_value){\n        return $B.JSObject(window.prompt(message, default_value||''))\n    },\n    win: $B.win,\n    window: $B.win\n  }\n})(__BRYTHON__)\n"], "time": [".js", "var $module=(function($B){\n\nvar _b_ = $B.builtins\nvar $s=[]\nfor(var $b in _b_) $s.push('var ' + $b +'=_b_[\"'+$b+'\"]')\neval($s.join(';'))\n\nvar stnames = ['tm_year','tm_mon','tm_mday','tm_hour','tm_min','tm_sec',\n    'tm_wday','tm_yday','tm_isdst']\n\nvar StructTimeDict = {__name__:'struct_time',__class__:$B.$type}\n\nStructTimeDict.__mro__ = [StructTimeDict,_b_.object.$dict]\n\nStructTimeDict.__getattr__ = function(self,name){\n    var ix = stnames.indexOf(name)\n    if(ix==-1){throw AttributeError(\n        \"'time.struct_time' object has no attribute '\"+name+\"'\")}\n    return StructTimeDict.__getitem__(self,ix)\n}\n\nStructTimeDict.__getitem__ = function(self, rank){\n    if(!typeof rank=='number'){throw _b_.TypeError(\n        'list indices must be integers, not '+$B.get_class(rank).__name__)\n    }\n    var res = self.value[rank]\n    if(res===undefined){throw _b_.KeyError(rank)}\n    return res\n}\n\nStructTimeDict.__repr__ = StructTimeDict.__str__ = function(self){\n    var res = 'time.struct_time('\n    var elts = []\n    for(var i=0;i<stnames.length;i++){\n        elts.push(stnames[i]+'='+self.value[i])\n    }\n    res += elts.join(', ')\n    return res+')'\n}\n\nfunction StructTime(args){\n    return {__class__:StructTimeDict, value: args}\n}\nStructTime.$type = $B.factory\nStructTime.$dict = StructTimeDict\nStructTimeDict.$factory = StructTime\n\nvar $mod = {\n    __name__ : 'time',\n    tzname: _b_.tuple(['', '']),\n    daylight: 0,      //fix me.. returns Non zero if DST timezone is defined\n    ctime: function(timestamp){\n       if (timestamp === undefined) {\n          timestamp=int(new Date().getTime()/1000);\n       }\n       var d=new Date(0);\n       d.setUTCSeconds(timestamp);\n       return d.toUTCString();\n    },\n    gmtime: function(){\n       var d=new Date();\n       return [d.getUTCFullYear(), d.getUTCMonth()+1, d.getUTCDate(),\n               d.getUTCHours(), d.getUTCMinutes(), d.getUTCSeconds(),\n               d.getUTCDay(), 0, 0]\n    },\n    perf_counter: function() {\n        return float((new Date()).getTime()/1000.0);\n    },\n\n    localtime : function(secs){\n       var d=new Date();\n       if (secs === undefined || secs === None){\n           return d.getTime()\n       } else {\n           d = new Date(secs * 1000)\n       }\n\n\n\n       // calculate if we are in daylight savings time or not.\n       // borrowed from http://stackoverflow.com/questions/11887934/check-if-daylight-saving-time-is-in-effect-and-if-it-is-for-how-many-hours\n       var jan = new Date(d.getFullYear(), 0, 1);\n       var jul = new Date(d.getFullYear(), 6, 1);\n       var dst=int(d.getTimezoneOffset() < Math.max(jan.getTimezoneOffset(), jul.getTimezoneOffset()));\n\n       return [d.getFullYear(), d.getMonth()+1, d.getDate(), d.getHours(),\n                    d.getMinutes(), d.getSeconds(), d.getDay(), 0, dst]\n       //fixme  (second to last value is 0 which is the number of days in this year..)\n    },\n    time : function(){return float((new Date().getTime())/1000)},\n\n    sleep : function(secs){},\n\n    strftime : function(format,arg){\n        function ns(arg,nb){\n            // left padding with 0\n            var res = arg.toString()\n            while(res.length<nb){res = '0'+res}\n            return res\n        }\n        if(arg){\n            var obj = new Date(arg[0],arg[1]-1,arg[2],arg[3],arg[4],arg[5],arg[6])\n        }else{\n            var obj=new Date()\n        }\n        var abb_weekdays = ['Su','Mo','Tu','We','Th','Fr','Sa']\n        var full_weekdays = ['Sunday','Monday','Tuesday','Wednesday',\n            'Thursday','Friday','Saturday']\n        var abb_months = ['Jan','Feb','Mar','Apr','May','Jun',\n            'Jul','Aug','Sep','Oct','Nov','Dec']\n        var full_months = ['January','February','March','April','May','June',\n            'July','August','September','October','November','December']\n        var res = format\n        res = res.replace(/%H/,ns(obj.getHours(),2))\n        res = res.replace(/%M/,ns(obj.getMinutes(),2))\n        res = res.replace(/%S/,ns(obj.getSeconds(),2))\n        res = res.replace(/%Y/,ns(obj.getFullYear(),4))\n        res = res.replace(/%y/,ns(obj.getFullYear(),4).substr(2))\n        res = res.replace(/%m/,ns(obj.getMonth()+1,2))\n        res = res.replace(/%d/,ns(obj.getDate(),2))\n        res = res.replace(/%a/,abb_weekdays[obj.getDay()])\n        res = res.replace(/%A/,full_weekdays[obj.getDay()])\n        res = res.replace(/%b/,abb_months[obj.getMonth()])\n        res = res.replace(/%B/,full_months[obj.getMonth()])\n        return res\n    },\n\n    struct_time : function(arg){\n        if(!isinstance(arg,[tuple,list])){\n            throw TypeError('constructor requires a sequence')\n        }\n        if(len(arg)!=9){\n            throw TypeError(\"time.struct_time() takes a 9-sequence (\"+len(arg)+\"-sequence given\")\n        }\n        var res = arg\n        var names = ['tm_year','tm_mon','tm_mday','tm_hour','tm_min','tm_sec','tm_wday',\n            'tm_yday','tm_isdst','tm_zone','tm_gmtoff']\n        res.__getattr__ = function(attr){\n            var ix = names.indexOf(attr)\n            if(ix>-1){return arg.__getitem__(ix)}\n            if(typeof res[attr]==='function'){\n                return (function(obj){\n                    return function(){return obj[attr].apply(obj,arguments)}\n                })(res)\n            }else if(res[attr]!==undefined){\n                return res[attr]\n            }else{throw AttributeError(\"object has no attribute '\"+attr+\"'\")}\n        }\n        return res\n    }\n}\n\nfunction to_struct_time(ptuple){\n    // Receives a packed tuple, pass its attribute \"arg\" to struct_time\n    var arg = ptuple.arg\n    // The tuple received from module _strptime has 7 elements, we must add\n    // the rank of day in the year in the range [1, 366]\n    var ml = [31,28,31,30,31,30,31,31,30,31,30,31]\n    if(arg[0]%4==0){ml[1]++}\n    console.log(ml)\n    var i=1, yday=0\n    while(i<arg[1]){yday+=ml[i-1];i++}\n    yday += arg[2]\n    arg.push(yday)\n    arg.push(-1)\n    return $mod.struct_time(arg)\n}\n\n$mod.strptime = function(string, format){\n    var _strptime = _b_.__import__('_strptime')\n    return StructTime(_strptime._strptime_datetime(to_struct_time, string, format))\n}\n\nreturn $mod\n})(__BRYTHON__)\n"], "pyre": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\n\nimport sys\nimport sre_compile\nimport sre_parse\nimport functools\n\n\n__all__ = [ \"match\", \"search\", \"sub\", \"subn\", \"split\", \"findall\",\n\"compile\", \"purge\", \"template\", \"escape\", \"A\", \"I\", \"L\", \"M\", \"S\", \"X\",\n\"U\", \"ASCII\", \"IGNORECASE\", \"LOCALE\", \"MULTILINE\", \"DOTALL\", \"VERBOSE\",\n\"UNICODE\", \"error\" ]\n\n__version__ = \"2.2.1\"\n\n\nA = ASCII = sre_compile.SRE_FLAG_ASCII \nI = IGNORECASE = sre_compile.SRE_FLAG_IGNORECASE \nL = LOCALE = sre_compile.SRE_FLAG_LOCALE \nU = UNICODE = sre_compile.SRE_FLAG_UNICODE \nM = MULTILINE = sre_compile.SRE_FLAG_MULTILINE \nS = DOTALL = sre_compile.SRE_FLAG_DOTALL \nX = VERBOSE = sre_compile.SRE_FLAG_VERBOSE \n\n\nT = TEMPLATE = sre_compile.SRE_FLAG_TEMPLATE \nDEBUG = sre_compile.SRE_FLAG_DEBUG \n\n\nerror = sre_compile.error\n\n\n\n\ndef match(pattern, string, flags=0):\n \"\"\n return _compile(pattern, flags).match(string)\n \ndef search(pattern, string, flags=0):\n \"\"\n return _compile(pattern, flags).search(string)\n \ndef sub(pattern, repl, string, count=0, flags=0):\n \"\"\n return _compile(pattern, flags).sub(repl, string, count)\n \ndef subn(pattern, repl, string, count=0, flags=0):\n \"\"\n return _compile(pattern, flags).subn(repl, string, count)\n \ndef split(pattern, string, maxsplit=0, flags=0):\n \"\"\n return _compile(pattern, flags).split(string, maxsplit)\n \ndef findall(pattern, string, flags=0):\n \"\"\n return _compile(pattern, flags).findall(string)\n \nif sys.hexversion >= 0x02020000:\n __all__.append(\"finditer\")\n def finditer(pattern, string, flags=0):\n  \"\"\n  return _compile(pattern, flags).finditer(string)\n  \ndef compile(pattern, flags=0):\n \"\"\n \n return _compile(pattern, flags)\n \ndef purge():\n \"\"\n _cache.clear()\n _cache_repl.clear()\n \ndef template(pattern, flags=0):\n \"\"\n return _compile(pattern, flags|T)\n \n_alphanum_str = frozenset(\n\"_abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ01234567890\")\n_alphanum_bytes = frozenset(\nb\"_abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ01234567890\")\n\ndef escape(pattern):\n \"\"\n if isinstance(pattern, str):\n  alphanum = _alphanum_str\n  s = list(pattern)\n  for i, c in enumerate(pattern):\n   if c not in alphanum:\n    if c == \"\\000\":\n     s[i] = \"\\\\000\"\n    else:\n     s[i] = \"\\\\\" + c\n  return \"\".join(s)\n else:\n  alphanum = _alphanum_bytes\n  s = []\n  esc = ord(b\"\\\\\")\n  for c in pattern:\n   if c in alphanum:\n    s.append(c)\n   else:\n    if c == 0:\n     s.extend(b\"\\\\000\")\n    else:\n     s.append(esc)\n     s.append(c)\n  return bytes(s)\n  \n  \n  \n  \n_cache = {}\n_cache_repl = {}\n\n_pattern_type = type(sre_compile.compile(\"\", 0))\n\n_MAXCACHE = 512\ndef _compile(pattern, flags):\n\n try:\n \n \n  return _cache[\"%s:%s:%s\" % (type(pattern), pattern, flags)]\n except KeyError:\n  pass\n  \n if isinstance(pattern, _pattern_type):\n  if flags:\n   raise ValueError(\n   \"Cannot process flags argument with a compiled pattern\")\n  return pattern\n if not sre_compile.isstring(pattern):\n  raise TypeError(\"first argument must be string or compiled pattern\")\n p = sre_compile.compile(pattern, flags)\n \n if len(_cache) >= _MAXCACHE:\n  _cache.clear()\n  \n  \n _cache[\"%s:%s:%s\" % (type(pattern), pattern, flags)]= p\n return p\n \ndef _compile_repl(repl, pattern):\n\n try:\n \n \n  return _cache_repl[\"%s:%s\" % (repl, pattern)]\n except KeyError:\n  pass\n p = sre_parse.parse_template(repl, pattern)\n if len(_cache_repl) >= _MAXCACHE:\n  _cache_repl.clear()\n _cache_repl[\"%s:%s\" % (repl, pattern)] = p\n \n \n return p\n \ndef _expand(pattern, match, template):\n\n template = sre_parse.parse_template(template, pattern)\n return sre_parse.expand_template(template, match)\n \ndef _subx(pattern, template):\n\n template = _compile_repl(template, pattern)\n if not template[0] and len(template[1]) == 1:\n \n  return template[1][0]\n def filter(match, template=template):\n  return sre_parse.expand_template(template, match)\n return filter\n \n \n \nimport copyreg\n\ndef _pickle(p):\n return _compile, (p.pattern, p.flags)\n \ncopyreg.pickle(_pattern_type, _pickle, _compile)\n\n\n\n\nclass Scanner:\n def __init__(self, lexicon, flags=0):\n  from sre_constants import BRANCH, SUBPATTERN\n  self.lexicon = lexicon\n  \n  p = []\n  s = sre_parse.Pattern()\n  s.flags = flags\n  for phrase, action in lexicon:\n   p.append(sre_parse.SubPattern(s, [\n   (SUBPATTERN, (len(p)+1, sre_parse.parse(phrase, flags))),\n   ]))\n  s.groups = len(p)+1\n  p = sre_parse.SubPattern(s, [(BRANCH, (None, p))])\n  self.scanner = sre_compile.compile(p)\n def scan(self, string):\n  result = []\n  append = result.append\n  match = self.scanner.scanner(string).match\n  i = 0\n  while 1:\n   m = match()\n   if not m:\n    break\n   j = m.end()\n   if i == j:\n    break\n   action = self.lexicon[m.lastindex-1][1]\n   if callable(action):\n    self.match = m\n    action = action(self, m.group())\n   if action is not None:\n    append(action)\n   i = j\n  return result, string[i:]\n"], "unittest.test.test_skipping": [".py", "import unittest\n\nfrom .support import LoggingResult\n\n\nclass Test_TestSkipping(unittest.TestCase):\n\n def test_skipping(self):\n  class Foo(unittest.TestCase):\n   def test_skip_me(self):\n    self.skipTest(\"skip\")\n  events = []\n  result = LoggingResult(events)\n  test = Foo(\"test_skip_me\")\n  test.run(result)\n  self.assertEqual(events, ['startTest', 'addSkip', 'stopTest'])\n  self.assertEqual(result.skipped, [(test, \"skip\")])\n  \n  \n  class Foo(unittest.TestCase):\n   def setUp(self):\n    self.skipTest(\"testing\")\n   def test_nothing(self): pass\n  events = []\n  result = LoggingResult(events)\n  test = Foo(\"test_nothing\")\n  test.run(result)\n  self.assertEqual(events, ['startTest', 'addSkip', 'stopTest'])\n  self.assertEqual(result.skipped, [(test, \"testing\")])\n  self.assertEqual(result.testsRun, 1)\n  \n def test_skipping_decorators(self):\n  op_table = ((unittest.skipUnless, False, True),\n  (unittest.skipIf, True, False))\n  for deco, do_skip, dont_skip in op_table:\n   class Foo(unittest.TestCase):\n    @deco(do_skip, \"testing\")\n    def test_skip(self): pass\n    \n    @deco(dont_skip, \"testing\")\n    def test_dont_skip(self): pass\n   test_do_skip = Foo(\"test_skip\")\n   test_dont_skip = Foo(\"test_dont_skip\")\n   suite = unittest.TestSuite([test_do_skip, test_dont_skip])\n   events = []\n   result = LoggingResult(events)\n   suite.run(result)\n   self.assertEqual(len(result.skipped), 1)\n   expected = ['startTest', 'addSkip', 'stopTest',\n   'startTest', 'addSuccess', 'stopTest']\n   self.assertEqual(events, expected)\n   self.assertEqual(result.testsRun, 2)\n   self.assertEqual(result.skipped, [(test_do_skip, \"testing\")])\n   self.assertTrue(result.wasSuccessful())\n   \n def test_skip_class(self):\n  @unittest.skip(\"testing\")\n  class Foo(unittest.TestCase):\n   def test_1(self):\n    record.append(1)\n  record = []\n  result = unittest.TestResult()\n  test = Foo(\"test_1\")\n  suite = unittest.TestSuite([test])\n  suite.run(result)\n  self.assertEqual(result.skipped, [(test, \"testing\")])\n  self.assertEqual(record, [])\n  \n def test_skip_non_unittest_class(self):\n  @unittest.skip(\"testing\")\n  class Mixin:\n   def test_1(self):\n    record.append(1)\n  class Foo(Mixin, unittest.TestCase):\n   pass\n  record = []\n  result = unittest.TestResult()\n  test = Foo(\"test_1\")\n  suite = unittest.TestSuite([test])\n  suite.run(result)\n  self.assertEqual(result.skipped, [(test, \"testing\")])\n  self.assertEqual(record, [])\n  \n def test_expected_failure(self):\n  class Foo(unittest.TestCase):\n   @unittest.expectedFailure\n   def test_die(self):\n    self.fail(\"help me!\")\n  events = []\n  result = LoggingResult(events)\n  test = Foo(\"test_die\")\n  test.run(result)\n  self.assertEqual(events,\n  ['startTest', 'addExpectedFailure', 'stopTest'])\n  self.assertEqual(result.expectedFailures[0][0], test)\n  self.assertTrue(result.wasSuccessful())\n  \n def test_unexpected_success(self):\n  class Foo(unittest.TestCase):\n   @unittest.expectedFailure\n   def test_die(self):\n    pass\n  events = []\n  result = LoggingResult(events)\n  test = Foo(\"test_die\")\n  test.run(result)\n  self.assertEqual(events,\n  ['startTest', 'addUnexpectedSuccess', 'stopTest'])\n  self.assertFalse(result.failures)\n  self.assertEqual(result.unexpectedSuccesses, [test])\n  self.assertTrue(result.wasSuccessful())\n  \n def test_skip_doesnt_run_setup(self):\n  class Foo(unittest.TestCase):\n   wasSetUp = False\n   wasTornDown = False\n   def setUp(self):\n    Foo.wasSetUp = True\n   def tornDown(self):\n    Foo.wasTornDown = True\n   @unittest.skip('testing')\n   def test_1(self):\n    pass\n    \n  result = unittest.TestResult()\n  test = Foo(\"test_1\")\n  suite = unittest.TestSuite([test])\n  suite.run(result)\n  self.assertEqual(result.skipped, [(test, \"testing\")])\n  self.assertFalse(Foo.wasSetUp)\n  self.assertFalse(Foo.wasTornDown)\n  \n def test_decorated_skip(self):\n  def decorator(func):\n   def inner(*a):\n    return func(*a)\n   return inner\n   \n  class Foo(unittest.TestCase):\n   @decorator\n   @unittest.skip('testing')\n   def test_1(self):\n    pass\n    \n  result = unittest.TestResult()\n  test = Foo(\"test_1\")\n  suite = unittest.TestSuite([test])\n  suite.run(result)\n  self.assertEqual(result.skipped, [(test, \"testing\")])\n"], "optparse": [".py", "\"\"\n\n__version__ = \"1.5.3\"\n\n__all__ = ['Option',\n'make_option',\n'SUPPRESS_HELP',\n'SUPPRESS_USAGE',\n'Values',\n'OptionContainer',\n'OptionGroup',\n'OptionParser',\n'HelpFormatter',\n'IndentedHelpFormatter',\n'TitledHelpFormatter',\n'OptParseError',\n'OptionError',\n'OptionConflictError',\n'OptionValueError',\n'BadOptionError']\n\n__copyright__ = \"\"\"\nCopyright (c) 2001-2006 Gregory P. Ward.  All rights reserved.\nCopyright (c) 2002-2006 Python Software Foundation.  All rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n  * Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n\n  * Redistributions in binary form must reproduce the above copyright\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n\n  * Neither the name of the author nor the names of its\n    contributors may be used to endorse or promote products derived from\n    this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\nIS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\nTO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\nPARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR\nCONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\nEXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\nPROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\"\"\"\n\nimport sys, os\nimport textwrap\n\ndef _repr(self):\n return \"<%s at 0x%x: %s>\" % (self.__class__.__name__, id(self), self)\n \n \n \n \n \n \n \n \ntry:\n from gettext import gettext, ngettext\nexcept ImportError:\n def gettext(message):\n  return message\n  \n def ngettext(singular, plural, n):\n  if n == 1:\n   return singular\n  return plural\n  \n_ = gettext\n\n\nclass OptParseError (Exception):\n def __init__(self, msg):\n  self.msg = msg\n  \n def __str__(self):\n  return self.msg\n  \n  \nclass OptionError (OptParseError):\n \"\"\n \n def __init__(self, msg, option):\n  self.msg = msg\n  self.option_id = str(option)\n  \n def __str__(self):\n  if self.option_id:\n   return \"option %s: %s\" % (self.option_id, self.msg)\n  else:\n   return self.msg\n   \nclass OptionConflictError (OptionError):\n \"\"\n \nclass OptionValueError (OptParseError):\n \"\"\n \nclass BadOptionError (OptParseError):\n \"\"\n def __init__(self, opt_str):\n  self.opt_str = opt_str\n  \n def __str__(self):\n  return _(\"no such option: %s\") % self.opt_str\n  \nclass AmbiguousOptionError (BadOptionError):\n \"\"\n def __init__(self, opt_str, possibilities):\n  BadOptionError.__init__(self, opt_str)\n  self.possibilities = possibilities\n  \n def __str__(self):\n  return (_(\"ambiguous option: %s (%s?)\")\n  % (self.opt_str, \", \".join(self.possibilities)))\n  \n  \nclass HelpFormatter:\n\n \"\"\n \n NO_DEFAULT_VALUE = \"none\"\n \n def __init__(self,\n indent_increment,\n max_help_position,\n width,\n short_first):\n  self.parser = None\n  self.indent_increment = indent_increment\n  self.help_position = self.max_help_position = max_help_position\n  if width is None:\n   try:\n    width = int(os.environ['COLUMNS'])\n   except (KeyError, ValueError):\n    width = 80\n   width -= 2\n  self.width = width\n  self.current_indent = 0\n  self.level = 0\n  self.help_width = None \n  self.short_first = short_first\n  self.default_tag = \"%default\"\n  self.option_strings = {}\n  self._short_opt_fmt = \"%s %s\"\n  self._long_opt_fmt = \"%s=%s\"\n  \n def set_parser(self, parser):\n  self.parser = parser\n  \n def set_short_opt_delimiter(self, delim):\n  if delim not in (\"\", \" \"):\n   raise ValueError(\n   \"invalid metavar delimiter for short options: %r\" % delim)\n  self._short_opt_fmt = \"%s\" + delim + \"%s\"\n  \n def set_long_opt_delimiter(self, delim):\n  if delim not in (\"=\", \" \"):\n   raise ValueError(\n   \"invalid metavar delimiter for long options: %r\" % delim)\n  self._long_opt_fmt = \"%s\" + delim + \"%s\"\n  \n def indent(self):\n  self.current_indent += self.indent_increment\n  self.level += 1\n  \n def dedent(self):\n  self.current_indent -= self.indent_increment\n  assert self.current_indent >= 0, \"Indent decreased below 0.\"\n  self.level -= 1\n  \n def format_usage(self, usage):\n  raise NotImplementedError(\"subclasses must implement\")\n  \n def format_heading(self, heading):\n  raise NotImplementedError(\"subclasses must implement\")\n  \n def _format_text(self, text):\n  \"\"\n  text_width = self.width - self.current_indent\n  indent = \" \"*self.current_indent\n  return textwrap.fill(text,\n  text_width,\n  initial_indent=indent,\n  subsequent_indent=indent)\n  \n def format_description(self, description):\n  if description:\n   return self._format_text(description) + \"\\n\"\n  else:\n   return \"\"\n   \n def format_epilog(self, epilog):\n  if epilog:\n   return \"\\n\" + self._format_text(epilog) + \"\\n\"\n  else:\n   return \"\"\n   \n   \n def expand_default(self, option):\n  if self.parser is None or not self.default_tag:\n   return option.help\n   \n  default_value = self.parser.defaults.get(option.dest)\n  if default_value is NO_DEFAULT or default_value is None:\n   default_value = self.NO_DEFAULT_VALUE\n   \n  return option.help.replace(self.default_tag, str(default_value))\n  \n def format_option(self, option):\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  result = []\n  opts = self.option_strings[option]\n  opt_width = self.help_position - self.current_indent - 2\n  if len(opts) > opt_width:\n   opts = \"%*s%s\\n\" % (self.current_indent, \"\", opts)\n   indent_first = self.help_position\n  else: \n   opts = \"%*s%-*s  \" % (self.current_indent, \"\", opt_width, opts)\n   indent_first = 0\n  result.append(opts)\n  if option.help:\n   help_text = self.expand_default(option)\n   help_lines = textwrap.wrap(help_text, self.help_width)\n   result.append(\"%*s%s\\n\" % (indent_first, \"\", help_lines[0]))\n   result.extend([\"%*s%s\\n\" % (self.help_position, \"\", line)\n   for line in help_lines[1:]])\n  elif opts[-1] != \"\\n\":\n   result.append(\"\\n\")\n  return \"\".join(result)\n  \n def store_option_strings(self, parser):\n  self.indent()\n  max_len = 0\n  for opt in parser.option_list:\n   strings = self.format_option_strings(opt)\n   self.option_strings[opt] = strings\n   max_len = max(max_len, len(strings) + self.current_indent)\n  self.indent()\n  for group in parser.option_groups:\n   for opt in group.option_list:\n    strings = self.format_option_strings(opt)\n    self.option_strings[opt] = strings\n    max_len = max(max_len, len(strings) + self.current_indent)\n  self.dedent()\n  self.dedent()\n  self.help_position = min(max_len + 2, self.max_help_position)\n  self.help_width = self.width - self.help_position\n  \n def format_option_strings(self, option):\n  \"\"\n  if option.takes_value():\n   metavar = option.metavar or option.dest.upper()\n   short_opts = [self._short_opt_fmt % (sopt, metavar)\n   for sopt in option._short_opts]\n   long_opts = [self._long_opt_fmt % (lopt, metavar)\n   for lopt in option._long_opts]\n  else:\n   short_opts = option._short_opts\n   long_opts = option._long_opts\n   \n  if self.short_first:\n   opts = short_opts + long_opts\n  else:\n   opts = long_opts + short_opts\n   \n  return \", \".join(opts)\n  \nclass IndentedHelpFormatter (HelpFormatter):\n \"\"\n \n def __init__(self,\n indent_increment=2,\n max_help_position=24,\n width=None,\n short_first=1):\n  HelpFormatter.__init__(\n  self, indent_increment, max_help_position, width, short_first)\n  \n def format_usage(self, usage):\n  return _(\"Usage: %s\\n\") % usage\n  \n def format_heading(self, heading):\n  return \"%*s%s:\\n\" % (self.current_indent, \"\", heading)\n  \n  \nclass TitledHelpFormatter (HelpFormatter):\n \"\"\n \n def __init__(self,\n indent_increment=0,\n max_help_position=24,\n width=None,\n short_first=0):\n  HelpFormatter.__init__ (\n  self, indent_increment, max_help_position, width, short_first)\n  \n def format_usage(self, usage):\n  return \"%s  %s\\n\" % (self.format_heading(_(\"Usage\")), usage)\n  \n def format_heading(self, heading):\n  return \"%s\\n%s\\n\" % (heading, \"=-\"[self.level] * len(heading))\n  \n  \ndef _parse_num(val, type):\n if val[:2].lower() == \"0x\": \n  radix = 16\n elif val[:2].lower() == \"0b\": \n  radix = 2\n  val = val[2:] or \"0\" \n elif val[:1] == \"0\": \n  radix = 8\n else: \n  radix = 10\n  \n return type(val, radix)\n \ndef _parse_int(val):\n return _parse_num(val, int)\n \n_builtin_cvt = { \"int\" : (_parse_int, _(\"integer\")),\n\"long\" : (_parse_int, _(\"integer\")),\n\"float\" : (float, _(\"floating-point\")),\n\"complex\" : (complex, _(\"complex\")) }\n\ndef check_builtin(option, opt, value):\n (cvt, what) = _builtin_cvt[option.type]\n try:\n  return cvt(value)\n except ValueError:\n  raise OptionValueError(\n  _(\"option %s: invalid %s value: %r\") % (opt, what, value))\n  \ndef check_choice(option, opt, value):\n if value in option.choices:\n  return value\n else:\n  choices = \", \".join(map(repr, option.choices))\n  raise OptionValueError(\n  _(\"option %s: invalid choice: %r (choose from %s)\")\n  % (opt, value, choices))\n  \n  \n  \nNO_DEFAULT = (\"NO\", \"DEFAULT\")\n\n\nclass Option:\n \"\"\n \n \n \n ATTRS = ['action',\n 'type',\n 'dest',\n 'default',\n 'nargs',\n 'const',\n 'choices',\n 'callback',\n 'callback_args',\n 'callback_kwargs',\n 'help',\n 'metavar']\n \n \n \n ACTIONS = (\"store\",\n \"store_const\",\n \"store_true\",\n \"store_false\",\n \"append\",\n \"append_const\",\n \"count\",\n \"callback\",\n \"help\",\n \"version\")\n \n \n \n \n STORE_ACTIONS = (\"store\",\n \"store_const\",\n \"store_true\",\n \"store_false\",\n \"append\",\n \"append_const\",\n \"count\")\n \n \n \n TYPED_ACTIONS = (\"store\",\n \"append\",\n \"callback\")\n \n \n \n ALWAYS_TYPED_ACTIONS = (\"store\",\n \"append\")\n \n \n CONST_ACTIONS = (\"store_const\",\n \"append_const\")\n \n \n \n TYPES = (\"string\", \"int\", \"long\", \"float\", \"complex\", \"choice\")\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n TYPE_CHECKER = { \"int\" : check_builtin,\n \"long\" : check_builtin,\n \"float\" : check_builtin,\n \"complex\": check_builtin,\n \"choice\" : check_choice,\n }\n \n \n \n \n \n \n \n \n \n \n CHECK_METHODS = None\n \n \n \n \n def __init__(self, *opts, **attrs):\n \n \n  self._short_opts = []\n  self._long_opts = []\n  opts = self._check_opt_strings(opts)\n  self._set_opt_strings(opts)\n  \n  \n  self._set_attrs(attrs)\n  \n  \n  \n  \n  \n  \n  for checker in self.CHECK_METHODS:\n   checker(self)\n   \n def _check_opt_strings(self, opts):\n \n \n \n  opts = [opt for opt in opts if opt]\n  if not opts:\n   raise TypeError(\"at least one option string must be supplied\")\n  return opts\n  \n def _set_opt_strings(self, opts):\n  for opt in opts:\n   if len(opt) < 2:\n    raise OptionError(\n    \"invalid option string %r: \"\n    \"must be at least two characters long\" % opt, self)\n   elif len(opt) == 2:\n    if not (opt[0] == \"-\" and opt[1] != \"-\"):\n     raise OptionError(\n     \"invalid short option string %r: \"\n     \"must be of the form -x, (x any non-dash char)\" % opt,\n     self)\n    self._short_opts.append(opt)\n   else:\n    if not (opt[0:2] == \"--\" and opt[2] != \"-\"):\n     raise OptionError(\n     \"invalid long option string %r: \"\n     \"must start with --, followed by non-dash\" % opt,\n     self)\n    self._long_opts.append(opt)\n    \n def _set_attrs(self, attrs):\n  for attr in self.ATTRS:\n   if attr in attrs:\n    setattr(self, attr, attrs[attr])\n    del attrs[attr]\n   else:\n    if attr == 'default':\n     setattr(self, attr, NO_DEFAULT)\n    else:\n     setattr(self, attr, None)\n  if attrs:\n   attrs = sorted(attrs.keys())\n   raise OptionError(\n   \"invalid keyword arguments: %s\" % \", \".join(attrs),\n   self)\n   \n   \n   \n   \n def _check_action(self):\n  if self.action is None:\n   self.action = \"store\"\n  elif self.action not in self.ACTIONS:\n   raise OptionError(\"invalid action: %r\" % self.action, self)\n   \n def _check_type(self):\n  if self.type is None:\n   if self.action in self.ALWAYS_TYPED_ACTIONS:\n    if self.choices is not None:\n    \n     self.type = \"choice\"\n    else:\n    \n     self.type = \"string\"\n  else:\n  \n  \n  \n  \n  \n   import builtins\n   if ( isinstance(self.type, type) or\n   (hasattr(self.type, \"__name__\") and\n   getattr(builtins, self.type.__name__, None) is self.type) ):\n    self.type = self.type.__name__\n    \n   if self.type == \"str\":\n    self.type = \"string\"\n    \n   if self.type not in self.TYPES:\n    raise OptionError(\"invalid option type: %r\" % self.type, self)\n   if self.action not in self.TYPED_ACTIONS:\n    raise OptionError(\n    \"must not supply a type for action %r\" % self.action, self)\n    \n def _check_choice(self):\n  if self.type == \"choice\":\n   if self.choices is None:\n    raise OptionError(\n    \"must supply a list of choices for type 'choice'\", self)\n   elif not isinstance(self.choices, (tuple, list)):\n    raise OptionError(\n    \"choices must be a list of strings ('%s' supplied)\"\n    % str(type(self.choices)).split(\"'\")[1], self)\n  elif self.choices is not None:\n   raise OptionError(\n   \"must not supply choices for type %r\" % self.type, self)\n   \n def _check_dest(self):\n \n \n  takes_value = (self.action in self.STORE_ACTIONS or\n  self.type is not None)\n  if self.dest is None and takes_value:\n  \n  \n  \n   if self._long_opts:\n   \n    self.dest = self._long_opts[0][2:].replace('-', '_')\n   else:\n    self.dest = self._short_opts[0][1]\n    \n def _check_const(self):\n  if self.action not in self.CONST_ACTIONS and self.const is not None:\n   raise OptionError(\n   \"'const' must not be supplied for action %r\" % self.action,\n   self)\n   \n def _check_nargs(self):\n  if self.action in self.TYPED_ACTIONS:\n   if self.nargs is None:\n    self.nargs = 1\n  elif self.nargs is not None:\n   raise OptionError(\n   \"'nargs' must not be supplied for action %r\" % self.action,\n   self)\n   \n def _check_callback(self):\n  if self.action == \"callback\":\n   if not callable(self.callback):\n    raise OptionError(\n    \"callback not callable: %r\" % self.callback, self)\n   if (self.callback_args is not None and\n   not isinstance(self.callback_args, tuple)):\n    raise OptionError(\n    \"callback_args, if supplied, must be a tuple: not %r\"\n    % self.callback_args, self)\n   if (self.callback_kwargs is not None and\n   not isinstance(self.callback_kwargs, dict)):\n    raise OptionError(\n    \"callback_kwargs, if supplied, must be a dict: not %r\"\n    % self.callback_kwargs, self)\n  else:\n   if self.callback is not None:\n    raise OptionError(\n    \"callback supplied (%r) for non-callback option\"\n    % self.callback, self)\n   if self.callback_args is not None:\n    raise OptionError(\n    \"callback_args supplied for non-callback option\", self)\n   if self.callback_kwargs is not None:\n    raise OptionError(\n    \"callback_kwargs supplied for non-callback option\", self)\n    \n    \n CHECK_METHODS = [_check_action,\n _check_type,\n _check_choice,\n _check_dest,\n _check_const,\n _check_nargs,\n _check_callback]\n \n \n \n \n def __str__(self):\n  return \"/\".join(self._short_opts + self._long_opts)\n  \n __repr__ = _repr\n \n def takes_value(self):\n  return self.type is not None\n  \n def get_opt_string(self):\n  if self._long_opts:\n   return self._long_opts[0]\n  else:\n   return self._short_opts[0]\n   \n   \n   \n   \n def check_value(self, opt, value):\n  checker = self.TYPE_CHECKER.get(self.type)\n  if checker is None:\n   return value\n  else:\n   return checker(self, opt, value)\n   \n def convert_value(self, opt, value):\n  if value is not None:\n   if self.nargs == 1:\n    return self.check_value(opt, value)\n   else:\n    return tuple([self.check_value(opt, v) for v in value])\n    \n def process(self, opt, value, values, parser):\n \n \n \n  value = self.convert_value(opt, value)\n  \n  \n  \n  \n  return self.take_action(\n  self.action, self.dest, opt, value, values, parser)\n  \n def take_action(self, action, dest, opt, value, values, parser):\n  if action == \"store\":\n   setattr(values, dest, value)\n  elif action == \"store_const\":\n   setattr(values, dest, self.const)\n  elif action == \"store_true\":\n   setattr(values, dest, True)\n  elif action == \"store_false\":\n   setattr(values, dest, False)\n  elif action == \"append\":\n   values.ensure_value(dest, []).append(value)\n  elif action == \"append_const\":\n   values.ensure_value(dest, []).append(self.const)\n  elif action == \"count\":\n   setattr(values, dest, values.ensure_value(dest, 0) + 1)\n  elif action == \"callback\":\n   args = self.callback_args or ()\n   kwargs = self.callback_kwargs or {}\n   self.callback(self, opt, value, parser, *args, **kwargs)\n  elif action == \"help\":\n   parser.print_help()\n   parser.exit()\n  elif action == \"version\":\n   parser.print_version()\n   parser.exit()\n  else:\n   raise ValueError(\"unknown action %r\" % self.action)\n   \n  return 1\n  \n  \n  \n  \nSUPPRESS_HELP = \"SUPPRESS\"+\"HELP\"\nSUPPRESS_USAGE = \"SUPPRESS\"+\"USAGE\"\n\nclass Values:\n\n def __init__(self, defaults=None):\n  if defaults:\n   for (attr, val) in defaults.items():\n    setattr(self, attr, val)\n    \n def __str__(self):\n  return str(self.__dict__)\n  \n __repr__ = _repr\n \n def __eq__(self, other):\n  if isinstance(other, Values):\n   return self.__dict__ == other.__dict__\n  elif isinstance(other, dict):\n   return self.__dict__ == other\n  else:\n   return NotImplemented\n   \n def _update_careful(self, dict):\n  \"\"\n  for attr in dir(self):\n   if attr in dict:\n    dval = dict[attr]\n    if dval is not None:\n     setattr(self, attr, dval)\n     \n def _update_loose(self, dict):\n  \"\"\n  self.__dict__.update(dict)\n  \n def _update(self, dict, mode):\n  if mode == \"careful\":\n   self._update_careful(dict)\n  elif mode == \"loose\":\n   self._update_loose(dict)\n  else:\n   raise ValueError(\"invalid update mode: %r\" % mode)\n   \n def read_module(self, modname, mode=\"careful\"):\n  __import__(modname)\n  mod = sys.modules[modname]\n  self._update(vars(mod), mode)\n  \n def read_file(self, filename, mode=\"careful\"):\n  vars = {}\n  exec(open(filename).read(), vars)\n  self._update(vars, mode)\n  \n def ensure_value(self, attr, value):\n  if not hasattr(self, attr) or getattr(self, attr) is None:\n   setattr(self, attr, value)\n  return getattr(self, attr)\n  \n  \nclass OptionContainer:\n\n \"\"\n \n def __init__(self, option_class, conflict_handler, description):\n \n \n \n \n  self._create_option_list()\n  \n  self.option_class = option_class\n  self.set_conflict_handler(conflict_handler)\n  self.set_description(description)\n  \n def _create_option_mappings(self):\n \n \n \n  self._short_opt = {} \n  self._long_opt = {} \n  self.defaults = {} \n  \n  \n def _share_option_mappings(self, parser):\n \n \n  self._short_opt = parser._short_opt\n  self._long_opt = parser._long_opt\n  self.defaults = parser.defaults\n  \n def set_conflict_handler(self, handler):\n  if handler not in (\"error\", \"resolve\"):\n   raise ValueError(\"invalid conflict_resolution value %r\" % handler)\n  self.conflict_handler = handler\n  \n def set_description(self, description):\n  self.description = description\n  \n def get_description(self):\n  return self.description\n  \n  \n def destroy(self):\n  \"\"\n  del self._short_opt\n  del self._long_opt\n  del self.defaults\n  \n  \n  \n  \n def _check_conflict(self, option):\n  conflict_opts = []\n  for opt in option._short_opts:\n   if opt in self._short_opt:\n    conflict_opts.append((opt, self._short_opt[opt]))\n  for opt in option._long_opts:\n   if opt in self._long_opt:\n    conflict_opts.append((opt, self._long_opt[opt]))\n    \n  if conflict_opts:\n   handler = self.conflict_handler\n   if handler == \"error\":\n    raise OptionConflictError(\n    \"conflicting option string(s): %s\"\n    % \", \".join([co[0] for co in conflict_opts]),\n    option)\n   elif handler == \"resolve\":\n    for (opt, c_option) in conflict_opts:\n     if opt.startswith(\"--\"):\n      c_option._long_opts.remove(opt)\n      del self._long_opt[opt]\n     else:\n      c_option._short_opts.remove(opt)\n      del self._short_opt[opt]\n     if not (c_option._short_opts or c_option._long_opts):\n      c_option.container.option_list.remove(c_option)\n      \n def add_option(self, *args, **kwargs):\n  \"\"\n  if isinstance(args[0], str):\n   option = self.option_class(*args, **kwargs)\n  elif len(args) == 1 and not kwargs:\n   option = args[0]\n   if not isinstance(option, Option):\n    raise TypeError(\"not an Option instance: %r\" % option)\n  else:\n   raise TypeError(\"invalid arguments\")\n   \n  self._check_conflict(option)\n  \n  self.option_list.append(option)\n  option.container = self\n  for opt in option._short_opts:\n   self._short_opt[opt] = option\n  for opt in option._long_opts:\n   self._long_opt[opt] = option\n   \n  if option.dest is not None: \n   if option.default is not NO_DEFAULT:\n    self.defaults[option.dest] = option.default\n   elif option.dest not in self.defaults:\n    self.defaults[option.dest] = None\n    \n  return option\n  \n def add_options(self, option_list):\n  for option in option_list:\n   self.add_option(option)\n   \n   \n   \n def get_option(self, opt_str):\n  return (self._short_opt.get(opt_str) or\n  self._long_opt.get(opt_str))\n  \n def has_option(self, opt_str):\n  return (opt_str in self._short_opt or\n  opt_str in self._long_opt)\n  \n def remove_option(self, opt_str):\n  option = self._short_opt.get(opt_str)\n  if option is None:\n   option = self._long_opt.get(opt_str)\n  if option is None:\n   raise ValueError(\"no such option %r\" % opt_str)\n   \n  for opt in option._short_opts:\n   del self._short_opt[opt]\n  for opt in option._long_opts:\n   del self._long_opt[opt]\n  option.container.option_list.remove(option)\n  \n  \n  \n  \n def format_option_help(self, formatter):\n  if not self.option_list:\n   return \"\"\n  result = []\n  for option in self.option_list:\n   if not option.help is SUPPRESS_HELP:\n    result.append(formatter.format_option(option))\n  return \"\".join(result)\n  \n def format_description(self, formatter):\n  return formatter.format_description(self.get_description())\n  \n def format_help(self, formatter):\n  result = []\n  if self.description:\n   result.append(self.format_description(formatter))\n  if self.option_list:\n   result.append(self.format_option_help(formatter))\n  return \"\\n\".join(result)\n  \n  \nclass OptionGroup (OptionContainer):\n\n def __init__(self, parser, title, description=None):\n  self.parser = parser\n  OptionContainer.__init__(\n  self, parser.option_class, parser.conflict_handler, description)\n  self.title = title\n  \n def _create_option_list(self):\n  self.option_list = []\n  self._share_option_mappings(self.parser)\n  \n def set_title(self, title):\n  self.title = title\n  \n def destroy(self):\n  \"\"\n  OptionContainer.destroy(self)\n  del self.option_list\n  \n  \n  \n def format_help(self, formatter):\n  result = formatter.format_heading(self.title)\n  formatter.indent()\n  result += OptionContainer.format_help(self, formatter)\n  formatter.dedent()\n  return result\n  \n  \nclass OptionParser (OptionContainer):\n\n \"\"\n \n standard_option_list = []\n \n def __init__(self,\n usage=None,\n option_list=None,\n option_class=Option,\n version=None,\n conflict_handler=\"error\",\n description=None,\n formatter=None,\n add_help_option=True,\n prog=None,\n epilog=None):\n  OptionContainer.__init__(\n  self, option_class, conflict_handler, description)\n  self.set_usage(usage)\n  self.prog = prog\n  self.version = version\n  self.allow_interspersed_args = True\n  self.process_default_values = True\n  if formatter is None:\n   formatter = IndentedHelpFormatter()\n  self.formatter = formatter\n  self.formatter.set_parser(self)\n  self.epilog = epilog\n  \n  \n  \n  \n  \n  self._populate_option_list(option_list,\n  add_help=add_help_option)\n  \n  self._init_parsing_state()\n  \n  \n def destroy(self):\n  \"\"\n  OptionContainer.destroy(self)\n  for group in self.option_groups:\n   group.destroy()\n  del self.option_list\n  del self.option_groups\n  del self.formatter\n  \n  \n  \n  \n  \n def _create_option_list(self):\n  self.option_list = []\n  self.option_groups = []\n  self._create_option_mappings()\n  \n def _add_help_option(self):\n  self.add_option(\"-h\", \"--help\",\n  action=\"help\",\n  help=_(\"show this help message and exit\"))\n  \n def _add_version_option(self):\n  self.add_option(\"--version\",\n  action=\"version\",\n  help=_(\"show program's version number and exit\"))\n  \n def _populate_option_list(self, option_list, add_help=True):\n  if self.standard_option_list:\n   self.add_options(self.standard_option_list)\n  if option_list:\n   self.add_options(option_list)\n  if self.version:\n   self._add_version_option()\n  if add_help:\n   self._add_help_option()\n   \n def _init_parsing_state(self):\n \n  self.rargs = None\n  self.largs = None\n  self.values = None\n  \n  \n  \n  \n def set_usage(self, usage):\n  if usage is None:\n   self.usage = _(\"%prog [options]\")\n  elif usage is SUPPRESS_USAGE:\n   self.usage = None\n   \n  elif usage.lower().startswith(\"usage: \"):\n   self.usage = usage[7:]\n  else:\n   self.usage = usage\n   \n def enable_interspersed_args(self):\n  \"\"\n  self.allow_interspersed_args = True\n  \n def disable_interspersed_args(self):\n  \"\"\n  self.allow_interspersed_args = False\n  \n def set_process_default_values(self, process):\n  self.process_default_values = process\n  \n def set_default(self, dest, value):\n  self.defaults[dest] = value\n  \n def set_defaults(self, **kwargs):\n  self.defaults.update(kwargs)\n  \n def _get_all_options(self):\n  options = self.option_list[:]\n  for group in self.option_groups:\n   options.extend(group.option_list)\n  return options\n  \n def get_default_values(self):\n  if not self.process_default_values:\n  \n   return Values(self.defaults)\n   \n  defaults = self.defaults.copy()\n  for option in self._get_all_options():\n   default = defaults.get(option.dest)\n   if isinstance(default, str):\n    opt_str = option.get_opt_string()\n    defaults[option.dest] = option.check_value(opt_str, default)\n    \n  return Values(defaults)\n  \n  \n  \n  \n def add_option_group(self, *args, **kwargs):\n \n  if isinstance(args[0], str):\n   group = OptionGroup(self, *args, **kwargs)\n  elif len(args) == 1 and not kwargs:\n   group = args[0]\n   if not isinstance(group, OptionGroup):\n    raise TypeError(\"not an OptionGroup instance: %r\" % group)\n   if group.parser is not self:\n    raise ValueError(\"invalid OptionGroup (wrong parser)\")\n  else:\n   raise TypeError(\"invalid arguments\")\n   \n  self.option_groups.append(group)\n  return group\n  \n def get_option_group(self, opt_str):\n  option = (self._short_opt.get(opt_str) or\n  self._long_opt.get(opt_str))\n  if option and option.container is not self:\n   return option.container\n  return None\n  \n  \n  \n  \n def _get_args(self, args):\n  if args is None:\n   return sys.argv[1:]\n  else:\n   return args[:] \n   \n def parse_args(self, args=None, values=None):\n  \"\"\n  rargs = self._get_args(args)\n  if values is None:\n   values = self.get_default_values()\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n  self.rargs = rargs\n  self.largs = largs = []\n  self.values = values\n  \n  try:\n   stop = self._process_args(largs, rargs, values)\n  except (BadOptionError, OptionValueError) as err:\n   self.error(str(err))\n   \n  args = largs + rargs\n  return self.check_values(values, args)\n  \n def check_values(self, values, args):\n  \"\"\n  return (values, args)\n  \n def _process_args(self, largs, rargs, values):\n  \"\"\n  while rargs:\n   arg = rargs[0]\n   \n   \n   \n   if arg == \"--\":\n    del rargs[0]\n    return\n   elif arg[0:2] == \"--\":\n   \n    self._process_long_opt(rargs, values)\n   elif arg[:1] == \"-\" and len(arg) > 1:\n   \n   \n    self._process_short_opts(rargs, values)\n   elif self.allow_interspersed_args:\n    largs.append(arg)\n    del rargs[0]\n   else:\n    return \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n def _match_long_opt(self, opt):\n  \"\"\n  return _match_abbrev(opt, self._long_opt)\n  \n def _process_long_opt(self, rargs, values):\n  arg = rargs.pop(0)\n  \n  \n  \n  if \"=\" in arg:\n   (opt, next_arg) = arg.split(\"=\", 1)\n   rargs.insert(0, next_arg)\n   had_explicit_value = True\n  else:\n   opt = arg\n   had_explicit_value = False\n   \n  opt = self._match_long_opt(opt)\n  option = self._long_opt[opt]\n  if option.takes_value():\n   nargs = option.nargs\n   if len(rargs) < nargs:\n    self.error(ngettext(\n    \"%(option)s option requires %(number)d argument\",\n    \"%(option)s option requires %(number)d arguments\",\n    nargs) % {\"option\": opt, \"number\": nargs})\n   elif nargs == 1:\n    value = rargs.pop(0)\n   else:\n    value = tuple(rargs[0:nargs])\n    del rargs[0:nargs]\n    \n  elif had_explicit_value:\n   self.error(_(\"%s option does not take a value\") % opt)\n   \n  else:\n   value = None\n   \n  option.process(opt, value, values, self)\n  \n def _process_short_opts(self, rargs, values):\n  arg = rargs.pop(0)\n  stop = False\n  i = 1\n  for ch in arg[1:]:\n   opt = \"-\" + ch\n   option = self._short_opt.get(opt)\n   i += 1 \n   \n   if not option:\n    raise BadOptionError(opt)\n   if option.takes_value():\n   \n   \n    if i < len(arg):\n     rargs.insert(0, arg[i:])\n     stop = True\n     \n    nargs = option.nargs\n    if len(rargs) < nargs:\n     self.error(ngettext(\n     \"%(option)s option requires %(number)d argument\",\n     \"%(option)s option requires %(number)d arguments\",\n     nargs) % {\"option\": opt, \"number\": nargs})\n    elif nargs == 1:\n     value = rargs.pop(0)\n    else:\n     value = tuple(rargs[0:nargs])\n     del rargs[0:nargs]\n     \n   else: \n    value = None\n    \n   option.process(opt, value, values, self)\n   \n   if stop:\n    break\n    \n    \n    \n    \n def get_prog_name(self):\n  if self.prog is None:\n   return os.path.basename(sys.argv[0])\n  else:\n   return self.prog\n   \n def expand_prog_name(self, s):\n  return s.replace(\"%prog\", self.get_prog_name())\n  \n def get_description(self):\n  return self.expand_prog_name(self.description)\n  \n def exit(self, status=0, msg=None):\n  if msg:\n   sys.stderr.write(msg)\n  sys.exit(status)\n  \n def error(self, msg):\n  \"\"\n  self.print_usage(sys.stderr)\n  self.exit(2, \"%s: error: %s\\n\" % (self.get_prog_name(), msg))\n  \n def get_usage(self):\n  if self.usage:\n   return self.formatter.format_usage(\n   self.expand_prog_name(self.usage))\n  else:\n   return \"\"\n   \n def print_usage(self, file=None):\n  \"\"\n  if self.usage:\n   print(self.get_usage(), file=file)\n   \n def get_version(self):\n  if self.version:\n   return self.expand_prog_name(self.version)\n  else:\n   return \"\"\n   \n def print_version(self, file=None):\n  \"\"\n  if self.version:\n   print(self.get_version(), file=file)\n   \n def format_option_help(self, formatter=None):\n  if formatter is None:\n   formatter = self.formatter\n  formatter.store_option_strings(self)\n  result = []\n  result.append(formatter.format_heading(_(\"Options\")))\n  formatter.indent()\n  if self.option_list:\n   result.append(OptionContainer.format_option_help(self, formatter))\n   result.append(\"\\n\")\n  for group in self.option_groups:\n   result.append(group.format_help(formatter))\n   result.append(\"\\n\")\n  formatter.dedent()\n  \n  return \"\".join(result[:-1])\n  \n def format_epilog(self, formatter):\n  return formatter.format_epilog(self.epilog)\n  \n def format_help(self, formatter=None):\n  if formatter is None:\n   formatter = self.formatter\n  result = []\n  if self.usage:\n   result.append(self.get_usage() + \"\\n\")\n  if self.description:\n   result.append(self.format_description(formatter) + \"\\n\")\n  result.append(self.format_option_help(formatter))\n  result.append(self.format_epilog(formatter))\n  return \"\".join(result)\n  \n def print_help(self, file=None):\n  \"\"\n  if file is None:\n   file = sys.stdout\n  file.write(self.format_help())\n  \n  \n  \n  \ndef _match_abbrev(s, wordmap):\n \"\"\n \n if s in wordmap:\n  return s\n else:\n \n  possibilities = [word for word in wordmap.keys()\n  if word.startswith(s)]\n  \n  if len(possibilities) == 1:\n   return possibilities[0]\n  elif not possibilities:\n   raise BadOptionError(s)\n  else:\n  \n   possibilities.sort()\n   raise AmbiguousOptionError(s, possibilities)\n   \n   \n   \n   \n   \n   \nmake_option = Option\n"]};

